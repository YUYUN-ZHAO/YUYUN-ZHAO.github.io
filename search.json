[{"title":"【MyBatis】MyBatis-Plus","url":"/2021/12/29/【MyBatis】MyBatis-Plus/","content":"\n## 简介\n\n> https://baomidou.com/pages/24112f/\n\n\n\nBaseMapper\n\n常用方法\n\nrenren-fast-generator 的自动逆向工程\n\n\n\n```\n/**\n * 商品id，需要自己输入主键（因为数据库里该字段并非自增的主键，而是需要手动传入的值，\n * 如果不写，MyBatis-Plus会默认把它当做自增主键，就无法插入该字段）\n */\n@TableId(type = IdType.INPUT)\nprivate Long spuId;\n/**\n```\n\n分页插件\n\n```java\n@Configuration\n@EnableTransactionManagement\n@MapperScan(\"com.zhao.yunmall.product.dao\")\npublic class MyBatisConfig {\n\n    /**\n    * 注入MyBatis-Plus的分页插件\n    */\n    @Bean\n    public PaginationInterceptor paginationInterceptor() {\n        PaginationInterceptor paginationInterceptor = new PaginationInterceptor();\n        // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求  默认false\n        paginationInterceptor.setOverflow(true);\n        // 设置最大单页限制数量，默认 500 条，-1 不受限制\n        paginationInterceptor.setLimit(500);\n        // 开启 count 的 join 优化,只针对部分 left join\n        paginationInterceptor.setCountSqlParser(new JsqlParserCountOptimize(true));\n        return paginationInterceptor;\n    }\n}\n```\n\n\n\n\n\n\n\n开启日志\n\n\n\n```\nlogging:\n  level:\n    com.zhao.yunmall: debug\n```","tags":["MyBatis","SSM"],"categories":["MyBatis","SSM"]},{"title":"【Project】云商城","url":"/2021/12/20/【Project】云商城/","content":"\n从零开始的云商城项目。\n\n# 前言\n\n## 简介\n\n阿里云服务器\n\n- CPU & 内存：1 核 & 2 GiB\n- 地址：www.yuyunzhao.cn（47.98.120.35）\n\n\n\n\n\n### 各个服务的端口号\n\n- MySQL：3306\n- Redis：6379\n- ElasticSearch：9200\n- Kibana：5601\n- Nginx：80\n\n\n\n### 微服务技术栈\n\n**结合 Spring Cloud Alibaba 我们最终的技术搭配方案：**\n\n- Spring Cloud Alibaba - Nacos：注册中心（服务发现/注册）\n- Spring Cloud Alibaba - Nacos：配置中心（动态配置管理）\n- Spring Cloud - Ribbon：负载均衡\n- Spring Cloud - Feign：声明式 HTTP 客户端（调用远程服务）\n- Spring Cloud Alibaba - Sentinel：服务容错（限流、降级、熔断）\n- Spring Cloud - Gateway：API 网关（webflux 编程模式）\n- Spring Cloud - Sleuth：调用链监控\n- Spring Cloud Alibaba - Seata：原Fescar，即分布式事务解决方案\n\n\n\n\n\nvue npm 的总结文档\n\n\n\n<!-- More -->\n\n# 环境准备\n\n## 环境配置\n\n### MyBatis-Plus & 数据库\n\n1、 导入数据库驱动以及 MyBatis-Plus 的 Maven 依赖：\n\n```xml\n<dependencies>\n    <!-- 导入 mysql 驱动，官方推荐 8.0 版本 -->\n    <dependency>\n        <groupId>mysql</groupId>\n        <artifactId>mysql-connector-java</artifactId>\n        <version>8.0.22</version>\n    </dependency>\n    \n    <!-- 导入 MyBatis-plus 的场景启动器 -->\n    <!-- 无需额外导入 MyBatis、Mybatis-Spring 等依赖，其由 MyBatis-plus 自动维护 -->\n    <dependency>\n        <groupId>com.baomidou</groupId>\n        <artifactId>mybatis-plus-boot-starter</artifactId>\n        <version>3.2.0</version>\n    </dependency>\n</dependencies>\n```\n\n2、在 `application.yaml` 中配置数据源以及 MyBatis-Plus 的相关信息：\n\n```yaml\nspring:\n  datasource:\n    username: root\n    password: zhaoyuyun\n    url: jdbc:mysql://47.98.120.35:3306/yunmall_pms?useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai\n    # 若使用 MySQl 5.0 版本的驱动，则类名为：com.mysql.jdbc.Driver\n    driver-class-name: com.mysql.cj.jdbc.Driver\n\nmybatis-plus:\n  mapperLocations: classpath:mapper/**/*.xml\n  global-config:\n    db-config:\n      # 设置主键自增\n      id-type: auto\n      # 设置逻辑删除\n      logic-delete-value: 1     # 逻辑已删除值(默认为 1)\n      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)\n```\n\n### Spring Boot2\n\n1、导入 Spring Boot2 相关依赖：\n\n``` xml\n<!-- 继承 Spring Boot 父工程，其由继承自 spring-boot-dependencies，里面管理了大量的jar包 -->\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.3.4.RELEASE</version>\n</parent>\n\n<dependencies>\n    <!-- 导入 Spring Boot 依赖，版本默认使用 spring-boot-starter-parent 里指定的版本 -->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <!-- 导入 Spring Boot 测试依赖 -->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n\n<build>\n    <plugins>\n        <plugin>\n            <!-- 以Maven的方式为Spring Boot应用提供支持，能够将Spring Boot应用打包为可执行的jar或war文件，进行相应部署后即可启动Spring Boot应用 -->\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n            <configuration>\n                <fork>true</fork>\n                <addResources>true</addResources>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n2、在 `application.yaml` 中进行配置：\n\n``` yaml\n\n```\n\n\n\n### Spring Cloud\n\n1、 导入相关依赖（注意需要和 Spring Boot 的版本对应上，否则无法启动项目）：\n\n版本对应查询：https://spring.io/projects/spring-cloud\n\n``` xml\n\n\n\n<dependencyManagement>\n    <dependencies>\n        <!-- 作用类似于 spring-boot-starter-parent 中的 spring-boot-dependencies，都是用于各种依赖的版本控制 -->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-dependencies</artifactId>\n            <version>Hoxton.SR3</version>\n            <!-- 以 pom 形式将所有的相关依赖都导入到当前位置，这样继承自该模块的子模块就可以直接使用它导入的依赖而不需要写版本号 -->\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\n\n\n在这里整理 Nacos 等所有cloud的技术栈依赖\n\n再配上配置文件里的各个技术栈的参数配置\n\n\n\n\n\n\n\n只有配置中心写在bootstrap\n\n\n\n### Spring Cloud Alibaba Nacos\n\nnacos 里的  可以单独使用的\n\n```\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n    <version>2.2.1.RELEASE</version>\n</dependency>\n```\n\n以后补充 Nacos 的配置文件的实例\n\n\n\n\n\n总结一份 完整的 配置文件\n\n\n\n\n\n\n\n## 后台管理系统前端工程\n\n本项目的后台管理系统的前端工程选择基于人人开源的 `renren-fast-vue` 项目进行快速开发，其提供了整个后台管理系统的框架与基本功能。该项目将与人人开源的后端工程 `renren-fast` 配合使用。\n\n整个工程的结构：\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20220101132840890.png\" alt=\"image-20220101132840890\" style=\"zoom:67%;\" />\n\n其中，`/src/views` 目录下的文件将显示在前端页面上，我们主要在其内进行开发，为每个功能创建相应的前端界面。具体介绍见下文。\n\n### 启动项目\n\n> https://www.cnblogs.com/misscai/p/12809404.html\n\n该工程的启动流程：\n\n1. 切换淘宝镜像安装\n\n``` bash\nnpm install -g cnpm --registry=https://registry.npm.taobao.org\n```\n\n2. 设置权限：输入 `set-ExecutionPolicy RemoteSigned` 选择 A\n3. 安装依赖\n\n``` bash\ncnpm install\n```\n\n4. 启动项目\n\n``` bash\nnpm run dev\n```\n\n下面介绍如何为该前端项目创建自定义的功能菜单。\n\n### 创建分类维护页面\n\n首先在人人快速开发平台中新建一个**商品系统**菜单，然后在其内新增一个**分类维护**菜单：\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227203054809.png\" alt=\"image-20211227203054809\" style=\"zoom:50%;\" />\n\n然后根据在菜单路由中配置的 `prodcut/category`，我们需要在 `renren-fast-vue` 项目的 `src/views/modules/` 目录下创建一个 `product `文件夹，代表前面创建的**商品系统**菜单，该菜单下的所有子菜单的页面都应该在该文件夹下。然后根据当前的**分类维护**页面创建一个 `category.vue` 文件。目录结构如下：\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227203307572.png\" alt=\"image-20211227203307572\" style=\"zoom:50%;\" />\n\n在其内编写代码即可在 `http:/xxx/#/product-category` 页面生成对应组件。\n\n## 前后端数据通讯\n\n本项目采用前后端分离技术分别部署前端项目 `renren-fast-vue` 和后端众多服务。数据通讯方式为：前端发出 POST/GET 请求给后端，以 JSON 形式传输数据。\n\n> 详细接口文档：https://easydoc.net/s/78237135/ZUqEdvA4/hKJTcbfd\n\n后端统一将返回结果封装到 R 对象中：\n\n```java\n/**\n * 返回数据\n */\npublic class R extends HashMap<String, Object> {\n    private static final long serialVersionUID = 1L;\n\n    public R() {\n        put(\"code\", 0);\n        put(\"msg\", \"success\");\n    }\n\n    public static R error() {\n        return error(HttpStatus.SC_INTERNAL_SERVER_ERROR, \"未知异常，请联系管理员\");\n    }\n\n    public static R error(String msg) {\n        return error(HttpStatus.SC_INTERNAL_SERVER_ERROR, msg);\n    }\n\n    public static R error(int code, String msg) {\n        R r = new R();\n        r.put(\"code\", code);\n        r.put(\"msg\", msg);\n        return r;\n    }\n\n    public static R ok(String msg) {\n        R r = new R();\n        r.put(\"msg\", msg);\n        return r;\n    }\n\n    public static R ok(Map<String, Object> map) {\n        R r = new R();\n        r.putAll(map);\n        return r;\n    }\n\n    public static R ok() {\n        return new R();\n    }\n\n    public R put(String key, Object value) {\n        super.put(key, value);\n        return this;\n    }\n}\n```\n\n该对象继承自 `HashMap`，Controller 层将会把该对象转换成 JSON 字符串发送给前端，前端接收到数据后，通过 `response.data` 获取到后端发送的真实数据，例如：\n\n```java\n/**\n * 将数据封装到 R 中，其将会被转换成 JSON 字符串发送给前端（因为 @ResponseBody 注解）\n */\n@ResponseBody\n@RequestMapping(\"/list/tree\")\npublic R list(){\n    // 将所有数据以树形结构组织\n    List<CategoryEntity> entities = categoryService.listWithTree();\n    // key: data 就是和前端约定好的格式，前端将通过 response.data 获取到后端发送的真实数据\n    return R.ok().put(\"data\", entities);\n}\n```\n\n> 注意后端 Controller 层必须按照该协议封装成 R 对象，因为和前端的通讯协议里，都是从response.data 中获取数据，如果不按照该协议，前端将无法解析到后端发送的数据\n\n其中，前端项目在发出 GET 请求时，都会在最后拼接上一个**时间戳**参数 `url = xxxxxx?t=new Data().getTime()`：\n\n``` js\n/**\n * get请求参数处理\n * @param {*} params 参数对象\n * @param {*} openDefultParams 是否开启默认参数?\n */\nhttp.adornParams = (params = {}, openDefultParams = true) => {\n    var defaults = {\n        't': new Date().getTime()\n    }\n    return openDefultParams ? merge(defaults, params) : params\n}\n```\n\n这是因为浏览器向服务器发出的 GET 请求如果和之前一样，会直接返回**缓存**的结果，而不会向服务器发出新的请求。因此需要在后面带个一个时间戳参数，使得每一次发出的请求都不相同，这样浏览器就不会返回缓存结果了。\n\n前端发出 POST 请求的模板：\n\n``` js\n/**\n * post请求数据处理\n * @param {*} data 数据对象\n * @param {*} openDefultdata 是否开启默认数据?\n * @param {*} contentType 数据格式\n *  json: 'application/json; charset=utf-8'\n *  form: 'application/x-www-form-urlencoded; charset=utf-8'\n */\nhttp.adornData = (data = {}, openDefultdata = true, contentType = 'json') => {\n    var defaults = {\n        't': new Date().getTime()\n    }\n    data = openDefultdata ? merge(defaults, data) : data\n    return contentType === 'json' ? JSON.stringify(data) : qs.stringify(data)\n}\n```\n\n其中，data 为传入的 JSON 对象，后端将使用 `@RequestBody` 注解解析该对象数据，并同样返回一个 JSON 对象给前端：\n\n```java\n@RequestMapping(\"/update\")\npublic R update(@RequestBody CategoryEntity category){\n    categoryService.updateById(category);\n    return R.ok();\n}\n```\n\n\n\n# 微服务间调用\n\nnacos\n\nfeign等等的配置\n\n\n\n正向代理：帮忙访问别人，客户端信息被屏蔽\n\n反向代理：帮忙被别人访问，服务端信息被屏蔽\n\n只有 postmapping 的请求体里才能放json数据\n\n\n\nMP：查询多个就用\n\nselectList(new QueryWrapper().eq()...)\n\n\n\n\n\n\n\n# 第三方服务\n\n本项目中的所有图片信息都选择存储在阿里云的 OSS 中，在数据库中仅保存这些图片在 OSS 中的 URL。前端在本地选择好图片后，将向第三方服务发出请求获取**许可签名**，在收到签名后，前端将使用许可密码信息向阿里云 OSS 中的指定 Bucket 发出请求保存选中的图片数据。\n\n第三方服务仅用于向阿里云 OSS 获取许可签名，真正的上传工作由前端完成。\n\n> https://help.aliyun.com/document_detail/31926.html\n\n![img](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/p139016.png)\n\n## OSS\n\n对象存储服务（Object Storage Service，OSS）用于是一种海量、安全、低成本、高可靠的云存储服务，适合存放任意类型的文件。容量和处理能力弹性扩展，多种存储类型供选择，全面优化存储成本。\n\n### 创建 Bucket\n\n创建自己的对象存储 Bucket：`yunmall-project`\n\n![image-20211227212122593](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227212122593.png)\n\n设置读写权限为**公共读**：\n\n![image-20220101152432522](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20220101152432522.png)\n\n\n\n### 配置第三方服务\n\n1. 导入阿里云 OSS 的场景启动器依赖：\n\n```xml\n<!-- 阿里云OSS，对于某些SpringBoot版本的场景启动器，需要特别指定版本，否则会无法导入-->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alicloud-oss</artifactId>\n    <version>2.2.0.RELEASE</version>\n</dependency>\n```\n\n2. 配置文件：\n\n```yaml\nserver:\n  port: 30000\n\nspring:\n  cloud:\n    nacos:\n      # 服务注册中心\n      discovery:\n        server-addr: localhost:8848\n    # 阿里云OSS配置    \n    alicloud:\n      # 自己阿里云账号下的RAM用户的访问密码，注意不能使用自己阿里云账号的访问密码！\n      access-key: LTAI5tPg8hhbq8wNcjPS9uiv\n      secret-key: Bylo34G1xcs3cnQejXC4tpuJ0Ybrkw\n      oss:\n        endpoint: oss-cn-hangzhou.aliyuncs.com\n        bucket: yunmall-project\n        \n# endpoint填写Bucket所在地域对应的Endpoint。以华东1（杭州）为例，Endpoint填写为https://oss-cn-hangzhou.aliyuncs.com。\n# \n```\n\n3. 在网关中配置第三方服务的路由规则：\n\n```yaml\nspring:\n  application:\n    name: yunmall-gateway\n  cloud:\n    nacos:\n      # 注册中心\n      discovery:\n        server-addr: localhost:8848\n    gateway:\n      routes:\n        # 第三方服务的路由规则\n        - id: third-party-route\n          uri: lb://yunmall-third-party\n          predicates:\n            - Path=/api/third-party/**\n          filters:\n            - RewritePath=/api/third-party/(?<segment>.*), /$\\{segment}\n```\n\n**注意**：阿里云账号 AccessKey 拥有所有 API 的访问权限，风险很高。强烈建议您创建并使用 RAM 用户进行API访问或日常运维，请登录 RAM 控制台创建 RAM 用户。\n\n---\n\nRAM 用户是 RAM 中的一种身份，对应某一个操作实体（运维操作人员或应用程序）。通过创建新的RAM用户并授权，RAM用户便可以访问相关资源。\n\n创建步骤：\n\n1. 使用阿里云账号登录 [RAM控制台](https://ram.console.aliyun.com/?spm=5176.8466010.help.3.7a501450kyjqXl)。\n\n2. 在左侧导航栏，选择**身份管理** > **用户**。\n\n3. 在**用户**页面，单击**创建用户**。\n\n4. 在**创建用户**页面的**用户账号信息**区域，输入**登录名称**和**显示名称**。\n\n   **说明** 单击**添加用户**，可一次性创建多个 RAM 用户。\n\n5. 在**访问方式**区域，选择访问方式。\n\n   - 控制台访问：设置控制台登录密码、重置密码策略和多因素认证策略。\n   - **OpenAPI调用访问**：自动为 RAM 用户生成访问密钥（AccessKey），支持通过API或其他开发工具访问阿里云。\n\n6. 单击**确定**。\n\n---\n\n4. 在 Controller 层配置，向 OSS 发出请求或许许可签名：\n\n```java\n/**\n * @author yuyun zhao\n * @date 2021/12/27 20:53\n */\n@RestController\npublic class OssController {\n    @Autowired\n    OSS ossClient;\n\n    @Value(\"${spring.cloud.alicloud.oss.endpoint}\")\n    private String endpoint;\n\n    @Value(\"${spring.cloud.alicloud.oss.bucket}\")\n    private String bucket;\n\n    @Value(\"${spring.cloud.alicloud.access-key}\")\n    private String accessId;\n\n    /**\n    * 签名方法\n    * @return 返回给前端JSON字符串，注意必须封装成R对象，因为和前端的通讯协议里，都是从response.data中获取数据\n    */\n    @RequestMapping(\"/oss/policy\")\n    public R policy() {\n        String host = \"https://\" + bucket + \".\" + endpoint; // host的格式为 bucketname.endpoint\n        // callbackUrl为上传回调服务器的URL，请将下面的IP和Port配置为您自己的真实信息。\n        // String callbackUrl = \"http://88.88.88.88:8888\";\n        String date = new SimpleDateFormat(\"yyyy-MM-dd\").format(new Date());\n        // 用户上传文件时指定的前缀。\n        String dir = date + \"/\"; \n\n        Map<String, String> respMap = null;\n        try {\n            long expireTime = 30;\n            long expireEndTime = System.currentTimeMillis() + expireTime * 1000;\n            Date expiration = new Date(expireEndTime);\n            // PostObject请求最大可支持的文件大小为5GB，即CONTENT_LENGTH_RANGE为5*1024*1024*1024。\n            PolicyConditions policyConds = new PolicyConditions();\n            policyConds.addConditionItem(PolicyConditions.COND_CONTENT_LENGTH_RANGE, 0, 1048576000);\n            policyConds.addConditionItem(MatchMode.StartWith, PolicyConditions.COND_KEY, dir);\n\n            String postPolicy = ossClient.generatePostPolicy(expiration, policyConds);\n            byte[] binaryData = postPolicy.getBytes(\"utf-8\");\n            String encodedPolicy = BinaryUtil.toBase64String(binaryData);\n            String postSignature = ossClient.calculatePostSignature(postPolicy);\n\n            respMap = new LinkedHashMap<String, String>();\n            respMap.put(\"accessid\", accessId);\n            respMap.put(\"policy\", encodedPolicy);\n            respMap.put(\"signature\", postSignature);\n            respMap.put(\"dir\", dir);\n            respMap.put(\"host\", host);\n            respMap.put(\"expire\", String.valueOf(expireEndTime / 1000));\n            // respMap.put(\"expire\", formatISO8601Date(expiration));\n        } catch (Exception e) {\n            // Assert.fail(e.getMessage());\n            System.out.println(e.getMessage());\n        } finally {\n            ossClient.shutdown();\n        }\n        return R.ok().put(\"data\", respMap);\n    }\n}\n```\n\n> 单独使用阿里云 OSS 的配置参考阿里云官方文档：https://help.aliyun.com/document_detail/84781.html\n\n5. 在前端工程中导入封装好的上传组件：\n\n![image-20211227211934007](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227211934007.png)\n\n在其中修改地址为自己的 Bucket 外网访问域名：`action=\"http://yunmall-project.oss-cn-hangzhou.aliyuncs.com\"`。这样前端在收到第三方服务发来的许可签名后，就可以使用该签名里的访问密码信息向配置的 Bucket 中上传图片数据。\n\n\n\n### 跨域问题\n\n在前端项目发出请求试图访问阿里云的 OSS 服务器时，同样会出现跨域问题。\n\n![image-20211227214629342](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227214629342.png)\n\n![image-20211227214728392](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227214728392.png)\n\n![image-20211227215530358](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227215530358.png)\n\n\n\n\n\n![image-20211227220201294](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227220201294.png)\n\n# 商品服务\n\n## 三级分类\n\n商品的三级分类功能将在后台管理系统中以树形结构显示所有商品，最终效果图：\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211227200422237.png\" alt=\"image-20211227200422237\" style=\"zoom:50%;\" />\n\n### 网关路由\n\n三级分类页面打开时，前端 `renren-fast-vue` 项目会发出 GET 请求访问后端的商品模块 `yunmall-product` 以获取商品信息：\n\n``` v\n// 方法集合\nmethods: {\n    // 向后端发送数据，获取三级菜单信息\n    getMenus() {\n        this.$http({\n            url: this.$http.adornUrl(\"/product/category/list/tree\"),\n            method: \"get\",\n        }).then((data) => {\n            console.log(\"成功获取到菜单数据...\", data);\n        });\n    },\n},\n```\n\n但因为默认 `renren-fast-vue` 项目配置的 api 接口请求地址的前缀是：\n\n``` js\n// api接口请求地址\nwindow.SITE_CONFIG['baseUrl'] = 'http://localhost:8080/renren-fast';\n```\n\n此时，我们发送的请求 `/product/category/list/tree` 会拼接上 `http://localhost:8080/renren-fast`，导致无法正确向后端发送请求。\n\n因此，我们需要修改前端项目发送的 api 接口地址前缀为：`'http://localhost:88/api'`。其中，88 端口为 Gateway 网关的端口，我们将请求统一发到网关，然后再根据定义的路由规则转发到对应的服务。`/api` 为我们为前端发出请求锁规定的统一前缀。\n\n同时，我们也需要将 `renren-fast` 后台管理模块也加入到网关中，因为前端项目也会向 `renren-fast` 模块发出请求，例如获取验证码的请求：https://localhost:8080/renrenfast/captcha.jpg?uuid=xxx 。所以我们需要将其也加入到网关中管理，并配置路由规则（注意需要重写路径，将前端发来的 `/api` 转换成 `/renren-fast`，否则无法正确指向验证码的链接）：\n\n```yaml\nserver:\n  port: 88\n\nspring:\n  application:\n    name: yunmall-gateway\n  cloud:\n    nacos:\n      # 注册中心\n      discovery:\n        server-addr: localhost:8848\n    gateway:\n      routes:\n        # 商品服务的路由规则\n        - id: product_route\n          uri: lb://yunmall-product\n          predicates:\n            - Path=/api/product/**\n          filters:\n            - RewritePath=/api/(?<segment>.*), /$\\{segment}\n        # 后台管理系统的路由规则\n        - id: admin_route\n          uri: lb://renren-fast # 负载均衡到 renren-fast\n          predicates:\n            - Path=/api/**   # 前端的请求都带 /api 前缀\n          filters:\n            # 前端发来的请求 /api/... 被重写成 /renren-fast/...\n            - RewritePath=/api/(?<segment>.*), /renren-fast/$\\{segment}\n\n## 前端项目发来的请求都带有 /api 前缀。转发到路由服务后，需要重写路径，将 /api 前缀给去掉\n## 注意，要将精确的路径放在更前面，代表优先级更高\n# http://localhost:88/api/catcha.jpg?uuid=xxxx   ->  http://localhost:8080/renren-fast/catcha.jpg?uuid=xxxx\n# http://localhost:88/api/product/category/list/tree -> http://localhost:10000/product/category/list/tree\n```\n\n### 跨域问题\n\n配置完毕后，访问前端界面时，发现报错：\n\n```\nAccess to XMLHttpRequest at 'http://localhost:88/api/sys/login' from origin 'http://localhost:8001' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n```\n\n这是跨域问题所导致的：\n\n- **跨域**：指的是浏览器不能执行其他网站的脚本。它是由浏览器的同源策略造成的，**是浏览器对 javascript 施加的安全限制，不让 js 获取远程网站的数据**。js 要向获取数据，需要使用 `XMLHttpRequest` 对象发出 ajax 请求，该对象要想从本网站向远程的其他 URL 发送请求，默认是不允许的。这是因为同源策略所限制的。\n- **同源策略**：是指协议，域名，端口都要相同，其中有一个不同都会产生跨域\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211224223851621.png\" alt=\"image-20211224223851621\" style=\"zoom:50%;\" />\n\n跨域示例：\n\n![image-20201017090210286](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20201017090210286-1640355845932.png)\n\n我们的报错原因：浏览器在 http://localhost:8001/#/login 地址（`renren-fast-vue` 的登录页地址）发出了一个 http://localhost:88/api/sys/login 请求（试图发给网关），造成了跨域。\n\n这个跨域请求的实现是通过**预检请求**实现的，先发送一个 **OPSTIONS** 探路，收到允许跨域的响应后再发送真实请求：\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211224222914166.png\" alt=\"image-20211224222914166\" style=\"zoom: 67%;\" />\n\n跨域流程：\n\n![image-20201017090318165](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20201017090318165-1640356020890.png)\n\n此时，我们的服务器是不允许跨域的，因此真实的请求并没有发送过去。\n\n> 相关资料参考：https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Access_control_CORS\n\n#### 解决方案一：Nginx\n\n可以将服务都交给 Nginx 代理，实现动静分离，静态请求路由到 vue-admin，动态请求路由到网关：\n\n![image-20201017090434369](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20201017090434369.png)\n\n该方法在最终上线项目时再采用，开发时选用方案二。\n\n#### 解决方案二：配置当次请求允许跨域\n\n在开发阶段，可以暂时不考虑安全问题，将所有请求都放行，具体做法是：创建配置类，向 Spring 容器中注入一个 `CorsWebFilter` 对象，在其内配置放行所有请求：\n\n<img src=\"/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211225115344361.png\" alt=\"image-20211225115344361\" style=\"zoom: 67%;\" />\n\n```java\n@Configuration\npublic class MallCorsConfiguration {\n    @Bean\n    public CorsWebFilter corsWebFilter() {\n        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();\n        CorsConfiguration corsConfiguration = new CorsConfiguration();\n        \n        // 配置跨越\n        corsConfiguration.addAllowedHeader(\"*\"); // 允许那些头\n        corsConfiguration.addAllowedMethod(\"*\"); // 允许那些请求方式\n        corsConfiguration.addAllowedOrigin(\"*\"); //  允许请求来源\n        corsConfiguration.setAllowCredentials(true); // 是否允许携带cookie跨越\n        // 注册跨越配置\n        source.registerCorsConfiguration(\"/**\",corsConfiguration);\n\n        return new CorsWebFilter(source);\n    }\n}\n```\n\n响应头含义：\n\n- `Access-Control-Allow-Origin`：支持哪些来源的请求跨域\n- `Access-Control-Allow-Methods`：支持哪些方法跨域\n- `Access-Control-Allow-Credentials`：跨域请求默认不包含cookie，设置为true可以包含cookie\n- `Access-Control-Expose-Headers`：跨域请求暴露的字段。CORS请求时, XML .HttpRequest对象的 `getResponseHeader()` 方法只能拿到6个基本字段：CacheControl、Content-L anguage、Content Type、Expires、 Last-Modified、 Pragma。 如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。\n- `Access-Control-Max-Age`：表明该响应的有效时间为多少秒。在有效时间内，浏览器无须为同一-请求再次发起预检请求。请注意，浏览器自身维护了一个最大有效时间，如果该首部字段的值超过了最大有效时间，将不会生效。\n\n### 商品三级分类\n\n后端在收到前端发出的 GET 请求后，将去数据库查询所有分类，并进行三级分类：\n\n1. Controller 层：\n\n```java\n@RestController\n@RequestMapping(\"product/category\")\npublic class CategoryController {\n    @Autowired\n    private CategoryService categoryService;\n\n    /**\n     * 查出所有分类以及子分类，以树形结构组装起来\n     */\n    @RequestMapping(\"/list/tree\")\n    public R list(){\n        // 将所有数据以树形结构组织\n        List<CategoryEntity> entities = categoryService.listWithTree();\n\t\t// 将组织好的数据以JSON的形式返回给前端\n        // R 继承自 HashMap，将被转换成 JSON 字符串\n        return R.ok().put(\"data\", entities);\n    }\n}\n```\n\n2. Service 层：\n\n```java\npublic interface CategoryService extends IService<CategoryEntity> {\n    List<CategoryEntity> listWithTree();\n}\n```\n\n```java\n@Service(\"categoryService\")\npublic class CategoryServiceImpl extends ServiceImpl<CategoryDao, CategoryEntity> implements CategoryService {\n\n    @Override\n    public List<CategoryEntity> listWithTree() {\n        // 1. 查出所有商品分类\n        List<CategoryEntity> entities = baseMapper.selectList(null);\n\n        // 2. 组装成父子的树形结构\n        // 2.1 找到所有的一级分类商品（根据parentCid字段父种类id为0的筛选出来）\n        // 2.2 递归地设置每种商品的子商品\n        // 2.3 按照每种商品的sort字段进行排序\n        List<CategoryEntity> menusLevel1 = entities.stream()\n                .filter(categoryEntity -> categoryEntity.getParentCid() == 0)\n                .map((menu) -> {\n                    // 当前管道输入的menu是已经经过过滤的一级商品，设置其孩子为parentCid等于自己的商品\n                    // 同时该方法内也将递归地设置其孩子商品的孩子商品，从而完成所有商品的分类\n                    menu.setChildren(getChildren(menu, entities));\n                    // 当前的menu是父菜单\n                    return menu;\n                })\n                .sorted((m1, m2) -> (m1.getSort() == null ? 0 : m1.getSort()) - (m2.getSort() == null ? 0 : m2.getSort()))\n                .collect(Collectors.toList());\n\n        return menusLevel1;\n    }\n\n    @Override\n    public void removeMenusByIds(List<Long> idList) {\n        // TODO：1. 检查当前要删除的菜单是否被其他菜单所引用\n        // 不使用物理删除，而是使用逻辑删除\n        baseMapper.deleteBatchIds(idList);\n    }\n\n    /**\n     * 递归设置所有菜单的子菜单\n     * @param root：当前商品\n     * @param all：所有商品\n     * @return：当前商品的直接孩子商品\n     */\n    public List<CategoryEntity> getChildren(CategoryEntity root, List<CategoryEntity> all) {\n        // 获取当前商品类型root的子类型children，并且在其内递归的设置children的子类型\n        List<CategoryEntity> children = all.stream()\n                .filter(entity -> entity.getParentCid().equals(root.getCatId()))\n                .map(menu -> {\n                    // 为当前的商品类型递归地设置其子类型\n                    menu.setChildren(getChildren(menu, all));\n                    return menu;\n                }).sorted((m1, m2) -> (m1.getSort() == null ? 0 : m1.getSort()) - (m2.getSort() == null ? 0 : m2.getSort()))\n                .collect(Collectors.toList());\n        return children;\n    }\n}\n```\n\n### 逻辑删除\n\n我们不直接在数据库中删除数据，而是采用**逻辑删除**的方式，将某个字段设置为 1 代表逻辑已删除，设置为 0 代表逻辑未删除。该字段可选择表中的 `show_status`。\n\n1、配置 MyBatis-Plus 的逻辑删除功能：\n\n```yaml\nmybatis-plus:\n  global-config:\n    db-config:\n      # 设置逻辑删除\n      logic-delete-value: 1     # 逻辑已删除值(默认为 1)\n      logic-not-delete-value: 0 # 逻辑未删除值(默认为 0)\n```\n\n2、给实体类的指定字段上加上`@TableLogic`注解，该字段就将被视为逻辑删除标志字段：\n\n``` java\n/**\n* 数据库中：是否显示[0-不显示，1显示]\n* 因为我们数据库中的字段为1代表显示，为0代表不显示。与MyBatis-Plus默认规则相反\n* 所以需要特殊指定删除规则\n*/\n@TableLogic(value = \"1\", delval = \"0\")\nprivate Integer showStatus;\n```\n\n这样再执行 MyBatis-Plus 的 `baseMapper.deleteBatchIds(idList)` 方法时，就不再将数据从表中删除，而是只修改其标志位。 \n\n3、测试：开启日志功能，查看实际向数据库发出的 SQL 语句：\n\n``` \n2021-12-25 13:37:45.585 DEBUG 12700 --- [io-10000-exec-1] c.z.y.p.dao.CategoryDao.deleteBatchIds   : ==>  Preparing: UPDATE pms_category SET show_status=0 WHERE cat_id IN ( ? , ? ) AND show_status=1 \n2021-12-25 13:37:45.606 DEBUG 12700 --- [io-10000-exec-1] c.z.y.p.dao.CategoryDao.deleteBatchIds   : ==> Parameters: 1431(Long), 54126(Long)\n2021-12-25 13:37:45.631 DEBUG 12700 --- [io-10000-exec-1] c.z.y.p.dao.CategoryDao.deleteBatchIds   : <==    Updates: 2\n```\n\n可以看到只是更新了 `show_status` 字段而已，从而实现了逻辑删除的功能。\n\n### 分类拖拽功能\n\n为三级分类添加拖拽功能，具体做法：为每个分类菜单添加拖拽的响应事件：\n\n- 一个用于响应拖拽时的 UI 变化\n- 一个用于响应拖拽后更新所有层级信息，并同步到数据库中\n\n其中，在完成拖拽后可以得知源菜单 source 相对拖拽的目标位置 target 的位置是 inner 还是 before/after：\n\n- 如果是 inner，则源菜单将成为 target 菜单的子菜单。此时源菜单的新层级就等于 target 的层级 + 1（前提是不超过 3，否则就不允许拖拽），新的父节点就是 target\n- 如果是 before/after，则源菜单将成为 target 菜单的兄弟菜单（同一级）。此时源菜单的新层级就等于 target 的层级，新的父节点就是 target 的父节点\n\n同时拖拽完毕后，要：\n\n- 对变化后的层内的节点重新排序（按照字母等策略）\n- 递归地对源节点的所有子节点都更新其新的层级\n\n\n\n## 品牌管理\n\n品牌管理服务需要上传品牌的图片，本项目选用阿里云的 OSS 存储图片。\n\n\n\n\n\n品牌新增\n\n### 前端表单校验\n\n首先在前端表单里添加校验规则，对不合规的输入进行限制，效果：\n\n![image-20201019204335899](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20201019204335899.png)\n\nel-form 组件提供了表单验证的功能，只需要通过 `rules` 属性传入约定的验证规则，并将 Form-Item 的 `prop` 属性设置为需校验的字段名即可。\n\n``` javascript\n<el-form\n      :model=\"dataForm\"\n      :rules=\"dataRule\"\n      ref=\"dataForm\"\n      @keyup.enter.native=\"dataFormSubmit()\"\n      label-width=\"140px\"\n    >\n</el-form>\n```\n\n 自定义规则，对用户输入的数据进行校验：\n\n```javascript\ndataRule: {\n    name: [{ required: true, message: \"品牌名不能为空\", trigger: \"blur\" }],\n        // 对首字母字段添加自定义的规则  \n        firstLetter: [\n            { validator: (rule, value, callback) => {\n                if(value == '') {\n                    callback(new Error(\"首字母必须填写\"))\n                } else if(! /^[a-zA-Z]$/.test(value)) {\n                    callback(new Error(\"首字母必须a-z或者A-Z之间\"))\n                } else {\n                    callback()\n                }\n            },trigger:'blur'}\n        ],\n            // 对排序字段添加自定义的规则  \n            sort: [{ validator: (rule, value, callback) => {\n                if(value == '') {\n                    callback(new Error(\"排序字段必须填写\"));\n                } else if(!Number.isInteger(value) || value < 0) {\n                    callback(new Error(\"排序必须是一个大于等于0的整数\"));\n                } else {\n                    callback();\n                }\n            }, trigger: \"blur\" }]\n}\n```\n\n这样前端就可以对一些非法数据进行拦截，但仍然可能有人绕过前端发送非法数据请求，因此还需要进行后端校验。\n\n### JSR 303 后端数据校验 \n\n> https://www.jianshu.com/p/48725b7328c9\n\nJSR 是 Java Specification Requests 的缩写，即 Java 规范提案。简单的理解为 JSR 是一种 Java 标准，存在各种各样的 JSR，JSR 303 就是数据检验的一个标准。[JSR-303](https://link.jianshu.com/?t=https://jcp.org/en/jsr/detail?id=303) 是 Java EE 6 中的一项子**规范**，叫做 Bean Validation，官方参考**实现**是hibernate Validator。此实现与 Hibernate ORM 没有任何关系。 JSR 303 用于对 Java  Bean 中的字段的值进行验证。 Spring MVC 3.x 之中也大力支持 JSR-303，可以在控制器中对表单提交的数据方便地验证。\n\nSpring Boot 2.2 版本之前的场景启动器依赖中默认内置了该依赖（2.3之后的版本失效），如果需要单独引入依赖，可以使用：\n\n```xml\n<dependency>\n    <groupId>org.hibernate</groupId>\n    <artifactId>hibernate-validator</artifactId>\n    <version>5.4.0.Final</version>\n</dependency>\n<dependency>\n    <groupId>javax.el</groupId>\n    <artifactId>el-api</artifactId>\n    <version>2.2</version>\n</dependency>\n<dependency>\n    <groupId>org.glassfish.web</groupId>\n    <artifactId>javax.el</artifactId>\n    <version>2.2.4</version>\n</dependency>\n```\n\n#### 相关注解\n\nBean Validation 中内置的 constraint：\n\n| Constraint                 |                         详细信息                         |\n| :------------------------- | :------------------------------------------------------: |\n| @Null                      |                 被注释的元素必须为 null                  |\n| @NotNull                   |                被注释的元素必须不为 null                 |\n| @AssertTrue                |                 被注释的元素必须为 true                  |\n| @AssertFalse               |                 被注释的元素必须为 false                 |\n| @Min(value)                | 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 |\n| @Max(value)                | 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 |\n| @DecimalMin(value)         | 被注释的元素必须是一个数字，其值必须大于等于指定的最小值 |\n| @DecimalMax(value)         | 被注释的元素必须是一个数字，其值必须小于等于指定的最大值 |\n| @Size(max, min)            |           被注释的元素的大小必须在指定的范围内           |\n| @Digits(integer, fraction) |   被注释的元素必须是一个数字，其值必须在可接受的范围内   |\n| @Past                      |             被注释的元素必须是一个过去的日期             |\n| @Future                    |             被注释的元素必须是一个将来的日期             |\n| @Pattern(value)            |           被注释的元素必须符合指定的正则表达式           |\n\nHibernate Validator 附加的 constraint：\n\n| Constraint |                详细信息                |\n| :--------- | :------------------------------------: |\n| @Email     |     被注释的元素必须是电子邮箱地址     |\n| @Length    | 被注释的字符串的大小必须在指定的范围内 |\n| @NotEmpty  |        被注释的字符串的必须非空        |\n| @Range     |     被注释的元素必须在合适的范围内     |\n\n#### 使用示例\n\n1. 首先在实体类的相关属性上添加相应注解：\n\n```java\n/**\n * 品牌\n * \n * @author yuyun.zhao\n * @email im.yuyunzhao@gmail.com\n * @date 2021-12-21 16:22:28\n */\n@Data\n@TableName(\"pms_brand\")\npublic class BrandEntity implements Serializable {\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * 品牌id\n     */\n    @TableId\n    private Long brandId;\n    /**\n     * 品牌名，校验：至少得是一个非空格字符\n     */\n    @NotBlank(message = \"品牌名必须提交\")\n    private String name;\n    /**\n     * 品牌logo地址\n     */\n    @NotEmpty\n    @URL(message = \"log必须是一个合法的url地址\")\n    private String logo;\n    /**\n     * 介绍\n     */\n    private String descript;\n    /**\n     * 显示状态[0-不显示；1-显示]\n     */\n    private Integer showStatus;\n    /**\n     * 检索首字母\n     */\n    @NotEmpty\n    @Pattern(regexp = \"^[a-zA-Z]$\", message = \"检索首字母必须是一个字母\")\n    private String firstLetter;\n    /**\n     * 排序\n     */\n    @NotNull\n    @Min(value = 0, message = \"排序必须大于等于0\")\n    private Integer sort;\n\n}\n```\n\n2. 在 Controller 层相应实体类参数上开启校验 `@Valid`：\n\n```java\n/**\n * 保存，开启校验注解，校验前端发来的数据是否合规，bindingResultL获取到校验结果\n */\n@RequestMapping(\"/save\")\npublic R save(@Valid @RequestBody BrandEntity brand, BindingResult result){\n    if (result.hasErrors()) {\n        Map<String, String> map = new HashMap<>();\n        result.getFieldErrors().forEach(item -> map.put(item.getField(), item.getDefaultMessage()));\n        return R.error(400, \"提交的数据不合法\").put(\"data\", map);\n    }\n    // 如果合法再向服务器保存\n    brandService.save(brand);\n    return R.ok();\n}\n```\n\n参数中的 `BindingResult` 用于绑定校验异常的信息。一旦解析时发现某个参数不合法，就会将相应信息（字段名、注解中配置的 `message` 等）包装到该对象中，通过调用该对象的相关方法即可得到字段与信息。\n\n如果没有在参数列表中写 `BindingResult`，则异常就会向外抛出，不会进入到业务方法内。此时就可以写一个**异常处理的切面类**，统一处理这些抛出的校验异常。\n\n### 统一异常处理\n\n创建统一处理异常的切面类 `MallExceptionControllerAdvice`，使用 Spring MVC 提供的 `@ControllerAdvice` 注解并指定要扫描的包，这样这些 Controller 在抛出异常时就会被该切面类拦截到，并做相应处理，从而实现业务和异常处理的解耦。\n\n```java\n/**\n * 集中处理所有异常，AOP的思想，拦截Controller层抛出的所有异常，无侵入的实现统一异常处理\n * @author yuyun zhao\n * @date 2021/12/28 10:47\n */\n@Slf4j\n@RestControllerAdvice(basePackages = \"com.zhao.yunmall.product.controller\")\n// 效果等同于 @ResponseBody + @ControllerAdvice\npublic class MallExceptionControllerAdvice {\n\n    /**\n     * 统一处理异常\n     * @param e：Controller层抛出的MethodArgumentNotValidException异常会被当前方法捕获，处理完毕后发送回前端\n     * @return R.error()\n     */\n    @ExceptionHandler(value = MethodArgumentNotValidException.class)\n    public R handleValidException(MethodArgumentNotValidException e) {\n        log.error(\"数据校验出现问题{}，异常类型{}\", e.getMessage(), e.getClass());\n        // 从异常类对象中获取到异常的字段和信息\n        BindingResult bindingResult = e.getBindingResult();\n        // 将异常的字段以及其默认展示的信息封装到map中\n        Map<String, String> map = new HashMap<>();\n        bindingResult.getFieldErrors().forEach(item -> map.put(item.getField(), item.getDefaultMessage()));\n        // 以JSON形式返回\n        return R.error(BizCodeEnum.VALID_EXCEPTION.getCode(), BizCodeEnum.VALID_EXCEPTION.getMsg()).put(\"data\", map);\n    }\n\n    /**\n    * 拦截Controller层抛出的其他异常（优先级最低，用于兜底拦截）\n    * @param throwable：拦截的异常\n    * @return R.error()\n    */\n    @ExceptionHandler(value = Throwable.class)\n    public R handlException(Throwable throwable) {\n        return R.error(BizCodeEnum.UNKNOWN_EXCEPTION.getCode(), BizCodeEnum.UNKNOWN_EXCEPTION.getMsg());\n    }\n}\n```\n\n这样 Controller 层的业务就不需要修改，实现了无侵入的异常处理：\n\n```java\n/**\n * 保存。开启校验注解，校验前端发来的数据是否合法，如果发生异常（不合法），\n * 将直接被MallExceptionControllerAdvice拦截，其处理完后直接返回给前端\n */\n@RequestMapping(\"/save\")\npublic R save(@Valid @RequestBody BrandEntity brand){\n    // 如果合法再向服务器保存。不合法时抛出的异常直接被MallExceptionControllerAdvice拦截，不会进入到该方法内\n    brandService.save(brand);\n    return R.ok();\n}\n```\n\n---\n\n其中，错误码和错误信息定义类用于同一规定错误码信息，在 `mall-common` 包下：\n\n```java\npackage com.zhao.common.exception;\n\n/**\n * 错误码和错误信息定义类\n * 1. 错误码定义规则为5为数字\n * 2. 前两位表示业务场景，最后三位表示错误码。例如：100001。10:通用 001:系统未知异常\n * 3. 维护错误码后需要维护错误描述，将他们定义为枚举形式\n * 错误码列表：\n *  10: 通用\n *      001：参数格式校验\n *  11: 商品\n *  12: 订单\n *  13: 购物车\n *  14: 物流\n * @author yuyun zhao\n * @date 2021/12/28 11:09\n */\npublic enum BizCodeEnum {\n\n    UNKNOWN_EXCEPTION(10000,\"系统未知异常\"),\n    VALID_EXCEPTION(10001,\"参数格式校验失败\");\n\n    private final int code;\n    private final String msg;\n\n    BizCodeEnum(int code,String msg){\n        this.code = code;\n        this.msg = msg;\n    }\n\n    public int getCode() {\n        return code;\n    }\n\n    public String getMsg() {\n        return msg;\n    }\n}\n```\n\n---\n\n### JSR 303 分组校验\n\n当需要多场景复杂校验时（例如新增时 `id` 字段必须为空，修改时不能为空），就要给校验注解标注什么情况需要进行校验，也就是分组校验。\n\n1. 添加分组后的实体类注解：\n\n```java\npackage com.zhao.yunmall.product.entity;\n\nimport com.zhao.common.valid.AddGroup;\nimport com.zhao.common.valid.UpdateGroup;\nimport com.zhao.common.valid.UpdateStatusGroup;\n\n// import ...\n\n/**\n * 品牌\n * \n * @author yuyun.zhao\n * @email im.yuyunzhao@gmail.com\n * @date 2021-12-21 16:22:28\n */\n@Data\n@TableName(\"pms_brand\")\npublic class BrandEntity implements Serializable {\n    private static final long serialVersionUID = 1L;\n\n    /**\n     * 品牌。使用分组校验，分情况决定是否为null。新增时必须为空；修改时不能为空\n     */\n    @TableId\n    @NotNull(message = \"修改时必须指定品牌id\", groups = {UpdateGroup.class})\n    @Null(message = \"新增时不能指定品牌id\", groups = {AddGroup.class})\n    private Long brandId;\n    /**\n     * 品牌名。任何情况都要校验：至少得是一个非空格字符\n     */\n    @NotBlank(message = \"品牌名必须提交\", groups = {AddGroup.class, UpdateGroup.class})\n    private String name;\n    /**\n     * 品牌logo地址。新增时需要校验：不能为空且必须是合法URL；修改时可以为空，如果不为空时要得是合法URL\n     */\n    @NotEmpty(groups = {AddGroup.class})\n    @URL(message = \"log必须是一个合法的url地址\", groups = {AddGroup.class,UpdateGroup.class})\n    private String logo;\n    /**\n     * 介绍\n     */\n    private String descript;\n    /**\n     * 显示状态[0-不显示；1-显示]\n     * 新增时不能为空，修改状态时不能为空。普通修改可以为空\n     */\n    @NotNull(groups = {AddGroup.class, UpdateStatusGroup.class})\n    private Integer showStatus;\n    /**\n     * 检索首字母。新增时不能为空，修改时可以为空；如果不为空时必须得符合正则\n     */\n    @NotEmpty(groups = {AddGroup.class})\n    @Pattern(regexp = \"^[a-zA-Z]$\", message = \"检索首字母必须是一个字母\", groups = {AddGroup.class,UpdateGroup.class})\n    private String firstLetter;\n    /**\n     * 排序。新增时不能为空，修改时可以为空；如果不为空则必须要满足大于0\n     */\n    @NotNull(groups = {AddGroup.class})\n    @Min(value = 0, message = \"排序必须大于等于0\", groups = {AddGroup.class,UpdateGroup.class})\n    private Integer sort;\n\n}\n```\n\n其中，`groups = {AddGroup.class,UpdateGroup.class}` 中的接口在 `mall-common` 模块的 `valid` 包下定义：\n\n![image-20211228135908575](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211228135908575.png)\n\n2. 在 Controller 上添加 `@Validated({AddGroup.class})` 注解（该注解由 Spring 提供，非 Java 标准 JSR），并在其中指定当前请求的分组：\n\n```java\n/**\n * 保存。开启校验注解，校验前端发来的数据是否合法，如果发生异常（不合法），\n * 将直接被MallExceptionControllerAdvice拦截，其处理完后直接返回给前端\n * 所属分组：{AddGroup.class}\n */\n@RequestMapping(\"/save\")\npublic R save(@Validated({AddGroup.class}) @RequestBody BrandEntity brand){\n    // 如果合法再向服务器保存\n    brandService.save(brand);\n    return R.ok();\n}\n\n/**\n * 修改状态信息。\n * 所属分组：{UpdateStatusGroup.class}\n */\n@RequestMapping(\"/update/status\")\npublic R updateStatus(@Validated({UpdateStatusGroup.class}) @RequestBody BrandEntity brand){\n    brandService.updateById(brand);\n    return R.ok();\n}\n\n/**\n * 修改信息\n * 所属分组：{UpdateGroup.class}\n */\n@RequestMapping(\"/update\")\npublic R update(@Validated({UpdateGroup.class}) @RequestBody BrandEntity brand){\n    brandService.updateById(brand);\n    return R.ok();\n}\n```\n\n**注意**：如果一些字段的注解没有指定分组，则在分组校验情况下其校验逻辑不生效。这些字段只会在 `@Validated()` 内容为空时生效，一旦 `@Validated()`  中带了分组信息，那些没有指定分组的字段就会失效。\n\n3. 测试，发送不合法的请求，返回错误信息：\n\n``` json\n{\n    \"msg\": \"参数格式校验失败\",\n    \"code\": 10001,\n    \"data\": {\n        \"brandId\": \"新增时不能指定品牌id\",\n        \"showStatus\": \"必须提交指定的值\",\n        \"sort\": \"排序必须大于等于0\",\n        \"firstLetter\": \"检索首字母必须是一个字母\"\n    }\n}\n```\n\n\n\n### 自定义校验\n\n1. 编写一个自定义的**校验器**\n\n```java\npublic class ListValueConstraintValidator implements ConstraintValidator<ListValue, Integer> {\n    // 存储合法的值\n    private Set<Integer> set = new HashSet<>();\n\n    /**\n     * 初始化方法。初始化时，将注解中标注的值加入到 set 中，后续就可以从该 set 中判断前端传来的数据是否在该范围内\n     */\n    @Override\n    public void initialize(ListValue constraintAnnotation) {\n        int[] vals = constraintAnnotation.vals();\n        for(int val : vals) {\n            // 将结果添加到set集合\n            set.add(val);\n        }\n    }\n\n    /**\n     * 判断效验是否成功\n     * @param value 需要效验的值\n     * @param context 上下文环境\n     * @return 返回是否包含当前值\n     */\n    @Override\n    public boolean isValid(Integer value, ConstraintValidatorContext context) {\n        // 判断是包含该值\n        return set.contains(value);\n    }\n}\n```\n\n2. 编写一个自定义的**校验注解**并**绑定**校验注解和其对应的校验类 `@Constraint(validatedBy = {ListValueConstraintValidator.class}) `。一个校验注解**可以绑定多个**校验类，其将根据该注解标注的字段的实际类型决定使用哪个校验类：\n\n```java\n@Documented\n// 绑定注解和对应类：可以指定多个不同的校验器，适配不同类型的校验\n@Constraint(validatedBy = {ListValueConstraintValidator.class, xxx.class, xxx.class}) \n@Target({ElementType.METHOD, ElementType.FIELD, ElementType.ANNOTATION_TYPE, ElementType.CONSTRUCTOR, ElementType.PARAMETER, ElementType.TYPE_USE})\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface ListValue {\n    // 三要素不能丢\n    // 回显的异常信息，默认绑定了 com.zhao.common.valid.ListValue.message 属性，需要在该位置创建配置文件写上message属性\n    String message() default \"{com.zhao.common.valid.ListValue.message}\";\n    Class<?>[] groups() default { };\n    Class<? extends Payload>[] payload() default { };\n\n    // 自定义的属性\n    int[] vals() default { };\n}\n```\n\n3. 按照 JSR 规范，在 `mall-common` 模块添加配置文件：`ValidationMessages.properties`，在其内填写自定义的异常回显信息：\n\n```properties\ncom.zhao.common.valid.ListValue.message=必须提交指定的值\n```\n\n4. 在字段上添加自定义校验注解：\n\n``` java\n/**\n * 显示状态[0-不显示；1-显示]\n * 只有取值0或1才合法，否则都不合法\n */\n@ListValue(vals = {0, 1})\nprivate Integer showStatus;\n```\n\n这样如果前端发来的数据中的 `showStatus `字段的范围不在 0,1 之内，则会返回：\n\n``` json\n{\n    \"msg\": \"参数格式校验失败\",\n    \"code\": 10001,\n    \"data\": {\n        \"showStatus\": \"必须提交指定的值\"\n    }\n}\n```\n\n## 属性分组\n\n\n\n总结增删改查的哥哥套路\n\n\n\nfeign的配置\n\n\n\n配置文件\n\n\n\nmybatis的各种操作\n\n\n\n\n\nfeign 记得加@EnableFeignClients(basePackages = \"com.zhao.yunmall.ware.feign\")\n\n\n\n\n\nmybatis的分页插件的configuration配置\n\n\n\n配置日期\n\n```\njackson:\n  date-format: yyyy-MM-dd HH:mm:ss\n  time-zone: GMT+8\n```\n\n\n\n```\n/**\n * \n */\n@TableField(fill = FieldFill.INSERT) //创建时自动填充\nprivate Date createTime;\n/**\n * \n */\n@TableField(fill = FieldFill.INSERT_UPDATE) //创建与修改时自动填充\nprivate Date updateTime;\n```\n\n\n\n\n\n很常用的这个分页查询到底怎么原理\n\n\n\n```\nIPage<PurchaseEntity> page = this.page(\n        new Query<PurchaseEntity>().getPage(params),\n        new QueryWrapper<PurchaseEntity>()\n);\n```\n\n\n\n![image-20211231144216460](/images/%E3%80%90Project%E3%80%91%E4%BA%91%E5%95%86%E5%9F%8E/image-20211231144216460.png)\n\n整理各个服务的代码\n\nController层只干三件事：\n\n```\n*  1、Controller：处理请求，接受和校验数据\n*  2、Service接受controller传来的数据，进行业务处理\n*  3、Controller接受Service处理完的数据，封装页面指定的vo\n```\n\n\n\n再看一下什么是三范式\n\n违反**三范式**，以冗余空间换时间效率\n\n\n\n```java\n/**\n * 当前商品的子类型\n * @JsonInclude(JsonInclude.Include.NON_EMPTY) 当该字段不为空时才添加到JSON中返回给前端，如果为空直接不添加到JSO那种\n * @TableField(exist = false) 该字段在表中不存在，所以需要额外声明，查询数据库时不要带上该字段\n */\n@JsonInclude(JsonInclude.Include.NON_EMPTY)\n@TableField(exist = false)\nprivate List<CategoryEntity> children;\n```\n\n\n\n\n\nVO：\n\n\n\n\n\n```\n// 5.1 保存sku的基本信息到pms_sku_info表\n// 当前sku对象被插入到数据库后MyBatis-Plus会为其自动回显自增主键id值\nskuInfoService.saveSkuInfo(skuInfoEntity);\n// 插入到数据库后，就可以获取其回显的主键了\nLong skuId = skuInfoEntity.getSkuId();\n```\n\n\n\n\n\n\n\n```\n* 远程调用原理：\n* 1、CouponFeignService.saveSpuBounds(spuBoundTo);\n* 1）、@RequestBody将这个对象转为json。\n* 2）、找到gulimall-coupon服务，给/coupon/spubounds/save发送请求。\n* 将上一步转的json放在请求体位置，发送请求；\n* 3）、对方服务收到请求。请求体里有json数据。\n* (@RequestBody SpuBoundsEntity spuBounds)；将请求体的json转为SpuBoundsEntity；\n* 只要json数据模型是兼容的。双方服务无需使用同一个to\n```\n\n\n\n设置当前会话的隔离级别为**读未提交**，以方便 DEBUG：\n\n``` sql\nset session transaction isolation level read uncommitted;\n\n-- 然后在当前会话框内查询\nselect * from `table_name`;\n```\n\n\n\n开启debug观察sql语句的细节\n\n```\nlogging:\n  level:\n    com.zhao.yunmall: debug\n```\n\n```\nString key = (String) params.get(\"key\");\nif (!StringUtils.isEmpty(key)) {\n   // .and() 的作用是，把 (id = key or spu_name like key) 给括起来，作为一个整体，\n   // 否则 or 很可能影响后面跟着的其他 and 条件\n   queryWrapper.and((w) -> {\n      w.eq(\"id\", key).or().like(\"spu_name\", key);\n   });\n}\n// status=1 and (id=1 or spu_name like xxx)\nString status = (String) params.get(\"status\");\nif (!StringUtils.isEmpty(status)) {\n   queryWrapper.eq(\"publish_status\", status);\n}\n\nString brandId = (String) params.get(\"brandId\");\nif (!StringUtils.isEmpty(brandId) && !\"0\".equalsIgnoreCase(brandId)) {\n   queryWrapper.eq(\"brand_id\", brandId);\n}\n\nString catelogId = (String) params.get(\"catelogId\");\nif (!StringUtils.isEmpty(catelogId) && !\"0\".equalsIgnoreCase(catelogId)) {\n   queryWrapper.eq(\"catalog_id\", catelogId);\n}\n\n\nIPage<SpuInfoEntity> page = this.page(\n      new Query<SpuInfoEntity>().getPage(params),\n      queryWrapper\n);\n\nreturn new PageUtils(page);\n```\n\n\n\n商品服务里的：全局时间格式化\n\n```yaml\nspring\n  jackson:\n    date-format: yyyy-MM-dd HH:mm:ss\n```\n\n\n\n# 检索服务\n\nSKU 标题\n\n价格区间\n\n销量\n\n所属于那个品牌，分类\n\n商品规格\n\n\n\nmac保存的截图，两者保存到ES里的方式\n\n\n\n动态计算\n\n\n\n第二种方法，节省了空间，但是每次先查到spu后，还要再去查对应spu的规格属性，就会浪费很多时间，高并发下，严重阻塞，所以选择第一种方式存储检索，虽然浪费了空间，但是节省了时间\n\n\n\n\n\n相当于加了一个nginx，其负责接收总的请求，只要是80的都被nginx接收，然后nginx转发给网关，后续就和网关一模一样了。只是多了静态页面渲染而已\n\n注意要带上 header\n\n\n\n\n\n# 遇到的问题\n\n### MySQL 无法连接\n\nmysql 启动后，可以使用 telnet 命令测试 mysql 能否被顺利连接：\n\n``` bash\ntelnet 47.98.120.35 3306\n```\n\n> https://www.jianshu.com/p/b0abc38aa601\n\n如果不能连通，可能的原因：\n\n- 防火墙没有开启 3306 端口\n- 云服务器的安全组没有开通 3306 端口\n- docker 内的 mysql 只允许其所在的服务器连接，不能被其他主机访问。此时需要在 mysql 服务器上设置一下允许的 ip 权限：\n\n``` bash\n# root表示mysql的一个用户名  '%'表示所有远程ip  '123456'是密码\n# 该命令的意思是任何公网IP的都可以通过用户名为root 密码为123456 访问改数据库\ngrant all privileges on *.* to root@'%' identified by 'zhaoyuyun' with grant option;\n\n# 使其立即生效\nflush privileges;\n```\n\n### 登录 MySQL 时：ERROR 1045 (28000): Access denied for user\n\n进入 docker 内 mysql 时报错:：045 (28000)错误：\n\n> ”Access denied for user ‘root’@’localhost’ (using password: YES)”\n\n解决方案：https://www.jianshu.com/p/a49389497a0c\n\n\n\n### Spring Boot 和 Spring Cloud 版本冲突\n\n当二者版本不对应时，无法启动 Spring Boot 项目，会报错：\n\n``` \nError starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.\n2021-12-21 17:18:03.123 ERROR 17424 --- [           main] o.s.boot.SpringApplication               : Application run failed\n\norg.springframework.context.ApplicationContextException: Unable to start web server; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/boot/context/properties/ConfigurationPropertiesBean\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:156) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:543) ~[spring-context-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:141) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.SpringApplication.refresh(SpringApplication.java:744) [spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:391) [spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:312) [spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1215) [spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1204) [spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat com.zhao.yunmall.coupon.MallCouponApplication.main(MallCouponApplication.java:11) [classes/:na]\nCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.boot.autoconfigure.web.servlet.ServletWebServerFactoryConfiguration$EmbeddedTomcat': Initialization of bean failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/boot/context/properties/ConfigurationPropertiesBean\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:601) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:199) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:392) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1321) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1160) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:555) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:515) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:320) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:222) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:318) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:204) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.getWebServerFactory(ServletWebServerApplicationContext.java:210) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.createWebServer(ServletWebServerApplicationContext.java:179) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.onRefresh(ServletWebServerApplicationContext.java:153) ~[spring-boot-2.1.8.RELEASE.jar:2.1.8.RELEASE]\n\t... 8 common frames omitted\nCaused by: java.lang.NoClassDefFoundError: org/springframework/boot/context/properties/ConfigurationPropertiesBean\n\tat org.springframework.cloud.context.properties.ConfigurationPropertiesBeans.postProcessBeforeInitialization(ConfigurationPropertiesBeans.java:76) ~[spring-cloud-context-3.0.4.jar:3.0.4]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsBeforeInitialization(AbstractAutowireCapableBeanFactory.java:414) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1770) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:593) ~[spring-beans-5.1.9.RELEASE.jar:5.1.9.RELEASE]\n\t... 25 common frames omitted\nCaused by: java.lang.ClassNotFoundException: org.springframework.boot.context.properties.ConfigurationPropertiesBean\n\tat java.net.URLClassLoader.findClass(URLClassLoader.java:382) ~[na:1.8.0_281]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:418) ~[na:1.8.0_281]\n\tat sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355) ~[na:1.8.0_281]\n\tat java.lang.ClassLoader.loadClass(ClassLoader.java:351) ~[na:1.8.0_281]\n\t... 29 common frames omitted\n\n\nProcess finished with exit code 1\n```\n\n此时需要修改 Spring Boot 和 Spring Cloud 的版本，使其能适配。\n\n### MySQL 重置主键 id\n\nhttps://www.programminghunter.com/article/2768944322/","tags":["Project"],"categories":["Project"]},{"title":"【算法】概率问题","url":"/2021/12/15/【算法】概率问题/","content":"\n## 概率问题常见题目\n\n### 蓄水池抽样算法（Reservoir Sampling）\n\n> https://www.jianshu.com/p/7a9ea6ece2af\n\n给定一个数据流，数据流长度 N 很大，且 N 直到处理完所有数据之前都不可知，请问如何在只遍历一遍数据（O(N)）的情况下，能够随机选取出 m 个不重复的数据。\n\n这个场景强调了3件事：\n\n1. 数据流长度N很大且不可知，所以不能一次性存入内存。\n2. 时间复杂度为 O(N)。\n3. 随机选取 m 个数，每个数被选中的概率为 m/N。\n\n第 1 点限制了不能直接取 N 内的 m 个随机数，然后按索引取出数据。第 2 点限制了不能先遍历一遍，然后分块存储数据，再随机选取。第 3 点是数据选取绝对随机的保证。\n\n算法思路：\n\n1. 如果接收的数据量小于 m，则依次放入蓄水池。\n2. 当接收到第 i 个数据时，i >= m，则**使得其以 m / i 的概率进入蓄水池**，**同时从蓄水池中不放回地随机选出一个元素将其弹出（1 / m 的概率）**。**具体做法**为：在 [0, i] 范围内取随机数 d，若 d 落在 [0, m-1] 范围内，则用接收到的第 i 个数据替换蓄水池中的第 d 个数据。\n3. 重复步骤2。\n\n算法的精妙之处在于：**当处理完所有的数据时，蓄水池中的每个数据都是以 m/N 的概率获得的。**\n\n#### 应用\n\n蓄水池算法的 O(N) 时间复杂度，O(m) 空间复杂度令其适用于对流数据、大数据集的等概率抽样。比如一个大文本数据，随机输出其中的几行；抽奖系统，等概率抽取每个第一次登录的用户。使用该算法可以以很低的空间复杂度处理随机问题。\n\n### 分布式蓄水池抽样（Distributed/Parallel Reservoir Sampling）\n\n一块 CPU 的计算能力再强，也总有内存和磁盘 IO 拖他的后腿。因此为提高数据吞吐量，分布式的硬件搭配软件是现在的主流。\n\n如果遇到超大的数据量，即使是 O(N) 的时间复杂度，蓄水池抽样程序完成抽样任务也将耗时很久。因此分布式的蓄水池抽样算法应运而生。运作原理如下：\n\n1. 假设有 K 台机器，将大数据集分成 K 个数据流，每台机器使用单机版蓄水池抽样处理一个数据流，抽样m个数据，并最后记录处理的数据量为N1, N2, ..., Nk, ..., NK(假设m < Nk)。N1 + N2 + ... + NK = N。\n2. 取 [1, N] 一个随机数 d，若 d < N1，则在第一台机器的蓄水池中等概率不放回地（1 / m）选取一个数据；若 N1 <= d < (N1 + N2)，则在第二台机器的蓄水池中等概率不放回地选取一个数据；一次类推，重复 m 次，则最终从 N 大数据集中选出 m 个数据。\n\nm/N 的概率验证如下：\n\n1. 第 k 台机器中的蓄水池数据被选取的概率为 m / Nk。\n2. 从第 k 台机器的蓄水池中选取一个数据放进最终蓄水池的概率为 Nk / N。\n3. 第 k 台机器蓄水池的一个数据被选中的概率为 1 / m。（不放回选取时等概率的）\n4. 重复 m 次选取，则每个数据被选中的概率为 **m\\*(m/Nk\\*Nk/N\\*1/m)=m/N**。\n\n<!-- More -->\n\n### 随机数生成器\n\n问题：已知有一个随机数生成器，可以等概率生成 1 - 7 范围的整数。如何在不借助系统随机方法的前提下，将该随机数生成器包装成：等概率生成 20 - 30 范围的整数。\n\n思路：**将随机数生成器生成的数字转换成二进制的 0 或 1**：\n\n- 判断随机数生成器生成的数字：\n  - 如果处于 [1, 3] 范围，则转换成 0\n  - 如果处于 [4, 6] 范围，则转换成 1\n  - 如果等于 7，则重新再生成一数直到落在 [0, 6] 范围\n- 将要转换成的数字范围进行标准化：[20, 30] -> [0, 10]，之后只需要做到随即生成 [0, 10] 范围内的数字即可通过 +20 的方式得到目标范围\n- 标准化后要转换成的数字最大为 10，该数字最少可以用 4 位二进制数表示，则进行 4 次上述过程，随机生成四个 0 或 1。将这四个 0 或 1 组成一个数字：\n  - 若该数字不在 [0, 10] 内，则重复该过程，重新生成 4 个 0 或 1\n  - 若该数字在 [0, 10] 内，则该数字 + 20 就是我们自定义的生成器所返回的数字\n\n使用该机制即可将任意范围的整数转换成另外一个范围的整数。\n\n#### 扩展\n\n如果随机生成器只生成 0 或 1，但是二者的概率不同。以 p 的概率生成 0，以 1 - p 的概率生成 1。则如何将该随机生成器包装成能等概率返回 0 和 1。\n\n思路：调用两次该生成器，生成结果有：\n\n- 00：概率为 p*p。舍弃不要，重新调用两次\n- 01：概率为 p*(1-p)。返回 0\n- 10：概率为 (1-p)*p。返回 1\n- 11：概率为 (1-p)*(1-p)。舍弃不要，重新调用两次\n\n只在返回 01 和 10 时生成出 0 和 1，即可做到等概率生成 0 和 1。\n\n代码：\n\n``` java\npublic class Rand5ToRand7 {\n    public static int rand1To5() {\n        // 随机生成 0-4 + 1 = 0-5 的数字\n        return (int)(Math.random() * 5) + 1;\n    }\n\n    // f() 方法用于随机生成0或1\n    public static int f() {\n        int num = 0;\n        do {\n            // 随机生成1-5范围, 如果为3, 重新生成\n            num = rand1To5();\n        } while (num == 3);\n        //\n        return num < 3 ? 0 : 1;\n    }\n\n    public static int rand1To7() {\n        // 先用 f() 随机生成 0-6 范围的数字, 然后加一生成 1-7 范围\n        // 随机生成三次0或1, 拼接起来如果大于6则重新生成三次\n        int res = 0;\n        do {\n            res = (f() << 2) + (f() << 1) + f();\n        } while (res > 6);\n        return res + 1;\n    }\n}\n```\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"【ElasticSearch】ElasticSearch","url":"/2021/12/14/【ElasticSearch】ElasticSearch/","content":"\n<img src=\"/images/%E3%80%90ElasticSearch%E3%80%91ElasticSearch/image-20211214223034124.png\" alt=\"image-20211214223034124\" style=\"zoom: 25%;\" />\n\n## 简介\n\nThe Elastic Stack，包括 Elasticsearch、 Kibana、 Beats 和 Logstash（也称为 ELK Stack）。能够安全可靠地获取任何来源、任何格式的数据，然后实时地对数据进行搜索、分析和可视化。\n\nElaticsearch，简称为 ES， 是一个**开源的高扩展的分布式全文搜索引擎**， 是整个 ElasticStack 技术栈的核心，是一个可以用于**检索**、**存储**和**分析**的引擎。它可以近乎实时的存储、检索数据；本身扩展性很好，可以扩展到上百台服务器，处理 PB 级别的数据。\n\n### 全文搜索引擎\n\nGoogle，百度类的网站搜索，它们都是根据网页中的关键字生成索引，我们在搜索的时候输入关键字，它们会将该关键字即索引匹配到的所有网页返回；还有常见的项目中应用日志的搜索等等。对于这些非结构化的数据文本，关系型数据库搜索不是能很好的支持。\n\n一般传统数据库，全文检索都实现的很鸡肋，因为一般也没人用数据库存文本字段。进行全文检索需要扫描整个表，如果数据量大的话即使对 SQL 的语法优化，也收效甚微。建立了索引，但是维护起来也很麻烦，对于 insert 和 update 操作都会重新构建索引。\n\n基于以上原因可以分析得出，在一些生产环境中，使用常规的搜索方式，性能是非常差的：\n\n- 搜索的数据对象是大量的非结构化的文本数据\n- 文件记录量达到数十万或数百万个甚至更多。\n- 支持大量基于交互式文本的查询\n- 需求非常灵活的全文搜索查询\n- 对高度相关的搜索结果的有特殊需求，但是没有可用的关系数据库可以满足\n- 对不同记录类型、非文本数据操作或安全事务处理的需求相对较少的情况。为了解决结构化数据搜索和非结构化数据搜索性能问题，我们就需要专业，健壮，强大的全文搜索引擎 \n\n这里说到的**全文搜索引擎**指的是目前广泛应用的主流搜索引擎。它的工作原理是计算机索引程序通过扫描文章中的每一个词，对每一个词建立一个索引，指明该词在文章中出现的次数和位置，当用户查询时，检索程序就根据事先建立的索引进行查找，并将查找的结果反馈给用户的检索方式。这个过程类似于通过字典中的检索字表查字的过程（倒排索引）。\n\n### ELK\n\nELK 是 Elasticsearch、Logstash、 Kibana 三大开源框架首字母大写简称。市面上也被称为 Elastic Stack。\n\n- 其中 Elasticsearch 是一个基于 Lucene、分布式、通过 Restful 方式进行交互的**近实时搜索平台框架**。像百度、谷歌这种大数据全文搜索引擎的场景都可以使用 Elasticsearch 作为底层支持框架，可见 Elasticsearch 提供的搜索能力确实强大，市面上很多时候我们简称 Elasticsearch 为ES。\n- Logstash 是 ELK 的**中央数据流引擎**，用于从不同目标（文件/数据存储/MQ）收集的不同格式数据，经过过滤后支持输出到不同目的地（文件/MQ/redis/elasticsearch/kafka等）。\n- Kibana 可以将 ElasticSearch 的数据通过友好的页面展示出来，提供实时分析的功能。\n\n市面上很多开发只要提到 ELK 能够一致说出它是一个日志分析架构技术栈总称，但实际上 ELK 不仅仅适用于日志分析，它还可以支持其它任何数据分析和收集的场景，日志分析和收集只是更具有代表性，并非唯一性。\n\n收集清洗数据（Logstash） ==> 搜索、存储（ElasticSearch） ==> 展示（Kibana）\n\n![img](/images/%E3%80%90ElasticSearch%E3%80%91ElasticSearch/20201124224044.png)\n\n### Elasticsearch 应用案例\n\n- GitHub：2013 年初，抛弃了 Solr，采取 Elasticsearch 来做 PB 级的搜索。 “GitHub 使用Elasticsearch 搜索 20TB 的数据，包括 13 亿文件和 1300 亿行代码”。\n- 维基百科：启动以 Elasticsearch 为基础的核心搜索架构\n- 百度：目前广泛使用 Elasticsearch 作为文本数据分析，采集百度所有服务器上的各类指标数据及用户自定义数据，通过对各种数据进行多维分析展示，辅助定位分析实例异常或业务层面异常。目前覆盖百度内部 20 多个业务线（包括云分析、网盟、预测、文库、直达号、钱包、 风控等），单集群最大 100 台机器， 200 个 ES 节点，每天导入 30TB+数据。\n- 新浪：使用 Elasticsearch 分析处理 32 亿条实时日志。\n- 阿里：使用 Elasticsearch 构建日志采集和分析体系。\n- Stack Overflow：解决 Bug 问题的网站，全英文，编程人员交流的网站。\n\n### Lucene\n\n- 是 **apache软件基金会** 4 jakarta 项目组的一个子项目\n- 是一个开放源代码的**全文检索引擎工具包**\n- **不是一个完整的全文检索引擎，而是一个全文检索引擎的架构**，提供了完整的查询引擎和索引引擎，部分[文本分析](https://baike.baidu.com/item/文本分析/11046544)引擎（英文与德文两种西方语言）\n- 当前以及最近几年最受欢迎的**免费 Java 信息检索程序库**。\n\nLucene 和 ElasticSearch 的关系：**ElasticSearch 基于 Lucene 做了封装和增强**。ES 使用 Java 开发并使用 Lucene 作为其核心来实现所有索引和搜索的功能，但是它的**目的**是通过简单的 **RESTful API** 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。\n\n### Solr 简介\n\n- Solr 是 Apache 下的一个顶级开源项目，采用 Java 开发，它是**基于Lucene的全文搜索服务器**。Solr 提供了比 Lucene 更为**丰富的查询语言**，同时实现了**可配置**、**可扩展**，并**对索引、搜索性能进行了优化**\n- Solr 可以**独立运行**，运行在 letty，Tomcat 等这些 Selrvlet 容器中，Solr 索引的实现方法很简单，用 POST 方法向 Solr 服务器发送一个描述 Field 及其内容的 XML 文档，Solr根据 XML 文档**添加、删除、更新**索引。Solr 搜索只需要发送HTTP GET请求，然后对 Solr 返回 XML、JSON 等格式的查询结果进行解析，组织页面布局\n- Solr 不提供构建 UI 的功能，**Solr提供了一个管理界面，通过管理界面可以查询 Solr 的配置和运行情况**\n- Solr 是基于 Lucene 开发企业级搜索服务器，实际上就是封装了lucene.\n- Solr 是一个独立的企业级搜索应用服务器，它**对外提供类似于 Web-service 的 API 接口**。用户可以通过 HTTP 请求，向搜索引擎服务器提交指定格式的文件，生成索引。也可以通过提出查找请求，并得到返回结果\n\n### ES 和 Solr\n\n> https://www.kuangstudy.com/bbs/1354069127022583809\n\n- ElasticSearch 是一个**实时分布式搜索和分析引擎**，它让你以前所未有的速度处理大数据成为可能。\n- 它用于<mark>**全文搜索、结构化搜索、分析**</mark>以及将这三者混合使用：\n  - 维基百科使用 ElasticSearch 提供**全文搜索**并**高亮关键字**，以及输入**实时搜索**（search-asyou-type）和**搜索纠错**（did-you-mean）等搜索建议功能。\n  - 英国卫报使用 ElasticSearch 结合用户日志和社交网络数据提供给他们的编辑以实时的反馈，以便及时了解公众对新发表的文章的回应。\n  - StackOverflow 结合全文搜索与地理位置查询，以及 more-like-this 功能来找到相关的问题和答案。\n  - Github 使用 ElasticSearch 检索 1300 亿行的代码。\n- ElasticSearch 是一个基于 Apache Lucene 的开源搜索引擎。无论在开源还是专有领域，Lucene可被认为是迄今为止最先进、性能最好的、功能最全的搜索引擎库。但是，**Lucene 只是一个库**。 想要使用它，你必须使用 Java 来作为开发语言并将其直接集成到你的应用中。更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。\n- ElasticSearch 也使用 Java 开发并使用 Lucene 作为其核心来实现所有引和搜索的功能，但是它的**目的**是通过简单的 **RESTful API** 来隐藏 Lucene 的复杂性，从而让全文搜索变得简单。\n\nElasticSearch 与 Solr 比较：\n\n- 当单纯的对已有数据进行搜索时，Solr 更快\n- 当实时建立索引时，Solr 会产生 io 阻塞，查询性能较差，ElasticSearch 具有明显的优势\n- 随着数据量的增加，Solr 的搜索效率会变得更低，而 ElasticSearch 却没有明显的变化\n\n#### 总结\n\n- Solr 利用 Zookeeper 进行分布式管理，而 ElasticSearch 自身带有分布式协调管理功能\n- Solr 支持更多格式的数据,比如JSON/XML/CSV，而 Elasticsearch 仅支持 JSON 文件格式\n- Solr 官方提供的功能更多,而Elasticsearch本身更注重于核心功能，高级功能多有第三方插件提供，例如图形化界面需要 kibana 友好支撑\n- **Solr 查询快，但更新索引时慢（即插入删除慢）** ，用于电商等查询多的应用。**ES 建立索引快（实时性查询快），用于 facebook，新浪等搜索。\n- Solr是传统搜索应用的有力解决方案，但 Elasticsearch 更适用于新兴的实时搜索应用。\n- Solr 比较成熟，有一个更大，更成熟的用户、开发和贡献者社区，而Elasticsearch相对开发维护者较少，更新太快，学习使用成本较高。\n\n<!-- More-->\n\n## 环境搭建\n\n在 Docker 下快速安装 ElasticSearch 7.4.2：\n\n1. 下载镜像文件\n\n``` bash\n$ docker pull elasticsearch:7.4.2\n\n$ docker pull kibana:7.4.2\n```\n\n2. 配置\n\n``` bash\n$ mkdir -p /mydata/elasticsearch/config  # 存放配置文件\n$ mkdir -p /mydata/elasticsearch/data    # 存放数据\n$ mkdir -p /mydata/elasticsearch/plugins # 存放插件\n$ echo \"http.host: 0.0.0.0\" >/mydata/elasticsearch/config/elasticsearch.yml # 允许任何机器访问\n$ chmod -R 777 /mydata/elasticsearch/ ## 设置elasticsearch文件可读写权限，否则将无法启动\n```\n\n3. 启动（9300 端口为 Elasticsearch 集群间组件的通信端口， 9200 端口为浏览器访问的 HTTP 请求端口）\n\n``` bash\n$ docker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\\n-e  \"discovery.type=single-node\" \\\n-e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" \\\n-v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\\n-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \\\n-v  /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\\n-d elasticsearch:7.4.2 \n```\n\n4. 设置开启启动\n\n``` bash\n$ docker update elasticsearch --restart=always\n```\n\n5. 启动 Kibana\n\n``` bash\n$ docker run --name kibana -e ELASTICSEARCH_HOSTS=http://yuyunzhao.cn:9200 -p 5601:5601 -d kibana:7.4.2\n# http://xxx:9200 改成自己 Elasticsearch 的地址\n```\n\n在浏览器访问 5601 端口即可进入到界面\n\n## 核心概念\n\nElasticsearch 是**面向文档型数据库**，一条数据在这里就是一个文档。将 Elasticsearch 里存储文档数据和关系型数据库 MySQL 存储数据的概念进行一个类比：\n\n![image-20220104162038740](/images/%E3%80%90ElasticSearch%E3%80%91ElasticSearch/image-20220104162038740.png)\n\nES 里的 Index 可以看做一个库，而 Types 相当于表， Documents 则相当于表的行。这里 Types 的概念已经被逐渐弱化， Elasticsearch 6.X 中，一个 index 下已经只能包含一个type， Elasticsearch 7.X 的一些版本中，Type 的概念已经被删除了。\n\n### 物理设计\n\nElasticSearch 在后台把**每个索引划分成多个分片**，每分分片可以在集群中的不同服务器间迁移。一个人就是一个集群，即**启动的 ElasticSearch 服务，默认就是一个集群，且默认集群名为ElasticSearch**。\n\n### 逻辑设计\n\n一个索引类型中，包含多个文档，比如说文档1，文档2。当我们索引一篇文档时，可以通过这样的顺序找到它：索引 => 类型 => 文档ID ，通过这个组合我们就能索引到某个具体的文档。 注意：ID不必是整数，实际上它是个字符串。\n\n> 文档（“行”）\n\n之前说 ElasticSearch 是面向文档的，那么就意味着**索引和搜索数据的最小单位是文档**，ElasticSearch中，文档有几个重要属性:\n\n- 自我包含，一篇文档同时包含字段和对应的值，也就是同时包含` key:value`\n- 可以是层次型的，一个文档中包含自文档，复杂的逻辑实体就是这么来的\n- 灵活的结构，文档不依赖预先定义的模式，我们知道关系型数据库中，要提前定义字段才能使用，在 ElasticSearch 中，对于字段是非常灵活的，有时候，我们可以忽略该字段，或者动态的添加一个新的字段。\n\n尽管我们可以随意新增或者忽略某个字段，但是，每个字段的类型非常重要，比如一个年龄字段类型，可以是字符串也可以是整型。因为 ElasticSearch 会保存字段和类型之间的映射及其他的设置。这种映射具体到每个映射的每种类型，这也是为什么在 ElasticSearch 中，类型有时候也称为映射类型。\n\n> 类型（“表”）\n\n类型是文档的逻辑容器，就像关系型数据库一样，表格是行的容器。类型中对于字段的定义称为映射，比如 name 映射为字符串类型。我们说文档是无模式的，它们不需要拥有映射中所定义的所有字段，比如新增一个字段，那么 ElasticSearch 是怎么做的呢？\n\nElasticSearch 会自动将新字段加入映射，但是这个字段的不确定它是什么类型，ElasticSearch 就开始猜，如果这个值是18，那么 EasticSearch 会认为它是整型。但是 ElasticSearch 也可能猜不对，所以最安全的方式就是提前定义好所需要的映射，这点跟关系型数据库殊途同归了，先定义好字段，然后再使用。\n\n> 索引（“库”）\n\n索引是映射类型的容器， ElasticSearch 中的索引是一个非常大的文档集合。 索引存储了映射类型的字段和其他设置。然后它们被存储到了各个分片上了。\n\n### 分片\n\n一个集群至少有一个节点，而一个节点就是一个 ElasticSearch 进程，节点可以有多个索引默认的，如果你创建索引，那么索引将会有个 5 个分片（primary shard，又称主分片）构成的，每一个主分片会有一个副本（replica shard，又称复制分片）\n\n![img](/images/%E3%80%90ElasticSearch%E3%80%91ElasticSearch/20201124234946.png)\n\n上图是一个有3个节点的集群，可以看到主分片和对应的复制分片都不会在同一个节点内，这样有利于某个节点挂掉了，数据也不至于失。实际上，**一个分片是一个Lucene索引（<mark>一个ElasticSearch索引包含多个Lucene索引</mark>）** ，**一个包含倒排索引的文件目录，倒排索引的结构使得elasticsearch在不扫描全部文档的情况下，就能告诉你哪些文档包含特定的关键字**。不过，等等，倒排索引是什么鬼?\n\n### 倒排索引\n\n正排索引（传统）：\n\n| id   | content              |\n| ---- | -------------------- |\n| 1001 | my name is zhang san |\n| 1002 | my name is li si     |\n\n倒排索引（将一条语句按照关键字进行分词拆分，保存每个关键字的 id）：\n\n| keyword | id         |\n| ------- | ---------- |\n| name    | 1001, 1002 |\n| zhang   | 1001       |\n\n\n\n## 基础增删改查\n\n对比关系型数据库，创建索引就等同于创建数据库。四种类型的 RESTful 请求概览：\n\n|      method       |                         URL                         |            描述            |\n| :---------------: | :-------------------------------------------------: | :------------------------: |\n| PUT（创建，修改） |       localhost:9200/索引名称/类型名称/文档id       |   创建文档（指定文档id）   |\n|   POST（创建）    |          localhost:9200/索引名称/类型名称           |   创建文档（随机文档id）   |\n|   POST（修改）    |       localhost:9200/索引名称/类型名称/文档id       |          修改文档          |\n|   POST（修改）    | localhost:9200/索引名称/类型名称/文档id/**_update** | 修改文档（会进行数据对比） |\n|  DELETE（删除）   |       localhost:9200/索引名称/类型名称/文档id       |          删除文档          |\n|    GET（查询）    |       localhost:9200/索引名称/类型名称/文档id       |       通过文档ID查询       |\n|    GET（查询）    |    localhost:9200/索引名称/类型名称/**_search**     |          条件查询          |\n\n### 创建文档\n\n创建文档有两种方式：\n\n- **PUT 请求**：**幂等性**操作。必须指定文档 id（必须明确知道要操作的对象）；如果该文档不存在，就创建该文档；如果文档已经存在，就直接**整个替换文档内容**（此时为修改请求）。\n- **POST 请求**：**非幂等性**操作。可以不指定文档 id（也可以指定）；如果不指定 id，则新增数据时服务**器自动为该文档创建**一个 id；如果指定 id，则以该 id 创建文档（如果文档已存在，则 POST 修改请求会修改目标对象的**部分内容**）\n\n---\n\n**PUT 和 POST 幂等性的讨论**：\n\n- PUT：幂等性操作。因为想发出 PUT 请求时必须指定文档 id（必须明确要操作的对象），那么无论发出多少次请求，始终都是在操作该对象，对其内容进行修改，并不会导致创建重复的该对象。\n- POST：非幂等性操作。因为 POST 请求可以不指定文档 id，这样在发出多次相同的 POST 请求时，如果不指定 id，服务器会创建多个重复的对象（内容相同，但 id 都是服务器随机生成的）\n\n---\n\n> https://cloud.tencent.com/developer/news/39873\n\n总结：使用 PUT 时，必须明确知道要操作的对象，如果对象不存在，创建对象；如果对象存在，则**全部替换**目标对象。同样 POST 既可以创建对象，也可以修改对象。但用 POST 创建对象时，之前并不知道要操作的对象，由 HTTP 服务器为新创建的对象生成一个唯一的 URI；使用 POST 修改已存在的对象时，一般**只是修改目标对象的部分内容**。\n\n### 查询文档\n\n查询数据通常用 GET 请求，同时可以选择是否指定文档 id：\n\n- 如果指定文档 id，类似于 MySQL 中以指定主键 id 的方式（主键查询）来查询数据，只会查出指定 id 的文档数据。\n- 如果不指定文档 id，则需要在 URL 里添加 `_search` 字段，表明进行**条件查询**（类似于 MySQL 里的 `WHERE`）， 同时需要在请求体里添加条件查询的条件。\n\n示例：http://localhost:9200/custom/external/1\n\n```json\n{\n    \"_index\": \"customer\", // 在哪个索引\n    \"_type\": \"external\",  // 在哪个类型\n    \"_id\": \"1\",           // 文档 id\n    \"_version\": 1,        // 版本号，代表该文档被修改了几次\n    \"_seq_no\": 0,         // 并发控制字段，每次更新就会+1，用来做乐观锁\n    \"_primary_term\": 1,   //同上，主分片重新分配，如重启，就会变化\n    \"found\": true, \n    \"_source\": {\n        \"name\": \"John Doe\" // 真正的内容\n    }\n}\n```\n\n### 修改文档\n\n修改文档有两种方式：\n\n- **PUT 请求**：**全量更新**。必须指定所有字段的值，否则漏写的字段将被覆盖为默认值。并且每次修改后，`_version` 字段的值都会加一。\n- **POST 请求**：**局部更新**。漏写的字段不会被覆盖。只会更新 POST 请求体里携带的字段，没有指定的字段的值不会被改变。如果 URL 里指定了 `_update`，则此时的 POST 请求会先进行一次检查，判断原数据的值是否和要更新的值相等：\n  - 如果相等，则不执行修改操作，`_version` 字段的值不会增加\n  - 如果不相等，才会执行修改操作，`_version` 字段的值加一\n\n> 不论是 PUT 请求还是 POST 请求，只要 URL 里不指定 `_update`，就不会执行重复校验。只有 POST 请求中指定了 `_update`，才会进行重复校验\n\n### 删除文档\n\n删除文档只能使用 DELETE 请求，并明确指定文档 id。\n\n### bulk 批量操作\n\n在请求中添加 `_bulk` 关键字可以进行批量操作：\n\n```\nPOST customer/external/_bulk\n# 两行是一条文档\n{\"index\":{\"_id\":\"1\"}}\n{\"name\":\"John Doe\"}\n# 两行是一条文档\n{\"index\":{\"_id\":\"2\"}}\n{\"name\":\"John Doe\"}\n```\n\n语法格式\n\n```json\n# 两行是一条文档\n{action:{metadata}}\n{requeestBody}\n# 两行是一条文档\n{action:{metadata}}\n{requesetbod }\n```\n\n- `index` 是新建索引，会覆盖文档；\n- `create` 是新建文档，不会覆盖文档\n\n复杂实例：\n\n```http\nPOST /_bulk\n{\"delete\":{\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"}}\n{\"create\":{\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"}}\n{\"title\":\"my first blog post\"}\n{\"index\":{\"_index\":\"website\",\"_type\":\"blog\"}}\n{\"title\":\"my second blog post\"}\n{\"update\":{\"_index\":\"website\",\"_type\":\"blog\",\"_id\":\"123\"}}\n{\"doc\":{\"title\":\"my updated blog post\"}}\n```\n\nbulk API 以此按顺序执行所有的action (动作)。如果某个单个的动作因任何原因而失败，它将继续处理它后面剩余的动作。当 bulkAPI 返回时，它将提供每个动作的状态（与发送的顺序相同），可以借此检查一个指定的动作是否失败了。\n\n### _cat\n\n在请求中添加 `_cat` 字段，可以用于查看 ES 服务器中的一些信息，例如：\n\n- `GET /_cat/nodes`：查看所有节点\n- `GET /_cat/health`：查看 es 健康状况\n- `GET /_cat/master`：查看主节点\n- `GET /_cat/incices`：查看所有索引 show databases\n\n其他表头：\n\n| 表头           | 含义                                                         |\n| -------------- | ------------------------------------------------------------ |\n| health         | 当前服务器健康状态： green(集群完整) yellow(单点正常、集群不完整) red(单点不正常) |\n| status         | 索引打开、关闭状态                                           |\n| index          | 索引名                                                       |\n| uuid           | 索引统一编号                                                 |\n| pri            | 主分片数量                                                   |\n| rep            | 副本数量                                                     |\n| docs.count     | 可用文档数量                                                 |\n| docs.deleted   | 文档删除状态（逻辑删除）                                     |\n| store.size     | 主分片和副分片整体占空间大小                                 |\n| pri.store.size | 主分片占空间大小                                             |\n\n \n\n## 复杂查询\n\n前面介绍到，在请求的 URL 中添加 `_search` 字段，表明进行**条件查询**（类似于 MySQL 里的 `WHERE`）， 同时需要在请求体里添加条件查询的条件。\n\n常用参数：\n\n- `query`：类似于 `where`，在其内添加各种匹配规则以实现条件查询\n- `_source`：过滤字段\n- `sort`：排序\n- `form`、`size` 分页\n\n![img](/images/%E3%80%90ElasticSearch%E3%80%91ElasticSearch/20201203002017.png)\n\n### 匹配\n\n匹配查询分为以下几种：\n\n- `match`：针对 **text 文本类型**的文档\n  - 如果字段类型是**数字**类型，则会**精确匹配**，只匹配出等于该值的文档\n  - 如果字段类型是**字符串**类型，则会**模糊匹配**，先使用分词器解析分析文档，然后进行查询。分词器会将该字符串拆分成多个单词，从而匹配出包含这些单词中的任何一个的文档，并再按照评分 `score` （包含这些单词的比例）对匹配到的文档进行排序\n  - 如果某个字段上加了 `keyword`（例如 `name.keyword`），就代表该字段查询时不进行分词，要精确匹配\n- `match_all`：查询所有，不做条件匹配\n- `match_phrase`：将需要匹配的值当成一个整体单词（**不分词**）进行检索\n- `multi_match`：同时设置多个条件，需要同时满足这些条件才算匹配\n- `term`：针对**非文本类型**的文档（例如 number/date/keyword），**精确匹配**具体数值，不进行分词，接通过**倒排索引**指定词条查询。\n\n---\n\n`text` 和 `keyword` 的区别：\n\n- `text`：\n  - **支持分词**，**全文检索**、支持模糊、精确查询，不支持聚合、排序操作;\n  - text 类型的最大支持的字符长度无限制，适合大字段存储；\n- `keyword`：\n  - **不进行分词**，**直接索引**、支持模糊、支持精确匹配，支持聚合、排序操作。\n  - `keyword`类型的最大支持的长度为——32766个UTF-8类型的字符,可以通过设置`ignore_above` 指定自持字符长度，超过给定长度后的数据将不被索引，**无法通过term精确匹配检索返回结果**。\n\n---\n\n### 复合查询\n\n> 复合语句可以合并任何其他嵌套语句，包括复合语句，了解这一点是很重要的，这就意味着，复合语句之间可以互相嵌套，可以表达式非常复杂的逻辑\n\n**多条件查询**（`bool`），其都需要写在 `query` 字段内，都属于条件查询：\n\n- `must`：必须达到 `must `列举的所有条件\n- `should`：应该达到 `should `列举的条件，**如果达到会增加相关文档的评分**，并**不会改变查询的结果**，如果 query 中只有 should 且只有一种匹配规则，那么 should 的条件就会被作为默认匹配条件而去改变查询结果。should 是**加分项**，不满足也能查出来。只是如果满足，score 会加分\n- `must_not`：必须不是指定的情况。`must_not` 不会额外贡献得分，但是其是一个 filter，不满足直接不显示\n- `filter`：条件过滤。效果和 `must` 类似，也能检索出目标记录，但是不会记录相关性得分，不满足 `filter` 的直接过滤，满足的留下。且满足的也不会额外增加相关性得分\n\n![img](/images/%E3%80%90ElasticSearch%E3%80%91ElasticSearch/20201203150628.png)\n\n> 上图中的相当于 and 不正确\n\n\n\n\n\n\n\n\n\n\n\n## 其他\n\n\n\n\n","tags":["ElasticSearch"],"categories":["ElasticSearch"]},{"title":"【数据结构】堆","url":"/2021/12/14/【数据结构】堆/","content":"\n## 堆结构\n\n![image-20211003201744690](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%A0%86/image-20211003201744690-1633921333456.png)\n\n> 堆结构本身比堆排序要重要\n\n堆结构就是用数组实现的**完全二叉树**结构。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211004174447857-1633921333457.png\" alt=\"image-20211004174447857\" style=\"zoom:50%;\" />\n\n堆结构的节点公式：\n\n- 节点 i 的父节点为 (i - 1) / 2（左右节点都可以统一用这个公式）\n- 节点 i 的左子节点为 2 \\* i + 1\n- 节点 i 的右子节点为 2 \\* i + 2\n\n使用上述公式即直接定位到某个节点的父/子节点\n\n### 大/小根堆\n\n- **大根堆**：堆中的每一个父节点都要比其子节点上的数字大（不考虑其对称的另一侧分支里的节点数字大小）。\n- **小根堆**：堆中的每一个父节点都要比其子节点上的数字小（不考虑其对称的另一侧分支里的节点数字大小）。\n\n堆结构最重要的两个操作：\n\n- **heapInsert**：add 操作，**新增**一个数据到已知堆中。具体做法是新增的数据不断向上遍历堆结构，将数字插入到合适的父节点位置\n- **heapify**：poll 操作，**弹出**堆里第一个元素（根节点）的值，并重新调整堆结构，令其余部分的元素继续保持大/小根堆结构。具体做法是新的根结点的元素不断向下遍历堆结构，交换其到合适的子节点位置\n\n---\n\n**heapInsert**：add 操作。用于新增一个数据到堆中，当新来一个数字时，将其添加到堆结构中，并且满足大根堆（或小根堆）：向上遍历他的每一个父节点，判断其是否大于它的父节点，若大于则和父节点交换，若小于则停止遍历。直到当前数字放到合适的父节点位置，使得当前堆满足大根。\n\n**heapify**：poll 操作。用于弹出堆中第一个元素，并令其余部分继续保持大/小根堆结构，若用户要求返回并删除当前大根堆的最大元素，并且要求删除后的其他元素依旧符合大根堆：返回当前堆的第一个节点（其肯定是最大元素），然后将当前堆的最后一个元素放到第一个元素的位置。之后开始向下遍历第一个元素的子节点，选出其子节点中最大的数字，并且判断该数字和自身的大小，若子节点数字更大，则交换自身和子节点，若子节点数字更小，则停止遍历；直到该元素被放到合适的子节点位置。\n\n---\n\n这两个操作的空间复杂度都是 O(logN)，因为 N 个节点的完全二叉树的高度为 O(logN)，上述两个操作都只需要遍历二叉树中的某一条分支即可，因此时间只有 O(logN)\n\nheapInsert 的代码：\n\n``` java\npublic static void heapInsert(int[] arr, int index) {\n  // 向上遍历当前节点的父节点,直到满足条件: 父节点的值 > 当前节点的值\n  while (arr[(index - 1) / 2] < arr[index]) {\n    swap(arr, (index - 1) / 2, index);\n    index = (index - 1) / 2; // index 记得变为父节点的值\n  }\n}\n```\n\nheapify 的代码：\n\n``` java\n// heapSize 用于表示逻辑上的堆的大小, 其和数组的大小没关系\n// 该方法的作用是, 在给定堆结构中, 当某个位置的元素被弹出,替换成了其他数字后\n// 要保证新的数组仍然保持堆结构, 那么就需要从这个位置开始向下遍历\n// 交换其子节点中最大的元素\npublic static void heapify(int[] arr, int index, int heapSize){\n  if (heapSize > arr.length) {\n    return;\n  }\n\n  while (2*index+1 < heapSize) {\n    // 两个孩子中, 判断谁的值更大\n    int largest = (2*index+2 < heapSize) && arr[2*index+1] < arr[2*index+2]\n      ? 2*index+2 : 2*index+1;\n\n    // 当前节点和子孩子中, 判断谁的值更大\n    largest = arr[index] < arr[largest] ? largest : index;\n\n    // 如果相等, 说明此时已经满足了大根堆的条件, 可以跳出循环\n    if (largest == index) {\n      break;\n    }\n\n    // 交换\n    swap(arr, index, largest);\n    index = largest;\n  }\n}\n```\n\n### 具体应用\n\n若用户要求修改堆结构中**任意一个位置**的元素的值，并要求修改后的数字仍然满足大根堆，则只需要判断修改后的元素是比原先大还是小：\n\n- 若修改后的元素比原先大，则进行 **heapInsert** 操作，将当前元素向上交换到合适的父节点位置\n- 若修改后的元素比原先小，则进行 **heapify** 操作，将当前元素向下交换到合适的子节点位置\n\n---\n\n小根堆在 Java 中就是**优先级队列**默认的实现方式： `PriorityQueue<Interger>`，其两个方法：\n\n- `add()` ：本质上就是 heapInsert 操作，将一个数字添加到已存在的小根堆中\n- `poll()`：本质上就是 heapify 操作，首先弹出当前小根堆的根结点元素，并令剩余数字依旧保持小根堆结构。\n\n但是其不能支持“修改堆中某个结构后以很轻的代价重新调整堆的结构”，只支持“弹出堆的根结点元素后重新调整堆的结构”，若想实现这些个性化的功能还需要自己定义堆结构。\n\n> 其扩容机制是当 heapSize 快满时，将 heapSize * 2。这个操作的时间复杂度在每个元素平摊下来后其实很低\n\n\n\n<!-- More -->\n\n## 堆排序\n\n堆排序的思想是：利用大根堆第一个元素最大的特性，令数组不断地组成大根堆，从而每次形成的大根堆里的第一个元素都是当前的最大值。\n\n算法流程：\n\n- 首先令当前数组的所有数字符合大根堆顺序（令一个数组变成大根堆的方式见后文，本质上就是不断做 heapInsert）\n- 当前大根堆的根节点就是最大的元素，将其与数组的最后一个元素交换位置，此时即得到了整个数组最大的元素\n- 接着将 heapSize--（因为已经有一个数字排好了序，heapSize 将减小），并对交换后的元素进行一次 heapify 操作：不断向下遍历子节点，直到与合适的位置数字进行交换。heapify 后，新的堆就又符合了大根堆结构\n- 再取当前大根堆的根节点上的元素，它就是原数组第二大的数字，将其与大根堆结构中最后一个节点的元素进行交换。此时原数组中最后两个位置的元素就是最大和第二大的元素\n- 再次 heapSize-- ，并对交换后的元素再进行一次 heapify 操作，新的大根堆的根结点的元素就是第三大的元素，将其与大根堆结构中最后一个节点的元素进行交换。\n- 重复上述过程，直到大根堆的 heapSize == 0，此时即完成了排序\n\n堆排序的复杂度：\n\n- 时间复杂度是 O(N \\* logN)\n- 额外空间复杂度 O(1)，只需要 swap 交换操作，不用开辟额外空间\n\n代码：\n\n```java\npublic static void heapSort(int[] arr) {\n  if (arr == null || arr.length < 2) {\n    return;\n  }\n\n  // 1. 先将数组变为大根堆\n  // 1.1 方式一: 依次将每个数字添加到堆结构中, 堆大小从0开始, 依次将新数字 heapInsert 进堆中\n  // 编码思路是, 从前往后将每个节点进行 heapInsert\n  // 其时间复杂度为 O(N*logN)\n  for (int i = 0; i < arr.length; i++) {  // O(N)\n    heapInsert(arr, i);                   // O(logN)\n  }\n\n  // 1.2 方式二: 从下向上, 先将每个子堆变为大根堆, 然后再将其父节点纳入再进行 heapify\n  // 编码思路是, 从后往前将每个节点进行 heapify\n  // 该方法速度更快, 其时间复杂度为 O(N)\n  for (int i = arr.length - 1; i >= 0; i--) {\n    heapify(arr, i, arr.length);\n  }\n  \n  // 2. 每次将大根堆的根结点元素与最后一个元素交换\n  int heapSize = arr.length;\n  while (heapSize > 0) {                  // O(N)\n    swap(arr, 0, heapSize-1);             // O(1)\n    // 注意 heapSize 先减一再进入 heapify\n    heapify(arr, 0, --heapSize);          // O(logN)\n  }\n\n  // 整体时间复杂度为 O(N*logN)\n}\n\npublic static void heapInsert(int[] arr, int index) {\n  // 向上遍历当前节点的父节点,直到满足条件: 父节点的值 > 当前节点的值\n  while (arr[(index - 1) / 2] < arr[index]) {\n    swap(arr, (index - 1) / 2, index);\n    index = (index - 1) / 2; // index 记得变为父节点的值\n  }\n}\n\n// heapSize 用于表示逻辑上的堆的大小, 其和数组的大小没关系\n// 该方法的作用是, 在给定堆结构中, 当某个位置的元素被弹出,替换成了其他数字后\n// 要保证新的数组仍然保持堆结构, 那么就需要从这个位置开始向下遍历\n// 交换其子节点中最大的元素\npublic static void heapify(int[] arr, int index, int heapSize){\n  if (heapSize > arr.length) {\n    return;\n  }\n\n  while (2*index+1 < heapSize) {\n    // 两个孩子中, 判断谁的值更大\n    int largest = (2*index+2 < heapSize) && arr[2*index+1] < arr[2*index+2]\n      ? 2*index+2 : 2*index+1;\n\n    // 当前节点和子孩子中, 判断谁的值更大\n    largest = arr[index] < arr[largest] ? largest : index;\n\n    // 如果相等, 说明此时已经满足了大根堆的条件, 可以跳出循环\n    if (largest == index) {\n      break;\n    }\n\n    // 交换\n    swap(arr, index, largest);\n    index = largest;\n  }\n}\n\npublic static void swap(int[] arr, int a, int b) {\n  if (a == b) {\n    return;\n  }\n\n  arr[a] = arr[a] ^ arr[b];\n  arr[b] = arr[a] ^ arr[b];\n  arr[a] = arr[a] ^ arr[b];\n}\n```\n\n---\n\n补充：想让一组数字变成一个大根堆/小根堆结构，上文中的编码方式时间复杂度是 O(N \\* logN)。然后还有一种更快的方式令一个数组变为大根堆/小根堆结构，其时间复杂度为 O(N)\n\n- 方式一：依次将每个数字添加到堆结构中，堆大小从0开始，依次将新数字 heapInsert 进堆中。当遍历完成后，即得到了大根堆，但这种方法的时间复杂度为 O(N \\* logN)\n- 方式二：从下向上，先将每个子堆变为大根堆，然后再将其父节点纳入再进行 heapify。其时间复杂度为 O(N)（其时间复杂度的估计方法使用了错位相减法）\n\n方式二就是一种逆向思维，反过来从后往前遍历数组，令其往后的子树符合大根堆，然后再向前遍历，不断扩大子树的大小，令新的子树也符合大根堆。这样的操作时间复杂度更低，因为整个树上一半的节点都是叶子节点，根本不需要做交换：\n\n![image-20211004203745738](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%A0%86/image-20211004203745738-1633921354763.png)\n\n![image-20211004203713788](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%A0%86/image-20211004203713788-1633921354763.png)\n\n代码：\n\n``` java\n// 1. 先将数组变为大根堆\n// 1.1 方式一: 依次将每个数字添加到堆结构中, 堆大小从0开始, 依次将新数字 heapInsert 进堆中\n// 编码思路是, 从前往后将每个节点进行 heapInsert\n// 其时间复杂度为 O(N*logN)\nfor (int i = 0; i < arr.length; i++) {  // O(N)\n  heapInsert(arr, i);                   // O(logN)\n}\n\n// 1.2 方式二: 从下向上, 先将每个子堆变为大根堆, 然后再将其父节点纳入再进行 heapify\n// 编码思路是, 从后往前将每个节点进行 heapify\n// 该方法速度更快, 其时间复杂度为 O(N)\nfor (int i = arr.length - 1; i >= 0; i--) {\n  heapify(arr, i, arr.length);\n}\n```\n\n---\n\n### 堆排序的扩展：几乎有序的数组\n\n![image-20211004204032904](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%A0%86/image-20211004204032904-1633921378395.png)\n\n**解题思路**：这个移动距离不超过 k 非常重要，这意味着我们可以在 k 范围内组成一个小根堆，这个小根堆的第一个元素就是这个范围内的最小值，依次移动指针，将每个子 k 区域内的数组组成小根堆，即可不断得到当前范围内的最小值，从而完成排序。\n\n具体流程：\n\n- 首先取数组的前 k 个数字，组成小根堆（复杂度为 O(k \\* logk)，或用更快的方式可以达到 O(k)），然后将小根堆第一个位置的元素弹出，放到原数组的0位置，这个数就是整个数组的最小值（因为这道题限制了每个数字的移动距离不会超过 k）\n- 接着向后移动1个位置，再取 k+1 位置上的数 arr[k+1] 与上一步剩下的 k-1 个元素一起再组成新的小根堆后，再取出最新小根堆里的第一个元素（此元素就是整个数组第二小的数）\n\n重复上述过程，直到整个数组被遍历完，即可得到排序后的数组。此过程的时间复杂度为 O(N \\* logk)，如果这个k很小，那么这个算法的时间复杂度就比较接近 O(N)\n\n具体实现既可以通过自己定义堆结构，又可以直接使用 Java 提供的优先级队列：`PriorityQueue<Interger>`，其底层就是一个小根堆结构。\n\n---\n\n**小根堆**在 Java 中就是**优先级队列**默认的实现方式： `PriorityQueue<Interger>`，其两个方法：\n\n- `add()` ：本质上就是 heapInsert 操作，将一个数字添加到已存在的小根堆中\n- `poll()`：本质上就是 heapify 操作，首先弹出当前小根堆的根结点元素，并令剩余数字依旧保持小根堆结构。\n\n但是其不能支持“修改堆中某个结构后以很轻的代价重新调整堆的结构”，只支持“弹出堆的根结点元素后重新调整堆的结构”，若想实现这些个性化的功能还需要自己定义堆结构。\n\n> 其扩容机制是当 heapSize 快满时，将 heapSize * 2。这个操作的时间复杂度在每个元素平摊下来后其实很低\n\n若想实现大根堆，则只需要在创建优先级队列时传入自定义的比较器：\n\n``` java\n// 修改成大根堆\nPriorityQueue<Integer> heap = new PriorityQueue<>((o1, o2) -> o2 - o1);\n```\n\n---\n\n使用 `PriorityQueue<Interger>` 解该题：\n\n``` java\npackage com.zhao;\n\nimport java.util.Arrays;\nimport java.util.PriorityQueue;\n\npublic class SortArrayDistanceLessK {\n    public static void sortArrayDistanceLessK(int[] arr, int k) {\n        if (arr == null || arr.length < 2) {\n            return;\n        }\n\n        // 默认为小根堆\n        PriorityQueue<Integer> heap = new PriorityQueue<>();\n\n        // 0 ~ k-1 位置上的数组成小根堆(这里要取k和arr.length的最小值)\n        for (int i = 0; i < Math.min(k, arr.length); i++) {\n            heap.add(arr[i]);\n        }\n\n        int i = 0;\n        for (; i < arr.length - k; i++) {\n            arr[i] = heap.poll();\n            // 注意索引值不是 i+k+1\n            // 因为整个小根堆的heapSize==k, 所以 \"当前根节点索引+k\" 就是小根堆的下一个索引值\n            heap.add(arr[i + k]);\n        }\n\n        // 上述遍历完毕后, 将大根堆里剩余的数挨个弹出放到数组的最后k个位置\n        while (!heap.isEmpty()) {\n            arr[i++] = heap.poll();\n        }\n    }\n\n    public static void main(String[] args) {\n        int[] arr = new int[]{2,3,1,5,4,6,8,7};\n\n        SortArrayDistanceLessK.sortArrayDistanceLessK(arr, 3);\n        System.out.println(Arrays.toString(arr));\n    }\n}\n```\n\n## 堆结构的常见问题\n\n### 最小的 K 个数\n\n> https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/3chong-jie-fa-miao-sha-topkkuai-pai-dui-er-cha-sou/\n\n[剑指 Offer 40. 最小的k个数](https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/)：输入整数数组 `arr` ，找出其中最小的 `k` 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。\n\n思路：我们用一个大根堆**实时维护数组的前 k 小值**。首先将前 k 个数插入大根堆中，随后从第 k+1 个数开始遍历，如果当前遍历到的数比大根堆的堆顶的数要小，就把堆顶的数弹出，再插入当前遍历到的数。最后将大根堆里的数存入数组返回即可。\n\n代码：\n\n``` java\n// 1. 大根堆不断维护当前小的k个数字，当来新的数字，如果比堆顶大\n//（比当前k个小数里的最大的小，说明这个最大的堆顶肯定不在答案里了），弹出堆顶\npublic int[] getLeastNumbers01(int[] arr, int k) {\n    // 注意！！将系统默认的小根堆改成大根堆\n    Queue<Integer> maxHeap = new PriorityQueue<>((o1, o2) -> o2 - o1);\n    for (int i = 0; i < arr.length; i++) {\n        if (i < k) {\n            maxHeap.offer(arr[i]);\n        } else {\n            if (maxHeap.peek() > arr[i]) {\n                maxHeap.poll();\n                maxHeap.offer(arr[i]);\n            } \n        }\n    }\n\n    int[] res = new int[k];\n    int i = 0;\n    // 弹出前k个元素\n    while (!maxHeap.isEmpty()) {\n        res[i++] = maxHeap.poll();\n    }\n    return res;\n}\n```\n\n\n\n\n\n### 数据流中的中位数\n\n[剑指 Offer 41. 数据流中的中位数](https://leetcode-cn.com/problems/shu-ju-liu-zhong-de-zhong-wei-shu-lcof/)：如何得到一个数据流中的中位数？如果从数据流中读出奇数个数值，那么中位数就是所有数值排序之后位于中间的数值。如果从数据流中读出偶数个数值，那么中位数就是所有数值排序之后中间两个数的平均值。\n\n思路：建立一个 **小根堆** A 和 **大根堆** B ，各保存列表的**一半元素**，且规定：\n\n- A 保存**较大的一半数字**，长度为 N/2（N 为偶数时）或 (N + 1) / 2 （N 为奇数时）\n- A 保存**较小的一半数字**，长度为 N/2（N 为偶数时）或 (N - 1) / 2 （N 为奇数时）\n- 每次添加一个新元素时，若需要加入到 A 中，则**不能直接加入到 A**，而是先加入到 B 中，令其重新调整后弹出 B 的堆顶后再加入到 A 中；加入到 B 同理\n\n随后，中位数可仅根据 A, B 的堆顶元素计算得到。总结：**A 中所有数字都比 B 中的大**，并且当 N 为奇数时，**A 中保存的数字个数比 B 多一个**。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%A0%86/image-20211214210648202.png\" alt=\"image-20211214210648202\" style=\"zoom: 67%;\" />\n\n代码：\n\n``` java\nclass MedianFinder {\n    public PriorityQueue<Integer> A;\n    public PriorityQueue<Integer> B = new PriorityQueue<>();\n\n    public MedianFinder() {\n        // A：保存较大的一半数，是一个小根堆\n        A = new PriorityQueue<>();\n        // B：保存较小的一半数，是一个大根堆\n        B = new PriorityQueue<>((x, y) -> y - x);\n    }\n\n    public void addNum(int num) {\n        // 如果 A 比 B 多，当前数字应该加入到 B 中\n        if (A.size() > B.size()) {\n            A.offer(num);\n            B.offer(A.poll());\n        } else {\n            // 如果一样多，加到 A 中\n            B.offer(num);\n            A.offer(B.poll());\n        }\n    }\n\n    public double findMedian() {\n        return A.size() == B.size() ? 0.5 * (A.peek() + B.peek()) : A.peek();\n    } \n}\n```\n\n","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【数据结构】数组与字符串","url":"/2021/12/01/【数据结构】数组与字符串/","content":"\n## 二维数组常见题目\n\n### 顺时针打印矩阵\n\n输入一个矩阵，按照从外向里以顺时针的顺序依次打印出每一个数字。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/image-20211220183010271.png\" alt=\"image-20211220183010271\" style=\"zoom:50%;\" />\n\n示例 1：\n\n``` \n输入：matrix = [[1,2,3],[4,5,6],[7,8,9]]\n输出：[1,2,3,6,9,8,7,4,5]\n```\n\n思路：定义两个点：左上角和右下角。这两个点每次都在同一层的边框上，只要确定了这两个点，就可以顺时针方向遍历这一层框的元素（四条边上的元素）。遍历完毕后再将**左上角向右下方向移动一格**，右下角向左上方向移动一格。从而使得边框向内层收缩，然后重复上一步骤即可。\n\n例如下图使用不同颜色代表每一层的各个边，两个箭头代表两个边界点的移动方向：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%AD%97%E7%AC%A6%E4%B8%B2/image-20211220165107072.png\" alt=\"image-20211220165107072\" style=\"zoom:50%;\" />\n\n其中，在打印当前层的边框时，需要**特别注意**：分别打印四条边时，每次循环的终止是在该边的另一端点（另一条边的起点）的前一个位置，不能将该端点也打印，而应该将其作为下一条边的起点时被打印。以上图为例，最外层的遍历每次只能遍历四个格子，不能遍历到该行/列的最后一个，因为这一个元素是下一条边的起点，不能提前遍历了。\n\n代码：\n\n``` java\npublic class PrintMatrixSpiralOrder {\n    public static void printMatrixSpiralOrder(int[][] matrix) {\n        if (matrix == null || matrix.length < 1) {\n            return;\n        }\n        int topRow = 0;\n        int topCol = 0;\n        int downRow = matrix.length - 1;\n        int downCol = matrix[0].length - 1;\n        while (topRow <= downRow && topCol <= downCol) {\n            // 打印当前边界后，左上角向右下移动一步，右下角向左上移动一步，缩小边界框，继续循环\n            printEdge(matrix, topRow++, topCol++, downRow--, downCol--);\n        }\n\n    }\n\n    public static void printEdge(int[][] matrix, int topRow, int topCol, int downRow, int downCol) {\n        if (topRow > downRow || topCol > downCol) {\n            // 如果左上角在右下角的右下方，代表越界了，直接返回\n            return;\n        }\n        if (topRow == downRow) {\n            // 如果左上角和右下角在同一行，则只需要打印这一行即可\n            while (topCol <= downCol) {\n                System.out.print(matrix[topRow][topCol] + ' ');\n                topCol++;\n            }\n        } else if (topCol == downCol) {\n            // 如果左上角和右下角在同一列，则只需要打印这一列即可\n            while (topRow <= downRow) {\n                System.out.print(matrix[topRow][topCol] + ' ');\n                topRow++;\n            }\n        } else {\n            // 普通情况，四轮循环打印四条边\n            int currRow = topRow;\n            int currCol = topCol;\n            // 注意！！！ currCol 不能等于 downCol，否则在到达角点时，进行currCol++后会使得currCol越界\n            while (currCol < downCol) {\n                System.out.print(matrix[currRow][currCol] + \" \");\n                currCol++;\n            }\n            while (currRow < downRow) {\n                System.out.print(matrix[currRow][currCol] + \" \");\n                currRow++;\n            }\n            while (currCol > topCol) {\n                System.out.print(matrix[currRow][currCol] + \" \");\n                currCol--;\n            }\n            while (currRow > topRow) {\n                System.out.print(matrix[currRow][currCol] + \" \");\n                currRow--;\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        int[][] matrix = { { 1, 2, 3, 4 }, { 5, 6, 7, 8 }, { 9, 10, 11, 12 },\n                          { 13, 14, 15, 16 } };\n        printMatrixSpiralOrder(matrix);\n    }\n}\n```\n\n<!-- More -->\n\n### 顺时针旋转正方形\n\n给定一个 n × n 的二维矩阵 matrix 表示一个图像。请你将图像顺时针旋转 90 度。你必须在**原地**旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要使用另一个矩阵来旋转图像。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%95%B0%E7%BB%84%E4%B8%8E%E5%AD%97%E7%AC%A6%E4%B8%B2/image-20211220183127440.png\" alt=\"image-20211220183127440\" style=\"zoom:50%;\" />\n\n#### 方法一：由外向内层层遍历，交换每层内的四个对应位置\n\n同样可以使用上面题目的套路解该题，由外向内一层一层遍历该矩阵，每次将当前层的四条边上的对应位置进行交换。例如，交换如下四个元素：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%AD%97%E7%AC%A6%E4%B8%B2/image-20211220165545301.png\" alt=\"image-20211220165545301\" style=\"zoom:50%;\" />\n\n代码：\n\n```java\npublic class RotateMatrix {\n    public static void rotateMatrix(int[][] matrix) {\n        if (matrix == null || matrix.length == 0) {\n            return;\n        }\n        int topRow = 0;\n        int topCol = 0;\n        int downRow = matrix.length - 1;\n        int downCol = matrix[0].length - 1;\n        while (topRow < downRow && topCol < downCol) {\n            rotateEdge(matrix, topRow++, topCol++, downRow--, downCol--);\n        }\n    }\n\n    public static void rotateEdge(int[][] matrix, int topRow, int topCol, int downRow, int downCol) {\n        if (topRow > downRow || topCol > downCol) {\n            return;\n        }\n        int tmp = 0;\n        // 当前框内每一组有total个元素\n        int total = downCol - topCol;\n        // 正方形矩阵，不会发生左上角与右下角共行/列的情况\n        // 遍历四组中的每一个元素i，将其与其他组的位置交换\n        // 注意不能包含 downCol 列，因为该位置是属于第二组的第一个元素，不属于第一组\n        for (int i = 0; i < total; i++) {\n            tmp = matrix[topRow][topCol + i];\n            // 第一组的值改为第四组的对应位置\n            matrix[topRow][topCol + i] = matrix[downRow - i][topCol];\n            // 第四组的值改为第三组的对应位置\n            matrix[downRow - i][topCol] = matrix[downRow][downCol - i];\n            // 第三组的值改为第二组的对应位置\n            matrix[downRow][downCol - i] = matrix[topRow + i][downCol];\n            // 第二组的值改为第一组的对应位置\n            matrix[topRow + i][downCol] = tmp;\n        }\n    }\n\n    public static void printMatrix(int[][] matrix) {\n        for (int i = 0; i != matrix.length; i++) {\n            for (int j = 0; j != matrix[0].length; j++) {\n                System.out.print(matrix[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n\n    public static void main(String[] args) {\n        int[][] matrix = { { 1, 2, 3, 4 }, { 5, 6, 7, 8 }, { 9, 10, 11, 12 },\n                          { 13, 14, 15, 16 } };\n        printMatrix(matrix);\n        rotateMatrix02(matrix);\n        System.out.println(\"=========\");\n        printMatrix(matrix);\n    }\n}\n```\n\n#### 方法二：上下翻转 + 对角翻转\n\n使用数学规律，先将数组上下翻转，然后沿着对角线反转，同样可以得到答案。\n\n代码：\n\n```java\n// 方法二：使用数学规律，先将数组上下翻转，然后沿着对角线反转\npublic static void rotateMatrix02(int[][] matrix) {\n    if (matrix == null || matrix.length == 0) {\n        return;\n    }\n    int N = matrix.length;\n    int tmp = 0;\n    // 先上下反转\n    for (int i = 0; i < N / 2; i++) {\n        for (int j = 0; j < N; j++) {\n            // 交换上下对称位置的值\n            tmp = matrix[i][j];\n            matrix[i][j] = matrix[N - 1 - i][j];\n            matrix[N - 1 - i][j] = tmp;\n        }\n    }\n    // 然后沿着对角线反转\n    for (int i = 0; i < N; i++) {\n        // 注意对角线上的元素不反转\n        for (int j = i + 1; j < N; j++) {\n            tmp = matrix[i][j];\n            matrix[i][j] = matrix[j][i];\n            matrix[j][i] = tmp;\n        }\n    }\n}\n```\n\n\n\n### zigzag 方式打印矩阵\n\n用 zigzag 的方式打印矩阵，比如如下的矩阵\n\n示例：\n\n```\n矩阵：\n  0 1 2 3\n  4 5 6 7\n  8 9 10 11\n打印顺序为：0 1 4 8 5 2 3 6 9 10 7 11\n```\n\n思路：定义两个边界点，分别沿着下图黑色路径与灰色路径移动，**二者每次都一起移动一格**。如果遇到边界就拐弯。二者每一起运动一格后，就打印二者构成的对角线上的元素（交替顺序，一次向上，一次向下），最终二者相遇在右下角时全部打印完毕。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%AD%97%E7%AC%A6%E4%B8%B2/image-20211220170626523.png\" alt=\"image-20211220170626523\" style=\"zoom:50%;\" />\n\n代码：\n\n```java\npublic class ZigZagPrintMatrix {\n    public static void zigZagPrint(int[][] matrix) {\n        if (matrix == null || matrix.length == 0) {\n            return;\n        }\n        // 上边界\n        int topRow = 0;\n        int topCol = 0;\n        // 下边界\n        int downRow = 0;\n        int downCol = 0;\n        // 右下角点（终止点）\n        int endRow = matrix.length - 1;\n        int endCol = matrix[0].length - 1;\n\n        boolean fromUp = false;\n        // 将在右下角相遇，然后退出循环\n        while (topRow <= endRow) {\n            printLine(matrix, fromUp, topRow, topCol, downRow, downCol);\n            // 上边界点一直右移，直到移动到最后一列后开始向下移动\n\n            // 注意 ⬇⬇⬇ 两个边界点移动时的顺序非常重要，因为行会受到列的影响或列会受到行的影响\n\n            // 注意！！上边界要先更新行，因为行会受到列的影响，而列不会受到行的影响。要先更新会受影响的变量\n            // 如果先更新列，那么可能在边角处漏掉一个位置元素\n            topRow = topCol == endCol ? topRow + 1: topRow;\n            topCol = topCol == endCol ? topCol : topCol + 1;\n            // 下边界点一直下移，直到移动到最后一行后开始向右移动\n            // 注意！！下边界要先更新列，因为列会受到行的影响，而行不会受到列的影响。要先更新会受影响的变量\n            // 如果先更新行，那么可能在边角处漏掉一个位置元素\n            downCol = downRow == endRow ? downCol + 1: downCol;\n            downRow = downRow == endRow ? downRow : downRow + 1;\n\n            // 交替上下打印，每次取反\n            fromUp = !fromUp;\n        }\n    }\n\n    public static void printLine(int[][] matrix, boolean fromUp, int topRow, int topCol, int downRow, int downCol) {\n        if (fromUp) {\n            // 从上到下打印\n            while (topRow <= downRow) {\n                System.out.print(matrix[topRow++][topCol--] + \" \");\n            }\n        } else {\n            // 从下到上打印\n            while (topRow <= downRow) {\n                System.out.print(matrix[downRow--][downCol++] + \" \");\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        int[][] matrix = { { 1, 2, 3, 4 }, { 5, 6, 7, 8 }, { 9, 10, 11, 12 } };\n        zigZagPrint(matrix);\n    }\n}\n```\n\n\n\n\n\n## KMP 算法\n\n\n\n代码：\n\n```java\npublic class KMP {\n\n    // 整体时间复杂度：O(N)，N 为 s 的长度\n    public static int getIndexOf(String s, String m) {\n        if (s == null || m == null || m.length() < 1 ||  s.length() < m.length()) {\n            return -1;\n        }\n\n        char[] str1 = s.toCharArray();\n        char[] str2 = m.toCharArray();\n        int[] next = getNextArray(str2);\n        int i1 = 0;\n        int i2 = 0;\n\n        while (i1 < str1.length && i2 < str2.length) {\n            if (str1[i1] == str2[i2]) {\n                // 情况一：当前位置相同，则一起往后移动\n                i1++;\n                i2++;\n            } else if (next[i2] == -1) {\n                // 情况二：str2 都到0位置了，还是和 str1 匹配不了。那么此时 str1 需要换一个开头和 str2 比较\n                // 等价于 i2 == 0，说明 i2 回到了原点，没有前缀了，也就没有办法再继续用技巧往右跳了\n                i1++;\n            } else {\n                // 情况三：当前的 X 和 Y 不相同，但是 Y 又不是 0，说明此时 str2 中 0 ~ Y-1 上的字符串和 str1 中已经有重合了，\n                // 但是 Y 位置却和 X 不同，说明 Y 该调出其最大前缀，使用技巧直接跳过这些字符到 next[i2] 位置\n                // PS：[0, i2 -1] 范围内的字符串肯定和 [Y-1 - (i2-1) , Y-1] 上的字符串完全匹配，所以可以直接跳到 i2 位置继续匹配\n                // str1 的 X 位置固定不动，str2 的 Y 使用技巧跳过重复的前缀元素\n                i2 = next[i2];\n            }\n        }\n        return i2 == str2.length ? i1 - i2 : -1;\n    }\n\n    // 时间复杂度：O(M)，M 为 str 的长度\n    public static int[] getNextArray(char[] str) {\n        if (str.length == 1) {\n            return new int[]{ -1 };\n        }\n\n        int[] next = new int[str.length];\n        // 前两个位置的值是固定的\n        next[0] = -1;\n        next[1] = 0;\n\n        // i 代表遍历 str 过程中当前的位置\n        int i = 2;\n        // cn 代表在遍历过程中，每个 i-1 位置对应的最大前缀值：next[i-1]。当前 i 位置需要使用该值进行计算得到 next[i] 的值\n        // cn：当前位置 i 的前一个位置 i-1 的最大前缀子串的下一个字符在什么位置，即 cn == next[i-1]\n        // 该位置的字符需要和 i-1 位置的字符比较是否相同，相同则 i 位置的最大前缀为 next[i-1] + 1，否则继续向前跳计算新的 cn\n        int cn = 0;\n\n        while (i < str.length) {\n            if (str[cn] == str[i - 1]) {\n                // 情况一：cn 位置的值等于 i-1 位置的值，则当前 i 位置的最大前缀子串长度为 next[i-1] + 1\n                // i++：将进行下一个位置的计算；++cn：下一个位置的cn要更新了，因为i位置的最大前缀加了1，所以下一个位置也要+1\n                next[i++] = ++cn;\n            } else if (cn > 0) {\n                // 注意：判别条件是 cn > 0，不是 next[cn] > 0\n                // 情况二：当前跳到 cn 位置的字符，和 i-1 位置字符匹配不上时，cn 继续向前跳\n                // 注意：cn 更新为当前 cn 的最大前缀子串的下一个字符位置，即 next[cn]\n                cn = next[cn];\n            } else {\n                // 情况三：如果无法往前跳了，则当前位置i不存在重合区间\n                // 注意：i 要 ++，进行更新\n                next[i++] = 0;\n            }\n        }\n        return next;\n    }\n}\n```\n\n\n\n## Man\n\n\n\n\n\n\n\n## 字符串常见题目\n\n### 翻转单词顺序\n\n输入一个英文句子，翻转句子中单词的顺序，但单词内字符的顺序不变。为简单起见，标点符号和普通字母一样处理。例如输入字符串\"I am a student. \"，则输出\"student. a am I\"。 说明：\n\n- 无空格字符构成一个单词。\n- 输入字符串可以在前面或者后面包含多余的空格，但是反转后的字符不能包括。\n- 如果两个单词间有多余的空格，将反转后单词间的空格减少到只含一个。\n\n示例 1：\n\n```\n输入: \"the sky is blue\"\n输出: \"blue is sky the\"\n```\n\n示例 2：\n\n``` \n输入: \"  hello world!  \"\n输出: \"world! hello\"\n解释: 输入字符串可以在前面或者后面包含多余的空格，但是反转后的字符不能包括。\n```\n\n示例 3：\n\n```\n输入: \"a good   example\"\n输出: \"example good a\"\n解释: 如果两个单词间有多余的空格，将反转后单词间的空格减少到只含一个。\n```\n\n代码：\n\n``` java\n// 我自己的：\npublic String reverseWords(String s) {\n    if (s == null || s.length() < 1) {\n        return s;\n    }\n\n    List<String> list = new ArrayList<>();\n    int left = 0;\n    int right = 0;\n    int count = 0;\n    // 1. 遍历过程中将首尾空格去掉，然后使用left和right将中间的多个空格去掉\n    for (; right < s.length(); right++) {\n        if (s.charAt(right) == ' ') {\n            if (left != right) {\n                list.add(s.substring(left, right));\n                count++;\n                left = right + 1;\n            } else {\n                left++;\n            }\n        }\n    }\n    // right遍历完后记得再额外判断一次最后的[left, right]区间\n    if (left != right) {\n        list.add(s.substring(left, right));\n        count++;\n    }\n\n\n    StringBuilder sb = new StringBuilder();\n\n    // 2. 倒序遍历list，这样就实现了整体的反转\n    while (count-- > 0) {\n        String substr = list.get(count);\n        sb.append(substr);\n        if (count != 0) {\n            sb.append(' ');\n        }\n    }\n    return sb.toString();\n}\n\n// 题解：只需一次遍历\npublic String reverseWords(String s) {\n    // 删除首尾空格\n    s = s.trim(); \n    // 也是使用的双指针锁定子字符串区间\n    int j = s.length() - 1, i = j;\n    StringBuilder res = new StringBuilder();\n    // 从后往前倒序遍历\n    while(i >= 0) {\n        // 搜索首个空格\n        while(i >= 0 && s.charAt(i) != ' ') {\n            i--; \n        }\n        // 添加单词\n        res.append(s.substring(i + 1, j + 1) + \" \"); \n        // 跳过单词间空格\n        while(i >= 0 && s.charAt(i) == ' ') {\n            i--; \n        }\n        // j 指向下个单词的尾字符（更新右指针）\n        j = i;\n    }\n    return res.toString().trim(); // 转化为字符串并返回\n}\n\n```\n\n\n\n\n\n","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【数据结构】并查集","url":"/2021/11/30/【数据结构】并查集/","content":"\n## 并查集\n\n并查集中有三个哈希表，存储三种信息：\n\n- **元素表**：存储用户传入的数据类型 `V` 到自定义包装类型 `Element <V>`间的映射（装饰器模式）。该表用于根据用户传入的变量查询自定义的包装类型变量\n- **父节点表**：存储每个元素的父节点的信息（头节点的父节点是其自身）\n- **秩表**：存储每个集合中元素节点的个数（只有每个集合的头节点才存储在该表中）\n\n并查集的主要思想：\n\n- **查找某个元素的头节点**：从父节点表中不断遍历当前元素的父节点，直到父节点等于自身，即找到了头节点\n- **判断两个元素所在的集合是否相同**：寻找每个元素所在集合的头节点，判断二者是否相等\n- **合并两个集合**：将节点数量少的集合的头节点的父节点设置为节点多的集合的父节点（节点数量存储在秩表中）\n\n一种通用的并查集模板：\n\n```java\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Stack;\n\npublic class UnionFind {\n   public static class Element<V> {\n      private V value;\n      public Element(V v) {\n         this.value = v;\n      }\n   }\n\n   public static class UnionFindSet<V> {\n      // 保存每个V对象与其对应的包装类对象Element<V>\n      public Map<V, Element<V>> elementMap;\n      // 保存每个节点的父元素\n      public Map<Element<V>, Element<V>> fatherMap;\n      // 保存每个头节点所在并查集的大小（只有头结点才保存该信息，代表该头结点所在的并查集有多少节点）\n      public Map<Element<V>, Integer> rankMap;\n\n      // 初始化并查集时需要给每个元素单独创建自己所在的集合\n      public UnionFindSet(List<V> list) {\n         elementMap = new HashMap<>();\n         fatherMap = new HashMap<>();\n         rankMap = new HashMap<>();\n\n         for (V v : list) {\n            Element<V> element = new Element<V>(v);\n            elementMap.put(v, element);\n            fatherMap.put(element, element);\n            rankMap.put(element, 1);\n         }\n      }\n\n      public Element<V> findHead(Element<V> element) {\n         // 创建一个栈，用于在寻找element头节点的过程中，将途径元素都记录下来，\n         // 并在找到头节点后依次弹出，重新设置其父节点为找到的头节点，做到路径压缩（扁平化）\n         Stack<Element<V>> path = new Stack<>();\n         // 不创建额外的变量，复用element不断指向新的父节点，直到指向头结点\n         while (element != fatherMap.get(element)) {\n            path.push(element);\n            element = fatherMap.get(element);\n         }\n\n         // 找到头节点后，将栈中每个节点都重新设置父节点\n         while (!path.isEmpty()) {\n            fatherMap.put(path.pop(), element);\n         }\n         return element;\n      }\n\n      public boolean isSameSet(V a, V b) {\n         if (!elementMap.containsKey(a) || !elementMap.containsKey(b)) {\n            // 如果集合中都不存在这两个元素，则直接返回false\n            return false;\n         }\n\n         // 判断两个节点的头结点是否相等，如果不相等，则不在同一个集合中\n         return findHead(elementMap.get(a)) == findHead(elementMap.get(b));\n      }\n\n      public void union(V a, V b) {\n         if (elementMap.containsKey(a) && elementMap.containsKey(b)) {\n            Element<V> aH = findHead(elementMap.get(a));\n            Element<V> bH = findHead(elementMap.get(b));\n            if (aH != bH) {\n               Element<V> big = rankMap.get(aH) >= rankMap.get(bH) ? aH : bH;\n               Element<V> small = big == aH ? bH : aH;\n               // 更新小的头的父节点为大的头\n               fatherMap.put(small, big);\n               // 更新新的头\n               rankMap.put(big, rankMap.get(big) + rankMap.get(small));\n               // 移除旧的头\n               rankMap.remove(small);\n            }\n         }\n      }\n   }\n}\n```\n\n<!-- More -->","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【数据结构】哈希表","url":"/2021/11/28/【数据结构】哈希表/","content":"\n## 哈希\n\n> https://blog.csdn.net/u011240877/article/details/52940469\n\n哈希，又称“**散列**”。\n\n散列（hash）英文原意是“混杂”、“拼凑”、“重新表述”的意思。\n\n在某种程度上，散列是与排序相反的一种操作，排序是将集合中的元素按照某种方式比如字典顺序排列在一起，而散列通过计算哈希值，打破元素之间原有的关系，使集合中的元素按照散列函数的分类进行排列。\n\n在介绍一些集合时，我们总强调需要重写某个类的 `equlas()` 方法和 `hashCode()` 方法，确保唯一性。这里的 `hashCode()` 表示的是对当前对象的唯一标示。计算 hashCode 的过程就称作哈希。\n\n### 为什么需要哈希\n\n我们通常使用数组或者链表来存储元素，一旦存储的内容数量特别多，需要占用很大的空间，而且在**查找某个元素**是否存在的过程中，数组和链表都需要挨个循环比较，而通过哈希计算，可以大大**减少比较次数**。使得每次查找操作的时间复杂度为 O(1)。\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/20161026174147384)\n\n### 哈希函数\n\n哈希的过程中需要使用哈希函数进行计算。\n\n哈希函数是一种映射关系，根据数据的关键词 key ，通过一定的函数关系，计算出该元素存储位置的函数。表示为：`address = H [key]`\n\n常见的哈希函数构造方法：除留余数法。具体做法：首先将关键字key进行一个编码运算（例如MD5编码），生成对应的哈希值（MD5码的范围为 `0 ~ 2^64 - 1`）。然后该哈希值被某个不大于散列表长度 m 的数 p 求余，得到散列地址。即 `H(key) = key % p, p < m`。\n\n哈希函数的特性：经过哈希函数计算得到的散列地址是**均匀分布**的，经过 % 也还是均匀分布的。即使两个数字相差很小，经过哈希函数后二者也会大相径庭。这种特性被很好地应用在**一致性哈希**原理中，使得**众多虚拟节点平均地分布在整个哈希域中**，从而很好地做到数据库的**负载均衡**。\n\n### 哈希表\n\n在 Java 中哈希表的实现为 `HashMap`，其底层保存有一个 `Entry` 数组。通过重写的 `hashCode()` 方法计算出当前 POJO 对象的哈希值，从而将对象放到不同的位置，相同的哈希值的对象串联在一条链表上。当添加的对象过多导致链表长度过长时，哈希表会进行扩容，增加 `Entry` 数组的长度，此时会重新计算每个元素的哈希值（因为计算哈希值时的 m 和 p 发生了变化），将其重新分布在扩容后的哈希表上，这个过程是会消耗一定的时间的（JVM会开启另一个线程执行扩容工作，因此扩容过程并不会怎么影响用户线程时间）。\n\n时间复杂度分析：\n\n- **单次插入、修改或删除**哈希表中某个元素的时间复杂度为 O(k)，k 为串联链表上元素的个数，当 k 较小时可以认为是 O(1) 级别的\n- 哈希表**N个元素扩容**的时间复杂度为 O(N*logN)，**单次扩容**的理论时间复杂度为 O(logN)。实际工程上通过增大 k 值以减少扩容次数，可以使得单次扩容的时间复杂度接近于 O(1)\n\n\n\n---\n\n借助于哈希表设计数据结构\n\n![image-20211129203404158](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129203404158.png)\n\n思路：借助两个哈希表，一个存储的 `key : value` 为 `key : index`，另一个存储的为 `index : key`。等概率删除则借助于哈希表的平均分布的特性，在 index 范围内随机生成一个数字，删除以该数字为 index 的数据即可做到随机删除。\n\n> 细节：需要在每次删除后将 index 最大的元素交换到当前删除的位置，从而避免删除过程中的索引不连续出现的空洞现象。\n\n---\n\n<!-- More -->\n\n\n\n## 哈希表常见问题\n\n哈希表的去重性质，使得其可以解决许多问题，例如：\n\n### 差值为 k 的去重数字对\n\n给定一个数组 arr，求差值为 k 的去重数字对。\n\n思路：\n\n- 使用 HashSet，将所有数字加入其中，先做到了一个去重的效果。\n- 然后遍历 HashSet 里的每一个元素，将其加上 k 后，判断该数字是否存在于 HashSet 中，如果存在则找到了一对（这里是把每个元素作为较小的那个，加上 k 后寻找比他大的那个数字，因此可以避免重复加入同一对元素）\n\n代码：\n\n```java\npublic static List<List<Integer>> allPair(int[] arr, int k) {\n    HashSet<Integer> set = new HashSet<>();\n    for (int i = 0; i < arr.length; i++) {\n        set.add(arr[i]);\n    }\n    List<List<Integer>> res = new ArrayList<>();\n    for (Integer cur : set) {\n        if (set.contains(cur + k)) {\n            res.add(Arrays.asList(cur, cur + k));\n        }\n    }\n    return res;\n}\n```\n\n\n\n## 布隆过滤器\n\n> https://zhuanlan.zhihu.com/p/43263751\n\n本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 **“某样东西一定不存在或者可能存在”**。\n\n相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果是**概率性**的，而**不是确切的**。\n\n### 应用场景\n\n首先假设一个场景，需要设计一个黑名单URL的过滤器，使得黑名单的URL被拦截。如果使用传统的数组或哈希表来存储的话，那么显然大量的URL会占据非常多的系统资源（例如100亿条URL会占用几百G的内存）。因此就需要一种更好的数据结构来存储这些黑名单信息，既能节省内存又能以 O(1) 的时间复杂度进行增加和查询。\n\n布隆过滤器即可以处理这种问题（但是不能做到删除），也常用在预防缓存穿透。\n\n### 布隆过滤器数据结构\n\n布隆过滤器是一个 bit 向量或者说 bit 数组。其是以 bit 为单位（区别于 int[] 以32个 bits 为单位，boolean[] 以8个 bits 为单位）。数组的每个位置存储1或0。\n\n- 初始状态时，所有位都是0。\n- 设置黑名单时，首先经过 k 个不同的哈希函数，计算出 k 个哈希值；将这 k 个哈希值对应的数组元素设置为 1，代表这里来过一个黑名单（的 k 分之一）\n- 再来另一个黑名单时，仍然进行该操作。因为哈希函数的均匀分布性，不同的URL算出的哈希值会均匀分布在整个数组上。若发现某个位置已经为1了，则不做任何操作（意味着不同的URL生成的某种哈希值可能相同，这也导致了可能出现误判断的情况）。\n- 当所有黑名单设置完毕后，再来一个新的URL，同样计算其 k 个哈希值，判断是否都为1\n  - 如果都为1，说明当前URL是黑名单（但可能出现误判断，概率较低）\n  - 如果不都为1，说明当前URL一定不是黑名单\n\n示意图：\n\n![image-20211129205936391](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129205936391.png)\n\n误判的解释：\n\n- 黑名单误判成白名单：不可能发生，因为只要是黑名单，其对应的 k 个哈希值一定都为1\n- 白名单误判成黑名单：有可能发生但是概率非常低\n\n使用布隆过滤器的好处：极大地节省空间，不需要存储URL的信息，只需要维护一个位图即可，通常可以控制在30G以内。\n\n### 如何选择哈希函数个数和布隆过滤器长度\n\n很显然，过小的布隆过滤器很快所有的 bit 位均为 1，那么查询任何值都会返回“可能存在”，起不到过滤的目的了。布隆过滤器的长度会直接影响误报率，布隆过滤器越长其误报率越小。\n\n另外，哈希函数的个数也需要权衡，个数越多则布隆过滤器 bit 位置位 1 的速度越快，且布隆过滤器的效率越低；但是如果太少的话，那我们的误报率会变高。\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/v2-05d4a17ec47911d9ff0e72dc788d5573_1440w.jpg)\n\nk 为哈希函数个数，m 为布隆过滤器长度，n 为插入的元素个数，p 为误报率。如何选择适合业务的 k 和 m 值呢，公式：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129211516885.png\" alt=\"image-20211129211516885\" style=\"zoom:50%;\" />\n\n### 大 Value 拆分\n\nRedis 因其支持 setbit 和 getbit 操作，且纯内存性能高等特点，因此天然就可以作为布隆过滤器来使用。但是布隆过滤器的不当使用极易产生大 Value，增加 Redis 阻塞风险，因此生成环境中建议对体积庞大的布隆过滤器进行拆分。\n\n拆分的形式方法多种多样，但是本质是不要将 Hash(Key) 之后的请求分散在多个节点的多个小 bitmap 上，而是应该拆分成多个小 bitmap 之后，对一个 Key 的所有哈希函数都落在这一个小 bitmap 上。\n\n\n\n## 一致性哈希\n\n> https://segmentfault.com/a/1190000021199728\n\n在分布式系统中，当有多台数据库服务器时，使用传统的哈希算法进行**负载均衡**的思路时：对某个 key，先计算其哈希值，然后对节点数量 n 取模，从而决定其应该存储在哪台服务器节点上。示意图：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213109729.png\" alt=\"image-20211129213109729\" style=\"zoom:80%;\" />\n\n这种方式的一种**局限性**是：当增加和删除节点时，数据迁移的代价是全量的。例如本来有三个节点，所有数据均匀地分布在这三个节点上。当再来一台时，需要重新计算所有 key 的哈希值，然后再对4取模进行重新分配，这会浪费极大的时间。\n\n---\n\n选择作为哈希值的 key 时，要选择种类比较多的，能够让高频中频和低频的 key 在多台机器上分布比较均匀，从而实现数据库的负载均衡，让数据均匀分布在所有数据库上。\n\n一些不好的key选择：例如国家不适合作为 key，因为其分布不够均匀，会让大量相同国家的数据分布到同一台机器上；或选用性别的话只会分到两台机器上。\n\n---\n\n### 一致性哈希算法\n\n一致性哈希算法在 1997 年由麻省理工学院提出，是一种特殊的哈希算法，在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在**分布式哈希表**（Distributed Hash Table，DHT）中存在的**动态伸缩**等问题 。\n\n### 一致性哈希算法原理\n\n一致性哈希算法通过一个叫作**一致性哈希环**的数据结构实现。这个环的起点是 0，终点是 2^32 - 1，并且起点与终点连接，故这个环的整数分布范围是 [0, 2^32-1]（一致性哈希不计算取模 %），如下图所示：\n\n![image-20211129213029701](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213029701.png)\n\n#### 1、将对象放置到哈希环\n\n假设我们有 \"semlinker\"、\"kakuqo\"、\"lolo\"、\"fer\" 四个对象，分别简写为 o1、o2、o3 和 o4，然后使用哈希函数计算这个对象的 hash 值，值的范围是 [0, 2^32-1]：\n\n![image-20211129213229644](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213229644.png)\n\n图中对象的映射关系如下：\n\n```abnf\nhash(o1) = k1; hash(o2) = k2;\nhash(o3) = k3; hash(o4) = k4;\n```\n\n#### 2、将服务器放置到哈希环\n\n接着使用同样的哈希函数，我们将服务器也放置到哈希环上，可以选择服务器的 IP 或主机名作为键进行哈希，这样每台服务器就能确定其在哈希环上的位置。这里假设我们有 3 台缓存服务器，分别为 cs1、cs2 和 cs3：\n\n![image-20211129213311601](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213311601.png)\n\n图中服务器的映射关系如下：\n\n```bash\nhash(cs1) = t1; hash(cs2) = t2; hash(cs3) = t3; # Cache Server\n```\n\n#### 3、为对象选择服务器\n\n将对象和服务器都放置到同一个哈希环后，在哈希环上**顺时针**查找（可以使用二分查找实现）距离这个对象的 hash 值最近的机器，即是这个对象所属的机器。 以 o2 对象为例，顺序针找到最近的机器是 cs2，故服务器 cs2 会缓存 o2 对象。而服务器 cs1 则缓存 o1，o3 对象，服务器 cs3 则缓存 o4 对象。\n\n![image-20211129213405673](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213405673.png)\n\n#### 4、服务器增加的情况\n\n假设由于业务需要，我们需要增加一台服务器 cs4，经过同样的 hash 运算，该服务器最终落于 t1 和 t2 服务器之间，具体如下图所示：\n\n![image-20211129213425565](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213425565.png)\n\n对于上述的情况，只有 t1 和 t2 服务器之间的对象需要重新分配。在以上示例中只有 o3 对象需要重新分配，即它被重新到 cs4 服务器。在前面我们已经分析过，如果使用简单的取模方法，当新添加服务器时可能会导致大部分缓存失效，而使用一致性哈希算法后，这种情况得到了较大的改善，因为只有少部分对象需要重新分配。\n\n#### 5、服务器减少的情况\n\n假设 cs3 服务器出现故障导致服务下线，这时原本存储于 cs3 服务器的对象 o4，需要被重新分配至 cs2 服务器，其它对象仍存储在原有的机器上。\n\n![image-20211129213452096](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213452096.png)\n\n### 虚拟节点\n\n到这里一致性哈希的基本原理已经介绍完了，但对于新增服务器的情况还存在一些问题：\n\n1. 一开始服务器数量很少的时候，如何保证均匀性\n2. 一旦增加或减少服务器时，会导致负载不均衡，新增的服务器只承受较少的流量\n\n例如：新增的服务器 cs4 只分担了 cs1 服务器的负载，服务器 cs2 和 cs3 并没有因为 cs4 服务器的加入而减少负载压力。如果 cs4 服务器的性能与原有服务器的性能一致甚至可能更高，那么这种结果并不是我们所期望的。\n\n我们可以通过引入**虚拟节点**来解决负载不均衡的问题。即将每台物理服务器虚拟为一组虚拟服务器，**将虚拟服务器放置到哈希环上**，如果要确定对象的服务器，**需先确定对象的虚拟服务器，再由虚拟服务器确定物理服务器**。\n\n因为每个节点的虚拟服务器可以设置非常多个（例如1000个），从而使得这些虚拟服务器可以非常均匀地分布在整个哈希域上。并且新增或减少服务器时，其增加或减少的虚拟节点在环上的分布也是比较均匀的，因此仍然能保证负载均衡。\n\n![image-20211129213534006](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211129213534006.png)\n\n图中 o1 和 o2 表示对象，v1 ~ v6 表示虚拟服务器，s1 ~ s3 表示物理服务器。\n\n### 一致性哈希算法优点\n\n- 可扩展性。一致性哈希算法保证了增加或减少服务器时，数据存储的改变最少，相比传统哈希算法大大节省了数据移动的开销 。\n- 更好地适应数据的快速增长。采用一致性哈希算法分布数据，当数据不断增长时，部分虚拟节点中可能包含很多数据、造成数据在虚拟节点上分布不均衡，此时可以将包含数据多的虚拟节点分裂，这种分裂仅仅是将原有的虚拟节点一分为二、不需要对全部的数据进行重新哈希和划分。虚拟节点分裂后，如果物理服务器的负载仍然不均衡，只需在服务器之间调整部分虚拟节点的存储分布。这样可以随数据的增长而动态的扩展物理服务器的数量，且代价远比传统哈希算法重新分布所有数据要小很多\n\n\n\n## 大数据问题\n\n本章将介绍使用哈希函数解决大数据问题的常见技巧：\n\n- 哈希函数可以把数据按照种类**均匀分流**\n- 布隆过滤器用于集合的建立与查询，并可以**节省大量空间**\n- 一致性哈希解决数据服务器的**负载管理**问题\n- 利用并查集结构做岛问题的**并行计算**\n- 位图解决某一范围上数字的**出现情况**，并可以节省大量空间\n- 利用**分段统计**思想、并进一步节省大量空间\n- 利用堆、外排序来做**多个处理单元的结果合并**\n\n### 均匀分流\n\n题目一：\n\n![image-20211206160259675](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211206160259675.png)\n\n思路：如果内存不受限制，则可以创建一个超大的词频表，记录每个数字出现的频次，频次为0的即为未出现过的数。但是当内存受限时，不能创建所有数字的词频表，只能创建少量数字的词频表。\n\n此时的思路为：创建一个词频表（长度为 N），该表中每个元素代表某一个区间范围内的数字出现的总次数。这样对于没有出现过的数字所在的区间，其词频总数就会小于 `40 亿 / N `。因此通过第一次的统计，就可以得知哪个区间内的数字至少有一个从未出现过，那么第二次遍历就可以直接缩小范围到该区间内，在该区间内再平均划分 N 份，然后再遍历一次 40 亿个数字，将在该子区间内的数字进行词频统计……重复该过程直到找到某一个数字从未出现过。\n\n细节：\n\n- unsigned int 的范围为 [0, 2^32 - 1]，2^32 - 1 > 40 亿\n- 词频表长度 N 如何确定—— N = 10MB（内存限制 ） / 4B（unsigned int 长度）= 10240 * 1000 / 4 = 2560000，从而将 [0, 2^32 - 1] 范围内的数字均匀分到长度为 2560000 的词频表中\n- 如何确定某个数字应该被分配到词频表的哪个位置：先用 2^32 / N，计算出每个区间上数字的取值范围，然后来一个数字，就将其除以 2^32 / N，即可知道该数字属于哪个区间\n\n题目二：\n\n![image-20211206165633171](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211206165633171.png)\n\n> 1 GB = 2^30 byte\n\n思路一：**哈希函数均匀分流**\n\n- 先将所有数字先后经过哈希函数和取模操作，均匀分流到不同的子文件，记录其词频\n- 然后在该子文件中使用哈希表等方式统计出词频为 2 的数字\n- 对所有子文件都进行该操作，即可得到所有出现 2 次的数字\n\n思路二：**位图**\n\n- 创建一个位图，每两个 bit 代表一个数字出现的次数：\n  - 00：没出现过\n  - 01：出现过一次\n  - 10：出现过两处\n  - 11：出现过三次及以上\n- 这样对于 unsigned int 类型的整数，可以在 1GB 的内存空间内创建这么一个位图，每两个 bit 代表一个数字出现的次数，遍历所有数字更新该位图，即可得知所有出现两次的数字。\n\n> 使用基本数据类型创建位图的方法见博客：[【算法】位运算](https://yuyun-zhao.github.io/2021/11/24/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/)\n\n**【进阶】** 如果最多只能用 10 MB 的内存，如何找到这 40 亿个整数的中位数？\n\n思路：同上一题一样，可以使用**均匀分流**的技巧。\n\n- 先根据内存限制计算出词频数组的长度，然后将每个数字分配到不同的区间内，记录其频次\n- 遍历完一遍即可得知每个区间内出现数字的总频次\n- 题目要找的第 20 亿个数字，据此判断这个数字是落在哪个子区间上\n- 对该子区间继续划分子区间重复上述过程，不断缩小搜索范围，直到找到全局的第 20 亿个数字\n\n\n\n### 重复的 URL \n\n问题：有一个包含 100 亿个 URL 的大文件，假设每个 URL 占用 64B，请找出其中所有重复的URL。\n\n#### 方法一：哈希函数均匀分流\n\n所有 URL 放到同一个文件中，则该文件太大。因此可以使用哈希函数将所有的 URL 进行均匀分流，分别存储在许多的小文件中。具体做法为：将每个 URL 经过哈希函数计算后再对某个数（小文件的个数）取模；将其存放在计算结果对应的文件中。这样即可完成一次粗定位，将所有 URL 按照种类均匀存储在不同的文件中。然后再在每个子文件中使用哈希表等方式进行查重。\n\n#### 方法二：使用布隆过滤器\n\n创建布隆过滤器，当来一个 URL 时，计算其在布隆过滤器中的位置，并都标记为1。之后如果该 URL 再来一次的话，就可以发现其对应的位置在布隆过滤器中都已存在，这说明该 URL 已存在。但是该方法的缺点是会存在一定的错误率。可能两个不同的 URL 算出的值是相同的。\n\n---\n\n**【进阶】** 某搜索公司一天的用户搜索词汇是海量的（百亿数据量），请设计一种求出每天热门 Top 100 词汇的可行办法。\n\n分析：如果直接对所有数据进行排序，则空间复杂度过大。因此可以使用**均匀分流**的思路，将所有的词汇平均分配到多个子文件中，然后对每个子文件中的词汇进行排序，选出 Top 100。最终可以得到 N 个 Top 100 排行表。然后利用堆、外排序来做**多个处理单元的结果合并**。具体思路：\n\n- 初始化：\n  - 将每个子文件中的 Top 100 数据放入到一个大根堆中\n  - 创建一个**总堆**，用于存储所有词汇的 Top 100 数据\n  - 将所有子堆的堆顶弹出并压入到总堆中；\n- 迭代计算 Top 100：\n  - 弹出总堆的堆顶元素，放入到 Top 100 的结果集中\n  - 该堆顶元素属于哪个子堆，就从哪个子堆中再弹出一个堆顶元素压入到总堆中\n  - 继续弹出总堆的堆顶元素，放入到 Top 100 的结果集中\n  - 再判断该堆顶元素属于哪个子堆，就从哪个子堆中再弹出一个堆顶元素压入到总堆中\n  - 重复上述过程，直到总堆弹出100个堆顶元素，即找到了所有词汇的 Top 100 词语\n\n---\n\n### 文件数据排序\n\n有 10GB int32 类型的无序文件数据。希望能使用 5G/5M 内存将这些数据进行排序并存储在硬盘中（只使用少量内存完成大容量文件数据的排序）。\n\n#### 方法一：小根堆\n\n使用小根堆结构，保存每个文件数据的值与词频数：`Element<value: count>`\n\n实现步骤：\n\n- 将 [-2^31, 2^31 - 1] 范围的 10GB 文件数据先按照大小分为 N 组。N 的计算方法为：\n  - 首先根据题目的限制 5GB 计算出这个内存空间能保存多少个`Element<value: count>`元素：假设一个元素占 8（value:4 count:4） + 8（堆的其他结构） = 16 字节，则 5GB 能保存 5 * 2^30 / 16 ≈ 2^28 个元素。将其称为一组数据，一组数据保存着 2^28 个不同的数字\n  - 然后根据内存中最大能保存的元素个数计算出 [-2^31, 2^31 - 1] 范围的数据一共需要的组数 N = 2^32 / 2^28 = 16 组。注意是计算的 int32 范围的所有数组能划分多少组，和题目给的 10GB 无关\n- 确定了组数后，遍历一次这 10GB 的数据，将符合当前区间范围（[-2^31, -2^31+2^28]）的数字放入到小根堆中，同时更新其词频（记录词频的原因：如果一个数字出现了非常多次。如果保存值的话，需要将该值保存非常多份；而如果保存词频的话，只需要记录该值以及其出现的次数，只用 8 byte 即可，这样即可不受制于题目给的 10GB 限制，哪怕有很多重复的数字，也能通过记录词频的方式较好的降低了内存）\n- 该小根堆按照升序记录了 2^28 个数字以及其词频。可以利用该信息完成 [-2^31, -2^31+2^28] 区间内的所有数字的排序，将其内的数据按照升序保存到磁盘中即完成了该部分的排序。\n- 清空内存，继续下一轮遍历。每遍历一次 10GB 的文件，确定某一个区间内的数字的词频，重复上述过程 16 次，即可完成整体的排序\n\n#### 方法二：大根堆\n\n使用大根堆结构，并设置一个阈值，每次往大根堆中存储**高于该阈值**的**最小的 M 个**数据。该阈值的大小将随着遍历而不断提高，直到完成整个文件数据的排序。具体步骤：\n\n- 设置阈值为 -2^31，遍历一遍整个文件，将大于阈值的数据加入到大根堆中，同时保证大根堆中只能存储 M 个数据（该数据用上文中的方法进行计算得到）\n- 这样遍历完一次后，就可以得到当前区间范围内的 M 个排好序的数据，将其保存到磁盘中\n- 接着提高阈值为当前大根堆的最大值，然后继续重复上述过程，直到阈值提升到所有数据中的最大值，就完成了所有数据的排序\n\n### 岛问题\n\n![image-20211206150425460](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8/image-20211206150425460.png)\n\n进阶：若该地图特别大，希望用并行算法同时计算多个子地图中的岛屿数量，最后汇总。\n\n思路：使用**并查集**\n\n- 先单独计算每个子地图上的岛屿数量，并在子地图与其他子地图交接的边缘区域，将每个岛屿编上号，分别初始化为不同的集合。\n- 然后两块接壤的子地图的边界元素开始进行并查集算法中的合并操作，若能合并，则当前两个岛屿是同一个；若不能合并，则是两个独立岛屿。\n\n","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【算法】动态规划","url":"/2021/11/28/【算法】动态规划/","content":"\n## 动态规划的思想\n\n首先进行暴力尝试，然后建立记忆搜索表进行缓存，最后建立严格表结构。\n\n直接使用**暴力递归**，会将所有情况都进行尝试，这样时间复杂度较高，有很多之前尝试过的答案会在其他分支仍然进行尝试。因此可以在暴力递归的基础上建立记忆搜索表（缓存表），将已经尝试过的答案缓存到表中，这样在其他分支就不需要再次尝试了，可以直接从基友搜索表里获取结果，从而节省了大量的时间，该方法又被称为**记忆化递归法**。最后可以根据暴力尝试的推导公式建立严格表结构，从而省去递归操作，在严格表中通过递推快速得到结果。\n\n暴力递归就是尝试：\n\n- 把问题转化为规模缩小了的同类问题的子问题\n- 有明确的不需要继续进行递归的条件（base case）\n- 有当得到了子问题的结果之后的决策过程\n- 不记录每一个子问题的解\n\n暴力递归的常用技巧：\n\n- 在递归过程中不保存结果，而是在调用到 base case（栈底）时才执行保存，因为到 base case 时说明当前这条路是走得通的，那么走到底时就可以保存结果了，如果某条路走不通（例如八皇后问题中可能某些路就走不通）则不会到 base case，从而不会保存。\n- 在递归过程中通过修改 char[] 或 int[] 里的值来节省空间，在调用子问题前先修改原数组（要注意暂存起来修改前的值），并在子问题执行完毕后将其原始值保存回去，从而做到保持原数组的正确性，不影响其他的递归栈\n\n上述技巧使用举例：例如要保存一个字符串的所有子序列：\n\n- 递归过程中在修改 char[] 数组当前位置的值为空 `''`，代表不考虑当前字符的情况，修改后进入子问题，得到不考虑当前位置字符时的结果；然后该子问题的方法栈调用完毕后，再将原始值赋值回去，再调用一次子问题，代表考虑当前字符的情况，又可以得到一种结果\n- 递归到底时，再保存当前 char[] 中的内容到结果列表里。\n\n\n\n<!-- More -->\n\n## 动态规划常见题目\n\n### 汉诺塔问题\n\n在经典汉诺塔问题中，有 3 根柱子及 N 个不同大小的穿孔圆盘，盘子可以滑入任意一根柱子。一开始，所有盘子自上而下按升序依次套在第一根柱子上(即每一个盘子只能放在更大的盘子上面)。移动圆盘时受到以下限制：\n\n- 每次只能移动一个盘子\n- 盘子只能从柱子顶端滑出移到下一根柱子\n- 盘子只能叠在比它大的盘子上\n\n请编写程序，用栈将所有盘子从第一根柱子移到最后一根柱子。你需要原地修改栈。\n\n``` java\npublic void hanota(List<Integer> A, List<Integer> B, List<Integer> C) {\n    // 用栈：先将所有元素start中的元素都压入到other中，然后start最底层的圆盘就可以压入到end里了\n    // 递归进行该过程\n    hanotaHelper(A.size(), A, C, B);\n}\n\n// A: start B: end C: Other\npublic void hanotaHelper(int i, List<Integer> start, List<Integer> end, List<Integer> other) {\n    if (i == 1) {\n        // base case\n        end.add(0, start.remove(0));\n        return;\n    }\n    // 把 i-1 个元素压入other中备用，i要到end中\n    hanotaHelper(i-1, start, other, end);\n    // i 从 start 到 end\n    end.add(0, start.remove(0));\n    // 再把other里备用的i-1个重新压入到end中\n    hanotaHelper(i-1, other, end, start);\n}\n```\n\n### 打印一个字符串的全部子序列\n\n打印一个字符串的全部子序列，包括空字符串。\n\n思路：\n\n- 递归过程中在修改 char[] 数组当前位置的值为空 `''`，代表不考虑当前字符的情况，修改后进入子问题，得到不考虑当前位置字符时的结果；然后该子问题的方法栈调用完毕后，再将原始值赋值回去，再调用一次子问题，代表考虑当前字符的情况，又可以得到一种结果\n- 递归到底时，再保存当前 char[] 中的内容到结果列表里。\n\n``` java\npublic static List<String> printAllSubsquences(String str) {\n    if (str == null) {\n        return null;\n    }\n\n    char[] cstr = str.toCharArray();\n    List<String> res = new ArrayList<>();\n    process(0, cstr, res);\n    return res;\n}\n\npublic static void process(int i, char[] cstr, List<String> res) {\n    if (i == cstr.length) {\n        // 到底了，将当前的 cstr 转成 String 并保存到 res 中\n        res.add(new String(cstr));\n        return;\n    }\n\n    // 分支一：不考虑当前位置\n    char tmp = cstr[i];\n    cstr[i] = 0;\n    process(i + 1, cstr, res);\n\n    // 分支二：考虑当前位置\n    cstr[i] = tmp;\n    process(i + 1, cstr, res);\n}\n\npublic static void main(String[] args) {\n    String test = \"abc\";\n    System.out.println(printAllSubsquences(test));\n}\n```\n\n### 打印一个字符串的全部排列\n\n> 相似题目：打印一个数组的全部排列\n\n打印一个字符串的全部排列，要求不要出现重复的排列。\n\n本题使用交换字符的技巧减少占用的空间，并设置 visited[] 数组避免重复的排列（可能某些字符会重复出现在数组中）\n\n代码：\n\n```java\npublic static List<String> printAllPermutations(String str) {\n    if (str == null) {\n        return null;\n    }\n    char[] cstr = str.toCharArray();\n    List<String> res = new ArrayList<>();\n    process(0, cstr, res);\n    return res;\n}\n\n// 不重复体现在多一个 visited[] 数组\n\npublic static void process(int i, char[] cstr, List<String> res) {\n    if (i == cstr.length) {\n        // 到底时保存结果\n        res.add(new String(cstr));\n        return;\n    }\n    // 作用：在当前层遍历length-i种可能时，避免相同的字符都被swap到当前i位置，造成生成重复子序列\n    boolean[] visited = new boolean[26];\n    // 前i-1的字符顺序已定，当前层的字符可能有 length-i 种可能，每一种都对应了一个分支（子问题）\n    // 通过swap的方式确定前i-1字符，做到节省空间\n    for (int j = i; j < cstr.length; j++) {\n        // 先判断当前位置的字符是否在当前层已经访问过了，能避免重复子序列\n        if (visited[cstr[j] - 'a'] == true) {\n            continue;\n        }\n        // 代表当前字符已经访问过了\n        visited[cstr[j] - 'a'] = true;\n        // 先将遍历到的当前字符交换到第i个位置（当前递归栈遍历到第i层）\n        // 目的是保证遍历到第i层时，数组中的前i个元素是保存着当前分支下确定好顺序的字符，\n        // 也就是当前分支下已经确定了前i个元素的顺序，后面的字符要在子问题里确认顺序\n        swap(cstr, i, j);\n        process(i + 1, cstr, res);\n        // 当前分支处理完后记得交换回来，不要影响当前层的其他分支\n        swap(cstr, i, j);\n    }\n}\n\nprivate static void swap(char[] cstr, int i, int j) {\n    char tmp = cstr[i];\n    cstr[i] = cstr[j];\n    cstr[j] = tmp;\n}\n\npublic static void main(String[] args) {\n    String test = \"abc\";\n    System.out.println(printAllPermutations(test));\n}\n```\n\n\n\n### 栈的逆序\n\n给你一个栈，请你逆序这个栈，不能申请额外的数据结构，只能使用递归函数。如何实现?\n\n思路：\n\n定义方法 `reverse()`，将递归地调用该方法将整个栈中的元素进行反转，步骤：\n\n- 先调用自定义的方法 `getAndRemoveLastElement()` 抽取出栈底元素\n- 接着递归调用 `reverse()` 方法栈中剩余元素进行反转\n- 反转完毕后，再将刚才抽取出的栈底元素放到栈顶，即完成了整体的逆序\n\n该过程利用了系统栈将每一层方法栈中抽取的栈底元素保存起来，将剩余元素逆序后再回到当前方法栈，取回刚才保存的栈底元素放到栈顶。\n\n代码：\n\n```java\npublic static void reverse(Stack<Integer> stack) {\n    if (stack.isEmpty()) {\n        // base case\n        return;\n    }\n\n    // 1. 取出栈底元素\n    Integer tmp = getAndRemoveLastElement(stack);\n    // 2. 剩余元素递归逆序\n    reverse(stack);\n    // 3. 栈底元素放到栈顶\n    stack.push(tmp);\n}\n\n// 取出栈底元素并将其从栈中删除\n// 可以形象的理解为：\n// 1. 当前层的元素先弹出来，存到当前栈位置的局部变量表里\n// 2. 一层一层调用时，栈不断减小，这些元素不断被弹出保存到局部变量表里\n// 3. 直到最后一层，满足了base case，将栈底元素一路return到最外层的方法栈，\n//    在这个过程中之前被保存到局部变量表里的变量不断再压入栈中，从而恢复了栈\npublic static Integer getAndRemoveLastElement(Stack<Integer> stack) {\n    // 这里不需要判断栈是否为空，因为在调用该方法的reverse()方法里已经判断过了\n\n    Integer curr = stack.pop();\n    if (stack.isEmpty()) {\n        // base case\n        // 如果此时栈空了，说明刚才弹出的就是栈底元素\n        return curr;\n    } else {\n        // 如果栈还不为空，说明还没找到栈底，则递归调用该方法继续寻找栈底，\n        // 一直递归到栈底，在栈底时触发上面if成立的条件，从而将该元素一路返回到最外层递归，从而找到了栈底元素\n        Integer last = getAndRemoveLastElement(stack);\n        stack.push(curr);\n        return last;\n    }\n}\n\npublic static void main(String[] args) {\n    Stack<Integer> test = new Stack<Integer>();\n    test.push(1);\n    test.push(2);\n    test.push(3);\n    test.push(4);\n    test.push(5);\n    reverse(test);\n    while (!test.isEmpty()) {\n        System.out.println(test.pop());\n    }\n}\n```\n\n\n\n### 背包问题\n\n给定两个长度都为N的数组weights和values，weights[i]和values[i]分别代表i号物品的重量和价值。给定一个正数bag，表示一个载重bag的袋子，你装的物品不能超过这个重量。返回你能装下最多的价值是多少？\n\n代码：\n\n```java\npackage com.zhao;\n\npublic class Knapsack {\n    public static int maxValue(int[] weights, int[] values, int bag) {\n        return process(0, weights, values, 0, 0, bag);\n    }\n\n    public static int process(int i, int[] weights, int[] values, int alreadyWeight, int alreadyValue, int bag) {\n        // 如果当前重量已经超了，则不需要再继续递归了，下面肯定不满足了\n        if (alreadyWeight > bag) {\n            // 如果发现当前的重量超了，说明上一层调用时，前一个袋子里的重量加上去就超了，\n            // 所以当前层以后的都不用考虑了，因为肯定会超出限制，直接返回，并且返回的总价值要减去上层的价值，\n            // 代表上层不能将其重量算进去，否则就超了。也就是说上一层的分支止步于此了，\n            // 这条分支选择拿了了上一层的values[i-1]物品，发现超了，也就是说不能拿这个物品，\n            // 所以该分支止步于此了，其最大值就是 alreadyValue - values[i-1]（因为alreadValue里多算了values[i-1]，这个是不能算进去的，因为会导致超出重量限制\n            return alreadyValue - values[i - 1];\n            // 也可以 return 0\n        }\n\n        if (i == weights.length) {\n            // base case\n            return alreadyValue;\n        }\n\n        // 1. 加上当前重量\n        // 2. 不加上当前重量\n        // 返回两种情况的最大值\n        // 注意：在这里并没有考虑加上当前层后是否会超出重量限制，所以需要在下一层先判断alreadyWeight是否大于bag，\n        // 如果大于，这条添加当前物品的分支就止步于此了，返回的价值要减去当前加上的values[i]，体现在代码第一行的判断\n        return Math.max(\n            process(i + 1, weights, values, alreadyWeight + weights[i], alreadyValue + values[i], bag),\n            process(i + 1, weights, values, alreadyWeight, alreadyValue, bag)\n        );\n    }\n\n    // 动态规划版\n    public static int maxValue2(int[] c, int[] p, int bag) {\n        int[][] dp = new int[c.length + 1][bag + 1];\n        for (int i = c.length - 1; i >= 0; i--) {\n            for (int j = bag; j >= 0; j--) {\n                dp[i][j] = dp[i + 1][j];\n                if (j + c[i] <= bag) {\n                    dp[i][j] = Math.max(dp[i][j], p[i] + dp[i + 1][j + c[i]]);\n                }\n            }\n        }\n        return dp[0][0];\n    }\n\n    public static void main(String[] args) {\n        int[] weights = { 4, 7, 6, 8 };\n        int[] values = { 5, 6, 3, 19 };\n        int bag = 11;\n        System.out.println(maxValue(weights, values, bag));\n        System.out.println(maxValue2(weights, values, bag));\n    }\n}\n```\n\n### 纸牌游戏\n\n给定一个整型数组arr，代表数值不同的纸牌排成一条线。玩家A和玩家B依次拿走每张纸牌，规定玩家A先拿，玩家B后拿，但是每个玩家每次只能拿走最左或最右的纸牌，玩家A和玩家B都绝顶聪明。请返回最后获胜者的分数。\n\n![image-20211129181112430](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%9A%B4%E5%8A%9B%E9%80%92%E5%BD%92/image-20211129181112430.png)\n\n思路：将整个抽牌过程拆成先手和后手两种策略。\n\n- **己方先作为先手抽牌**，有两种情况，取这两种情况的**最大**点数情况\n  - 抽最左侧的牌，然后己方作为后手等待对方抽一张\n  - 抽最右侧的牌，然后己方作为后手等待对方抽一张\n- **己方作为后手时是不能抽牌的**，要等对方抽完一张**后己方再作为先手抽牌**，此时流程又回到了己方作为先手抽牌的情况。对方有两种抽法，己方要取两种先手情况的**最小值**。因为对方肯定会抽掉某张牌，**使得己方再作为先手抽剩下的牌时得分最少**，所以是取最小值\n\n代码中将不断递归地在先手方法里调用后手方法，在后手方法里递归地调用先手方法，直到就剩一张牌，此时：\n\n- 己方若为先手，则抽到这张牌，返回该值，递归栈开始返回\n- 己方若为后手，则不能抽到这张牌，返回0，递归栈开始返回\n\n需要注意的是，己方作为后手时是不能抽牌的，要直接返回去掉两侧牌后的两种先手情况的最小值。\n\n代码：\n\n```java\npublic class CardsInLine {\n    public static int maxScore01(int[] nums) {\n        if (nums == null || nums.length == 0) {\n            return 0;\n        }\n        // 我们不知道最大得分是先手赢还是后手赢，所以都要尝试，取最大值\n        return Math.max(first(nums, 0, nums.length - 1), second(nums, 0, nums.length - 1));\n    }\n\n    // 先手方法：己方先抽时能抽到的点数，肯定是任自己选择的\n    // 要么抽取第i张牌（最左侧），要么抽取第j张牌（最右侧），那么策略就是取这两种方式里总点数最大的\n    // 当前剩余牌的区间 [i, j]\n    public static int first(int[] nums, int i, int j) {\n        if (i == j) {\n            // 只剩一张牌了，先手只能抽这张牌\n            return nums[i];\n        }\n\n        // 1. 抽取第i张牌（最左侧）：nums[i] + second(nums, i + 1, j)\n        // 2. 要么抽取第j张牌（最右侧）：nums[j] + second(nums, i, j - 1)\n        // 因为是己方先手，所以肯定抽到两个策略里的最大值\n        return Math.max(nums[i] + second(nums, i + 1, j), nums[j] + second(nums, i, j - 1));\n    }\n\n    // 后手方法：己方在对方抽取一张牌后再抽时能得到的点数，自己是不能选择的\n    // 因为后手的优先权是在对方手里的，对方肯定会抽令自己优势最大的，因此己方的后手方法返回的是两种策略里的最小值\n    public static int second(int[] nums, int i, int j) {\n        // 己方后手时如果发现牌就剩一张了，那肯定被对方抽走了，自己后手留下的点数就是0\n        if (i == j) {\n            return 0;\n        }\n\n        // 1. 抽取第i张牌（最左侧）：nums[i] + second(nums, i + 1, j)\n        // 2. 要么抽取第j张牌（最右侧）：nums[j] + second(nums, i, j - 1)\n        // 之所以是min的原因是，最大的总点数的情况是被对方抽走的，自己只能剩下两种策略里的最小值\n        // 因为是己方后手，所以肯定抽到两个策略里的最小值\n        // 注意！！！这里不能加nums[i]，因为自己后手是不能抽牌的，是对方抽一张，然后自己作为先手再抽（即执行first()）\n        return Math.min(first(nums, i + 1, j), first(nums, i, j - 1));\n    }\n\n    public static int win2(int[] arr) {\n        if (arr == null || arr.length == 0) {\n            return 0;\n        }\n        int[][] f = new int[arr.length][arr.length];\n        int[][] s = new int[arr.length][arr.length];\n        for (int j = 0; j < arr.length; j++) {\n            f[j][j] = arr[j];\n            for (int i = j - 1; i >= 0; i--) {\n                f[i][j] = Math.max(arr[i] + s[i + 1][j], arr[j] + s[i][j - 1]);\n                s[i][j] = Math.min(f[i + 1][j], f[i][j - 1]);\n            }\n        }\n        return Math.max(f[0][arr.length - 1], s[0][arr.length - 1]);\n    }\n\n    public static void main(String[] args) {\n        int[] arr = { 1, 9, 1 };\n        System.out.println(maxScore01(arr));\n        System.out.println(win2(arr));\n    }\n}\n```\n\n### 青草游戏\n\n牛牛和羊羊都很喜欢青草，今天他们决定玩青草游戏。最初有一个装有n份青草的箱子，牛牛和羊羊依次进行，牛牛先开始。在每个回合中，每个玩家必须吃一些箱子中的青草，所吃的青草份数必须是4的x次幂，比如1，4，16，64等等。不能在箱子中吃到有效份数青草的玩家落败。假定牛牛和羊羊都是按照最佳方法进行游戏，请输出胜利者的名字。\n\n思路：\n\n- 先枚举 n <= 4 时的胜负情况。\n- 然后先手第一次选择吃 1 份，判断此时剩余的草让对方成为先手开始吃胜负属于谁；\n- 如果自己胜利则直接返回，否则先手第一次选择吃 4 份，继续判断此时剩余的草让对方成为先手开始吃胜负属于谁；\n- 如果仍然是对方胜利，则先手第一次选择吃 16 份，继续判断此时剩余的草让对方成为先手开始吃胜负属于谁；\n- 重复以上过程，如果先手第一次无论吃多少份，赢得都是后手，代表先手不可能获胜，答案就是后手。如果中途有一次能让先手获胜，则答案就是先手。\n- **母过程的先手和子过程里的后手是同一个人**，如果子过程的后手赢了，就代表母过程的先手赢了\n\n代码：\n\n``` java\npublic class EatGlass {\n\n    public static String winner01(int n) {\n        if (n >= 0 && n <= 4) {\n            // 0  1  2  3  4\n            // 后 先 后 先 先\n            return (n == 0 || n == 2) ? \"后手\" : \"先手\";\n        }\n\n        /*\n         * n >= 5 时, 先手决定吃的草的数量\n         * 从 1 开始尝试, 先手吃 1 份草的情况下, 递归后续情况判断是谁赢\n         * 如果先吃 1 份草先手无法赢, 则开始翻倍变为吃 4 份, 再递归后续情况判断是谁赢\n         * 如果还不能赢, 则继续乘以 4. 重复该过程知道 base > n,\n         * 如果这个过程中先手始终无法赢, 则答案就是后手赢\n         */\n        int base = 1;\n        while (base <= n) {\n            // 先手吃掉 base 份后, 还剩下 n - base 份, 此时递归判断在这种情况下是先手赢还是后手赢\n            // 母过程的先手和子过程里的后手是同一个人, 如果子过程的后手赢了, 就代表母过程的先手赢了\n            if (\"后手\".equals(winner01(n - base))) {\n                return \"先手\";\n            }\n            // 防止 base * 4 后溢出整数范围, 从而造成死循环, 因此提前跳出\n            if (base > n / 4) {\n                break;\n            }\n            base *= 4;\n        }\n        return \"后手\";\n    }\n\n    // 打表:\n    public static String winner02(int n) {\n        if (n % 5 == 0 || n % 5 == 2) {\n            return \"先手\";\n        } else {\n            return \"后手\";\n        }\n    }\n\n    public static void main(String[] args) {\n        // 遍历找规律\n        for (int i = 0; i <= 50; i++) {\n            System.out.println(i + \" \" + winner01(i));\n        }\n    }\n}\n```\n\n\n\n\n\n### N 皇后\n\nn 皇后问题 研究的是如何将 n 个皇后放置在 n×n 的棋盘上，并且使皇后彼此之间不能相互攻击。\n\n给你一个整数 n ，返回所有不同的 n 皇后问题 的解决方案。每一种解法包含一个不同的 n 皇后问题 的棋子放置方案，该方案中 'Q' 和 '.' 分别代表了皇后和空位。\n\n代码：\n\n```java\nclass Solution {\n    public List<List<String>> solveNQueens(int n) {\n\n        // 记录每一行的皇后存储在哪一列\n        // 例如 record[2] = 3 代表第3行的皇后在第4列\n        int[] record = new int[n];\n        process(0, record, n);\n        return res;\n    }\n\n    List<List<String>> res = new ArrayList<>();\n\n    public void process(int i, int[] record, int n) {\n        if (i == n) {\n            // 在调用到底时才生成答案，这样就能保证答案一定正确\n            res.add(generateBoard(n, record));\n            return;\n        }\n\n        // j代表在第i行尝试的列数，需要尝试所有列的情况\n        for (int j = 0; j < n; j++) {\n            // 先检查第i行第j列能否放皇后（要根据前i-1行的皇后摆放情况来验证）\n            if (isValid(record, i, j)) {\n                // 如果第i行第j列可以摆放，则更新record数组\n                record[i] = j;\n                // 递归调用第下一行\n                process(i+1, record, n);\n            }\n        }\n    }\n\n    public boolean isValid(int[] record, int i, int j) {\n        // 遍历前i-1行的record\n        for (int k = 0; k < i; k++) {\n            if (record[k] == j || Math.abs(record[k] - j) == Math.abs(i - k)) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    public List<String> generateBoard(int n, int[] record) {\n        List<String> list = new ArrayList<>();\n\n        for (int row = 0; row < n; row++) {\n            // record[row]存储着第k行的皇后位置，据此生成String\n            // StringBuilder sb = new StringBuilder();\n            // for (int col = 0; col < n; col++) {\n            //     if (col == record[row]) {\n            //         sb.append('Q');\n            //     } else {\n            //         sb.append('.');\n            //     }\n            // }\n            // list.add(sb.toString());\n\n            // 改进版：\n            char[] board = new char[n];\n            Arrays.fill(board, '.'); // 快速填充\n            board[record[row]] = 'Q';\n            list.add(new String(board));\n        }\n        return list;\n    }\n}\n```\n\n\n\n### 机器人的运动范围\n\n[剑指 Offer 13. 机器人的运动范围](https://leetcode-cn.com/problems/ji-qi-ren-de-yun-dong-fan-wei-lcof/)：地上有一个m行n列的方格，从坐标 [0,0] 到坐标 [m-1,n-1] 。一个机器人从坐标 [0, 0] 的格子开始移动，它每次可以向左、右、上、下移动一格（不能移动到方格外），也不能进入行坐标和列坐标的数位之和大于k的格子。例如，当k为18时，机器人能够进入方格 [35, 37] ，因为3+5+3+7=18。但它不能进入方格 [35, 38]，因为3+5+3+8=19。请问该机器人能够到达多少个格子？\n\n代码：\n\n``` java\npublic int movingCount(int m, int n, int k) {\n    int[][] record = new int[m][n];\n    movingCountHelper(0, 0, m, n, k, record);\n    return count;\n}\npublic int count = 0;\n\npublic void movingCountHelper(int i, int j, int m, int n, int k, int[][] record) {\n    // 如果超出了边界，返回\n    if (i < 0 || i >= m || j < 0 || j >= n) {\n        return;\n    }\n    // 如果当前坐标和超过了k，也直接返回\n    if (!isValid(i, j, k)) {\n        return;\n    }\n    // 当前格子已经访问过，则不在继续访问\n    if (record[i][j] == 1) {\n        return;\n    }\n\n    // 设置当前为访问过\n    record[i][j] = 1;\n    count++;\n    movingCountHelper(i - 1, j, m, n, k, record);\n    movingCountHelper(i, j - 1, m, n, k, record);\n    movingCountHelper(i + 1, j, m, n, k, record);\n    movingCountHelper(i, j + 1, m, n, k, record);\n}\n\n// return true：符合条件\npublic boolean isValid(int i, int j, int k) {\n    int sum = 0;\n    // 计算i与j的位数和\n    while (i != 0) {\n        sum += i % 10;\n        i /= 10;\n    }\n    while (j != 0) {\n        sum += j % 10;\n        j /= 10;\n    }\n    return sum <= k;\n}\n```\n\n\n\n\n\n### 构建乘积数组\n\n[剑指 Offer 66. 构建乘积数组](https://leetcode-cn.com/problems/gou-jian-cheng-ji-shu-zu-lcof/)：给定一个数组 A[0,1,…,n-1]，请构建一个数组 B[0,1,…,n-1]，其中 B[i] 的值是数组 A 中除了下标 i 以外的元素的积, 即 `B[i]=A[0]×A[1]×…×A[i-1]×A[i+1]×…×A[n-1]`。不能使用除法。\n\n**示例:**\n\n```\n输入: [1,2,3,4,5]\n输出: [120,60,40,30,24]\n```\n\n根据表格的主对角线（全为 11 ），可将表格分为 **上三角** 和 **下三角** 两部分。分别迭代计算下三角和上三角两部分的乘积，即可 **不使用除法** 就获得结果。\n\n![Picture1.png](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/1624619180-vpyyqh-Picture1.png)\n\n算法流程：\n\n1. 初始化：数组 B，其中 B[0] = 1；辅助变量 tmp = 1；\n2. 计算 B[i] 的 **下三角** 各元素的乘积，直接乘入 B[i]；\n3. 计算 B[i] 的 **上三角** 各元素的乘积，记为 tmp，并乘入 B[i]；\n\n代码：\n\n``` java\nclass Solution {\n    public int[] constructArr(int[] a) {\n        if (a == null || a.length == 0) {\n            return new int[0];\n        }\n        // 1. 正向遍历数组，计算出b[]数组，b[i]代表当前位置i左侧的积（[0, i-1]相乘），\n        // 2. 再反向遍历数组，当前位置左侧的积为b[i]，再乘以右侧的积（该值在反向遍历的过程中不断更新为[i+1, N]上的乘积） \n        int[] b = new int[a.length];\n        // 最后一个元素的左侧积为1\n        b[0] = 1;\n        for (int i = 1; i < a.length; i++) {\n            // a[i - 1]：当前位置左侧的值\n            // b[i - 1]：当前位置左侧元素的左侧的积\n            // 二者相乘即为当前位置左侧的积\n            b[i] = b[i - 1] * a[i - 1];\n        }\n\n        int[] res = new int[a.length];\n        // 最后一个元素的右侧积为1\n        int tmp = 1;\n        for (int i = a.length - 1; i >= 0; i--) {\n            // 当前值 = 左侧的积 * 右侧的积\n            res[i] = b[i] * tmp;\n            // 更新右侧的积\n            tmp = tmp * a[i];\n        }\n        return res;\n    }\n}\n```\n\n\n\n###  戳气球\n\n[312. 戳气球](https://leetcode-cn.com/problems/burst-balloons/)：有 `n` 个气球，编号为`0` 到 `n - 1`，每个气球上都标有一个数字，这些数字存在数组 `nums` 中。现在要求你戳破所有的气球。戳破第 `i` 个气球，你可以获得 `nums[i - 1] * nums[i] * nums[i + 1]` 枚硬币。这里的 `i - 1` 和 `i + 1` 代表和 `i` 相邻的两个气球的序号。如果 `i - 1`或 `i + 1` 超出了数组的边界，那么就当它是一个数字为 `1` 的气球。求所能获得硬币的最大数量。\n\n示例 1：\n\n``` \n输入：nums = [3,1,5,8]\n输出：167\n解释：\nnums = [3,1,5,8] --> [3,5,8] --> [3,8] --> [8] --> []\ncoins =  3*1*5    +   3*5*8   +  1*3*8  + 1*8*1 = 167\n```\n\n思路：尝试的依据：当前位置**必须是最后一个戳**的情况下，整体获得的硬币数量。那么只需要先递归地计算左侧区域的硬币数（代表先戳破左边），再递归地计算右侧区域的硬币数（代表再戳破右边），最后只剩下当前一个气球，将其戳破，即可得到当前位置最后一个戳破整体可以得到的硬币数量。在戳左侧区域时，右边界就是当前位置；在戳右侧区域时，左边界就是当前位置。\n\n> 其中，需要先构造**辅助数组**，**在数组的左右边界额外补充两个1**，这样在某个数组中的气球最后戳的时候也能顺利通过 L - 1 和 R + 1 得到当前戳得到的硬币：`1 * nums[i] * 1`，否则还得考虑边界条件，非常麻烦。\n\n递归方法里需要将当前区间 [L, R] 内的位置一一尝试进行计算，会有大量重复计算，因此构建缓存表避免重复计算。\n\n代码：\n\n``` java\nclass Solution {\n    public int maxCoins(int[] nums) {\n        // 先构造辅助数组，在数组的左右边界加上1，这样在某个数组中的气球最后戳的时候也能顺利通过L-1和R+1得到当前戳得到的硬币：1 * nums[i] * 1，否则还得考虑边界条件，非常麻烦\n        int[] help = new int[nums.length + 2];\n        help[0] = 1;\n        help[nums.length + 1] = 1;\n        for (int i = 0; i < nums.length; i++) {\n            help[i + 1] = nums[i];\n        }\n\n        int[][] record = new int[help.length][help.length];\n        // 原数组的值在[1, nums.length+1]范围内\n        // 使用记忆化搜索算法：在该方法内遍历每一个位置，计算出当前位置最后戳的情况下得到的硬币数量，最后取最大值返回即可得到答案\n        // 尝试的依据：当前位置必须是最后一个戳的情况下，整体获得的硬币数量\n        return maxCoinsRecur(help, 1, nums.length, record);\n    }\n\n    // 计算当前区间 [L, R] 内，哪个位置的气球被最后戳爆可以得到的最大收益\n    public int maxCoinsRecur(int[] nums, int L, int R, int[][] record) {\n        // base case: 当只需要戳爆一个气球时，得到的硬币就等于该值乘以左侧和右侧的值\n        if (L >= R) {\n            return nums[L - 1] * nums[L] * nums[R + 1];\n        }\n        // \n        if (record[L][R] != 0) {\n            return record[L][R];\n        }\n        int res = 0;\n        int coins = 0;\n\n        // 先计算两个边界情况：i == L 与 i == R\n        // 这两个位置因为只有一侧需要计算，另一侧是不需要的，如果计算递归则会发生越界错误\n        // 1. i == L，只需要计算右侧\n        int coins1 = maxCoinsRecur(nums, L + 1, R, record) + nums[L - 1] * nums[L] * nums[R + 1];\n        // 2. i == R，只需要计算左侧\n        int coins2 = maxCoinsRecur(nums, L, R - 1, record) + nums[L - 1] * nums[R] * nums[R + 1];\n        res = Math.max(coins1, coins2);\n\n        for (int i = L + 1; i <= R - 1; i++) {\n            coins = maxCoinsRecur(nums, L, i - 1, record) + maxCoinsRecur(nums, i + 1, R, record) + nums[L - 1] * nums[i] * nums[R + 1];\n            res = Math.max(res, coins);\n        }\n        record[L][R] = res;\n        return res;\n    }\n}\n```\n\n\n\n\n\n\n\n## 斐波那契系列问题\n\n### 斐波那契数列\n\n[剑指 Offer 10- I. 斐波那契数列](https://leetcode-cn.com/problems/fei-bo-na-qi-shu-lie-lcof/)：写一个函数，输入 `n` ，求斐波那契（Fibonacci）数列的第 `n` 项（即 `F(N)`）。斐波那契数列的定义如下：\n\n```\nF(0) = 0,   F(1) = 1\nF(N) = F(N - 1) + F(N - 2), 其中 N > 1.\n```\n\n斐波那契数列由 0 和 1 开始，之后的斐波那契数就是由之前的两数相加而得出。\n\n#### 版本一：暴力递归\n\n直接暴力递归时间复杂度过高，因为重复计算了大量的值：\n\n``` java\n// version 1: 暴力递归, 时间复杂度较高\npublic static int f1(int n) {\n    if (n < 1) {\n        return 0;\n    }\n    if (n == 1 || n == 2) {\n        return 1;\n    }\n    return f1(n - 1) + f1(n - 2);\n}\n```\n\n#### 版本二：动态规划\n\n可以使用滚动数组版本的动态规划解决该问题，但是其时间复杂度为 O(N)：\n\n``` java\n// version 2: 动态规划\npublic static int f2(int n) {\n    if (n < 1) {\n        return 0;\n    }\n    if (n == 1 || n == 2) {\n        return 1;\n    }\n    int p = 0;\n    int q = 1;\n    int res = 0;\n    // 注意i可以取到n\n    for (int i = 2; i <= n; i++) {\n        // f(n) = f(n-1) + f(n-2)\n        res = p + q;\n        // f(n-2) = f(n-1)\n        p = q;\n        // f(n-1) = f(n)\n        q = res;\n    }\n    return res;\n}\n```\n\n#### 版本三：快速幂\n\n可以使用矩阵的快速幂方法，其时间复杂度为 O(logN)\n\n![image-20211214221246265](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211214221246265.png)\n\n``` java\n// version 3: 快速幂\npublic static int f3(int  n) {\n    if (n < 1) {\n        return 0;\n    }\n    if (n == 1 || n == 2) {\n        return 1;\n    }\n    int[][] base = new int[][]{{1, 1}, {1, 0}};\n    int[][] res = matrixPower(base, n - 2);\n    // f(n) = f(2) * res(0, 0) + f(1) * res(1, 0)\n    return 1 * res[0][0] + 1 * res[1][0];\n}\n\npublic static int[][] matrixPower(int[][] m, int p) {\n    int[][] res = new int[m.length][m[0].length];\n    // 矩阵对角线初始化为1\n    for (int i = 0; i < m.length; i++) {\n        res[i][i] = 1;\n    }\n    // 矩阵的一次方\n    int[][] tmp = m;\n    for (; p > 0; p >>= 1) {\n        if ((p & 1) == 1) {\n            res = matrixMulti(res, tmp);\n        }\n        tmp = matrixMulti(tmp, tmp);\n    }\n    return res;\n}\n\nprivate static int[][] matrixMulti(int[][] a, int[][] b) {\n    // a * b 得到的维度是 a 的行 * b 的列\n    int[][] res = new int[a.length][b[0].length];\n    // 计算矩阵乘法结果\n    for (int i = 0; i < a.length; i++) {\n        for (int j = 0; j < b[0].length; j++) {\n            // 计算对应行和列的元素累乘和\n            for (int k = 0; k < a[0].length; k++) {\n                res[i][j] += a[i][k] * b[k][j];\n            }\n        }\n    }\n    return res;\n}\n```\n\n#### 总结\n\n快速幂的套路同样适合于**严格递推关系**的动态规划问题，比如本题的 `f(n) = f(n - 1) + f(n - 2)`，是一个严格递推关系，可以通过该关系**枚举前几项构成方程组**从而推算出 M 矩阵的具体值以及矩阵公式。西面再介绍几个可以使用该套路的题目。\n\n递推过程：先枚举出前几项，构造方程组求解 a b c d 的值，即可求得 M：\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211215161354377.png\" alt=\"image-20211215161354377\" style=\"zoom:50%;\" />\n\n### 青蛙跳台阶\n\n[剑指 Offer 10- II. 青蛙跳台阶问题](https://leetcode-cn.com/problems/qing-wa-tiao-tai-jie-wen-ti-lcof/)：一只青蛙一次可以跳上1级台阶，也可以跳上2级台阶。求该青蛙跳上一个 `n` 级的台阶总共有多少种跳法。\n\n该问题与斐波那契数列非常相似，只是边界值不同而已：\n\n- 青蛙跳台阶问题： f(0)=1, f(1)=1, f(2)=2\n- 斐波那契数列问题： f(0)=0, f(1)=1, f(2)=1\n\n该问题同样可以使用上面介绍的套路进行快速幂的计算，并且 M 矩阵也是相同的，唯一区别在于边界条件的值不相等。\n\n### 母牛问题\n\n一只母牛在出生三年后，每一年都可以开始生小牛，生出来的小牛在三年后也可以生小牛。假设母牛出生后永远不会死亡，则 n 年后总共有多少头牛？\n\n该问题同样符合严格递推公式：`f(n) = f(n - 1) + f(n - 3)`。\n\n> 其中 f(n - 1) 代表前一年存活的牛肯定也会活到第 n 年；f(n - 3) 代表三年前存活的母牛在第 n 年肯定都可以生育新的小牛，所以也要加上\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211215162519905.png\" alt=\"image-20211215162519905\" style=\"zoom:50%;\" />\n\n该问题若想采用快速幂进行求解时，可以构造成：`f(n) = 1 * f(n - 1) + 0 * f(n - 2) + 1 * f(n - 3)`。此时要构造的就是一个 3*3 的矩阵，有三次项：\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211215162724604.png\" alt=\"image-20211215162724604\" style=\"zoom:50%;\" />\n\n如果题目设定母牛会在 10 年后死亡，则该递推公式将改为：`f(n) = f(n - 1) + f(n - 3) - f(n - 10)`\n\n### 把数字翻译成字符串\n\n[剑指 Offer 46. 把数字翻译成字符串](https://leetcode-cn.com/problems/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-lcof/)：规定1和A对应、2和B对应、3和C对应...那么一个数字字符串比如\"111\"，就可以转化为\"AAA\"、\"KA\"和\"AK\"。给定一个只有数字字符组成的字符串str，返回有多少种转化结果。\n\n思路：归纳出翻译的规则，字符串的第 i 位置：\n\n- 可以单独作为一位来翻译\n- 如果第 i - 1 位和第 i 位组成的数字在 10 到 25 之间，可以把这两位连起来翻译\n\n#### 记忆化递归尝试版本\n\n```java\npublic static List<String> convert(String str) {\n    // 0. 如果到底，则开始将结果转换成String并加入到list中\n    // 1. 当前数字为0，说明往后不能转换成字母，则递归栈开始返回，不会将当前分支转换成字符串\n    // 2. 当前数字大于等于3，则只能将当前数字转换成字母，然后继续调用子问题\n    // 3. 当前数字为1，有两种情况\n    //   3.1 将当前数字转换为A，然后继续调用子问题\n    //   3.2 不将当前数字进行转换，而是将其和下一位数字一起转换成一个英文字母（前提是下一位必须存在），然后继续调用子问题\n    // 4. 当前数字为2，有两种情况\n    //      4.1 将当前数字转换为B，然后继续调用子问题\n    //      4.2 不将当前数字进行转换，而是将其和下一位数字一起转换成一个英文字母（前提是下一位必须存在且不大于6），然后继续调用子问题\n    char[] arr = str.toCharArray();\n    char[] tmp = new char[arr.length];\n    List<String> res = new ArrayList<>();\n    process(0, arr, tmp, res);\n    return res;\n}\n\n\npublic static void process(int i, char[] arr, char[] tmp, List<String> res) {\n    if (i == arr.length) {\n        // base case\n        // 0. 如果到底，则开始将结果转换成String并加入到list中\n        // 可以再加个处理，将为0的字符去掉不要\n        res.add(new String(tmp));\n        return;\n    }\n\n    // 1. 当前数字为0，说明往后不能转换成字母，则递归栈开始返回，不会将当前分支转换成字符串\n    if (arr[i] == '0') {\n        return;\n    }\n    // 2. 当前数字大于等于3，则只能将当前数字转换成字母，然后继续调用子问题\n    if (arr[i] >= '3') {\n        tmp[i] = (char)((int)'A' + (arr[i] - '1'));\n        process(i + 1, arr, tmp, res);\n        // i+1 层之后的都清空\n        clearCache(tmp, i+1);\n        return;\n    }\n    // 3. 当前数字为1，有两种情况\n    if (arr[i] == '1') {\n        // 3.1 将当前数字转换为A，然后继续调用子问题\n        tmp[i] = 'A';\n        process(i + 1, arr, tmp, res);\n        // i+1 层之后的都清空，防止tmp后面的内容被其他分支修改，从而导致当前分支内容受影响\n        clearCache(tmp, i+1);\n\n        // 3.2 不将当前数字进行转换，而是将其和下一位数字一起转换成一个英文字母（前提是下一位必须存在）\n        if (i + 1 < arr.length) {\n            tmp[i] = (char)((int)'A' + (10 + arr[i + 1] - '1'));\n            // 注意此时是从i+2调用子问题，因为i+1此时已经考虑进去了\n            process(i + 2, arr, tmp, res);\n            // i+1 层之后的都清空，防止tmp后面的内容被其他分支修改，从而导致当前分支内容受影响\n            clearCache(tmp, i+1);\n        }\n        return;\n    }\n    // 4. 当前数字为2，有两种情况\n    if (arr[i] == '2') {\n        // 4.1 将当前数字转换为B，然后继续调用子问题\n        tmp[i] = 'B';\n        process(i + 1, arr, tmp, res);\n        // i+1 层之后的都清空\n        clearCache(tmp, i+1);\n\n        // 4.2 不将当前数字进行转换，而是将其和下一位数字一起转换成一个英文字母（前提是下一位必须存在且不大于6），然后继续调用子问题\n        if (i + 1 < arr.length && arr[i + 1] <= '6') {\n            tmp[i] = (char) ((int) 'A' + (20 + arr[i + 1] - '1'));\n            // 注意此时是从i+2调用子问题，因为i+1此时已经考虑进去了\n            process(i + 2, arr, tmp, res);\n            // i+1 层之后的都清空\n            clearCache(tmp, i+1);\n        }\n    }\n}\n\npublic static void clearCache(char[] tmp, int count) {\n    for (int i = count; i < tmp.length; i++) {\n        tmp[i] = '0';\n    }\n}\n\npublic static void main(String[] args) {\n    System.out.println(convert(\"123\"));\n}\n```\n\n#### 简化版问题：统计出可行的方案\n\n当问题只需要统计出可行的方案时（不要求实际转换），条件 3 和 4 可以进行合并：如果当前位的数字和下一位的数字组成的数字处于 10 和 27 之间，则统一进行新一轮的递归。\n\n代码：\n\n``` java\npublic static int process(char[] str, int index) {\n    if (index == str.length) {\n        return 1;\n    }\n    if (str[index] == '0') {\n        return 0;\n    }\n    int res = process(str, index + 1);\n    if (index == str.length - 1) {\n        return res;\n    }\n    // 如果下一位还有并且在10到26之间，则可以将二者转换成一个字母\n    if (((str[index] - '0') * 10 + str[index + 1] - '0') < 27) {\n        res += process(str, index + 2);\n    }\n    return res;\n}\n```\n\n\n\n#### 动态规划版本\n\n> 题解：https://leetcode-cn.com/problems/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-lcof/solution/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-by-leetcode-sol/\n\n我们可以用 f(i) 表示以第 i 位结尾的前缀串翻译的方案数，考虑第 i 位单独翻译和与前一位连接起来再翻译对 f(i) 的贡献。\n\n- 单独翻译对 f(i) 的贡献为 f(i−1)；\n- 如果第 i - 1 位存在，并且第 i−1 位和第 i 位形成的数字 x 满足 10 ≤ x ≤ 25，那么就可以把第 i - 1 位和第 i 位连起来一起翻译，对 (i) 的贡献为 f(i−2)，否则为 0。\n\n我们可以列出这样的动态规划转移方程：*f*(*i*)=*f*(*i*−1)+*f*(*i*−2)[*i*−1≥0,10≤*x*≤25]。边界条件是 f(-1) = 0，f(0) = 1。方程中 [c] 的意思是 c 为真的时候 [c] = 1，否则 [c] = 0。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211210221236011.png\" alt=\"image-20211210221236011\" style=\"zoom:50%;\" />\n\n> 本质上是青蛙跳台阶问题\n\n代码：\n\n``` java\npublic int translateNum(int num) {\n    String src = String.valueOf(num);\n    int p = 0, q = 0, r = 1;\n    for (int i = 0; i < src.length(); ++i) {\n        p = q; \n        q = r; \n        r = 0;\n        r += q;\n        if (i == 0) {\n            continue;\n        }\n        // 获取前一个字符和当前字符组成的数字\n        String pre = src.substring(i - 1, i + 1);\n        if (pre.compareTo(\"25\") <= 0 && pre.compareTo(\"10\") >= 0) {\n            r += p;\n        }\n    }\n    return r;\n}\n```\n\n### 达标的字符串\n\n给定一个数 N，想象只由 0 和 1 两种字符组成的所有长度为 N 的字符串。如果某个字符串任何 0 字符的左边都有 1 紧挨着，则认为这个字符串达标。返回有多少达标的字符串。\n\n例如：\n\n- 达标的字符串：11101011101110\n- 不达标的字符串：001001000（只要有某个 0 的左边不是 1 就不达标）\n\n思路：该问题同样是一道动态规划问题。可以进行以下尝试：\n\n- 如果当前位置设置为 1，则其没有额外限制，截至目前为止的种类数为 f(n) = f(n - 1)\n- 如果当前位置设置为 0，则其左边必须为 1，截至目前为止的种类数为 f(n) = f(n - 2)。因为 n-1 位置必须为 0，需要考虑前 n-2 的种类数\n\n因此当前位置的总种类数为：`f(n) = f(n - 1) + f(n - 2)`。\n\n> 该问题与“把数字翻译成字符串”问题类似，本质上都是青蛙跳台阶问题\n\n### 铺瓷砖\n\n假设有一个 2*N 面积的地面，我们有足够多数量的瓷砖（尺寸为 1 * 2 或 2 * 1），则完全铺满该地面有多少种铺法。\n\n思路：该问题的本质同样是**青蛙跳台阶**。当前位置的尝试方法：\n\n- 如果上一个瓷砖是 1 * 2 尺寸，则当前位置也必须是 1 * 2 尺寸。此时的铺法为 f(n - 2)。因为1 * 2 的尺寸占用了两个单元，所以要减二\n- 如果上一个瓷砖是 2 * 1 尺寸，则当前位置也必须是 2 * 1 尺寸。此时的铺法为 f(n - 1)。因为2 * 1 的尺寸占用了一个单元，所以要减一\n\n所以总的铺法就是` f(n) = f(n - 1) + f(n - 2)`。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211215164225152.png\" alt=\"image-20211215164225152\" style=\"zoom:50%;\" />\n\n\n\n\n\n## 股票系列问题\n\n### 买卖股票的最佳时机\n\n假设把某股票的价格按照时间先后顺序存储在数组中，请问买卖该股票一次可能获得的最大利润是多少？\n\n思想：遍历每个元素，规定**必须在当前元素卖出**的情况下，**在其前面哪个地方买**，收益最大\n\n代码：\n\n``` java\npublic int maxProfit(int[] prices) {\n    if (prices == null || prices.length < 1) {\n        return 0;\n    }\n    int ans = 0;\n    // 最小值初始化为第一个值\n    int min = prices[0];\n\n    // 思想是：遍历每个元素，规定当前元素必须卖出的情况下，在其前面哪个地方买，收益最大\n    for (int i = 1; i < prices.length; i++) {\n        // 先更新当前区间内的最小值\n        min = Math.min(prices[i], min);\n        // 然后更新当前区间内卖出的最大收益\n        // 1. 如果当前值小于当前区间内的最小值，则说明当前区间卖出得到的是负收益，那么其再与ans取最大值，就会得到前面位置的最大值，意味着当前得不到更大的值，不更新ans\n        // 2. 如果当前值大于当前区间内的最大值，则如果当前点必须卖出的话，得到的最大收益就是当前值-min\n        ans = Math.max(prices[i] - min, ans);\n    }\n    return ans;\n}\n```\n\n\n\n### 买卖股票的最佳时机 II\n\n给定一个数组 prices ，其中 prices[i] 是一支给定股票第 i 天的价格。\n\n设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n\n思路：任意次数的购买，最佳策略就是记录**所有上升的区间**的收益。将整体进行**离散化**考虑，**对每个上升的子区间都进行累加收益**，代表只要发现有收益，就进行一笔买卖，累加收益。\n\n代码：\n\n``` java\npublic int maxProfit(int[] prices) {\n    // 任意次数的购买，最佳策略就是记录所有上升的区间的收益\n    // 在代码中的较好实现方式为：\n    // 从index == 1 位置开始遍历数组：\n    //   1. 如果当前价格大于前一个价格，说明前一个位置买，当前位置卖可以得到一笔收益，因此更新总收益。表示在前一个位置买，当前位置全卖\n    //   2. 如果当前价格小于等于前一个价格，说明前一个买，当前位置卖无法得到一笔收益，因此不更新总收益，表示不买不卖\n    // 整体的思想是，判断当前位置是否比前一个位置价格高\n    // 如果高，就前一个位置买，当前位置全卖，完成一笔交易，更新收益\n    // 如果不高，就不做任何交易，不更新收益\n    // 整个过程不需要额外一个min记录最小值，因为每笔交易都是立即成交，立即更新的，之前买过的位置不会再买一次\n\n    int ans = 0;\n    // 注意要从1开始\n    for (int i = 1; i < prices.length; i++) {\n        //  不需要更新当前区间的最小值，交易和更新是实时的\n        if (prices[i] > prices[i - 1]) {\n            ans += prices[i] - prices[i - 1];\n        }\n    }    \n    return ans;  \n}\n```\n\n### 买卖股票的最佳时机 III\n\n给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。\n\n设计一个算法来计算你所能获取的最大利润。你最多可以完成**两笔**交易。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。\n\n整体思想：将在当前区间内买两次拆成两个步骤：\n\n- 先在当前区间内**买卖一次**，并**必须在当前区间内买一笔**，并且令二者的总收益最大，这样后面再在当前点卖就肯定能获得最大收益；\n- 第二次遍历所有位置，在每个当前位置卖出，即可得到在当前区间内**买卖两笔**的总收益\n\n那么遍历完所有位置，肯定能得到全局最大的收益值。\n\n代码：\n\n``` java\npublic int maxProfit(int[] prices) {\n    if (prices == null || prices.length < 2) {\n        return 0;\n    }\n    // 1. doneOnceMax: [0, i] 区间内只卖卖一次，获得的最大收益。注意这里卖出的时机不要求是当前位置，而是这个区间任意位置均可以\n    int[] doneOnceMax = new int[prices.length];\n    // 0 位置的收益肯定是0.\n    doneOnceMax[0] = 0;\n    int min = prices[0];\n\n    for (int i = 1; i < prices.length; i++) {\n        // 先保存当前区间的最小值\n        min = Math.min(min, prices[i]);\n        // 注意这里要和前一个位置比较，如果更大就保存，否则就保存前一个的值\n        doneOnceMax[i] = Math.max(prices[i] - min, doneOnceMax[i - 1]); \n    }\n\n    // 整体思想就是，将买两次拆成两个步骤：\n    // 1. 买卖一次，并必须在当前区间内买一笔，让总收益最大，这样后面再卖就肯定能获得最大收益\n    // 2. 再在当前位置卖出，\n    // 那么遍历所有位置，肯定能得到最大的收益值\n\n    // 2. 然后计算 doneOnceMinusOneBuyMax：代表[0, i]区间上任意位置买卖一笔，然后再买一笔后的最大收益\n    // 要达到最大，就要先完成一笔比较好的收益，然后再买一个价格便宜的位置\n    int[] doneOnceMinusOneBuyMax = new int[prices.length];\n    // doneOnceMinusOneBuyMax[0]：买卖一笔还得再买一笔，那收益肯定是 -prices[0]\n    doneOnceMinusOneBuyMax[0] = -1 * prices[0];\n    // 从 1 位置开始遍历\n    for (int i = 1; i < prices.length; i++) {\n        // 两种情况取最大：\n        // 1. 不在当前点买入一笔，那么当前位置区间的值肯定等于[0, i-1]区间内的值\n        // 2. 在当前点卖买入一笔，那么当前区间内的值等于该区间内只卖卖一次的最大收益（doneOnceMax[i]）- 当前价格（prices[i]）\n        doneOnceMinusOneBuyMax[i] = Math.max(doneOnceMinusOneBuyMax[i - 1], doneOnceMax[i] - prices[i]);\n    }\n\n    // 3. 在遍历每个元素，doneOnceMinusOneBuyMax + 当前price，即可得到[0, i]区间内的最大收益\n    // 思想：在前面买卖了一笔，又买了一笔便宜的，这样再在当前位置卖（必须在当前位置卖，思路同股票I中的卖的规定），那么遍历所有的情况取最大值，就是答案了\n    int ans = 0;\n    for (int i = 0; i < prices.length; i++) {\n        ans = Math.max(doneOnceMinusOneBuyMax[i] + prices[i], ans);\n    }\n\n    return ans;\n}\n```\n\n\n\n## 左右括号系列问题\n\n### 合法括号匹配序列的深度\n\n一个合法的括号匹配序列有以下定义：\n\n- 空串 \"\" 是一个合法的括号匹配序列\n- 如果 \"X\" 和 \"Y\" 都是合法的括号匹配序列，\"XY\" 也是一个合法的括号匹配序列\n- 如果 \"X\" 是一个合法的括号匹配序列，那么 \"(X)\" 也是一个合法的括号匹配序列\n- 每个合法的括号序列都可以由以上规则生成。\n\n例如：\"\"，\"()\"，\"()()\"，\"((()))\" 都是合法的括号序列。对于一个合法的括号序列我们又有以下定义它的深度:\n\n- 空串 \"\" 的深度是0\n- 如果字符串 \"X\" 的深度是 x，字符串 \"Y\" 的深度是y，那么字符串 \"XY\" 的深度为 max(x,y) \n- 如果 \"X\" 的深度是 x，那么字符串 \"(X)\" 的深度是 x+1\n\n例如：\"()()()\" 的深度是 1，\"((()))\" 的深度是 3。现在给你一个合法的括号序列，需要你计算出其深度。\n\n思路：定义变量 count，遍历字符串：\n\n- 当遇到左括号时，count++，代表当前子序列的深度加一；\n- 当 count 等于 0 时，说明已经经过了某一个合法的括号子序列，记录此时的 count 到结果中（取最大值）\n- 遍历完整个字符串后，即可得到最大的深度\n\n代码：\n\n``` java\n// 未来补充\n```\n\n\n\n### 括号序列合法化\n\n给定义一个可能不合法的括号序列，求至少需要添加多少个括号才能令该括号序列变得合法。\n\n思路：定义变量 count 记录左右括号出现的情况，定义 ans 记录需要添加的括号数量，遍历字符串：\n\n- 如果遇到左括号，则 count++\n- 如果遇到右括号，则先判断 count 此时是否是 0\n  - 如果是，则代表当前的右括号在左侧没有匹配的左括号，需要添加一个左括号，ans++\n  - 如果不是，则还不需要添加左括号，count--\n\n遍历完毕后，count 的数量就是没有匹配的左括号的数量，ans 的数量就是没有匹配的右括号的数量，二者相加即是答案。\n\n代码：\n\n``` java\npublic class NeedParentheses {\n    public static int needParentheses(String s) {\n        // 遍历过程中记录当前左右括号出现情况\n        int count = 0;\n        int ans = 0;\n        for (int i = 0; i < s.length(); i++) {\n            // 如果是 (, 则count++\n            if (s.charAt(i) == '(') {\n                count++;\n            } else if (s.charAt(i) == ')') {\n                // 如果是 ), 则先判断count此时是否是0,\n                if (count == 0) {\n                    // 如果是, 代表当前的 ) 在左侧没有匹配的 (, ans++\n                    ans++;\n                    // 不需要再额外count--了\n                } else {\n                    count--;\n                }\n            }\n        }\n        // 出循环时, count 的数量就是没有匹配的 ( 的数量, ans 的数量就是没有匹配的 ) 的数量\n        return ans + count;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(needParentheses(\"Sadadsd)dsd(((dsds))\"));\n    }\n}\n```\n\n\n\n### 最长有效括号\n\n[32. 最长有效括号](https://leetcode-cn.com/problems/longest-valid-parentheses/)：给你一个只包含 `'('` 和 `')'` 的字符串，找出最长有效（格式正确且连续）括号子串的长度。\n\n#### 方法一：双指针 + 双向遍历\n\n> 本质上是一种贪心策略\n\n在此方法中，我们利用两个计数器 left 和 right。首先，我们从左到右遍历字符串，对于遇到的每个 左括号，我们增加 left 计数器，对于遇到的每个右括号，我们增加 right 计数器。每当 left 计数器与 right 计数器相等时，我们计算当前有效字符串的长度，并且记录目前为止找到的最长子字符串。**当 right 计数器比 left 计数器大时，我们将 left 和 right 计数器同时变回 0**。\n\n这样的做法贪心地考虑了以当前字符下标结尾的有效括号长度，每次当右括号数量多于左括号数量的时候之前的字符我们都**扔掉不再考虑**，**重新从下一个字符开始计算**，但这样会漏掉一种情况，就是遍历的时候左括号的数量始终大于右括号的数量，即 `(()` ，这种时候最长有效括号是求不出来的。\n\n解决的方法也很简单，我们只需要从右往左遍历用类似的方法计算即可，只是这个时候判断条件反了过来：\n\n- 当 left 计数器比 right 计数器大时，我们将 left 和 right 计数器同时变回 0\n- 当 left 计数器与 right 计数器相等时，我们计算当前有效字符串的长度，并且记录目前为止找到的最长子字符串\n\n思路总结：\n\n- 一旦相等，就找到了一个局部的有效子串，更新长度，然后遍历（注意此时可不能令 left 和 right 归零，因为其后面可能还连着更长的有效子串）\n- 如果一直是右括号（体现在 right > left），则不可能是有效的，那么算法就会一直令 left 和 right 清零，代表这些右括号开头的子串不可能有效\n- 如果先是左括号，则 left > right，不会清空，继续遍历，直到 right == left，代表之前的左括号都找到了对应的匹配右括号，那么就进行更新，然后继续遍历。\n- 直到 right > left，代表当前有效子串后面多加了一个右括号，导致当前子串不是有效的了，那么就二者一起清零，开始判断当前位置的下一个位置往后还有没有有效的（这里**很重要的思想**就是：一旦 right > left，那么 [left, right] 区间内任意位置开头的子串都不可能再和后面的子串拼接起来了（因为当前位置的右括号始终补不上），所以才会直接令 left 和 right 清零，表示不再考虑刚才的子串了，重新开始，这也就避免了重复遍历数组，使得时间复杂度为 O(N)）\n\n代码：\n\n``` java\n// 双指针从前往后遍历 + 从后往前遍历\npublic int longestValidParentheses02(String s) {\n    int left = 0, right = 0, maxlength = 0;\n    // 正向遍历：如果遇到左括号 left 就右移，否则 right 移动\n    // 每到一个位置，就判断此时的 left 是否等于 right，\n    // 1. 如果相等则找到了一个有效的子串，更新长度 2 * right\n    // 2. 如果 right > left，则此时说明当前子序列的右括号比左括号多，那肯定不是有效的，舍弃掉 \n    for (int i = 0; i < s.length(); i++) {\n        if (s.charAt(i) == '(') {\n            left++;\n        } else {\n            right++;\n        }\n        if (left == right) {\n            maxlength = Math.max(maxlength, 2 * right);\n        } else if (right > left) {\n            left = right = 0;\n        }\n    }\n    left = right = 0;\n    // 再反向遍历一遍，操作相反，思想一致\n    for (int i = s.length() - 1; i >= 0; i--) {\n        if (s.charAt(i) == '(') {\n            left++;\n        } else {\n            right++;\n        }\n        if (left == right) {\n            maxlength = Math.max(maxlength, 2 * left);\n        } else if (left > right) {\n            left = right = 0;\n        }\n    }\n    return maxlength;\n}\n```\n\n#### 方法二：动态规划\n\n> https://www.bilibili.com/video/BV13g41157hK?p=21\n\n思想：计算出以每个位置作为有效字符串的**结尾**时，当前子字符串的长度，取最大值即可得到答案。当前位置能作为有效字符串的结尾的**前提**是：**当前位置必须是左括号**，如果是右括号，肯定不能作为结尾。\n\n- 令 pre 指向 dp[i-1]，代表的**合格子串的前一个位置**（见下图的黄色块）\n- 判断 pre 位置的符号是否为 (：\n  - 如果是，则恰好能和当前 i 的 ) 组成一个 `( (...dp[i-1]...) )` 合格子串（见下图的黄色块 + 绿色块 + 红色块）\n    - 如果 pre-1 位置 dp[pre - 1] 不为 0，则将其也纳入当前的子串（见下图的蓝色块），否则长度就是 dp[i-1] 的长度 + 2\n  - 如果是 )，则不能和当前的 ）构成合格子串，则当前位置的 dp[i] 值为 0\n\n示意图：\n\n![image-20211218210931962](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/image-20211218210931962.png)\n\n代码：\n\n``` java\nclass Solution {\n    public int longestValidParentheses(String s) {\n        if (s == null || s.length() < 1) {\n            return 0;\n        }\n        return longestValidParentheses03(s);\n    }\n\n    // 动态规划：计算出以每个位置作为有效字符串的结尾时，当前子字符串的长度，取最大值即可得到答案\n    // 当前位置能作为有效字符串的结尾的前提是：当前位置必须是)，如果是(，肯定不能作为结尾\n    public int longestValidParentheses03(String s) {\n        int[] dp = new int[s.length()];\n        char[] str = s.toCharArray();\n        int pre = 0;\n        int res = 0;\n        // dp[0] = 0，只需要从1开始遍历\n        for (int i = 1; i < s.length(); i++) {\n            // 如果为(，则当前位置肯定不能作为字符串的结尾，dp值设置为0\n            if (str[i] == '(') {\n                dp[i] = 0;\n                continue;\n            } else {\n                // 如果当前位置为)，则可以作为结尾。\n                // pre 指向dp[i-1]代表的合格子串的前一个位置符号\n                pre = i - dp[i - 1] - 1;\n                // 判断该位置的符号是否为(，如果是，则恰好能和当前i的)组成一个( (...dp[i-1]...) )合格子串\n                if (pre >= 0 && str[pre] == '(') {\n                    // 如果pre-1还有，则将其也纳入当前的子串\n                    // 否则长度就是 dp[i-1]的长度 + 2\n                    dp[i] = pre - 1 >=0 ? dp[i - 1] + 2 + dp[pre - 1] : dp[i - 1] + 2;\n                } else {\n                    // 如果是)，则i位置的最长合格子串是0\n                    dp[i] = 0;\n                }\n\n            }\n            res = Math.max(res, dp[i]);\n        }\n        return res;\n    }\n\n   \n}\n```\n\n\n\n\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"【算法】贪心算法","url":"/2021/11/28/【算法】贪心算法/","content":"\n## 贪心算法常见题目\n\n\n\n\n\n\n\n<!-- More -->\n\n\n\n### 把数组排成最小的数\n\n[剑指 Offer 45. 把数组排成最小的数](https://leetcode-cn.com/problems/ba-shu-zu-pai-cheng-zui-xiao-de-shu-lcof/)：输入一个非负整数数组，把数组里所有数字拼接起来排成一个数，打印能拼接出的所有数字中最小的一个。\n\n贪心策略：若拼接字符串 x + y > y + x，则 x “大于” y ；反之，若 x + y < y + x ，则 x “小于” y。\n\n> *x* “小于” y 代表：排序完成后，数组中 x 应在 y 左边；“大于” 则反之。\n\n根据以上规则，套用任何排序方法对 nums 执行排序即可。\n\n代码：\n\n``` java\npublic String minNumber(int[] nums) {\n    String[] strs = new String[nums.length];\n    for(int i = 0; i < nums.length; i++)\n        strs[i] = String.valueOf(nums[i]);\n    // 自定义比较器\n    Arrays.sort(strs, (x, y) -> (x + y).compareTo(y + x));\n    StringBuilder res = new StringBuilder();\n    for(String s : strs)\n        res.append(s);\n    return res.toString();\n}\n```\n\n\n\n### 小虎买苹果\n\n#### 方法一：普通贪心策略——先尽可能多的买 8个的袋子\n\n- 如果要买的苹果数量是奇数，则没有答案，直接返回 -1。\n- 如果要买的苹果是偶数，则开始贪心：\n  - 先尽可能多的买 8 个的袋子，判断此时剩余的苹果能不能被 6 整除，如果可以找到了最佳方案。\n  - 如果不行，减少一个 8个的袋子，再看剩余的苹果能不能被 6 整除。\n  - 重复该过程直到 8个的袋子为 0，如果剩余的苹果还不能被 6 整除，则说明没有满足条件的装法。\n\n这种贪心策略会优先考虑买 8个的袋子，从而能保证得到的结果是最优的。\n\n#### 方法一的优化版本\n\n可以对方法一进行优化：当剩余的苹果数量大于 24 时不需要再往下尝试了，后续不可能在存在可行方案了。这里的 24 是 6 和 8 的最小公倍数。如果该数字能被 6 整除，则其肯定能被 8 整除。但是在上面的尝试中已经表明了该数字不能被 8 整除，否则也不会遍历到当前位置。因此这个数字肯定也不能被 6 整除。\n\n代码：\n\n``` java\npublic class AppleMinBags {\n    public static int minBags(int n) {\n        // 小于 6 个肯定不可行\n        if (n <= 5) {\n            return -1;\n        }\n        // 如果 n 为奇数, 肯定也不可行\n        if (n % 2 == 1) {\n            return -1;\n        }\n        /*\n         * 贪心策略: 先尝试 8个的袋子, 如果剩余的无法被 6 整除, 再减去一个 8个的袋子, 继续尝试\n         * 如果尝试到发现剩余的苹果数量大于 24( 8 和 6 的最小公倍数), 则不可能有可行方案, 直接返回\n         */\n        int bag8 = n / 8;\n        // 初始化为 -1, 这样在遍历完毕后判断 bag6 是否为 -1, 如果是则不存在可行方案\n        int bag6 = -1;\n        int rest = n - bag8 * 8;\n        while (bag8 >= 0 && rest < 24) {\n            // 判断当前剩余的苹果能否被 6 整除\n            bag6 = minBagBase6(rest);\n            if (bag6 != -1) {\n                break;\n            }\n            // 减少一袋, 继续尝试\n            bag8--;\n            rest = n - bag8 * 8;\n        }\n        return bag6 != -1 ? bag6 + bag8 : -1;\n    }\n\n    public static int minBagBase6(int n) {\n        // 如果能整除就返回数量, 否则返回 -1\n        return (n % 6 == 0) ? n / 6 : -1;\n    }\n\n    // 打表:\n    public static int minBagAwesome(int apple) {\n        if ((apple & 1) != 0) {\n            return -1;\n        }\n        if (apple < 18) {\n            return apple == 0 ? 0 : (apple == 6 || apple == 8) ? 1\n                : (apple == 12 || apple == 14 || apple == 16) ? 2 : -1;\n        }\n        return (apple - 18) / 8 + 3;\n    }\n\n    public static void main(String[] args) {\n        int max = Integer.MAX_VALUE;\n        int testTime = 100000000;\n        for (int test = 0; test < testTime; test++) {\n            int apple = (int) (Math.random() * max);\n            if (minBags(apple) != minBagAwesome(apple)) {\n                System.out.println(\"error\");\n            }\n        }\n\n    }\n}\n```\n\n\n\n\n\n\n\n\n\n### 避免洪水泛滥\n\n[1488. 避免洪水泛滥](https://leetcode-cn.com/problems/avoid-flood-in-the-city/)：你的国家有无数个湖泊，所有湖泊一开始都是空的。当第 n 个湖泊下雨的时候，如果第 n 个湖泊是空的，那么它就会装满水，否则这个湖泊会发生洪水。你的目标是避免任意一个湖泊发生洪水。\n\n给你一个整数数组 rains ，其中：\n\n- `rains[i] > 0` 表示第 i 天时，第 rains[i] 个湖泊会下雨。\n- `rains[i] == 0` 表示第 i 天没有湖泊会下雨，你可以选择 一个湖泊并抽干这个湖泊的水。\n\n请返回一个数组 ans ，满足：\n\n- `ans.length == rains.length`\n- 如果 `rains[i] > 0` ，那么 `ans[i] == -1`。\n- 如果 `rains[i] == 0`，ans[i] 是你第 i 天选择抽干的湖泊。\n\n如果有多种可行解，请返回它们中的 **任意一个** 。如果没办法阻止洪水，请返回一个 **空的数组** 。\n\n> https://leetcode-cn.com/problems/avoid-flood-in-the-city/solution/avoid-flood-in-the-city-by-ikaruga/、https://leetcode-cn.com/problems/avoid-flood-in-the-city/solution/java-hashmap-hashset-treeset-mian-xiang-vxeda/\n\n思路：\n\n- 将晴天的日期全部记录到 TreeSet  中\n- 使用 HashMap 来记录每个湖泊上一次下雨的日期\n- 遇到晴天时先不用管抽哪个湖\n- 当下雨时，湖泊已经水满了时，我们可以查询到上次下雨的日期\n- 通过这个日期在晴天记录中查找对应的晴天日期。在有序数据中使用二分查找\n- 如果找到了，就可以使用那一天抽水，找不到就不可避免的洪水了。找到了更新下雨表中当前湖泊的日期为当前日期。\n\n其中：\n\n- 核心思想 ： 遇到可以抽水的天时，把它存起来，遇到满水湖泊需要抽水时，观察上次该湖泊满水时与当前日期之间是否有可抽水天气 ， **取最靠近上次满水的那一个晴天**。\n- HashMap 作用 ：记录某湖泊**最近一次**蓄满水的日期（同一时刻某个湖泊只会存一个日期，当遇到同一湖泊的另一个下雨日期时，就要进行处理，处理完毕后更新该湖泊的下雨日期为当前日期）。\n- TreeSet 作用 ：存晴天日期，用于二分查找出对某需要抽水湖泊的最佳抽水日期（距离该湖泊上一次下雨的最近日期）。\n- 空闲的晴天 ：设为1。\n\n代码：\n\n``` java\npublic int[] avoidFlood(int[] rains) {\n    if (rains == null || rains.length < 1) {\n        return rains;\n    }\n\n    // 使用有序树保存晴天，使用 set.higher(i) 方法能返回比 i 大的最小元素，也就是比 i 大的距离他最近的元素\n    TreeSet<Integer> sunnyDaySet = new TreeSet<>();\n    // 使用哈希表保存下雨天的湖泊编号以及其索引。key：湖泊编码，value：该湖泊下雨天的索引\n    HashMap<Integer, Integer> rainyDayMap = new HashMap<>();\n    int[] res = new int[rains.length];\n    // 按照题意初始化\n    Arrays.fill(res, -1);\n\n    for (int i = 0; i < rains.length; i++) {\n        if (rains[i] == 0) {\n            // 如果当前天是晴天，则加入到有序表中\n            sunnyDaySet.add(i);\n            // 按照题意，晴天如果不抽水，则设置为 1\n            res[i] = 1;\n            continue;\n        }\n        if (!rainyDayMap.containsKey(rains[i])) {\n            // 如果下雨表中没保存过当前湖泊编号，则说明该湖泊还没下过雨，将其添加到表中\n            rainyDayMap.put(rains[i], i);\n            continue;\n        }\n        /* 如果当前天是下雨天，且已经存在于下雨表中，则需要从晴天表里选出某一天来清空当前下雨的湖泊。\n            * 并且要选出的这一天需要是距离该湖泊上一次下雨后最近的一个晴天\n            * 也就是在晴天表中比该湖泊上一次下雨天要大的天数中最小的一个，使用 higher() 方法可以实现（二分查找）\n            */\n        Integer recentDay = sunnyDaySet.higher(rainyDayMap.get(rains[i]));\n        if (recentDay == null) {\n            // 如果找不到，则返回\n            return new int[0];\n        }\n        // 如果找得到，就修改 res 中该晴天锁抽干的湖泊编号，并从晴天表中删掉该天\n        res[recentDay] = rains[i];\n        // 注意！！！当前日期变更为该湖泊的最近满水日期，要记得更新当前湖泊的下雨天\n        rainyDayMap.put(rains[i] , i);\n        sunnyDaySet.remove(recentDay);\n    }\n    return res;\n}\n```\n\n\n\n\n\n### 课程表 III\n\n[630. 课程表 III](https://leetcode-cn.com/problems/course-schedule-iii/)：这里有 n 门不同的在线课程，按从 1 到 n 编号。给你一个数组 `courses` ，其中 `courses[i] = [durationi, lastDayi]` 表示第 i 门课将会 持续 上 `durationi `天课，并且必须在不晚于 lastDayi 的时候完成。你的学期从第 1 天开始。且不能同时修读两门及两门以上的课程。返回你最多可以修读的课程数目。\n\n贪心策略：对于两门课，**如果后者的关闭时间较晚 ，那么我们先学习前者，再学习后者，总是最优的**。\n\n代码：\n\n``` java\npublic int scheduleCourse(int[][] courses) {\n    // 以结束时间排序\n    Arrays.sort(courses, (c1, c2) -> c1[1] - c2[1]);\n    // 储存已选择的课程，按照持续时间排序\n    PriorityQueue<int[]> heap = new PriorityQueue<>((c1, c2) -> c2[0] - c1[0]);\n    int day = 0;\n    for (int[] c : courses) {\n        if (day + c[0] <= c[1]) {\n            // 如果当前课程时间不冲突，将该课程加入队列\n            // 这里的不冲突可以理解为，0~day+c[0]这段区间，我们还可以再插入当前一节课\n            day += c[0];\n            heap.offer(c);\n        } else if (!heap.isEmpty() && heap.peek()[0] > c[0]) {\n            // 课程时间冲突，且有选过其他课，这时我们找到最长时间的课程，用当前的短课替换了，余出了更多的空区间\n            // 所以这里我们余出的时间其实就是两者的持续时间之差，课程变短了，day会前移，这样我们相当于变相给后面的课程增加了选择的区间\n            day -= heap.poll()[0] - c[0];\n            heap.offer(c);\n        }\n    }\n    return heap.size();\n}\n```\n\n\n\n\n\n## 预处理技巧\n\n### 染色问题\n\n牛牛有一些排成一行的正方形。每个正方形已经被染成红色或者绿色。牛牛现在可以选择任意一个正方形然后用这两种颜色的任意一种进行染色,这个正方形的颜色将会被覆盖。牛牛的目标是在完成染色之后,每个红色R都比每个绿色G距离最左侧近。牛牛想知道他最少需要涂染几个正方形。如样例所示：s = RGRGR\n\n我们涂染之后变成 RRRGG 满足要求了，涂染的个数为2，没有比这个更好的涂染方案。\n\n思路：遍历每一个位置，以当前位置为分界线，\n\n- 统计左侧有多少个G，将其染成R\n- 统计右侧有多少个R，将其染成G\n- 二者的和就是当前位置作为分界线时的涂染个数。\n\n但如果每到一个位置都需要遍历左右侧的区间统计R和G的个数，则时间复杂度为 O(N^2)。我们可以使用**预处理**技巧：先遍历两遍数组，分别统计出每个位置左侧有多少个G，以及每个位置右侧有多少个R，然后再遍历一遍数组，就可以使用预处理的数组快速计算出当前位置的染色数量，从而加速算法。**进一步优化**：预处理时只遍历right数组，然后在遍历left数组的过程中就可以计算答案。\n\n代码：\n\n``` java\npublic class ColorLeftRight {\n    public static int minPaint(String s) {\n        if (s == null || s.length() < 1) {\n            return 0;\n        }\n        char[] str = s.toCharArray();\n        int N = str.length;\n        /*\n\t\t * 遍历每一个位置, 以当前位置为分界线:\n\t\t * 1. 统计左侧有多少个G, 将其染成R.\n\t\t * 2. 统计右侧有多少个R, 将其染成G.\n\t\t * 遍历每个位置后, 即可得到染色最少的方案\n\t\t * 这种方法的时间复杂度为 O(N^2)\n\t\t */\n        // for (int i = 0; i <= N; i++) {\n        // \tif (i == 0) {\n        // \t\t// 如果分界线在0位置, 代表左侧不需要染色, 需要统计右侧有多少个R\n        // \t} else if (i == N) {\n        // \t\t// 如果分界线在N位置, 代表右侧不需要染色, 需要统计左侧有多少个G\n        // \t} else {\n        // \t\t// 否则将数组划分为 [0, i - 1] 与 [i, N - 1]\n        // \t\t// 分别统计左侧有多少个G与右侧有多少个R\n        // \t}\n        // }\n\n        /*\n\t\t * 预处理技巧: 先遍历两遍数组, 分别统计出每个位置左侧有多少个G, 以及每个位置右侧有多少个R,\n\t\t * 然后再遍历一遍数组, 就可以使用预处理的数组快速计算出当前位置的染色数量, 从而加速算法\n\t\t * 进一步优化: 预处理时只遍历right数组, 然后在遍历left数组的过程中就可以计算答案\n\t\t */\n        int[] right = new int[N];\n        // 初始化最后一个位置的值\n        right[N - 1] = str[N - 1] == 'R' ? 1 : 0;\n        // 倒序遍历数组, 更新right数组\n        for (int i = N - 2; i >= 0; i--) {\n            right[i] = right[i + 1] + (str[i] == 'R' ? 1 : 0);\n        }\n\n        // 正向遍历数组, 使用变量left记录目前位置左侧G的数量, 就可以省掉一次left数组的创建\n        int left = 0;\n        int res = Integer.MAX_VALUE;\n        //\n        for (int i = 0; i <= N; i++) {\n            if (i == 0) {\n                // 如果分界线在0位置, 代表左侧不需要染色, 需要统计右侧有多少个R\n                res = right[0];\n            } else if (i == N) {\n                // 如果分界线在N位置, 代表右侧不需要染色, 需要统计左侧有多少个G\n                left += str[i - 1] == 'G' ? 1 : 0;\n                res = Math.min(res, left);\n            } else {\n                // 否则将数组划分为 [0, i - 1] 与 [i, N - 1]\n                // 分别统计左侧[0, i-1]有多少个G, 以及右侧right[i]有多少个R\n                // [0, i - 1]: 'G'的数量 = left + str[i-1]是否是'G'\n                left += str[i - 1] == 'G' ? 1 : 0;\n                res = Math.min(res, right[i] + left);\n            }\n        }\n        return res;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(minPaint(\"GGGGGR\"));\n    }\n}\n```\n\n### 最大的正方形边框\n\n![image-20211220150352356](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/image-20211220150352356.png)\n\n最暴力的方法：遍历矩阵中的每一个位置，在该位置处遍历此处可以支持的边框的大小（扩到矩阵边界为止），然后遍历该边框内的值，判断是否都是1。这种方式时间复杂度为 O(N^4)，不可采纳。\n\n预处理技巧：\n\n**1、判断边框内是否都为1**：创建两个辅助数组 right 和 down，分别保存：\n\n- right[]：包含当前位置在内，往后连续为1的个数，多扩一列（为了最后一列的计算方便）\n- down[]：包含当前位置在内，往下连续为1的个数，多扩一行（为了最后一行的计算方便）\n\n> **注意**：这里的 right 和 down 的范围要**比原矩阵多一列和一行**，这样就能快速计算出最后一行和最后一列的值，不需要单独初始化最后一行和最后一列。\n\n事先遍历一遍整个矩阵，将 right 和 down 内的值初始化完毕，后面使用该矩阵即可快速计算出当前框内是否都为1。方法为：判断边框左上角，右上角和左下角的 right/down 中的值即可：\n\n``` java\n// 判断当前框内是否都是1\nif (right[i][j] >= size && down[i][j] >= size\n    && right[i + size - 1][j] >= size\n    && down[i][j + size - 1] >= size) {\n    return true;\n}\n```\n\n**2、遍历矩阵**：不同于正向思维中遍历到每一个位置后再遍历可能的边框情况。我们选用**逆向思维**，**先确定边框的范围（从大到小）**，然后**再判断在当前边框大小的情况下，原矩阵中哪些位置可以作为边框的左上角被遍历到**，在这些左上角位置开始调用封装好的方法判断此位置画框能否都是1。这样就能从边框最大的情况开始，一旦找到了该边框尺寸情况下某个位置都是1，则就可以直接返回了，不需要再遍历更小边框的情况了，无疑节省了大量时间。\n\n代码：\n\n```java\npublic class MaxBorderSize {\n    public static int getMaxBorderSize(int[][] m) {\n        if (m == null || m.length < 1) {\n            return 0;\n        }\n        // right: 包含当前位置在内, 往后连续为1的个数，多扩一列（为了最后一列的计算方便）\n        // down: 包含当前位置在内, 往下连续为1的个数，多扩一行（为了最后一行的计算方便）\n        int[][] right = new int[m.length][m[0].length + 1];\n        int[][] down = new int[m.length + 1][m[0].length];\n\n        // 设置right和down的值\n        setBorderMapSimple(m, right, down);\n        // size从最大开始取, 遍历每一个可行的位置, 判断当前大小的边界是否都是1\n        for (int size = Math.min(m.length, m[0].length); size > 0; size--) {\n            if (meets(m, right, down, size)) {\n                return size;\n            }\n        }\n        return 0;\n    }\n\n    private static boolean meets(int[][] m, int[][] right, int[][] down, int size) {\n        int row = m.length;\n        int col = m[0].length;\n        // 遍历此时可以画框的位置, 判断该正方形的三个点: m[i][j] m[i+size-1][j] m[i][j+size-1] 在right和down中的值\n        for (int i = 0; i < row - size + 1; i++) {\n            for (int j = 0; j < col - size + 1; j++) {\n                // 判断当前框内是否都是1\n                if (right[i][j] >= size && down[i][j] >= size\n                    && right[i + size - 1][j] >= size\n                    && down[i][j + size - 1] >= size) {\n                    return true;\n                }\n            }\n        }\n        return false;\n    }\n\n    // 不推荐\n    public static void setBorderMap(int[][] m, int[][] right, int[][] down) {\n        int row = m.length;\n        int col = m[0].length;\n        // 先初始化最后一行最后一列\n        if (m[row - 1][col - 1] == 1) {\n            right[row - 1][col - 1] = 1;\n            down[row - 1][col - 1] = 1;\n        }\n\n        // 初始化最后一列\n        for (int i = row - 2; i >= 0; i--) {\n            // 当前位置如果为1, 则更新其下面连续的1的个数\n            if (m[i][col - 1] == 1) {\n                // 更新每一行最后一列的right矩阵\n                right[i][col - 1] = 1;\n                // 更新down矩阵为下一行的值加一\n                down[i][col - 1] = down[i + 1][col - 1] + 1;\n            }\n        }\n        // 初始化最后一行\n        for (int j = col - 2; j >= 0; j--) {\n            // 当前位置如果为1, 则更新其下面连续的1的个数\n            if (m[row - 1][j] == 1) {\n                // 更新每一列最后一行的down矩阵\n                down[row - 1][j] = 1;\n                // 更新down矩阵为下一行的值加一\n                right[row - 1][j] = right[row - 1][j + 1] + 1;\n            }\n        }\n        // 更新其他行与列(从倒数第二行倒数第二列开始)\n        for (int i = row - 2; i >= 0; i--) {\n            for (int j = col - 2; j >= 0; j--) {\n                if (m[i][j] == 1) {\n                    right[i][j] = right[i][j + 1] + 1;\n                    down[i][j] = down[i + 1][j] + 1;\n                }\n            }\n        }\n    }\n\n    public static void setBorderMapSimple(int[][] m, int[][] right, int[][] down) {\n        int row = m.length;\n        int col = m[0].length;\n        // 先初始化m矩阵最后一行最后一列的位置\n        if (m[row - 1][col - 1] == 1) {\n            right[row - 1][col - 1] = 1;\n            down[row - 1][col - 1] = 1;\n        }\n\n        // 不需要额外初始化最后一行和最后一列了，因为right扩了一列，down扩了一行，恰好能处理最后一行和最后一列\n        for (int i = row - 1; i >= 0; i--) {\n            for (int j = col - 1; j >= 0; j--) {\n                if (m[i][j] == 1) {\n                    // right矩阵恰好扩了一列，使得原矩阵最后一列可以取到col-1 + 1的位置（0）\n                    right[i][j] = right[i][j + 1] + 1;\n                    down[i][j] = down[i + 1][j] + 1;\n                }\n            }\n        }\n    }\n\n    public static int[][] generateRandom01Matrix(int rowSize, int colSize) {\n        int[][] res = new int[rowSize][colSize];\n        for (int i = 0; i != rowSize; i++) {\n            for (int j = 0; j != colSize; j++) {\n                res[i][j] = (int) (Math.random() * 2);\n            }\n        }\n        return res;\n    }\n\n    public static void printMatrix(int[][] matrix) {\n        for (int i = 0; i != matrix.length; i++) {\n            for (int j = 0; j != matrix[0].length; j++) {\n                System.out.print(matrix[i][j] + \" \");\n            }\n            System.out.println();\n        }\n    }\n\n    public static void main(String[] args) {\n        int[][] matrix = generateRandom01Matrix(7, 8);\n        printMatrix(matrix);\n        System.out.println(getMaxBorderSize(matrix));\n    }\n}\n```","tags":["算法"],"categories":["算法"]},{"title":"【算法】单调栈","url":"/2021/11/25/【算法】单调栈/","content":"\n## 单调栈结构\n\n遍历整个数组，使用一个栈记录数组中的元素**索引**。\n\n### 所有元素不重复的情况\n\n- 当寻找某个元素左右距离他最近的比他小的元素时，栈底元素的值小于栈顶元素的值。例如栈中：`[2 -> 3 -> 4(栈顶)`。新来一个元素1，其值小于4，则找到了当前栈顶4左右侧距离他最近的比他小的元素3和1。将4弹出，记录其左右侧的3和1，然后继续。\n- 当寻找某个元素左右距离他最近的比他大的元素时，栈底元素大于栈顶元素。例如栈中：`[4 -> 3 -> 2(栈顶)`。新来一个元素5，其值大于2，则找到了当前栈顶2左右侧距离他最近的比他大的元素3和5。\n\n规律：\n\n- 整体是满足**单调性**的。当发现新来的元素破坏了栈中的单调性时，**将栈顶元素弹出**（其余元素不弹出，新来的元素也不在此时入栈，而是进行下一轮判断是否可以入栈），记录此时新的栈顶元素作为其左侧最近元素，记录新来的元素为其右侧最近元素。\n- **栈中保存的元素始终是按照升序或降序排列的**，肯定满足单调性。这是因为中途破坏单调性的元素都被弹出并记录了，还在栈中的都是单调排序的。\n- 找某个元素左右比他小的，栈中是升序排列；找某个元素左右比他大的，栈中是降序排列。\n\n### 有元素重复的情况\n\n当有元素重复时，栈中不能单单只存储一个 Integer 类型变量，而应该存储一个 ArrayList，将相同值的元素存储到同一个 List 中。\n\n算法整体顺序一致，区别在于弹栈时弹出的是一个 List，需要将这个 List 中的所有元素都遍历一次，加入到 `res[][]` 中；另外，在获取左侧的元素索引值时，需要获取到栈顶第二个 List 里的**最后一个元素**（这个元素是最靠近当前弹出栈的元素的，因为整体是单调的，越靠后的，越在 List 的后面）。\n\n代码：\n\n```java\npublic class MonotonousStack {\n\n   public static int[][] getNearLessNoRepeat(int[] nums) {\n      if (nums == null || nums.length < 1) {\n         return null;\n      }\n\n      Stack<Integer> stack = new Stack<>();\n      int[][] res = new int[nums.length][2];\n\n      for (int i = 0; i < nums.length; i++) {\n         // 如果遇到栈顶元素大于当前元素，说明栈顶元素找到了其左侧小于它的第一个元素（栈顶下的第二个的元素）\n         // 如果新来的元素仍是按照升序或降序排列，则都不会弹栈，因为仍然是符合单调性的，只有在破坏单调性时才弹栈记录\n         while (!stack.isEmpty() && nums[stack.peek()] > nums[i]) {\n            int popIndex = stack.pop();\n            // 弹出的栈顶元素左侧的最小值就是新的栈顶元素（或不存在，对应栈空）\n            int leftLessIndex = stack.isEmpty() ? -1 : stack.peek();\n            // 存储这个栈顶元素的左侧小于它的第一个元素索引 leftLessIndex 和其右边小于它的第一个元素索引 i\n            res[popIndex][0] = leftLessIndex;\n            res[popIndex][1] = i;\n         }\n         // 跳出while循环时，i位置的元素已经能插入到栈中并满足栈中的单调性了，此时将i压入栈中\n         stack.push(i);\n      }\n\n      // 遍历完数组后，栈中可能还存在一些元素，这些元素的最近元素还没保存到res里\n      // 将栈中元素依次弹出，其左侧最近值就是下一个栈中元素，右侧最近值不存在，保存-1\n      while (!stack.isEmpty()) {\n         int popIndex = stack.pop();\n         int leftLessIndex = stack.isEmpty() ? -1 : stack.peek();\n         res[popIndex][0] = leftLessIndex;\n         res[popIndex][1] = -1;\n      }\n      return res;\n   }\n\n\n   public static int[][] getNearLess(int[] nums) {\n      if (nums == null || nums.length < 1) {\n         return null;\n      }\n\n      Stack<List<Integer>> stack = new Stack<>();\n      int[][] res = new int[nums.length][2];\n      for (int i = 0; i < nums.length; i++) {\n         while (!stack.isEmpty() && nums[stack.peek().get(0)] > nums[i]) {\n            // 获取到list集合，里面可能存着多个相同值的元素\n            List<Integer> popList = stack.pop();\n            // 左边最小的元素为新的栈顶集合里的最后一个元素，因为最后一个元素是最靠近当前元素的（因为栈结构的单调性）\n            int leftLessIndex = stack.isEmpty() ? -1 :stack.peek().get(stack.peek().size() - 1);\n            // 遍历当前list里的元素（值相同），为其赋上左边最小元素索引（是相同的）以及右侧元素（i）\n            for (Integer popIndex : popList) {\n               res[popIndex][0] = leftLessIndex;\n               res[popIndex][1] = i;\n            }\n         }\n         // 将i加入到栈中，注意分两种情况：\n         //   1. i的值和当前栈顶元素的值不相同，则新建一个list，将该list入栈\n         //   2. i的值和当前栈顶元素的值相同，则将i加入到栈顶元素的list里的最后一个位置\n         // 注意要带上 !stack.isEmpty() && ，必须要有元素才行\n         if (!stack.isEmpty() && nums[stack.peek().get(0)] == nums[i]) {\n            // 相同时，直接加入到栈顶的list中\n            stack.peek().add(i);\n         } else {\n            // 不同时，新建一个list，入栈\n            List<Integer> list = new ArrayList<>();\n            list.add(i);\n            stack.push(list);\n         }\n      }\n\n      // 全部遍历完毕后，依次弹栈，记录栈中元素的左侧最小信息到res中\n      while (!stack.isEmpty()) {\n         List<Integer> popList = stack.pop();\n         for (Integer popIndex : popList) {\n            int leftLessIndex = stack.isEmpty() ? -1 : stack.peek().get(stack.peek().size() - 1);\n            res[popIndex][0] = leftLessIndex;\n            res[popIndex][1] = -1;\n         }\n      }\n\n      return res;\n   }\n\n   // for test\n   public static int[] getRandomArrayNoRepeat(int size) {\n      int[] arr = new int[(int) (Math.random() * size) + 1];\n      for (int i = 0; i < arr.length; i++) {\n         arr[i] = i;\n      }\n      for (int i = 0; i < arr.length; i++) {\n         int swapIndex = (int) (Math.random() * arr.length);\n         int tmp = arr[swapIndex];\n         arr[swapIndex] = arr[i];\n         arr[i] = tmp;\n      }\n      return arr;\n   }\n\n   // for test\n   public static int[] getRandomArray(int size, int max) {\n      int[] arr = new int[(int) (Math.random() * size) + 1];\n      for (int i = 0; i < arr.length; i++) {\n         arr[i] = (int) (Math.random() * max) - (int) (Math.random() * max);\n      }\n      return arr;\n   }\n\n   // for test\n   public static int[][] rightWay(int[] arr) {\n      int[][] res = new int[arr.length][2];\n      for (int i = 0; i < arr.length; i++) {\n         int leftLessIndex = -1;\n         int rightLessIndex = -1;\n         int cur = i - 1;\n         while (cur >= 0) {\n            if (arr[cur] < arr[i]) {\n               leftLessIndex = cur;\n               break;\n            }\n            cur--;\n         }\n         cur = i + 1;\n         while (cur < arr.length) {\n            if (arr[cur] < arr[i]) {\n               rightLessIndex = cur;\n               break;\n            }\n            cur++;\n         }\n         res[i][0] = leftLessIndex;\n         res[i][1] = rightLessIndex;\n      }\n      return res;\n   }\n\n   // for test\n   public static boolean isEqual(int[][] res1, int[][] res2) {\n      if (res1.length != res2.length) {\n         return false;\n      }\n      for (int i = 0; i < res1.length; i++) {\n         if (res1[i][0] != res2[i][0] || res1[i][1] != res2[i][1]) {\n            return false;\n         }\n      }\n\n      return true;\n   }\n\n   // for test\n   public static void printArray(int[] arr) {\n      for (int i = 0; i < arr.length; i++) {\n         System.out.print(arr[i] + \" \");\n      }\n      System.out.println();\n   }\n\n   public static void main(String[] args) {\n      int size = 10;\n      int max = 20;\n      int testTimes = 2000000;\n      for (int i = 0; i < testTimes; i++) {\n         int[] arr1 = getRandomArrayNoRepeat(size);\n         int[] arr2 = getRandomArray(size, max);\n         if (!isEqual(getNearLessNoRepeat(arr1), rightWay(arr1))) {\n            System.out.println(\"Oops!\");\n            printArray(arr1);\n            break;\n         }\n         if (!isEqual(getNearLess(arr2), rightWay(arr2))) {\n            System.out.println(\"Oops!\");\n            printArray(arr2);\n            break;\n         }\n      }\n   }\n}\n```\n\n<!-- More -->\n\n## 单调栈的相关题目\n\n### 数组中累积和与最小值的乘积\n\n定义指标A：正数数组中累积和与最小值的乘积。给定一个数组，请返回子数组中，指标A最大的值。\n\n该问题可以使用单调栈结构进行求解。思路：\n\n- 遍历每一个元素，以该元素作为当前子区间内的最小值元素（其子区间内的元素都比当前元素大）；\n- 尽可能的扩大该子区间的范围，使得当前元素为最小值的子区间范围尽可能的大，这样其数组中的累加和就会尽可能的大；\n- 找到当前元素左右侧区间边界的方法为：使用单调栈找出当前元素左侧和右侧距离他最近的比他小的元素\n- 对数组中每个元素都进行该操作，直到找出最大的指标A\n- 可以在单调栈的建立过程中更新最大的指标A，无需创建索引后再单独计算\n\n代码：\n\n``` java\npublic class MonotonousStack {\n    public static int solution(int[] nums) {\n        if (nums == null || nums.length < 1) {\n            return -1;\n        }\n\n        // 数组的前缀累加和\n        int[] sums = new int[nums.length];\n        // 初始化第一个元素\n        sums[0] = nums[0];\n        // 遍历每一个元素,计算前缀累加和\n        for (int i = 1; i < nums.length; i++) {\n            sums[i] = sums[i - 1] + nums[i];\n        }\n\n        Stack<Integer> stack = new Stack<>();\n        // 记录答案\n        int max = Integer.MIN_VALUE;\n        for (int i = 0; i < nums.length; i++) {\n            // 注意单调栈里保存的是索引值\n            // 如果当前栈顶元素大于新来的元素,则找到了当前栈顶元素左右离他最近的元素,将其弹出\n            // 注意是 while 循环，不断判断当前元素 nums[i] 与新的栈顶的大小，可能会一直弹出\n            while (!stack.isEmpty() && nums[stack.peek()] >= nums[i]) {\n                // 弹出栈顶元素，更新指标A的最大值\n                // 注意这两个边界值的元素值都比当前元素小\n                int j = stack.pop();\n                // 1. 如果栈空，则不存在比他小的左边界，可以一直取到nums[0]，则当前子区间的累加和等于sums[i-1]（不能包含i值，因为其小于nums[j]）\n                // 2. 如果栈不为空，则存在比他小的左边界且该边界值取不到，则当前子区间的累加和等于sums[i - 1] - sums[stack.peek()]\n                max = Math.max(max, (stack.isEmpty() ? sums[i - 1] : (sums[i - 1] - sums[stack.peek()])) * nums[j]);\n            } \n            // 新来的元素入栈\n            stack.push(i);\n        }\n        // 最后将栈里剩余元素进行设置\n        while (!stack.isEmpty()) {\n            int j = stack.pop();\n            // 当前栈中元素都不存在比他小的右边界，所以右边界从sums[size - 1]开始取\n            max = Math.max(max, (stack.isEmpty() ? sums[size - 1] : (sums[size - 1] - sums[stack.peek()])) * arr[j]);\n        }\n        return max;\n    }\n}\n```\n\n\n\n### 柱状图中最大的矩形\n\n[柱状图中最大的矩形](https://leetcode-cn.com/problems/largest-rectangle-in-histogram/)：给定 *n* 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8D%95%E8%B0%83%E6%A0%88/image-20211215154559108.png\" alt=\"image-20211215154559108\" style=\"zoom:50%;\" />\n\n该问题即为上一题的具体形式，同样可以使用单调栈进行求解。\n\n\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"【算法】滑动窗口","url":"/2021/11/24/【算法】滑动窗口/","content":"\n## 滑动窗口模板\n\n### 模板一\n\n滑动窗口模板一：适用于**窗口大小固定**，整体向右移动。\n\n此时只使用一个变量，代表右边界，不断向右移动。代码：\n\n``` java\npublic int[] template01(int[] nums, int k) {\n    int ans = 0;\n    int sum = 0;\n    int maxSum = 0;\n    for (int i = 0; i < nums.length; i++) {\n        // 更新当前窗口内的累加和\n        sum += nums[i];\n        // 第一次满足该条件时，[0,i] 区间形成了第一个窗口\n        // 此时就该记录该区间内的数字和的\n        // 之后i不断++，窗口的右边界不断右移，左边界 i-k+1 也不断右移\n        if (i >= k - 1) {\n            if (sum > maxSum) {\n                maxSum = sum;\n                ans = i - k + 1;\n            }\n            // 窗口即将整体右移，更新sum：减去左边界的值\n            sum -= nums[i - k + 1];\n        }\n    }\n}\n```\n\n这种方式当退出循环时无需其他操作，因为最后一个窗口位置的情况也考虑在内了。\n\n### 模板二\n\n滑动窗口模板二：适用于**窗口任意大小**。\n\n此时需要两个指针 left 与 right，二者根据题目的要求进行右移。代码：\n\n``` java\npublic int template02(String s) {\n    int left = 0;\n    int right = 0;\n    // 词频表\n    Map<Character, Integer> freq = new HashMap<>();\n    int maxCount = 0;\n\n    while (right < s.length()) {\n        // 如果当前字符已经被访问过，则right不动，left++\n        if (freq.containsKey(s.charAt(right))) {\n            // 清掉left的字符的频次\n            freq.remove(s.charAt(left));\n            // 此时[left, right-1]区间即为一个局部不重复子串区间\n            // 更新最大值\n            maxCount = Math.max(maxCount, (right - left));\n            // left右移\n            left++;\n        } else {\n            // 如果当前字符没有被访问过，righ++\n            // 先更新当前字符的词频\n            freq.put(s.charAt(right), 1);\n            // right右移\n            right++;\n        }\n    }\n    // 跳出后还要额外判断一次当前的left和right间的距离\n    maxCount = Math.max(maxCount, (right - left));\n    return maxCount;\n}\n```\n\n这种方式需要在最后 right 跳出循环后，额外判断此时的 [left, right) 区间内的情况。\n\n可使用滑动窗口的题目有：\n\n- 最小包含子串长度\n- 最多有 K 个不同字符的最大子串长度\n- 正好有 K 个不同整数的子数组数量\n- 累加和至少为 K 的最短子数组长度\n- 至少有 K 个重复字符的最长子串\n\n<!-- More -->\n\n## 滑动窗口常见题目\n\n### 最长不含重复字符的子字符串\n\n[剑指 Offer 48. 最长不含重复字符的子字符串](https://leetcode-cn.com/problems/zui-chang-bu-han-zhong-fu-zi-fu-de-zi-zi-fu-chuan-lcof/)：请从字符串中找出一个最长的不包含重复字符的子字符串，计算该最长子字符串的长度。\n\n示例 1：\n\n```\n输入: \"abcabcbb\"\n输出: 3 \n解释: 因为无重复字符的最长子串是 \"abc\"，所以其长度为 3。\n```\n\n示例 2：\n\n```\n输入: \"bbbbb\"\n输出: 1\n解释: 因为无重复字符的最长子串是 \"b\"，所以其长度为 1。\n```\n\n代码：\n\n``` java\npublic int lengthOfLongestSubstring(String s) {\n    if (s == null || s.length() < 1) {\n        return 0;\n    }\n    return lengthOfLongestSubstring01(s);\n}\n\n// 滑动窗口\npublic int lengthOfLongestSubstring01(String s) {\n    int left = 0;\n    int right = 0;\n    // 词频表\n    Map<Character, Integer> freq = new HashMap<>();\n    int maxCount = 0;\n\n    while (right < s.length()) {\n        // 如果当前字符已经被访问过，则right不动，left++\n        if (freq.containsKey(s.charAt(right))) {\n            // 清掉left的字符的频次\n            freq.remove(s.charAt(left));\n            // 此时[left, right-1]区间即为一个局部不重复子串区间\n            // 更新最大值\n            maxCount = Math.max(maxCount, (right - left));\n            // left右移\n            left++;\n        } else {\n            // 如果当前字符没有被访问过，righ++\n            // 先更新当前字符的词频\n            freq.put(s.charAt(right), 1);\n            // right右移\n            right++;\n        }\n    }\n    // 跳出后还要额外判断一次当前的left和right间的距离\n    maxCount = Math.max(maxCount, (right - left));\n    return maxCount;\n}\n```\n\n\n\n### 最小覆盖子串\n\n[76. 最小覆盖子串](https://leetcode-cn.com/problems/minimum-window-substring/)：给你一个字符串 `s` 、一个字符串 `t` 。返回 `s` 中涵盖 `t` 所有字符的最小子串。如果 `s` 中不存在涵盖 `t` 所有字符的子串，则返回空字符串 `\"\"` 。\n\n**注意：**\n\n- 对于 `t` 中重复字符，我们寻找的子字符串中该字符数量必须不少于 `t` 中该字符数量。\n- 如果 `s` 中存在这样的子串，我们保证它是唯一的答案。\n\n示例 ：\n\n```\n输入：s = \"ADOBECODEBANC\", t = \"ABC\"\n输出：\"BANC\"\n```\n\n代码：\n\n```java\npublic String minWindow(String s, String t) {\n    if (s.length() < t.length()) {\n        return \"\";\n    }\n    char[] schar = s.toCharArray();\n    char[] tchar = t.toCharArray();\n\n    // 先准备一个词频表\n    int[] map = new int[256];\n    // 记录“欠的总债”\n    int all = t.length();\n    for (char curr : tchar) {\n        // 每个字符的词频加一，即先记录下来“欠的债”\n        // 将在后面被不断还债\n        map[curr]++;\n    }\n\n    // 用于记录待返回的答案\n    int minLength = Integer.MAX_VALUE;\n    int ansl = -1;\n    int ansr = -1;\n\n    // [left, right)：左闭右开，left == right 时代表区间内没有元素\n    int left = 0;\n    int right = 0;\n\n    // right 右移的过程，是在不断“还债”，词频表里的当前字符的频率值不断减少\n    // left  右移的过程，是在不断“欠债”，词频表里的当前字符的频率值不断增加\n    // right 在到达 s 字符串的末尾前一直循环\n    while (right < s.length()) {\n        // 先把当前 right 位置的词频减一（还一次债）\n        map[schar[right]]--;\n\n        // 判断减一后的词频是否大于等于0\n        if (map[schar[right]] >= 0) {\n            // 如果当前字符在还了一次债后还是大于等于0，\n            // 说明当前还债是一次有效还债，总债数 all 需要减一\n            all--;\n        }\n        // 当 right 到了某个位置后满足 all == 0 的条件时，说明找到了一个局部子串\n        // 但是该区间不一定是最短的，因此 left 该开始右移了\n        // 开始不断右移 left，直到某个位置的 left 与 right 一起构成局部最小子串\n        if (all == 0) {         \n            // 当前字符的词频不断增加，直到其重新等于0（该过程就是在不断欠债）\n            // 目的是让之前词频小于0的字符的词频重新回到0。\n            // 这些字符在之前还债时词频不断--，小于了0（可以理解为多还了这些债，是一种浪费，导致子串变长），那些词频等于0的就是没有多还债的，不是浪费，需要保留的\n            // 注意，在这个过程中，是一直满足 all == 0 的，不会令任意一个词频大于 0 的\n            // 因为一旦词频等于了0，就退出了 while 循环\n            // 当前位置词频小于0，说明 left 能往右移动\n            while (map[schar[left]] < 0) {\n                map[schar[left++]]++;\n            }\n            // 跳出 while 循环的时机是，left 来到了一个出现在 s 中的字符，\n            // 这个字符当前的词频等于0，说明不能再欠债了，否则其词频就大于0了，all就大于0了\n            // [left,right] 的位置就是局部的最小子串\n            \n            // 解释肯定是在 s 中的字符的原因：因为不在 s 中的字符，其词频上限就是0。\n            // 一旦这些字符在前面有还债，那么其对应的词频肯定小于0，不可能会等于0，\n            // 因此这里等于0的肯定是那些在 s 中的字符，其在left右移欠债的过程中，使得其词频从负转为0，\n            // 因此此时就不能再右移left了，否则all就会大于0了，就不是最小子串了。我们要保证整个过程中 all 一直等于0\n            \n            // 保存该值\n            if (minLength > (right - left + 1)) {\n                minLength = right - left + 1;\n                ansl = left;\n                ansr = right;\n            }\n            // 找到了一个局部最小子串后，left 需要继续右移，开始寻找新的局部子串\n            // 人为增加一个all，为了是让 right 继续向右寻找新的局部子串\n            all++;\n            map[schar[left++]]++;\n        }\n        // left 此时已经调整到了局部最小子串的位置，接下来继续移动 right，进行新的“还债”过程\n        right++;\n\n    }\n    // 注意 substring 方法是左闭右开的 [ansl, ansr + 1)，所以 ansr 要加一\n    return minLength == Integer.MAX_VALUE ? \"\" : s.substring(ansl, ansr + 1);\n}\n```\n\n\n\n### K 个不同整数的子数组\n\n[992. K 个不同整数的子数组](https://leetcode-cn.com/problems/subarrays-with-k-different-integers/)：给定一个正整数数组 A，如果 A 的某个子数组中不同整数的个数恰好为 K，则称 A 的这个连续、不一定不同的子数组为好子数组。返回 A 中好子数组的数目。\n\n> 例如，[1,2,3,1,2] 中有 3 个不同的整数：1，2，以及 3。\n\n思路：将恰好有 K 个不同整数的问题转换为 “最多有 K 个不同” - “最多有 K-1 个不同”\n\n代码：\n\n``` java\npublic int subarraysWithKDistinct(int[] nums, int k) {\n    // 将恰好有 K 个不同整数的问题转换为 “最多有 K 个不同” - “最多有 K-1 个不同”\n    return atMostKDistinct(nums, k) - atMostKDistinct(nums, k-1);\n}\n\npublic int atMostKDistinct(int[] nums, int k) {\n    // 题目条件：1 <= A[i] <= A.length，因此词频表的范围最大就是 nums.length-1\n    // 创建词频表\n    int[] map = new int[nums.length + 1];\n\n    // [left, right)：左闭右开的范围内存储着符合题意的“最多有K个不同整数”的子数组\n    int left = 0;\n    int right = 0;\n    // 记录当前子数组[left, right)中，存在的不同整数的种类数\n    // 当该种类数大于K时，说明不符合题目中最多有K个的条件，此时就需要left++\n    int kinds = 0; \n    // 记录返回结果\n    int res = 0;\n\n    while (right < nums.length) {\n        // 如果当前的right位置的词频为0，说明这个种类目前还没计算过，则kinds+1\n        // 记得词频也要++\n        if (map[nums[right]]++ == 0) {\n            kinds++;\n        }\n        // 无论当前的right是否遇到新的种类，都要后移，因为子数组的区间是[left, right)，\n        // 是不包含right在内的，因此right就算后移也不影响，计算子数组长度时是不会算上这一位的\n        right++;\n\n        // 如果 kinds 大于了 K，说明上面那一步的kinds++导致子数组加入了一个新种类，因此需要left右移来抵消这个增加了\n        // 当left右移时，当遇到某个词频要归零了，就说明这个种类要消失了，也就和刚才的kind++抵消掉了，重新符合了题意的最多K个\n        // 一直循环着，直到 kinds == k，才会继续到下面的 res += right - left，否则算出来的就不是最多有K个了\n        while (kinds > k) {\n            // 当前left位置的词频为1，说明这个种类是目前子数组中的唯一一个，将其剔除后，kinds就要减一了\n            if (map[nums[left]]-- == 1) {\n                kinds--;\n            }\n            // 无论当前的left位置的数字是否即将消失，都需要left++，因为无论是否抵消，left都要右移来减小区间范围\n            // 1. left 位置的数字要抵消了，那么肯定要left++\n            // 2. left 位置的数字的词频还大于0，说明后面还有该数字呢，肯定也要left++\n            left++;\n        }\n\n        // 注意是左闭右开[left, right)，不能把right这一位算进去，因为这一位在上面的 right++ 里多移动了，是出于开区间的\n        res += right - left;\n    }\n\n    return res;\n}\n```\n\n\n\n### 三个无重叠子数组的最大和\n\n[689. 三个无重叠子数组的最大和](https://leetcode-cn.com/problems/maximum-sum-of-3-non-overlapping-subarrays/)：给你一个整数数组 nums 和一个整数 k ，找出三个长度为 k 、互不重叠、且 3 * k 项的和最大的子数组，并返回这三个子数组。以下标的数组形式返回结果，数组中的每一项分别指示每个子数组的起始位置（下标从 0 开始）。如果有多个结果，返回字典序最小的一个。\n\n示例 1：\n\n``` \n输入：nums = [1,2,1,2,6,7,5,1], k = 2\n输出：[0,3,5]\n解释：子数组 [1, 2], [2, 6], [7, 5] 对应的起始下标为 [0, 3, 5]。\n也可以取 [2, 1], 但是结果 [1, 3, 5] 在字典序上更大。\n```\n\n示例 2：\n\n``` \n输入：nums = [1,2,1,2,1,2,1,2,1], k = 2\n输出：[0,2,4]\n```\n\n思路：我们使用三个大小为 k 的滑动窗口。设 sum1 为第一个滑动窗口的元素和，该滑动窗口从 [0, k-1] 开始；sum2 为第二个滑动窗口的元素和，该滑动窗口从 [k, 2k-1] 开始；sum3 为第三个滑动窗口的元素和，该滑动窗口从 [2k, 3k-1] 开始。\n\n我们同时向右滑动这三个窗口，维护 maxSum12 及其对应位置。每次滑动时，计算当前 maxSum12 与 sum3 之和。统计这一过程中的 maxSum12 + sum3 的最大值及其对应位置。\n\n代码：\n\n``` java\npublic int[] maxSumOfThreeSubarrays(int[] nums, int k) {\n    int[] ans = new int[3];\n    int sum1 = 0, maxSum1 = 0, maxSum1Idx = 0;\n    int sum2 = 0, maxSum12 = 0, maxSum12Idx1 = 0, maxSum12Idx2 = 0;\n    int sum3 = 0, maxTotal = 0;\n    for (int i = k * 2; i < nums.length; ++i) {\n        sum1 += nums[i - k * 2];\n        sum2 += nums[i - k];\n        sum3 += nums[i];\n        if (i >= k * 3 - 1) {\n            if (sum1 > maxSum1) {\n                maxSum1 = sum1;\n                maxSum1Idx = i - k * 3 + 1;\n            }\n            if (maxSum1 + sum2 > maxSum12) {\n                maxSum12 = maxSum1 + sum2;\n                maxSum12Idx1 = maxSum1Idx;\n                maxSum12Idx2 = i - k * 2 + 1;\n            }\n            if (maxSum12 + sum3 > maxTotal) {\n                maxTotal = maxSum12 + sum3;\n                ans[0] = maxSum12Idx1;\n                ans[1] = maxSum12Idx2;\n                ans[2] = i - k + 1;\n            }\n            sum1 -= nums[i - k * 3 + 1];\n            sum2 -= nums[i - k * 2 + 1];\n            sum3 -= nums[i - k + 1];\n        }\n    }\n    return ans;\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n## 滑动窗口中的双端队列\n\n由该题引出滑动窗口问题中常使用的双端队列，用于维护当前窗口区间内的最大/小值。\n\n### 维持窗口内部最大值或者最小值\n\n![image-20211125143219920](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/image-20211125143219920.png)\n\n窗口只能右边界或左边界向右滑的情况下，维持窗口内部最大值或者最小值快速更新的结构。\n\n思路：使用一个**双端队列**，在其内保存当前窗口内的**索引值**（不保存数值，保存索引值，用于在左指针移动时判断队首的索引值是否等于旧的左指针的索引值（要淘汰的）），并且保证队列内的元素大小是递增或递减的且不能相等（对应求窗口内的最小值或最大值）。其**含义**是：如果此时形成的窗口状况不想让右指针向右移动而让左指针向右移动，哪个元素会成为最大/小值的**优先级**。\n\n以求窗口内的最大值为例：\n\n- 定义左右指针边界，一起向右移动\n- 先将当前窗口内队首索引值对应的元素值获取到，赋值给要返回给用户的数组 `res[]` 中，代表获取到了当前窗口内的最大值。然后窗口**即将整体右移**（体现在左右指针先后右移）\n- 左指针先右移，**判断当前队首元素的索引值是否等于左指针右移前的位置的索引值**。目的是：左指针一旦右移，说明左指针指向的前一个位置**已经离开了窗口范围**，该位置需要从队列中**淘汰掉**。如果队首元素的**索引值**等于这个旧的**索引值**，说明队首的这个元素已经要离开窗口范围了（因为窗口整体更新右移了），因此将该元素**从队列中弹出**。注意队列中存储的是索引值而不是元素值，要判断刚离开的左指针的位置是否等于队首的索引值。\n- 右指针后右移，判断当前队尾元素是否小于等于当前元素\n  - 若是，则说明之前窗口内有某些元素的值小于当前新加入的元素，则这些比较小的元素肯定不会是新的窗口内的最大值了，那么就直接将其踢出队列，不再使用。重复进行该过程，直到没有队尾元素比当前元素大，或为空\n  - 若不是，则说明之前窗口内的所有元素值都比当前新加入的元素大，则不需要踢出之前的元素\n  - 最后将当前元素的索引值加入到队尾\n  - 注意相等的情况也是要移出队列的，因为之前的元素是旧的，现在来的是新的，要保证队列里保存又新又大的元素的**索引**\n- 重复进行上述过程，直到左指针来到 `nums.length - (w - 1)` 的位置时，说明到底了，直接跳出循环返回答案\n\n> 如果一个数又旧又小，那一定不是最大值。在队列里的值，要么更新，要么更大。\n\n时间复杂度分析：\n\n- 队列总的更新时间代价为 `O(N)`，因为数组中每个元素都只进出一次队列，丢掉的不在找回，而且左指针和右指针都在一起向右移动，不回头\n- 队列单次的更新时间代价为 `O(N) / N = O(1)`\n\n若采用最直接的遍历，时间复杂度是 `O(M*N)`。其中，M 是窗口内元素的个数，因为要遍历窗口内的元素才能取得最大值。\n\n代码：\n\n```java\npublic static int[] getMaxWindow(int[] nums, int w) {\n    if (nums == null || nums.length < w || w < 1) {\n        return null;\n    }\n\n    Deque<Integer> queueMax = new LinkedList<>();\n    // 先创建出来第一个窗口\n    for (int i = 0; i < w; i++) {\n        // 如果队尾元素小于等于当前元素，则队尾元素弹出（代表该元素不可能为当前窗口内的最大值了，直接丢弃）\n        if (!queueMax.isEmpty() && nums[queueMax.peekLast()] <= nums[i]) {\n            queueMax.pollLast();\n        }\n        // 直到队尾元素大于当前元素时停止弹出，将当前元素的索引加入队列\n        // 注意要加入的是索引而不是值\n        queueMax.addLast(i);\n    }\n\n    // 初始化两个指针位置，一个在0位置，一个在w-1位置\n    int left = 0;\n    int right = w - 1;\n    // 要返回的数组的长度是 nums.length - w + 1，注意不要忘了加一\n    int[] res = new int[nums.length - w + 1];\n\n    // right 一直遍历到数组尾部\n    while (right < nums.length) {\n        // left 指向当前位置索引\n        // 先将队列中的队首元素添加到res中，其就是当前窗口内的最大值\n        // 注意不能弹出，只是获取该值。要在该元素过期时才弹出\n        res[left++] = nums[queueMax.peekFirst()];\n\n        // 此时的 left -1 就是已经过期的元素，需要弹出\n        if (left - 1 == queueMax.peekFirst()) {\n            queueMax.pollFirst();\n        }\n\n        // 若成立，则说明窗口走到尽头了，不能再往下继续right++了，要越界了，直接break;\n        if (left == nums.length - (w - 1)) {\n            break;\n        }\n\n        // 此时 left 已经右移了一位，窗口需要整体右移，因此该 right 右移了\n        right++;\n        // right 右移时，需要将新的 right 加入到队列中，更新窗口内的最大值\n\t\t// 注意相等的情况也是要移出队列的，因为之前的元素是旧的，现在来的是新的\n        while (!queueMax.isEmpty() && nums[queueMax.peekLast()] <= nums[right]) {\n            queueMax.pollLast();\n        }\n        queueMax.addLast(right);\n    }\n\n    return res;\n}\n\n\npublic static int[] getMaxWindow1(int[] arr, int w) {\n    if (arr == null || w < 1 || arr.length < w) {\n        return null;\n    }\n    LinkedList<Integer> qmax = new LinkedList<Integer>();\n    int[] res = new int[arr.length - w + 1];\n    int index = 0;\n    for (int i = 0; i < arr.length; i++) {  // 窗口的 R\n        while (!qmax.isEmpty() && arr[qmax.peekLast()] <= arr[i]) {\n            qmax.pollLast();\n        }\n        qmax.addLast(i);\n        if (qmax.peekFirst() == i - w) { // i-w ：过期的下标\n            qmax.pollFirst();  // 这里的i-w已经是过期了的，不在当前窗口里的了\n        }\n        if (i >= w - 1) { // 窗口形成了 i 从 W-1 开始，窗口已经形成了\n            res[index++] = arr[qmax.peekFirst()];\n        }\n    }\n    return res;\n}\n\n// for test\npublic static void printArray(int[] arr) {\n    for (int i = 0; i != arr.length; i++) {\n        System.out.print(arr[i] + \" \");\n    }\n    System.out.println();\n}\n\npublic static void main(String[] args) {\n    int[] arr = { 4, 3, 5, 4, 3, 3, 6, 7 };\n    int w = 3;\n    printArray(getMaxWindow(arr, w));\n}\n```\n\n\n\n### 达标子数组的数量\n\n给定一个整型数组 nums 和一个整数 threshold，某个 nums 中的子数组 sub 如果想达标必须满足：sub 中的最大值 - sub 中的最小值 <= num。返回 nums 中达标子数组的数量。\n\n思路：使用两个双端队列分别维护当前窗口内的最大值和最小值。然后以每个 left 为左边界，不断移动 right 直到不达标，计算以该 left 为左边界时的达标子数组数量。接着 left++，继续该过程，计算以此时的 left 为左边界时的达标子数组数量。\n\n代码：\n\n```java\npublic static int allLessNumSubArray(int[] nums, int threshold) {\n    // 区间：[left, right) 左闭右开，right 代表可行的区间右边界的下一个元素\n    int left = 0;\n    int right = 0;\n\n    // 两个双端队列\n    Deque<Integer> minQueue = new LinkedList<>();\n    Deque<Integer> maxQueue = new LinkedList<>();\n\n    int count = 0;\n\n    // 外层循环不断移动 left，计算出以每个 left 为左边界的区间包含几个符合题意的子数组\n    while (left < nums.length) {\n        while (right < nums.length) {\n            // 注意：以下的更新队列内容很可能对同一个 right 重复执行多次，因为每次 left 更新后，之前已经处理过的 right 还会再判断一次，不过并不影响结果\n            // 更新最小值队列\n            while (!minQueue.isEmpty() && nums[minQueue.peekLast()] >= nums[right]) {\n                minQueue.pollLast();\n            }\n            // 注意队列维护的是索引信息\n            minQueue.addLast(right);\n            // 更新最大值队列\n            while (!maxQueue.isEmpty() && nums[maxQueue.peekLast()] <= nums[right]) {\n                maxQueue.pollLast();\n            }\n            // 注意队列维护的是索引信息\n            maxQueue.addLast(right);\n\n            // 如果当前最大值和最小值大于了阈值，则当前 right 不能继续右移了，要更新当前 [left, right) 区间内的子区间总数\n            // 注意队列维护的是索引信息\n            if (nums[maxQueue.getFirst()] - nums[minQueue.getFirst()] > threshold) {\n                break;\n            }\n\n            right++;\n        }\n\n        // 更新当前 [left, right) 区间内的子区间总数\n        count += right - left;\n\n        // 如果最小最大队列里的队首索引等于当前位置，则弹出\n        if (minQueue.peekFirst() == left) {\n            minQueue.pollFirst();\n        }\n        if (maxQueue.peekFirst() == left) {\n            maxQueue.pollFirst();\n        }\n\n        // 当前位置遍历完毕后，右移 left 继续计算以该值为左边界的区间包含几个符合题意的子数组\n        left++;\n    }\n    return count;\n}\n```\n\n\n\n\n\n必须以当前值为最小值的最长子数组（越长累加和越大）\n\n\n\n\n\n\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"【算法】位运算","url":"/2021/11/24/【算法】位运算/","content":"\n## 位运算\n\n### 位运算技巧\n\n位移运算：\n\n``` java\n// 有符号右移，会在最高位自动补 1\nn >> 1;\n// 无符号右移，最高位不会补 1\nn >>> 1;\n```\n\n获取每个数字最右侧为 1 的位数：\n\n``` java\n// 以补码加一的形式将 n 取相反数\nrightOne = n & (~n + 1);\n// 等价于直接取反\nrightOne = n & -n;\n```\n\n将二进制数字 n 最右侧的 1 变为 0，其余不变：\n\n```java\n// 最右侧的 1 变为 0，此 1 右边的 0 都变为 1\nn = n - 1;\n// 最右侧的 1 变为 0\nn = n & (n - 1);\n```\n\n统计二进制中 1 的个数：\n\n``` java\npublic int hammingWeight(int n) {\n    // 遍历 0-31 位，记录有几个 1\n    int res = 0;\n    while (n != 0) {\n        // 累加上当前位\n        res += n & 1;\n        // 注意是无符号右移\n        n >>>= 1;\n    }\n    return res;\n}\n```\n\n判断某个数字的符号：\n\n``` java\n// 负数的最高位为 1，正数的最高位为 0\n// n 先右移 31 位，得到其最高位的值，然后与 1 取异或，即可得到其符号\n// 如果 n 为负数，其最高位 1 经过异或就是 0，反之就是 1\nint sign = ((n >> 31) & 1) ^ 1;\n```\n\n判断一个 32 位正数是不是 2 的幂、4 的幂：\n\n``` java\n// 如果是2的幂，则其二进制位上只可能有一位为1，其他位都是0\n// 例如 4：00000100  8:00001000。一次移动一位\n// 这样其与自身减去一取与，得到的就是0。因为所有1都错位了\npublic static boolean is2Power(int n) {\n    // 将最右侧的 1 变为 0\n    return (n & (n - 1)) != 0;\n}\n\n// 如果是4的幂，前提得是2的幂。\n// 然后找规律，4的幂的数字只可能有一位是1，并且该位肯定是在第1,2,4,6,8,10...中的某一个，其他位都为0\n// 例如 16：00010000  32:0010000。一次移动两位\npublic static boolean is4Power(int n) {\n    // 0x55555555：010101....01010101。0101四位组成一个0x5，共8个\n    return (n & (n - 1)) != 0 && (n & 0x55555555) != 0;\n}\n```\n\n使用位运算完成取相反数操作：\n\n``` java\n// 一个数的相反数 = 该数取补码 + 1\npublic static int negNum(int n) {\n    return ~n + 1;\n}\n```\n\n判断数字奇偶性：\n\n``` java\nx & 1;  // 因为如果 x 的最低位为1，则代表其肯定是某一个2的倍数加上了1，所以肯定是奇数\n// 等价于\nx % 2;\n```\n\n<!-- More -->\n\n### 位图\n\n位图：bit 为单位的数组。\n\n基本数据类型数组的 bit 情况：\n\n- boolean[] 数组每个元素占 8 bits（1 byte = 8 bits）\n- int[] 数组每个元素占 32 bits（8 byte = 32 bits）\n\n直接使用基本数据类型无法创建每个元素为一个bit的位图。那么我们可以考虑将基本数据类型数组拆为位图。例如可以使用 int[] 数组作为位图：\n\n``` java\nint[] arr = new int[10]; // 320 bits\n```\n\n那么如果我们想要得到第 178 个 bit 位置的数值时，我们可以：\n\n``` java\nint numIndex = 178 / 32;  // 获取第178个bit在arr[]的哪个索引位置上\nint bitIndex = 178 % 32;  // 获取第178个bit在该索引位置的int数值的哪一位上（32bits中的哪一个）\n\n// 将第bitIndex位移动到该数的最右侧（最低位），通过位移动和与1取&实现\n// 注意移动的位数是32 - bitIndex，因为低位在右侧，高位在左侧，第bitIndex位想要移动到最右侧需要移动32 - bitIndex\nint state = (arr[numIndex] >> (32 - bitIndex) & 1)\n```\n\n若想将该位的状态改为1，则可以：\n\n``` java\narr[numIndex] = arr[numIndex] || (1 << (32 - bitIndex));\n```\n\n若想将该位的状态改为0，则可以：\n\n``` java\narr[numIndex] = arr[numIndex] & (~(1 << (32 - bitIndex)));\n```\n\n\n\n\n\n## 位运算常见题目\n\n### 仅使用位运算比较数字大小\n\n给定两个有符号 32 位整数 a 和 b，不用做任何比较判断，返回 a 和 b 中较大的。\n\n``` java\npublic static int flip(int n) {\n    return n ^ 1;\n}\n\npublic static int sign(int n) {\n    return flip((n >> 31) & 1);\n}\n\n// 方法一：当 a 为正数，b 为负数时可能发生溢出\npublic static int getMax1(int a, int b) {\n    int c = a - b;\n    int scA = sign(c);\n    int scB = flip(scA);\n    return a * scA + b * scB;\n}\n\n// 方法二：不会溢出\npublic static int getMax2(int a, int b) {\n    int c = a - b;\n    int sa = sign(a);\n    int sb = sign(b);\n    int sc = sign(c);\n    int difSab = sa ^ sb;\n    int sameSab = flip(difSab);\n    int returnA = difSab * sa + sameSab * sc;\n    int returnB = flip(returnA);\n    return a * returnA + b * returnB;\n}\n\npublic static void main(String[] args) {\n    int a = -16;\n    int b = 1;\n    System.out.println(getMax1(a, b));\n    System.out.println(getMax2(a, b));\n    a = 2147483647;\n    b = -2147480000;\n    System.out.println(getMax1(a, b)); // wrong answer because of overflow\n    System.out.println(getMax2(a, b));\n\n}\n```\n\n### 仅使用位运算实现加减乘除\n\n> https://www.bilibili.com/video/BV13g41157hK?p=15\n\n给定两个有符号 32 位整数 a 和 b，不能使用算术运算符，分别实现 a 和 b 的加、减、乘、除运算。\n\n#### 加法\n\n- 异或运算 ^ （`a ^ b`）：两个数**无进位相加**的结果\n- 与运算 & 后再左移一位（`(a & b) << 1`）：两个数的进位结果\n\n使用这两个运算即可实现加法：进位相加结果加上进位结果就是二者的和，因此可以一直重复该过程直到进位结果为 0。具体做法是一直计算 `a ^ b` 和 `(a & b) << 1`，直到 `(a & b) << 1 == 0`，说明不再有进位信息了，则两个数的相加结果就是此时的 `a ^ b`。\n\n``` java\npublic static int add(int a, int b) {\n    int sum = a;\n    // 当 b == 0 时，代表此时的无进位相加结果就是最终结果（因为没进位了）\n    while (b != 0) {\n        // 无进位相加结果\n        sum = a ^ b;\n        // a + b 的结果等于 (a ^ b) + ((a & b) << 1)\n        // 那么就更新计算目标，使得 a =  (a ^ b)，b = (a & b) << 1\n        \n        // 更新 b 为进位结果\n        b = (a & b) << 1;\n        // 更新 a 为二者无进位相加结果\n        a = sum;\n    }\n    return sum;\n}\n```\n\n#### 减法\n\n`a - b` 可以转换为 `a + (-b)`。因此取 b 的相反数后即可使用加法运算得到 `a - b` 的结果。\n\n``` java\n// 一个数的相反数 = 该数取补码 + 1\npublic static int negNum(int n) {\n    return add(~n, 1);\n}\n\n// 减法\npublic static int minus(int a, int b) {\n    return add(a, negNum(b));\n}\n```\n\n#### 乘法\n\n二进制进行乘法 `a * b` 时，每次判断当前的 b 的最右位是否为 1，若是则对 a 左移一位后累加到当前结果中，然后 b 右移一位，继续判断当前 b 的最右位是否为 1，若不是则不累加当前结果，仍然左移 a，右移 b。重复该过程直至 `b == 0`。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/image-20211207154803047.png\" alt=\"image-20211207154803047\" style=\"zoom: 33%;\" />\n\n``` java\npublic static int multi(int a, int b) {\n    int res = 0;\n    while (b != 0) {\n        if ((b & 1) != 0) {\n            res = add(res, a);\n        }\n        a <<= 1;\n        b >>>= 1;\n    }\n    return res;\n}\n```\n\n#### 除法\n\n二进制的除法其实就是乘法的逆序。先将 b 左移到最左侧的比 a 小的位置，在该位置记1，代表 `a / b` 的最大值在该位置；然后 b 左移到最左侧的右侧某一个比 a 小的位置，再将该位置记1，代表 `a / b` 的第二大位置在该位置……重复该过程直到 b 不能在往左侧移动，即完成了除法。\n\n> 注意：在实现时因为 b 左移可能会溢出，因此改用 a 右移到最左侧比 b 的位置，来取代 b 左移。\n\n``` java\n// 一个数的相反数 = 该数取补码 + 1\npublic static int negNum(int n) {\n    return add(~n, 1);\n}\n\npublic static boolean isNeg(int n) {\n    return n < 0;\n}\n\npublic static int div(int a, int b) {\n    int x = isNeg(a) ? negNum(a) : a;\n    int y = isNeg(b) ? negNum(b) : b;\n    int res = 0;\n    for (int i = 31; i > -1; i = minus(i, 1)) {\n        if ((x >> i) >= y) {\n            res |= (1 << i);\n            x = minus(x, y << i);\n        }\n    }\n    return isNeg(a) ^ isNeg(b) ? negNum(res) : res;\n}\n\npublic static int divide(int a, int b) {\n    if (b == 0) {\n        throw new RuntimeException(\"divisor is 0\");\n    }\n    if (a == Integer.MIN_VALUE && b == Integer.MIN_VALUE) {\n        return 1;\n    } else if (b == Integer.MIN_VALUE) {\n        return 0;\n    } else if (a == Integer.MIN_VALUE) {\n        int res = div(add(a, 1), b);\n        return add(res, div(minus(a, multi(res, b)), b));\n    } else {\n        return div(a, b);\n    }\n}\n\n// 测试\npublic static void main(String[] args) {\n    int a = (int) (Math.random() * 100000) - 50000;\n    int b = (int) (Math.random() * 100000) - 50000;\n    System.out.println(\"a = \" + a + \", b = \" + b);\n    System.out.println(add(a, b));\n    System.out.println(a + b);\n    System.out.println(\"=========\");\n    System.out.println(minus(a, b));\n    System.out.println(a - b);\n    System.out.println(\"=========\");\n    System.out.println(multi(a, b));\n    System.out.println(a * b);\n    System.out.println(\"=========\");\n    System.out.println(divide(a, b));\n    System.out.println(a / b);\n    System.out.println(\"=========\");\n\n    a = Integer.MIN_VALUE;\n    b = 32;\n    System.out.println(divide(a, b));\n    System.out.println(a / b);\n}\n```\n\n\n\n### Pow(a, b)\n\n#### 方法一：递归\n\n![image-20211214211359973](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/image-20211214211359973.png)\n\n代码：\n\n``` java\nclass Solution {\n    public double myPow(double x, int n) {\n        long N = n;\n        return N >= 0 ? quickMul(x, N) : 1.0 / quickMul(x, -N);\n    }\n\n    public double quickMul(double x, long N) {\n        if (N == 0) {\n            return 1.0;\n        }\n        double y = quickMul(x, N / 2);\n        return N % 2 == 0 ? y * y : y * y * x;\n    }\n}\n```\n\n#### 方法二：位运算技巧\n\n![image-20211214211721186](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/image-20211214211721186.png)\n\n![image-20211214211931855](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/image-20211214211931855.png)\n\n将幂的大小进行二进制拆分，将二进制位为1的组分进行相乘即可得到的答案。\n\n代码：\n\n``` java\nclass Solution {\n    public double myPow(double x, int n) {\n        // 记得先转换成long，防止n转换成相反数时溢出。例如n取最小的负数时，其相反数会溢出\n        long N = n;\n        return N >= 0 ? quickMulti(x, N) : quickMulti(1.0 / x, -N);\n    }\n\n    public double quickMulti(double x, long n) {\n        double res = 1.0;\n        // 当前的累积：x^1 * x^2 * x^4 * x^8 ...\n        // 每次 tmp 变为 tmp * tmp，代表不断向高位移动\n        double tmp = x;\n        // n 每次右移一位，判断当前最低位是否是1，如果是则累乘上res，否则不乘\n        for (; n > 0; n >>= 1) {\n            if ((n & 1) == 1) {\n                res *= tmp;\n            }\n            // tmp 不断向高位移动\n            tmp *= tmp;\n        }\n        return res;\n    }\n}\n```\n\n\n\n### 数组中数字出现的次数\n\n[剑指 Offer 56 - II. 数组中数字出现的次数 II](https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-ii-lcof/)：在一个数组 `nums` 中除一个数字只出现一次之外，其他数字都出现了三次。请找出那个只出现一次的数字。\n\n#### 方法一：哈希表记录\n\n最简单的方式就是使用哈希表记录每个数字出现的频次，最后选出只有一次的。该方法空间复杂度较高。\n\n#### 方法二：遍历统计\n\n思路：遍历一遍数组，统计每个数字的 32 位二进制数字出现的频次，存放在数组中，最后遍历 32 位的每一位，计算当前位为 1 的数量，**对 3 取余**，那么最后剩下的数字就是只出现过一次的数字，那些出现 3 次的数字对 3 取余后为 0。需要特别注意位数组的顺序。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/28f2379be5beccb877c8f1586d8673a256594e0fc45422b03773b8d4c8418825-Picture1.png\" alt=\"Picture1.png\" style=\"zoom: 67%;\" />\n\n代码：\n\n``` java\npublic int singleNumber(int[] nums) {\n    // 遍历一遍数组，统计每个数字的32位二进制数字，存放在数组中，最后遍历32位的每一位，计算当前位为1的数量，对3取余\n    int[] count = new int[32];\n    for (int num : nums) {\n        for (int i = 31; i >= 0; i--) {\n            // 从低位向高位遍历，将当前位的数字存放到count对应位置中，然后num无符号右移，代表将比较新的低位\n            // 注意每次比较的都是当前num的最低位，所以count中保存的顺序是：从高位到低位\n            count[i] += num & 1;\n            num >>>= 1;\n        }\n    }\n\n    // 全部加入到count数组后，开始遍历每一位，计算所有位上数量和对m取余的结果，将其拼接起来就是那个只出现过一次的数字\n    int res = 0;\n    for (int i = 0; i < 32; i++) {\n        // res就是目标数字在当前位的二进制值\n        // 因为res左移后新出现的低位为0，所以要用或运算\n        // % 3 的结果要么是0要么是1\n        res |= count[i] % 3;\n        // 除了最低位以外，每次取得当前位的值后都要左移以将当前为移动到应该在的地方\n        // 但是注意在最低位时不能再移动了，否则就会多移动一次，因为i=31处理完后没有下一位需要判断了，也就不需要移动了\n        // 或者将左移放到 res |= 的上一行，也能表示最后一位处理完不再左移\n        if (i != 31) {\n            res <<= 1;\n        }\n    }\n    return res;\n}\n```\n\n#### 方法三：有限状态机（最佳）\n\n使用有限状态机来统计每个数字的每一位出现的次数，但不通过数组保存的方式，而是通过有限状态机来进行统计：\n\n对于所有数字中的某二进制位 1 的个数，存在 3 种状态，即对 3 余数为 0, 1, 2。\n\n- 若输入二进制位 1 ，则状态按照以下顺序转换；\n- 若输入二进制位 0 ，则状态不变。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/ab00d4d1ad961a3cd4fc1840e34866992571162096000325e7ce10ff75fda770-Picture2.png\" alt=\"Picture2.png\" style=\"zoom:50%;\" />\n\n如下图所示，由于二进制只能表示 0, 1，因此需要使用两个二进制位来表示 3 个状态。设此两位分别为 two, one，则状态转换变为：00 → 01 → 10 → 00 → ⋯\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/0a7ea5bca055b095673620d8bb4c98ef6c610a22f999294ed11ae35d43621e93-Picture3.png\" alt=\"Picture3.png\" style=\"zoom:50%;\" />\n\n接下来，需要通过 **状态转换表** 导出 **状态转换的计算公式** 。\n\n**计算 one 方法：**\n\n设当前状态为 two one，此时输入二进制位 n 。如下图所示，通过对状态表的情况拆分，可推出 one 的计算方法为：\n\n``` java\nif two == 0:\n  if n == 0:\n    one = one\n  if n == 1:\n    one = ~one\nif two == 1:\n    one = 0\n```\n\n引入 **异或运算** ，可将以上拆分简化为：\n\n``` java\nif two == 0:\n    one = one ^ n\nif two == 1:\n    one = 0\n```\n\n引入 **与运算** ，可继续简化为：\n\n``` java\none = one ^ n & ~two\n```\n\n![Picture4.png](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/f75d89219ad93c69757b187c64784b4c7a57dce7911884fe82f14073d654d32f-Picture4.png)\n\n**计算 two 方法：**\n\n由于是先计算 one，因此应在新 one 的基础上计算 two 。如下图所示，修改为新 one 后，得到了新的状态图。观察发现，可以使用同样的方法计算 two ，即：\n\n``` java\ntwo = two ^ n & ~one\n```\n\n![Picture5.png](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/6ba76dba1ac98ee2bb982e011fdffd1df9a6963f157b2780461dbce453f0ded3-Picture5.png)\n\n\n\n以上是对数字的二进制中 “一位” 的分析，而 `int` 类型的其他 31 位具有相同的运算规则，因此可将以上公式直接套用在 32 位数上。\n\n遍历完所有数字后，各二进制位都处于状态 00 和状态 01 （取决于 “只出现一次的数字” 的各二进制位是 1 还是 0 ），而此两状态是由 one 来记录的（此两状态下 twos 恒为 00 ），因此返回 ones 即可。\n\n详细解释见：https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-ii-lcof/solution/ji-yu-krahetsda-lao-gei-chu-de-you-xian-67dkc/\n\n代码：\n\n``` java\npublic int singleNumber(int[] nums) {\n    int ones = 0, twos = 0;\n    for(int num : nums){\n        // 同时计算出32位上新的状态情况\n        // 记住规律背下来\n        ones = ones ^ num & ~twos;\n        twos = twos ^ num & ~ones;\n    }\n    // 全部算完后，twos肯定都是0，因为只有一个数只出现过一次，所以某一位不可能有2个，只可能是0或1，也就只在ones上\n    return ones;\n}\n```\n\n\n\n\n\n\n\n## 异或操作题目\n\n### 出现奇数次的数字\n\n题目：一个数组中，除了一个数字出现奇数次，其他数字都出现偶数次，找出这个数字。\n\n思路：可以使用异或操作实现。异或操作的性质：\n\n- a^a=0；自己和自己异或等于0\n- a^0=a；任何数字和0异或还等于他自己\n- a^b^c=a^c^b；异或运算具有交换律\n\n所以将整个数组进行异或，偶数次的数字和自己异或的结果为0，因此最后得到的结果就是那个出现奇数次的数字。\n\n示意图：\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/image-20211218194147466.png\" alt=\"image-20211218194147466\" style=\"zoom:50%;\" />\n\n代码：\n\n```java\npackage com.zhao;\n\npublic class Eor {\n\n    // 适用题目: 除了一个数字存在奇数次, 其他数字都存在偶数次\n    public static int singleNumber(int[] nums) {\n        int eor = 0;\n        for (int i = 0; i < nums.length; i++) {\n            eor = eor ^ nums[i];\n        }\n        // 连续异或得到的结果就是那个唯一出现奇数次的数字\n        return eor;\n    }\n}\n```\n\n\n\n### 出现偶数次的数字\n\n[剑指 Offer 56 - I. 数组中数字出现的次数](https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-lcof/)：一个数组中，除了**两个**数字出现奇数次，其他数字都出现偶数次，找出这两个数字。\n\n思路：可以使用异或操作实现，但需要一些技巧：\n\n- 首先将0与整个数组的元素进行异或，得到的结果为那两个出现奇数次的数字的异或： `eor = a ^ b`\n- 接着分析 eor 的特性：其不等于0，说明其8个bit上必定有某一位为1，那么就找出这一位。这里使用技巧找出 eor 最右侧的为1的位数：`rightOne = eor & (~eor + 1)`\n- 得到 `rightOne` 后，将整个数组里的元素分为两类：\n  - `rightOne` 位上为1的元素\n  - `rightOne` 位上不为1的元素\n- 只对其中的某一类元素进行累计求异或操作，得到的结果 `onlyOneEor` 就是a或b其中的某一个\n- 接着计算 `onlyOneEor ^ eor` 即可得到a或b中的另一个。\n- 至此找出了两个数字\n\n示意图：\n\n![image-20211218194213340](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BD%8D%E8%BF%90%E7%AE%97/image-20211218194213340.png)\n\n代码：\n\n``` java\n// 适用题目: 除了两个数字存在奇数次, 其他数字都存在偶数次\npublic static void twoSingleNumber(int[] nums) {\n    int eor = 0;\n    for (int n : nums) {\n        eor = eor ^ n;\n    }\n\n    // 连续异或结果就是那两个出现奇数次的数字a和b的异或 a ^ b\n    // eor != 0: 说明eor的8个位上必有一个为1, 且a和b在这一位上一个为1一个为0\n    int rightOne = eor & (~eor + 1); // 将eor最右侧位的1找出来\n\n    // 只将数组中最右侧位也为1的数字找出来, 目的是将a和b区分出来,因为二者只有一个这一位为1\n\n    int onlyOneEor = 0;\n    for (int n : nums) {\n        if ((n & rightOne) != 0)\n            onlyOneEor ^= n;\n    }\n\n    System.out.println(eor);\n    System.out.println((eor ^ onlyOneEor));\n}\n```\n\n\n\n\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"【算法】技巧总结","url":"/2021/11/24/【算法】技巧总结/","content":"\n## 常用 API\n\n### 数组\n\n初始化数组：\n\n``` java\n// 如果不赋值，则[]内需要指定大小\nint[] nums = new int[n];\n// 如果同时要赋值的话，[]内不带值\nint[] nums = new int[]{1,2,3,4};\n\n// 二维数组\nint[][] nums = new int[m][n];\nint[][] nums = new int[][]{{1,3},{1,2},{4,5},{3,7}};\n\n// 字符串数组的初始化与整型类似\nchar[] cstr = new char[n];\nchar[] cstr = new char[]{'a', 'b', 'c'};\n// 也可以从String对象中提取出对应的字符串数组\nchar[] cstr = new String(\"abc\").toCharArray();\n\n// String数组的初始化需要带()\nString[] str = new String[n];\nString[] str = new String[]{\"aaa\", \"bbb\", \"ccc\"};\n// 或者使用字面量形式\nString[] str = {\"aaa\", \"bbb\", \"ccc\"};\n```\n\n总结：初始化时，若要通过`{}`赋值，则数组的`[]`内不能带数字；如果不赋值，则必须要带数字。因为使用`{}`赋值时，编译器会根据赋值的数量自动算出数组长度，因此`[]`内就不能加数字了。\n\n数组操作：\n\n``` java\nint[][] nums = new int[][]{{1,3},{1,2},{4,5},{3,7}};\n\n// 根据二维数组的某一位进行排序\n// 最简洁的Lambda表达式\nArrays.sort(nums, (o1, o2) -> o1[0] - o2[0]);\n// 或可以写多行的形式\nArrays.sort(nums, (o1, o2) -> {\n    o1[0] - o2[0]\n});\n// 或匿名内部类\nArrays.sort(nums, new Comparator<int[]>() {\n    @Override\n    public int compare(int[] a, int[] b){\n        if(a[0]==b[0]){\n            return a[1] - b[1];\n        }else {\n            return a[0] - b[0];\n        }\n    }\n});\n\n\n// 对数组集合进行反转\nCollections.reverse(list);\n// 集合的排序\nCollections.sort(list, (o1, o2) -> o1 - o2);\n\n// 从原始组中复制出来一份 [0, k]\nArrays.copyOf(arr, k);\n\n// 将数组中每个元素值都设置为 1\nint[] arr = new int[10];\nArrays.fill(arr, 1);\n```\n\n### 字符串\n\n``` java\n// 将数字转换为字符串（在字符串问题中非常常用）\nString s = String.valueOf(num);\n// 将字符串转换为数字\nint n = Integer.parseInt(s);\n// 或\nint n = Integer.valueOf(s);\n\ns.substring(a,b); // 截取 s 在区间 [a, b) 上的子字符串\n\nchar c = s.charAt(i); // 获取 s 在第 i 位置上的字符\n\n\ns = s.trim(); // String 字符串删除首尾空格\n\nCharacter.isLetter(ch);     // 判断某个字符是否是字母\nCharacter.toLowerCase(ch);  // 将某个字母转为小写字母 \nchar[] str = s.toLowerCase();  // 将 String 转换成小写字母数组\n\n// StringBuilder的API\n// 添加字符串\nsb.append(new String(\"123\"));\n// 删除字符串某个位置的元素\nsb.deleteCharAt(i);\n```\n\n\n\n### 集合\n\nLinkedList中add，addLast，offer，pollLast，removeLast等区别：https://blog.csdn.net/cpppp66/article/details/115759578。\n\n- `addLast()` 仅仅将元素链接到队列尾部。 然而 `add()` 不仅将元素链接到队列尾部，还返回true。\n- `offer()` 直接调用了 `add()` 方法。所以在 `LinkedList `中 `add()` 与 `offer()` 的使用相当于是一样的\n\n总结：\n\n- 需要链接元素到队列尾时优先用 `offer()`\n- 查看元素优先使用 `peek()`\n- 删除元素优先使用 `poll()`\n\n特别情况：\n\n- 想要在指定索引位置链接元素可以使用 `add(int index, E element)`\n- 获取指定索引的元素可以使用 `get(int index)`\n- 修改指定索引的元素可以使用 `set(int index, E newElement)`\n\n其他：\n\n``` java\n// 对数组集合进行反转\nCollections.reverse(list);\n// 集合的排序\nCollections.sort(list, (o1, o2) -> o1 - o2);\n\n// 从原始组中复制出来一份 [0, k]\nArrays.copyOf(arr, k);\n```\n\n\n\n一些深度优先遍历问题，通常做法是创建一个全局的集合 path，其将随着递归栈的调用而被不断修改。在递归到底部满足条件进行保存结果时，注意需要另外创建一个新的集合变量，存储该 path 中的值，以防其随着递归栈的返回被修改。具体做法为：`res.add(new LinkedList<Integer>(path))`\n\n代码：\n\n``` java\nList<List<Integer>> res = new LinkedList<List<Integer>>();\nDeque<Integer> path = new LinkedList<Integer>();\n\npublic void dfs(TreeNode curr, int target) {\n    // 假设如果满足某种条件，就将当前分支的内容保存到总结果集合 res 中\n    // 则需要另外创建一个新的集合变量，存储该 path 中的值，以防其随着递归栈的返回被修改\n    if (target == 0) {\n        res.add(new LinkedList<Integer>(path));\n    }\n}\n```\n\n### 哈希表\n\n``` java\n\nSet<Integer> set = new HashSet<>();\n// HashSet 添加元素\nfor (int i = 0; i < arr.length; i++) {\n    set.add(arr[i]);\n}\n// 遍历 HashSet\nfor (Integer cur : set) {\n    if (set.contains(cur + k)) {\n        res.add(Arrays.asList(cur, cur + k));\n    }\n}\n\n\nMap<String, Integer> map = new HashMap<>();\n// 遍历 HashMap\nfor (Entry<String, Integer> entry : map.entrySet()) {\n    // 获取每一个 key\n    String str = entry.getKey();\n    // 获取每一个 value\n    Integer times = entry.getValue();\n}\n```\n\n\n\n### 概率\n\n```java\n// 随机获得一个[0, i]内的随机整数，注意是左闭右开，是不包含 i + 1 的\nint d = rand.nextInt(i + 1);\n\n// 随机生成 0-4 + 1 = 0-5 的数字\nint d = (int)(Math.random() * 5) + 1;\n```\n\n\n\n<!-- More -->\n\n\n\n \n\n## 运算\n\n### 获取每个数字最右侧为 1 的位数\n\n``` java\nrightOne = eor & (~eor + 1)\n```\n\n### 两个整数相除向上取整\n\n两个整数相除的向下取整为：\n\n``` java\nint res = a / b;\n```\n\n两个整数相除的向上取整为：\n\n``` java\nint res = (a + b - 1) / b;\n\n// 或者：\nint res = (a / b) + (a % b == 0 ? 0 : 1);\n```\n\n这里分两种情况：\n\n- `a / b` 没有余数：例如 ` 14 / 7`，则 `(14 + 6) / 7` 还是等于 2，此时 a 加上的 `b - 1` 没有带来额外的进位（这就是要减一的原因）\n- ` a / b` 有余数：例如 `15 / 7`，则 `(15 + 6) / 7` 等于 3，此时原本 `15 / 7` 会被省略掉的余数因为加上了 `b - 1`，从而额外进了一位，因此达到了向上取整的效果。即使 `15 / 7` 只余下 1，也会因为加上了 `b - 1`，从而多算了一个 `b / b = 1`，因此多进了一位。\n\n### 判断某个数字 x 是否是 n 的完全开平方\n\n问题：判断 x 是否等于 sqrt(n)。\n\n技巧：如果直接判断 `x * x ?= n`，则可能因 x 过大而发生溢出；此时我们可以使用如下判断：\n\n``` java\nn % x == 0 && n / x == x\n```\n\n`n % x == 0` 保证了 n 能整除 x，否则肯定不满足 `x * x == n`；其次使用 `n / x == x` 来防止 `x * x` 溢出。\n\n\n\n### int 类型范围\n\nint 类型的范围： -2147483648 ～ 2147483647\n\n在一些题目里，如果 n 取了 int 类型的最小值  -2147483648，则对其直接取反后，会超出 int 的最大值 2147483647，导致 `-n != n`， 因此要先将 n 变成 long 类型进行操作。最后再变回 int。\n\n例如：[50. Pow(x, n)](https://leetcode-cn.com/problems/powx-n/) 这道题，n 如果取到最小值，这时对其反转，得到的就不是想要的值，而应该将 n 转换成 long 类型再计算。\n\n### 数组的前缀和\n\n如果要频繁的获取数组中某个区间内的累加和，则可以使用前缀和的技巧进行加速。具体方法为：\n\n- 创建一个 sum[] 数组。sum[i] 代表原数组在 [0, i]  范围内的累加和。\n- 遍历一遍整个数组，计算出 sum[] 数组每个位置上的值\n- 这样再想计算某个区间 [L, R] 上的累加和，就只需要计算 sum[R] - sum[L-1] 即可。\n\n### 或的短路原则\n\n在需要多条路径进行递归时，可以使用 || 的**短路原则**，缩短搜索时间。例如：\n\n``` java\nboolean res = dfs(i + 1, j, k + 1, board, words) || dfs(i, j + 1, k + 1, board, words)\n    || dfs(i - 1, j, k + 1, board, words) || dfs(i, j - 1, k + 1, board, words);\n```\n\n上述代码中只需要前面的某一条分支返回true，就无需再递归判断后续的其他分支，从而节省了大量时间。\n\n### 摩尔投票法\n\n[剑指 Offer 39. 数组中出现次数超过一半的数字](https://leetcode-cn.com/problems/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi-lcof/)：数组中有一个数字出现的次数超过数组长度的一半，请找出这个数字。\n\n摩尔投票法：可以类比打擂台。如果台上没人，则当前的人作为擂主，之后如果遇到己方阵营（和自己相等），则台上人数加一，如果遇到对方阵营（和自己不相等），则台上人数减一（同归于尽），最后台上剩下的阵营一定是众数（如果题目不保证一定存在众数，则在找到该数字后再遍历一遍数组判断当前数字是不是众数即可）\n\n``` java\nclass Solution {\n    public int majorityElement(int[] nums) {\n        int x = 0;\n        int votes = 0;\n        for (int num : nums) {\n            if (votes == 0) {\n                // 如果当前擂台上没人（可能之前没人上或之前人都同归于尽了），则当前的人作为擂主\n                x = num; \n                // 注意！！！这里别忘了votes++，令当前票数+1，或者下面的votes += ... 不要放到else里\n                votes++;\n            } else {\n                // 如果当前擂台上的擂主不是己方阵营，则当前人和擂主阵营中的一个人同归于尽，votes--；如果是同一方阵营，则votes++\n                votes += (x == num) ? 1 : -1;\n            }\n        }\n        // 最后擂主一定是众数（如果题目不保证一定存在众数，则在找到该数字后再遍历一遍数组判断当前数字是不是众数即可）\n        return x;\n    }\n}\n```\n\n### 一年中的第几天\n\n给你一个字符串 `date` ，按 `YYYY-MM-DD` 格式表示一个 [现行公元纪年法](https://baike.baidu.com/item/公元/17855) 日期。请你计算并返回该日期是当年的第几天。通常情况下，我们认为 1 月 1 日是每年的第 1 天，1 月 2 日是每年的第 2 天，依此类推。每个月的天数与现行公元纪年法（格里高利历）一致。\n\n思路：注意闰年的判断方式：闰年的判定方法为：**year 是 400 的倍数，或者 year 是 4 的倍数且不是 100 的倍数**。\n\n```java\npublic int dayOfYear(String date) {\n    int year = Integer.parseInt(date.substring(0, 4));\n    int month = Integer.parseInt(date.substring(5, 7));\n    int day = Integer.parseInt(date.substring(8));\n\n    int[] amount = {31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31};\n    if (year % 400 == 0 || (year % 4 == 0 && year % 100 != 0)) {\n        ++amount[1];\n    }\n\n    int ans = 0;\n    for (int i = 0; i < month - 1; ++i) {\n        ans += amount[i];\n    }\n    return ans + day;\n}\n```\n\n","tags":["算法"],"categories":["算法"]},{"title":"【算法】二分查找法","url":"/2021/11/24/【算法】二分查找法/","content":"\n## 二分查找法模板\n\n> https://leetcode-cn.com/leetbook/read/binary-search/x6q6fi/\n\n### 模板一\n\n二分查找法的标准模板适用于**只需要寻找某一个符合条件的值**：\n\n- 初始化 `right = nums.length - 1`\n- 更新区间时：`left = mid + 1`；`right = mid - 1`\n- 查找的区间为 `[left, right]`，左闭右闭\n- 跳出 while 循环的条件是 `left == right + 1`\n\n``` java\npublic int binarySearch(int[] nums, int target) {\n    if(nums == null || nums.length == 0)\n        return -1;\n\n    int left = 0;\n    int right = nums.length - 1;\n    int mid;\n\n    while (left <= right) {\n        mid = left + (right - left >> 1);\n        if (nums[mid] == target) {\n            // 只要找到一个目标值即可返回\n            return mid;\n        } else if (nums[mid] > target) {\n            right = mid - 1;\n        } else if (nums[mid] < target) {\n            left = mid + 1;\n        }\n    }\n    // left == right + 1，如果到这里还没找到说明整个数组里没有任何一个满足条件的元素，返回-1\n    return -1;\n}\n```\n\n\n\n### 模板二\n\n二分查找法的标准模板适用于寻找符合条件的**最左边界**：\n\n- 初始化 `right = nums.length`\n- 更新区间时：`left = mid + 1`；`right = mid`\n- 查找的区间为 `[left, right)`，左闭右开\n- 跳出 while 循环的条件是 `left == right`\n\n之所以更新右指针为 `right = mid`：\n\n- 一是因为要求解最左边界，则在 right 更新时**需要保存着当前满足条件的值**（该值左侧可能还有满足条件的值，需要用 right 保存着当前满足的值），最后跳出循环时其位置就是最左满足条件的值\n- 二是因为查找区间为**左闭右开**，不包含 right。因此在发现 mid 位置满足条件时，接下来的二分过程中，要令 `right = mid`，这样 mid 因为右开而不被考虑，mid - 1 能正常被考虑。否则若 `right = mid - 1`，则下一轮的二分中 mid - 1 就没有被考虑在内，从而漏算了该值\n\n``` java\npublic int binarySearch(int[] nums, int target) {\n    if(nums == null || nums.length == 0)\n        return -1;\n\n    int left = 0;\n    int right = nums.length;\n    int mid;\n\n    while (left < right) {\n        mid = left + (right - left >> 1);\n        if (nums[mid] >= target) {\n            // 要寻找满足条件的最左区间，因此满足条件也不能退出，而是继续更新右边界\n            // 右边界要保存着当前满足条件的值\n            right = mid;\n        } else if (nums[mid] < target) {\n            left = mid + 1;\n        }\n    }\n    // 退出循环时，left == right，需要额外判断一下left位置的元素值是否满足条件\n    return nums[left] == target ? left : -1;\n}\n```\n\n> 许多求解最左/由边界的题目其实都可以使用模板一，只需要额外借助一个变量 ans，在二分过程中记录下满足条件的值（不要 return），然后继续二分直到跳出循环，这样到最后 ans 就保存了最左/右边界\n\n模板二适合于在遍历过程中，mid 位置很可能就是符合题意的答案，但是因为在二分过程中没有写“遇到答案立即返回”的代码，因此需要考虑到 mid 就是答案的情况，在 right 更新时要包含 mid，不能将其跳过。\n\n> 关于二分查找法模板的更多细节：https://blog.csdn.net/xiao_jj_jj/article/details/106018702\n\n<!-- More -->\n\n## 二分查找法常见题目\n\n可以使用二分法的题目的一个特点：**单调性**\n\n\n\n\n\n### 搜索旋转排序数组\n\n> https://leetcode-cn.com/problems/search-in-rotated-sorted-array/solution/sou-suo-xuan-zhuan-pai-xu-shu-zu-by-leetcode-solut/\n\n整数数组 nums 按升序排列，数组中的值互不相同 。\n\n在传递给函数之前，nums 在预先未知的某个下标 k（0 <= k < nums.length）上进行了 旋转，使数组变为 [nums[k], nums[k+1], ..., nums[n-1], nums[0], nums[1], ..., nums[k-1]]（下标 从 0 开始 计数）。例如， [0,1,2,4,5,6,7] 在下标 3 处经旋转后可能变为 [4,5,6,7,0,1,2] 。\n\n给你旋转后的数组 nums 和一个整数 target ，如果 nums 中存在这个目标值 target ，则返回它的下标，否则返回 -1 。\n\n![img](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/33_fig1.png)\n\n思路：这道题的关键是找到**单调性**。\n\n最关键的一步就是通过 nums[mid] 和 nums[0] 的大小差别，判断 mid 左侧还是右侧是有序数组（也就是找单调性）。 我们只在有序数组里判断 target 是否在其内，不在其中，那肯定在另一侧无序数组里\n通过这点来进行二分查找。\n\n代码：        \n\n```java\nclass Solution {\n    public int search(int[] nums, int target) {\n        if (nums == null || nums.length < 1) {\n            return -1;\n        }\n        int left = 0;\n        int right = nums.length - 1;\n        int mid;\n\n        // 在有序的区间范围内判断 target 是否在该区间内\n        // 在该区间内的话，就可以继续二分，缩小区间，\n\n        // 最关键的一步就是通过 nums[mid] 和 nums[0] 的大小差别，判断 mid 左侧还是右侧是有序数组（也就是找单调性）\n        // 我们只在有序数组里判断 target 是否在其内，不在其中，那肯定在另一侧无序数组里\n        // 通过这点来进行二分查找\n        while (left <= right) {\n            mid = left + (right - left >> 1);\n            if (nums[mid] == target) {\n                return mid;\n            } \n            // 判断mid的左侧是有序数组还是右侧是有序数组\n            // 注意带上 等于号\n            if (nums[0] <= nums[mid]) {\n               // 如果左侧是有序数组，则判断一下 target 的大小是否处于该区间内\n               // 注意有等于号\n               // 因为 target 肯定不等于 nums[mid] 了，否则上面就返回了\n               if (target >= nums[left] && target < nums[mid]) {\n                   // 如果处于该区间内，则直接忽略掉另一侧不是有序的数组，在当前数组里继续二分查找，因为 target 肯定不在另一个数组里\n                   // 此时就可以更新 right 为 mid-1，肯定在[left,mid-1]区间内\n                   right = mid - 1;\n               } else {\n                   left = mid + 1;\n               }\n            } else {\n                // 如果左侧不是有序的，那么右侧就是有序的了\n                // 如果 target 在右侧的数组中，则缩小查找范围为 [mid+1, right]\n                // 注意有等于号\n                if (target > nums[mid] && target <= nums[right]) {\n                    left = mid + 1;\n                } else {\n                    // 如果在左侧数组（无序的部分），则缩小查找范围为 [left, mid-1]\n                    right = mid - 1;\n                }\n            }\n        }\n        return -1;\n    }\n}\n```\n\n### 旋转数组的最小数字\n\n> https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/solution/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-by-leetcode-s/\n\n把一个数组最开始的若干个元素搬到数组的末尾，我们称之为数组的旋转。输入一个递增排序的数组的一个旋转，输出旋转数组的最小元素。例如，数组 [3,4,5,1,2] 为 [1,2,3,4,5] 的一个旋转，该数组的最小值为1。 \n\n该问题的思路与上一题相似，都是先判断单调性，然后再进行二分，区别在于，这里是判断与 right  值的关系从而确定单调性。上一题是一直判断与 0 位置的关系从而确定单调性。\n\n> 上一题是找目标值位置，这一题是找最小值\n\n![img](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/1.png)\n\n![img](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/4.png)\n\n详细分析见官方题解。\n\n代码：\n\n```java\npublic int minArrayTwoSperate(int[] numbers) {\n    int left = 0;\n    int right = numbers.length - 1;\n\n    // 一直二分到left == right，此时的left就是要找的最小值\n    while (left < right) {\n        int mid = left + ((right - left) >> 1);\n\n        // 只判断mid和right的关系就够了，不需要再去判断left\n        // 因为右边如果正常，左边肯定异常，因此不需要判断左边界值\n        if (numbers[mid] > numbers[right]) {    \n            // 如果mid值大于right，说明右边有问题，更新左边界\n            left = mid + 1;\n        } else if (numbers[mid] < numbers[right]) {\n            // 如果mid值小于right，说明右边是正常的，左边有问题，更新右边界\n            right = mid;\n        } else {\n            // 如果mid==right，则无法判断最小值是在mid左还是右\n            // 因为有可能 [4,3, 4 ,4,4] 或者 [4,4, 4 ,3,4]\n            // ps: [5,3, 4 ,4,4] 也有可能\n            // 这两种情况都满足mid==right，但是最小值在左还是右边无法确定\n            // 所以right--，再进入下一次循环，更新mid的位置，从而找到最小值\n            right--;\n        } \n    }\n\n    // left此时等于right\n    return numbers[left];\n}\n```\n\n\n\n### step sum\n\n> step sum 的定义：比如 680，680 + 68 + 6 = 754，则 680 的 step sum 为 754\n\n给定一个正整数 target，判断他是否是某个数的 step sum，若是返回 true，若不是返回 false。\n\n思路：某个数 x 的 stepSum(x) 肯定满足 `x <= stepSum(x)`，满足单调性。因此可以使用二分法，从区间 [0, target]，在其内不断二分，判断中点 mid 的 `stepSum(mid)` 与 target 的关系。\n\n- 若` stepSum(mid) < target`，则结果值 x 肯定在 mid 的右边\n- 若` stepSum(mid) > target`，则结果值 x 肯定在 mid 的左边\n- 若` stepSum(mid) == target`，则找到了结果值 x == mid\n\n```java\n// 二分查找 [0, target] 范围内，某个数 x 的 stepSum(x) == target\n// x <= stepSum(x)，满足单调性，可以使用二分\npublic boolean isStepSum(int target) {\n   int left = 0;\n   int right = target;\n   int mid;\n\n   while (left <= right) {\n      mid = left + (right - left >> 1);\n      if (stepSum(mid) < target) {\n         // 如果小于，则要求的值一定在 mid 右边\n         left = mid + 1;\n      } else if (stepSum(mid) > target) {\n         // 如果大于，则要求的值一定在 mid 左边\n         right = mid - 1;\n      } else {\n         return true;\n      }\n   }\n   return false;\n}\n\n// 计算 x 的 stepSum\npublic int stepSum(int x) {\n   int sum = 0;\n   while (x != 0) {\n      sum += x;\n      x /= 10;\n   }\n   return sum;\n}\n```\n\n\n\n### 画家问题\n\n题目：给定一个整型数组 nums，数组中的每个值都是正数，表示完成一幅画作需要的时间，在给定一个整数 num 表示画匠的数量，每个画匠只能画连在一起的画作。所有的画家并行工作，返回完成所有的画作需要的最少时间。\n\n类似题目：[410. 分割数组的最大值](https://leetcode-cn.com/problems/split-array-largest-sum/)\n\n> 注意：题目给的画家数 m 其实**并不一定是最优分配情况下的画家数**，而可能比最优数要大。例如在 m = 4 时的整体最小作画耗时和 m = 3 时的整体最小作画耗时可能是相等的，这一点体现在代码中的 `need(nums, mid) <= m` 里，很可能存在比当前最小作画耗时更短的情况下，需要的画家数量还更少，这种情况当然是满足题意的。\n\n题目中的两个**隐形要求**：\n\n- 需要的画家数不能超过题目给定的画家数 `m`\n- 整体的最小作画耗时 `h` 要尽可能小\n\n整体最小作画耗时 `h` 的分布区间：\n\n- 区间越往左侧，`h` 越小，需要的画家数量也越多，但可能不满足要求1（最小的 `h` 等于1）\n- 区间越往右侧，`h` 越大，需要的画家数量也越少，画家数量是可以满足题目要求，但是需要的耗时太大，可能不满足要求2（最大的 `h` 等于整个数组的累计和，代表一个画家画完所有画，是最费时的一种情况）\n\n题目的目标就是在这个区间中**尽可能左侧**的位置（代表 `h` 尽可能小），找到一个满足*要求1：画家数量不超过 `m`* 的作画耗时值。\n\n可以从上述规律中找出**单调性**：需要的画家越多，最大耗时越小。因此可以用二分法解决该问题。将求解最短作画耗时的问题转化为**二分地判断当前最大作画耗时的情况下，需要几个画家**：\n\n- 如果需要的画家多于题目给定的 `m`（不满足要求1），则说明当前要求的最大作画耗时太小了（太靠近区间左侧了），那么就二分增加该时间限制（向区间右侧二分）；\n- 如果需要的画家小于等于题目给定的 `m`（满足要求1），则当前的最大作画耗时是满足要求1的（更靠近区间右侧），但可能还不是最优的，还可能在区间左侧有一个更小的时间也是满足该时间对应的画家数量也是小于 `m` 的（要求1）。因此先记录下来当前时间值 `ans`，然后继续向左侧二分；\n- 直到不满足 `left <= right`，二分结束，返回此时记录的时间值 `ans`，就是既满足要求1，又满足要求2的答案值\n\n这是一种**逆向思维**，将求时间限制的问题转换为：求哪种时间限制的情况下，需要的画家满足题目给定的条件。\n\n代码：\n\n``` java\npublic int splitArray(int[] nums, int m) {\n    // 画家问题\n    // nums：需要完成的画\n    // m：画家的个数\n    \n    // 先计算出一个画家画完所有画需要的时间 \n    int sum = 0;\n    for (int i = 0; i < nums.length; i++) {\n        sum += nums[i];\n    }\n\n    // left 和 right 均代表时间限制，也就是要二分查找的结果\n    int left = 1;\n    int right = sum;\n    int mid;\n    int ans = 0;\n    // 无限多的画家（对应二分区间里的最小值（耗时））肯定能得到最小的总耗时，但是题目不可能给这么多画家，所以必须 left 右移，\n    // 只要一个画家（对应二分区间里的最大值（耗时））肯定需要耗费很多的时间，所以必须 right 左移\n\n    while (left <= right) {\n        // mid 代表的是最大耗时\n        mid = left + (right - left >> 1);\n        // 如果当前最大耗时所需要的画家数量比题目给定的还少\n        // 说明可以继续增加画家数量，使得最大耗时进一步减少，因此向左二分\n        // 注意要包含等于的情况\n        if (need(nums, mid) <= m) {\n            ans = mid;\n            right = mid - 1;\n        } else {\n            // 如果当前最大耗时所需要的画家数量比题目给定的多\n            // 说明需要减少画家数量，使得最大耗时增大，因此向右二分\n            left = mid + 1;\n        }\n    }\n    return ans;\n}\n\n// 根据最大作画时间 h 计算最少的画家个数 n\n// 每一幅画需要的时间都在 nums 里，如果一定要求整体不超过 h 小时\n// 那么返回需要的最少画家数量\npublic int need(int[] nums, int h) {\n    for (int i = 0; i < nums.length; i++) {\n        if (nums[i] > h) {\n            // 如果某个时间大于了限制的最大作画时间\n            // 则说明多少个画家都不可能完成\n            // 返回系统最大值，代表无解\n            return Integer.MAX_VALUE;\n        }\n    }\n\n    // 需要的最少画家个数 parts\n    int parts = 1;\n\n    // 当前画家已经作画的时间\n    // 注意，该时间需要先赋值为第一幅画的耗时\n    // 从第二幅画开始遍历\n    int currTime = nums[0];\n\n    // 从第二幅画开始遍历\n    for (int i = 1; i < nums.length; i++) {\n        // 如果当前画家已经画的时间 currTime 加上当前画需要耗时后大于最大限制 h\n        // 则代表需要一个新的画家画这幅画，当前画家的任务结束了，该另其一个新画家了\n        if (currTime + nums[i] > h) {\n            // 另起一个新的画家\n            parts++;\n            // 新画家的耗时设置为当前画的耗时\n            currTime = nums[i];\n        } else {\n            // 如果不超出，则更新当前画家的作画总耗时\n            currTime += nums[i];\n        }\n    }\n    return parts;\n}\n```\n\n### 峰值元素\n\n> https://leetcode-cn.com/problems/find-peak-element/solution/xun-zhao-feng-zhi-by-leetcode-solution-96sj/\n\n该方法适用于模板二。\n\n峰值元素是指其值严格大于左右相邻值的元素。\n\n给你一个整数数组 nums，找到峰值元素并返回其索引。数组可能包含多个峰值，在这种情况下，返回 任何一个峰值 所在位置即可。\n\n代码：\n\n```java\nclass Solution {\n    public int findPeakElement(int[] nums) {\n        int left = 0;\n        int right = nums.length - 1;\n        int mid;\n\n        // 退出时left==right，因此mid的上限也不会超过最大的right，也就等于 nums.length-1，所以肯定不会越界\n        // 这样能避免 mid + 1 越界\n        while (left < right) {\n            mid = left + (right - left >> 1);\n            // 此时已经保证了 mid+1 不会越界，但是不能保证 mid-1 不会越界\n            // 因此我们只判断 mid 和 mid+1 的关系\n            // 因为四种情况都可以总结为判断 mid 和 mid+1 的关系\n            //  mid-1 < mid > mid+1  ---> 找到答案\n            //  mid-1 < mid < mid+1  ---> 坡顶肯定在右侧，left = mid + 1\n            //  mid-1 > mid < mid+1  ---> 坡顶可能在左也可能在右，随便走一个方向，比如右边，left = mid + 1\n            //  mid-1 > mid > mid+1  ---> 坡顶肯定在左侧，right = mid。之所以不减一是因为要考虑上面第一种情况 mid-1 < mid > mid+1，这时的mid可能就是答案，不能跳过，除非不用模板二，而是在找到时直接返回，就不用再这样了\n\n            // 综上，不需要考虑mid-1的大小（因为mid-1可能等于-1，越界），上述四种情况可以总结为和 mid+1 的关系的比较\n            // mid > mid+1，就往左二分，mid < mid+1，就往右二分\n            if (nums[mid] < nums[mid+1]) {\n                // 坡顶在右侧，往右侧二分\n                left = mid + 1;\n            } else {\n                // 坡顶在左侧（或者mid就是坡顶）\n                right = mid; // 不减一是因为可能mid就是坡顶，不能忽略掉\n            }\n        }\n\n        // 额外考虑 left == right 时的情况\n        return left;\n    }\n}\n```\n\n### 找到 K 个最接近的元素\n\n[658. 找到 K 个最接近的元素](https://leetcode-cn.com/problems/find-k-closest-elements/)：给定一个排序好的数组 `arr` ，两个整数 `k` 和 `x` ，从数组中找到最靠近 `x`（两数之差最小）的 `k` 个数。返回的结果必须要是按升序排好的。\n\n``` java\nclass Solution {\n    public List<Integer> findClosestElements(int[] arr, int k, int x) {\n        if (arr == null && arr.length < k) {\n            return null;\n        }\n        int[] nums = arr;\n        // 查找出来的结果放优先级队列里\n        // 先二分查找到距离x最近的位置（左，右）\n        // 对比左右边界哪个距离x更近，\n        // 然后将最近的（左或右）放到优先级队列里（前提是count小于k），\n        // 最后将队列里的数字取出来就是排好序的\n        int left = 0;\n        int right = arr.length - 1;\n        int mid = 0;\n\n        // 如果找到等于的，直接break，在此基础上进行寻找k个最小的数\n        // 如果找不到等于的，则跳出循环时，mid肯定最接近x，但是可能在x左边，也可能在x右边\n        while (left <= right) {\n            mid = left + (right - left >> 1);\n            if (nums[mid] == x) {\n                // 只要数组中有和x相等的，在这一步肯定能找到\n                break;\n            } else if (nums[mid] < x) {\n                left = mid + 1; // mid 小于 x，开始向右查找\n            } else if (nums[mid] > x) {\n                right = mid - 1;\n            }\n        } \n\n        // 出循环后，要么mid的位置等于x，要么mid在x的左，或者右（最接近x）\n        // 通过mid值和x的大小找出mid是在x的左侧还是右侧\n        // 找出来之后就可以确定第二个指针的位置了\n        // 通过mid值和x大小的关系确定出三种情况下的双指针策略\n        int l = 0;\n        int r = 0;\n        // 其实不需要heap，只需要最后得到l和r就可以得到list了\n        Queue<Integer> heap = new PriorityQueue<>();\n        if (nums[mid] == x) {\n            // 如果相等，则先将mid位置进优先队列，然后设置左右指针\n            heap.add(nums[mid]);\n            k--;\n            l = mid - 1;\n            r = mid + 1;\n        } else if (nums[mid] < x) {\n            // 如果mid小于x，则mid是左指针，mid+1是右指针\n            l = mid;\n            r = mid + 1;\n        } else if (nums[mid] > x) {\n            l = mid - 1;\n            r = mid;\n        }\n\n        // 双指针 l 和 r 移动时先判断谁更小，更小的进队列\n        // 注意边界条件\n        while (k-- > 0) {\n            // 循环k次，将k个数入堆\n            // 故意设置左指针减去x的值为正数，代表左指针越界\n            // 故意设置右指针减去x的值为负数，代表右指针越界\n            int lDiff = 1;\n            int rDiff = -1;\n            if (l >= 0) {\n                lDiff = nums[l] - x;\n            }\n            if (r < nums.length) {\n                rDiff = nums[r] - x;\n            }\n\n            // 说明都正常\n            if (lDiff <= 0 && rDiff >= 0) {\n                if (Math.abs(lDiff) <= Math.abs(rDiff)) {\n                    // 当前更小值入堆\n                    heap.add(nums[l]);\n                    l--;\n                } else {\n                    heap.add(nums[r]);\n                    r++;\n                }\n            } else if (lDiff == 1 && rDiff != -1) {\n                // 说明左侧越界，右侧没越界\n                heap.add(nums[r]);\n                r++;\n            } else if (rDiff == -1 && lDiff != 1) {\n                heap.add(nums[l]);\n                l--;\n            }\n        }\n\n        List<Integer> list = new ArrayList<>();\n        // 最后将heap变成数组\n        while (!heap.isEmpty()) {\n            list.add(heap.poll());\n        }\n        return list;\n\n        // 题解里的思路：先用模板二right=mid找出最接近x的右侧的与元素\n        // 然后比较该元素和其左边元素谁更接近目标值，从而确定index\n        // 确定之后，使得l和r在index两侧不断向两侧展开\n        // 知道r和l组成的开区间(l,r)内的元素个数等于k，跳出循环\n        // 说明找到了(l,r)内的k个元素，就是答案，注意，l和r组成的是开区间，不要把二者包含进去\n\n        int leftindex = index-1;\n        int rightindex = index+1;\n        while(rightindex-leftindex-1<k){\n            if(leftindex<0){\n                rightindex++;\n                continue;\n            } \n            if(rightindex>=len){\n                leftindex--;\n                continue;\n            } \n            if(x-arr[leftindex]<=arr[rightindex]-x) leftindex--;\n            else rightindex++;\n        }\n    }\n}\n```\n\n","tags":["算法"],"categories":["算法"]},{"title":"【算法】排序算法","url":"/2021/11/10/【算法】排序算法/","content":"\n## 排序算法总结\n\n快排首选，它的常数项经过试验是最低的\n\n归并排特点：能保证稳定性\n\n堆排：空间复杂度低 O(1)\n\n\n\n\n\n![image-20211005221404802](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211005221404802-1633921404335.png)\n\n\n\n\n\n为什么 Java 的 `Arrays.sort()` 会根据：\n\n- 数组是基础数组，就用快排，因为不需要保证稳定性\n- 数组是引用类型数组，就用归并，因为需要保证稳定性\n\n\n\n\n\n\n\n\n\n<!-- More -->\n\n\n\n## 选择排序\n\n遍历数组的 i ～ N-1 范围内的元素，选出该范围内的最小值与 i 位置进行交换；重复上述过程 N-1 次直到完成排序。\n\n总结：从前往后缩小范围遍历，选择当前范围内最小的数，放在当前范围的队首。队伍前面的数字都是排好序的小数，队伍后面的数字都是待排序的。\n\n- 时间复杂度 O(N^2)\n- 额外空间复杂度O(1)\n\n代码：\n\n``` java\npublic class SelectionSort {\n  public static void selectionSort(int[] arr) {\n    if (arr == null || arr.length < 2) {\n      return;\n    }\n\n    for (int i = 0; i < arr.length; i++) {\n      int minIndex = i;\n      for (int j = i + 1; j < arr.length; j++) {\n        // 寻找 i ~ N-1 位置上的最小值索引, 全部遍历完找到索引后再进行交换\n        minIndex = (arr[minIndex] < arr[j]) ? minIndex : j;\n      }\n      swap(arr, i, minIndex);\n    }\n  }\n\n  public static void swap(int[] arr, int i, int j) {\n    arr[i] = arr[i] ^ arr[j];\n    arr[j] = arr[i] ^ arr[j];\n    arr[i] = arr[i] ^ arr[j];\n  }\n}\n```\n\n---\n\n补充：一种交换数据a和b的方式：连续三次异或。前提是a和b在内存中处于不同的空间，并且 arr[a] 不能等于 arr[b]，否则得到的结果是0。\n\n``` java\npublic void swap(int[] arr, int i, int j) {\n  // 这种方式的弊端: arr[a] 和 arr[b] 不能相等\n  arr[i] = arr[i] ^ arr[j]; \n  arr[j] = arr[i] ^ arr[j];\n  arr[i] = arr[i] ^ arr[j];\n}\n```\n\n---\n\n\n\n## 冒泡排序\n\n遍历数组 0～i 范围内的元素，比较当前元素与其后元素的大小，若当前元素较大则与其交换（像冒泡一样不断将比较大的元素向数组队尾移动），从而将该范围内的最大值元素后移放到 i 位置。\n\n总结：从前往后缩小范围遍历，选择当前范围内最大的数，放在当前范围的队尾。队伍前面的数字都是待排序的，队伍后面的数字都是排好序的大数。\n\n- 时间复杂度 O(N^2)\n- 额外空间复杂度O(1)\n\n代码：\n\n```java\npackage com.zhao;\n\npublic class BubbleSort {\n    public static void bubbleSort(int[] arr) {\n        if (arr == null || arr.length < 2) {\n            return;\n        }\n\n        for (int i = arr.length - 1; i > 0; i--) {\n            for (int j = 0; j < i; j++) {\n                if (arr[j] > arr[j+1])\n                    swap(arr, j, j+1);\n            }\n        }\n    }\n\n    public static void swap(int[] arr, int i, int j) {\n        // 这种方式的弊端: arr[a] 和 arr[b] 不能相等\n        arr[i] = arr[i] ^ arr[j];\n        arr[j] = arr[i] ^ arr[j];\n        arr[i] = arr[i] ^ arr[j];\n    }\n}\n```\n\n\n\n## 插入排序\n\n遍历 0 ～ i 范围内的元素，从后往前判断当前元素是否小于前一个元素，若小于则将二者进行交换，直到前一个元素小于当前元素。类似扑克牌中新来的牌不断判断与上一个牌的大小，直到将牌插入到符合条件的位置。\n\n总结：从前往后遍历，将当前范围内的数字排好序，新来的数据插入到前面排好序的数字的适当位置中。队伍前面的数字都是排好序的小数，队伍后面的数字都是待排序的。\n\n- 时间复杂度 O(N^2)\n- 额外空间复杂度O(1)\n\n代码：\n\n```java\npackage com.zhao;\n\npublic class InsertionSort {\n    public static void insertionSort(int[] arr) {\n        if (arr == null || arr.length < 2) {\n            return;\n        }\n\n        for (int i = 1; i < arr.length; i++) {\n//            for (int j = i; j > 0; j--) {\n//                if (arr[j] > arr[j-1]) {\n//                    break;\n//                } else {\n//                    swap(arr, j, j-1);\n//                }\n//            }\n\n            // 更简洁的写法\n            for (int j = i; j > 0 && arr[j] < arr[j-1]; j--) {\n                swap(arr, j, j-1);\n            }\n\n        }\n    }\n\n    public static void swap(int[] arr, int i, int j) {\n        // 这种方式的弊端: arr[a] 和 arr[b] 不能相等\n        arr[i] = arr[i] ^ arr[j];\n        arr[j] = arr[i] ^ arr[j];\n        arr[i] = arr[i] ^ arr[j];\n    }\n}\n```\n\n\n\n## 归并排序\n\n归并排序 = 递归 + 合并 的排序。\n\n算法大致流程：\n\n1. 将整个数组平均划分为两部分\n2. 先将左侧的半个数组排序\n3. 再将右侧的半个数组排序\n4. 开辟一个和目标数组相同大小的数组空间\n5. 定义两个指针Left和Right，分别指向左侧数组和右侧数组的第一个元素，再定义一个指针i，指向新数组的第一个元素\n6. 不断遍历左右数组移动指针，判断Left和Right指向的元素大小：\n   1. 若Left小于等于Right，则将新数组的当前位置i赋值为Left指向的元素\n   2. 若Left大于Right，则将新数组的当前位置i赋值为Right指向的元素\n7. 不断执行步骤6，每次要么移动Left，要么移动Right，直到某一个指针达到数组末尾；再将另一半数组的后面的所有元素拷贝到新数组的末尾。\n\n将整个数组**递归**执行上述 1-7 的过程，从完整的数组不断递归地平均拆分，直到递归到最底层的**前一层**：\n\n- `process(arr, Left, Left+1)`\n- `process(arr, Left+1, Right)`\n- `merge(arr, Left, Right)`\n\n其中，Left = Right -2，`process(arr, Left, Left+1)` 里会将 [Left, Left+1] 范围内的两个数字进行排序, 再调用 `process(arr, Left+1, Right) `里会将 [Left+1, Right] 范围内的两个排序（此时 Left+1 位置上的数组已经经过了前一步的排序），因此归并排序最底层的合并排序只有两个数字进行比大小。（该过程可参考下文代码）\n\n经过上述步骤后，即将 [Left, Left+1, Right] 范围内的三个数字进行了排序，递归开始返回，不断的将更大范围内的数组进行归并排序，直到递归返回到第二层时数组被分为了两半，左侧数组和右侧数组都进行了排序，再对二者进行一次 merge，即完成了整个数组的归并排序。\n\n> 例如：第一条递归分支一直从 process(arr, 0, 2) --> process(arr, 0, 1) --> process(arr, 0, 0) + process(arr, 1, 1) + merge(arr, 0, 1, 0)。此时递归到了底部，process(arr, 0, 0) 和 process(arr, 1, 1) 都直接 return ，剩余 merge(arr, 0, 1, 0) 将合并左右数组 arr[0] 与 arr[1] 这两个数字，将二者合并到一个新的数组中。\n\n---\n\n递归行为的时间复杂度估算公式：\n\n>  https://www.bilibili.com/video/BV13g41157hK?p=3\n\n![image-20211002195502529](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211002195502529-1633921209453.png)\n\n其中，b为数组被平均分的份数（二分归并排序算法里等于2），a为每次拆分时调用几个递归分支（二分归并排序算法里等于2），O(N^d) 为递归到底部时进行的操作的时间复杂度，根据不同的应用场景有不同的复杂度，例如在求数组最大值时，d=0；在归并排序里，d=1\n\n举例：\n\n- 在二分递归求数组最大值问题时，T(N) = 0.5 \\* T(N / 2) + O(1)\n- 在数组二分归并排序问题时，T(N) = 0.5 \\* T(N / 2) + O(N)\n\n根据上图中的计算公式，归并排序算法的时间复杂度为 O(N*log(N))\n\n---\n\n总结：归并排序就是不断递归地将数组拆分成更小的数组，直到最底层时拆分成的两个数组中**每个数组只有一个数字**，对这两个数字进行**排序并合并**后返回，不断返回后合并出的数组就越来越长，直到整个数组被合并排序。\n\n归并排序的时间复杂度：\n\n- 时间复杂度 O(N*log(N))\n- 额外空间复杂度O(N)\n\n代码：\n\n```java\npackage com.zhao;\n\npublic class MergeSort {\n    public static void mergeSort(int[] arr) {\n        if(arr == null || arr.length < 2) {\n            return;\n        }\n\n        process(arr, 0, arr.length-1);\n    }\n\n    public static void process(int[] arr, int left, int right) {\n        if (left == right) {\n            return;\n        }\n        // 计算中点, 能避免范围溢出\n        int mid = left + ((right - left) >> 1);\n\n        // 两条递归分支\n        process(arr, left, mid);\n        process(arr, mid+1, right);\n\n        // 两条递归分支会一直递归到: 划分的两个数组各有一个元素, 将这两个元素进行排序并合并\n        merge(arr, left, right, mid);\n    }\n\n    public static void merge(int[] arr, int left, int right, int mid) {\n        int[] tmp = new int[right - left + 1];\n\n        int i = 0;\n        // 指向左数组的第一个\n        int p1 = left;\n        // 指向右数组的第一个\n        int p2 = mid + 1;\n        // 递归到最底部时，left == mid == right - 1。此时左数组为[left]；右数组为[right]\n\n        // 双指针一起向右移动,将当前较小的元素拷贝到tmp中,只会有其中的某一个数组的指针先到数组尾部\n        while (p1 <= mid && p2 <= right) {\n            tmp[i++] = arr[p1] <= arr[p2] ? arr[p1++] : arr[p2++];\n        }\n\n        // 将另一个数组的剩下所有元素拷贝到tmp中,只会有一个满足条件\n        while (p1 <= mid) {\n            tmp[i++] = arr[p1++];\n        }\n        while (p2 <= right) {\n            tmp[i++] = arr[p2++];\n        }\n\n        // tmp中的元素拷贝回原数组\n        for (int n = 0; n < tmp.length; n++) {\n            arr[left + n] = tmp[n];\n        }\n    }\n}\n```\n\n> 补充：使用递归的方法计算数组中最大值时，只需要将合并操作 merge 替换成求两个数字最大值的操作 `Math.max(left, right)`\n\n### 归并排序的扩展：小和问题和逆序对问题\n\n> https://www.bilibili.com/video/BV13g41157hK?p=3\n\n![image-20211002214054579](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211002214054579-1633921248245.png)\n\n小和问题和逆序对问题本质上都是归并排序，二者是等价的。求每一个数左边比当前数小的数字的累积等价于求每一个数右边比当前数大的个数 \\* 自身大小。\n\n- 不断递归拆分数组，直到递归返回、数组开始合并时：\n- 在合并排序前使用双指针判断左侧数组当前元素是否小于右侧数组当前元素：\n  - 若小于，说明左侧当前元素比右侧数组当前元素之后的所有元素都要小（因为右侧数组都是排好序的，所以可以直接用索引数量计算出小和，不用再遍历判断大小了），那么就把**左侧当前元素大小 \\* 右侧当前元素之后的元素数量**，即可得到左侧当前元素相对右侧数组而言的的小和数\n  - 若等于，则此时不计算小和，把**右侧**数组的当前元素拷贝到临时数组中（之所以优先拷贝右侧是因为这样在排序后，之后的循环再比较大小时就不会把右侧数组中等于该元素大小的数字计算在内，因为相等的数字不在小和范围内）\n  - 若大于，则不计算小和，将右侧数组的当前元素拷贝到临时数组中，右侧指针移动，进入下一次循环\n- 左右数组中的某一个遍历完毕后，即可将另一个数组的剩余元素拷贝到临时数组中，这之后的步骤就同归并排序一样了。\n\n这种思想既不会漏算小和，又不会重算小和，因为某个元素只有在和右侧的数组 merge 时才会计算右侧数组内有几个数比其大，然后一旦 merge 后，其在合并后的组内就不会再去重复计算组内有没有比他大的。因此不会漏算，也不会重算。\n\n小和问题的代码：\n\n```java\npackage com.zhao;\n\npublic class SmallSum {\n    public static int smallSum(int[] arr) {\n        if (arr == null || arr.length < 2) {\n            return 0;\n        }\n        return process(arr, 0, arr.length-1);\n    }\n\n    public static int process(int[] arr, int left, int right) {\n        if (left == right) {\n            return 0;\n        }\n\n        int mid = left + ((right - left) >> 1);\n        // 返回三者的和\n        return process(arr, left, mid) + process(arr, mid+1, right) + merge(arr, left, right, mid);\n\n    }\n\n    public static int merge(int[] arr, int left, int right, int mid) {\n        int result = 0;\n\n        int[] tmp = new int[right - left + 1];\n\n        int i = 0;\n        int p1 = left;\n        int p2 = mid + 1;\n\n        while (p1 <= mid && p2 <= right) {\n            // 若当前元素arr[p1]小于右侧数组的当前元素arr[p2]\n            // 计算小和 = 当前元素的大小 * 右侧数组当前所有往右的数字的个数\n            // 因为右侧数组已经排好序了, 所以可以直接用索引个数计算小和,而不用再遍历判断了\n            result += arr[p1] < arr[p2] ? arr[p1] * (right - p2 + 1) : 0;\n\n            // 计算完小和后进行合并排序,将p1和p2中较小的那一个拷贝到tmp中\n            // 相等的情况下优先把右侧数组的数字拷贝,这样就能避免重复算的情况\n            tmp[i++] = arr[p1] < arr[p2] ? arr[p1++] : arr[p2++];\n        }\n\n        // 后面就和归并排序一样了\n        while (p1 <= mid) {\n            tmp[i++] = arr[p1++];\n        }\n        while (p2 <= right) {\n            tmp[i++] = arr[p2++];\n        }\n\n        for (int n = 0; n < tmp.length; n++) {\n            arr[n + left] = tmp[n];\n        }\n\n        return result;\n    }\n}\n```\n\n逆序对问题的代码：\n\n未来补充\n\n\n\n## 快速排序\n\n### 快速排序前奏一：荷兰国旗问题\n\n> 类似问题：将一个数组中奇数数字放到数组左边，偶数数字放到数组右边。\n\n![image-20211003121356235](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211003121356235-1633921272991.png)\n\n问题二：小于等于 num 的数放在数组的左边，等于 num 的数放在数组的中间，大于 num 的数放在数组的右边。\n\n排序效果：像荷兰国旗一样，将数组分为三个区域，左侧区域为小于 num 的数字；中间区域为等于 num 的数字；右侧区域为等于 num 的数字。\n\n本质是一种**分区思想**，将数组分为三个区域。\n\n思路：\n\n- 定义一个**小于区域**，在其内存储小于 num 的数字，定义一个**大于区域**，在其内存储大于 num 的数字，定义一个**等于区域**，在其内存储等于 num 的数字。\n- 定义三个指针，一个指针 i 不断向右移动，另一个指针 left 指向**小于区域**右侧的下一个数字（该数字不在小于区域内），最后一个指针指向**大于区域**内最左侧的数字（该数字在大于区域内）。\n- 遍历数组，判断当前元素 arr[i] 和 num 的大小关系：\n  - 如果 arr[i] 等于 num，则指针 i 右移一位，不做其他操作\n  - 如果 arr[i] 小于 num，则先将 i 位置的元素和 left 位置的元素（小于区域的右侧下一个元素）进行交换，然后指针 i 和 left 右移一位\n  - 如果 arr[i] 大于 num，则将 i 位置的元素和 right 位置的元素（大于区域内左侧的元素）进行交换，然后指针 right 左移一位，**指针 i 不移动**（因为右侧交换之后并不能确定右侧换过来的这个数是不是比 num 小，还需要再进下一次循环判断交换后的 i 位置的数字是否小于 num）\n- 遍历的终止条件：`i == right`\n\n代码：\n\n```java\npublic static void hollandFlag(int[] arr, int num) {\n    if (arr == null || arr.length < 2) {\n        return;\n    }\n    int left = -1;\n    int right = arr.length - 1;\n\n    for (int i = 0; i < arr.length;) {\n        if (arr[i] < num) {\n            // 令小于区域的右边下一个元素和当前元素交换, 两个指针都右移一位\n            // 如果不交换, 则和 num 相等的区域中就会混杂着小于区域的数字\n            // 因此为了区分小于区域和等于区域,必须要交换\n            swap(arr, i++, ++left);\n        } else if (arr[i] > num) {\n            // 右侧只交换, i先不进行--, 因为右侧交换之后并不能确定右侧换过来的这个数是不是比num小\n            // 还需要再进下一次循环判断交换后的i位置的数字是否小于num\n            swap(arr, i, right--);\n            System.out.println(\"right = \" + right);\n        } else {\n            // arr[i] == num 时, i++, 不做其他操作\n            i++;\n        }\n\n        // 判断当前的 i 是否已经等于了 right, 如果已经等于了, 说明双向奔赴结束\n        if (i == right) {\n            break;\n        }\n        System.out.println(Arrays.toString(arr));\n    }\n}\n\n// 交换 a 和 b 位置上的元素\npublic static void swap(int[] arr, int a, int b) {\n    if (a == b) {\n        return;\n    }\n\n    // 这种方式的弊端: arr[a] 和 arr[b] 不能相等\n    arr[a] = arr[a] ^ arr[b];\n    arr[b] = arr[a] ^ arr[b];\n    arr[a] = arr[a] ^ arr[b];\n}\n```\n\n快速排序中同样使用这种分区的思想，并将该思想和递归操作合并。\n\n### 快速排序前奏二：数组奇偶分离\n\n输入一个整数数组，实现一个函数来调整该数组中数字的顺序，使得所有奇数在数组的前半部分，所有偶数在数组的后半部分。\n\n借助这道题总结出分区类型题目的解决模板套路。注意下面 left 和 right 的设置方式：\n\n``` java\npublic void exchange(int[] nums) {\n    // 左边界内的 [... left] 都是奇数，left + 1 是交换的下一个\n    int left = -1;\n    // 右边界内的 [ right ...] 都是偶数， right - 1 是要交换的下一个\n    int right = nums.length;\n    int curr = 0;\n\n    // 当curr==right时，代表左分区和右分区都计算完毕，结束循环\n    while (curr < right) {\n        // 如果是奇数，和左分区的下一个 left + 1 交换\n        if (nums[curr] & 1 == 1) { // 等价于 nums[curr] % 2 == 1\n            swap(nums, left + 1, curr);\n            // 交换后开始下一个位置判断\n            curr++;\n            left++;\n        } else {\n            // 如果是偶数，和右分区的下一个 right - 1 交换\n            swap(nums, right - 1, curr);\n            right--;\n            // 右分区交换后不能curr++，还要进行下一轮的判断交换后的数字满不满足奇数\n        }\n    }\n}\n\npublic void swap(int[] nums, int a, int b) {\n    int tmp = nums[a];\n    nums[a] = nums[b];\n    nums[b] = tmp;\n}\n```\n\n### 快速排序思想\n\n![image-20211003204741869](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211003204741869-1633921306506.png)\n\n快速.排序共有三个版本，版本一二分别对应了荷兰国旗中的问题一、问题二；版本三对应了问题二的**随机取数字**版本。\n\n快速排序的思想是：**递归** + **分区**。即在递归过程中，首先将当前子数组进行分区，然后再在分好的小于区域内进行递归、接着在分好的大于区域内进行递归。这样最后递归完成时，整个数组就排好了序。\n\n### 三个版本分区方式\n\n- 版本一没有等于区域，小于等于 num 的数字都在小于区域，并且小于区域最右边的是等于的数\n- 版本二加入了等于区域，将整个数组划分为了小于区域、等于区域和大于区域\n- 版本三的分区方式与版本二相同，区别在于取 num 的方式变为了随机取。\n\n在快速排序的某个分区中，每次比较的数字 num 为该分区中数组的某一个数字（版本一二中 num 为数组的最后一个元素，版本三中数字改为随机选取）\n\n### 算法流程\n\n- 选取一个数字作为 num 和其他数字比较。在版本一二中，该数字选取数组中的最后一个元素；版本三种该数字随机选取数组中的某一个元素\n- 随机选取数字的具体实现方式为：在当前 [left, right] 范围内生成一个随机数索引值，并将该元素与当前范围内的 right 位置的元素进行交换，这样后续的分区方法内只用统一的用 arr[right] 进行比较即可\n- 先将整个数组进行分区，得到小于区域、等于区域、大于区域。此时等于区域后续就不需要再排序了\n- 接着**递归**地将小于区域和大于区域进行分区，同样分为小于区域、等于区域、大于区域\n- 相当于小于区域内再继续划分，此时划分出来的数字肯定都比原数组里的等于区域小了，所以不会重复排序\n- 递归完成后，每个划分好的子数组都完成了分区，这样整个数组就完成了排序\n\n细节：其中，在分区后需要记录**等于区域**的**左右边界**，后续小于区域和大于区域内的递归划分需要用到这两个边界值，只在左右边界之外的区域内进行递归分区\n\n### 关于取数字 num 的方式\n\n版本二的快排本身已经足够优秀，但是因为可能人为制造糟糕数据（故意让最后一个元素最大，造成每次都要遍历所有元素），因此最坏情况的时间复杂度为 O(N^2)。\n\n为了应付这种最坏情况，版本三的快排采用了**随机取数字**的方式：随机方式消除了极端情况，使得算法整体的时间复杂度为 O(N*logN)。\n\n版本三的快速排序代码：\n\n```java\npublic class QuickSort {\n    public static void quickSort(int[] arr) {\n        if (arr == null || arr.length < 2) {\n            return;\n        }\n\n        quickSort(arr, 0, arr.length - 1);\n    }\n\n    public static void quickSort(int[] arr, int left, int right) {\n        if (left < right) {\n            // 在当前区间内随机取一个索引, 令其与 arr[right] 交换\n            // 这样分区方法内就可以统一用 arr[right] 进行比较了\n            swap(arr, left + (int) (Math.random() * (right - left + 1)), right);\n\n            System.out.println(\"after swap: \" + Arrays.toString(arr));\n\n            // 先分区\n            int[] bound = partition(arr, left, right);\n            // 需要一个变量存储当前等于区域的数字位置\n\n            System.out.println(\"after partition: \" + Arrays.toString(arr));\n\n            quickSort(arr, left, bound[0] - 1);\n            quickSort(arr, bound[1] + 1, right);\n        }\n    }\n\n    // 分区: 就是荷兰国旗问题\n    // 默认以 arr[right] 作为 num 进行比较\n    // 返回等于区域的左右边界 bound[0] bound[1]\n    public static int[] partition(int[] arr, int left, int right) {\n        // i不断遍历, less指向小于区域的右边界, more指向大于区域的左边界\n        int i = left;\n        int less = left - 1;\n        int more = right;\n\n        // 保存 num 的值以免交换后被替换掉\n        int num = arr[right];\n\n        // 注意这里要 <= more, 边界条件有=\n        // 因为 more 在上一次减一后指向的的元素不包含在大于区域内\n        // 所以这个元素需要加入到循环中判断\n        while (i <= more) {\n            if (arr[i] < num) {\n                // less 最后指向的是小于区域的右边界(在小于区域范围内)\n                swap(arr, ++less, i++);\n            } else if (arr[i] > num) {\n                // more 最后指向的是大于区域的左边界(在大于区域范围外)\n                swap(arr, i, more--);\n            } else {\n                i++;\n            }\n        }\n\n        // 返回 等于区域 的左\\右边界\n        return new int[]{less + 1, more};\n    }\n}\n```\n\n### 快速排序的空间复杂度\n\n- 最差情况是 O(N)，每一层递归都选在了最差的位置，占用了一个空间保存数据\n- 最好的情况是 O(logN)，每一层递归都选在了比较好的中点位置，就会以一个二叉树的形式向下递归，同时每一层的空间都可以复用（左侧的数组分好区后，方法栈向上弹出，那个中点位置的空间就可以释放，让给右侧的数组压栈使用）\n\n这个中点的位置即是上文代码中保存的每一次分区后**等于区域的左右边界位置**，其必须要记录，用于记录哪里是小于区域，哪里是大于区域，只在其内进行递归分区，这样就能保证不重复排序。\n\n> 其作用是在递归调用结束后，方法栈弹出返回到当时调用它的母方法时，能够知道右侧哪个区域将要继续开始向下递归分区。因此这个中点数据的空间是不能省略的，必须要存在用来记录分区的边界\n\n**当采用随机取 num 的策略时，整体的空间复杂度就是 O(logN)**\n\n### 快速排序的扩展问题\n\n只要有分区特性（数字按照某种0/1规则分成两/三个区）的题目都可以用快排来做\n\n1. 将一个数组中奇数数字放到数组左边，偶数数字放到数组右边。这就可以用快排来做，只不过在分区时，快排中是设置小于等于某个数字的放到左边，这道题是奇数放到左边。（本质还是一个荷兰国旗问题）\n\n\n\n### 快速排序的常见题目\n\n#### 最小的 K 个数\n\n> https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/solution/3chong-jie-fa-miao-sha-topkkuai-pai-dui-er-cha-sou/\n\n[剑指 Offer 40. 最小的k个数](https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/)：输入整数数组 `arr` ，找出其中最小的 `k` 个数。例如，输入4、5、1、6、2、7、3、8这8个数字，则最小的4个数字是1、2、3、4。\n\n**方法一：堆**\n\n我们用一个大根堆**实时维护数组的前 k 小值**。首先将前 k 个数插入大根堆中，随后从第 k+1 个数开始遍历，如果当前遍历到的数比大根堆的堆顶的数要小，就把堆顶的数弹出，再插入当前遍历到的数。最后将大根堆里的数存入数组返回即可。\n\n代码：\n\n``` java\n// 1. 大根堆不断维护当前小的k个数字，当来新的数字，如果比堆顶大\n//（比当前k个小数里的最大的小，说明这个最大的堆顶肯定不在答案里了），弹出堆顶\npublic int[] getLeastNumbers01(int[] arr, int k) {\n    // 注意！！将系统默认的小根堆改成大根堆\n    Queue<Integer> maxHeap = new PriorityQueue<>((o1, o2) -> o2 - o1);\n    for (int i = 0; i < arr.length; i++) {\n        if (i < k) {\n            maxHeap.offer(arr[i]);\n        } else {\n            if (maxHeap.peek() > arr[i]) {\n                maxHeap.poll();\n                maxHeap.offer(arr[i]);\n            } \n        }\n    }\n\n    int[] res = new int[k];\n    int i = 0;\n    // 弹出前k个元素\n    while (!maxHeap.isEmpty()) {\n        res[i++] = maxHeap.poll();\n    }\n    return res;\n}\n```\n\n**方法二：快排思想**\n\n快排的划分函数每次执行完后都能将数组分成两个部分，小于等于分界值 `pivot` 的元素的都会被放到数组的左边，大于的都会被放到数组的右边，然后返回分界值的下标。与快速排序不同的是，快速排序会根据分界值的下标递归处理划分的两侧，而这里我们只处理划分的一边。\n\n我们定义函数 `randomized_selected(arr, l, r, k)` 表示划分数组 `arr` 的 `[l,r]` 部分，使前 `k` 小的数在数组的左侧，在函数里我们调用快排的划分函数，假设划分函数返回的下标是 `pos`（表示分界值 `pivot` 最终在数组中的位置），即 `pivot` 是数组中第 `pos - l + 1` 小的数，那么一共会有三种情况：\n\n- 如果 `pos - l + 1 == k`，表示 `pivot` 就是第 k*k* 小的数，直接返回即可；\n- 如果 `pos - l + 1 < k`，表示第 k*k* 小的数在 `pivot` 的右侧，因此递归调用 `randomized_selected(arr, pos + 1, r, k - (pos - l + 1))`；\n- 如果 `pos - l + 1 > k`，表示第 k*k* 小的数在 `pivot` 的左侧，递归调用 `randomized_selected(arr, l, pos - 1, k)`。\n\n函数递归入口为 `randomized_selected(arr, 0, arr.length - 1, k)`。在函数返回后，将前 k 个数放入答案数组返回即可。\n\n代码：\n\n``` java\n// 2. 改进版快排\npublic void quickSearch(int[] arr, int left, int right, int k) {\n    // 以pos为分界线，左侧都小于等于该值，右侧都大于该值\n    int pos = randomPartition(arr, left, right);\n\n    // 如果前number个元素正好是前k个，则完成了排序，返回\n    // 此时前面有 pos + 1 个元素\n    if (pos == k - 1) {\n        return;\n    } else if (pos > k - 1) {\n        // 如果k在number左边，则只需要对左侧进行分区\n        quickSearch(arr, left, pos - 1, k);\n    } else {\n        // 如果k在number右边，则number左边的都是答案，只需要对右侧进行分区\n        quickSearch(arr, pos + 1, right, k);\n    }\n}\n\npublic int randomPartition(int[] arr, int left, int right) {\n    swap(arr, left + (int)(Math.random() * (right - left + 1)), right);\n    return partition(arr, left, right);\n}\n\npublic int partition(int[] arr, int left, int right) {\n    // l：左侧区域的最右元素\n    int l = left - 1;\n    // r：右侧区域的最左元素\n    int r = right + 1;\n    // 二者一开始都为空，所以在数组范围之外\n\n    int curr = left;\n    int num = arr[right];\n\n    // curr == r 时，curr就已经在右侧区域内了\n    while (curr < r) {\n        if (arr[curr] < num) {\n            swap(arr, ++l, curr++);\n        } else if (arr[curr] > num) {\n            swap(arr, --r, curr);\n        } else {\n            curr++;\n        }\n    }\n    return curr - 1;\n}\n\npublic void swap(int[] arr, int i, int j) {\n    int tmp = arr[i];\n    arr[i] = arr[j];\n    arr[j] = tmp;\n}\n```\n\n\n\n## 堆排序\n\n### 堆结构\n\n![image-20211003201744690](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211003201744690-1633921333456.png)\n\n> 堆结构本身比堆排序要重要\n\n堆结构就是用数组实现的**完全二叉树**结构。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211004174447857-1633921333457.png\" alt=\"image-20211004174447857\" style=\"zoom:50%;\" />\n\n堆结构的节点公式：\n\n- 节点 i 的父节点为 (i - 1) / 2（左右节点都可以统一用这个公式）\n- 节点 i 的左子节点为 2 \\* i + 1\n- 节点 i 的右子节点为 2 \\* i + 2\n\n使用上述公式即直接定位到某个节点的父/子节点\n\n### 大/小根堆\n\n- **大根堆**：堆中的每一个父节点都要比其子节点上的数字大（不考虑其对称的另一侧分支里的节点数字大小）。\n- **小根堆**：堆中的每一个父节点都要比其子节点上的数字小（不考虑其对称的另一侧分支里的节点数字大小）。\n\n堆结构最重要的两个操作：\n\n- **heapInsert**：add 操作，**新增**一个数据到已知堆中。具体做法是新增的数据不断向上遍历堆结构，将数字插入到合适的父节点位置\n- **heapify**：poll 操作，**弹出**堆里第一个元素（根节点）的值，并重新调整堆结构，令其余部分的元素继续保持大/小根堆结构。具体做法是新的根结点的元素不断向下遍历堆结构，交换其到合适的子节点位置\n\n---\n\n**heapInsert**：add 操作。用于新增一个数据到堆中，当新来一个数字时，将其添加到堆结构中，并且满足大根堆（或小根堆）：向上遍历他的每一个父节点，判断其是否大于它的父节点，若大于则和父节点交换，若小于则停止遍历。直到当前数字放到合适的父节点位置，使得当前堆满足大根。\n\n**heapify**：poll 操作。用于弹出堆中第一个元素，并令其余部分继续保持大/小根堆结构，若用户要求返回并删除当前大根堆的最大元素，并且要求删除后的其他元素依旧符合大根堆：返回当前堆的第一个节点（其肯定是最大元素），然后将当前堆的最后一个元素放到第一个元素的位置。之后开始向下遍历第一个元素的子节点，选出其子节点中最大的数字，并且判断该数字和自身的大小，若子节点数字更大，则交换自身和子节点，若子节点数字更小，则停止遍历；直到该元素被放到合适的子节点位置。\n\n---\n\n这两个操作的空间复杂度都是 O(logN)，因为 N 个节点的完全二叉树的高度为 O(logN)，上述两个操作都只需要遍历二叉树中的某一条分支即可，因此时间只有 O(logN)\n\nheapInsert 的代码：\n\n``` java\npublic static void heapInsert(int[] arr, int index) {\n  // 向上遍历当前节点的父节点,直到满足条件: 父节点的值 > 当前节点的值\n  while (arr[(index - 1) / 2] < arr[index]) {\n    swap(arr, (index - 1) / 2, index);\n    index = (index - 1) / 2; // index 记得变为父节点的值\n  }\n}\n```\n\nheapify 的代码：\n\n``` java\n// heapSize 用于表示逻辑上的堆的大小, 其和数组的大小没关系\n// 该方法的作用是, 在给定堆结构中, 当某个位置的元素被弹出,替换成了其他数字后\n// 要保证新的数组仍然保持堆结构, 那么就需要从这个位置开始向下遍历\n// 交换其子节点中最大的元素\npublic static void heapify(int[] arr, int index, int heapSize){\n    if (heapSize > arr.length) {\n        return;\n    }\n\n    while (2*index+1 < heapSize) {\n        // 两个孩子中, 判断谁的值更大\n        int largest = (2*index+2 < heapSize) && arr[2*index+1] < arr[2*index+2]\n            ? 2*index+2 : 2*index+1;\n\n        // 当前节点和子孩子中, 判断谁的值更大\n        largest = arr[index] < arr[largest] ? largest : index;\n\n        // 如果相等, 说明此时已经满足了大根堆的条件, 可以跳出循环\n        if (largest == index) {\n            break;\n        }\n\n        // 交换\n        swap(arr, index, largest);\n        index = largest;\n    }\n}\n```\n\n### 具体应用\n\n若用户要求修改堆结构中**任意一个位置**的元素的值，并要求修改后的数字仍然满足大根堆，则只需要判断修改后的元素是比原先大还是小：\n\n- 若修改后的元素比原先大，则进行 **heapInsert** 操作，将当前元素向上交换到合适的父节点位置\n- 若修改后的元素比原先小，则进行 **heapify** 操作，将当前元素向下交换到合适的子节点位置\n\n\n\n---\n\n小根堆在 Java 中就是**优先级队列**默认的实现方式： `PriorityQueue<Interger>`，其两个方法：\n\n- `add()` ：本质上就是 heapInsert 操作，将一个数字添加到已存在的小根堆中\n- `poll()`：本质上就是 heapify 操作，首先弹出当前小根堆的根结点元素，并令剩余数字依旧保持小根堆结构。\n\n但是其不能支持“修改堆中某个结构后以很轻的代价重新调整堆的结构”，只支持“弹出堆的根结点元素后重新调整堆的结构”，若想实现这些个性化的功能还需要自己定义堆结构。\n\n> 其扩容机制是当 heapSize 快满时，将 heapSize * 2。这个操作的时间复杂度在每个元素平摊下来后其实很低\n\n---\n\n### 堆排序思想\n\n堆排序的思想是：利用大根堆第一个元素最大的特性，令数组不断地组成大根堆，从而每次形成的大根堆里的第一个元素都是当前的最大值。\n\n算法流程：\n\n- 首先令当前数组的所有数字符合大根堆顺序（令一个数组变成大根堆的方式见后文，本质上就是不断做 heapInsert）\n- 当前大根堆的根节点就是最大的元素，将其与数组的最后一个元素交换位置，此时即得到了整个数组最大的元素\n- 接着将 heapSize--（因为已经有一个数字排好了序，heapSize 将减小），并对交换后的元素进行一次 heapify 操作：不断向下遍历子节点，直到与合适的位置数字进行交换。heapify 后，新的堆就又符合了大根堆结构\n- 再取当前大根堆的根节点上的元素，它就是原数组第二大的数字，将其与大根堆结构中最后一个节点的元素进行交换。此时原数组中最后两个位置的元素就是最大和第二大的元素\n- 再次 heapSize-- ，并对交换后的元素再进行一次 heapify 操作，新的大根堆的根结点的元素就是第三大的元素，将其与大根堆结构中最后一个节点的元素进行交换。\n- 重复上述过程，直到大根堆的 heapSize == 0，此时即完成了排序\n\n堆排序的复杂度：\n\n- 时间复杂度是 O(N \\* logN)\n- 额外空间复杂度 O(1)，只需要 swap 交换操作，不用开辟额外空间\n\n代码：\n\n```java\npublic static void heapSort(int[] arr) {\n    if (arr == null || arr.length < 2) {\n        return;\n    }\n\n    // 1. 先将数组变为大根堆\n    // 1.1 方式一: 依次将每个数字添加到堆结构中, 堆大小从0开始, 依次将新数字 heapInsert 进堆中\n    // 编码思路是, 从前往后将每个节点进行 heapInsert\n    // 其时间复杂度为 O(N*logN)\n    for (int i = 0; i < arr.length; i++) {  // O(N)\n        heapInsert(arr, i);                   // O(logN)\n    }\n\n    // 1.2 方式二: 从下向上, 先将每个子堆变为大根堆, 然后再将其父节点纳入再进行 heapify\n    // 编码思路是, 从后往前将每个节点进行 heapify\n    // 该方法速度更快, 其时间复杂度为 O(N)\n    for (int i = arr.length - 1; i >= 0; i--) {\n        heapify(arr, i, arr.length);\n    }\n\n    // 2. 每次将大根堆的根结点元素与最后一个元素交换\n    int heapSize = arr.length;\n    while (heapSize > 0) {                  // O(N)\n        swap(arr, 0, heapSize-1);             // O(1)\n        // 注意 heapSize 先减一再进入 heapify\n        heapify(arr, 0, --heapSize);          // O(logN)\n    }\n\n    // 整体时间复杂度为 O(N*logN)\n}\n\npublic static void heapInsert(int[] arr, int index) {\n    // 向上遍历当前节点的父节点,直到满足条件: 父节点的值 > 当前节点的值\n    while (arr[(index - 1) / 2] < arr[index]) {\n        swap(arr, (index - 1) / 2, index);\n        index = (index - 1) / 2; // index 记得变为父节点的值\n    }\n}\n\n// heapSize 用于表示逻辑上的堆的大小, 其和数组的大小没关系\n// 该方法的作用是, 在给定堆结构中, 当某个位置的元素被弹出,替换成了其他数字后\n// 要保证新的数组仍然保持堆结构, 那么就需要从这个位置开始向下遍历\n// 交换其子节点中最大的元素\npublic static void heapify(int[] arr, int index, int heapSize){\n    if (heapSize > arr.length) {\n        return;\n    }\n\n    while (2*index+1 < heapSize) {\n        // 两个孩子中, 判断谁的值更大\n        int largest = (2*index+2 < heapSize) && arr[2*index+1] < arr[2*index+2]\n            ? 2*index+2 : 2*index+1;\n\n        // 当前节点和子孩子中, 判断谁的值更大\n        largest = arr[index] < arr[largest] ? largest : index;\n\n        // 如果相等, 说明此时已经满足了大根堆的条件, 可以跳出循环\n        if (largest == index) {\n            break;\n        }\n\n        // 交换\n        swap(arr, index, largest);\n        index = largest;\n    }\n}\n\npublic static void swap(int[] arr, int a, int b) {\n    if (a == b) {\n        return;\n    }\n\n    arr[a] = arr[a] ^ arr[b];\n    arr[b] = arr[a] ^ arr[b];\n    arr[a] = arr[a] ^ arr[b];\n}\n```\n\n\n\n---\n\n补充：想让一组数字变成一个大根堆/小根堆结构，上文中的编码方式时间复杂度是 O(N \\* logN)。然后还有一种更快的方式令一个数组变为大根堆/小根堆结构，其时间复杂度为 O(N)\n\n- 方式一：依次将每个数字添加到堆结构中，堆大小从0开始，依次将新数字 heapInsert 进堆中。当遍历完成后，即得到了大根堆，但这种方法的时间复杂度为 O(N \\* logN)\n- 方式二：从下向上，先将每个子堆变为大根堆，然后再将其父节点纳入再进行 heapify。其时间复杂度为 O(N)（其时间复杂度的估计方法使用了错位相减法）\n\n方式二就是一种逆向思维，反过来从后往前遍历数组，令其往后的子树符合大根堆，然后再向前遍历，不断扩大子树的大小，令新的子树也符合大根堆。这样的操作时间复杂度更低，因为整个树上一半的节点都是叶子节点，根本不需要做交换：\n\n![image-20211004203745738](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211004203745738-1633921354763.png)\n\n![image-20211004203713788](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211004203713788-1633921354763.png)\n\n代码：\n\n``` java\n// 1. 先将数组变为大根堆\n// 1.1 方式一: 依次将每个数字添加到堆结构中, 堆大小从0开始, 依次将新数字 heapInsert 进堆中\n// 编码思路是, 从前往后将每个节点进行 heapInsert\n// 其时间复杂度为 O(N*logN)\nfor (int i = 0; i < arr.length; i++) {  // O(N)\n    heapInsert(arr, i);                   // O(logN)\n}\n\n// 1.2 方式二: 从下向上, 先将每个子堆变为大根堆, 然后再将其父节点纳入再进行 heapify\n// 编码思路是, 从后往前将每个节点进行 heapify\n// 该方法速度更快, 其时间复杂度为 O(N)\nfor (int i = arr.length - 1; i >= 0; i--) {\n    heapify(arr, i, arr.length);\n}\n```\n\n---\n\n### 堆排序的扩展：几乎有序的数组\n\n![image-20211004204032904](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211004204032904-1633921378395.png)\n\n**解题思路**：这个移动距离不超过 k 非常重要，这意味着我们可以在 k 范围内组成一个小根堆，这个小根堆的第一个元素就是这个范围内的最小值，依次移动指针，将每个子 k 区域内的数组组成小根堆，即可不断得到当前范围内的最小值，从而完成排序。\n\n具体流程：\n\n- 首先取数组的前 k 个数字，组成小根堆（复杂度为 O(k \\* logk)，或用更快的方式可以达到 O(k)），然后将小根堆第一个位置的元素弹出，放到原数组的0位置，这个数就是整个数组的最小值（因为这道题限制了每个数字的移动距离不会超过 k）\n- 接着向后移动1个位置，再取 k+1 位置上的数 arr[k+1] 与上一步剩下的 k-1 个元素一起再组成新的小根堆后，再取出最新小根堆里的第一个元素（此元素就是整个数组第二小的数）\n\n重复上述过程，直到整个数组被遍历完，即可得到排序后的数组。此过程的时间复杂度为 O(N \\* logk)，如果这个k很小，那么这个算法的时间复杂度就比较接近 O(N)\n\n具体实现既可以通过自己定义堆结构，又可以直接使用 Java 提供的优先级队列：`PriorityQueue<Interger>`，其底层就是一个小根堆结构。\n\n---\n\n小根堆在 Java 中就是**优先级队列**默认的实现方式： `PriorityQueue<Interger>`，其两个方法：\n\n- `add()` ：本质上就是 heapInsert 操作，将一个数字添加到已存在的小根堆中\n- `poll()`：本质上就是 heapify 操作，首先弹出当前小根堆的根结点元素，并令剩余数字依旧保持小根堆结构。\n\n但是其不能支持“修改堆中某个结构后以很轻的代价重新调整堆的结构”，只支持“弹出堆的根结点元素后重新调整堆的结构”，若想实现这些个性化的功能还需要自己定义堆结构。\n\n> 其扩容机制是当 heapSize 快满时，将 heapSize * 2。这个操作的时间复杂度在每个元素平摊下来后其实很低\n\n---\n\n使用 `PriorityQueue<Interger>` 解该题：\n\n``` java\npackage com.zhao;\n\nimport java.util.Arrays;\nimport java.util.PriorityQueue;\n\npublic class SortArrayDistanceLessK {\n    public static void sortArrayDistanceLessK(int[] arr, int k) {\n        if (arr == null || arr.length < 2) {\n            return;\n        }\n\n        // 默认为小根堆\n        PriorityQueue<Integer> heap = new PriorityQueue<>();\n\n        // 0 ~ k-1 位置上的数组成小根堆(这里要取k和arr.length的最小值)\n        for (int i = 0; i < Math.min(k, arr.length); i++) {\n            heap.add(arr[i]);\n        }\n\n        int i = 0;\n        for (; i < arr.length - k; i++) {\n            arr[i] = heap.poll();\n            // 注意索引值不是 i+k+1\n            // 因为整个小根堆的heapSize==k, 所以 \"当前根节点索引+k\" 就是小根堆的下一个索引值\n            heap.add(arr[i + k]);\n        }\n\n        // 上述遍历完毕后, 将大根堆里剩余的数挨个弹出放到数组的最后k个位置\n        while (!heap.isEmpty()) {\n            arr[i++] = heap.poll();\n        }\n    }\n\n    public static void main(String[] args) {\n        int[] arr = new int[]{2,3,1,5,4,6,8,7};\n\n        SortArrayDistanceLessK.sortArrayDistanceLessK(arr, 3);\n        System.out.println(Arrays.toString(arr));\n    }\n}\n```\n\n## 桶排序\n\n> https://www.bilibili.com/video/BV13g41157hK?p=4\n\n词频表 count[10] 中统计某一位小于等于当前数字的个数有多少个，例如下图中，count 数组中 count[2] = 4，代表原数组中个位数小于等于2的数字有4个（21，11，52，62）\n\n![image-20211005184227223](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211005184227223-1633921396069.png)\n\n这个数组存在的意义是，可以通过其索引上的数字为原数组某一位进行**分片**，例如按照个位数字的大小按顺序排列，例如下图中的辅助数组 help[] 就是使用 count 数组将原数组按照个位数字的大小进行分片排序，让个位数字为1的在一起，为2的在一起……：\n\n![image-20211005184133152](/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/image-20211005184133152-1633921396069.png)\n\n遍历流程：\n\n**从右往左**遍历原数组，将遇到的每一个数字放到辅助数组的 `help[count[i]-1]`  位置，并且将 `count[i]--` 。\n\n---\n\n结合上面两幅图，举例说明这样做的原因：\n\n例如先按照**个位**进行分片排序：**从右往左**遍历到62时，当前数字62肯定是“某一位（个位）上数值相同的数字”中排序最靠后的，因此就将其放到 help 数组中“这一位（个位）所处的分片区域”的最靠后位置  `help[count[i]-1]` ，即 `help[3]`。\n\n因为根据 count 数组可知，个位数字小于等于2的数字一共有4个，那么当前从右往左遍历到的数字62就应该是这四个数里的最后一个，即 `help[count[2]-1]`。\n\n记得接下来要将  `count[2]--` ，这样再往左遍历到下一个元素52时，这个排序更靠前一些的数字52就会放到62的前面  `help[count[2]-1] = help[2]`。\n\n---\n\n这样做的目的是，让先入桶的先出桶，达到队列的效果\n\n\n\n\n\n\n\n\n\n\n","tags":["算法"],"categories":["算法"]},{"title":"【Docker】Docker 配置实战案例","url":"/2021/11/09/【Docker】Docker配置实战案例/","content":"\n## 安装 Docker \n\n>  Docker官网： https://www.docker.com/； Docker中文网站: https://www.docker-cn.com/； Docker Hub官网：https://hub.docker.com/\n\n1. CentOS 7 安装 Docker：\n\n``` bash\nyum install -y docker\n```\n\n2. 开启 Docker 服务：\n\n``` bash\nsystemctl start docker.service\n```\n\n3. 查看安装结果：\n\n``` bash\ndocker version\n```\n\n4. 设置开机启动：\n\n``` bash\nsystemctl enable docker.service\n```\n\n5. 配置 docker 镜像下载加速。编辑配置⽂件：\n\n``` bash\nvim /etc/docker/daemon.json\n```\n\n在其中加入加速镜像源地址即可（https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors）：\n\n``` bash\n{\n  \"registry-mirrors\": [\"https://gc2odbl5.mirror.aliyuncs.com\"]\n}\n```\n\n加完加速地址后，重新加载配置⽂件，重启docker 服务即可：\n\n``` bash\nsystemctl daemon-reload\nsystemctl restart docker.service\n```\n\n<!-- More -->\n\n## Docker 安装 MySQL\n\n1. 下载镜像文件\n\n``` bash\n$ docker pull mysql:5.7\n```\n\n2. 创建实例并启动\n\n``` bash\n# --name指定容器名字 -v目录挂载 -p指定端口映射  -e设置mysql参数 -d后台运行\n$ sudo docker run -p 3306:3306 --name mysql \\\n-v /mydata/mysql/log:/var/log/mysql \\\n-v /mydata/mysql/data:/var/lib/mysql \\\n-v /mydata/mysql/conf:/etc/mysql \\\n-e MYSQL_ROOT_PASSWORD=root \\\n-d mysql:5.7\n\n# 参数说明\n-v 将对应文件挂载到主机\n-e 初始化对应\n-p 容器端口映射到主机的端口\n-d 后台运行\n```\n\n3. 添加 MySQL 配置\n\n``` bash\n$ vi /mydata/mysql/conf/my.cnf # 创建&修改该文件\n```\n\n``` \n[client]\ndefault-character-set=utf8\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld]\ninit_connect='SET collation_connection = utf8_unicode_ci'\ninit_connect='SET NAMES utf8'\ncharacter-set-server=utf8\ncollation-server=utf8_unicode_ci\nskip-character-set-client-handshake\nskip-name-resolve\n# skip-grant-tables 取消权限认证\n```\n\n启动后，可以使用 telnet 命令测试 mysql 能否被顺利连接：\n\n``` bash\ntelnet 47.98.120.35 3306\n```\n\n> https://www.jianshu.com/p/b0abc38aa601\n\n如果不能连通，可能的原因：\n\n- 防火墙没有开启 3306 端口\n- 云服务器的安全组没有开通 3306 端口\n- docker 内的 mysql 只允许其所在的服务器连接，不能被其他主机访问。此时需要在 mysql 服务器上设置一下允许的 ip 权限：\n\n``` bash\n# root表示mysql的一个用户名  '%'表示所有远程ip  '123456'是密码\n# 该命令的意思是任何公网IP的都可以通过用户名为root 密码为123456 访问改数据库\ngrant all privileges on *.* to root@'%' identified by 'zhaoyuyun' with grant option;\n\n# 使其立即生效\nflush privileges;\n```\n\n\n\n## Docker 安装 Redis\n\n1. 下载镜像文件\n\n``` bash\ndocker pull redis\n```\n\n2. 创建实例并启动\n\n```bash\nmkdir -p /mydata/redis/conf\ntouch /mydata/redis/conf/redis.conf\n\n# 启动 同时 映射到对应文件夹\n# 后面 \\ 代表换行\ndocker run -p 6379:6379 --name redis \\\n-v /mydata/redis/data:/data \\\n-v /mydata/redis/conf/redis.conf:/etc/redis/redis.conf \\\n-d redis redis-server /etc/redis/redis.conf\n```\n\n3. 使用 redis 镜像执行 `redis-cli` 命令连接\n\n``` bash\ndocker exec -it redis redis-cli\n```\n\n4. 开启 redis 持久化\n\n```bash\nvim /mydata/redis/conf/redis.conf\n\n# 插入下面内容\nappendonly yes\n```\n\n## Docker 安装 Nginx\n\n由于先拉取镜像然后再生成的 nginx 实例里没有包含配置文件，因此需要先直接启动一个 nginx 实例，并将其内生成的配置文件拷贝到宿主服务器中，然后再删掉这个启动的实例，重新按照标准流程生成一个 nginx 实例并挂载到宿主服务器的指定目录下。\n\n1. 先直接启动一个 nginx  实例，为了将其自动生成的配置文件复制出来\n\n``` bash\ndocker run -p80:80 --name nginx -d nginx:1.10   \n```\n\n2. 将容器内自动生成的配置文件拷贝到宿主服务器\n\n``` bash\ndocker container cp nginx:/etc/nginx /mydata/\n```\n\n3. 将拷贝出的文件夹` /mydata/nginx` 重命名为 `/mydata/conf`，并创建文件夹 `/mydata/nginx`，将 `/mydata/conf` 文件夹移动到 `/mydata/nginx` 文件夹内 \n\n``` bash\n# 重命名\nmv /mydata/ngnix/ /mydata/conf\n\n# 创建新的nginx文件夹\nmkdir /mydata/nginx\n\n# 移动到新的nginx文件夹下\nmv /mydata/conf /mydata/nginx/\n```\n\n4. 在 `/mydata/nginx` 目录下新建两个文件夹分别存放网页和日志\n\n``` bash\nmkdir -p /mydata/nginx/html\nmkdir -p /mydata/nginx/logs\n\n# 在html文件夹下创建 index.html 文件即可作为默认的nginx首页\nvim /mydata/nginx/html/index.html\n```\n\n5. 停止并删除之前创建的 nginx 实例\n\n``` bash\ndocker stop nginx\ndocker rm nginx  \n```\n\n6. 启动新的 nginx 实例，并进行挂载，此时就完成了配置文件的初始化\n\n``` bash\ndocker run -p 80:80 --name nginx \\\n -v /mydata/nginx/html:/usr/share/nginx/html \\\n -v /mydata/nginx/logs:/var/log/nginx \\\n -v /mydata/nginx/conf/:/etc/nginx \\\n -d nginx:1.10\n```\n\n7. 设置自启动\n\n``` bash\ndocker update nginx --restart=always\n```\n\n关于 Nginx 的详细配置方法见文章：https://yuyun-zhao.github.io/2021/07/26/%E3%80%90Nginx%E3%80%91Nginx/\n\n## Docker 安装 ElasticSearch\n\n1. 下载镜像文件\n\n``` bash\ndocker pull elasticsearch:7.4.2\n\ndocker pull kibana:7.4.2\n```\n\n2. 配置\n\n``` bash\nmkdir -p /mydata/elasticsearch/config  # 存放配置文件\nmkdir -p /mydata/elasticsearch/data    # 存放数据\nmkdir -p /mydata/elasticsearch/plugins # 存放插件\necho \"http.host: 0.0.0.0\" >/mydata/elasticsearch/config/elasticsearch.yml # 允许任何机器访问\nchmod -R 777 /mydata/elasticsearch/ ## 设置elasticsearch文件可读写权限，否则将无法启动\n```\n\n3. 启动（9300 端口为 Elasticsearch 集群间组件的通信端口， 9200 端口为浏览器访问的 HTTP 请求端口）\n\n``` bash\ndocker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\\n-e  \"discovery.type=single-node\" \\\n-e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" \\\n-v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\\n-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \\\n-v  /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\\n-d elasticsearch:7.4.2 \n```\n\n4. 设置自启动\n\n``` bash\ndocker update elasticsearch --restart=always\n```\n\n5. 启动 Kibana\n\n``` bash\ndocker run --name kibana -e ELASTICSEARCH_HOSTS=http://yuyunzhao.cn:9200 -p 5601:5601 -d kibana:7.4.2\n# http://xxx:9200 改成自己 Elasticsearch 的地址\n```\n\n在浏览器访问 5601 端口即可进入到界面\n\n### 安装 ik 分词器\n\n从 https://github.com/medcl/elasticsearch-analysis-ik/releases 下载 ik 分词器并拷贝解压到 `/mydata/elasticsearch/plugins` 目录下即可。\n\n### 自定义词库\n\n1. 修改 `/mydata/elasticsearch/plugins/ik/config` 目录下的 `IKAnalyzer.cfg.xml` 文件，在其内写上远程字典地址：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\">\n<properties>\n        <comment>IK Analyzer 扩展配置</comment>\n        <!--用户可以在这里配置自己的扩展字典 -->\n        <entry key=\"ext_dict\"></entry>\n         <!--用户可以在这里配置自己的扩展停止词字典-->\n        <entry key=\"ext_stopwords\"></entry>\n        <!--用户可以在这里配置远程扩展字典 -->\n         <entry key=\"remote_ext_dict\">http://yuyunzhao.cn/es/fenci.txt</entry>\n        <!--用户可以在这里配置远程扩展停止词字典-->\n        <!-- <entry key=\"remote_ext_stopwords\">words_location</entry> -->\n</properties>\n```\n\n其中，远程字典文件 `/es/fenci.txt` 创建在了 nginx 的 `/mydata/nginx/html` 目录下，这样才可以被其他服务器访问到。\n\n2. 在词典中添加自定义的分词：\n\n``` bash\n乔碧萝\n```\n\n3. 添加了分词后记得重新启动 elasticsearch 服务：\n\n``` bash\ndocker restart elasticsearch\n```\n\n4. 这样在检索时就可以指定分词器为 ik 分词器：\n\n``` bash\nPOST _analyze\n{\n  \"analyzer\": \"ik_max_word\", # 还有 ik_smart 等分词器\n  \"text\": [\"乔碧萝殿下\"]\n}\n```\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Docker","Linux"],"categories":["Docker","Linux"]},{"title":"【MySQL】MySQL 索引","url":"/2021/10/28/【MySQL】MySQL索引/","content":"\n![image-20210913132511709](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20210913132511709.png)\n\n> MySQL官方对索引的定义为：索引（Index）是帮助 MySQL 高效**查找**数据的**排好序**的**数据结构**。其中，排好序体现在 B+ 树最底层页结构组成的**双向链表**结构上。\n\n索引的本质：索引是一种**数据结构**。\n\n- 查找：体现在 WHERE、ON 等条件判断上\n- 排序：体现在 ORDER BY、GROUP BY 分组排序上\n\n## 索引简介\n\n索引在数据库表的字段上添加，是为了**提高查询效率**而存在的一种机制。索引是各种数据库进行优化时的重要手段，优化时优先考虑的因素就是索引。一张表的一个字段可以添加一个索引，多个字段联合起来也可以添加索引。\n\n索引相当于一本书的目录，是为了缩小扫描范围而存在的一种机制。MySQL 在查询方面主要是两种方式：\n\n- **全表扫描**：一条一条检索，效率较低\n- **根据索引检索**：先通过索引定位大概位置，然后在此局部范围内扫描，效率较高\n\n索引是在 MySQL 的**存储引擎层**中实现的，而不是在服务器层实现的。所以每种存储引擎的索引都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型的。MySQL 目前提供了以下4种索引：\n\n- BTREE 索引 ： 最常见的索引类型，大部分索引都支持 B 树索引。\n- HASH 索引：只有Memory引擎支持 ， 使用场景简单 。\n- R-tree 索引（空间索引）：空间索引是MyISAM引擎的一个特殊索引类型，主要用于地理空间数据类型，通常使用较少，不做特别介绍。\n- Full-text （全文索引） ：全文索引也是MyISAM的一个特殊索引类型，主要用于全文索引，InnoDB从Mysql5.6版本开始支持全文索引。\n\n<center><b>MyISAM、InnoDB、Memory三种存储引擎对各种索引类型的支持</b></center>\n\n| 索引        | InnoDB 引擎      | MyISAM 引擎 | Memory 引擎 |\n| ----------- | ---------------- | ----------- | ----------- |\n| BTREE 索引  | 支持             | 支持        | 支持        |\n| HASH 索引   | 不支持           | 不支持      | 支持        |\n| R-tree 索引 | 不支持           | 支持        | 不支持      |\n| Full-text   | 5.6 版本之后支持 | 支持        | 不支持      |\n\n我们平常所说的索引，如果没有特别指明，都是指B+树（多路搜索树，并不一定是二叉的）结构组织的索引。其中聚集索引、复合索引、前缀索引、唯一索引默认都是使用 B+tree 索引，统称为索引。\n\n### 索引的分类\n\n> 在一个表中，主键索引只能有一个，唯一索引可以有多个\n\n- 主键索引（PRIMARY KEY)：唯一的标识，主键不可重复，只能有一列作为主键\n- 唯一索引（UNIQUE KEY）：唯一索引的名字不能重复出现，避免重复的列出现，唯一索引可以有多个\n- 常规索引（KEY/INDEX）：默认的，用INDEX或KEY来设置\n- 全文索引（FULLTEXT）：快速定位数据（一般用Elastic Search做全文索引）\n\n### 索引的数据结构\n\n索引的数据结构理论上可以采用以下五种：\n\n- 二叉树\n- 红黑树\n- Hash 表\n- B 树\n- B+ 树\n\n**在 MySQL 当中，索引采用最多的是 B+ 树（多路搜索树）数据结构**。遵循左小右大原则存放，采用中序遍历方式遍历取数据。\n\n<!-- More -->\n\n## MySQL 索引结构\n\n为什么 MySQL 采用 B+ 树结构而不采用其他数据结构呢？下面依次分析其他几种结构存在的弊端。\n\n### 二叉树和红黑树\n\n二叉树与红黑树的每一个节点**自身只能存储一个索引**，且**只能指向两个索引**，这种存储效率是很低的，当数据量较大时，树的高度会很高。千万级的索引量需要树高达十几二十层，这样进行检索需要遍历许多层，效率不够高。\n\n二叉树索引的示意图：\n\n![image-20211030140707972](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211030140707972.png)\n\n### Hash 表\n\n使用 Hash 表的结构，能够提高**确定常数值**（const）的查询效率，例如：\n\n```sql\nselect * from t1 where t1.col1 = 22;\n```\n\n因为每个索引值的 Hash 值基本都不相同，因此查找时可以直接定位到其位置。\n\n但是其缺点也很明显：当需要区间查找时，使用 Hash 表就无法实现快速的定位目标区间。因为其只能快速定位单个索引的位置，无法定位一个区间内的位置。例如：\n\n```sql\nselect * from t1 where t1.col1 > 22;\n```\n\n这种情况下，Hash 表就无法快速检索了。因此开发中基本不采用这种结构。\n\n> Memory 存储引擎使用 Hash 表结构，因为其数据都是在内存中的，因此遍历的速度是很快的，哪怕是范围查询，也可以在内存中快速的遍历出符合条件的数据。但 InnoDB 的数据是在硬盘中的，频繁的遍历需要大量的IO操作，降低了效率\n\n\n\n### B 树\n\n> B 代表 Balanced，平衡\n\nB 树是一种**自平衡多叉树**，一个节点可以拥有2个以上的子节点（最大子节点数 + 1 = 其阶数m）。一个 B 树的节点内可以划分多个区间，从而在检索时能够快速定位到子区间。在实际应用中的B树的阶数m都非常大（通常大于100），所以**即使存储大量的数据，B 树的高度仍然比较小**。B 树的特点：\n\n- **叶节点具有相同的深度**（体现了 B 树平衡的特性），叶节点的指针为空\n- **所有索引元素不重复**（B+ 树的叶子节点会包含所有索引）\n- 节点中的数据索引从左到右**递增排序**\n- **每个节点都同时存储索引值和其存储的数据**（B+ 树只有叶子结点存储数据，非叶子节点不存储数据，MyISAM只保存数据逻辑地址，数据和索引的存储位置是分开的）\n\n> 2-3 树和 2-3-4 树是一种特殊的 B 树。\n\nB 树结构图解：\n\n![1555903449006](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555903449006-1635424297505.png)\n\n![img](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/834468-20180406232632321-1557309284.png)\n\n上图是一颗阶数为 4 的 B 树。在实际应用中的B树的阶数 m 都非常大（通常大于100），所以即使存储大量的数据，B树的高度仍然比较小。每个结点中存储了关键字（key）和关键字对应的数据（data），以及孩子结点的指针。**其中，key 代表表中某条记录的索引值，data 为其在硬盘上的逻辑地址（以 MyISAM 为例）**。在数据库中我们将B树（和B+树）作为索引结构，可以加快查询速度，此时 B 树中的 key 就表示索引键，而 data 表示了这个键对应的条目在硬盘上的逻辑地址。\n\n> 至于 data 中是存储真实数据还是数据的逻辑地址，要视存储引擎而定\n\n简易结构图：\n\n![image-20211028163552324](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211028163552324.png)\n\n> B 树的优点\n\nB 树相比于二叉树和红黑树而言，每一个节点能存储的索引数量大大增加，从而在数据量相同的情况下极大地**减少了整棵树的高度**。通过调大 B 树每一个节点存储的索引个数（阶数m - 1），可以在千万级的数据量的情况下，保持树的高度不超过4。这与二叉树红黑树需要十几层的结构相比，无疑提高了性能。\n\n但 B 树与下面要介绍的 B+ 树相比，还是存在许多弊端的。\n\n### B+ 树\n\nB+ 树是 B 树的变种，**其拥有比 B 树更快的查询效率**。B+ 树的特点：\n\n- 只有叶子节点存储数据，**非叶子节点只存储索引和页地址**，不存储数据\n- 叶子节点包含所有索引字段\n- 叶子节点中的数据索引从左到右**递增排序**（这也是索引被称为**排好序**的数据结构的原因）\n- 叶子节点间使用两个指针相互连接，构成一个**双向链表**，**提高区间访问的性能**\n\n> B+ 树中每个“叶子节点”实际上是一个**页（Page）**，本节先用叶子节点称呼以方便理解，下文再详细分析页的结构\n\nB+ 树结构图解：\n\n![1555906287178](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555906287178-1635424301698.png)\n\n> 图中每一个磁盘块即为一个页结构\n\n根节点层的索引是常驻内存的，直接省掉一次 IO 成本。高版本的 MySQL 不仅根节点层，其叶子节点层也会直接放在内存中，效率更高。\n\n> B+ 树的优点\n\n1、**千万级数据量下，B+ 树最少可以只占 3 层**。\n\n原因：MySQL 里，每一个节点（页）分配的物理空间为 16kb。一个索引的类型为 bigint，占 8 个字节；两个索引间的指针地址占 6 个字节，因此每一个非叶子节点（页）最多分配 16 kb / (8 + 6) b = 1170 个。因此两页就可以分配 1170*1170 个索引，那么只需要三层（前两层只放索引，最后一层放索引和数据）即可容纳上千万条索引。这与二叉树和红黑树需要十几二十层相比，无疑提高了效率。\n\n2、B+ 树**只在叶子节点存储数据**，从而在占用相同空间大小（高度相同）的情况下，**B+ 树所能存储的索引数远大于 B 树**。\n\n原因：B 树的所有节点都会存储数据，这样每一个索引（bigint类型，占8个字节）都需要配上一个数据（可能占 1kb 个字节）（以 InnoDB 引擎为例），从而一个单位大约占 1kb 个字节。而 B+ 树的非叶子节点只用存储索引，无需存储数据地址，因此一个单位只占8个字节。这就导致了在占用相同空间大小的情况下，B+ 树所能存储的索引数远大于 B 树。\n\n3、B+ 树可以很好地处理**区间查找**。\n\n原因：B+ 树的叶子节点之间使用两个指针相互连接，构成一个**双向链表**结构。同时这条双向链表上的索引值是按照升序排列，因此也是**排好序**的。这样在进行区间查找时，只要找到这个区间的临界索引值，即可按着某一个方向一直遍历目标区间的所有数据。\n\n例如上图中要想查询主键大于15的所有数据，只需要先找到主键为15的节点位置，然后一直沿着链表升序方向遍历即可得到所有主键大于15的数据。这一点上，B 树是无法做到的。\n\n\n\n### B+ 树与 B 树的区别\n\nB+ 树可以看成是对 B 树的优化改造：\n\n- B+ 树只在叶子结点存储数据的逻辑地址，非叶子节点只存储索引（从而增加了每一层可存放的索引个数）\n- B+ 树的非叶子节点上存在的索引也会出现在叶子节点上\n- B+ 树的叶子节点组成了一个双向链表结构（从而提高了区间查找效率）\n\n\n\n### InnoDB 中的页（Page）\n\n> **页**结构即为前面 B+ 树中的**叶子节点的实际数据结构**\n\n**页（Page） 是 InnoDB 存储的最基本结构**，也是 InnoDB 磁盘管理的**最小单位**，与数据库相关的所有内容都存储在Page结构里。Page分为几种类型：`数据页（B-Tree Node）`，`Undo页（Undo Log Page）`，`系统页（System Page）`，`事务数据页（Transaction System Page）`等。**每个数据页的大小为 16kb**。\n\n页是 InnoDB 从磁盘中**读取数据**时的一个基本单位，即一次从磁盘中最少取 16 kb 的数据组成一个页单位。\n\n> InnoDB 取数据时的单位为页，而不是行。一次取一页，而不是一次取一行\n\n页的结构示意图：\n\n<img src=\"/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211029143152391.png\" alt=\"image-20211029143152391\" style=\"zoom:67%;\" />\n\n> 图里省略了每个数据对应的**索引信息**，只画出了数据信息和页目录。索引信息实际上是和数据存储在一起的\n\n一个页结构中：\n\n- **用户数据区域**：存储每条索引对应的真实数据\n- **页目录区域**：相当于一个本书的目录，便于快速定位到目标索引位置。其内存储着索引分组，一个分组包含六条索引。页目录的目的：用少量空间换取遍历时间。例如想在当前页内查找索引值为 10 的记录，不需要从第一个索引开始一一遍历每个索引，而是可以直接在页目录内遍历，先找到**大致区间**，然后再在该子区间内逐个遍历直到找到目标索引\n- **页头**：存储着前向指针和后向指针，用于链接前后两个页组成一条**双向链表**\n\n对比上文中分析的 B+ 树结构：\n\n![1555906287178](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555906287178-1635424301698.png)\n\n> 该图中只画了每条索引和其数据，省略了页结构中的**页目录**\n\n一个磁盘块即为一个页结构，上层的页结构中只保存索引值和其对应的地址（因此可以存储非常多的索引，大约1170个），最底层的页结构中既保存了索引值，又保存了真实数据。通常将最底层的页叫**数据页**，上层的页叫**索引页**。\n\n索引特性里的**排好序**体现在：\n\n- 最底层的每一个页**内部**都是排好序的\n- 每个页和**相邻的两个页之间**也是排好序的\n\n**全表扫描**方式：沿着最底层页组成的双向链表进行遍历，从最左侧页的第一个索引开始，沿着双向链表一直遍历所有索引。\n\n\n\n#### 页分裂\n\n如果新插入的一条数据的索引值小于目前页中索引的最大值，并且当前页的数据量即将超出 16kb，此时即需要进行页分裂：将当前数据插入到当前页内索引大小合适的位置，并将原先的索引最大的数据调整到新的一页中，也就说整棵树结构进行了调整。\n\n可以看出，这种页分裂的操作会增加额外的操作，无疑会降低效率。\n\n而如果使用自增索引，插入新数据时就不会出现分裂的情况，因为新插入的索引值肯定比原先的都大，所以不需要进行页分裂。效率就会明显提升。\n\n\n\n### 复合索引的数据结构\n\n复合索引同样采用 B+ 树的数据结构，只不过从单个索引变为了多个索引：\n\n![image-20211028202151731](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211028202151731.png)\n\n索引的比较顺序是有优先级的，先判断高优先级的索引，再判断低优先级的索引（索引的优先级是由创建索引时的顺序决定的）。以上图为例，先比较第一个索引 `name` ，再比较第二个索引 `age`，最后比较第三个索引 `position`。\n\n复合索引时，就涉及到了索引**最左前缀原则**。\n\n\n\n## 存储引擎中索引的实现\n\n### MyISAM \n\nMyISAM 索引文件和数据文件是**非聚集**（分离）的（**非聚集索引**）：索引和数据存储的位置是分离的，其在磁盘上的位置：\n\n- `*.frm`  表结构的定义文件\n- `*.MYD` 数据文件（data）\n- `*.MYI`  索引文件（index）\n\n以主键索引为例，描述 MyISAM 中 B+ 树的索引和真实数据间的关系：\n\n![image-20211028155748763](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211028155748763.png)\n\n可以看到，整棵树上索引值的存储地址和真实数据的存储地址是分开的，每个索引只携带其对应数据的逻辑地址而不存储真实数据。\n\n### InnoDB\n\nInnoDB 索引文件和数据文件是**聚集**的（**聚集索引**）：索引和数据是存储在一起的，叶子结点包含了完整的数据记录，其在磁盘上的位置：\n\n- `*.frm`  表结构的定义文件\n- `*.ibd` 数据和索引共同存储在一个文件中\n\n以**主键**索引为例，描述 InnoDB 中 B+ 树的索引和真实数据间的关系：\n\n![image-20211028204317324](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211028204317324.png)\n\n可以看到，索引和数据是存储在一起的，叶子节点中既包含索引值，又包含数据。这样做的好处，**用内存空间换查询效率**：直接将数据本身也加载到内存中，这样查询数据时减少了一次向磁盘中另一个文件查询数据内容的 IO 操作，效率会更高一些。**相应的代价**是每一层存储的节点数量要少于只存储逻辑地址的方式，因为一个数据占用的内存空间要远大于一个地址。\n\n**非主键**索引（第二索引）则存储的不是真实数据，而是存储的**对应数据的主键索引的值**：\n\n![image-20211028205257723](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211028205257723.png)\n\n根据第二索引进行查找时，将先找到目标数据的主键索引，然后再去根据主键索引值查找真实数据，这样性能明显是不如直接根据主键索引查找。这个过程也被称为**回表**（回去找主键索引树上存储的表数据）。\n\n但这样做的好处是：\n\n- **节省存储空间**：真实数据只存储在内存中的一个地方，节省了空间\n- **保证数据的一致性**：因为数据只有一份，所以高并发下不会出现数据更新不一致的情况\n\n> 为什么 InnoDB 表必须有主键，且推荐索引使用自增整数类型？\n\n1. 使用整型的原因：整型数据比大小比较快，占用字节也比较少（UUID这种字符串比大小比较慢，占用字节也多）\n2. 使用自增的原因：如果使用自增索引，那么使用 insert 新添加的索引只需要向当前最大索引后面添加即可，并不需要重新调整整棵树的结构，不需要让树进行分裂再重新平衡，这样插入速度就会比较快；而如果不自增的话， 随便插入很容易让节点进行分裂、让树重新调整平衡，速度就会降低\n\n#### InnoDB 中的两种扫描方式\n\n- **全表扫描**方式：沿着最底层页组成的双向链表进行遍历，从最左侧页的第一个索引开始，沿着双向链表一直遍历所有索引。\n- **索引 + 回表**扫描方式：主要针对非主键索引。先按照非主键索引进行快速查询，查到其对应的主键值后，再回表去查询主键树中的真实数据。\n\nInnoDB 会在不同的场景下权衡使用哪种方式，找出一种更高效的方式进行实际查询。\n\n\n\n\n\n\n\n## 索引语法\n\n> 创建索引\n\n``` sql\nCREATE INDEX emp_ename_index ON emp(ename);\n```\n\n给`emp`表的`ename`字段添加索引并起别名：`emp_ename_index`。\n\n> 删除索引\n\n``` sql\nDROP INDEX emp_ename_index ON emp;\n```\n\n将`emp`表上的`emp_ename_index`索引对象删除。\n\n> 查看某一个SQL语句是否使用了索引进行检索\n\n``` sql\nEXPLAIN SELECT * FROM emp WHERE ename = 'KING';\n```\n\n> 索引的使用\n\n```sql\n-- 1. 在创建表的时候给字段增加索引\n-- 2. 创建完毕后，增加索引\nSHOW INDEX FROM student;\n\n-- 增加一个全文索引  ADD FULLTEXT INDEX 索引名（列名）\nALTER TABLE school.`student` ADD FULLTEXT INDEX `studentName`(`studentName`);\n\n-- EXPLAIN 分析sql执行的状况 \n\nEXPLAIN SELECT * FROM student; -- 非全文索引\n\nSELECT * FROM student WHERE MATCH(studentName) AGAINST('张');\n```\n\n\n\n## 索引设计原则\n\n索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑符合这些原则，便于提升索引的使用效率，更高效的使用索引。\n\n- 索引不是越多越好（因为索引也是需要维护的，太多的话反而降低性能）\n- 不要对经常变动的数据加索引（因为DML之后，索引需要重新排序）\n- 小数据量的表不需要加索引（数据量庞大时才需要）\n- 对**查询频次较高**，**且数据量比较大**的表建立索引\n- 索引一般加在常用来查询的字段上（常出现在`WHERE`之后）\n- 建议通过主键或`UNIQUE`字段修饰的字段进行查询（区分度越高）\n- 使用短索引，索引创建之后也是使用硬盘来存储的。假如构成索引的字段总长度比较短，那么在给定大小的存储块内可以存储更多的索引值，相应的可以有效的提升 MySQL 访问索引的 I/O 效率。\n- 利用最左前缀原则，N个列组合而成的组合索引，那么相当于是创建了N个索引，如果查询时where子句中使用了组成该索引的前几个字段，那么这条查询SQL可以利用组合索引来提升查询效率。\n\n\n\n## EXPLAIN 指令\n\n`EXPLAIN`：SQL 的执行计划，使用 `EXPLAIN` 关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理SQL语句的。\n\n查询 SQL 语句的执行计划 ： \n\n```sql\nexplain select * from tb_item where id = 1;\n```\n\n![1552487489859](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552487489859.png)\n\n```sql\nexplain select * from tb_item where title = '阿尔卡特 (OT-979) 冰川白 联通3G手机3';\n```\n\n![1552487526919](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552487526919.png)\n\n各个字段的含义：\n\n- `id`：表的读取顺序。\n- `select_type`：数据读取操作的操作类型。\n- `possible_keys`：哪些索引可以使用。\n- `key`：哪些索引被实际使用。\n- `ref`：表之间的引用。\n- `rows`：每张表有多少行被优化器查询。\n- `extra`：额外信息\n\n### EXPLAIN 字段\n\n#### id\n\n`id`：表的读取和加载顺序。值有以下三种情况：\n\n- `id`相同，执行顺序由上至下。\n- `id`不同，如果是子查询，id的序号会递增，**id值越大优先级越高，越先被执行。**\n- `id`相同不同，同时存在。**永远是id大的优先级最高，id相等的时候顺序执行。**\n\n示例：\n\n```sql\nEXPLAIN SELECT * FROM t_role r , (SELECT * FROM user_role ur WHERE ur.`user_id` = '2') a WHERE r.id = a.role_id ; \n```\n\n![1556103294182](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556103294182.png)\n\n 先执行 id = 2 的，然后按上到下顺序执行 id = 1 的。\n\n\n\n#### select_type\n\n`select_type`：数据查询的类型，主要是用于区别，普通查询、联合查询、子查询等的复杂查询。\n\n- `SIMPLE`：简单的`SELECT`查询，查询中不包含子查询或者`UNION `。\n- `PRIMARY`：查询中如果包含任何复杂的子部分，最外层查询则被标记为`PRIMARY`。\n- `SUBQUERY`：在`SELECT`或者`WHERE`子句中包含了子查询。\n- `DERIVED`：在`FROM`子句中包含的子查询被标记为`DERIVED(衍生)`，MySQL会递归执行这些子查询，把结果放在临时表中。\n- `UNION`：如果第二个`SELECT`出现在`UNION`之后，则被标记为`UNION`；若`UNION`包含在`FROM`子句的子查询中，外层`SELECT`将被标记为`DERIVED`。\n- `UNION RESULT`：从`UNION`表获取结果的`SELECT`。\n\n\n\n#### type\n\n`type`：访问类型排列。\n\n**从最好到最差依次是：**`system`>`const`>`eq_ref`>`ref`>`range`>`index`>`ALL`。除了`ALL`没有用到索引，其他级别都用到索引了。\n\n一般来说，得保证查询至少达到`range`级别，最好达到`ref`。\n\n- `system`：表**只有一行记录**（等于系统表），这是`const`类型的特例，平时不会出现，这个也可以忽略不计。\n- `const`：表示**通过索引一次就找到了**，`const`用于比较`primary key`或者`unique`索引。因为只匹配一行数据，所以很快。如将主键置于`where`列表中，MySQL就能将该查询转化为一个常量。\n- `eq_ref`：唯一性索引扫描，读取本表中和**关联**表表中的每行组合成的一行，查出来只有一条记录。除了 `system` 和` const` 类型之外，这是最好的联接类型。\n- `ref`：**非唯一性**索引扫描，返回匹配某个单独值的**所有行**。本质上也是一种索引访问，返回所有匹配某个单独值的所有行（有多行匹配）\n- `range`：只检索**给定范围**的行，一般就是在`WHERE`语句中出现了`BETWEEN`、`< >`、`in`等的查询。这种范围扫描索引比全表扫描要好，因为它只需要开始于索引树的某一点，而结束于另一点，不用扫描全部索引。\n- `index`：`Full Index Scan`，**全索引扫描**，`index`和`ALL`的区别为`index`类型只遍历索引树。**也就是说虽然`ALL`和`index`都是读全表，但是`index`是从索引中读的，`ALL`是从磁盘中读取的**。\n- `ALL`：`Full Table Scan`，没有用到索引，全表扫描。\n\n---\n\n下面逐个分析比较常见的几个类型。\n\n1. `const`：唯一性索引扫描（**常数**）。出现在使用`primary key`或者`unique`索引、并**只匹配一行**数据时。例如：\n\n```sql\nselect * from t_user where id = 1;\n```\n\n因为要查询的索引是唯一的，因此可以在对应的索引树上直接快速定位到目标数据，不需要做额外的遍历。只需要有限次地在树中查找即可快速定位。\n\n2. `eq_ref`：唯一性索引扫描。和 `const` 一样，同样要求查询的是**唯一性索引**，但必须要**联表查询**，常用于A表的主键关联B表的主键。因为要查找的索引是唯一的，所以可以直接定位到目标数据，不需要在树上进行大量遍历。例如：\n\n```sql\nselect * from t_user u, t_role r where u.id = r.id;\n```\n\n上述查询用到了两个表，并且两个表要匹配的字段都是唯一性索引，这时也能有限次地在树中快速定位到目标数据。\n\n3. `ref`：**非唯一性**索引扫描。与 `const` 相比，区别在于要查询的不是唯一性索引，有多条记录可以与目标索引匹配，返回结果也是多行数据（`const`只返回一行）。因为这些行的索引值是相同的，所以同样可以在对应索引树上快速定位到这些行的数据，同样不需要额外遍历。例如：\n\n```sql\nselect * from t_user where name = \"bill\";  -- name 索引不是唯一性索引\n```\n\n4. `range`：只检索**给定范围**的行，一般就是在`WHERE`语句中出现了`BETWEEN`、`< >`、`in`等的查询。这种范围扫描索引比全表扫描要好，因为它只需要开始于索引树的某一点，而结束于另一点，不用扫描全部索引（只需要先定位到临界值的位置，然后**沿着最底层页组成的双向链表一直遍历**即可）。例如：\n\n``` sql\nselect * from t_user where id > 5;\n```\n\n查找时，先查询 id = 2 的数据位置，然后沿着双向链表的方向一直向后遍历所有数据即可。\n\n5. `index`：**全索引扫描**。常出现在**查询某个索引对应的全部数据**（而不是整个表的所有数据），与 `all` 的区别在于，不需要去主键树上遍历整个表的数据，而只需要在目标索引树上遍历最底层页上的所有**索引数据**即可。这是因为查询时只要求返回索引数据，不需要全表数据，所以没必要去主键树上遍历全表数据，只需要在目标索引树上遍历全部目标索引值即可。效率略高于 `all`。例如：\n\n``` sql\nselect name from t_user;\n```\n\n因为 `name` 所在的索引树上天然就保存了 `name` 的信息（因为索引数据就是 `name` 字段本身），所以直接在该索引树上遍历即可得到所有 `name` 数据。\n\n6. `all`：**全表扫描**。效率最差的一种查询，需要去主键树上遍历全表数据。例如：\n\n``` sql\nselect * from t_user;\n```\n\n> index 与 all 的区别在于：要查询的结果是否恰好是建了索引的列\n\n---\n\n\n\n#### possible_keys 和 key\n\n`possible_keys`：显示可能应用在这张表中的索引，一个或者多个。查询涉及到的字段上若存在索引，则该索引将被列出，**但不一定被查询实际使用。**\n\n`key`：实际使用的索引。如果为`NULL`，则没有使用索引。**查询中如果使用了覆盖索引，则该索引仅仅出现在`key`列表中**。示例（col1、col2 组成了复合索引）：\n\n```sql\nmysql> explain select col1, col2 from t1;\n\n-- possible_keys: NULL\n-- key: idx_col1_col2\n-- Extra: Using index\n```\n\n这种情况，因为 sql 语句中没有显式指定用索引去查找，所以 `possible_keys` 显示为 NULL，而又因为要查找的 col1、col2 恰好建了索引，所以 `key` 为 `idx_col1_col2`。同时只出现了 `Using index`，而没有 `Using where` ，表明索引只用来读取数据而没有执行查找动作。\n\n上述例子不是全表扫描，而是索引的原因：`col1`和`col2`索引不涉及存储数据，所以每一页存储的索引更多，从而页数更少，所以从磁盘读取页数据的次数更少，效率更高，所以可以直接从这些索引构成的树上遍历得到覆盖索引值。\n\n\n\n#### key_len\n\n`key_len`：表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度。`key_len`显示的值为索引字段的最大可能长度，并非实际使用长度，即`key_len`是根据表定义计算而得，不是通过表内检索出的。在不损失精度的情况下，长度越短越好。\n\n`key_len`计算规则：**https://blog.csdn.net/qq_34930488/article/details/102931490**\n\n```shell\nmysql> desc pms_category;\n+---------------+------------+------+-----+---------+----------------+\n| Field         | Type       | Null | Key | Default | Extra          |\n+---------------+------------+------+-----+---------+----------------+\n| cat_id        | bigint(20) | NO   | PRI | NULL    | auto_increment |\n| name          | char(50)   | YES  |     | NULL    |                |\n| parent_cid    | bigint(20) | YES  |     | NULL    |                |\n| cat_level     | int(11)    | YES  |     | NULL    |                |\n| show_status   | tinyint(4) | YES  |     | NULL    |                |\n| sort          | int(11)    | YES  |     | NULL    |                |\n| icon          | char(255)  | YES  |     | NULL    |                |\n| product_unit  | char(50)   | YES  |     | NULL    |                |\n| product_count | int(11)    | YES  |     | NULL    |                |\n+---------------+------------+------+-----+---------+----------------+\n9 rows in set (0.00 sec)\n\n\nmysql> explain select cat_id from pms_category where cat_id between 10 and 20 \\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: pms_category\n   partitions: NULL\n         type: range\npossible_keys: PRIMARY\n          key: PRIMARY  # 用到了主键索引，通过查看表结构知道，cat_id是bigint类型，占用8个字节\n      key_len: 8        # 这里只用到了cat_id主键索引，所以长度就是8！\n          ref: NULL\n         rows: 11\n     filtered: 100.00\n        Extra: Using where; Using index\n1 row in set, 1 warning (0.00 sec)\n```\n\n#### ref\n\n`ref`：当前表的索引引用了其他表的哪些索引。如果没引用其他表的索引，就是 const，否则就显示那些索引。示例：\n\n```sql\nmysql> explain select t2.* \n    -> from t1, t2, t3 \n    -> where t1.id = t2.id and t1.id = t3.id\n    -> and t1.other_colum = '';\n    \n+-----------------+-------------+\n| table | type    | ref         |\n+-----------------+-------------+\n| t1    | ref     | const       |\n| t3    | eq_ref  | test.t1.ID  |\n| t2    | eq_ref  | test.t1.ID  |\n+-----------------+-------------+\n```\n\n\n\n#### rows\n\n`rows`：根据表统计信息及索引选用情况，大致估算出找到所需的记录需要读取的行数。\n\n#### Extra\n\n`Extra`：包含不适合在其他列中显示但十分重要的额外信息，**主要用于显示 `ORDER BY` 和 `GROUP BY` 语句进行排序时的执行计划**。\n\n- `Using filesort`：出现在使用 `order by` 进行排序的情况下，说明 MySQL 会对数据使用一个**外部的索引排序**，而不是按照表内的索引顺序进行读取（因为查询时没有指定按照索引列进行 order by，而是按照非索引列进行排序）。**MySQL 中无法利用索引完成的排序操作成为\"文件内排序\"。**\n- `Using temporary`：使用了**临时表**保存中间结果，MySQL在对查询结果排序时使用了临时表。常见于**分组查询**`group by`。**临时表对系统性能损耗很大**，比`Using filesort`更糟糕。\n- `Using index`：表示相应的`SELECT`操作中使用了**覆盖索引**（要查询的字段恰好全部都建了索引），避免访问了表的数据行（只需要访问索引列），效率不错！如果同时出现`Using where`，表示索引被用来执行索引键值的查找；如果没有同时出现`Using where`，表明索引用来读取数据而非执行查找动作。\n\n> 排序时，如果是根据索引列进行排序，则会 `Using index`，如果根据非索引列进行排序，则会 `Using filesort`。\n\n**注意**：如果 `order by` 使用到了多个索引，则**这几个索引必须事先创建成一个复合索引**，并且书写时的顺序和创建复合索引时的顺序必须一致，否则还是会进行额外的 `Using filesort`。因为复合索引排序时的顺序是固定好“先左后右”的，如果 `order by` 时没有遵循这个顺序，就无法按照复合索引树进行快速遍历（这点和 `where `很不一样，`where `里出现顺序无关，而` order by` 有关，因为 `where `里的条件不需要有顺序，而 `order by` 书写的顺序是有影响的，先排前面写的，再排后面写的）。\n\n---\n\n`Using temporary` 常见于 `group by`，场景举例（col1 和 col2 共同组成复合索引，col1 在前，col2 在后）：\n\n```sql\nmysql> explain select col1 from t1 where col1 in ('ac', 'ab', 'aa') group by col2;\n\n-- Extra: Using where; Using index; Using temporary; Using filesort\n```\n\n这种情况下因为 `group by` 里直接跳过了 col1 直接对 col2 进行分组，就会导致前面用索引查出来的 col1 数据不能直接按照索引顺序获取到分组结果（因为跳过了 col1 直接对 col2 分组），必须把这些数据先存储到一个临时表里，然后按照 col2 进行排序分组（因为获取到的 col1 数据是先按照 col1 排序，然后再按照 col2 排序的，所以获取到的数据必须得先存储到临时表里，然后再额外进行一次排序）\n\n优化方法就是，`group by` 改成 `group by col1, col2`，此时 Extra 里的内容就是：`Extra: Using where; Using index for group-by`\n\n---\n\n```bash\n# 排序没有使用索引（使用非索引列进行排序）\nmysql> explain select name from pms_category where name='Tangs' order by cat_level \\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: pms_category\n   partitions: NULL\n         type: ref\npossible_keys: idx_name_parentCid_catLevel\n          key: idx_name_parentCid_catLevel\n      key_len: 201\n          ref: const\n         rows: 1\n     filtered: 100.00\n        Extra: Using where; Using index; Using filesort\n1 row in set, 1 warning (0.00 sec)\n\n#~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~\n# 排序使用到了索引（使用索引列进行排序）\n\nmysql> explain select name from pms_category where name='Tangs' order by parent_cid,cat_level\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: pms_category\n   partitions: NULL\n         type: ref\npossible_keys: idx_name_parentCid_catLevel\n          key: idx_name_parentCid_catLevel\n      key_len: 201\n          ref: const\n         rows: 1\n     filtered: 100.00\n        Extra: Using where; Using index\n1 row in set, 1 warning (0.00 sec)\n```\n\n**覆盖索引**：就是 `select` 的数据列只用从索引中就能够取得，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。\n\n- `Using index`：使用覆盖索引的时候就会出现\n- `Using where`：where 语句中使用到了索引，如果不显示这个，说明没有在 where 中使用索引\n- `Using index condition`：查找使用了索引，但是需要回表查询数据\n- `Using index ; using where`：查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据\n\n如果出现 `Using index` 的同时没有同时出现 `Using where`，表明索引只用来读取数据而没有执行查找动作。例如：\n\n```bash\n# 注意：如果要使用覆盖索引，一定不能写SELECT *，要写出具体的字段。\nmysql> explain select cat_id from pms_category \\G;\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: pms_category\n   partitions: NULL\n         type: index\npossible_keys: NULL       \n          key: PRIMARY\n      key_len: 8\n          ref: NULL\n         rows: 1425\n     filtered: 100.00\n        Extra: Using index   # select的数据列只用从索引中就能够取得，不必从数据表中读取   \n1 row in set, 1 warning (0.00 sec)\n```\n\n其他：\n\n- `Using join buffer`：使用了连接缓存。\n- `impossible where`：`WHERE`子句的值总是false，不能用来获取任何元组。\n\n```bash\nmysql> explain select name from pms_category where name = 'zs' and name = 'ls'\\G\n*************************** 1. row ***************************\n           id: 1\n  select_type: SIMPLE\n        table: NULL\n   partitions: NULL\n         type: NULL\npossible_keys: NULL\n          key: NULL\n      key_len: NULL\n          ref: NULL\n         rows: NULL\n     filtered: NULL\n        Extra: Impossible WHERE   # 不可能字段同时查到两个名字\n1 row in set, 1 warning (0.00 sec)\n```\n\n\n\n## 索引失效情况\n\n- 不满足**最佳左前缀原则**\n- 在索引列上做**任何操作**（计算、函数、（自动或手动）类型转换）都会导致索引失效而转向全表扫描。\n- 字符串不加单引号索引失效（变相等于第二条：对索引列做强制类型转换操作）\n- **范围查询条件右边的索引**会全部失效\n- 在使用 `!=` 或者 `<>` 的时候**有时可能**无法使用索引会导致全表扫描\n- `is null`、`is not null` **有时可能**会无法使用索引（视情况而定，并不绝对）\n- 以 `%` 开头的 `like` 模糊查询（`like '%abc'` ），会变成全表扫描（但使用覆盖索引就不会全表扫描了）\n- 用 `or` 分割开的条件， 如果 `or` 前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到\n- 如果 MySQL 评估使用索引比全表更慢，则不使用索引\n\n下面详细分析这些索引失效的情况，并给出解决方案。\n\n### 索引最左前缀原则\n\n最左前缀原则：在使用复合索引的情况下，查询从索引的最左前列开始并且不跳过索引中的字段。如果不包含，就会出现索引失效的情况。\n\n> 最左前缀原则只针对 where 条件语句，前面 select 里要查询的字段和这个原则没关系\n\n![image-20211028202151731](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/image-20211028202151731.png)\n\n以上图为例，分析下面三个查找语句的执行情况：\n\n```sql\nKEY idx_name_age_position (name, age, position) USING BTREE\n\nEXPLAIN SELECT * FROM empolyees WHERE name = 'BILL' AND age = 31;\nEXPLAIN SELECT * FROM empolyees WHERE age = 30 AND position = 'dev';\nEXPLAIN SELECT * FROM empolyees WHERE position = 'manager';\n```\n\n根据其创建索引时的顺序可知，这三个索引的优先级为：`name > age > position`\n\n- 第一句使用了前两个索引，因为复合索引是按照优先级排序的，从上图可知，前两个索引是排好序了，所以就算最后一个字段没有用于查询，也可以只使用前两个索引进行快速定位，将范围缩小到某一个局部节点，即找到了目标区间内的数据。\n- 第二句则跳过第一个索引，直接试图根据第二个索引去查找，会发现这时根本无法直接定位到一个小区间，因为第二个索引的优先级别比较低，哪个局部区间内都有该索引值，无法直接根据该索引快速定位到目标局部区域。例如在上图中不看第一个索引，只看第二个索引值，会发现第二个索引值只在每一个节点内是有序的，两个节点间是无序的，整棵树来看是无序的，没有符合最左前缀原则，因此这种情况下索引失效。\n- 第三句跳过了前两个所有，直接试图根据第三个索引去查找，同样没有符合最左前缀原则，因此这种情况下索引失效。\n\n> 是否符合最左前缀原则和 WHRER 语句里几个字段的出现顺序无关，书写的顺序无所谓，只要包含左侧的索引即可。\n\n\n\n### 索引列上不计算\n\n在索引列上进行任何操作（包含类型转换），会使索引失效。\n\n这是因为，对索引列进行操作时，操作后的结果就无法和原先索引组成的 B+ 树上的值进行关联对比，即操作后的值就无法在原先的树上找到对应值了，因此索引失效。例如：\n\n![explain](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803171857325.png)\n\n运算操作示例：\n\n``` sql\nEXPLAIN SELECT * FROM t1 WHERE age + 1 = 1;\n```\n\n\n\n### 字符串不加单引号\n\n> 该情况本质上也属于在索引列上进行**类型转换**操作\n\n该情况常出现在忘记给字符串值添加单引号，导致索引值进行强制转换，从而失效。该情况发生了字符串类型的强制类型转换，将字符串类型的索引转换成了整型类型，从而导致索引失效。例如：\n\n- 覆盖索引情况： `select name from t1 where name = 1` 会先把 name 索引的所有值全部转成数字，再去和 1 比较是否相等，同时因为是覆盖索引，所以只需要遍历所有的 name 索引，不需要全表扫描\n- 全表扫描情况：`select * from t1 where name = 1` 会先把 name 索引的所有值全部转成数字，再去和 1 比较是否相等，同时因为不是覆盖索引，所以需要全表扫描，扫描每一个数据时将其 name 字段值转换成数字，然后再与 1 比较\n\n---\n\nMySQL 中字符串与整型类型转换时：\n\n- 如果字符是纯数字，转为对应数字（例如 `'100'` 转成数字 100）\n- 如果字符带有字符，转为 0（例如 `'a'` 转成数字 0）\n\n整型类型与字符串类型转换时：直接将该数字变成一个字符串（例如 100 转为 `'100'`）\n\n---\n\n类型转换示例：\n\n```sql\n/* 使用正确，使用到了覆盖索引，type = index */\nEXPLAIN SELECT `id`, `name` FROM `staffs` WHERE `name` = 'Ringo';\n\n/* 使用错误，先将 name 转成 2000 再判断，使用到了覆盖索引，type = index */\nEXPLAIN SELECT `id`, `name` FROM `staffs` WHERE `name` = 2000;\n\n/* 使用错误，索引失效，全表扫描，type = ALL */\nEXPLAIN SELECT * FROM `staffs` WHERE `name` = 2000;\n```\n\n![1556172967493](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556172967493.png)\n\n### 范围之后全失效\n\n**范围查询条件右边的索引**会全部失效。例如：\n\n![explain](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803173357787.png)\n\n分析该例子，存储引擎将使用前两个索引 name 和 age 进行快速查找，迅速定位到 `name = 'zs' AND age > 18` 范围内的数据。但是此时因为 age 使用了范围条件，导致 pos 索引无法在定位到的这些数据内快速定位到 `pos = 'manager'` 的数据，只能在这个范围数据内逐个遍历去定位，就无法利用 B+ 树的特性快速定位到目标数据了（本质是因为复合索引的特性，即使 age 不同的数据也可能会满足 `pos = 'manager'` ，所以要遍历所有 `age > 18` 的数据，看哪个里面的 `pos = 'manager'`，这也有点像最左匹配原则）。\n\n> 就好像先定位到的范围内有 1000 条数据，这些数据都满足 `name = 'zs' AND age > 18`，但是这些数据都可能会满足  `pos = 'manager'` ，所以要一一测试。而反过来则不会失效，如果前面的都是等于条件，最后一个是大于条件，那么还是不影响利用复合索引快速定位。\n\n### 覆盖索引尽量用\n\n> 覆盖索引：只访问索引的查询，索引列和查询列一致\n\n使用覆盖索引时不需要进行回表查询，能够提高性能。减少使用`SELECT *`，这样肯定会进行回表。例如：\n\n![使用覆盖索引](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803213031893.png)\n\n如果查询的有些列没有加索引，则会进行额外的回表操作去查询这些没有索引的列在主键树上的值，因此会降低性能。例如，下图中 `password` 字段没有添加索引，因此 Extra 里显示 `Using index codition`，表示进行了额外的回表：\n\n![1556173986068](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556173986068.png)\n\n### 不等有时会失效\n\n> 该情况可归类于：如果 MySQL 评估使用索引比全表更慢，则不使用索引。\n\n在使用 `!=` 或者 `<>` 的时候**有时可能**无法使用索引会导致全表扫描。\n\n> 索引**完全失效的前提**：查询结果为 `select *` 而非覆盖索引时完全失效， `type = ALL`。若查询结果为覆盖索引时索引仍有效， `type = index`\n\n**注意，是有时可能，而不是绝对不会**。会出现这种情况的原因是：MySQL 的优化器会在执行语句前先**分析表中要查询索引值的占比情况**，判断当前要查询的索引值占所有索引值的比例。\n\n- 如果该比例比较低，则进行 `!=` 或 `<>` 判断时，若去索引树上查找，会发现绝大多数的索引值都不等于目标值，这显然会浪费很多的时间，这时还不如直接去全表扫描来得快。这时 `type = index` 或者 `type = ALL`（区别在于是否为覆盖索引，如果是覆盖索引就是 `index`，否则为 `ALL`）\n- 如果该比例很高，说明很多索引值都等于目标值，那么进行 `!=` 或 `<>` 判断时，会发现**只有比较少的数据是需要去查找的**（因为大多都是目标值，这些目标值是不需要查找的，相当于直接过滤掉了大量数据），那么这时就不需要去全表扫描了，直接在索引树上进行少量的查找即可快速定位到。这时 `type = range`\n\n补充：比例较低时，如果是**覆盖索引**的情况，则会进行 `index` 而不是 `ALL`，因为这时要查的只是索引数据，没必要去全表扫描，而是直接遍历索引树上的双向链表即可。\n\n> 注意：上面讨论的情况为` !=` 或 `<>`，如果是 `=`、 `>` 或 `<` 的情况**同样会进行这种评估**，评估使用索引能否带来的高效。\n\n示例：表中 age 字段添加了索引，大多数的值为18，少数的值为 2。\n\n``` sql\n/* 值为2的数据占比比较低，优化器衡量后决定不走索引树去查找了，直接遍历。\n又因为是 select * 而不是 select age（覆盖索引0），所以是 ALL 而不是 index */\nexplain select * from test where age != 2;\n\n/* 值为2的数据占比比较低，优化器衡量后决定不走索引树去查找了，直接遍历。\n又因为是 select age（覆盖索引0），所以是 index */\nexplain select age from test where age != 2;\n\n/* 值为18的数据占比比较高，优化器衡量后决定走索引树去查找，type = range */\nexplain select * from test where age != 18;\n\n/* 值为18的数据占比比较高，优化器衡量后决定走索引树去查找，type = range */\nexplain select age from test where age != 18;\n```\n\n总结：这种情况适用于必须是不等这种排除当前数据的操作（不能是等于或大于小于类型），因为这会去花很多时间遍历，所以优化器就会权衡值不值得去索引树上遍历一次，还是直接去全表扫描更快一些，如果衡量结果是去全表扫描更快一些（目标值占比比较小），则就会进行全表扫描。\n\n另外，这种分析同样适用于 **“is NULL, is NOT NULL” 有时索引失效** 的情况，原理是相同的。MySQL 会先分析 NULL 的占比，并根据该值大小进行决策是否直接进行全表扫描。\n\n**总结**：优化器在发现要查找的（满足条件）的数据占比较低时（说明查找的代价较低），就会使用索引，此时查找的代价比较小，速度较快。\n\n> 如果一个查询语句中用到了多个单列索引，那么优化器会评估选择**辨识度最高**的那个索引进行查找\n\n### like % 少加左\n\n `%` 加在左边的 `like` 模糊查询（`like '%abc'` ），会变成全表扫描（但使用覆盖索引就不会全表扫描了，会变成 `type = index`）：\n\n``` sql\n/* 索引失效，全表扫描，type = ALL */\nEXPLAIN SELECT * FROM `staffs` WHERE `name` LIKE '%ing%';\n\n/* 索引失效，全表扫描，type = ALL */\nEXPLAIN SELECT * FROM `staffs` WHERE `name` LIKE '%ing';\n```\n\n但如果仅仅是**尾部**模糊匹配（`%` 加在右边），索引不会失效，这种情况其实类似于范围查找（`like 'xx%'` 效果类似于` where name > 'xxx'`，但是不同的是 `like 'xx%'` 后面的索引仍然生效，而 后者会失效），`type = range`：\n\n``` sql\n/* 使用索引范围查询，type = range */\nEXPLAIN SELECT * FROM `staffs` WHERE `name` LIKE 'Rin%';\n```\n\n如果一定要在左边加 `%`，而且还要保证索引不失效，那么使用**覆盖索引**来编写SQL，不需要全表扫描，性能略好：\n\n``` sql\n/* 索引不，type = index */\nEXPLAIN SELECT `name` FROM `staffs` WHERE `name` LIKE '%in%';\n```\n\n案例：\n\n```sql\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `id` FROM `staffs` WHERE `name` LIKE '%in%';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `name` FROM `staffs` WHERE `name` LIKE '%in%';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `age` FROM `staffs` WHERE `name` LIKE '%in%';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `pos` FROM `staffs` WHERE `name` LIKE '%in%';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `id`, `name` FROM `staffs` WHERE `name` LIKE '%in%';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `id`, `age` FROM `staffs` WHERE `name` LIKE '%in%';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `id`,`name`, `age`, `pos` FROM `staffs` WHERE `name` LIKE '%in';\n\n/* 使用到了覆盖索引 */\nEXPLAIN SELECT `id`, `name` FROM `staffs` WHERE `pos` LIKE '%na';\n\n/* 索引失效 全表扫描 */\nEXPLAIN SELECT `name`, `age`, `pos`, `add_time` FROM `staffs` WHERE `name` LIKE '%in';\n```\n\n![模糊查询百分号一定加前边](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803220743206.png)\n\n\n\n### OR 中一个没索引整体都不用索引\n\n用 `or` 分割开的条件， 如果 `or` 前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会被用到。（推荐用 `UNION `代替 `OR`）\n\n示例：name 字段是索引列 ， 而 createtime 不是索引列，中间是 OR 进行连接是不走索引的 ： \n\n```sql\nexplain select * from tb_seller where name='黑马程序员' or createtime = '2088-01-01 12:00:00'\\G;\t\n```\n\n![1556174994440](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556174994440.png) \n\n### MySQL 自己评估是否要使用索引\n\nMySQL 的优化器会在执行语句前先分析语句和表中的情况，并据此判断是否要使用索引。如果MySQL评估使用索引比全表扫描更慢，则不使用索引（前提是必须得回表）。例如：\n\n- 使用 `!=` 或 `<>` 时会计算索引临界值占所有值的比例\n- 使用 `\"is NULL, is NOT NULL\"` 时会计算 NULL 的占比\n- 使用 `=`、 `>` 或 `<` 时，会计算满足条件的临界值占所有值的比例\n\n**注意**：索引**完全失效**的前提是查询结果为 `select *`而不是覆盖索引，如果查询的是覆盖索引，则索引仍然生效，`type = index`。因为覆盖索引不需要再回表查询，会出现失效是因为优化器认为直接去全表扫描的效率高于先去索引树遍历再去回表，所以如果查询结果是覆盖索引，根本不会回表，所以就不会失效，顶多是 `index`。\n\n---\n\n示例：优化器先计算目标索引值在表中的占比，如果发现占比较大，并且是 `select *` ，说明要将做很多次回表，还不如直接去全表扫描：\n\n![1556175445210](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556175445210.png)\n\n上述例子没有走索引，直接全表扫描的原因：如果走索引，先根据第一个索引定位到了符合条件的若干索引数据，然后再一一遍历到这些索引位置，获取其主键值，然后再去主键索引树上一一去查询，若索引数据较少还好，但如果符合条件的索引数据量极大（体现在上文中描述的占比较高），则 InnoDB 发现这种情况下，与其进行大量的回表，还不如直接去全表扫描来的高效。因为这种范围查找，在先使用第一个索引定位到后，还是要一一沿着双向链表进行遍历，找到所有区间内的索引，然后再对这些索引一个一个的去主键索引树上遍历，其实这样效率并不高，还不如直接去主键索引树上全表扫描来的快。\n\n针对 `>` 或 `<` 的情况，是否直接进行全表扫描和设置的**临界值大小**有关系：如果临界值设置的太小，需要遍历很多，InnoDB就会判定直接全表扫描效率更高。如果临界值设置的比较大，遍历+回表的次数就会比较少，InnoDB就会判定索引 + 回表更高效。\n\n---\n\n当然上述讨论的情况都是查询结果必须要进行回表（例如 `select *`）。如果不需要回表（例如覆盖索引），则就不存在上面讨论的这些弊端，肯定还是会走索引，只不过可能是 index 级别。\n\n覆盖索引情况分析：如果要查询的字段正好是索引，这样就不需要回表了，直接在目标索引树上进行查找，用该字段的值作为索引去查找，查找到的结果本身就是要查的目标字段，所以不用回表了，可以直接找到符合条件的目标字段。并且查出的结果本身就是排好序的，因为是在排好序的索引双向链表上直接返回的，本身就排好了序，不需要再 ORDER BY。\n\n**总结**：在必须要回表的情况下，优化器在发现要查找的（满足条件）的数据占比较低时（说明查找的代价较低），就会使用索引，此时查找的代价比较小，速度较快。\n\n\n\n### 索引失效相关题目\n\n假设 a，b，c 组成了一个复合索引：`index(a, b, c)`\n\n| Where 语句                                              | 索引是否被使用                             |\n| ------------------------------------------------------- | ------------------------------------------ |\n| where a = 3                                             | Y，使用到a                                 |\n| where a = 3 and b = 5                                   | Y，使用到a，b                              |\n| where a = 3 and b = 5                                   | Y，使用到a，b，c                           |\n| where b = 3 或者 where b = 3 and c = 4 或者 where c = 4 | N，没有用到a字段                           |\n| where a = 3 and c = 5                                   | 使用到a，但是没有用到c，因为b断了          |\n| where a = 3 and b > 4 and c = 5                         | 使用到a，b，但是没有用到c，因为c在范围之后 |\n| where a = 3 and b like 'kk%' and c = 4                  | Y，a，b，c都用到                           |\n| where a = 3 and b like '%kk' and c = 4                  | 只用到a                                    |\n| where a = 3 and b like '%kk%' and c = 4                 | 只用到a                                    |\n| where a = 3 and b like 'k%kk%' and c = 4                | Y，a，b，c都用到                           |\n\n综合案例：\n\n> 数据准备\n\n```sql\n/* 创建表 */\nCREATE TABLE `test03`(\n`id` INT PRIMARY KEY NOT NULL AUTO_INCREMENT,\n`c1` CHAR(10),\n`c2` CHAR(10),\n`c3` CHAR(10),\n`c4` CHAR(10),\n`c5` CHAR(10)\n);\n\n/* 插入数据 */\nINSERT INTO `test03`(`c1`,`c2`,`c3`,`c4`,`c5`) VALUES('a1','a2','a3','a4','a5');\nINSERT INTO `test03`(`c1`,`c2`,`c3`,`c4`,`c5`) VALUES('b1','b22','b3','b4','b5');\nINSERT INTO `test03`(`c1`,`c2`,`c3`,`c4`,`c5`) VALUES('c1','c2','c3','c4','c5');\nINSERT INTO `test03`(`c1`,`c2`,`c3`,`c4`,`c5`) VALUES('d1','d2','d3','d4','d5');\nINSERT INTO `test03`(`c1`,`c2`,`c3`,`c4`,`c5`) VALUES('e1','e2','e3','e4','e5');\n\n/* 创建复合索引 */\nCREATE INDEX idx_test03_c1234 ON `test03`(`c1`,`c2`,`c3`,`c4`);\n```\n\n> 题目\n\n```sql\n/* 最好索引怎么创建的，就怎么用，按照顺序使用，避免让MySQL再自己去翻译一次 */\n\n/* 1.全值匹配 用到索引c1 c2 c3 c4全字段 */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' AND `c3` = 'a3' AND `c4` = 'a4';\n\n/* 2.用到索引c1 c2 c3 c4全字段 MySQL的查询优化器会优化SQL语句的顺序*/\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' AND `c4` = 'a4' AND `c3` = 'a3';\n\n/* 3.用到索引c1 c2 c3 c4全字段 MySQL的查询优化器会优化SQL语句的顺序*/\nEXPLAIN SELECT * FROM `test03` WHERE `c4` = 'a4' AND `c3` = 'a3' AND `c2` = 'a2' AND `c1` = 'a1';\n\n/* 4.用到索引c1 c2 c3字段，c4字段失效，范围之后全失效 */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' AND `c3` > 'a3' AND `c4` = 'a4';\n\n/* 5.用到索引c1 c2 c3 c4全字段 MySQL的查询优化器会优化SQL语句的顺序*/\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' AND `c4` > 'a4' AND `c3` = 'a3';\n\n/* \n   6.用到了索引c1 c2 c3三个字段, c1和c2两个字段用于查找,  c3字段用于排序了但是没有统计到key_len中，c4字段失效\n*/\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' AND `c4` = 'a4' ORDER BY `c3`;\n\n/* 7.用到了索引c1 c2 c3三个字段，c1和c2两个字段用于查找, c3字段用于排序了但是没有统计到key_len中*/\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' ORDER BY `c3`;\n\n/* \n   8.用到了索引c1 c2两个字段，c4失效，c1和c2两个字段用于查找，c4字段排序产生了Using filesort说明排序没有用到c4字段 ，因为断了c3，想隔着c3去排序c4是做不到的，需要额外的文件排序\n*/\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' ORDER BY `c4`;\n\n/* 9.用到了索引c1 c2 c3三个字段，c1用于查找，c2和c3用于排序 */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c5` = 'a5' ORDER BY `c2`, `c3`;\n\n/* 10.用到了c1一个字段，c1用于查找，c3和c2两个字段索引失效，产生了Using filesort */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c5` = 'a5' ORDER BY `c3`, `c2`;\n\n/* 11.用到了c1 c2 c3三个字段，c1 c2用于查找，c2 c3用于排序 */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND  `c2` = 'a2' ORDER BY c2, c3;\n\n/* 12.用到了c1 c2 c3三个字段，c1 c2用于查找，c2 c3用于排序 */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND  `c2` = 'a2' AND `c5` = 'a5' ORDER BY c2, c3;\n\n/* \n   13.用到了c1 c2 c3三个字段，c1 c2用于查找，c2 c3用于排序 没有产生Using filesort \n      因为之前c2这个字段已经确定了是'a2'了，这是一个常量，再去ORDER BY c3,c2 这时候c2已经不用排序了！\n      所以没有产生Using filesort 和(10)进行对比学习！\n*/\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c2` = 'a2' AND `c5` = 'a5' ORDER BY c3, c2;\n\n\n/* GROUP BY 表面上是叫做分组，但是分组之前必定排序。 */\n\n/* 14.用到c1 c2 c3三个字段，c1用于查找，c2 c3用于排序，c4失效 */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c4` = 'a4' GROUP BY `c2`,`c3`;\n\n/* 15.用到c1这一个字段，c4失效，c2和c3排序失效产生了Using filesort */\nEXPLAIN SELECT * FROM `test03` WHERE `c1` = 'a1' AND `c4` = 'a4' GROUP BY `c3`,`c2`;\n```\n\n总结：`GROUP BY`基本上都需要进行排序，索引优化几乎和`ORDER BY`一致，但是`GROUP BY`会有临时表的产生。\n\n\n\n##  SQL 优化分析步骤\n\n在应用的开发过程中，由于初期数据量小，开发人员写 SQL 语句时更重视功能上的实现，但是当应用系统正式上线后，随着生产数据量的急剧增长，很多 SQL 语句开始逐渐显露出性能问题，对生产的影响也越来越大，此时这些有问题的 SQL 语句就成为整个系统性能的瓶颈，因此我们必须要对它们进行优化。\n\n当面对一个有 SQL 性能问题的数据库时，我们的分析顺序：\n\n- 观察至少 1 天，看看生产环境下的慢 SQL 情况\n- 定位低效率的 SQL：\n  - 开启**慢查询日志**，设置阈值，比如超过 5 秒钟的就是慢 SQL，并将它抓取出来\n  - 或 `show processlist` 实时查看 SQL 执行情况\n- `EXPLAIN` 分析 SQL 执行计划\n- `show profiles` 查询 SQL 在 MySQL 数据库中的执行细节和生命周期情况\n- 运维经理或者DBA，进行 MySQL 数据库服务器的参数调优\n\n\n\n### 查看 SQL 执行频率\n\nMySQL 客户端连接成功后，通过 `show [session|global] status` 命令可以提供服务器状态信息。`show [session|global] status` 可以根据需要加上参数“session”或者“global”来显示 session 级（当前连接）的计结果和 global 级（自数据库上次启动至今）的统计结果。如果不写，默认使用参数是“session”。\n\n下面的命令显示了当前 session 中所有统计参数的值：\n\n```\nshow status like 'Com_______';\n```\n\n![1552487172501](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552487172501.png)\n\n```\nshow status like 'Innodb_rows_%';\n```\n\n![1552487245859](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552487245859.png)\n\n`Com_xxx` 表示每个 xxx 语句执行的次数，我们通常比较关心的是以下几个统计参数。\n\n| 参数                 | 含义                                         |\n| :------------------- | -------------------------------------------- |\n| Com_select           | 执行 select 操作的次数，一次查询只累加 1。   |\n| Com_insert           | 执行 INSERT 操作的次数，批量插入只累加一次。 |\n| Com_update           | 执行 UPDATE 操作的次数。                     |\n| Com_delete           | 执行 DELETE 操作的次数。                     |\n| Innodb_rows_read     | select 查询返回的行数。                      |\n| Innodb_rows_inserted | 执行 INSERT 操作插入的行数。                 |\n| Innodb_rows_updated  | 执行 UPDATE 操作更新的行数。                 |\n| Innodb_rows_deleted  | 执行 DELETE 操作删除的行数。                 |\n| Connections          | 试图连接 MySQL 服务器的次数。                |\n| Uptime               | 服务器工作时间。                             |\n| Slow_queries         | 慢查询的次数。                               |\n\n- `Com_***`      :  这些参数对于所有存储引擎的表操作都会进行累计。\n- `Innodb_***` :  这几个参数只是针对 InnoDB 存储引擎的，累加的算法也略有不同。\n\n### 定位低效率的 SQL\n\n可以通过以下两种方式定位执行效率较低的 SQL 语句。\n\n- **慢查询日志**：通过慢查询日志定位那些执行效率较低的 SQL 语句，用`--log-slow-queries[=file_name]`选项启动时，mysqld 写一个包含所有执行时间超过 `long_query_time` 秒的 SQL 语句的日志文件。\n- `show processlist`：慢查询日志在查询结束以后才纪录，所以在应用反映执行效率出现问题的时候查询慢查询日志并不能定位问题，可以使用`show processlist`命令查看当前MySQL在进行的线程，包括线程的状态、是否锁表等，可以实时地查看 SQL 的执行情况，同时对一些锁表操作进行优化。\n\n#### 慢查询日志\n\n- MySQL的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中响应时间超过阈值的语句，具体指运行时间超过 `long_query_time` 值的 SQL，则会被记录到慢查询日志中。\n- `long_query_time` 的默认值为 10，意思是运行 10 秒以上的语句。\n- 由慢查询日志来查看哪些 SQL 超出了我们的最大忍耐时间值，比如一条SQL执行超过5秒钟，我们就算慢 SQL，希望能收集超过 5 秒钟的 SQL，结合之前 `explain` 进行全面分析。\n\n> 特别说明\n\n**默认情况下，MySQL 数据库没有开启慢查询日志**，需要我们手动来设置这个参数。\n\n**当然，如果不是调优需要的话，一般不建议启动该参数**，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件。\n\n> 查看慢查询日志是否开以及如何开启\n\n- 查看慢查询日志是否开启：`SHOW VARIABLES LIKE '%slow_query_log%';`。\n\n- 开启慢查询日志：`SET GLOBAL slow_query_log = 1;`。**使用该方法开启 MySQL 的慢查询日志只对当前数据库生效，如果 MySQL 重启后会失效。**\n\n```shell\n# 1、查看慢查询日志是否开启\nmysql> SHOW VARIABLES LIKE '%slow_query_log%';\n+---------------------+--------------------------------------+\n| Variable_name       | Value                                |\n+---------------------+--------------------------------------+\n| slow_query_log      | OFF                                  |\n| slow_query_log_file | /var/lib/mysql/1dcb5644392c-slow.log |\n+---------------------+--------------------------------------+\n2 rows in set (0.01 sec)\n\n# 2、开启慢查询日志\nmysql> SET GLOBAL slow_query_log = 1;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n如果要使慢查询日志永久开启，需要修改`my.cnf`文件，在`[mysqld]`下增加修改参数。\n\n```shell\n# my.cnf\n[mysqld]\n# 1.这个是开启慢查询。注意ON需要大写\nslow_query_log=ON  \n\n# 2.这个是存储慢查询的日志文件。这个文件不存在的话，需要自己创建\nslow_query_log_file=/var/lib/mysql/slow.log\n```\n\n> 开启了慢查询日志后，什么样的SQL才会被记录到慢查询日志里面呢？\n\n这个是由参数`long_query_time`控制的，默认情况下`long_query_time`的值为10秒。\n\nMySQL中查看`long_query_time`的时间：`SHOW VARIABLES LIKE 'long_query_time%';`。\n\n```shell\n# 查看long_query_time 默认是10秒\n# 只有SQL的执行时间>10才会被记录\nmysql> SHOW VARIABLES LIKE 'long_query_time%';\n+-----------------+-----------+\n| Variable_name   | Value     |\n+-----------------+-----------+\n| long_query_time | 10.000000 |\n+-----------------+-----------+\n1 row in set (0.00 sec)\n```\n\n修改`long_query_time`的时间，需要在`my.cnf`修改配置文件\n\n```shell\n[mysqld]\n# 这个是设置慢查询的时间，我设置的为1秒\nlong_query_time=1\n```\n\n查询慢查询日志的总记录条数：`SHOW GLOBAL STATUS LIKE '%Slow_queries%';`。\n\n```shell\nmysql> SHOW GLOBAL STATUS LIKE '%Slow_queries%';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| Slow_queries  | 3     |\n+---------------+-------+\n1 row in set (0.00 sec)\n```\n\n\n\n#### show processlist\n\n慢查询日志在查询结束以后才纪录，所以在应用反映执行效率出现问题的时候查询慢查询日志并不能定位问题，可以使用`show processlist`命令查看当前MySQL在进行的线程，包括线程的状态、是否锁表等，可以实时地查看 SQL 的执行情况，同时对一些锁表操作进行优化。\n\n![1556098544349](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556098544349.png)\n\n```\n1） id列，用户登录mysql时，系统分配的\"connection_id\"，可以使用函数connection_id()查看\n2） user列，显示当前用户。如果不是root，这个命令就只显示用户权限范围的sql语句\n3） host列，显示这个语句是从哪个ip的哪个端口上发的，可以用来跟踪出现问题语句的用户\n4） db列，显示这个进程目前连接的是哪个数据库\n5） command列，显示当前连接的执行的命令，一般取值为休眠（sleep），查询（query），连接（connect）等\n6） time列，显示这个状态持续的时间，单位是秒\n7） state列，显示使用当前连接的sql语句的状态，很重要的列。state描述的是语句执行中的某一个状态。一个sql语句，以查询为例，可能需要经过copying to tmp table、sorting result、sending data等状态才可以完成\n8） info列，显示这个sql语句，是判断问题语句的一个重要依据\n```\n\n### EXPLAIN 分析执行计划\n\n`EXPLAIN`：SQL 的执行计划，使用 `EXPLAIN` 关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理SQL语句的。\n\n通过以上步骤查询到效率低的 SQL 语句后，可以通过 `EXPLAIN` 或者 `DESC` 命令获取 MySQL如何执行 SELECT 语句的信息，包括在 SELECT 语句执行过程中表如何连接和连接的顺序。\n\n查询SQL语句的执行计划 ： \n\n```sql\nexplain select * from tb_item where id = 1;\n```\n\n![1552487489859](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552487489859.png)\n\n```sql\nexplain select * from tb_item where title = '阿尔卡特 (OT-979) 冰川白 联通3G手机3';\n```\n\n![1552487526919](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552487526919.png)\n\n各个字段的含义：\n\n- `id`：表的读取顺序。\n- `select_type`：数据读取操作的操作类型。\n- `possible_keys`：哪些索引可以使用。\n- `key`：哪些索引被实际使用。\n- `ref`：表之间的引用。\n- `rows`：每张表有多少行被优化器查询。\n- `extra`：额外信息\n\n关于 `EXPLAIN` 指令的更多详细分析见 [EXPLAIN 指令](#explain-指令)。\n\n### show profiles 分析 SQL\n\nMySQL 从 5.0.37 版本开始增加了对 `show profiles` 和 `show profile` 语句的支持。`show profiles` 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。\n\n`Show Profile`：MySQL 提供可以用来分析当前会话中语句执行的资源消耗情况。可以用于SQL的调优的测量。**默认情况下，参数处于关闭状态，并保存最近 15 次的运行结果**。\n\n1、通过 `have_profiling` 参数，能够看到当前 MySQL 是否支持 profile：\n\n![1552488401999](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552488401999.png)\n\n2、默认`profiling`是关闭的，可以通过 Set 语句在 Session 级别开启 profiling：\n\n![1552488372405](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552488372405.png)\n\n```sql\nset profiling=1;  -- 开启profiling 开关；\n```\n\n3、执行一系列的操作，如下图所示：\n\n```sql\nshow databases;\n\nuse db01;\n\nshow tables;\n\nselect * from tb_item where id < 5;\n\nselect count(*) from tb_item;\n```\n\n4、执行完上述命令之后，再执行`show profiles` 指令， 来查看SQL语句执行的耗时：\n\n![1552489017940](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552489017940.png)\n\n> `Duration`：持续时间\n\n5、诊断SQL：通过`show  profile for  query  query_id` 语句可以查看到该SQL执行过程中每个线程的状态和消耗的时间：\n\n![1552489053763](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552489053763.png)\n\n> Sending data 状态表示MySQL线程开始访问数据行并把结果返回给客户端，而不仅仅是返回个客户端。由于在Sending data状态下，MySQL线程往往需要做大量的磁盘读取操作，所以经常是整各查询中耗时最长的状态。\n\n\n在获取到最消耗时间的线程状态后，MySQL支持进一步选择all、cpu、block io 、context switch、page faults等明细类型类查看MySQL在使用什么资源上耗费了过高的时间。例如，选择查看CPU的耗费时间  ：\n\n![1552489671119](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1552489671119.png)\n\n| 字段       | 含义                                                  |\n| ---------- | ----------------------------------------------------- |\n| Status     | sql 语句执行的状态（代表一个 SQL 的**完整生命周期**） |\n| Duration   | sql 执行过程中每一个步骤的耗时                        |\n| CPU_user   | 当前用户占有的cpu                                     |\n| CPU_system | 系统占有的cpu                                         |\n\n`Show Profile`查询参数备注：\n\n- `ALL`：显示所有的开销信息。\n- `BLOCK IO`：显示块IO相关开销（通用）。\n- `CONTEXT SWITCHES`：上下文切换相关开销。\n- `CPU`：显示CPU相关开销信息（通用）。\n- `IPC`：显示发送和接收相关开销信息。\n- `MEMORY`：显示内存相关开销信息。\n- `PAGE FAULTS`：显示页面错误相关开销信息。\n- `SOURCE`：显示和Source_function。\n- `SWAPS`：显示交换次数相关开销的信息。\n\n`Show Profile`查询列表中若出现以下信息则说明**当前 SQL 存在性能问题**：\n\n- `converting HEAP to MyISAM`：查询结果太大，内存都不够用了，往磁盘上搬了。\n- `Creating tmp table`：创建临时表（拷贝数据到临时表，用完再删除），非常耗费数据库性能。\n- `Copying to tmp table on disk`：把内存中的临时表复制到磁盘，危险！！！\n- `locked`：死锁。\n\n\n\n\n\n### trace 分析优化器执行计划\n\nMySQL 5.6 提供了对 SQL 的跟踪 trace，通过 trace文件能够进一步了解为什么优化器选择A计划, 而不是选择B计划。\n\n打开 trace， 设置格式为 JSON，并设置 trace 最大能够使用的内存大小，避免解析过程中因为默认内存过小而不能够完整展示。\n\n```sql\nSET optimizer_trace=\"enabled=on\",end_markers_in_json=on;\nset optimizer_trace_max_mem_size=1000000;\n```\n\n执行SQL语句 ：\n\n```sql\nselect * from tb_item where id < 4;\n```\n\n最后， 检查`information_schema.optimizer_trace`就可以知道MySQL是如何执行SQL的 ：\n\n```sql\nselect * from information_schema.optimizer_trace\\G;\n```\n\n\n\n\n\n## SQL 优化技巧\n\n索引优化的**通用一般性**建议：\n\n- 对于单值索引，尽量选择针对当前查询过滤性更好（辨识度更高）的索引\n- 在选择复合索引的时候，当前查询中过滤性最好的字段在索引字段顺序中，**位置越靠前越好**\n- 在选择复合索引的时候，尽量选择能够包含当前查询中的 `WHERE` 子句中更多字段的索引\n- 尽量使用覆盖索引（只访问索引的查询），避免使用 `SELECT *`\n\n下面介绍针对具体语句的优化方法。\n\n### JOIN 语句优化\n\n使用 JOIN 语句进行联表查询时，要遵循**小表驱动大表**原则：数据量小的表驱动数据量大的表。例如：\n\n- 左连接（`LEFT JOIN`）时，左表的数据量应该比较小，右表的数据量应该比较大，同时索引建在右表上，这样查询效率就很非常高\n- 右连接（`RIGHT JOIN`）时，右表的数据量应该比较小，左表的数据量应该比较大，同时索引建在左表上，这样查询效率就很非常高\n\n#### 案例\n\n> 数据准备\n\n```sql\nDROP TABLE IF EXISTS `class`;\nDROP TABLE IF EXISTS `book`;\n\nCREATE TABLE IF NOT EXISTS `class`(\n`id` INT(10) UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT COMMENT '主键',\n`card` INT(10) UNSIGNED NOT NULL COMMENT '分类' \n) COMMENT '商品类别';\n\nCREATE TABLE IF NOT EXISTS `book`(\n`bookid` INT(10) UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT COMMENT '主键',\n`card` INT(10) UNSIGNED NOT NULL COMMENT '分类'\n) COMMENT '书籍';\n```\n\n> 两表连接查询的SQL执行计划\n\n1、不创建索引的情况下，SQL 的执行计划。\n\n![explain](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803143557187.png)\n\n`book`和`class`两张表都是没有使用索引，全表扫描，那么如果进行优化，索引是创建在`book`表还是创建在`class`表呢？下面分别尝试：\n\n2、左表（`book`表）创建索引 `idx_book_card`\n\n```sql\n/* 在book表创建索引 */\nCREATE INDEX idx_book_card ON book(card);\n```\n\n在 `book` 表中有 `idx_book_card` 索引的情况下，查看 SQL 执行计划\n\n![explain](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803144429349.png)\n\n观察 rows：先遍历了左表的索引24行，然后再全表遍历右表，判断了22次\n\n3、删除`book`表的索引，右表（`class`表）创建索引 `idx_class_card`\n\n```sql\n/* 在class表创建索引 */\nCREATE INDEX idx_class_card ON class(card);\n```\n\n在 `class `表中有 `idx_class_card` 索引的情况下，查看 SQL 执行计划\n\n![explain](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/20200803145030597.png)\n\n先在左表全表遍历24，然后用索引直接一次就定位到了目标位置\n\n**由此可见，左连接将索引创建在右表上更合适，右连接将索引创建在左表上更合适。**\n\n原因：左连接，一定会先扫描左表，左表的每一行都会要的，所以左表没必要加索引，因为加了也得全遍历一次该索引值，而右表只需要满足条件的行，所以要加索引，这样会很快定位到需要的值，回表后把数据拼装给左表满足ON条件的行上，然后左表剩余不满足ON的也要查出来，只不过其右表的值是NULL。\n\n---\n\n补充：`IN `和 `EXISTS`\n\n```sql\n/* IN适合B表比A表数据小的情况*/\nSELECT * FROM `A` WHERE `id` IN (SELECT `id` FROM `B`)\n\n/* EXISTS适合B表比A表数据大的情况 */\nSELECT * FROM `A` WHERE EXISTS (SELECT 1 FROM `B` WHERE `B`.id = `A`.id);\n```\n\n本质是因为 SQL 的**机读顺序**，`IN` 的情况先执行括号内的查询，所以括号内的表要小（小表驱动大表）；而 `EXISTS `的情况先执行括号外的查询，所以括号外的表要小。\n\n**EXISTS**：\n\n- 语法：`SELECT....FROM tab WHERE EXISTS(subquery);`该语法可以理解为：\n- 该语法可以理解为：将主查询的数据，放到子查询中做条件验证，根据验证结果（`true`或是`false`）来决定主查询的数据结果是否得以保留。\n\n**提示：**\n\n- `EXISTS(subquery)`子查询只返回`true`或者`false`，因此子查询中的`SELECT *`可以是`SELECT 1 OR SELECT X`，它们并没有区别。\n- `EXISTS(subquery)`子查询的实际执行过程可能经过了优化而不是我们理解上的逐条对比，如果担心效率问题，可进行实际检验以确定是否有效率问题。\n- `EXISTS(subquery)`子查询往往也可以用条件表达式，其他子查询或者`JOIN`替代，何种最优需要具体问题具体分析。\n\n\n\n### INSERT 语句优化\n\n当进行数据的 `insert` 操作的时候，可以考虑采用以下几种优化方案。\n\n**1、添加主键，并且推荐索引使用自增数据类型**\n\n如果不设置主键，则 InnoDB 会自己寻找一个数据值都不相同的列，为其创建主键索引。如果找不到都不相同的，则会维护一个隐藏列（6字节的row id）作为主键，这无疑浪费了时间与空间。因此建议自己添加索引。\n\n1. 使用整型的原因：整型数据比大小比较快，占用字节也比较少（UUID这种字符串比大小比较慢，占用字节也多）\n2. 使用自增的原因：如果使用自增索引，那么使用 `insert` 新添加的索引只需要向当前最大索引后面添加即可，不会发生页分裂，也就不需要重新调整整棵树的结构，这样插入速度就会比较快；而如果不自增的话， 随便插入很容易出现页分裂、让树重新调整平衡，速度就会降低\n\n**2、按照索引顺序插入数据，避免无序插入**\n\n无序插入时会频繁发生页分裂，造成性能降低。\n\n```\n脚本文件介绍 :\n\tsql1.log  ----> 主键有序\n\tsql2.log  ----> 主键无序\n```\n\n插入有序的 ID 数据：\n\n![1555771750567](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555771750567.png)\n\n插入无序的 ID 数据：\n\n![1555771959734](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555771959734.png)\n\n**3、关闭唯一性校验**\n\nMySQL 默认开启了唯一性校验，每次插入数据时都会进行校验，这样就会造成一定的性能降低，在插入大量数据时延迟尤其凸显。因此可以在插入大量数据时手动将其关闭，插入完成后再手动开启。\n\n在导入数据前执行 `SET UNIQUE_CHECKS=0`，关闭唯一性校验，在导入结束后执行`SET UNIQUE_CHECKS=1`，恢复唯一性校验，可以提高导入的效率。\n\n![1555772132736](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555772132736.png)\n\n**4、手动提交事务**\n\nMySQL 默认会自动开启事务，在每次插入数据前开启事务，在插入大量数据时会出现一定的延迟。因此可以在插入大量数据前先关闭事务，插入完成后再手动提交。\n\n如果应用使用自动提交的方式，建议在插入大量数据前执行 `SET AUTOCOMMIT=0`，关闭自动提交，导入结束后再执行 `SET AUTOCOMMIT=1`，打开自动提交，也可以提高导入的效率。\n\n![1555772351208](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1555772351208.png)\n\n**5、多条 insert 语句合并成一条**\n\n如果需要同时对一张表插入很多行数据时，应该尽量使用多个值表的insert语句，这种方式将大大的缩减客户端与数据库之间的**连接**、**关闭**等消耗。使得效率比分开执行的单个 `insert `语句快。\n\n原始方式为：\n\n```sql\ninsert into tb_test values(1,'Tom');\ninsert into tb_test values(2,'Cat');\ninsert into tb_test values(3,'Jerry');\n```\n\n优化后的方案为 ： \n\n```sql\ninsert into tb_test values(1,'Tom'),(2,'Cat')，(3,'Jerry');\n```\n\n**6、大批量插入数据时建议分组提交，一组一组的插入提交**\n\n\n\n### ORDER BY 语句优化\n\n`ORDER BY`子句，尽量使用索引排序 `Using index`，避免使用文件排序 `Using filesort`。**尽可能在索引列上完成排序操作，遵照索引建的最佳左前缀原则**。\n\nMySQL 支持两种方式的排序：\n\n- 索引排序 `Using index`：MySQL 扫描索引本身即可完成排序，效率较高。需要满足条件：\n  - 查询的结果是覆盖索引\n  - `ORDER BY` 中索引满足最左前缀原则，并且顺序要和建索引时保持一致\n  - 复合索引时，升序降序必须要统一，不能一个升序一个降序\n- 文件排序 `Using filesort`：使用了额外的文件排序，效率较差。\n\n---\n\n> 如果不在索引列上，MySQL 就要启动 File Sort。其实现有两种算法：双路排序算法和单路排序算法\n\n1、双路排序算法：MySQL 4.1 之前使用双路排序，字面意思就是两次扫描磁盘，最终得到数据，读取行指针和`ORDER BY`列，対他们进行排序，然后扫描已经排序好的列表，按照列表中的值重新从列表中读取对应的数据输出。**一句话，从磁盘取排序字段，在`buffer`中进行排序，再从磁盘取其他字段。**\n\n取一批数据，要对磁盘进行两次扫描，众所周知，IO是很耗时的，所以在MySQL4.1之后，出现了改进的算法，就是单路排序算法。\n\n2、单路排序算法：从磁盘读取查询需要的所有列，按照`ORDER BY`列在`buffer`対它们进行排序，然后扫描排序后的列表进行输出，它的效率更快一些，避免了第二次读取数据。并且把随机IO变成了顺序IO，但是它会使用更多的空间，因为它把每一行都保存在内存中了。\n\n由于单路排序算法是后出的，总体而言效率好过双路排序算法。但是单路排序算法有问题：如果`SortBuffer`缓冲区太小，导致从磁盘中读取所有的列不能完全保存在`SortBuffer`缓冲区中，这时候单路复用算法就会出现问题，反而性能不如双路复用算法。\n\n**单路复用算法的优化策略：**\n\n- 增大`sort_buffer_size`参数的设置。\n- 增大`max_length_for_sort_data`参数的设置。\n\nMySQL 通过比较系统变量 `max_length_for_sort_data` 的大小和查询语句取出的字段总大小， 来判定是否那种排序算法，如果 `max_length_for_sort_data` 更大，那么使用第二种优化之后的算法；否则使用第一种。\n\n可以适当提高 `sort_buffer_size`  和 `max_length_for_sort_data` 系统变量，来增大排序区的大小，提高排序的效率。\n\n![1556338367593](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556338367593-1635859234637.png)\n\n**提高 ORDER BY 排序的速度：**\n\n- `ORDER BY`时使用`SELECT *`是大忌，查什么字段就写什么字段，这点非常重要。在这里的影响是：\n  - 当查询的字段大小总和小于`max_length_for_sort_data`而且排序字段不是`TEXT|BLOB`类型时，会使用单路排序算法，否则使用多路排序算法。\n  - 两种排序算法的数据都有可能超出`sort_buffer`缓冲区的容量，超出之后，会创建`tmp`临时文件进行合并排序，导致多次IO，但是单路排序算法的风险会更大一些，所以要增大`sort_buffer_size`参数的设置。\n- 尝试提高`sort_buffer_size`：不管使用哪种算法，提高这个参数都会提高效率，当然，要根据系统的能力去提高，因为这个参数是针对每个进程的。\n- 尝试提高`max_length_for_sort_data`：提高这个参数，会增加用单路排序算法的概率。但是如果设置的太高，数据总容量`sort_buffer_size`的概率就增大，明显症状是高的磁盘IO活动和低的处理器使用率。\n\n---\n\n#### 案例一\n\n![1556335817763](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556335817763.png)\n\n通过有序索引顺序扫描直接返回有序数据，这种情况即为` Using index`，不需要额外排序，操作效率高。\n\n![1556335866539](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556335866539.png) \n\n多字段排序\n\n![1556336352061](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556336352061.png)\n\n#### 案例二\n\n> 数据准备\n\n```sql\nCREATE TABLE `talA`(\n`age` INT,\n`birth` TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP\n);\n\nINSERT INTO `talA`(`age`) VALUES(18);\nINSERT INTO `talA`(`age`) VALUES(19);\nINSERT INTO `talA`(`age`) VALUES(20);\nINSERT INTO `talA`(`age`) VALUES(21);\nINSERT INTO `talA`(`age`) VALUES(22);\nINSERT INTO `talA`(`age`) VALUES(23);\nINSERT INTO `talA`(`age`) VALUES(24);\nINSERT INTO `talA`(`age`) VALUES(25);\n\n/* 创建索引 */\nCREATE INDEX idx_talA_age_birth ON `talA`(`age`, `birth`);\n```\n\n> 案例\n\n```sql\n/* 1.使用索引进行排序了 不会产生Using filesort */\nEXPLAIN SELECT * FROM `talA` WHERE `age` > 20 ORDER BY `age`;\n\n/* 2.使用索引进行排序了 不会产生Using filesort（两个都建了索引，并且满足最左前缀原则） */\nEXPLAIN SELECT * FROM `talA` WHERE `age` > 20 ORDER BY `age`,`birth`;\n\n/* 3.没有使用索引进行排序 产生了Using filesort（因为没有满足最左前缀原则） */\nEXPLAIN SELECT * FROM `talA` WHERE `age` > 20 ORDER BY `birth`;\n\n/* 4.没有使用索引进行排序 产生了Using filesort（因为没有满足最左前缀原则） */\nEXPLAIN SELECT * FROM `talA` WHERE `age` > 20 ORDER BY `birth`,`age`;\n\n/* 5.没有使用索引进行排序 产生了Using filesort（因为没有满足最左前缀原则） */\nEXPLAIN SELECT * FROM `talA` ORDER BY `birth`;\n\n/* 6.没有使用索引进行排序 产生了Using filesort（因为没有满足最左前缀原则） */\nEXPLAIN SELECT * FROM `talA` WHERE `birth` > '2020-08-04 07:42:21' ORDER BY `birth`;\n\n/* 7.使用索引进行排序了 不会产生Using filesort（因为 birth 和 age 都建了索引） */\nEXPLAIN SELECT * FROM `talA` WHERE `birth` > '2020-08-04 07:42:21' ORDER BY `age`;\n\n/* 8.没有使用索引进行排序 产生了Using filesort（一个升序一个降序会失效） */\nEXPLAIN SELECT * FROM `talA` ORDER BY `age` ASC, `birth` DESC;\n```\n\n`ORDER BY` 各种场景总结：\n\n```sql\n/* 创建a b c三个字段的索引 */\nidx_table_a_b_c(a, b, c)\n\n/* 1.ORDER BY 能使用索引最左前缀 */\nORDER BY a;\nORDER BY a, b;\nORDER BY a, b, c;\nORDER BY a DESC, b DESC, c DESC;\n\n/* 2.如果WHERE子句中使用索引的最左前缀定义为常量，则ORDER BY能使用索引 */\nWHERE a = 'Ringo' ORDER BY b, c;\nWHERE a = 'Ringo' AND b = 'Tangs' ORDER BY c;\nWHERE a = 'Ringo' AND b > 2000 ORDER BY b, c;\n\n/* 3.不能使用索引进行排序 */\nORDER BY a ASC, b DESC, c DESC;  /* 排序不一致 */\nWHERE g = const ORDER BY b, c;   /* 丢失a字段索引 */\nWHERE a = const ORDER BY c;      /* 丢失b字段索引 */\nWHERE a = const ORDER BY a, d;   /* d字段不是索引的一部分 */\nWHERE a IN (...) ORDER BY b, c;  /* 对于排序来说，多个相等条件(a=1 or a=2)也是范围查询 */\n```\n\n\n\n### GROUP BY 语句优化\n\n> GROUP BY 可能出现 Using temporary 和 Using filesort\n\n由于 `GROUP BY` 实际上也同样会进行排序操作，而且与 `ORDER BY` 相比，`GROUP BY` 主要只是多了排序之后的分组操作。当然，如果在分组的时候还使用了其他的一些聚合函数，那么还需要一些聚合函数的计算。所以，在 `GROUP BY` 的实现过程中，与 `ORDER BY` 一样也可以利用到索引，按照 `ORDER BY` 语句优化的思路优化 `GROUP BY`。\n\n`GROUP BY` 优化技巧：\n\n- `GROUP BY` 实质是**先排序后进行分组**，因此 `ORDER BY` 语句的优化思路也可以用在这里。例如：\n  - 尽量在索引列上进行分组，使用覆盖索引\n- **手动禁用排序**：如果查询结果不需要排序的话，可以在 `GROUP BY` 后添加 `ORDER BY NULL`\n- 当无法使用索引列时，会使用`Using filesort`进行排序，增大`max_length_for_sort_data`参数的设置和增大`sort_buffer_size`参数的设置，会提高性能\n- `WHERE`执行顺序高于`HAVING`，能写在`WHERE`限定条件里的就不要写在`HAVING`中\n\n#### 案例\n\n优化前（删除索引后分组查询。默认会排序）：\n\n```SQL\ndrop index idx_emp_age_salary on emp;\n\nexplain select age,count(*) from emp group by age;\n```\n\n![1556339573979](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556339573979.png)\n\n初优化（取消排序，但不添加索引，此时会出现临时表进行分组）：\n\n```sql\nexplain select age,count(*) from emp group by age order by null;\n```\n\n![1556339633161](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556339633161.png)\n\n最终优化（创建索引后再取消排序分组） ：\n\n```SQL\ncreate index idx_emp_age_salary on emp(age,salary)；\n```\n\n![1556339688158](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556339688158.png) \n\n###  嵌套子查询优化\n\nMySQL 4.1 版本之后，开始支持SQL的子查询。这个技术可以使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，**子查询是可以被更高效的连接查询（JOIN）替代**。\n\n**连接查询之所以更有效率一些 ，是因为 MySQL 不需要在内存中创建临时表来完成查询**。\n\n示例：查找有角色的所有的用户信息 : \n\n```SQL\n explain select * from t_user where id in (select user_id from user_role );\n```\n\n执行计划为 : \n\n![1556359399199](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556359399199.png)\n\n优化后 :\n\n```SQL\nexplain select * from t_user u , user_role ur where u.id = ur.user_id;\n```\n\n![1556359482142](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556359482142.png)\n\n观察 rows：明显查询行数更少\n\n\n\n### OR 语句优化 \n\n对于包含 OR 的查询子句，如果要利用索引，则 OR 之间的每个条件列都必须用到**单列索引**， 而且**不能使用到复合索引**； 如果没有索引，则应该考虑增加索引。\n\n**建议使用 `UNION `替换 `OR`**。\n\n获取 emp 表中的所有的索引 ： \n\n![1556354464657](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556354464657.png)\n\n即使是复合索引，OR 也不走索引，**除非左右都是单列索引**，复合索引是不会分别为索引创建单列索引的\n\n示例 ： \n\n```SQL\nexplain select * from emp where id = 1 or age = 30;\n```\n\n![1556354887509](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556354887509.png)\n\n![1556354920964](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556354920964.png)\n\n使用 `UNION `替换 `OR`：\n\n![1556355027728](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556355027728.png)\n\n我们来比较下重要指标，发现主要差别是 type 和 ref 这两项：\n\ntype 显示的是访问类型，是较为重要的一个指标，结果值从好到坏依次是：\n\n```\nsystem > const > eq_ref > ref > fulltext > ref_or_null  > index_merge > unique_subquery > index_subquery > range > index > ALL\n```\n\n- UNION 语句的 type 值为 ref，OR 语句的 type 值为 range，可以看到这是一个很明显的差距\n- UNION 语句的 ref 值为 const，OR 语句的 type 值为 null，const 表示是常量值引用，非常快\n\n这两项的差距就说明了 UNION 要优于 OR 。\n\n\n\n### LIMIT 语句优化\n\n一般分页查询时，通过创建**覆盖索引**能够比较好地提高性能。一个常见又非常头疼的问题就是 `limit 2000000,10`，此时需要 MySQL 排序前2000010 记录，仅仅返回2000000 - 2000010 的记录，其他记录丢弃，查询排序的代价非常大。例如：\n\n![1556361314783](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556361314783.png)\n\n1、在索引上完成排序分页操作，最后根据主键关联回原表查询所需要的其他列内容。\n\n![1556416102800](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556416102800.png)\n\n2、可以把 Limit 查询转换成某个位置的查询（该方案适用于主键自增的表）。\n\n![1556363928151](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556363928151.png) \n\n### 使用 SQL 提示\n\nSQL 提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的。\n\n#### USE INDEX\n\n在查询语句中表名的后面，添加 use index 来提供希望MySQL去参考的索引列表，就可以让MySQL不再考虑其他可用的索引。\n\n```sql\ncreate index idx_seller_name on tb_seller(name);\n```\n\n![1556370971576](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556370971576.png)\n\n#### IGNORE INDEX\n\n如果用户只是单纯的想让 MySQL 忽略一个或者多个索引，则可以使用 ignore index 作为 hint 。\n\n```sql\n explain select * from tb_seller ignore index(idx_seller_name) where name = '小米科技';\n```\n\n![1556371004594](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556371004594.png)\n\n #### FORCE INDEX\n\n为强制 MySQL 使用一个特定的索引，可在查询中使用 force index 作为 hint 。 \n\n``` SQL\ncreate index idx_seller_address on tb_seller(address);\n```\n\n![1556371355788](/images/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/1556371355788.png)\n\n\n\n## 索引相关杂项\n\n### 前缀索引\n\n在对 varchar 类型的字段添加索引时，如果字段长度过长，那么索引长度就会比较长，那么同样大小的页结构中存储的索引数量就会降低，这样会导致一棵树上存储的索引个数降低，这显然是不利于快速查询。\n\n因此可以对 varchar 类型的字段添加前缀索引，即只对前几个字符创建索引，从而增加每一页中索引的个数，提高查询效率。\n\n添加前缀索引的方法：\n\n```sql\nCREATE INDEX emp_ename_index ON emp(ename(3));\n```\n\n这样只对 ename 字段的前三个字符创建索引。\n\n\n\n### 索引下推\n\n看了那个视频在补充\n\n\n\n### FIC\n\nFIC：Fast Index Creation。FIC 作用：可以让Innodb存储引擎避免创建临时表，提高索引**创建效率**。\n\n在对索引字段进行增删改操作时，整个索引树的结构都需要进行调整（可能发生页分裂等过程），调整过程首先要保证是线程安全的，而且要尽可能的快速。那么如何安全且快速进行调整呢？\n\n对于之前的版本，索引的添加或删除这类DDL操作，MySQL数据库的操作过程为如下：\n\n- 首先创建新的临时表，表结构通过命令ALTAR TABLE新定义的结构\n- 然后把原表中数据导入到临时表\n- 删除原表\n- 最后把临时表重命名为原来的表名\n\n上述过程我们不难发现，若我们对一张大表进行索引的添加或者删除，需要很长的时间，致命的是若有大量的访问请求，意味着无法提供服务。\n\nInnodb存储引擎从1.0.x版本开始支持Fast index Creation（快速索引创建），简称FIC。对于辅助索引的创建，**会对创建索引的表加一个S锁（共享锁）**。在创建的过程中，不需要重建表，因此速度有明显提升。对于删除辅助索引Innodb存储引擎只需要更新内部视图，并将辅助索引的空间标记为可用，同时删除MySQL数据库内部视图上对该表的索引定义即可。特别需要注意的时，临时表的创建路径是通过参数tmpdir设置的。必须确保tmpdir有足够的空间，否则将会导致辅助索引创建失败。\n\n由于在创建辅助索引时加的是S锁，所以在这过程中只**能对该表进行读操作**，若有事务需要对该表进行写操作，那么数据库服务同样不可用。\n\n**需要注意的是，FIC方式只限定于辅助索引，对于主键的创建和删除同样需要重建一张表。**\n\n\n\n\n\n\n\n## 索引最佳实践\n\n### 为什么千万级别数据量下 MySQL 可以快速查找到目标？\n\n因为 MySQL 巧妙地运用了 B+ 树的优点，让数据量的增长和树的高度不成正比（拉宽了整棵树的宽度），哪怕是千万级的数据量，整棵树的高度也可以不超过5层，从而极大地提高了查询效率（只需要遍历不超过5次即可找到目标）\n\n\n\n### 为什么 InnoDB 表必须有主键，且推荐索引使用自增整数类型？\n\n如果不设置主键，则 InnoDB 会自己寻找一个数据值都不相同的列，为其创建主键索引。如果找不到都不相同的，则会维护一个隐藏列作为主键，这无疑浪费了时间与空间。因此建议自己添加索引。\n\n1. 使用整型的原因：整型数据比大小比较快，占用字节也比较少（UUID这种字符串比大小比较慢，占用字节也多）\n2. 使用自增的原因：如果使用自增索引，那么使用 insert 新添加的索引只需要向当前最大索引后面添加即可，不会发生页分裂，也就不需要重新调整整棵树的结构，这样插入速度就会比较快；而如果不自增的话， 随便插入很容易出现页分裂、让树重新调整平衡，速度就会降低\n\n---\n\n分布式数据库中不推荐自增索引，因为：待补充\n\n其需要用到雪花算法做到全局UUID：待补充\n\n---\n\n\n\n### 尽量使用覆盖索引以减少回表，提高性能\n\n> 覆盖索引：只访问索引的查询，索引列和查询列一致\n\n使用覆盖索引时不需要进行回表查询，能够提高性能。减少使用`SELECT *`，这样肯定会进行回表。\n\n\n\n---\n\n更多 MySQL 内容，复习时见视频：https://www.bilibili.com/video/BV1xh411Z79d?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click","tags":["MySQL"],"categories":["MySQL"]},{"title":"【MySQL】MySQL 高级","url":"/2021/10/28/【MySQL】MySQL高级/","content":"\n![image-20210913132511709](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20210913132511709.png)\n\n## MySQL 逻辑架构\n\n![MySQL逻辑架构](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/20180831173911997)\n\n- `Connectors`：指的是不同语言中与SQL的交互。\n- `Connection Pool`：管理缓冲用户连接，线程处理等需要缓存的需求。**MySQL数据库的连接层**。\n- ` Management Serveices & Utilities`：系统管理和控制工具。备份、安全、复制、集群等等。。\n- `SQL Interface`：接受用户的SQL命令，并且返回用户需要查询的结果。\n- `Parser`：SQL语句解析器。\n- `Optimizer`：查询优化器，SQL语句在查询之前会使用查询优化器对查询进行优化。**就是优化客户端请求query**，根据客户端请求的 query 语句，和数据库中的一些统计信息，在一系列算法的基础上进行分析，得出一个最优的策略，告诉后面的程序如何取得这个 query 语句的结果。**For Example**： `select uid,name from user where gender = 1;`这个`select `查询先根据`where `语句进行选取，而不是先将表全部查询出来以后再进行`gender`过滤；然后根据`uid`和`name`进行属性投影，而不是将属性全部取出以后再进行过滤。最后将这两个查询条件联接起来生成最终查询结果。\n- `Caches & Buffers`：查询缓存。\n- `Pluggable Storage Engines`：**可插拔的存储引擎接口。MySQL区别于其他数据库的最重要的特点就是其插件式的表存储引擎(注意：存储引擎是基于表的，而不是数据库)。**\n- `File System`：数据落地到磁盘上，就是文件的存储。\n\nMySQL数据库和其他数据库相比，MySQL有点与众不同，主要体现在存储引擎的架构上，**插件式的存储引擎架构将查询处理和其他的系统任务以及数据的存储提取相分离**。这种架构可以根据业务的需求和实际需求选择合适的存储引擎。\n\n<!-- More -->\n\n> 逻辑架构分层\n\n![MySQL逻辑架构](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/20200801165252510.png)\n\n- **连接层**：最上层是一些客户端和连接服务，包含本地sock通信和大多数基于客户端/服务端工具实现的类似于`tcp/ip`的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上引入了线程池的概念，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于`SSL`的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。\n- **服务层**：MySQL的核心服务功能层，该层是MySQL的核心，包括查询缓存，解析器，解析树，预处理器，查询优化器。主要进行查询解析、分析、查询缓存、内置函数、存储过程、触发器、视图等，select操作会先检查是否命中查询缓存，命中则直接返回缓存数据，否则解析查询并创建对应的解析树。\n- **引擎层**：存储引擎层，存储引擎真正的负责了MySQL中数据的存储和提取，服务器通过API与存储引擎进行通信。不同的存储引擎具有的功能不同，这样我们可以根据自己的实际需要进行选取。\n- **存储层**：数据存储层，主要是将数据存储在运行于裸设备的文件系统之上，并完成与存储引擎的交互。\n\n![image-20211106205418314](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20211106205418314.png)\n\n## 存储引擎\n\n> **存储引擎是对一张表而言**，而非对数据库而言，不同的表可以有不同的存储引擎（可以在 CREATE 语句中指定存储引擎类型）\n\n存储引擎即一张表在数据库中的存储方式。\n\n|              | MyISAM                 | InnoDB                         |\n| ------------ | ---------------------- | ------------------------------ |\n| 事务支持     | 不支持（最新版支持）   | 支持                           |\n| 数据行表锁   | 不支持行锁，只支持表锁 | 支持行锁                       |\n| 外键约束     | 不支持                 | 支持                           |\n| 全文索引     | 支持                   | 不支持（最新版支持）           |\n| 表空间的大小 | 较小                   | 较大，约为2倍                  |\n| 缓存         | 只缓存索引             | 不仅缓存索引，还要缓存真实数据 |\n| 关注点       | 性能                   | 事务                           |\n\n- **MyISAM**：**可被转换为压缩、只读表来节省空间**。节约空间，速度较快\n- **InnoDB**：安全性高，支持**事务**的处理，多表多用户操作，在MySQL服务器**崩溃后提供自动恢复**，支持级联删除和更新\n- **MEMORY**：查询速度**最快**，**表数据和索引**被存储在**内存**中，不支持事务，数据容易丢失。不能包含TEXT或BLOB字段\n\n> 在物理空间存在的位置\n\n所有数据库文件都存在data目录下，一个文件夹就是一个数据库，本质还是文件的存储。MySQL引擎在物理文件上的区别：\n\n- InnoDB：\n  - `*.frm`  表结构的定义文件\n  - `*.ibd` 数据和索引共同存储在一个文件中\n- MyISAM：\n  - `*.frm`  表结构的定义文件\n  - `*.MYD` 数据文件（data）\n  - `*.MYI`  索引文件（index）\n\n> 其中，InnDB 采用聚集（聚数）索引（索引和真实数据存储在一起），MyISAM 采用非聚集（稀疏）索引（索引和真实数据分开存储），这才导致了二者在磁盘上存储文件类型的区别。\n\n三种存储引擎的适用条件：\n\n- MyISAM：适用于大量的数据读而少量数据更新的混合操作（因为是加的表锁），另一种适用情形是使用压缩的只读表\n- InnoDB：适用于查询中包含较多的数据更新操作，其行级锁机制和多版本的支持为数据读取和更新的混合操作提供了良好的并发机制\n- MEMORY：适用于存储非永久需要的数据，或者是能够从基于磁盘的表中重新生成的数据\n\n存储引擎中索引的实现见[【MySQL】MySQL 索引](https://yuyun-zhao.github.io/2021/10/27/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/)。\n\n\n\n### 存储引擎的选择\n\n在选择存储引擎时，应该根据应用系统的特点选择合适的存储引擎。对于复杂的应用系统，还可以根据实际情况选择多种存储引擎进行组合。以下是几种常用的存储引擎的使用环境。\n\n- InnoDB：是 MySQL 默认存储引擎，用于事务处理应用程序，支持外键。如果应用对事务的完整性有比较高的要求，在并发条件下要求数据的一致性，数据操作除了插入和查询意外，还包含很多的更新、删除操作，那么InnoDB存储引擎是比较合适的选择。InnoDB存储引擎除了有效的降低由于删除和更新导致的锁定， 还可以确保事务的完整提交和回滚，对于类似于计费系统或者财务系统等对数据准确性要求比较高的系统，InnoDB是最合适的选择。\n- MyISAM：如果应用是以读操作和插入操作为主，只有很少的更新和删除操作，并且对事务的完整性、并发性要求不是很高，那么选择这个存储引擎是非常合适的。\n- MEMORY：将所有数据保存在RAM中，在需要快速定位记录和其他类似数据环境下，可以提供几块的访问。MEMORY的缺陷就是对表的大小有限制，太大的表无法缓存在内存中，其次是要确保表的数据可以恢复，数据库异常终止后表中的数据是可以恢复的。MEMORY表通常用于更新不太频繁的小表，用以快速得到访问结果。\n- MERGE：用于将一系列等同的MyISAM表以逻辑方式组合在一起，并作为一个对象引用他们。MERGE表的优点在于可以突破对单个MyISAM表的大小限制，并且通过将不同的表分布在多个磁盘上，可以有效的改善MERGE表的访问效率。这对于存储诸如数据仓储等VLDB环境十分合适。\n\n\n\n### InnoBD 相比 MyISAM 的优点\n\n- 支持事务\n- 支持行锁，并发性较好，适合大量写请求的高并发场景\n- 索引数据和实际数据是分开存储的，所以相同大小的页结构中存储的索引数量更多\n\nMyISAM 适合大量读操作，少量写操作，这种情况下性能较高。\n\n### 存储引擎相关命令\n\n`show engines;` 命令查看MySQL 5.7 支持的存储引擎。\n\n```shell\nmysql> show engines;\n```\n\n![存储引擎](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/20200801170442428.png)\n\n`show variables like 'default_storage_engine%';` 查看当前数据库正在使用的存储引擎。\n\n```shell\nmysql> show variables like 'default_storage_engine%';\n+------------------------+--------+\n| Variable_name          | Value  |\n+------------------------+--------+\n| default_storage_engine | InnoDB |\n+------------------------+--------+\n1 row in set (0.01 sec)\n```\n\n<!-- More -->\n\n\n\n## MySQL 性能优化\n\nMySQL 性能下降的原因：\n\n- 查询语句写的差\n- 索引失效：索引建了，但是没有使用\n- 联表查询太多（设计缺陷或者不得已的需求）\n- 服务器调优以及各个参数的设置（缓冲、线程数等）\n\n下面介绍一些常用的优化手段。\n\n### 索引优化\n\n关于 MySQL 索引优化的分析见文章[【MySQL】MySQL 索引](https://yuyun-zhao.github.io/2021/10/28/%E3%80%90MySQL%E3%80%91MySQL%E7%B4%A2%E5%BC%95/)。\n\n### 应用优化：使用连接池\n\n对于访问数据库来说，建立连接的代价是比较昂贵的，因为我们频繁的创建关闭连接，是比较耗费资源的，我们有必要建立 数据库连接池，以提高访问的性能。\n\n**1、避免对数据进行重复检索**\n\n在编写应用代码时，需要能够理清对数据库的访问逻辑。能够一次连接就获取到结果的，就不用两次连接，这样可以大大减少对数据库无用的重复请求。\n\n比如 ，需要获取书籍的 id 和 name 字段， 则查询如下： \n\n```sql\nselect id , name from tb_book;\n```\n\n之后，在业务逻辑中有需要获取到书籍状态信息， 则查询如下：\n\n```sql\nselect id, status from tb_book;\n```\n\n这样，就需要向数据库提交两次请求，数据库就要做两次查询操作。其实完全可以用一条SQL语句得到想要的结果。\n\n```sql\nselect id, name, status from tb_book;\n```\n\n**2、增加 cache 层**\n\n在应用中，我们可以在应用中增加**缓存层**来达到减轻数据库负担的目的。缓存层有很多种，也有很多实现方式，只要能达到降低数据库的负担又能满足应用需求就可以。\n\n因此可以部分数据从数据库中抽取出来放到应用端以文本方式存储， 或者使用框架（Mybatis, Hibernate）提供的一级缓存/二级缓存，或者使用Redis数据库来缓存数据 。\n\n### 应用优化：负载均衡 \n\n负载均衡是应用中使用非常普遍的一种优化方法，它的机制就是利用某种均衡算法，将固定的负载量分布到不同的服务器上， 以此来降低单台服务器的负载，达到优化的效果。\n\n**1、利用 MySQL 复制分流查询**\n\n通过MySQL的主从复制，实现读写分离，使增删改操作走主节点，查询操作走从节点，从而可以降低单台服务器的读写压力。\n\n![1](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1.jpg) \n\n**2、采用分布式数据库架构**\n\n分布式数据库架构适合大数据量、负载高的情况，它有良好的拓展性和高可用性。通过在多台服务器之间分布数据，可以实现在多台服务器之间的负载均衡，提高访问效率。\n\n\n\n### 查询缓存优化\n\n> 高版本的 MySQL 取消了查询缓存的功能（因为会降低 MySQL 的性能），一般使用 Redis 等缓存中间件实现查询缓存。\n\n开启 MySQL 的查询缓存，当执行完全相同的 SQL 语句的时候，服务器就会直接从缓存中读取结果，当数据被修改，之前的缓存会失效，修改比较频繁的表不适合做查询缓存。\n\n操作流程：\n\n ![20180919131632347](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/20180919131632347.png) \n\n1. 客户端发送一条查询给服务器；\n2. 服务器先会检查查询缓存，如果命中了缓存，则立即返回存储在缓存中的结果。否则进入下一阶段；\n3. 服务器端进行SQL解析、预处理，再由优化器生成对应的执行计划；\n4. MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询；\n5. 将结果返回给客户端。\n\n\n\n### 内存管理及优化\n\n#### 内存优化原则\n\n- 将尽量多的内存分配给MySQL做缓存，但要给操作系统和其他程序预留足够内存。\n- MyISAM 存储引擎的数据文件读取依赖于操作系统自身的IO缓存，因此，如果有MyISAM表，就要预留更多的内存给操作系统做IO缓存。\n- 排序区、连接区等缓存是分配给每个数据库会话（session）专用的，其默认值的设置要根据最大连接数合理分配，如果设置太大，不但浪费资源，而且在并发连接较高时会导致物理内存耗尽。\n\n#### MyISAM 内存优化\n\nMyISAM 存储引擎使用 key_buffer 缓存索引块，加速 MyISAM 索引的读写速度。对于 MyISAM 表的数据块，MySQL 没有特别的缓存机制，完全依赖于操作系统的IO缓存。\n\n**key_buffer_size**\n\nkey_buffer_size决定MyISAM索引块缓存区的大小，直接影响到MyISAM表的存取效率。可以在MySQL参数文件中设置key_buffer_size的值，对于一般MyISAM数据库，建议至少将1/4可用内存分配给key_buffer_size。\n\n在`/usr/my.cnf` 中做如下配置：\n\n```\nkey_buffer_size=512M\n```\n\n**read_buffer_size**\n\n如果需要经常顺序扫描 MyISAM 表，可以通过增大read_buffer_size的值来改善性能。但需要注意的是read_buffer_size是每个session独占的，如果默认值设置太大，就会造成内存浪费。\n\n**read_rnd_buffer_size**\n\n对于需要做排序的 MyISAM 表的查询，如带有order by子句的sql，适当增加 read_rnd_buffer_size 的值，可以改善此类的sql性能。但需要注意的是 read_rnd_buffer_size 是每个session独占的，如果默认值设置太大，就会造成内存浪费。\n\n#### InnoDB 内存优化\n\nInnodb用一块内存区做IO缓存池，该缓存池不仅用来缓存innodb的索引块，而且也用来缓存innodb的数据块。\n\n**innodb_buffer_pool_size**\n\n该变量决定了 innodb 存储引擎表数据和索引数据的最大缓存区大小。在保证操作系统及其他程序有足够内存可用的情况下，innodb_buffer_pool_size 的值越大，缓存命中率越高，访问InnoDB表需要的磁盘I/O 就越少，性能也就越高。\n\n```\ninnodb_buffer_pool_size=512M\n```\n\n**innodb_log_buffer_size**\n\n决定了innodb重做日志缓存的大小，对于可能产生大量更新记录的大事务，增加innodb_log_buffer_size的大小，可以避免innodb在事务提交前就执行不必要的日志写入磁盘操作。\n\n```\ninnodb_log_buffer_size=10M\n```\n\n\n\n### 并发参数调整\n\n从实现上来说，MySQL Server 是多线程结构，包括后台线程和客户服务线程。多线程可以有效利用服务器资源，提高数据库的并发性能。在Mysql中，控制并发连接和线程的主要参数包括 max_connections、back_log、thread_cache_size、table_open_cahce。\n\n**max_connections**\n\n采用max_connections 控制允许连接到MySQL数据库的最大数量，默认值是 151。如果状态变量 connection_errors_max_connections 不为零，并且一直增长，则说明不断有连接请求因数据库连接数已达到允许最大值而失败，这是可以考虑增大 max_connections 的值。\n\nMySQL 最大可支持的连接数，取决于很多因素，包括给定操作系统平台的线程库的质量、内存大小、每个连接的负荷、CPU的处理速度，期望的响应时间等。在Linux 平台下，性能好的服务器，支持 500-1000 个连接不是难事，需要根据服务器性能进行评估设定。\n\n#### back_log\n\nback_log 参数控制MySQL监听TCP端口时设置的积压请求栈大小。如果MySql的连接数达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源，将会报错。5.6.6 版本之前默认值为 50 ， 之后的版本默认为 `50 + (max_connections / 5)`， 但最大不超过900。\n\n如果需要数据库在较短的时间内处理大量连接请求， 可以考虑适当增大back_log 的值。\n\n#### table_open_cache\n\n该参数用来控制所有SQL语句执行线程可打开表缓存的数量， 而在执行SQL语句时，每一个SQL执行线程至少要打开 1 个表缓存。该参数的值应该根据设置的最大连接数 max_connections 以及每个连接执行关联查询中涉及的表的最大数量来设定 ：`max_connections x N` \n\n#### thread_cache_size\n\n为了加快连接数据库的速度，MySQL 会缓存一定数量的客户服务线程以备重用，通过参数 thread_cache_size 可控制 MySQL 缓存客户服务线程的数量。\n\n#### innodb_lock_wait_timeout\n\n该参数是用来设置InnoDB 事务等待行锁的时间，默认值是50ms ， 可以根据需要进行动态设置。对于需要快速反馈的业务系统来说，可以将行锁的等待时间调小，以避免事务长时间挂起； 对于后台运行的批量处理程序来说， 可以将行锁的等待时间调大， 以避免发生大的回滚操作。\n\n\n\n## MySQL 锁\n\n从对数据操作的粒度分： \n\n- 表锁：操作时，会锁定整个表。\n- 行锁：操作时，会锁定当前操作行。\n\n从对数据操作的类型分：\n\n- 读锁（共享锁）：针对同一份数据，多个读操作可以同时进行而不会互相影响。\n- 写锁（排它锁）：当前操作没有完成之前，它会阻断其他写锁和读锁。\n\n相对其他数据库而言，MySQL的锁机制比较简单，其最显著的特点是不同的存储引擎支持不同的锁机制。下表中罗列出了各存储引擎对锁的支持情况：\n\n| 存储引擎 | 表级锁 | 行级锁 | 页面锁 |\n| -------- | ------ | ------ | ------ |\n| MyISAM   | 支持   | 不支持 | 不支持 |\n| InnoDB   | 支持   | 支持   | 不支持 |\n| MEMORY   | 支持   | 不支持 | 不支持 |\n| BDB      | 支持   | 不支持 | 支持   |\n\nMySQL这3种锁的特性可大致归纳如下 ：\n\n| 锁类型 | 特点                                                         |\n| ------ | ------------------------------------------------------------ |\n| 表级锁 | 偏向 MyISAM 存储引擎，开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。 |\n| 行级锁 | 偏向 InnoDB 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。 |\n| 页面锁 | 开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。 |\n\n从上述特点可见，很难笼统地说哪种锁更好，只能就具体应用的特点来说哪种锁更合适。仅从锁的角度来说：**表级锁更适合于以查询为主**，只有少量按索引条件更新数据的应用，如Web 应用；而**行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用**，如一些在线事务处理（OLTP）系统。\n\n### MyISAM 表锁\n\nMyISAM 存储引擎只支持表锁，这也是MySQL开始几个版本中唯一支持的锁类型。MyISAM：\n\n- 在执行**查询**语句（SELECT）前，会**自动**给涉及的所有表加**读锁**\n- 在执行**更新**操作（UPDATE、DELETE、INSERT 等）前，会自动给涉及的表加**写锁**\n\n这个过程并不需要用户干预，自动在执行前加锁，在执行完毕后解锁。因此，用户一般不需要直接用 `LOCK TABLE` 命令给 MyISAM 表显式加锁。\n\n显式加表锁语法：\n\n```SQL\n加读锁： lock table table_name read;\n\n加写锁： lock table table_name write；\n```\n\n​\tMyISAM 锁模式的相互兼容性如表中所示：\n\n![1553905621992](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1553905621992-1635924540829.png)\n\n- 对 MyISAM 表的**读操作**，不会阻塞其他用户对同一表的读请求，但**会阻塞对同一表的写请求**；\n- 对 MyISAM 表的**写操作**，则**会阻塞**其他用户对同一表的**读和写**操作；\n\n简而言之，就是读锁会阻塞写，但是不会阻塞读。而写锁，则既会阻塞读，又会阻塞写。这点和 JUC 中的读写锁是一致的。\n\n此外，MyISAM 的读写锁调度是写优先，这也是 MyISAM 不适合做写为主的表的存储引擎的原因。因为写锁后，其他线程不能做任何操作，大量的更新会使查询很难得到锁，从而造成长期阻塞。\n\n\n\n### InnoDB 行锁\n\n> **使用行锁的前提是操作必须走索引**，否则行锁就会变为表锁。\n\n行锁特点 ：偏向 InnoDB 存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。InnoDB 与 MyISAM 的最大不同有两点：一是支持事务；二是采用了行级锁。\n\n**行锁的实现依赖于事务**。必须在事务内加锁。\n\nInnoDB  实现了以下两种类型的行锁。\n\n- **共享锁**（S）：又称为读锁，简称S锁，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。\n- **排他锁**（X）：又称为写锁，简称X锁，排他锁就是不能与其他锁并存，如一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据就行读取和修改。\n\nInnoDB 加锁时机：\n\n- 对于UPDATE、DELETE和INSERT语句，InnoDB会**自动**给涉及数据集加**写锁**；\n- 对于普通SELECT语句，InnoDB **不会加任何锁**；\n- 索引失效时**行锁升级为表锁**\n\n自动加锁的机制：\n\n- 在开启事务后加上写锁\n- `COMMIT` 或 `ROLL BACK` 后释放锁\n\n**注意**：即使某一行加了锁，也不影响其他会话 SELECT 语句的查询，因为 SELECT 查询不加任何锁，可以无视其他会话加的写锁（不会阻塞）。只不过其读取不到另一个加了锁的会话修改的数据罢了（因为其加锁的会话还没提交，是无法独到它未提交的数据的）。\n\n![image-20210421122752768](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/20210421122919994.png)\n\n\n\n可以通过以下语句显式给记录集加共享锁或排他锁 。\n\n```sql\n共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE\n\n排他锁（X) ：SELECT * FROM table_name WHERE ... FOR UPDATE\n```\n\n#### 行锁基本演示\n\n![image-20211103162756082](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20211103162756082.png)\n\n![image-20211103162815546](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20211103162815546.png)\n\n#### 索引失效时行锁升级为表锁\n\n如果**不通过索引条件检索数据**，那么InnoDB将对表中的所有记录加锁，实际效果跟表锁一样。\n\n查看当前表的索引 ： show  index  from test_innodb_lock ;\n\n![1554385956215](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554385956215.png)\n\n![image-20211103163018500](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20211103163018500.png)\n\n由于执行更新时，name字段本来为varchar类型， 我们是作为数组类型使用，存在类型转换，索引失效，最终行锁变为表锁 ，其他会话更新其他行数据仍然阻塞；\n\n#### 间隙锁危害\n\n当我们使用范围条件，而不是使用相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据进行加锁； 对于键值在条件范围内但并不存在的记录，叫做 \"间隙（GAP）\" ， InnoDB也会对这个 \"间隙\" 加锁，这种锁机制就是所谓的**间隙锁**（Next-Key锁） 。\n\n`InnoDB`也会对这个\"间隙\"加锁，这种锁的机制就是所谓的\"间隙锁\"。\n\n> 间隙锁的危害\n\n因为执行过程中通过范围查找的话，他会锁定整个范围内所有的索引键值，即使这个键值不存在。\n\n间隙锁有一个比较致命的缺点，就是**当锁定一个范围的键值后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。**在某些场景下这可能会对性能造成很大的危害。\n\n示例 ： \n\n![image-20211103163115103](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20211103163115103.png)\n\n#### 如何锁定一行\n\n![锁定一行](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/2020080616050355.png)\n\n`SELECT .....FOR UPDATE`在锁定某一行后，其他写操作会被阻塞，直到锁定的行被`COMMIT`。\n\nInnoDB引擎默认的修改数据语句，update,delete,insert都会**自动给涉及到的数据加上排他锁**，**select语句默认不会加任何锁类型**，如果手动加排他锁可以使用`select ...for update`语句，手动加共享锁可以使用`select ... lock in share mode`语句。所以加过排他锁的数据行在其他事务种是不能修改数据的，也不能通过`for update`和`lock in share mode`锁的方式查询数据，但可以直接通过`select ...from...`查询数据，因为普通查询没有任何锁机制。\n\n![image-20210421122752768](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/20210421122919994.png)\n\n\n\n#### InnoDB 行锁争用情况\n\n```sql\nshow status like 'innodb_row_lock%';\n```\n\n![1556455943670](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1556455943670.png)\n\n- `Innodb_row_lock_current_waits`：当前正在等待锁定的数量。\n- `Innodb_row_lock_time`：从系统启动到现在锁定总时间长度（重要）。\n- `Innodb_row_lock_time_avg`：每次等待所花的平均时间（重要）。\n- `Innodb_row_lock_time_max`：从系统启动到现在等待最长的一次所花的时间。\n- `Innodb_row_lock_waits`：系统启动后到现在总共等待的次数（重要）。\n\n尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手制定优化策略。\n\n#### 总结\n\nInnoDB存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面带来了性能损耗可能比表锁会更高一些，但是在整体并发处理能力方面要远远由于MyISAM的表锁的。当系统并发量较高的时候，InnoDB的整体性能和MyISAM相比就会有比较明显的优势。\n\n但是，InnoDB的行级锁同样也有其脆弱的一面，当我们使用不当的时候，可能会让InnoDB的整体性能表现不仅不能比MyISAM高，甚至可能会更差。\n\n优化建议：\n\n- 尽可能让所有数据检索都能通过索引来完成，避免无索引行锁升级为表锁。\n- 合理设计索引，尽量缩小锁的范围\n- 尽可能减少索引条件，及索引范围，避免间隙锁\n- 尽量控制事务大小，减少锁定资源量和时间长度\n- 尽可使用低级别事务隔离（但是需要业务层面满足需求）\n\n\n\n## MySQL 常用工具\n\n### mysql\n\n该mysql不是指mysql服务，而是指mysql的**客户端工具**。语法 ：\n\n```\nmysql [options] [database]\n```\n\n#### 连接选项\n\n```\n参数 ： \n\t-u, --user=name\t\t\t指定用户名\n\t-p, --password[=name]\t指定密码\n\t-h, --host=name\t\t\t指定服务器IP或域名\n\t-P, --port=#\t\t\t指定连接端口\n\n示例 ：\n\tmysql -h 127.0.0.1 -P 3306 -u root -p\n\t\n\tmysql -h127.0.0.1 -P3306 -uroot -p2143\n```\n\n#### 执行选项\n\n```\n-e, --execute=name\t\t执行SQL语句并退出\n```\n\n此选项可以在Mysql客户端执行SQL语句，而不用连接到MySQL数据库再执行，对于一些批处理脚本，这种方式尤其方便。\n\n```\n示例：\n\tmysql -uroot -p2143 db01 -e \"select * from tb_book\";\n```\n\n![1555325632715](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1555325632715.png) \n\n### mysqladmin\n\nmysqladmin 是一个执行管理操作的客户端程序。可以用它来检查服务器的配置和当前状态、创建并删除数据库等。\n\n可以通过 ： mysqladmin --help  指令查看帮助文档\n\n![1555326108697](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1555326108697.png) \n\n```\n示例 ：\n\tmysqladmin -uroot -p2143 create 'test01';  \n\tmysqladmin -uroot -p2143 drop 'test01';\n\tmysqladmin -uroot -p2143 version;\n```\n\n### mysqlbinlog\n\n由于服务器生成的二进制日志文件以二进制格式保存，所以如果想要检查这些文本的文本格式，就会使用到mysqlbinlog 日志管理工具。\n\n语法 ：\n\n```\nmysqlbinlog [options]  log-files1 log-files2 ...\n\n选项：\n\t-d, --database=name : 指定数据库名称，只列出指定的数据库相关操作。\n\t-o, --offset=# : 忽略掉日志中的前n行命令。\n\t-r,--result-file=name : 将输出的文本格式日志输出到指定文件。\n\t-s, --short-form : 显示简单格式， 省略掉一些信息。\n\t--start-datatime=date1  --stop-datetime=date2 : 指定日期间隔内的所有日志。\n\t--start-position=pos1 --stop-position=pos2 : 指定位置间隔内的所有日志。\n```\n\n#### mysqldump\n\nmysqldump 客户端工具用来备份数据库或在不同数据库之间进行数据迁移。备份内容包含创建表，及插入表的SQL语句。\n\n语法 ：\n\n```\nmysqldump [options] db_name [tables]\n\nmysqldump [options] --database/-B db1 [db2 db3...]\n\nmysqldump [options] --all-databases/-A\n```\n\n#### 连接选项\n\n```\n参数 ： \n\t-u, --user=name\t\t\t指定用户名\n\t-p, --password[=name]\t指定密码\n\t-h, --host=name\t\t\t指定服务器IP或域名\n\t-P, --port=#\t\t\t指定连接端口\n```\n\n#### 输出内容选项\n\n```\n参数：\n\t--add-drop-database\t\t在每个数据库创建语句前加上 Drop database 语句\n\t--add-drop-table\t\t在每个表创建语句前加上 Drop table 语句 , 默认开启 ; 不开启 (--skip-add-drop-table)\n\t\n\t-n, --no-create-db\t\t不包含数据库的创建语句\n\t-t, --no-create-info\t不包含数据表的创建语句\n\t-d --no-data\t\t\t不包含数据\n\t\n\t-T, --tab=name\t\t\t自动生成两个文件：一个.sql文件，创建表结构的语句；\n\t \t\t\t\t\t\t一个.txt文件，数据文件，相当于select into outfile  \n```\n\n```\n示例 ： \n\tmysqldump -uroot -p2143 db01 tb_book --add-drop-database --add-drop-table > a\n\t\n\tmysqldump -uroot -p2143 -T /tmp test city\n```\n\n![image-20211103165212348](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20211103165212348.png)\n\n#### mysqlimport/source\n\nmysqlimport 是客户端数据导入工具，用来导入mysqldump 加 -T 参数后导出的文本文件。\n\n语法：\n\n```\nmysqlimport [options]  db_name  textfile1  [textfile2...]\n```\n\n示例：\n\n```\nmysqlimport -uroot -p2143 test /tmp/city.txt\n```\n\n如果需要导入sql文件，可以使用mysql中的source 指令 : \n\n```\nsource /root/tb_book.sql\n```\n\n#### mysqlshow\n\nmysqlshow 客户端对象查找工具，用来很快地查找存在哪些数据库、数据库中的表、表中的列或者索引。\n\n语法：\n\n```\nmysqlshow [options] [db_name [table_name [col_name]]]\n```\n\n参数：\n\n```\n--count\t\t显示数据库及表的统计信息（数据库，表 均可以不指定）\n\n-i\t\t\t显示指定数据库或者指定表的状态信息\n```\n\n示例：\n\n```bash\n#查询每个数据库的表的数量及表中记录的数量\nmysqlshow -uroot -p2143 --count\n\n#查询test库中每个表中的字段书，及行数\nmysqlshow -uroot -p2143 test --count\n\n#查询test库中book表的详细情况\nmysqlshow -uroot -p2143 test book --count\n```\n\n\n\n## MySQL 日志\n\n在任何一种数据库中，都会有各种各样的日志，记录着数据库工作的方方面面，以帮助数据库管理员追踪数据库曾经发生过的各种事件。MySQL 也不例外，在 MySQL 中，有 4 种不同的日志，分别是错误日志、二进制日志（BINLOG 日志）、查询日志和慢查询日志，这些日志记录着数据库在不同方面的踪迹。\n\n### 错误日志\n\n错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，可以首先查看此日志。\n\n该日志是默认开启的 ， 默认存放目录为 mysql 的数据目录（var/lib/mysql）, 默认的日志文件名为  hostname.err（hostname是主机名）。\n\n查看日志位置指令 ： \n\n```sql\nshow variables like 'log_error%';\n```\n\n![1553993244446](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1553993244446.png)\n\n查看日志内容 ： \n\n```shell\ntail -f /var/lib/mysql/xaxh-server.err\n```\n\n![1553993537874](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1553993537874.png)\n\n ### 二进制日志\n\n#### 概述\n\n二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但是不包括数据查询语句。此日志对于灾难时的数据恢复起着极其重要的作用，MySQL的主从复制， 就是通过该binlog实现的。\n\n二进制日志，默认情况下是没有开启的，需要到MySQL的配置文件中开启，并配置MySQL日志的格式。 \n\n配置文件位置：`/usr/my.cnf`\n\n日志存放位置：配置时，给定了文件名但是没有指定路径，日志默认写入MySQL的数据目录。\n\n```\n# 配置开启binlog日志， 日志的文件前缀为 mysqlbin -----> 生成的文件名如 : mysqlbin.000001,mysqlbin.000002\nlog_bin=mysqlbin\n\n# 配置二进制日志的格式\nbinlog_format=STATEMENT\n\n```\n\n#### 日志格式\n\n**STATEMENT**\n\n该日志格式在日志文件中记录的都是SQL语句（statement），每一条对数据进行修改的SQL都会记录在日志文件中，通过MySQL提供的mysqlbinlog工具，可以清晰的查看到每条语句的文本。主从复制的时候，从库（slave）会将日志解析为原文本，并在从库重新执行一次。\n\n**ROW**\n\n该日志格式在日志文件中记录的是每一行的数据变更，而不是记录SQL语句。比如，执行SQL语句 ： `update tb_book set status='1'` , 如果是STATEMENT 日志格式，在日志中会记录一行SQL文件； 如果是ROW，由于是对全表进行更新，也就是每一行记录都会发生变更，ROW 格式的日志中会记录每一行的数据变更。\n\n**MIXED**\n\n这是目前MySQL默认的日志格式，即混合了STATEMENT 和 ROW两种格式。默认情况下采用STATEMENT，但是在一些特殊情况下采用ROW来进行记录。MIXED 格式能尽量利用两种模式的优点，而避开他们的缺点。\n\n#### 日志读取\n\n由于日志以二进制方式存储，不能直接读取，需要用mysqlbinlog工具来查看，语法如下 ：\n\n```\nmysqlbinlog log-file；\n```\n\n**查看STATEMENT格式日志** \n\n执行插入语句 ：\n\n```SQL\ninsert into tb_book values(null,'Lucene','2088-05-01','0');\n```\n\n 查看日志文件 ：\n\n![1554079717375](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554079717375.png)\n\n- mysqlbin.index：该文件是日志索引文件 ， 记录日志的文件名；\n- mysqlbing.000001：日志文件\n\n查看日志内容 ：\n\n```\nmysqlbinlog mysqlbing.000001；\n```\n\n![1554080016778](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554080016778.png)\n\n**查看 ROW 格式日志**\n\n配置 :\n\n```\n# 配置开启binlog日志， 日志的文件前缀为 mysqlbin -----> 生成的文件名如 : mysqlbin.000001,mysqlbin.000002\nlog_bin=mysqlbin\n\n# 配置二进制日志的格式\nbinlog_format=ROW\n```\n\n插入数据 :\n\n```sql\ninsert into tb_book values(null,'SpringCloud实战','2088-05-05','0');\n```\n\n如果日志格式是 ROW , 直接查看数据 , 是查看不懂的 ; 可以在mysqlbinlog 后面加上参数 -vv  \n\n```SQL\nmysqlbinlog -vv mysqlbin.000002 \n```\n\n![1554095452022](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554095452022.png)\n\n### 日志删除\n\n对于比较繁忙的系统，由于每天生成日志量大 ，这些日志如果长时间不清楚，将会占用大量的磁盘空间。下面我们将会讲解几种删除日志的常见方法 ：\n\n**方式一** \n\n通过 Reset Master 指令删除全部 binlog 日志，删除之后，日志编号，将从 xxxx.000001重新开始 。\n\n查询之前 ，先查询下日志文件 ： \n\n![1554118609489](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554118609489.png)\n\n执行删除日志指令： \n\n```\nReset Master\n```\n\n执行之后， 查看日志文件 ：\n\n![1554118675264](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554118675264.png)\n\n**方式二**\n\n执行指令 ``` purge  master logs to 'mysqlbin.******'``` ，该命令将删除  ``` ******``` 编号之前的所有日志。 \n\n**方式三**\n\n执行指令 ``` purge master logs before 'yyyy-mm-dd hh24:mi:ss'``` ，该命令将删除日志为 `\"yyyy-mm-dd hh24:mi:ss\"` 之前产生的所有日志 。\n\n**方式四**\n\n设置参数 `--expire_logs_days=#` ，此参数的含义是设置日志的过期天数， 过了指定的天数后日志将会被自动删除，这样将有利于减少DBA 管理日志的工作量。\n\n配置如下 ： \n\n![1554125506938](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554125506938.png)\n\n ### 查询日志\n\n查询日志中记录了客户端的所有操作语句，而二进制日志不包含查询数据的SQL语句。\n\n默认情况下， 查询日志是未开启的。如果需要开启查询日志，可以设置以下配置 ：\n\n```\n# 该选项用来开启查询日志 ， 可选值 ： 0 或者 1 ； 0 代表关闭， 1 代表开启 \ngeneral_log=1\n\n# 设置日志的文件名 ， 如果没有指定， 默认的文件名为 host_name.log \ngeneral_log_file=file_name\n\n```\n\n在配置文件 `/usr/my.cnf` 中配置如下内容 ： \n\n![1554128184632](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554128184632.png)\n\n配置完毕之后，在数据库执行以下操作 ：\n\n```sql\nselect * from tb_book;\nselect * from tb_book where id = 1;\nupdate tb_book set name = 'lucene入门指南' where id = 5;\nselect * from tb_book where id < 8;\n```\n\n执行完毕之后， 再次来查询日志文件 ： \n\n![1554128089851](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554128089851.png)\n\n### 慢查询日志\n\n慢查询日志记录了所有执行时间超过参数 `long_query_time` 设置值并且扫描记录数不小于 `min_examined_row_limit` 的所有的SQL语句的日志。`long_query_time` 默认为 10 秒，最小为 0， 精度可以到微秒。\n\n#### 文件位置和格式\n\n慢查询日志默认是关闭的 。可以通过两个参数来控制慢查询日志 ：\n\n```\n# 该参数用来控制慢查询日志是否开启， 可取值： 1 和 0 ， 1 代表开启， 0 代表关闭\nslow_query_log=1 \n\n# 该参数用来指定慢查询日志的文件名\nslow_query_log_file=slow_query.log\n\n# 该选项用来配置查询的时间限制， 超过这个时间将认为值慢查询， 将需要进行日志记录， 默认10s\nlong_query_time=10\n```\n\n#### 日志的读取\n\n和错误日志、查询日志一样，慢查询日志记录的格式也是纯文本，可以被直接读取。\n\n1） 查询 `long_query_time` 的值。\n\n![1554130333472](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554130333472.png)\n\n2） 执行查询操作\n\n```sql\nselect id, title,price,num ,status from tb_item where id = 1;\n```\n\n![1554130448709](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554130448709.png)\n\n由于该语句执行时间很短，为0s ， 所以不会记录在慢查询日志中。\n\n```sql\nselect * from tb_item where title like '%阿尔卡特 (OT-927) 炭黑 联通3G手机 双卡双待165454%' ;\n```\n\n![1554130532577](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554130532577.png)\n\n该SQL语句 ， 执行时长为 26.77s ，超过10s ， 所以会记录在慢查询日志文件中。\n\n3） 查看慢查询日志文件\n\n直接通过cat 指令查询该日志文件 ： \n\n![1554130669360](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554130669360.png)\n\n如果慢查询日志内容很多， 直接查看文件，比较麻烦， 这个时候可以借助于mysql自带的 mysqldumpslow 工具， 来对慢查询日志进行分类汇总。 \n\n![1554130856485](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1554130856485.png)\n\n\n\n## MySQL 主从复制\n\n### 概述\n\n主从复制是指将主数据库的 DDL 和 DML 操作（不包含 SELECT 语句）通过**二进制日志**传到从库服务器中，然后在从库上对这些日志**重新执行**（也叫重做），从而使得从库和主库的数据保持同步。\n\nMySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。\n\n主从复制特点（与Redis相似）：\n\n- 主库负责写操作，从库负责读操作，实现读写分离。\n- 主库的数据一旦变更，从库立即更新。\n\n### 主从复制原理\n\n![1554423698190](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/1-1635929423937.jpg)\n\n整个过程分成三步：\n\n- Master 主库在事务提交时，会把数据变更（不包含 SELECT 语句）作为时间 Events 记录在二进制日志文件 Binlog 中。\n- 主库推送**二进制日志文件** Binlog 中的日志事件到从库的**中继日志** Relay Log。\n- Slave**重做**中继日志中的事件，将改变反映它自己的数据。\n\n### 主从复制基本原则\n\n- 每个Slave只有一个Master。\n- 每个Slave只能有一个唯一的服务器ID。\n- 每个Master可以有多个Salve。\n\n#### 复制优势\n\nMySQL 复制的有点主要包含以下三个方面：\n\n- 主库出现问题，可以快速**切换到从库**提供服务。\n- 可以在从库上执行查询操作，从主库中更新，实现**读写分离**，降低主库的访问压力。\n- 可以**在从库中执行备份**，以避免备份期间影响主库的服务。\n\n### 一主一从配置案例\n\n1、基本要求：Master和Slave的MySQL服务器版本一致且后台以服务运行。\n\n```shell\n# 创建mysql-slave1实例\ndocker run -p 3307:3306 --name mysql-slave1 \\\n-v /root/mysql-slave1/log:/var/log/mysql \\\n-v /root/mysql-slave1/data:/var/lib/mysql \\\n-v /root/mysql-slave1/conf:/etc/mysql \\\n-e MYSQL_ROOT_PASSWORD=333 \\\n-d mysql:5.7\n```\n\n2、主从配置都是配在[mysqld]节点下，都是小写\n\n```shell\n# Master配置\n[mysqld]\nserver-id=1 # 必须\nlog-bin=/var/lib/mysql/mysql-bin # 必须\nread-only=0\nbinlog-ignore-db=mysql\n```\n\n```shell\n# Slave配置\n[mysqld]\nserver-id=2 # 必须\nlog-bin=/var/lib/mysql/mysql-bin\n```\n\n3、Master配置\n\n```shell\n# 1、GRANT REPLICATION SLAVE ON *.* TO 'username'@'从机IP地址' IDENTIFIED BY 'password';\nmysql> GRANT REPLICATION SLAVE ON *.* TO 'zhangsan'@'172.18.0.3' IDENTIFIED BY '123456';\nQuery OK, 0 rows affected, 1 warning (0.01 sec)\n\n# 2、刷新命令\nmysql> FLUSH PRIVILEGES;\nQuery OK, 0 rows affected (0.00 sec)\n\n# 3、记录下File和Position\n# 每次配从机的时候都要SHOW MASTER STATUS;查看最新的File和Position\nmysql> SHOW MASTER STATUS;\n+------------------+----------+--------------+------------------+-------------------+\n| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |\n+------------------+----------+--------------+------------------+-------------------+\n| mysql-bin.000001 |      602 |              | mysql            |                   |\n+------------------+----------+--------------+------------------+-------------------+\n1 row in set (0.00 sec)\n```\n\n4、Slave从机配置\n\n```shell\nCHANGE MASTER TO MASTER_HOST='172.18.0.4',\nMASTER_USER='zhangsan',\nMASTER_PASSWORD='123456',\nMASTER_LOG_FILE='mysql-bin.File的编号',\nMASTER_LOG_POS=Position的最新值;\n```\n\n```shell\n# 1、使用用户名密码登录进Master\nmysql> CHANGE MASTER TO MASTER_HOST='172.18.0.4',\n    -> MASTER_USER='zhangsan',\n    -> MASTER_PASSWORD='123456',\n    -> MASTER_LOG_FILE='mysql-bin.000001',\n    -> MASTER_LOG_POS=602;\nQuery OK, 0 rows affected, 2 warnings (0.02 sec)\n\n# 2、开启Slave从机的复制\nmysql> START SLAVE;\nQuery OK, 0 rows affected (0.00 sec)\n\n# 3、查看Slave状态\n# Slave_IO_Running 和 Slave_SQL_Running 必须同时为Yes 说明主从复制配置成功！\nmysql> SHOW SLAVE STATUS\\G\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event # Slave待命状态\n                  Master_Host: 172.18.0.4\n                  Master_User: zhangsan\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File: mysql-bin.000001\n          Read_Master_Log_Pos: 602\n               Relay_Log_File: b030ad25d5fe-relay-bin.000002\n                Relay_Log_Pos: 320\n        Relay_Master_Log_File: mysql-bin.000001\n             Slave_IO_Running: Yes  \n            Slave_SQL_Running: Yes\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n           Replicate_Do_Table: \n       Replicate_Ignore_Table: \n      Replicate_Wild_Do_Table: \n  Replicate_Wild_Ignore_Table: \n                   Last_Errno: 0\n                   Last_Error: \n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 602\n              Relay_Log_Space: 534\n              Until_Condition: None\n               Until_Log_File: \n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File: \n           Master_SSL_CA_Path: \n              Master_SSL_Cert: \n            Master_SSL_Cipher: \n               Master_SSL_Key: \n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error: \n               Last_SQL_Errno: 0\n               Last_SQL_Error: \n  Replicate_Ignore_Server_Ids: \n             Master_Server_Id: 1\n                  Master_UUID: bd047557-b20c-11ea-9961-0242ac120002\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind: \n      Last_IO_Error_Timestamp: \n     Last_SQL_Error_Timestamp: \n               Master_SSL_Crl: \n           Master_SSL_Crlpath: \n           Retrieved_Gtid_Set: \n            Executed_Gtid_Set: \n                Auto_Position: 0\n         Replicate_Rewrite_DB: \n                 Channel_Name: \n           Master_TLS_Version: \n1 row in set (0.00 sec)\n```\n\n5、测试主从复制\n\n```shell\n# Master创建数据库\nmysql> create database test_replication;\nQuery OK, 1 row affected (0.01 sec)\n\n# Slave查询数据库\nmysql> show databases;\n+--------------------+\n| Database           |\n+--------------------+\n| information_schema |\n| mysql              |\n| performance_schema |\n| sys                |\n| test_replication   |\n+--------------------+\n5 rows in set (0.00 sec)\n```\n\n6、停止主从复制功能\n\n```shell\n# 1、停止Slave\nmysql> STOP SLAVE;\nQuery OK, 0 rows affected (0.00 sec)\n\n# 2、重新配置主从\n# MASTER_LOG_FILE 和 MASTER_LOG_POS一定要根据最新的数据来配\nmysql> CHANGE MASTER TO MASTER_HOST='172.18.0.4',\n    -> MASTER_USER='zhangsan',\n    -> MASTER_PASSWORD='123456',\n    -> MASTER_LOG_FILE='mysql-bin.000001',\n    -> MASTER_LOG_POS=797;\nQuery OK, 0 rows affected, 2 warnings (0.01 sec)\n\nmysql> START SLAVE;\nQuery OK, 0 rows affected (0.00 sec)\n\nmysql> SHOW SLAVE STATUS\\G\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: 172.18.0.4\n                  Master_User: zhangsan\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File: mysql-bin.000001\n          Read_Master_Log_Pos: 797\n               Relay_Log_File: b030ad25d5fe-relay-bin.000002\n                Relay_Log_Pos: 320\n        Relay_Master_Log_File: mysql-bin.000001\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB: \n          Replicate_Ignore_DB: \n           Replicate_Do_Table: \n       Replicate_Ignore_Table: \n      Replicate_Wild_Do_Table: \n  Replicate_Wild_Ignore_Table: \n                   Last_Errno: 0\n                   Last_Error: \n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 797\n              Relay_Log_Space: 534\n              Until_Condition: None\n               Until_Log_File: \n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File: \n           Master_SSL_CA_Path: \n              Master_SSL_Cert: \n            Master_SSL_Cipher: \n               Master_SSL_Key: \n        Seconds_Behind_Master: 0\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error: \n               Last_SQL_Errno: 0\n               Last_SQL_Error: \n  Replicate_Ignore_Server_Ids: \n             Master_Server_Id: 1\n                  Master_UUID: bd047557-b20c-11ea-9961-0242ac120002\n             Master_Info_File: /var/lib/mysql/master.info\n                    SQL_Delay: 0\n          SQL_Remaining_Delay: NULL\n      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates\n           Master_Retry_Count: 86400\n                  Master_Bind: \n      Last_IO_Error_Timestamp: \n     Last_SQL_Error_Timestamp: \n               Master_SSL_Crl: \n           Master_SSL_Crlpath: \n           Retrieved_Gtid_Set: \n            Executed_Gtid_Set: \n                Auto_Position: 0\n         Replicate_Rewrite_DB: \n                 Channel_Name: \n           Master_TLS_Version: \n1 row in set (0.00 sec)\n```\n\n\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"【JUC】i++ 源码详解","url":"/2021/10/21/【JUC】i加加操作详解/","content":"\n## 字节码自增指令\n\n自增操作对应的JVM字节码为 `iinc`。下面逐个分析 `i++` 操作和 `++i `操作的字节码指令。\n\n### `i++`\n\n``` java\npublic static void main(String[] args) {\n    int i = 0;\n    int a = i++;\n}\n```\n\n上述代码的字节码解析：\n\n- `iconst_0`：将数字 0 入操作数栈\n- `istore_1`：弹出操作数栈顶元素 0 并存储到局部变量表索引位置为1的变量（此时操作数栈为空）\n- `iload_1`：从局部变量表中加载索引位置1的元素（0）到操作数栈（目的是备份一下i  自增前的值，待自增结束后再赋值给 a）\n- `iinc 1 by 1`：首先读取局部变量表中 i 的值，再进行加一操作，最后存储加一后的值1到索引位置 1，重新赋给了 i（该指令没有原子性）\n- `istore_2`：将操作数栈顶的元素 0（第三步存储的）赋值给局部变量表中的 a\n\n所以最终结果就是，a 的值等于 0。而到这这一结果的根本原因是因为：在给 a 赋值前先从局部变量表中 `load `了 i 加一前的值，并在最后将该值又赋给了 a，所以造成了 `i++` 后 a 的值等于 i 加一前的值。\n\n![image-20211021142230633](/images/%E3%80%90JUC%E3%80%91i%E5%8A%A0%E5%8A%A0%E6%93%8D%E4%BD%9C%E8%AF%A6%E8%A7%A3/image-20211021142230633.png)\n\n注意：`iinc 1 by 1`这条指令虽然在JVM层面只是一条命令，但是其在最底层的CPU层面却是包含了三个步骤：\n\n1. 读取：从局部变量表中读取 i 的值\n2. 累加：将该值进行加一\n3. 保存：将加一后的值保存回局部变量表中\n\n其中的一条指令可以保证是原子操作，但是3条指令合在一起却不是，这就导致了`i++`语句不是原子操作。\n\n如果在读取操作进行后，当前线程失去了执行权，那么在该线程再一次获取到执行权后，就不会再做一次读取操作，而是直接使用线程切换前读取到的值进行加一，这就导致了高并发下 `i++` 操作的结果异常\n\n### `i--`\n\n``` java\npublic static void main(String[] args) {\n    int i = 0;\n    int a = ++i;\n}\n```\n\n![image-20211021163147335](/images/%E3%80%90JUC%E3%80%91i%E5%8A%A0%E5%8A%A0%E6%93%8D%E4%BD%9C%E8%AF%A6%E8%A7%A3/image-20211021163147335.png)\n\n对比 `++i` 和 `i++`，可以看到二者的区别是：\n\n- `++i` 是先执行 `iinc 1 by 1`，将 i 的值增加，然后再 `iload_1` 读取了加一后的 i 值，将该值赋给 a\n- `i++` 则是在 `iinc 1 by 1` 执行前就先把 i 原本的值**备份**了一份，然后 i 自增后，再将之前备份的值赋给 a\n\n\n\n>  补充：只有局部变量才使用 iinc 指令，如果是调用的成员变量属性++，则不会使用 iinc 指令，其指令更加复杂。先从局部变量表里 load 该值，然后再加一，最后存回局部变量表里去。\n\n\n\n## 多线程场景下 i++ 的问题\n\n情景：两个线程同时对 `static int i = 0` 进行各自连续100次的 `i++` 操作，理想情况下结果为 200，但最极端的情况下，结果为 2。该过程图解：\n\n![幻灯片1](/images/%E3%80%90JUC%E3%80%91i%E5%8A%A0%E5%8A%A0%E6%93%8D%E4%BD%9C%E8%AF%A6%E8%A7%A3/%E5%B9%BB%E7%81%AF%E7%89%871.PNG)","tags":["JUC","源码分析"],"categories":["JUC","源码分析"]},{"title":"【JVM】JVM 调优实战案例","url":"/2021/10/19/【JVM】JVM调优实战案例/","content":"\n本文首先介绍内存泄漏的常见案例并详细分析四种OOM案例下的排查方案，然后介绍一些JVM的调优实战案例，并演示JVM常见监控与诊断工具的使用。\n\n## Java 内存泄露的 8 种情况\n\n严格来说，**只有对象不会再被程序用到了，但是GC又不能回收他们的情况，才叫内存泄漏**。但实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致OOM，也可以叫做宽泛意义上的“内存泄漏”。\n\n可达性分析算法来判断对象是否是不再使用的对象，本质都是判断一个对象是否还被引用。那么对于这种情况下，由于代码的实现不同就会出现很多种内存泄漏问题（让JVM误以为此对象还在引用中，无法回收，造成内存泄漏）。\n\n![image-20200712195158470](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20200712195158470.png)\n\n如下图，当Y生命周期结束的时候，X依然引用着Y，这时候，垃圾回收器是不会回收对象Y的；如果对象X还引用着生命周期比较短的A、B、C，这样就可能造成大量无用的对象不能被回收，进而占据了内存资源，造成内存泄漏，直到内存溢出。\n\n![image-20211019200416595](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211019200416595.png)\n\n申请了内存用完了不释放，比如一共有1024M的内存，分配了512M的内存一直不回收，那么可以用的内存只有512M了，仿佛泄露掉了一部分。\n\n<!-- More -->\n\n### 内存泄漏的常见情况\n\n- 代码中有死循环\n- 使用了静态集合类，在其内添加了过多的对象，一直无法被回收\n- 使用了过多的单例对象，其内引用了其他外部对象，导致这些对象一直无法被回收\n- 各种连接忘记关闭\n- 变量作用域不合理\n- 缓存泄漏：缓存数据过多，无法及时清理\n\n解决方案：\n\n- 尽量减少静态集合类的使用，或者在不使用集合内的对象后，及时设置为 null 进行清理\n- 减少单例对象使用，尽量不引用外部对象\n- 及时关闭连接\n- 尽量使用局部变量，减少使用没必要的类成员变量\n- 缓存数据使用 `WeakHashMap`，在其内对象失去其他引用后就自动清理\n\n### 静态集合类\n\n静态集合类，如`HashMap`、`LinkedList`等等。如果这些容器为**静态**的，那么它们的生命周期与JVM程序一致，则容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。简单而言，长生命周期的对象持有短生命周期对象的引用，尽管短生命周期的对象不再使用，但是因为长生命周期对象持有它的引用而导致不能被回收。\n\n典型例子：在静态数组中不断添加对象，由于静态对象不会随着实例对象的回收而回收，因此其添加的对象就会造成内存泄漏：\n\n```java\npublic class MemoryLeak {\n    static List list = new ArrayList();\n    \n    /**\n     * 尽管这个局部变量Object生命周期非常短\n     * 但是它被生命周期非常长的静态列表引用\n     * 所以不会被GC回收 发生内存溢出\n     */\n    public void oomTests(){\n        Object obj = new Object(); //局部变量\n        list.add(obj);\n    }\n}\n```\n\n类卸载的条件非常苛刻,这个静态列表生命周期基本与JVM一样长\n\n### 单例模式\n\n单例模式，和静态集合导致内存泄露的原因类似，因为单例的静态特性，它的生命周期和 JVM 的生命周期一样长，所以如果单例对象如果持有外部对象的引用，那么这个外部对象也不会被回收，那么就会造成内存泄漏。\n\n**饿汉式单例模式**\n\n```java\npublic class Singleton {\n    private static final Singleton INSTANCE = new Singleton();\n\n    private Singleton(){\n        if (INSTANCE!=null){\n            throw new RuntimeException(\"not create instance\");\n        }\n    }\n\n    public static Singleton getInstance(){\n        return INSTANCE;\n    }\n}\n```\n\n饿汉式的单例模式也是被静态变量引用，即使不需要使用这个单例对象了，GC也不会回收\n\n### 非静态内部类持有外部类\n\n内部类持有外部类，如果一个外部类的实例对象的方法返回了一个内部类的实例对象。这个内部类对象被长期引用了，即使那个外部类实例对象不再被使用，但由于内部类持有外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄漏。\n\n```java\npublic class InnerClassTest {\n    class InnerClass {\n    }\n\n    public InnerClass getInnerInstance() {\n        return this.new InnerClass();\n    }\n\n    public static void main(String[] args) {\n        InnerClass innerInstance = null;\n\n        {\n            InnerClassTest innerClassTest = new InnerClassTest();\n            innerInstance = innerClassTest.getInnerInstance();\n            \n            System.out.println(\"========= 外部实例对象内存布局 =========\");\n            System.out.println(ClassLayout.parseInstance(innerClassTest).toPrintable());\n            System.out.println(\"========= 内部实例对象内存布局 =========\");\n            System.out.println(ClassLayout.parseInstance(innerInstance).toPrintable());\n        }\n\n        // ...\n    }\n}\n```\n\n当调用外部类实例方法通过外部实例对象返回一个内部实例对象时（调用代码中的`getInnerInstance()`方法），外部实例对象不需要使用了，但内部实例对象被长期使用，会导致这个外部实例对象生命周期变长。\n\n**因为内部实例对象隐藏了一个指针指向（引用）创建它的外部实例对象**\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20210520194055109.png)\n\n### 各种连接，如数据库连接、网络连接和 IO 连接等\n\n在对数据库进行操作的过程中，首先需要建立与数据库的连接，当不再使用时，需要调用`close()`方法来释放与数据库的连接。只有连接被关闭后，垃圾回收器才会回收对应的对象。否则，如果在访问数据库的过程中，对`Connection`、`Statement`或`ResultSet`不显性地关闭，将会造成大量的对象无法被回收，从而引起内存泄漏。\n\n```java\npublic static void main(String[] args) {\n    try {\n        Connection conn =null;\n        Class.forName(\"com.mysql.jdbc.Driver\");\n        conn =DriverManager.getConnection(\"url\",\"\",\"\");\n        Statement stmt =conn.createStatement();\n        ResultSet rs =stmt.executeQuery(\"....\");\n    } catch（Exception e）{\n        // 异常日志\n    } finally {\n        // 1．关闭结果集 Statement\n        // 2．关闭声明的对象 ResultSet\n        // 3．关闭连接 Connection\n    }\n}\n```\n\n### 变量不合理的作用域\n\n一般而言，一个变量的定义的作用范围大于其使用范围，很有可能会造成内存泄漏。另一方面，如果没有及时地把对象设置为null，很有可能导致内存泄漏的发生。\n\n``` java\npublic class UsingRandom {\n    private String msg;\n    public void receiveMsg(){\n        readFromNet();  // 从网络中接受数据保存到msg中\n        saveDB();       // 把msg保存到数据库中\n        \n        // 应该在使用完后手动 msg = null;\n    }\n}\n```\n\n如上面这个伪代码，通过`readFromNet()`方法把接受的消息保存在变量msg中，然后调用`saveDB()`方法把msg的内容保存到数据库中，此时msg已经就没用了，由于msg的生命周期与对象的生命周期相同，此时msg还不能回收，因此造成了内存泄漏。实际上这个msg变量可以放在`receiveMsg()`方法内部，当方法使用完，那么msg的生命周期也就结束，此时就可以回收了。还有一种方法，在使用完msg后，**把msg设置为nul**l，这样垃圾回收器也会回收msg的内存空间。\n\n### 改变哈希值\n\n改变哈希值，当一个对象被存储进`HashSet`集合中以后，就不能修改这个对象中的那些参与计算哈希值的字段了。否则，对象修改后的哈希值与最初存储进`HashSet`集合中时的哈希值就不同了，在这种情况下，即使在`contains()`方法使用该对象的当前引用作为的参数去`HashSet`集合中检索对象，也将返回找不到对象的结果，这也会导致无法从`HashSet`集合中单独删除当前对象，造成内存泄漏。\n\n这也是 String 为什么被设置成了不可变类型，我们可以放心地把 String 存入 `HashSet`，或者把String 当做 `HashMap` 的 key 值；\n\n当我们想把自己定义的类保存到散列表的时候，需要保证对象的 `hashCode` 不可变。\n\n``` java\npublic class ChangeHashCode {\n    public static void main(String[] args) {\n        HashSet set = new HashSet();\n        Person p1 = new Person(1001, \"AA\");\n        Person p2 = new Person(1002, \"BB\");\n\n        set.add(p1);\n        set.add(p2);\n\n        p1.name = \"CC\"; // 导致了内存的泄漏\n        set.remove(p1); // 删除失败\n\n        System.out.println(set);\n\n        set.add(new Person(1001, \"CC\"));\n        System.out.println(set);\n\n        set.add(new Person(1001, \"AA\"));\n        System.out.println(set);\n\n    }\n}\n\nclass Person {\n    int id;\n    String name;\n\n    public Person(int id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n\n    @Override\n    public boolean equals(Object o) {\n        if (this == o) return true;\n        if (!(o instanceof Person)) return false;\n\n        Person person = (Person) o;\n\n        if (id != person.id) return false;\n        return name != null ? name.equals(person.name) : person.name == null;\n    }\n\n    @Override\n    public int hashCode() {\n        int result = id;\n        result = 31 * result + (name != null ? name.hashCode() : 0);\n        return result;\n    }\n\n    @Override\n    public String toString() {\n        return \"Person{\" +\n            \"id=\" + id +\n            \", name='\" + name + '\\'' +\n            '}';\n    }\n}\n```\n\n所以说对象当作Key存入散列表时，该对象最好是逻辑不可变对象，不能在外界改变它的关键域，从而无法改变哈希值：\n\n![image-20210520211835353](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20210520211835353.png)\n\n将关键域设置为final，只能在实例代码块中初始化或构造器中。如果关键域是引用类型,可以用final修饰后，对外不提供改变该引用关键域的方法，从而让外界无法修改引用关键域中的值 (如同String类型，所以String常常用来当作散列表的Key)\n\n\n\n### 缓存泄露\n\n内存泄漏的另一个常见来源是缓存，一旦你把对象引用放入到缓存中，他就很容易遗忘。比如：之前项目在一次上线的时候，应用启动奇慢直到夯死，就是因为代码中会加载一个表中的数据到缓存（内存）中，测试环境只有几百条数据，但是生产环境有几百万的数据。\n\n对于这个问题，可以使用`WeakHashMap`代表缓存（其内的 `Entry `是弱引用），此种Map的特点是，当除了自身有对key的引用外，此key没有其他引用那么此map会自动丢弃此值。\n\n> `WeakHashMap` 内部的`Entry`是弱引用，当它的Key不再使用时，下次垃圾回收就会回收掉，不会发生内存泄漏\n\n``` java\npublic class MapTest {\n    static Map wMap = new WeakHashMap();\n    static Map map = new HashMap();\n\n    public static void main(String[] args) {\n        init();\n        testWeakHashMap();\n        testHashMap();\n    }\n\n    public static void init() {\n        String ref1 = new String(\"obejct1\");\n        String ref2 = new String(\"obejct2\");\n        String ref3 = new String(\"obejct3\");\n        String ref4 = new String(\"obejct4\");\n        wMap.put(ref1, \"cacheObject1\");\n        wMap.put(ref2, \"cacheObject2\");\n        map.put(ref3, \"cacheObject3\");\n        map.put(ref4, \"cacheObject4\");\n        System.out.println(\"String引用ref1，ref2，ref3，ref4 消失\");\n    }\n\n    public static void testWeakHashMap() {\n        System.out.println(\"WeakHashMap GC之前\");\n        for (Object o : wMap.entrySet()) {\n            System.out.println(o);\n        }\n        try {\n            System.gc();\n            TimeUnit.SECONDS.sleep(5);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"WeakHashMap GC之后\");\n        for (Object o : wMap.entrySet()) {\n            System.out.println(o);\n        }\n    }\n\n    public static void testHashMap() {\n        System.out.println(\"HashMap GC之前\");\n        for (Object o : map.entrySet()) {\n            System.out.println(o);\n        }\n        try {\n            System.gc();\n            TimeUnit.SECONDS.sleep(5);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"HashMap GC之后\");\n        for (Object o : map.entrySet()) {\n            System.out.println(o);\n        }\n    }\n}\n```\n\n上面代码和图示主演演示`WeakHashMap`如何自动释放缓存对象，当`init()`函数执行完成后，局部变量字符串引用weakd1，weakd2，d1，d2都会消失，此时只有静态map中保存着对字符串对象的引用，可以看到，调用gc之后，`HashMap`的没有被回收，而`WeakHashMap`里面的缓存被回收了。\n\n\n\n### 监听器和其他回调\n\n如果客户端在你实现的API中注册回调，却没有显示的取消，那么就会积聚。\n\n需要确保回调立即被当作垃圾回收的最佳方法是只保存它的弱引用，例如将他们保存成为`WeakHashMap`中的键。\n\n\n\n### 内存泄露案例分析\n\n``` java\npublic class Stack {\n    private Object[] elements;\n    private int size = 0;\n    private static final int DEFAULT_INITIAL_CAPACITY = 16;\n\n    public Stack() {\n        elements = new Object[DEFAULT_INITIAL_CAPACITY];\n    }\n\n    public void push(Object e) { // 入栈\n        ensureCapacity();\n        elements[size++] = e;\n    }\n\n    public Object pop() { // 出栈\n        if (size == 0)\n            throw new EmptyStackException();\n        return elements[--size];\n    }\n\n    private void ensureCapacity() {\n        if (elements.length == size)\n            elements = Arrays.copyOf(elements, 2 * size + 1);\n    }\n}\n```\n\n上述程序并没有明显的错误，但是这段程序有一个内存泄漏，随着GC活动的增加，或者内存占用的不断增加，程序性能的降低就会表现出来，严重时可导致内存泄漏，但是这种失败情况相对较少。\n\n代码的主要问题在`pop()`函数，下面通过这张图示展现。假设这个栈一直增长，增长后如下图所示：\n\n![image-20211019202508227](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211019202508227.png)\n\n当进行大量的`pop()`操作时，由于引用未进行置空，gc是不会释放的，如下图所示：\n\n![image-20211019202528238](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211019202528238.png)\n\n从上图中看以看出，如果栈先增长，再收缩，那么从栈中弹出的对象将不会被当作垃圾回收，即使程序不再使用栈中的这些队象，他们也不会回收，因为栈中仍然保存这对象的引用，俗称过期引用，这个内存泄露很隐蔽。\n\n将代码中的`pop()`方法变成如下方法：\n\n``` java\npublic Object pop() {\n    if (size == 0)\n        throw new EmptyStackException();\n    Object result = elements[--size];\n    elements[size] = null;\n    return result;\n}\n```\n\n一旦引用过期，清空这些引用，将引用置空。\n\n![image-20211019202604985](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211019202604985.png)\n\n动态数组`ArrayList`中`remove()`操作会改变size的同时将删除位置置空，从而不再引用元素,避免内存泄漏：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20210520214827223.png)\n\n## OOM 出现的原因\n\n主要分为四类：\n\n- 堆溢出：`java.lang.OutOfMemoryError: Java heap space`，原因为对象数量过多（最常见）\n- 元空间溢出： `java.lang.OutOfMemoryError: Metaspace`，原因为基于**反射**原理动态加载过多的类\n- 超出 GC 开销限制：`java.lang.OutOfMemoryError: GC overhead limit exceeded`，原因为**超过98%的时间用来做GC并且回收了不到2%的堆内存时会抛出此异常**。本质是一个**预判性**的异常，抛出该异常时系统没有真正的内存溢出，而是**预判到马上就要溢出了**。\n- 线程栈溢出：`java.lang.OutOfMemoryError : unable to create new native Thread`，原因为线程数量超出限制或超出操作系统上限\n\n> 如果某一个线程栈所占用的内存空间大于了其设置值，报的是 `StackOverflowError`\n\n\n\n## OOM 案例一：堆溢出\n\n### 案例模拟\n\n```java\n@RestController\npublic class MemoryTestController {\n    @Autowired\n    private UserService userSevice;\n\n    /**\n     * 案例1：模拟线上环境OOM\n     */\n    @RequestMapping(\"/add\")\n    public void addObject(){\n        System.err.println(\"add\" + userSevice);\n        ArrayList<User> people = new ArrayList<>();\n        while (true){\n            people.add(new User());\n        }\n    }\n}\n```\n\nJVM 参数：\n\n```\n-XX:+PrintGCDetails -XX:MetaspaceSize=64m -XX:+HeapDumpOnOutOfMemoryError \n-XX:HeapDumpPath=heap/heapdump.hprof -XX:+PrintGCDateStamps\n-Xms50M  -Xmx50M  -Xloggc:log/gc-oomHeap.log  \n```\n\n运行结果：\n\n```\njava.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) ~[na:1.8.0_131] at java.util.Arrays.copyOf(Arrays.java:3181) ~[na:1.8.0_131] at java.util.ArrayList.grow(ArrayList.java:261) ~[na:1.8.0_131] at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235) ~[na:1.8.0_131] at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227) ~[na:1.8.0_131] 运行程序得到 heapdump.hprof 文件。\n```\n\n报错信息：`java.lang.OutOfMemoryError: Java heap space`\n\n### 原因及解决方案\n\n原因：\n\n- 代码中可能存在大对象分配\n- 可能存在内存泄漏，导致在多次GC之后，还是无法找到一块足够大的内存容纳当前对象。 \n\n解决方法：\n\n- 检查是否存在大对象的分配，最有可能的是大数组分配  \n- 通过`jmap`命令，把堆内存dump下来，使用MAT等工具分析一下，检查是否存在内存泄漏的问题\n- 如果没有找到明显的内存泄漏，使用 `-Xmx` 加大堆内存 \n- 还有一点容易被忽略，检查是否有大量的自定义的 `Finalizable` 对象（这些自定义对象很可能会“复活”），也有可能是框架内部提供的，考虑其存在的必要性\n\n### JVisual VM 排查\n\n通过jvisualvm工具查看，**占用最多实例的类是哪个**，这样就可以定位到我们的问题所在。\n\n排查流程：\n\n![image-20211021202816470](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021202816470.png)\n\n![image-20211021202917101](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021202917101.png)\n\n![image-20211021203044271](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021203044271.png)\n\n分析对象情况，发现有大量的 User 对象：\n\n![image-20211021203309218](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021203309218.png)\n\n### MAT 排查\n\n 使用MAT工具查看，能找到对应的线程及相应线程中对应实例的位置和代码：  \n\n![image-20211021203949345](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021203949345.png)\n\n![image-20211021204650402](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021204650402.png)\n\n![image-20211021204534884](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021204534884.png)\n\n![image-20211021205142061](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021205142061.png)\n\n### GCeasy 查看\n\n![image-20211022190629659](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022190629659.png)\n\n可以看到每次 Full GC 后，堆空间大小都基本不变，并且也接近上限，说明有大量的内存泄漏。\n\n\n\n## OOM 案例二：元空间溢出\n\n### 案例模拟\n\n```java\n/**\n * 案例2:模拟元空间OOM溢出\n */\n@RequestMapping(\"/metaSpaceOom\")\npublic void metaSpaceOom(){\n    ClassLoadingMXBean classLoadingMXBean = ManagementFactory.getClassLoadingMXBean();\n    while (true){\n        Enhancer enhancer = new Enhancer();\n        enhancer.setSuperclass(User.class);\n        //            enhancer.setUseCache(false);\n        enhancer.setUseCache(false);\n        enhancer.setCallback((MethodInterceptor) (o, method, objects, methodProxy) -> {\n            System.out.println(\"我是加强类，输出print之前的加强方法\");\n            return methodProxy.invokeSuper(o,objects);\n        });\n        User user = (User)enhancer.create();\n        user.print();\n        System.out.println(user.getClass());\n        System.out.println(\"totalClass:\" + classLoadingMXBean.getTotalLoadedClassCount());\n        System.out.println(\"activeClass:\" + classLoadingMXBean.getLoadedClassCount());\n        System.out.println(\"unloadedClass:\" + classLoadingMXBean.getUnloadedClassCount());\n    }\n}\n```\n\nJVM 参数：\n\n```\n-Xms60M  -Xmx60M -XX:MetaspaceSize=60m -XX:MaxMetaspaceSize=60m -Xss512K\n-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapdumpMeta.hprof \n-XX:SurvivorRatio=8 -XX:+TraceClassLoading -XX:+TraceClassUnloading \n-XX:+PrintGCDetails -XX:+PrintGCDateStamps -Xloggc:log/gc-oomMeta.log\n```\n\n报错信息：`java.lang.OutOfMemoryError: Metaspace`\n\n### 原因及解决方案\n\nJDK 8 后，元空间替换了永久代，元空间使用的是本地内存，原因：\n\n- 运行期间生成了大量的代理类，导致方法区被撑爆，无法卸载\n- 应用长时间运行，没有重启\n- 元空间内存设置过小 \n\n解决方法：\n\n- 检查是否永久代空间或者元空间设置的过小\n- 检查代码中是否存在大量的**反射**操作\n- dump之后通过MAT检查是否存在**大量由于反射生成的代理类**\n\n本案例的具体解决方案：\n\n```java\nenhancer.setUseCache(false); // 开启缓存\n```\n\n\n\n### 命令行查看 GC 情况\n\n可以使用 jstat 命令查看堆空间和元空间的内存情况：\n\n```\njstat -gc pid 1000 10\n```\n\n> 每隔 1000 ms 打印一次 GC 情况，共打印 10 次\n\n打印结果：\n\n![image-20211021213540629](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021213540629.png)\n\n可以看到元空间几乎被占满了，并且出现了大量的 Full GC 。那么我们接下来分析到底是什么数据占用了大量的方法区。\n\n### JVisual VM 排查\n\n通过jvisualvm工具查看元空间的内存情况，请求访问前：\n\n![image-20211021213006851](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021213006851.png)\n\n访问该请求后，动态加载大量类，可以看到元空间占用明显增加，直至造成OOM：\n\n![image-20211021213232807](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021213232807.png)\n\n接着查看方法栈情况，找到自己包下的方法栈：\n\n![image-20211021214225726](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211021214225726.png)\n\n根据方法栈信息，找到代码中的相应位置，是因为创建了大量的类：\n\n```java\nUser user = (User)enhancer.create();\n```\n\n### MAT 排查\n\n首先我们先确定是哪里的代码发生了问题，首先可以通过线程来确定，因为在实际生产环境中，有时候是无法确定是哪块代码引起的OOM，那么我们就需要先定位问题线程，然后定位代码，如下图所示：\n\n![image-20211022115128142](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022115128142.png)\n\n从上图可以看到出现异常的方法栈位置在自己代码的第50行。\n\n定位到代码以后，发现有使用到**cglib动态代理**，那么我们猜想一下问题是不是由于产生了很多代理类，接下来，我们可以通过包看一下我们的类加载情况：\n\n![image-20211022094909679](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022094909679.png)\n\n这里发现Method类的实例非常多，查看with outgoing references发现了很多的User类在调用相关的方法。由于我们的代码是代理的User类，所以我们直接打开User类所在的包，打开如下图所示：可以看到确实加载了很多的代理类（`User$$EnhancerByCGLIB`）：\n\n![image-20211022095110080](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022095110080.png)\n\n![image-20211022095526532](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022095526532.png)\n\n最终找到了原因：动态加载了大量的类导致元空间OOM\n\n## OOM 案例三：GC overhead limit exceeded\n\n### 案例模拟\n\n```java\n/**\n * 案例3：测试 GC overhead limit exceeded\n */\npublic class OOMTest {\n    public static void main(String[] args) {\n        test1();\n        //test2();\n    }\n\n    public static void test1() {\n        int i = 0;\n        List<String> list = new ArrayList<>();\n        try {\n            while (true) {\n                list.add(UUID.randomUUID().toString().intern());\n                i++;\n            }\n        } catch (Throwable e) {\n            System.out.println(\"************i: \" + i);\n            e.printStackTrace();\n            throw e;\n        }\n    }\n\n    public static void test2() {\n        String str = \"\";\n        Integer i = 1;\n        try {\n            while (true) {\n                i++;\n                str += UUID.randomUUID();\n            }\n        } catch (Throwable e) {\n            System.out.println(\"************i: \" + i);\n            e.printStackTrace();\n            throw e;\n        }\n    }\n}\n```\n\nJVM 配置：\n\n```\n-XX:+PrintGCDetails  -XX:+HeapDumpOnOutOfMemoryError \n-XX:HeapDumpPath=heap/dumpExceeded.hprof \n-XX:+PrintGCDateStamps  -Xms10M  -Xmx10M \n-Xloggc:log/gc-oomExceeded.log\n```\n\n报错信息：`java.lang.OutOfMemoryError: GC overhead limit exceeded`\n\nGC 日志：\n\n``` \n[Full GC (Ergonomics) [PSYoungGen: 2047K->2047K(2560K)] [ParOldGen: 7110K->7095K(7168K)] 9158K->9143K(9728K), \n[Metaspace: 3177K->3177K(1056768K)], 0.0479640 secs] [Times: user=0.23 sys=0.01, real=0.05 secs] \njava.lang.OutOfMemoryError: GC overhead limit exceeded\n[Full GC (Ergonomics) [PSYoungGen: 2047K->2047K(2560K)] [ParOldGen: 7114K->7096K(7168K)] 9162K->9144K(9728K), \n[Metaspace: 3198K->3198K(1056768K)], 0.0408506 secs] [Times: user=0.22 sys=0.01, real=0.04 secs]  \n```\n\n通过查看GC日志可以发现，系统在频繁性的做Full GC，但是却没有回收掉多少空间，那么引起的原因可能是因为内存不足，也可能是存在内存泄漏的情况，接下来我们要根据堆dump文件来具体分析。\n\n### 原因与解决方案\n\n原因分析：这个是 JDK 6 新加的错误类型，一般都是**堆太小**导致的。Sun 官方对此的定义：**超过98%的时间用来做GC并且回收了不到2%的堆内存时会抛出此异常**。本质是一个**预判性**的异常，抛出该异常时系统没有真正的内存溢出，而是**预判到马上就要溢出了**。\n\n**第一段代码**：运行期间将内容放入常量池的典型案例 。`intern()` 方法：\n\n- 如果字符串常量池里面已经包含了等于字符串X的字符串，那么就返回常量池中这个字符串的引用；\n- 如果常量池中不存在，那么就会把当前字符串添加到常量池并返回这个字符串的引用\n\n**第二段代码**：不停的追加字符串 str 你可能会疑惑，看似 demo 也没有差太多，为什么第二个没有报 `GC overhead limit exceeded` 呢？以上两个demo的区别在于：\n\n- `Java heap space` 的 demo 每次都能回收大部分的对象（中间产生的UUID），只不过有一个对象是无法回收的，慢慢长大（字符串长度越来越大），直到内存溢出\n- `GC overhead limit exceeded` 的 demo 由于每个字符串都在被list引用，所以无法回收，很快就用完内存，触发不断回收的机制。\n\n解决方案：\n\n根据业务来修改是否需要死循环。\n\n- 检查项目中是否有大量的死循环或有使用大内存的代码，优化代码。\n- 添加参数 `-XX:-UseGCOverheadLimit` 禁用这个检查，其实这个参数解决不了内存问题，只是把错误的信息延后，最终出现 `java.lang.OutOfMemoryError: Java heap space`。\n- dump内存，检查是否存在内存泄漏，如果没有，**加大内存**。   \n\n\n\n### JVisual VM 排查\n\n定位到了具体的线程中具体出现问题的代码的位置，进而进行优化即可\n\n![image-20211022104627351](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022104627351.png)\n\n### MAT 排查\n\n![image-20211022104727014](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022104727014.png)\n\n![image-20211022104828175](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022104828175.png)\n\n上图中找到我们自己线程出现异常的方法栈位置，在26行，在代码中看到是因为进行了死循环，不停的往 `ArrayList `存放字符串常量（JDK1.8以后，字符串常量池移到了堆中存储，所以最终导致内存不足发生了OOM）\n\n同时从上图中可以看到我们自己线程下的局部变量 `java.util.ArrayList` 的深堆对象占用大量内存，分析其 outgoing reference，发现其内存储了大量的 String 对象：\n\n![image-20211022104950763](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022104950763.png)\n\n接着分析dump文件直方图，打开Histogram，可以看到，String类型的字符串占用了大概8M的空间，几乎把堆占满，但是还没有占满，所以这也符合Sun官方对此的定义：超过98%的时间用来做GC并且回收了不到2%的堆内存时会抛出此异常，本质是一个预判性的异常，抛出该异常时系统没有真正的内存溢出。    \n\n![image-20211022105050210](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211022105050210.png)\n\n\n\n## OOM 案例四：线程栈溢出\n\n### 案例模拟\n\n> 不添加 -Xss 参数\n\n在主程序中，不断创建新的线程，直到报异常：`java.lang.OutOfMemoryError : unable to create new native Thread`。同时操作系统失去响应，需要重新启动。\n\n出现这种异常，基本上都是**创建了大量的线程**导致的，超出了系统的资源上限。\n\n```\ni = 15241 \nException in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread \nat java.lang.Thread.start0(Native Method)\nat java.lang.Thread.start(Thread.java:717)\nat TestNativeOutOfMemoryError.main(TestNativeOutOfMemoryError.java:9)\n```\n\n> 添加 -Xss 参数，设置**每个**线程栈的大小\n\n在 Linux 下运行 Java 程序，并添加 JVM 参数设置线程栈大小：\n\n``` \njava -Xss512k TestNativeOutOfMemory\n```\n\n发现同样在 15241 左右次迭代时出现 OOM，似乎这个参数不起作用？\n\n### 原因\n\n通过 `-Xss` 可以设置**每个**线程栈大小的容量。\n\n- JDK 5.0 以后每个线程堆栈大小为1M，\n- JDK 5.0 以前每个线程堆栈大小为256K。\n\n> 如果一个线程栈的大小超出 -Xss 设置的值，就会报 SOF：Stack Over Flow\n\n正常情况下，在相同物理内存下，减小这个值能生成更多的线程。但是**操作系统**对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 能创建的线程数的具体计算公式如下：\n\n```\n(MaxProcessMemory - JVMMemory - ReservedOsMemory) / (ThreadStackSize) = Number of threads\n```\n\n- `MaxProcessMemory `：进程可寻址的最大空间\n- `JVMMemory`：JVM内存\n- `ReservedOsMemory `：保留的操作系统内存\n- `ThreadStackSize`：线程栈的大小\n\n在Java语言里， 当你创建一个线程的时候，虚拟机会在JVM内存创建一个Thread对象同时创建一个操作系统线程，而这个系统线程的内存用的不是JVMMemory，而是系统中剩下的内存`(MaxProcessMemory - JVMMemory - ReservedOsMemory)`。\n\n由公式得出结论：**你给JVM内存越多，那么你能创建的线程越少**，越容易发生`java.lang.OutOfMemoryError: unable to create new native thread`。 综上，在生产环境下如果需要更多的线程数量，建议使用64位操作系统，如果必须使用32位操作系统，可以通过调整`-Xss`的大小来控制线程数量。\n\n而之所以出现上面设不设置参数，结果都一样的原因是：64 位操作系统的`MaxProcessMemory`值非常非常大，可以理解为正无穷，所以就算分母除以的参数是默认的1M还是512K，算出来的线程数都特别特别多大，早就已经超出了操作系统的上限\n\n因为受到系统上限的影响，设不设置，可以出关键的线程数都达到了上限 15000+。因此两个案例启示都是在超出操作系统资源上限时OOM的，并没有达到这个公式里的理论值。\n\n### 补充\n\n线程总数也受到系统空闲内存和操作系统的限制，检查是否该系统下有此限制：\n\n- /proc/sys/kernel/pid_max：系统最大pid值，在大型系统里可适当调大\n-  /proc/sys/kernel/threads-max：系统允许的最大线程数 \n- maxuserprocess（ulimit -u）：系统限制某用户下最多可以运行多少进程或线程 \n- /proc/sys/vm/max_map_count：max_map_count文件包含限制一个进程可以拥有的VMA（虚拟内存区域）的数量。虚拟内存区域是一个连续的虚拟地址空间区域。\n\n在进程的生命周期中，每当程序尝试在内存中映射文件，链接到共享内存段，或者分配堆空间的时候，这些区域将被创建。调优这个值将限制进程可拥有VMA的数量。限制一个进程拥有VMA的总数可能导致应用程序出错，因为当进程达到了VMA上线但又只能释放少量的内存给其他的内核进程使用时，操作系统会抛出内存不足的错误。如果你的操作系统在NORMAL区域仅占用少量的内存，那么调低这个值可以帮助释放内存给内核用。  \n\n\n\n## JVM 调优概述\n\n### 为什么要调优？\n\n- 防止出现 OOM，进行 JVM 规划和**预**调优（例如在上线前先压测）\n- 解决程序**运行中**各种 OOM（运行时及时排查出OOM原因）\n- 减少 Full GC 出现的频率，解决运行慢、卡顿问题\n\n总结：预防 OOM，减少 Full GC。\n\n### 调优的大方向\n\n- 合理地编写代码\n- 充分并合理的使用硬件资源\n- 合理地进行JVM调优\n\n### 调优监控的依据\n\n- 运行日志\n- 异常堆栈\n- GC日志\n- 线程快照\n- 堆转储快照\n\n### 性能优化的步骤\n\n- 第1步：熟悉业务场景\n- 第2步（发现问题）：性能监控\n  - GC 频繁\n  - CPUload过高\n  - OOM\n  - 内存泄漏（可能导致OOM）\n  - 死锁（可能导致CPU负载过高）\n  - 程序响应时间较长（说明频繁GC）\n- 第3步（排查问题）：性能分析\n  - 打印GC日志，通过GCviewer或者 http://gceasy.io来分析日志信息\n  - 灵活运用命令行工具，jstack，jmap，jinfo等\n  - dump出堆文件，使用内存分析工具MAT分析文件\n  - 使用阿里Arthas，或jconsole，JVisualVM来实时查看JVM状态\n  - jstack查看堆栈信息\n- 第4步（解决问题）：性能调优\n  - 适当**增加内存**，根据业务背景选择合适的垃圾回收器\n  - 优化代码，控制内存使用\n  - **增加机器**，分散节点压力\n  - 合理设置**线程池**线程数量\n  - 使用**中间件**提高程序效率，比如缓存，消息队列等\n\n### 性能评价/测试指标\n\n- **停顿时间**（或响应时间）\n- **吞吐量**\n- 并发数\n- 内存占用\n- 相互间的关系\n\n\n\n## 调优案例一：调整堆大小提升服务的吞吐量\n\n本案例演示在不同堆大小的配置下，对比服务的吞吐量与GC情况。\n\n首先需要配置 Linux 下 Tomcat 的堆内存大小。\n\n生产环境下，Tomcat并不建议直接在`catalina.sh`里配置变量，而是写在与catalina同级目录（bin目录）下的`setenv.sh`里。 所以如果我们想要修改jvm的内存配置，那么我们就需要修改`setenv.sh`文件（默认没有，需新建一个`setenv.sh`）。   \n\n### 初始配置：堆内存较小\n\n初始配置（堆内存设置较小）：\n\n``` \nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xms20m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:SurvivorRatio=8\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xmx20m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+UseParallelGC\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDetails\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:MetaspaceSize=64m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDateStamps\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc.log\" \n```\n\n---\n\n-Xms 和 -Xmx 两个参数设置相同的值，目的是为了能够在每次GC后不需要再重新计算堆区要分配的大小，从而提高性能。\n\n如果二者设置不相同，则每次GC后，会根据当前GC的效果动态调整堆区的大小：回收效果好 -> 减小堆区大小；回收效果差 -> 增大堆区大小\n\n---\n\n使用 JMeter 进行压测，发送50 * 1000个请求：观察吞吐量与GC情况。\n\n吞吐量：\n\n![image-20211023100312067](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023100312067.png)\n\n\n\n使用 `jstat -gc pid 1000 5` 查看压测前GC情况：\n\n![image-20211023134101136](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023134101136.png)\n\n压测后GC情况：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/%7BD6923547-8F8E-AF96-2ED5-5DC4197F0994%7D.png)\n\n可以看出，在压测后，出现了大量的 Full GC，这正是因为堆区内存过小导致的，严重拖慢了系统效率。并且从 GC 日志文件中也可以看到大量的 Full GC：\n\n```\n2021-10-23T09:58:50.445+0800: 129.233: [Full GC (Ergonomics) [PSYoungGen: 5632K->0K(6144K)] [ParOldGen: 12061K->12061K(13824K)] 17693K->12061K(19968K),[Metaspace: 20418K->20418K(1069056K)], 0.0134114 secs] [Times: user=0.03 sys=0.01, real=0.02 secs]\n2021-10-23T09:58:50.547+0800: 129.335: [Full GC (Ergonomics) [PSYoungGen: 5632K->0K(6144K)] [ParOldGen: 12061K->12062K(13824K)] 17693K->12062K(19968K), [Metaspace: 20418K->20418K(1069056K)], 0.0137774 secs] [Times: user=0.02 sys=0.00, real=0.02 secs]\n2021-10-23T09:58:50.648+0800: 129.436: [Full GC (Ergonomics) [PSYoungGen: 5632K->0K(6144K)] [ParOldGen: 12062K->12062K(13824K)] 17694K->12062K(19968K), [Metaspace: 20418K->20418K(1069056K)], 0.0149746 secs] [Times: user=0.02 sys=0.00, real=0.01 secs]\n```\n\n\n\n### 优化配置：堆内存增大\n\n现在增加堆内存空间大小：\n\n```\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xms120m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:SurvivorRatio=8\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xmx120m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+UseParallelGC\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDetails\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:MetaspaceSize=64m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDateStamps\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc.log\" \n```\n\n再进行 50 \\* 1000 次压测，观察吞吐量与GC情况与之前的区别。\n\n吞吐量：\n\n![image-20211023100620829](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023100620829.png)\n\n压测前后GC情况：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/%7BD004F3A8-BA30-BE0D-03E1-1FC18FE913CC%7D.jpg)\n\n这次可以看到，压测前后 Full GC 数量没有增加，只进行了少量了 Young GC，同时吞吐量也提升了，说明增大堆内存空间的确能够有效提高系统吞吐量。\n\n\n\n## 调优案例二：逃逸分析\n\n### 逃逸分析简介\n\n 如何将堆上的对象分配到栈，需要使用逃逸分析手段。逃逸分析（Escape Analysis）是目前Java虚拟机中比较前沿的优化技术。这是一种可以有效减少Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。\n\n 通过逃逸分析，Java Hotspot编译器能够分析出一个新的对象的引用的使用范围，从而决定是否要将这个对象分配到堆上。 逃逸分析的基本行为就是分析对象**动态作用域**：当一个对象在方法中被定义后，**对象只在方法内部使用，则认为没有发生逃逸**。当一个对象在方法中被定义后，**它被外部方法所引用，则认为发生逃逸**。没有发生逃逸的对象，则**可以分配到栈上**，随着方法执行的结束，栈空间就被移除。\n\nJIT 编译器在开启逃逸分析后即可实现以下功能：\n\n- 标量替换：用标量值代替聚合对象的属性值\n- 栈上分配：对于未逃逸的对象分配对象在栈而不是堆\n- 同步消除：清除同步操作，通常指消除没必要的`synchronized`\n\n注意：\n\n- 逃逸分析只有在 JIT 及时编译阶段才会对代码进行优化，在字节码文件里还是原样代码，并不会在前期编译就做优化。\n- Hotspot 并没有真正实现将对象存储在栈上，而是使用标量替换的形式将对象拆解成标量后存储在栈上，而不是直接将引用类型变量存储在栈上。**即 Hotspot 中的栈上分配是通过标量替换实现的**。\n\n### 逃逸分析示例\n\n```java\npublic class EscapeAnalysis {\n\n    public EscapeAnalysis obj;\n\n    /*\n    方法返回EscapeAnalysis对象，发生逃逸\n     */\n    public EscapeAnalysis getInstance(){\n        return obj == null? new EscapeAnalysis() : obj;\n    }\n    /*\n    为成员属性赋值，发生逃逸\n     */\n    public void setObj(){\n        this.obj = new EscapeAnalysis();\n    }\n    //思考：如果当前的obj引用声明为static的，会发生逃逸吗？会！\n\n    /*\n    对象的作用域仅在当前方法中有效，没有发生逃逸\n     */\n    public void useEscapeAnalysis(){\n        EscapeAnalysis e = new EscapeAnalysis();\n    }\n    /*\n    引用成员变量的值，发生逃逸\n     */\n    public void useEscapeAnalysis1(){\n        EscapeAnalysis e = getInstance();\n        //getInstance().xxx()同样会发生逃逸\n    }\n    /*\n    * 也发生了逃逸\n    * */\n    public void operate(EscapeAnalysis e){\n        // e\n    }\n}\n```\n\n### 优化一：栈上分配\n\n> Hotspot 中的栈上分配是通过标量替换实现的，具体分析见后文。\n\n首先测试开启栈上分配与不开启的区别，开启栈上分配在开启逃逸分析后即可开启。\n\n#### 开启逃逸分析\n\n**默认情况下即开启了逃逸分析**，无需再手动指明 `-XX:+DoEscapeAnalysis`。\n\n只要开启了逃逸分析，就会判断方法中的变量是否发生了逃逸。如果没有发生逃逸，则会使用栈上分配，提高程序性能。\n\n案例代码：\n\n```java\n/**\n * 栈上分配测试\n * -Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails\n *\n * 只要开启了逃逸分析，就会判断方法中的变量是否发生了逃逸。如果没有发生逃逸，则会使用栈上分配\n */\npublic class StackAllocation {\n    public static void main(String[] args) {\n        long start = System.currentTimeMillis();\n\n        for (int i = 0; i < 10000000; i++) {\n            alloc();\n        }\n        // 查看执行时间\n        long end = System.currentTimeMillis();\n        System.out.println(\"花费的时间为： \" + (end - start) + \" ms\");\n        // 为了方便查看堆内存中对象个数，线程sleep\n        try {\n            Thread.sleep(1000000);\n        } catch (InterruptedException e1) {\n            e1.printStackTrace();\n        }\n    }\n\n    private static void alloc() {\n        User user = new User(); // 是否发生逃逸？ 没有！\n    }\n\n    static class User {\n\n    }\n}\n```\n\nJVM 参数：\n\n```\n-Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails\n```\n\n开启了逃逸分析后，因为启动了栈上分配技术，所以运行速度极快，程序循环部分只耗时了 4 ms。并且通过 jvisualvm 观察内存情况，发现内存中并没有大量的 User 对象：\n\n![image-20211023102515646](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023102515646.png)\n\n\n\n#### 关闭逃逸分析\n\n通过参数 `-XX:-DoEscapeAnalysis` 可以关闭逃逸分析。\n\nJVM 参数：\n\n```\n-Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails\n```\n\n关闭逃逸分析后，同样的程序耗时了 85 ms。并且通过 jvisualvm 观察内存情况，发现内存中有大量的 User 对象：\n\n![image-20211023102838831](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023102838831.png)\n\n\n\n### 优化二：标量替换\n\nHotspot 中的栈上分配是通过标量替换实现的，标量替换是 Hotspot 虚拟机逃逸分析的基础。\n\n案例代码：\n\n```java\n/**\n * 标量替换测试\n *  -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails -XX:-EliminateAllocations\n *\n *  结论：Java中的逃逸分析，其实优化的点就在于对栈上分配的对象进行标量替换。\n */\npublic class ScalarReplace {\n    public static class User {\n        public int id;\n        public String name;\n    }\n\n    public static void alloc() {\n        User u = new User(); // 未发生逃逸\n        u.id = 5;\n        u.name = \"www.xxx.com\";\n    }\n\n    public static void main(String[] args) {\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < 10000000; i++) {\n            alloc();\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(\"花费的时间为： \" + (end - start) + \" ms\");\n\n    }\n}\n```\n\n#### 开启标量替换\n\n**标量替换默认情况下就是开启的**，可以手动开启/关闭。并且标量替换若想开启，必须先开启逃逸分析：` -XX:+DoEscapeAnalysis`：\n\n```\n-XX:+DoEscapeAnalysis -XX:+EliminateAllocations\n```\n\n首先开启标量替换，JVM参数：\n\n```\n-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails -XX:-EliminateAllocations\n```\n\n此时程序耗时大概 4 ms。\n\n#### 关闭标量替换\n\n首先开启标量替换，JVM参数：\n\n```\n-Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGCDetails -XX:+EliminateAllocations\n```\n\n此时程序耗时大概 48 ms。\n\n**注意**：此时即可看出一些端倪。本程序在不开启标量替换的情况下，JVM参数设置和栈上分配案例一样，同样都开启了` -XX:+DoEscapeAnalysis`，理应运行时间也只有几毫秒，但是本例却耗费了几十毫秒的时间，而不是像开启栈上分配案例一样只有 4ms。**这说明了栈上分配的就是通过标量替换才实现的，不开启标量替换，栈上分配就无从谈起**。\n\n#### 对比\n\n最后对比两种情况下打印的堆空间情况。\n\n开启时：\n\n![image-20211023143332988](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023143332988.png)\n\n关闭时：\n\n![image-20211023143422165](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023143422165.png)\n\n可以看到开启标量替换后，伊甸园区的大小明显减小，说明的确将大量的对象拆解成了标量，存储在了栈上。\n\n\n\n### 优化三：同步消除（省略）\n\n如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步。 线程同步的代价是相当高的，同步的后果是降低并发性和性能。\n\n 在动态编译同步块的时候，JIT编译器可以借助逃逸分析来判断同步块所使用的锁对象是否只能够被一个线程访问而没有被发布到其他线程。如果没有，那么JIT编译器在编译这个同步块的时候就会取消对这部分代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫同步省略，也叫锁消除。  \n\n```java\npublic class SynchronizedTest {\n    public void f() {\n        /*\n        * 代码中对hollis这个对象进行加锁，但是hollis对象的生命周期只在f()方法中，\n        * 并不会被其他线程所访问到，所以在JIT编译阶段就会被优化掉。\n        *\n        * 问题：字节码文件中会去掉hollis吗？：答：不会，只有在编译阶段才会去掉\n        * */\n        Object hollis = new Object();\n        synchronized(hollis) {\n            System.out.println(hollis);\n        }\n\n        /*\n        * 优化后；\n        * Object hollis = new Object();\n        * System.out.println(hollis);\n        * */\n    }\n}\n```\n\n\n\n### 逃逸分析小结\n\n逃逸分析并不成熟。关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。其根本原因就是无法保证非逃逸分析的性能消耗一定能高于他的消耗。\n\n虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。一个极端的例子，**就是经过逃逸分析之后，发现没有一个对象是不逃逸的，那这个逃逸分析的过程就白白浪费掉了**。\n\n虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段。注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JVM设计者的选择。目前很多书籍还是基于JDK 7以前的版本，JDK已经发生了很大变化，intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。 \n\n\n\n## 调优案例三：合理配置堆内存\n\n在案例一中我们讲到了增加内存可以提高系统的性能而且效果显著，那么随之带来的一个问题就是，我们增加多少内存比较合适？\n\n- 如果内存过大，那么产生Full GC时，GC时间会相对比较长（因为遍历堆空间耗时增加了）\n- 如果内存较小，那么就会频繁触发GC\n\n在这种情况下，我们该如何合理的适配堆内存大小呢？\n\n### 官方推荐配置\n\n我们可以根据Java虚拟机规范里 Java Performance 里面的推荐公式来进行设置：\n\n![image-20211023164346392](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211023164346392.png)\n\n翻译：\n\n- Java整个堆大小：`-Xmx` 和 `-Xms` 设置为**老年代存活对象**的 **3 - 4** 倍，即Full GC之后的老年代内存占用的3-4倍。并且二者设置相同，避免动态调整堆大小造成性能损耗\n- 方法区（永久代或元空间）大小：设置为老年代存活对象的 **1.2 - 1.5** 倍\n- 年轻代大小：`-Xmn` 设置为老年代存活对象的 **1 - 1.5** 倍\n- 老年代大小：设置为老年代存活对象的 **2 - 3** 倍（大小为`-Xmx`大小减去`-Xmn`大小）\n\n但是，上面的说法也不是绝对的，也就是说这给的是一个**参考值**，根据多种调优之后得出的一个结论，可以根据这个值来设置一下我们的初始化内存，在保证程序正常运行的情况下，我们还要去查看GC的回收率，GC停顿耗时，内存里的实际数据来判断，Full GC是基本上不能有的，如果有就要做内存Dump分析，然后再去做一个合理的内存分配。\n\n我们还要注意到一点就是，上面说的老年代存活对象怎么去判定。\n\n### 如何计算老年代存活对象\n\n要么在运行时在命令行打印的日志里观察，要么直接dump一次，强制做一次GC，然后分析GC日志。\n\n#### 方式一：查看日志（推荐）\n\nJVM参数中添加**GC日志**（`-XX:+PrintGCDetails`），GC日志中会记录每次Full GC之后各代的内存大小，观察老年代GC之后的空间大小。可观察一段时间内（比如2天）Full GC之后的内存情况，根据多次的Full GC之后的老年代的空间大小数据来预估Full GC之后老年代的存活对象大小（可根据多次Full GC之后的内存大小取平均值）。\n\n#### 方式二：强制触发FullGC\n\n**会影响线上服务，慎用！**\n\n方式一比较可行，但需要更改JVM参数，并分析日志。同时，在使用CMS回收器的时候，有可能不能触发Full GC（因为运行中CMS的一次Full GC很可能会使用老年代串行Serial Old GC，它的速度是极慢的），或者程序上线后一直没有GC过，所以没有打印过日志，即日志中并没有记录Full GC的日志，这在分析的时候就比较难处理。 所以，有时候需要**强制触发**一次Full GC，来观察FullGC之后的老年代存活对象大小。\n\n注：强制触发Full GC，会造成线上服务停顿（STW），要谨慎！建议的操作方式为：**在强制Full GC前先把服务节点摘除，Full GC之后再将服务挂回可用节点，对外提供服务**，在**不同时间段**触发Full GC，根据多次Full GC之后的老年代内存情况来预估Full GC之后的老年代存活对象大小。\n\n> 线上服务进行压测比强制Full GC影响更大，会导致极大的STW，谨慎使用。\n\n如何强制触发Full GC？\n\n- `jmap -dump:live,format=b,file=heap.bin <pid>`：将当前的存活对象dump到文件，此时会触发FullGC。会**顺带触发一次Full GC**。\n- `jmap -histo:live <pid>`：打印每个class的实例数目、内存占用、类全名信息。.live子参数加上后，只统计活的对象数量。此时会**顺带触发一次Full GC**。\n- 在性能测试环境，可以通过Java监控工具来触发Full GC，比如使用VisualVM和JConsole，VisualVM集成了JConsole，VisualVM或者JConsole上面有一个触发GC的按钮。\n\n> 生成 dump 文件时都会顺便触发一次 Full GC\n\n\n\n### 案例演示\n\n将内存初始化为1024M。JVM配置参数：\n\n``` \n-XX:MetaspaceSize=64m -Xss512K -Xms1024M  -Xmx1024M \n-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapdump3.hprof  \n-XX:SurvivorRatio=8  -XX:+PrintGCDetails -XX:+PrintGCDateStamps  \n-Xloggc:log/gc-oom3.log\n```\n\n编写代码，每次请求都从数据库中查询指令，模拟真实业务：\n\n```java\n@RequestMapping(\"/getData\")\npublic List<User> getProduct(){\n    List<User> userList = userSevice.getUserList();\n    return userList;\n}\n```\n\n\n\n### 数据分析\n\n#### 初始情况\n\n项目启动，通过jmeter访问10000次（主要是看项目是否可以正常运行）之后，查看GC状态：\n\n```\njstat -gc pid\n```\n\n![image-20211025094508183](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025094508183.png)\n\n- YGC 平均耗时： 0.12s * 1000 / 7 = 17.14ms\n- FGC 未产生\n\n看起来似乎不错，YGC触发的频率不高，FGC也没有产生，但这样的内存设置是否还可以继续优化呢？是不是有一些空间是浪费的呢。\n\n####  查看老年代存活对象大小\n\n为了快速看数据，我们使用了方式2，通过命令 `jmap -histo:live pid` 产生几次Full GC，Full GC之后，使用的 `jmap -heap` 来看的当前的堆内存情况。\n\n```\njmap -heap pid\n```\n\n观察老年代存活对象大小：\n\n![image-20211025095004147](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025095004147.png)\n\n可以看到存活对象占用内存空间大概13.36M，老年代的内存占用为683M左右，这说明大量的老年代空间都是冗余的，这无疑会降低每次GC时的耗时。 按照整个堆大小是老年代 Full GC 之后剩余内存大小的3 - 4倍计算的话，设置堆内存情况如下：\n\n```\n-Xmx = 14 * 3 = 42M  至  14 * 4 = 56M 之间\n```\n\n\n\n### 优化配置：修改堆内存大小\n\n我们修改堆内存状态如下：\n\n```\n-XX:+PrintGCDetails -XX:MetaspaceSize=64m -Xss512K \n-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=heap/heapdump.hprof \n-XX:SurvivorRatio=8  -XX:+PrintGCDateStamps  \n-Xms60M  -Xmx60M -Xloggc:log/gc-oom.log\n```\n\n修改完之后，再次进行压测后查看一下GC状态：\n\n![image-20211025095401459](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025095401459.png)\n\n- YGC平均耗时： 0.195s * 1000 / 68 = 2.87ms\n- FGC未产生\n\n对比优化前后的GC日志，可以看出：\n\n- GC频率比优化前要多了一些，这是因为堆内存空间变小了\n- 但是YGC的平均耗时却明显减少\n- 同时依然未产生Full GC\n\n所以我们内存设置为60M也是比较合理的，相对之前节省了很大一块内存空间，并且平均YGC也较小。\n\n依然手动触发Full GC，查看堆内存结构：\n\n![image-20211025095747754](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025095747754.png)\n\n可以看到还有很多冗余空间，不会导致Full GC\n\n### 结论\n\n在内存相对紧张的情况下，可以按照上述的方式来进行内存的调优， 找到一个在GC频率和GC耗时上都可接受的一个内存设置，可以用较小的内存满足当前的服务需要。\n\n但当内存相对宽裕的时候，可以相对给服务多增加一点内存，可以减少GC的频率，GC的耗时相应会增加一些。 一般要求低延时的可以考虑多设置一点内存， 对延时要求不高的，可以按照上述方式设置较小内存。 \n\n如果在垃圾回收日志中观察到`OutOfMemoryError`，尝试把Java堆的大小扩大到物理内存的80%~90%。尤其需要注意的是堆空间导致的`OutOfMemoryError`以及一定要增加空间。\n\n- 比如说，增加`-Xms`和`-Xmx`的值来解决Old代的`OutOfMemoryError`\n- 增加`-XX:MetaspaceSize`和`-XX:MaxMetaspaceSize`来解决Metaspace引起的`OutOfMemoryError`（jdk8之后）\n\n记住一点，Java堆能够使用的容量受限于硬件以及是否使用64位的JVM。在扩大了Java堆的大小之后，再检查垃圾回收日志，直到没有`OutOfMemoryError`为止。如果应用运行在稳定状态下没有`OutOfMemoryError`就可以进入下一步了：计算活动对象的大小。\n\n\n\n### 补充问题：你会估算 GC 频率吗？\n\n正常情况我们应该根据我们的系统来进行一个内存的估算，这个我们可以在测试环境进行测试，最开始可以将内存设置的大一些，比如4G这样，当然这也可以根据业务系统估算来的。\n\n比如从数据库获取一条数据占用128个字节，需要获取1000条数据，那么一次读取到内存的大小就是（128 B/1024 Kb/1024M）* 1000 = 0.122M ，那么我们程序可能需要并发读取，比如每秒读取100次，那么内存占用就是0.122 * 100 = 12.2M  ，如果堆内存设置1个G，那么年轻代大小大约就是333M，那么333M * 80% / 12.2M  =21.84s ，也就是说我们的程序几乎每分钟进行两到三次youngGC。这样可以让我们对系统有一个大致的估算。\n\n- 0.122M * 100 = 12.2M /秒  ---Eden区\n- 1024M * 1/3 * 80% = 273M \n- 273 / 12.2M = 22.38s ---> YGC  每分钟2-3次YGC \n\n\n\n### 特殊问题：新生代与老年代的比例\n\n#### 参数设置\n\nJVM 参数设置为：\n\n```\n-XX:+PrintGCDetails   -XX:+PrintGCDateStamps  \n-Xms300M  -Xmx300M -Xloggc:log/gc.log\n```\n\n新生代 ( Young ) 与老年代 ( Old ) 的比例为 1:2。所以，内存分配应该是新生代100M，老年代 200M。我们可以先用命令查看一下堆内存分配是怎么样的：\n\n```\n# 查看进程ID\njps -l\n\n# 查看对应的进程ID的堆内存分配\njmap -heap 3725\n```\n\n结果看到：虽然默认配置的SurvivorRatio= 8，但是内存分配却不是8:1:1，这是为什么呢？\n\n#### AdaptiveSizePolicy 参数\n\n这是因为JDK 1.8 默认使用 Parallel 垃圾回收器，**该垃圾回收器默认启动了 AdaptiveSizePolicy**（可以选择关闭该参数），会根据GC的情况自动计算计算 Eden、From 和 To 区的大小；所以这是由于JDK 1.8的自适应大小策略导致的，除此之外，我们下面观察GC日志发现有很多类似这样的FULL GC（Ergonomics），也是一样的原因。\n\n我们可以在JVM参数中配置开启和关闭该配置：\n\n```\n# 开启：\n-XX:+UseAdaptiveSizePolicy\n\n# 关闭\n-XX:-UseAdaptiveSizePolicy\n```\n\n注意事项：\n\n- 在 JDK 1.8 中，如果使用 **CMS**，无论 `UseAdaptiveSizePolicy` 如何设置，都会将 `UseAdaptiveSizePolicy` 设置为 false；不过不同版本的JDK存在差异；\n- `UseAdaptiveSizePolicy`不要和`SurvivorRatio`参数显示设置搭配使用，一起使用会导致参数失效；\n- 由于`UseAdaptiveSizePolicy`会动态调整 Eden、Survivor 的大小，有些情况存在Survivor被自动调为很小，比如十几MB甚至几MB的可能，这个时候YGC回收掉Eden区后，还存活的对象进入Survivor 装不下，就会直接晋升到老年代，导致老年代占用空间逐渐增加，从而触发FULL GC，如果一次FULL GC的耗时很长（比如到达几百毫秒），那么在要求高响应的系统就是不可取的。\n\n> 对于面向外部的**大流量**、**低延迟**系统，不建议启用此参数，因为动态调整很可能降低系统的延迟性。\n\n如果不想动态调整内存大小，以下是解决方案：\n\n- 保持使用 UseParallelGC，显式设置 `-XX:SurvivorRatio=8`。\n- 使用 CMS 垃圾回收器。CMS 默认关闭 `AdaptiveSizePolicy`。配置参数 `-XX:+UseConcMarkSweepGC`\n\n\n\n## 调优案例四：CPU 占用很高排查方案\n\n### 案例模拟\n\n死锁案例\n\n```java\npublic class JstackDeadLockDemo {\n    /**\n     * 必须有两个可以被加锁的对象才能产生死锁，只有一个不会产生死锁问题\n     */\n    private final Object obj1 = new Object();\n    private final Object obj2 = new Object();\n\n    public static void main(String[] args) {\n        new JstackDeadLockDemo().testDeadlock();\n    }\n\n    private void testDeadlock() {\n        Thread t1 = new Thread(() -> calLock_Obj1_First());\n        Thread t2 = new Thread(() -> calLock_Obj2_First());\n        t1.start();\n        t2.start();\n    }\n\n    /**\n     * 先synchronized  obj1，再synchronized  obj2\n     */\n    private void calLock_Obj1_First() {\n        synchronized (obj1) {\n            sleep();\n            System.out.println(\"已经拿到obj1的对象锁，接下来等待obj2的对象锁\");\n            synchronized (obj2) {\n                sleep();\n            }\n        }\n    }\n\n    /**\n     * 先synchronized  obj2，再synchronized  obj1\n     */\n    private void calLock_Obj2_First() {\n        synchronized (obj2) {\n            sleep();\n            System.out.println(\"已经拿到obj2的对象锁，接下来等待obj1的对象锁\");\n            synchronized (obj1) {\n                sleep();\n            }\n        }\n    }\n\n    /**\n     * 为了便于让两个线程分别锁住其中一个对象，\n     * 一个线程锁住obj1，然后一直等待obj2，\n     * 另一个线程锁住obj2，然后一直等待obj1，\n     * 然后就是一直等待，死锁产生\n     */\n    private void sleep() {\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n\n\n### 问题呈现\n\n将上述代码运行在Linux服务器上：\n\n![image-20211025143122524](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025143122524.png)\n\n可以看到，程序依然处于运行状态。现在我们知道是线程死锁造成的问题。\n\n### 问题分析\n\n那么如果是生产环境的话，是怎么样才能发现目前程序有问题呢？我们可以推导一下，如果线程死锁，那么线程一直在占用CPU，这样就会导致CPU一直处于一个比较高的占用率。所示我们解决问题的思路应该是：\n\n- 首先查看java进程ID\n- 根据进程 ID 检查当前使用**异常线程**的pid\n- 把线程pid变为16进制如 31695 -> 7bcf  然后得到 0x7bcf\n- `jstack pid | grep -A20  0x7bcf`  得到相关进程的代码 （鉴于我们当前代码量比较小，线程也比较少，所以我们就把所有的信息全部导出来）\n\n> -A20：after 20，显示目标行后的20行内容\n\n接下来是我们的实现上面逻辑的步骤，如下所示：\n\n```\n# 查看所有java进程 ID\njps -l\n```\n\n![image-20211025143250556](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025143250556.png)\n\n```\n# 根据进程 ID 检查当前使用异常线程的pid\ntop -Hp 1456\n```\n\n![image-20211025143305762](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025143305762.png)\n\n从上图可以看出来，当前占用cpu比较高的线程 ID 是1465。把线程 PID 转换为16进制为：0x5b9\n\n最后我们把线程信息打印出来：\n\n![image-20211025143339575](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025143339575.png)\n\n所有的准备工作已经完成，我们接下来分析日志中的信息，来定位问题出在哪里。\n\n打开`jstack.log`文件  查找一下刚刚我们转换完的16进制ID是否存在：\n\n![image-20211025143359293](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025143359293.png)\n\njstack命令生成的thread dump信息包含了JVM中所有存活的线程，里面确实是存在我们定位到的线程 ID ，在thread dump中每个线程都有一个nid，在nid=0x5b9的线程调用栈中，我们发现两个线程在互相等待对方释放资源\n\n![image-20211025143413295](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025143413295.png)\n\n到此就可以检查对应的代码是否有问题，也就定位到我们的死锁问题。\n\n### 解决方案\n\n- 调整锁的顺序，保持一致\n- 或者采用**定时锁**，一段时间后，如果还不能获取到锁就释放自身持有的所有锁。\n\n### 总结\n\n- `ps aux | grep java`  查看到当前java进程使用cpu、内存、磁盘的情况获取使用量异常的进程\n- `top -Hp pid`  检查当前使用异常线程的pid\n- 把线程pid变为16进制如 31695 -> 7bcf  然后得到0x7bcf\n- `jstack pid | grep -A20  0x7bcf`  得到相关进程的代码\n\n\n\n\n\n## 调优案例五：G1 并发标记线程数对性能的影响\n\n### 配置信息\n\n硬件配置：8核 Linux\n\nJVM参数设置：\n\n``` \nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+UseG1GC\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xms30m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xmx30m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDetails\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:MetaspaceSize=64m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDateStamps\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc.log\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:ConcGCThreads=1\"\n```\n\n> 说明：最后一个参数可以在使用G1 GC测试初始并发GCThreads之后再加上。并且初始化内存和最大内存调整小一些，目的发生 FullGC，关注GC时间。\n\n关注点是：GC次数，GC时间，以及Jmeter的平均响应时间。\n\n### 初始状态\n\n1、启动Tomcat，查看进程默认的并发线程数：\n\n``` \njinfo -flag ConcGCThreads pid\n-XX:ConcGCThreads=1\n```\n\n没有配置的情况下：并发标记线程数是1。\n\n2、查看线程状态：\n\n![image-20211025144209223](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025144209223.png)\n\n- YGC：Young GC 次数是 1259 次\n- FGC：Full GC 次数是 6 次\n- GCT：GC 总时间是 5.556 s\n\n3、Jmeter 压测之后的GC状态：\n\n![image-20211025144315086](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025144315086.png)\n\n- YGC：Young GC 次数是 1600 次\n- FGC：Full GC 次数是 18 次\n- GCT：GC 总时间是 7.919 s\n\n由此我们可以计算出来压测过程中，发生的GC次数和GC时间差。\n\n---\n\n整个压测过程中 GC 状态：\n\n- YGC：Young GC 次数是 1600 - 1259 = 341 次\n- FGC：Full GC 次数是 18 - 6 = 12 次\n- GCT：GC 总时间是 7.919 - 5.556 = 2.363 s\n\nJmeter压测结果，主要关注响应时间：\n\n- 95% 的请求响应时间为：16ms\n- 99% 的请求响应时间为：28ms\n\n![image-20211025144532203](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025144532203.png)\n\n---\n\n### 优化之后\n\n增加并发线程配置（建议设置为CPU核数的1/4，太大也没有意义，反而抢占了并发用户线程）：\n\n```\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:ConcGCThreads=2\"\n```\n\n1、Tomcat启动之后的初始化GC状态：\n\n![image-20211025144843498](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025144843498.png)\n\n- YGC：Young GC 次数是 1134 次\n- FGC：Full GC 次数是 5 次\n- GCT：GC 总时间是 5.234 s\n\n2、Jmeter 压测之后的GC状态：\n\n![image-20211025144930791](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025144930791.png)\n\n- YGC：Young GC 次数是 1347 次\n- FGC：Full GC 次数是 16 次\n- GCT：GC 总时间是 7.149 s\n\n由此我们可以计算出来压测过程中，发生的GC次数和GC时间差\n\n---\n\n压测过程GC状态：\n\n- YGC：Young GC 次数是 1347 - 1134 = 213 次\n- FGC：Full GC 次数是 16 - 5 = 13 次\n- **GCT：GC 总时间是 7.149 - 5.234 = 1.915 s**\n\n对比优化后的GCT时间，发现比单线程时时间更短。这说明增大并发标记线程数，使得GC时间降低了。\n\nJmeter压测结果，主要关注响应时间：\n\n- 95%的请求响应时间为：15ms\n- 99%的请求响应时间为：22ms\n\n请求响应时间确实比优化前单线程更低了。\n\n![image-20211025145515800](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025145515800.png)\n\n---\n\n### 总结\n\n配置完线程数之后，我们的请求的平均响应时间和GC时间都有一个明显的减少了，仅从效果上来看，我们这次的优化是有一定效果的。在工作中对于线上项目进行优化的时候，可以考虑到这方面的优化。\n\n结论：**增大并发标记线程数可以减小响应延迟时间**。并且并发标记线程数设置太大也没更明显变化，反而因为抢占用户线程而导致。**经验：并发标记线程数设置为CPU核数的 1/4 即可**。\n\n\n\n## 调优案例六：调整垃圾回收器提高服务的吞吐量\n\n### 初始配置\n\n初始系统配置是单核CPU，我们看到日志，显示`DefNew`，说明我们用的是串行收集器：SerialGC\n\n### 优化配置一\n\n那么就考虑切换一下并行收集器是否可以提高性能，增加配置如下：\n\n```\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xms60m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xmx60m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+UseParallelGC\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDetails\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:MetaspaceSize=64m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDateStamps\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc6.log\"\n```\n\n进行压测后查看GC状态：\n\n![image-20211025151418354](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025151418354.png)\n\n发生3次Full GC，可以接受。\n\n查看吞吐量：\n\n![image-20211025151446184](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025151446184.png)\n\n发现吞吐量并没有明显变化，我们究其原因，本身UseParallelGC是并行收集器，但是我们的服务器是单核，所以变化不大。\n\n### 优化配置二\n\n接下来我们把服务器改为8核。\n\n![image-20211025151608283](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025151608283.png)\n\n8核状态下的性能表现如下，吞吐量大幅提升，甚至翻了一倍，这说明我们**在多核机器上面采用并行收集器对于系统的吞吐量有一个显著的效果**。\n\n### 优化配置三\n\n接下来我们改为G1收集器看看效果\n\n```\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+UseG1GC\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xms60m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xmx60m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDetails\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:MetaspaceSize=64m\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -XX:+PrintGCDateStamps\"\nexport CATALINA_OPTS=\"$CATALINA_OPTS -Xloggc:/opt/tomcat8.5/logs/gc6.log\"\n```\n\n查看GC状态：\n\n![image-20211025151657880](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025151657880.png)\n\n\n没有产生Full GC，效果较之前有提升。\n\n查看压测效果，吞吐量也是比串行收集器效果更佳，而且没有了Full GC。此次优化较为成功。\n\n![image-20211025151701558](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/image-20211025151701558.png)\n\n### 总结\n\n在多核CPU上，使用并行垃圾收集器的效果要好于串行垃圾收集器（体现在吞吐量上），并且G1更能提高服务的吞吐量。\n\n\n\n## 调优案例七：日均百万级订单交易系统如何设置 JVM 参数\n\n首先针对**吞吐量**进行分析：\n\n![](/images/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/%E5%B0%9A%E7%A1%85%E8%B0%B7_%E5%AE%8B%E7%BA%A2%E5%BA%B7_%E6%A1%88%E4%BE%8B7%EF%BC%9A%E6%97%A5%E5%9D%87%E7%99%BE%E4%B8%87%E8%AE%A2%E5%8D%95%E7%B3%BB%E7%BB%9FJVM%E5%8F%82%E6%95%B0%E8%AE%BE%E7%BD%AE.png)\n\n### 正常数据量情况\n\n正常数据量情况下的分析步骤：\n\n- 首先计算一秒的订单量，从而估算出一秒有多少kb数据\n- 将该数据量扩大20倍，以加上其他业务信息\n- 计算出正常情况下每秒在伊甸园区创建2M对象，从而算出11分钟会让伊甸园区占满。\n\n十几分钟处于可以接受的范围。\n\n我们可以继续优化：**提高新生代所占比例**。因为大量的订单都是临时数据，不需要将他们放到老年代，否则会增加Full GC。\n\n### 业务暴增情况\n\n业务量暴增时数据量可能增加几十倍，此时的处理方案：**水平扩容**，多增加一些服务器，分摊压力。\n\n然而如果不扩容机器，则会有两种因素导致系统性能降低：\n\n- 订单数量暴增，新生代每秒新增对象增加到几十兆\n- 同时，由于系统压力，一个订单几秒到几十秒才可生成，所以新生代的订单对象可能存活几秒到几十秒（生命周期变长）\n\n这两个因素共同导致每二三十秒就会发生一次Minor GC，导致过多对象进入老年代，直到Full GC，这无疑会增加系统的延迟响应时间，降低性能。\n\n优化思路：**增大年轻代的内存空间**，尽量让大量对象都在新生代，减少Full GC\n\n上述分析过程的几个影响因素：\n\n- 机器的配置、水平扩容的配置\n- 每秒的订单数量\n- 年轻代的内存大小\n\n### 总结\n\n针对日均百万级订单交易系统，可以进行的一些优化设置：\n\n- 水平扩容，增加服务器数量，增加硬件性能\n- 提高JVM内存空间大小，尤其是新生代的大小，让大量临时订单对象停留在新生代，不让其进入老年代\n- 使用 G1 垃圾回收器，增加服务吞吐量\n- 增大 G1 GC 中并发GC线程数量，设置为系统CPU核数的1/4\n\n\n\n---\n\n扩展：问如何进行服务器配置只是第一个层面的问题！第二个层面问题：如果要求**响应时间控制在100ms如何实现**？\n\n思路：使用G1垃圾回收器，通过参数 `-XX:MaxGCPauseMillis` 设置暂停时间（设置该参数无法保证高吞吐量）。同时在上线前进行压测，根据延迟时间对JVM参数进行调整，并且关注GC频率与吞吐量，通过反复压测调整参数的方式，控制响应时间。\n\n---\n\n\n\n\n\n## 面试题\n\n1、12306遭遇春节大规模抢票如何支撑？\n\n普通电商订单-->  下单 --> 订单系统（IO）减库存 ---> 等待用户付款\n\n12306一种可能的模型：下单 --> 减库存和订单（redis、kafka）同时异步进行 --> 等付款\n但减库存最后还会把压力压到一台服务器上。如何？\n\n**分布式本地库存** + **单独服务器做库存均衡**！\n\n\n\n2、有一个50万PV的资料类网站（从磁盘提取文档到内存）原服务器是32位的，1.5G的堆，用户反馈网站比较缓慢。因此公司决定升级，新的服务器为64位，16G的堆内存，结果用户反馈卡顿十分严重，反而比以前效率更低了！\n\n1. 为什么原网站慢？频繁的GC，STW时间比较长，响应时间慢！\n2. 为什么会更卡顿？内存空间越大，FGC时间更长，延迟时间更长\n3. 怎么解决？\n> 垃圾回收器：parallel GC ;  ParNew + CMS ; G1\n> 配置GC参数：-XX:MaxGCPauseMillis 、 -XX:ConcGCThreads \n> 根据log日志、dump文件分析，优化内存空间的比例\n> jstat   jinfo  jstack  jmap \n\n \n\n3、系统CPU经常100%，如何调优？（面试高频）\n\nCPU100%的话，一定是有线程占用系统资源。具体步骤前面已经讲过。\n\n> 注意： 工作中有时候是工作线程100%占用了CPU，还有可能是垃圾回收线程占用了100%\n\n\n\n4、系统内存飙高，如何查找问题？（面试高频）\n\n- 一方面：jmap -heap 、jstat 、... ; gc日志情况\n- 另一方面：dump文件分析\n\n\n\n5、如何监控 JVM\n\n > 命令行工具\n > 图形化界面工具","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 监控及诊断工具","url":"/2021/10/18/【JVM】JVM监控及诊断工具/","content":"\n## JVM 调优概述\n\n### 生产环境中的问题\n\n- 生产环境发生了内存溢出该如何处理？\n- 生产环境应该给服务器分配多少内存合适？\n- 如何对垃圾回收器的性能进行调优？\n- 生产环境CPU负载飙高该如何处理？\n- 生产环境应该给应用分配多少线程合适？\n- 不加log，如何确定请求是否执行了某一行代码？\n- 不加log，如何实时查看某个方法的入参与返回值？\n\n### 为什么要调优\n\n- 防止出现OOM\n- 解决OOM\n- 减少Full GC出现的频率\n\n**不同阶段的考虑**\n\n- 上线前\n- 项目运行阶段\n- 线上出现OOM\n\n### 调优概述\n\n**监控的依据**\n\n- 运行日志\n- 异常堆栈\n- GC日志\n- 线程快照\n- 堆转储快照\n\n**调优的大方向**\n\n- 合理地编写代码\n- 充分并合理的使用硬件资源\n- 合理地进行JVM调优\n\n### 性能优化的步骤\n\n**第1步：性能监控**\n\n- GC频繁\n- cpu load过高\n- OOM\n- 内存泄露\n- 死锁\n- 程序响应时间较长\n\n**第2步：性能分析**\n\n- 打印GC日志，通过GCviewer或者 http://gceasy.io 来分析异常信息\n- 灵活运用命令行工具、jstack、jmap、jinfo等\n- dump出堆文件，使用内存分析工具分析文件\n- 使用阿里Arthas、jconsole、JVisualVM来实时查看JVM状态\n- jstack查看堆栈信息\n\n**第3步：性能调优**\n\n- 适当增加内存，根据业务背景选择垃圾回收器\n- 优化代码，控制内存使用\n- 增加机器，分散节点压力\n- 合理设置线程池线程数量\n- 使用中间件提高程序效率，比如缓存、消息队列等\n\n<!-- More -->\n\n### 性能评价/测试指标\n\n- **停顿时间（或响应时间）**：提交请求和返回该请求的响应之间使用的时间，一般比较关注平均响应时间。在垃圾回收环节中：\n  - **暂停时间**：执行垃圾收集时，程序的工作线程被暂停的时间。\n  - 通过`-XX:MaxGCPauseMillis`参数进行设置\n- **吞吐量**：\n  - 对单位时间内完成的工作量（请求）的量度\n  - 在GC中：运行用户代码的事件占总运行时间的比例（总运行时间：程序的运行时间+内存回收的时间）\n  - 吞吐量为`1-1/(1+n)`，其中`-XX::GCTimeRatio=n`\n- 并发数\n  - 同一时刻，对服务器有实际交互的请求数\n- 内存占用\n  - Java堆区所占的内存大小\n\n相互间的关系（以高速公路通行状况为例）：\n\n- 吞吐量：每天通过高速公路收费站的车辆的数据\n- 并发数：高速公路上正在行驶的车辆的数目\n- 响应时间：车速\n\n补充：常用操作的响应时间列表\n\n| 操作                               | 响应时间 |\n| ---------------------------------- | -------- |\n| 打开一个站点                       | 几秒     |\n| 数据库查询一条记录（有索引）       | 十几毫秒 |\n| 机械磁盘一次寻址定位               | 4毫秒    |\n| 从机械磁盘顺序读取1M数据           | 2毫秒    |\n| 从SSD磁盘顺序读取1M数据            | 0.3毫秒  |\n| 从远程分布式换成Redis 读取一个数据 | 0.5毫秒  |\n| 从内存读取 1M数据                  | 十几微妙 |\n| Java程序本地方法调用               | 几微妙   |\n| 网络传输2Kb数据                    | 1 微妙   |\n\n\n\n## 浅堆深堆\n\n### 浅堆（Shallow Heap）\n\n浅堆是指一个对象所消耗的内存。在32位系统中，一个对象引用会占据4个字节，一个int类型会占据4个字节，long型变量会占据8个字节，每个对象头需要占用8个字节。根据堆快照格式不同，对象的大小可能会同8字节进行对齐。\n\n以String为例：2个int值共占8字节，对象引用占用4字节，对象头8字节，合计20字节，向8字节对齐，故占24字节。（JDK 7中）\n\n| int     | hash32    | 0                        |\n| ------- | --------- | ------------------------ |\n| **int** | **hash**  | **0**                    |\n| **ref** | **value** | **C:\\Users\\Administrat** |\n\n这24字节为String对象的浅堆大小。**它与String的value实际取值无关，无论字符串长度如何，浅堆大小始终是24字节**。\n\n**浅堆指对象本身占用的内存，不包括其内部引用对象的大小**\n\n### 保留集（Retained Set）\n\n**对象A的保留集指当对象A被垃圾回收后，可以被释放的所有的对象集合**（包括对象A本身），即对象A的保留集可以被认为是 ==**只能通过**== **对象A被直接或间接访问到的所有对象的集合**。通俗地说，就是指**仅被对象A所持有的对象的集合**。\n\n这些对象无法被其他对象所访问到，所以一旦A对象需要被回收，那么其所持有的的保留集中的对象都需要被回收。\n\n### 深堆（Retained Heap）\n\n深堆是指**对象的保留集中所有的对象的浅堆大小之和**。\n\n注意：**浅堆指对象本身占用的内存，不包括其内部引用对象的大小**。**一个对象的深堆指只能通过该对象访问到的（直接或间接）所有对象的浅堆之和，即对象被回收后，可以释放的真实空间**。\n\n### 对象的实际大小\n\n这里，对象的实际大小定义为**一个对象所能触及的所有对象的浅堆大小之和**，也就是通常意义上我们说的对象大小。与深堆相比，似乎这个在日常开发中更为直观和被人接受，但实际上，这个概念和垃圾回收无关。\n\n下图显示了一个简单的对象引用关系图，对象A引用了C和D，对象B引用了C和E。**那么对象A的浅堆大小只是A本身，不含C和D，而A的实际大小为A、C、D三者之和。而A的深堆大小为A与D之和，由于对象C还可以通过对象B访问到，因此不在对象A的深堆范围内**。\n\n![image-20211019194726602](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019194726602.png)\n\n### 支配树（Dominator Tree）\n\n支配树的概念源自图论。MAT提供了一个称为支配树（Dominator Tree）的对象图。支配树体现了对象实例间的支配关系。在对象引用图中，**所有指向对象B的路径都经过对象A，则认为对象A支配对象B**。如果对象A是离对象B最近的一个支配对象，则认为对象A为对象B的直接支配者。支配树是基于对象间的引用图所建立的，它有以下基本性质：\n\n- 对象A的子树（所有被对象A支配的对象集合）表示对象A的保留集（retained set），即深堆。\n- 如果对象A支配对象B，那么对象A的直接支配者也支配对象B。\n- 支配树的边与对象引用图的边不直接对应。\n\n如下图所示：左图表示对象引用图，右图表示左图所对应的支配树。对象A和B由根对象直接支配，由于在到对象C的路径中，可以经过A，也可以经过B，因此对象C的直接支配者也是根对象。对象F与对象D相互引用，因为到对象F的所有路径必然经过对象D，因此，对象D是对象F的直接支配者。而到对象D的所有路径中，必然经过对象C，即使是从对象F到对象D的引用，从根节点出发，也是经过对象C的，所以，对象D的直接支配者为对象C。同理，对象E支配对象G。到达对象H的可以通过对象D，也可以通过对象E，因此对象D和E都不能支配对象H，而经过对象C既可以到达D也可以到达E，因此对象C为对象H的直接支配者。\n\n![image-20211019194901811](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019194901811.png)\n\n\n\n## 命令行工具\n\n### 概述\n\n性能诊断是软件工程师在日常工作中需要经常面对和解决的问题，在用户体验至上的今天，解决好应用的性能问题能带来非常大的收益。\n\nJava 作为最流行的编程语言之一，其应用性能诊断一直受到业界广泛关注。可能造成 Java 应用出现性能问题的因素非常多，例如线程控制、磁盘读写、数据库访问、网络I/O、垃圾收集等。想要定位这些问题，一款优秀的性能诊断工具必不可少。\n\n在JDK的bin目录下，有很多官方提供的监控与诊断工具：\n\n![image-20211018143521569](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018143521569.png)\n\n### jps：查看正在运行的 Java 进程\n\njps（Java Process Status）：显示指定系统内所有的HotSpot虚拟机进程（查看虚拟机进程信息），可用于查询正在运行的虚拟机进程。\n\n格式：\n\n```\njps [options] [hostid]\n```\n\n常用参数：\n\n- `jps -q`：只显示Java进程号\n- `jps -l`：显示主类全类名\n- `jps -m`：显示主类`main()`的参数\n- `jps -v`：显示进程启动的JVM参数。比如：`-Xms20m` `-Xmx50m`是启动程序指定的JVM参数。\n\n上述参数可以组合使用。\n\n> 如果某 Java 进程关闭了默认开启的UsePerfData参数（即使用参数-XX：-UsePerfData），那么jps命令（以及下面介绍的jstat）将无法探知该Java 进程。\n\n### jstat：查看 JVM 统计信息\n\n> https://www.yuque.com/u21195183/jvm/pgrt7e\n\njstat（JVM Statistics Monitoring Tool）：用于监视虚拟机各种运行状态信息的命令行工具。它可以显示本地或者远程虚拟机进程中的类装载、内存、垃圾收集、JIT编译等运行数据。在没有GUI图形界面，只提供了纯文本控制台环境的服务器上，它将是运行期定位虚拟机性能问题的首选工具。常用于检测垃圾回收问题以及内存泄漏问题。\n\n**jstat是命令行中运行期间定位虚拟机性能问题首选工具，常用于检查垃圾回收以及内存泄漏问题**。\n\n格式：\n\n```\njstat -<option> [-t] [-h] <vmid> [interval] [count]\n```\n\n常用参数：\n\n- `-option`：要查看什么统计信息\n- `-t`：输出程序运行到现在好费时间\n- `-h` ：输出多少行后输出一次表头信息\n- `vmid`：要查看的进程号\n- `interval`：间隔多少毫秒输出一次统计信息\n- `count`：输出多少次终止\n\n常用命令：\n\n**jstat -class**：显示ClassLoader的相关信息：类的装载、卸载数量、总空间、类装载所消耗的时间等\n\n![image-20211018144605845](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144605845.png)\n\n**jstat -compiler**：显示JIT编译器编译过的方法、耗时等信息\n\n![image-20211018144636311](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144636311.png)\n\n**jstat -printcompilation**：输出已经被JIT编译的方法\n\n![image-20211018144724807](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144724807.png)\n\n**jstat -gc**：显示与GC相关的堆信息。包括Eden区、两个Survivor区、老年代、永久代等的容量、已用空间、GC时间合计等信息。\n\n![image-20211018144741353](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144741353.png)\n\n**jstat -gccapacity**：显示内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大、最小空间。\n\n![image-20211018144811128](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144811128.png)\n\n**jstat -gcutil**：显示内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比。\n\n![image-20211018144853740](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144853740.png)\n\n**jstat -gccause**：与-gcutil功能一样，但是会额外输出导致最后一次或当前正在发生的GC产生的原因。\n\n![image-20211018144920184](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144920184.png)\n\n**jstat -gcnew**：显示新生代GC状况\n\n![image-20211018144946904](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018144946904.png)\n\n**jstat -t**\n\n![image-20211018145058532](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018145058532.png)\n\n**jstat -t -h**\n\n![image-20211018145110053](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018145110053.png)\n\n| 表头 | 含义（字节）                                    |\n| ---- | ----------------------------------------------- |\n| EC   | Eden区的大小                                    |\n| EU   | Eden区已使用的大小                              |\n| S0C  | 幸存者0区的大小                                 |\n| S1C  | 幸存者1区的大小                                 |\n| S0U  | 幸存者0区已使用的大小                           |\n| S1U  | 幸存者1区已使用的大小                           |\n| MC   | 元空间的大小                                    |\n| MU   | 元空间已使用的大小                              |\n| OC   | 老年代的大小                                    |\n| OU   | 老年代已使用的大小                              |\n| CCSC | 压缩类空间的大小                                |\n| CCSU | 压缩类空间已使用的大小                          |\n| YGC  | 从应用程序启动到采样时young gc的次数            |\n| YGCT | 从应用程序启动到采样时young gc消耗时间（秒）    |\n| FGC  | 从应用程序启动到采样时full gc的次数             |\n| FGCT | 从应用程序启动到采样时的full gc的消耗时间（秒） |\n| GCT  | 从应用程序启动到采样时gc的总时间                |\n\n**经验**：\n\n- 当GC时间占总时间比率很大时，说明频繁GC，越大越可能OOM\n  - 计算GC占比公式 = 2次GC耗时时间相减 / 这2次程序持续时间相减\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210517225915759.png)\n\n- 当老年代占用内存不断上涨,可能出现内存泄漏\n\n\n\n**补充：** jstat还可以用来判断是否出现内存泄漏。\n\n- 第1步：在长时间运行的 Java 程序中，我们可以运行jstat命令连续获取多行性能数据，并取这几行数据中 OU 列（即已占用的老年代内存）的最小值\n- 第2步：然后，我们每隔一段较长的时间重复一次上述操作，来获得多组 OU 最小值。如果这些值呈上涨趋势，则说明该 Java 程序的老年代内存已使用量在不断上涨，这意味着无法回收的对象在不断增加，因此很有可能存在内存泄漏。\n\n![image-20211018145358819](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018145358819.png)\n\n\n\n### jinfo：实时查看和修改 JVM 配置参数\n\njinfo（Configuration Info for Java）：**查看虚拟机配置参数信息，也可用于实时修改虚拟机的配置参数**。在很多情况卡，Java应用程序不会指定所有的Java虚拟机参数。而此时，开发人员可能不知道某一个具体的Java虚拟机参数的默认值。在这种情况下，可能需要通过查找文档获取某个参数的默认值。这个查找过程可能是非常艰难的。但有了jinfo工具，开发人员可以很方便地找到Java虚拟机参数的当前值。\n\n> jinfo 可以在程序运行时动态修改某些参数（只有少数参数支持运行时修改）。更多的应用是查看JVM的一些参数\n\n格式：\n\n```\njinfo [options] pid\n```\n\n参数列表：\n\n| 选项             | 选项说明                                                     |\n| ---------------- | ------------------------------------------------------------ |\n| no option        | 输出全部的参数和系统属性                                     |\n| -flag name       | 输出对应名称的参数                                           |\n| -flag [+-]name   | 开启或者关闭对应名称的参数 只有被标记为manageable的参数才可以被动态修改 |\n| -flag name=value | 设定对应名称的参数                                           |\n| -flags           | 输出全部的参数                                               |\n| -sysprops        | 输出系统属性                                                 |\n\n常用参数：\n\n**jinfo -sysprops**：  输出系统属性\n\n```properties\n> jinfo -sysprops\njboss.modules.system.pkgs = com.intellij.rt\njava.vendor = Oracle Corporation\nsun.java.launcher = SUN_STANDARD\nsun.management.compiler = HotSpot 64-Bit Tiered Compilers\ncatalina.useNaming = true\nos.name = Windows 10\n...\n```\n\n**jinfo -flags**：输出全部的参数\n\n```shell\n> jinfo -flags 25592\nNon-default VM flags: -XX:CICompilerCount=4 -XX:InitialHeapSize=333447168 -XX:MaxHeapSize=5324668928 -XX:MaxNewSize=1774714880 -XX:MinHeapDeltaBytes=524288 -XX:NewSize=111149056 -XX:OldSize=222298112 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseFastUnorderedTimeStamps -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC\nCommand line:  -agentlib:jdwp=transport=dt_socket,address=127.0.0.1:8040,suspend=y,server=n -Drebel.base=C:\\Users\\Vector\\.jrebel -Drebel.env.ide.plugin.version=2021.1.2 -Drebel.env.ide.version=2020.3.3 -Drebel.env.ide.product=IU -Drebel.env.ide=intellij -Drebel.notification.url=http://localhost:7976 -agentpath:C:\\Users\\Vector\\AppData\\Roaming\\JetBrains\\IntelliJIdea2020.3\\plugins\\jr-ide-idea\\lib\\jrebel6\\lib\\jrebel64.dll -Dmaven.home=D:\\eclipse\\env\\maven -Didea.modules.paths.file=C:\\Users\\Vector\\AppData\\Local\\JetBrains\\IntelliJIdea2020.3\\Maven\\idea-projects-state-596682c7.properties -Dclassworlds.conf=C:\\Users\\Vector\\AppData\\Local\\Temp\\idea-6755-mvn.conf -Dmaven.ext.class.path=D:\\IDEA\\plugins\\maven\\lib\\maven-event-listener.jar -javaagent:D:\\IDEA\\plugins\\java\\lib\\rt\\debugger-agent.jar -Dfile.encoding=UTF-8\n```\n\n**jinfo -flag name**：输出对应名称的参数\n\n```shell\n> jinfo -flag UseParallelGC 25592\n-XX:+UseParallelGC\n\n> jinfo -flag UseG1GC 25592\n-XX:-UseG1GC\n```\n\n**jinfo -flag [+-]name**：开启或者关闭对应名称的参数，只有被标记为manageable的参数才可以被动态修改\n\n```shell\n> jinfo -flag +PrintGCDetails 25592\n> jinfo -flag PrintGCDetails 25592\n-XX:+PrintGCDetails\n\n> jinfo -flag -PrintGCDetails 25592\n> jinfo -flag PrintGCDetails 25592\n-XX:-PrintGCDetails\n```\n\n拓展：\n\n`java -XX:+PrintFlagsInitial` 查看所有JVM参数启动的初始值\n\n```shell\n[Global flags]\n     intx ActiveProcessorCount                      = -1                                  {product}\n    uintx AdaptiveSizeDecrementScaleFactor          = 4                                   {product}\n    uintx AdaptiveSizeMajorGCDecayTimeScale         = 10                                  {product}\n    uintx AdaptiveSizePausePolicy                   = 0                                   {product}\n...\n```\n\n`java -XX:+PrintFlagsFinal` 查看所有JVM参数的最终值\n\n```shell\n[Global flags]\n     intx ActiveProcessorCount                      = -1                                  {product}\n...\n     intx CICompilerCount                          := 4                                   {product}\n    uintx InitialHeapSize                          := 333447168                           {product}\n    uintx MaxHeapSize                              := 1029701632                          {product}\n    uintx MaxNewSize                               := 1774714880                          {product}\n```\n\n`java -XX:+PrintCommandLineFlags` 查看哪些已经被用户或者JVM设置过的详细的XX参数的名称和值\n\n```shell\n-XX:InitialHeapSize=332790016 -XX:MaxHeapSize=5324640256 -XX:+PrintCommandLineFlags -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:-UseLargePagesIndividualAllocation -XX:+UseParallelGC\n```\n\n\n\n### jmap：导出内存映像文件和内存使用情况\n\njmap（JVM Memory Map）：作用一方面是获取dump文件（堆转储快照文件，二进制文件），它还可以获取目标Java进程的内存相关信息，包括Java堆各区域的使用情况、堆中对象的统计信息、类加载信息等。开发人员可以在控制台中输入命令“jmap -help”查阅jmap工具的具体使用方式和一些标准选项配置。\n\n**jmap用于获取dump文件以及目标Java进程内存相关信息（堆使用情况，对象统计信息，类加载信息）**\n\n基本使用语法为：\n\n- `jmap [option] <pid>`\n- `jmap [option] <executable <core>`\n- `jmap [option] [server_id@] <remote server IP or hostname>`\n\n常用选项：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210518090954961.png)\n\n| 选项           | 作用                                                         |\n| -------------- | ------------------------------------------------------------ |\n| -dump          | 生成dump文件（Java堆转储快照），`-dump:live`只保存堆中的存活对象 |\n| -heap          | 输出整个堆空间的详细信息，包括GC的使用、堆配置信息，以及内存的使用信息等 |\n| -histo         | 输出堆空间中对象的统计信息，包括类、实例数量和合计容量，`-histo:live`只统计堆中的存活对象 |\n| -J \\<flag\\>    | 传递参数给jmap启动的jvm                                      |\n| -finalizerinfo | 显示在F-Queue中等待Finalizer线程执行finalize方法的对象，仅linux/solaris平台有效 |\n| -permstat      | 以ClassLoader为统计口径输出永久代的内存状态信息，仅linux/solaris平台有效 |\n| -F             | 当虚拟机进程对-dump选项没有任何响应时，强制执行生成dump文件，仅linux/solaris平台有效 |\n\n**该命令常用于导出dump文件**：\n\n- 手动导出dump文件：\n\n```shell\njmap -dump:format=b,file=<filename.hprof> <pid>\njmap -dump:live,format=b,file=<filename.hprof> <pid>\n```\n\n- 自动导出：启动程序时需要带参数，发生OOM时自动导出\n  - `-XX:+HeapDumpOnOutOfMemoryError`\n  - `-XX:HeapDumpPath=导出目录\\文件名.hprof`\n\n说明：这些参数和Linux下输入显示的命令多少会有不同，包括也受jdk版本的影响。\n\n由于jmap将访问堆中的所有对象，为了保证在此过程中不被应用线程干扰，**jmap需要借助安全点机制，让所有线程停留在不改变堆中数据的状态**。也就是说，由jmap导出的堆快照必定是安全点位置的。这可能导致基于该堆快照的分析结果存在偏差。\n\n举个例子，假设在编译生成的机器码中，某些对象的生命周期在两个安全点之间，那么:live选项将无法探知到这些对象。\n\n另外，如果某个线程长时间无法跑到安全点，jmap将一直等下去。与前面讲的jstat则不同，垃圾回收器会主动将jstat所需要的摘要数据保存至固定位置之中，而jstat只需直接读取即可。\n\n\n\n### jhat：JDK自带堆分析工具\n\njhat（JVM Heap Analysis Tool）：Sun JDK提供的jhat命令与jmap命令搭配使用，**用于分析jmap生成的heap dump文件**（堆转储快照）。jhat内置了一个微型的HTTP/HTML服务器，生成dump文件的分析结果后，用户可以在浏览器中查看分析结果（分析虚拟机转储快照信息）。\n\n使用了jhat命令，就启动了一个http服务，端口是7000，即http://localhost:7000/，就可以在浏览器里分析。使用的时候会占用CPU所以不会在生成环境中使用jhat来分析\n\n> 说明：jhat命令在JDK9、JDK10中已经被删除，官方建议用VisualVM代替。\n\n格式：\n\n```\njhat <option> <dumpfile>\n```\n\n常用参数：\n\n| option参数             | 作用                                   |\n| ---------------------- | -------------------------------------- |\n| -stack false｜true     | 关闭｜打开对象分配调用栈跟踪           |\n| -refs false｜true      | 关闭｜打开对象引用跟踪                 |\n| -port port-number      | 设置jhat HTTP Server的端口号，默认7000 |\n| -exclude exclude-file  | 执行对象查询时需要排除的数据成员       |\n| -baseline exclude-file | 指定一个基准堆转储                     |\n| -debug int             | 设置debug级别                          |\n| -version               | 启动后显示版本信息就退出               |\n| -J \\<flag\\>            | 传入启动参数，比如-J-Xmx512m           |\n\n### jstack：打印 JVM 中线程快照\n\njstack（JVM Stack Trace）：**用于生成虚拟机指定进程当前时刻的线程快照**（虚拟机堆栈跟踪）。线程快照就是当前虚拟机内指定进程的每一条线程正在执行的方法堆栈的集合。\n\n生成线程快照的作用：可用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等问题。这些都是导致线程长时间停顿的常见原因。当线程出现停顿时，就可以用jstack显示各个线程调用的堆栈情况。\n\n在thread dump中，要留意下面几种状态\n\n- 死锁，`Deadlock`（重点关注）\n- 等待资源，`Waiting on condition`（重点关注）\n- 等待获取监视器，`Waiting on monitor entry`（重点关注）\n- 阻塞，`Blocked`（重点关注）\n- 执行中，`Runnable`\n- 暂停，`Suspended`\n- 对象等待中，`Object.wait()` 或 `TIMED_WAITING`\n- 停止，`Parked`\n\n格式：\n\n```\njstack option pid\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210518224426354.png)\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210518224413517.png)\n\n### jcmd：多功能命令行\n\n> jcmd可以实现除了jstat外所有指令的功能\n\n在JDK 1.7以后，新增了一个命令行工具jcmd。它是一个**多功能**的工具，可以用来实现前面除了jstat之外所有命令的功能。比如：用它来导出堆、内存使用、查看Java进程、导出线程信息、执行GC、JVM运行时间等。jcmd拥有jmap的大部分功能，并且在Oracle的官方网站上也推荐使用jcmd命令代jmap命令。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210518225518037.png)\n\n常用命令：\n\n- `jcmd -l`：列出所有的JVM进程\n- `jcmd 进程号 help`：针对指定的进程，列出支持的所有具体命令\n- `jcmd 进程号 具体命令`：显示指定进程的指令命令的数据\n  - `Thread.print` 可以替换 jstack指令\n  - `GC.class_histogram` 可以替换 jmap中的`-histo`操作\n  - `GC.heap_dump` 可以替换 jmap中的`-dump`操作\n  - `GC.run` 可以查看GC的执行情况\n  - `VM.uptime` 可以查看程序的总执行时间，可以替换jstat指令中的`-t`操作\n  - `VM.system_properties` 可以替换 `jinfo -sysprops 进程id`\n  - `VM.flags` 可以获取JVM的配置参数信息\n\n### jstatd：远程主机信息收集\n\n之前的指令只涉及到监控本机的Java应用程序，而在这些工具中，一些监控工具也支持对远程计算机的监控（如jps、jstat）。为了启用远程监控，则需要配合使用jstatd 工具。命令jstatd是一个RMI服务端程序，它的作用相当于**代理服务器，建立本地计算机与远程监控工具的通信**。jstatd服务器将本机的Java应用程序信息传递到远程计算机。\n\n![image-20211020110057297](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211020110057297.png)\n\n\n\n## GUI 工具\n\n使用上一章命令行工具或组合能帮我们获取目标Java应用性能相关的基础信息，但它们存在下列局限：\n\n- 无法获取方法级别的分析数据，如方法间的调用关系、各方法的调用次数和调用时间等（这对定位应用性能瓶颈至关重要）。\n- 要求用户登录到目标 Java 应用所在的宿主机上，使用起来不是很方便。\n- 分析数据通过终端输出，结果展示不够直观。\n\n为此，JDK提供了一些内存泄漏的分析工具，如jconsole，jisualvm等，用于辅助开发人员定位问题，但是这些工具很多时候并不足以满足快速定位的需求。所以这里我们介绍的工具相对多一些、丰富一些。\n\n**JDK 自带的工具**\n\n-  jconsole：JDK自带的可视化监控工具。查看Java应用程序的运行概况、监控堆信息、永久区（或元空间）使用情况、类加载情况等 \n- Visual VM：Visual VM是一个工具，它提供了一个可视界面，用于查看Java虚拟机上运行的基于Java技术的应用程序的详细信息。 \n- JMC：Java Mission Control，内置Java Flight Recorder。能够以极低的性能开销收集Java虚拟机的性能数据。 \n\n**第三方工具**\n\n-  MAT：MAT（Memory Analyzer Tool）是基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗 \n- JProfiler：商业软件，需要付费。功能强大。 \n\n### JConsole\n\n> jconsole 可用于观察堆内存情况、检查线程是否发生死锁\n\njconsole：从Java 5开始，在JDK中自带的java**监控和管理控制台**。用于对JVM中内存、线程和类等的监控，是一个基于JMX（java management extensions）的GUI性能监控工具。\n\n官方地址：https://docs.oracle.com/javase/7/docs/technotes/guides/management/jconsole.html\n\n#### 启动\n\n![image-20210518235707000](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210518235707000.png)\n\n#### 连接\n\n![image-20210519000148496](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519000148496.png)\n\n无法连接解决方案，启动JVM参数加上\n\n```\n-Dcom.sun.management.jmxremote  \n-Dcom.sun.management.jmxremote.port=8011 \n-Dcom.sun.management.jmxremote.ssl=false\n-Dcom.sun.management.jmxremote.authenticate=false\n```\n\n#### 查看信息\n\n> 概述信息\n\n![image-20210519000756518](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519000756518.png)\n\n> 内存信息\n\n![image-20210519000816175](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519000816175.png)\n\n> 线程信息 可检查死锁\n\n![image-20210519000835395](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519000835395.png)\n\n> 关于类信息\n\n![image-20210519000848394](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519000848394.png)\n\n> 有关VM以及参数等信息\n\n![image-20210519000900135](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519000900135.png)\n\n### Visual VM\n\n> Visual VM 集合了上一章讲解的多个命令行工具的功能，并提供了可视化界面，能够替代 JConsole\n\nVisual VM是一个功能强大的多合一故障诊断和性能监控的可视化工具。它集成了多个JDK命令行工具，使用Visual VM可用于显示虚拟机进程及进程的配置和环境信息（jps，jinfo），监视应用程序的CPU、GC、堆、方法区及线程的信息（jstat、jstack）等，甚至代替JConsole。在JDK 6 Update 7以后，Visual VM便作为JDK的一部分发布（VisualVM 在JDK／bin目录下）即：它完全免费。\n\nIDEA 可以继承 Visual VM 插件。另外，Visual VM 也需要安装一个插件：Visual GC，用于观察GC情况。\n\n**主要功能：**\n\n- 生成/读取堆内存/线程快照\n- 查看JVM参数和系统属性\n- 查看运行中的虚拟机进程\n- 程序资源的实时监控\n- JMX代理连接、远程环境监控、CPU分析和内存分析\n\n官方地址：https://visualvm.github.io/index.html\n\n#### 查看堆dump文件\n\n![image-20210519132440728](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519132440728.png)\n\n#### 查看线程dump文件\n\n![image-20210519132543453](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519132543453.png)\n\n#### 查看CPU，内存抽样\n\n![image-20210519132722496](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519132722496.png)\n\n![image-20210519132711392](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210519132711392.png)\n\n### Eclipse MAT\n\nMAT（Memory Analyzer Tool）工具是一款功能强大的Java**堆内存分析器**。可以用于查找内存泄漏以及查看内存消耗情况。MAT是基于Eclipse开发的，不仅可以单独使用，还可以作为插件的形式嵌入在Eclipse中使用。是一款免费的性能分析工具，使用起来非常方便。\n\nMAT可以分析heap dump文件。在进行内存分析时，只要获得了反映当前设备内存映像的hprof文件，通过MAT打开就可以直观地看到当前的内存信息。一般说来，这些内存信息包含：\n\n- 所有的对象信息，包括对象实例、成员变量、存储于栈中的基本类型值和存储于堆中的其他对象的引用值。\n- 所有的类信息，包括classloader、类名称、父类、静态变量等\n- GCRoot到所有的这些对象的引用路径\n- 线程信息，包括线程的调用栈及此线程的线程局部变量（TLS）\n\nMAT 不是一个万能工具，它并不能处理所有类型的堆存储文件。但是比较主流的厂家和格式，例如Sun，HP，SAP 所采用的 HPROF 二进制堆存储文件，以及 IBM的 PHD 堆存储文件等都能被很好的解析。\n\n最吸引人的还是能够快速为开发人员生成内存泄漏报表，方便定位问题和分析问题。虽然MAT有如此强大的功能，但是内存分析也没有简单到一键完成的程度，很多内存问题还是需要我们从MAT展现给我们的信息当中通过经验和直觉来判断才能发现。\n\n官方地址： https://www.eclipse.org/mat/downloads.php\n\n![image-20211018212421955](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018212421955.png)\n\n![image-20211018212430167](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018212430167.png)\n\n![image-20211018212443302](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018212443302.png)\n\n![image-20211018212452056](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018212452056.png)\n\n### JProfiler\n\n在运行Java的时候有时候想测试运行时占用内存情况，这时候就需要使用测试工具查看了。在eclipse里面有 Eclipse Memory Analyzer tool（MAT）插件可以测试，而在IDEA中也有这么一个插件，就是JProfiler。JProfiler 是由 ej-technologies 公司开发的一款 Java 应用性能诊断工具。功能强大，但是收费。\n\n**特点：**\n\n- 使用方便、界面操作友好（简单且强大）\n- 对被分析的应用影响小（提供模板）\n- CPU，Thread，Memory分析功能尤其强大\n- 支持对jdbc，noSql，jsp，servlet，socket等进行分析\n- 支持多种模式（离线，在线）的分析\n- 支持监控本地、远程的JVM\n- 跨平台，拥有多种操作系统的安装版本\n\n**主要功能：**\n\n- 方法调用：对方法调用的分析可以帮助您了解应用程序正在做什么，并找到提高其性能的方法\n- 内存分配：通过分析堆上对象、引用链和垃圾收集能帮您修复内存泄露问题，优化内存使用\n- 线程和锁：JProfiler提供多种针对线程和锁的分析视图助您发现多线程问题\n- 高级子系统：许多性能问题都发生在更高的语义级别上。例如，对于JDBC调用，您可能希望找出执行最慢的SQL语句。JProfiler支持对这些子系统进行集成分析\n\n官网地址：https://www.ej-technologies.com/products/jprofiler/overview.html\n\n**数据采集方式：**\n\nJProfier数据采集方式分为两种：Sampling（样本采集）和Instrumentation（重构模式）\n\n- **Instrumentation**：这是JProfiler全功能模式。在class加载之前，JProfier把相关功能代码写入到需要分析的class的bytecode中，对正在运行的jvm有一定影响。\n  - 优点：功能强大。在此设置中，调用堆栈信息是准确的。\n  - 缺点：若要分析的class较多，则**对应用的性能影响较大**，CPU开销可能很高（取决于Filter的控制）。因此使用此模式一般配合Filter使用，只对特定的类或包进行分\n- **Sampling**：类似于样本统计，每隔一定时间（5ms）将每个线程栈中方法栈中的信息统计出来。\n  - 优点：对CPU的开销非常低，对应用影响小（即使你不配置任何Filter）\n  - 缺点：一些数据／特性不能提供（例如：方法的调用次数、执行时间）\n\n注：JProfiler本身没有指出数据的采集类型，这里的采集类型是针对方法调用的采集类型。因为JProfiler的绝大多数核心功能都依赖方法调用采集的数据，所以可以直接认为是JProfiler的数据采集类型。\n\n![image-20210520235805487](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210520235805487.png)\n\n#### 摇杆检测 Telemetries\n\n![image-20210521093956938](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521093956938.png)\n\n#### 内存视图分析 Live memory\n\nLive memory 内存剖析：class／class instance的相关信息。例如对象的个数，大小，对象创建的方法执行栈，对象创建的热点。\n\n- **所有对象 All Objects**：显示所有加载的类的列表和在堆上分配的实例数。只有Java 1.5（JVMTI）才会显示此视图。\n- **记录对象 Record Objects**：查看特定时间段对象的分配，并记录分配的调用堆栈。\n- **分配访问树 Allocation Call Tree**：显示一棵请求树或者方法、类、包或对已选择类有带注释的分配信息的J2EE组件。\n- **分配热点 Allocation Hot Spots**：显示一个列表，包括方法、类、包或分配已选类的J2EE组件。你可以标注当前值并且显示差异值。对于每个热点都可以显示它的跟踪记录树。\n- **类追踪器 Class Tracker**：类跟踪视图可以包含任意数量的图表，显示选定的类和包的实例与时间。\n\n可以通过对比分析，如果增加很多对象可能有几种情况：\n\n1. **频繁创建对象,死循环或循环次数多**\n2. **存在大对象（读取文件byte[]不要太大,边写边读,长时间不写出会导致byte[]过大）**\n3. **每次GC后，内存依次递增可能存在内存泄漏**\n\n![image-20210521145844721](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521145844721.png)\n\n- All Objects 所有对象：Size显示的是该实例对象的浅堆(不包含它引用字段的实际大小)\n- Recorded Objects 记录对象：可以动态看到类的对象变化情况 (默认不开启,开启后影响性能)\n\n![image-20210521145941114](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521145941114.png)\n\n- Allocation Call Tree 分配访问树：将执行方法所占时间显示成树 (默认不开启,开启后影响性能)\n\n![image-20210521150407870](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521150407870.png)\n\n- Allocation Hots Spots 分配热点：显示什么方法时间占比大\n\n![image-20210521150855253](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521150855253.png)\n\n- Class Tracker 类追踪器\n\n#### 堆遍历 Heap Walker\n\n通过对比发现对象增长过快,可以查看该对象的引用链\n\n![image-20210521153855310](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521153855310.png)\n\n![image-20210521154115936](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521154115936.png)\n\n![image-20210521154221915](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521154221915.png)\n\n#### CPU 视图 CPU views\n\nJProfiler 提供不同的方法来记录访问树以优化性能和细节。线程或者线程组以及线程状况可以被所有的视图选择。所有的视图都可以聚集到方法、类、包或J2EE组件等不同层上。\n\n- **访问树 Call Tree**：显示一个积累的自顶向下的树，树中包含所有在JVM中已记录的访问队列。JDBC，JMS和JNDI服务请求都被注释在请求树中。请求树可以根据Servlet和JSP对URL的不同需要进行拆分。\n- **热点 Hot Spots**：显示消耗时间最多的方法的列表。对每个热点都能够显示回溯树。该热点可以按照方法请求，JDBC，JMS和JNDI服务请求以及按照URL请求来进行计算。\n- **访问图 Call Graph**：显示一个从已选方法、类、包或J2EE组件开始的访问队列的图。\n- **方法统计 Method Statistis**：显示一段时间内记录的方法的调用时间细节。\n\n关于这种分析都可以从范围大的到范围小的 **package -> class -> method**\n\n![image-20210521154546655](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521154546655.png)\n\n![image-20211018213204845](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018213204845.png)\n\n![image-20211018213217786](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018213217786.png)\n\n#### 线程视图 Threads\n\nJProfiler通过对线程历史的监控判断其运行状态，并监控是否有线程阻塞产生，还能将一个线程所管理的方法以树状形式呈现。对线程剖析。\n\n- **线程历史 Thread History**：显示一个与线程活动和线程状态在一起的活动时间表。\n- **线程监控 Thread Monitor**：显示一个列表，包括所有的活动线程以及它们目前的活动状况。\n- **线程转储 Thread Dumps**：显示所有线程的堆栈跟踪。\n\n线程分析主要关心三个方面：\n\n- web容器的线程最大数。比如：Tomcat的线程容量应该略大于最大并发数。\n- 线程阻塞\n- 线程死锁\n\n查看线程运行状态，可以知道线程执行情况，比如main线程大部分时间在等待，少部分时间在运行\n\n![image-20210521154809697](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521154809697.png)\n\n![image-20211018213301773](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211018213301773.png)\n\n#### 监视器和锁 Monitors & Locks\n\n所有线程持有锁的情况以及锁的信息。观察JVM的内部线程并查看状态：\n\n- **死锁探测图表 Current Locking Graph**：显示JVM中的当前死锁图表。\n- **目前使用的监测器 Current Monitors**：显示目前使用的监测器并且包括它们的关联线程。\n- **锁定历史图表 Locking History Graph**：显示记录在JVM中的锁定历史。\n- **历史检测记录 Monitor History**：显示重大的等待事件和阻塞事件的历史记录。\n- **监控器使用统计 Monitor Usage Statistics**：显示分组监测，线程和监测类的统计监测数据\n\n\n\n### Arthas\n\n上述工具都必须在服务端项目进程中配置相关的监控参数，然后工具通过远程连接到项目进程，获取相关的数据。这样就会带来一些不便，比如**线上环境的网络是隔离的**，**本地的监控工具根本连不上线上环境**。并且类似于Jprofiler这样的商业工具，是需要付费的。那么有没有一款工具**不需要远程连接**，**也不需要配置监控参数**，同时也提供了丰富的性能监控数据呢？\n\n阿里巴巴开源的性能分析神器Arthas应运而生。\n\nArthas是Alibaba开源的Java诊断工具，深受开发者喜爱。在线排查问题，无需重启；动态跟踪Java代码；实时监控JVM状态。Arthas 支持JDK 6＋，支持Linux／Mac／Windows，采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决：\n\n- 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？\n- 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？\n- 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？\n- 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！\n- 是否有一个全局视角来查看系统的运行状况？\n- 有什么办法可以监控到JVM的实时运行状态？\n- 怎么快速定位应用的热点，生成火焰图？\n\n> 官方地址：https://arthas.aliyun.com/doc/quick-start.html\n\n#### 下载与使用\n\n下载方式：\n\n```\ncurl -O https://arthas.aliyun.com/arthas-boot.jar\n```\n\n安装方式：\n\n```\nwget https://io/arthas/arthas-boot.jar\nwget https://arthas/gitee/io/arthas-boot.jar\n```\n\nArthas只是一个java程序，所以可以直接用java -jar运行。\n\n```\n# 启动\njava -jar arthas-boot.jar\n\n# 关闭服务器(关闭所有客户端)\nstop\n\n# 关闭当前客户端\nquit\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521195844113.png)\n\n除了在命令行查看外，Arthas目前还支持 Web Console。在成功启动连接进程之后就已经自动启动，可以直接访问 http://127.0.0.1:8563/ 访问，页面上的操作模式和控制台完全一样。\n\n\n\n#### 基础命令\n\n- help——查看命令帮助信息\n- [cat](https://arthas.aliyun.com/doc/cat.html)——打印文件内容，和linux里的cat命令类似\n- [echo](https://arthas.aliyun.com/doc/echo.html)–打印参数，和linux里的echo命令类似\n- [grep](https://arthas.aliyun.com/doc/grep.html)——匹配查找，和linux里的grep命令类似\n- [base64](https://arthas.aliyun.com/doc/base64.html)——base64编码转换，和linux里的base64命令类似\n- [tee](https://arthas.aliyun.com/doc/tee.html)——复制标准输入到标准输出和指定的文件，和linux里的tee命令类似\n- [pwd](https://arthas.aliyun.com/doc/pwd.html)——返回当前的工作目录，和linux命令类似\n- cls——清空当前屏幕区域\n- session——查看当前会话的信息\n- [reset](https://arthas.aliyun.com/doc/reset.html)——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类\n- version——输出当前目标 Java 进程所加载的 Arthas 版本号\n- history——打印命令历史\n- quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响\n- stop——关闭 Arthas 服务端，所有 Arthas 客户端全部退出\n- [keymap](https://arthas.aliyun.com/doc/keymap.html)——Arthas快捷键列表及自定义快捷键\n\n#### JVM 相关\n\n- [dashboard](https://arthas.aliyun.com/doc/dashboard.html)——当前系统的实时数据面板\n- [thread](https://arthas.aliyun.com/doc/thread.html)——查看当前 JVM 的线程堆栈信息\n- [jvm](https://arthas.aliyun.com/doc/jvm.html)——查看当前 JVM 的信息\n- [sysprop](https://arthas.aliyun.com/doc/sysprop.html)——查看和修改JVM的系统属性\n- [sysenv](https://arthas.aliyun.com/doc/sysenv.html)——查看JVM的环境变量\n- [vmoption](https://arthas.aliyun.com/doc/vmoption.html)——查看和修改JVM里诊断相关的option\n- [perfcounter](https://arthas.aliyun.com/doc/perfcounter.html)——查看当前 JVM 的Perf Counter信息\n- [logger](https://arthas.aliyun.com/doc/logger.html)——查看和修改logger\n- [getstatic](https://arthas.aliyun.com/doc/getstatic.html)——查看类的静态属性\n- [ognl](https://arthas.aliyun.com/doc/ognl.html)——执行ognl表达式\n- [mbean](https://arthas.aliyun.com/doc/mbean.html)——查看 Mbean 的信息\n- [heapdump](https://arthas.aliyun.com/doc/heapdump.html)——dump java heap, 类似jmap命令的heap dump功能\n- [vmtool](https://arthas.aliyun.com/doc/vmtool.html)——从jvm里查询对象，执行forceGc\n\n#### class/classloader 相关\n\n- [sc](https://arthas.aliyun.com/doc/sc.html)——查看JVM已加载的类信息\n- [sm](https://arthas.aliyun.com/doc/sm.html)——查看已加载类的方法信息\n- [jad](https://arthas.aliyun.com/doc/jad.html)——反编译指定已加载类的源码\n- [mc](https://arthas.aliyun.com/doc/mc.html)——内存编译器，内存编译`.java`文件为`.class`文件\n- [retransform](https://arthas.aliyun.com/doc/retransform.html)——加载外部的`.class`文件，retransform到JVM里\n- [redefine](https://arthas.aliyun.com/doc/redefine.html)——加载外部的`.class`文件，redefine到JVM里\n- [dump](https://arthas.aliyun.com/doc/dump.html)——dump 已加载类的 byte code 到特定目录\n- [classloader](https://arthas.aliyun.com/doc/classloader.html)——查看classloader的继承树，urls，类加载信息，使用classloader去getResource\n\n#### monitor/watch/trace 相关\n\n> 请注意，这些命令，都通过字节码增强技术来实现的，会在指定类的方法中插入一些切面来实现数据统计和观测，因此在线上、预发使用时，请尽量明确需要观测的类、方法以及条件，诊断结束要执行 `stop` 或将增强过的类执行 `reset` 命令。\n\n- [monitor](https://arthas.aliyun.com/doc/monitor.html)——方法执行监控\n- [watch](https://arthas.aliyun.com/doc/watch.html)——方法执行数据观测\n- [trace](https://arthas.aliyun.com/doc/trace.html)——方法内部调用路径，并输出方法路径上的每个节点上耗时\n- [stack](https://arthas.aliyun.com/doc/stack.html)——输出当前方法被调用的调用路径\n- [tt](https://arthas.aliyun.com/doc/tt.html)——方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测\n\n\n\n### Java Misssion Control\n\n在Oracle收购Sun之前，Oracle的JRockit虚拟机提供了一款叫做 JRockit Mission Control 的虚拟机诊断工具。在Oracle收购sun之后，Oracle公司同时拥有了Hotspot和 JRockit 两款虚拟机。根据Oracle对于Java的战略，在今后的发展中，会将JRokit的优秀特性移植到Hotspot上。其中一个重要的改进就是在Sun的JDK中加入了JRockit的支持。\n\n在Oracle JDK 7.0之后，Mission Control这款工具已经绑定在Oracle JDK中发布。\n\n自Java11开始，本节介绍的JFR已经开源。但在之前的Java版本，JFR属于Commercial Feature通过Java虚拟机参数`-XX:+UnlockCommercialFeatures` 开启。\n\nJava Mission Control（简称JMC) ， Java官方提供的性能强劲的工具，是一个用于对 Java应用程序进行管理、监视、概要分析和故障排除的工具套件。它包含一个GUI客户端以及众多用来收集Java虚拟机性能数据的插件如 JMX Console（能够访问用来存放虚拟机齐个于系统运行数据的MXBeans）以及虚拟机内置的高效 profiling 工具 Java Flight Recorder（JFR）。\n\nJMC的另一个优点就是：**采用取样**，**而不是传统的代码植入技术，对应用性能的影响非常非常小**，**完全可以开着JMC来做压测（唯一影响可能是 full gc 多了）**。\n\n官方地址：https://github.com/JDKMissionControl/jmc\n\n![image-20211019183843470](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019183843470.png)\n\n#### Java Flight Recorder\n\nJava Flight Recorder是JMC的其中一个组件，能够以极低的性能开销收集Java虚拟机的性能数据。与其他工具相比，JFR的性能开销很小，在默认配置下平均低于1%。JFR能够直接访问虚拟机内的敌据并且不会影响虚拟机的优化。因此它非常适用于生产环境下满负荷运行的Java程序。\n\n**Java Flight Recorder 和 JDK Mission Control共同创建了一个完整的工具链**。JDK Mission Control 可对 Java Flight Recorder 连续收集低水平和详细的运行时信息进行高效、详细的分析。\n\n当启用时 JFR将记录运行过程中发生的一系列事件。其中包括Java层面的事件如线程事件、锁事件，以及Java虚拟机内部的事件，如新建对象，垃圾回收和即时编译事件。按照发生时机以及持续时间来划分，JFR的事件共有四种类型，它们分别为以下四种：\n\n- 瞬时事件（Instant Event) ，用户关心的是它们发生与否，例如异常、线程启动事件。 \n- 持续事件(Duration Event) ，用户关心的是它们的持续时间，例如垃圾回收事件。 \n- 计时事件(Timed Event) ，是时长超出指定阈值的持续事件。 \n- 取样事件（Sample Event)，是周期性取样的事件。 \n\n取样事件的其中一个常见例子便是方法抽样（Method Sampling），即每隔一段时问统计各个线程的栈轨迹。如果在这些抽样取得的栈轨迹中存在一个反复出现的方法，那么我们可以推测该方法是热点方法。\n\n![image-20211019183932731](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019183932731.png)\n\n![image-20211019183942592](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019183942592.png)\n\n![image-20211019183954641](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019183954641.png)\n\n![image-20211019184002347](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019184002347.png)\n\n![image-20211019184015271](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019184015271.png)\n\n![image-20211019184023306](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019184023306.png)\n\n![image-20211019184031773](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019184031773.png)\n\n\n\n#### Flame Graphs（火焰图）\n\n在追求极致性能的场景下，了解你的程序运行过程中cpu在干什么很重要，火焰图就是一种非常直观的展示CPU在程序整个生命周期过程中时间分配的工具。火焰图对于现代的程序员不应该陌生，这个工具可以非常直观的显示出调用找中的CPU消耗瓶颈。\n\n网上的关于Java火焰图的讲解大部分来自于Brenden Gregg的博客 [http://new.brendangregg.com/flamegraphs.html ](http://new.brendangregg.com/flamegraphs.html)\n\n![image-20211019184121880](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211019184121880.png)\n\n火焰图，简单通过x轴横条宽度来度量时间指标，y轴代表线程栈的层次。\n\n### Tprofiler\n\n> 案例： 使用JDK自身提供的工具进行JVM调优可以将下 TPS 由2.5提升到20（提升了7倍），并准确 定位系统瓶颈。\n\n系统瓶颈有：应用里静态对象不是太多、有大量的业务线程在频繁创建一些生命周期很长的临时对象，代码里有问题。\n\n那么，如何在海量业务代码里边准确定位这些性能代码？这里使用阿里开源工具 Tprofiler 来定位 这些性能代码，成功解决掉了GC 过于频繁的性能瓶预，并最终在上次优化的基础上将 TPS 再提升了4倍，即提升到100。\n\n- Tprofiler配置部署、远程操作、 日志阅谈都不太复杂，操作还是很简单的。但是其却是能够起到一针见血、立竿见影的效果，帮我们解决了GC过于频繁的性能瓶预。\n- Tprofiler最重要的特性就是**能够统汁出你指定时间段内 JVM 的 top method**。这些 top method 极有可能就是造成你 JVM 性能瓶颈的元凶。这是其他大多数 JVM 调优工具所不具备的，包括 JRockit Mission Control。JRokit 首席开发者 Marcus Hirt 在其私人博客《 Lom Overhead Method Profiling cith Java Mission Control》下的评论中曾明确指出  JRMC 井不支持 TOP 方法的统计。\n\n官方地址：http://github.com/alibaba/Tprofiler\n\n### Btrace\n\n常见的动态追踪工具有BTrace、HouseHD（该项目己经停止开发）、Greys-Anatomy（国人开发 个人开发者）、Byteman（JBoss出品），注意Java运行时追踪工具井不限干这几种，但是这几个是相对比较常用的。\n\nBTrace是SUN Kenai 云计算开发平台下的一个开源项目，旨在为java提供安全可靠的动态跟踪分析工具。先看一卜日Trace的官方定义：\n\n> 一个 Java 平台的安全的动态追踪工具，可以用来动态地追踪一个运行的 Java 程序。BTrace动态调整目标应用程序的类以注入跟踪代码（“字节码跟踪“）。\n\n其他小众监控工具：\n\n- **YourKit**\n- **JProbe**\n- **Spring Insight**\n\n\n\n## JVM 运行时参数\n\n> 官网地址：https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html\n\nJVM 的运行时参数可以分为三类：\n\n- 标准参数选项\n- -X参数选项\n- -XX:参数选项\n\n### 添加 JVM 参数选项\n\n运行 jar 包\n\n```bash\njava -Xms100m -Xmx100m -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -jar demo.jar\n```\n\nTomcat 运行 war 包\n\n```bash\n# linux下catalina.sh添加\nJAVA_OPTS=\"-Xms512M -Xmx1024M\"\n\n# windows下catalina.bat添加\nset \"JAVA_OPTS=-Xms512M -Xmx1024M\"\n```\n\n程序运行中\n\n```bash\n# 设置Boolean类型参数\njinfo -flag [+|-]<name> <pid>\n\n# 设置非Boolean类型参数\njinfo -flag <name>=<value> <pid>\n```\n\n\n\n### 类型一：标准参数选项\n\n特点：\n\n- 以`-`开头\n- 稳定，后续版本基本不变\n- 不常用\n\n``` shell\n> java -help\n用法: java [-options] class [args...]\n           (执行类)\n   或  java [-options] -jar jarfile [args...]\n           (执行 jar 文件)\n其中选项包括:\n    -d32          使用 32 位数据模型 (如果可用)\n    -d64          使用 64 位数据模型 (如果可用)\n    -server       选择 \"server\" VM\n                  默认 VM 是 server.\n\n    -cp <目录和 zip/jar 文件的类搜索路径>\n    -classpath <目录和 zip/jar 文件的类搜索路径>\n                  用 ; 分隔的目录, JAR 档案\n                  和 ZIP 档案列表, 用于搜索类文件。\n    -D<名称>=<值>\n                  设置系统属性\n    -verbose:[class|gc|jni]\n                  启用详细输出\n    -version      输出产品版本并退出\n    -version:<值>\n                  警告: 此功能已过时, 将在\n                  未来发行版中删除。\n                  需要指定的版本才能运行\n    -showversion  输出产品版本并继续\n    -jre-restrict-search | -no-jre-restrict-search\n                  警告: 此功能已过时, 将在\n                  未来发行版中删除。\n                  在版本搜索中包括/排除用户专用 JRE\n    -? -help      输出此帮助消息\n    -X            输出非标准选项的帮助\n    -ea[:<packagename>...|:<classname>]\n    -enableassertions[:<packagename>...|:<classname>]\n                  按指定的粒度启用断言\n    -da[:<packagename>...|:<classname>]\n    -disableassertions[:<packagename>...|:<classname>]\n                  禁用具有指定粒度的断言\n    -esa | -enablesystemassertions\n                  启用系统断言\n    -dsa | -disablesystemassertions\n                  禁用系统断言\n    -agentlib:<libname>[=<选项>]\n                  加载本机代理库 <libname>, 例如 -agentlib:hprof\n                  另请参阅 -agentlib:jdwp=help 和 -agentlib:hprof=help\n    -agentpath:<pathname>[=<选项>]\n                  按完整路径名加载本机代理库\n    -javaagent:<jarpath>[=<选项>]\n                  加载 Java 编程语言代理, 请参阅 java.lang.instrument\n    -splash:<imagepath>\n                  使用指定的图像显示启动屏幕\n有关详细信息, 请参阅 http://www.oracle.com/technetwork/java/javase/documentation/index.html。\n```\n\n\n\n**Server 模式和 Client 模式**\n\nHotspot JVM有两种模式，分别是server和client，分别通过`-server`和`-client`参数设置\n\n- 32位系统上，默认使用client类型的JVM。要想使用Server模式，机器配置至少有2个以上的CPU和2G以上的物理内存。client模式适用于对内存要求较小的桌面应用程序，默认使用Serial串行垃圾收集器\n- **64位系统上，只支持server模式的JVM**，适用于需要大内存的应用程序，默认使用并行垃圾收集器\n\n> 官网地址：https://docs.oracle.com/javase/8/docs/technotes/guides/vm/server-class.html\n\n如何知道系统默认使用的是哪种模式呢：通过`java -version`命令：可以看到Server VM字样，代表当前系统使用是Server模式\n\n```shell\n> java -version\njava version \"1.8.0_201\"\nJava(TM) SE Runtime Environment (build 1.8.0_201-b09)\nJava HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)\n```\n\n\n\n### 类型二：-X参数选项\n\n特点：\n\n- 以`-X`开头\n- 较稳定，后续版本可能改变\n\n``` shell\n> java -X\n    -Xmixed           混合模式执行 (默认)\n    -Xint             仅解释模式执行\n    -Xbootclasspath:<用 ; 分隔的目录和 zip/jar 文件>\n                      设置搜索路径以引导类和资源\n    -Xbootclasspath/a:<用 ; 分隔的目录和 zip/jar 文件>\n                      附加在引导类路径末尾\n    -Xbootclasspath/p:<用 ; 分隔的目录和 zip/jar 文件>\n                      置于引导类路径之前\n    -Xdiag            显示附加诊断消息\n    -Xnoclassgc       禁用类垃圾收集\n    -Xincgc           启用增量垃圾收集\n    -Xloggc:<file>    将 GC 状态记录在文件中 (带时间戳)\n    -Xbatch           禁用后台编译\n    -Xms<size>        设置初始 Java 堆大小\n    -Xmx<size>        设置最大 Java 堆大小\n    -Xss<size>        设置 Java 线程堆栈大小\n    -Xprof            输出 cpu 配置文件数据\n    -Xfuture          启用最严格的检查, 预期将来的默认值\n    -Xrs              减少 Java/VM 对操作系统信号的使用 (请参阅文档)\n    -Xcheck:jni       对 JNI 函数执行其他检查\n    -Xshare:off       不尝试使用共享类数据\n    -Xshare:auto      在可能的情况下使用共享类数据 (默认)\n    -Xshare:on        要求使用共享类数据, 否则将失败。\n    -XshowSettings    显示所有设置并继续\n    -XshowSettings:all\n                      显示所有设置并继续\n    -XshowSettings:vm 显示所有与 vm 相关的设置并继续\n    -XshowSettings:properties\n                      显示所有属性设置并继续\n    -XshowSettings:locale\n                      显示所有与区域设置相关的设置并继续\n\n-X 选项是非标准选项, 如有更改, 恕不另行通知。\n```\n\n其中，**重点需要记忆的参数有**：\n\n1、和解释器相关的参数：\n\n- `-Xint`：只使用解释器\n- `-Xcomp`：只使用编译器\n- `-Xmixed`：混用（默认选项），前期解释器解释字节码执行，等程序运行起来后后端编译器缓存热点代码，加速执行效率\n\n2、**和堆内存相关的参数**：\n\n- `-Xss`：设置**线程**（栈）内存大小，等效于`-XX:ThreadStackSize`（记忆：Stack Size）\n- `-Xms`：设置堆内存**初始**大小，等效于`-XX:InitalHeapSize`（记忆：Memory Size）\n- `-Xmx`：设置堆内存**最大**大小，等效于 `-XX:MaxHeapSize`（记忆：Memory maX）\n- `-Xmn`：设置**年轻代**内存，等同于`-XX:NewSize`+`-XX:MaxNewSize`（记忆：Memory New）\n\n3、日志相关：\n\n- `-Xloggc:<file>`：将 GC 状态记录在文件中 （带时间戳）；可以使用 **GCeasy** 网站分析 GC 记录，[GC 日志分析](#GC-日志分析)\n\n---\n\n`-Xms` 和 `-Xmx` 两个参数设置相同的值，目的是为了能够在每次GC后不需要再重新计算堆区要分配的大小，从而提高性能。\n\n如果二者设置不相同，则每次GC后，会根据当前GC的效果动态调整堆区的大小：回收效果好 -> 减小堆区大小；回收效果差 -> 增大堆区大小\n\n---\n\n\n\n### 类型三：-XX:参数选项\n\n特点：\n\n- 以`-XX:`开头\n- 不稳定，后续版本会改动\n- 常用\n\n**Boolean 类型格式**\n\n```bash\n-XX:+<option>  # 启用option属性，例如 -XX:+UseParallelGC：使用parallel垃圾收集器\n-XX:-<option>  # 禁用option属性，例如 -XX:-UseParallelGC：不使用parallel垃圾收集器\n```\n\n**非 Boolean 类型格式**\n\n```bash\n-XX:<option>=<number>  # 设置option数值，可以带单位如k/K/m/M/g/G，例如 -XX:SurvivorRatio=8 设置新生代中Eden区与survivor区占比为: 8:1:1\n-XX:<option>=<string>  # 设置option字符值，例如 -XX:HeapDumpPath=/usr/local/cl.hprof 设置堆Dump快照放在此地址\n```\n\n其中，**重点需要记忆的参数有**：\n\n- `-XX:+PrintFlagsFinal`：打印所有-XX选项的实际值\n- `-XX:NewRatio=2`：设置老年代与年轻代的比例，默认为2\n- `-XX:SurvivorRatio=8`：设置Eden区与Survivor区的比值，默认为8（虽然默认是8，但是因为默认开启了 `-XX:+UseAdaptiveSizePolicy` 自动调整策略，导致实际的新生代内比例可能不是8）\n- `-XX:+UseAdaptiveSizePolicy`：设置堆空间大小比例自适应，默认开启\n\n\n\n\n\n\n\n#### 打印设置的-XX选项及值\n\n``` bash\n-XX:+PrintCommandLineFlags  # 程序运行时JVM默认设置或用户手动设置的XX选项\n-XX:+PrintFlagsInitial      # 打印所有XX选项的默认值\n-XX:+PrintFlagsFinal        # 打印所有XX选项的实际值\n-XX:+PrintVMOptions         # 打印JVM的参数\n```\n\n`-XX:+PrintCommandLineFlags` ：打印**命令行启动时添加**的-XX选项或JVM自动设置的-XX选项\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521233837255.png)\n\n`-XX:+PrintFlagsInitinal` ：打印出所有-XX选项**默认值**\n\n![image-20210521234011514](https://gitee.com/tcl192243051/studyJVM/raw/master/4_%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%AF%87/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E5%8F%82%E6%95%B0.assets/image-20210521234011514.png)\n\n`-XX:+PrintFlagsFinal` ：打印出-XX选项**最终**在程序运行时的值（使用 `jinfo -flag 修改参数 pid` 进行修改）\n\n![image-20210521234301291](https://gitee.com/tcl192243051/studyJVM/raw/master/4_%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E7%AF%87/JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E5%8F%82%E6%95%B0.assets/image-20210521234301291.png)\n\n- ``-XX:+PrintVMOption` 打印JVM参数\n\n  ![image-20210521234626600](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20210521234626600.png)\n\n\n\n#### 堆、栈、方法区等内存大小设置\n\n``` bash\n# 栈\n-Xss128k <==> -XX:ThreadStackSize=128k       # 设置线程栈的大小为128K\n\n# 堆\n-Xms2048m <==> -XX:InitialHeapSize=2048m     # 设置JVM初始堆内存为2048M\n-Xmx2048m <==> -XX:MaxHeapSize=2048m         # 设置JVM最大堆内存为2048M\n-Xmn2g <==> -XX:NewSize=2g -XX:MaxNewSize=2g # 设置年轻代大小为2G\n-XX:SurvivorRatio=8                          # 设置Eden区与Survivor区的比值，默认为8\n-XX:NewRatio=2                               # 设置老年代与年轻代的比例，默认为2\n-XX:+UseAdaptiveSizePolicy                   # 设置大小比例自适应，默认开启\n-XX:PretenureSizeThreadshold=1024            # 设置让大于此阈值的对象直接分配在老年代，只对Serial、ParNew收集器有效\n-XX:MaxTenuringThreshold=15                  # 设置新生代晋升老年代的年龄限制，默认为15\n-XX:TargetSurvivorRatio                      # 设置MinorGC结束后Survivor区占用空间的期望比例\n\n# 方法区\n-XX:MetaspaceSize / -XX:PermSize=256m        # 设置元空间/永久代初始值为256M\n-XX:MaxMetaspaceSize / -XX:MaxPermSize=256m  # 设置元空间/永久代最大值为256M\n-XX:+UseCompressedOops                       # 使用压缩对象\n-XX:+UseCompressedClassPointers              # 使用压缩类指针\n-XX:CompressedClassSpaceSize                 # 设置Klass Metaspace的大小，默认1G\n\n# 直接内存\n-XX:MaxDirectMemorySize                      # 指定DirectMemory容量，默认等于Java堆最大值\n```\n\n\n\n#### OutOfMemory 相关的选项\n\n``` bash\n-XX:+HeapDumpOnOutMemoryError    # 内存出现OOM时生成Heap转储文件，两者互斥\n-XX:+HeapDumpBeforeFullGC        # 出现FullGC时生成Heap转储文件，两者互斥\n-XX:HeapDumpPath=<path>          # 指定heap转储文件的存储路径，默认当前目录\n-XX:OnOutOfMemoryError=<path>    # 指定可行性程序或脚本的路径，当发生OOM时执行脚本\n```\n\n\n\n#### 垃圾收集器相关选项\n\n首先需了解垃圾收集器之间的搭配使用关系：\n\n- 红色虚线表示在jdk8时被Deprecate，jdk9时被删除\n- 绿色虚线表示在jdk14时被Deprecate\n- 绿色虚框表示在jdk9时被Deprecate，jdk14时被删除\n\n![image-20200713094745366](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200713094745366.png)\n\n``` bash\n# Serial回收器 \n-XX:+UseSerialGC           # 年轻代使用Serial GC，老年代使用Serial Old GC\n\n# ParNew回收器\n-XX:+UseParNewGC            # 年轻代使用ParNew GC\n-XX:ParallelGCThreads       # 设置年轻代并行收集器的线程数。\n                            # 一般地，最好与CPU数量相等，以避免过多的线程数影响垃圾收集性能。\n                       \n# Parallel回收器 \n-XX:+UseParallelGC          # 年轻代使用 Parallel Scavenge GC，互相激活\n-XX:+UseParallelOldGC       # 老年代使用 Parallel Old GC，互相激活\n-XX:ParallelGCThreads\n-XX:MaxGCPauseMillis        # 设置垃圾收集器最大停顿时间（即STW的时间），单位是毫秒。\n                            # 为了尽可能地把停顿时间控制在MaxGCPauseMills以内，收集器在工作时会调整Java堆大小或者其他一些参数。\n                            # 对于用户来讲，停顿时间越短体验越好；但是服务器端注重高并发，整体的吞吐量。\n                            # 所以服务器端适合Parallel，进行控制。该参数使用需谨慎。\n\n-XX:GCTimeRatio             # 垃圾收集时间占总时间的比例（1 / (N＋1)），用于衡量吞吐量的大小\n                            # 取值范围（0,100），默认值99，也就是垃圾回收时间不超过1％。\n                            # 与前一个-XX：MaxGCPauseMillis参数有一定矛盾性。暂停时间越长，Radio参数就容易超过设定的比例。\n\n-XX:+UseAdaptiveSizePolicy  # 设置Parallel Scavenge收集器具有自适应调节策略。\n                            # 在这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数会被自动调整，以达到在堆大小、吞吐量和停顿时间之间的平衡点。\n                            # 在手动调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMills），\n                            # 让虚拟机自己完成调优工作。\n```\n\n其中，并行GC线程的线程数的经验公式：\n\n![image-20211020104915344](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211020104915344.png)\n\n``` bash\n# CMS回收器\n-XX:+UseConcMarkSweepGC             # 年轻代使用CMS GC。开启该参数后会自动将-XX：＋UseParNewGC打开。\n                                    # 即：ParNew（Young区）+ CMS（Old区）+ Serial Old的组合\n-XX:CMSInitiatingOccupanyFraction   # 设置堆内存使用率的阈值，一旦达到该阈值，便开始进行回收。JDK5及以前版本的默认值为68，DK6及以上版本默认值为92％。\n                                    # 如果内存增长缓慢，则可以设置一个稍大的值，大的阈值可以有效降低CMS的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。\n                                    # 反之，如果应用程序内存使用率增长很快，则应该降低这个阈值，以避免频繁触发老年代串行收集器。\n                                    # 因此通过该选项便可以有效降低Fu1l GC的执行次数。\n\n-XX:+UseCMSInitiatingOccupancyOnly  # 是否动态可调，使CMS一直按CMSInitiatingOccupancyFraction设定的值启动\n\n-XX:+UseCMSCompactAtFullCollection  # 用于指定在执行完Full GC后对内存空间进行压缩整理以此避免内存碎片的产生。\n                                    # 不过由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变得更长了。\n\n-XX:CMSFullGCsBeforeCompaction      # 设置在执行多少次Full GC后对内存空间进行压缩整理。\n\n-XX:ParallelCMSThreads              # 设置CMS的线程数量。CMS 默认启动的线程数是(ParallelGCThreads＋3)/4，\n                                    # ParallelGCThreads 是年轻代并行收集器的线程数。\n                                    # 当 CPU 资源比较紧张时，受到CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。\n\n-XX:ConcGCThreads                   # 设置并发垃圾收集的线程数，默认该值是基于ParallelGCThreads计算出来的\n-XX:+CMSScavengeBeforeRemark        # 强制hotspot在cms remark阶段之前做一次minor gc，用于提高remark阶段的速度\n-XX:+CMSClassUnloadingEnable        # 如果有的话，启用回收Perm 区（JDK8之前）\n-XX:+CMSParallelInitialEnabled      # 用于开启CMS initial-mark阶段采用多线程的方式进行标记\n                                    # 用于提高标记速度，在Java8开始已经默认开启\n-XX:+CMSParallelRemarkEnabled       # 用户开启CMS remark阶段采用多线程的方式进行重新标记，默认开启\n-XX:+ExplicitGCInvokesConcurrent    # 这两个参数用户指定hotspot虚拟在执行System.gc()时使用CMS周期\n-XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses \n                                    \n-XX:+CMSPrecleaningEnabled          # 指定CMS是否需要进行Pre cleaning阶段\n```\n\n``` bash\n# G1回收器\n-XX:+UseG1GC                        # 手动指定使用G1收集器执行内存回收任务。\n-XX:G1HeapRegionSize                # 设置每个Region的大小。值是2的幂，范围是1MB到32MB之间，\n                                    # 目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000。\n-XX:MaxGCPauseMillis                # 设置期望达到的最大GC停顿时间指标（JVM会尽力实现，但不保证达到）。默认值是200ms\n-XX:ParallelGCThread                # 设置STW时GC线程数的值。最多设置为8\n-XX:ConcGCThreads                   # 设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGCThreads）的1/4左右。\n-XX:InitiatingHeapOccupancyPercent  # 设置触发并发GC周期的Java堆占用率阈值。超过此值，就触发GC。默认值是45。\n-XX:G1NewSizePercent                # 新生代占用整个堆内存的最小百分比（默认5％）\n-XX:G1MaxNewSizePercent             # 新生代占用整个堆内存的最大百分比（默认60％）\n-XX:G1ReservePercent=10             # 保留内存区域，防止 to space（Survivor中的to区）溢出\n```\n\n**注意**：使用分代收集器G1时最好不要使用`-XX:NewRatio` ， `-Xmn`这种指定年轻代内存大小的参数，而是应该交给G1自动计算年轻代所占的内存大小以满足其**低延迟的暂停时间**，否则G1里的 `-XX:MaxGCPauseMillis` 可能无法实现。\n\n怎么选择垃圾回收器？\n\n- 优先让JVM自适应，调整堆的大小\n- 串行收集器：内存小于100M；单核、单机程序，并且没有停顿时间的要求\n- 并行收集器：多CPU、高吞吐量、允许停顿时间超过1秒\n- 并发收集器：多CPU、追求低停顿时间、快速响应（比如延迟不能超过1秒，如互联网应用）\n- 官方推荐G1，性能高。现在互联网的项目，基本都是使用G1\n\n\n\n### GC 日志相关选项\n\n``` bash\n-XX:+PrintGC <==> -verbose:gc          # 打印简要日志信息\n-XX:+PrintGCDetails                    # 打印详细日志信息\n-XX:+PrintGCTimeStamps                 # 打印程序启动到GC发生的时间，搭配-XX:+PrintGCDetails使用\n-XX:+PrintGCDateStamps                 # 打印GC发生时的时间戳，搭配-XX:+PrintGCDetails使用\n-XX:+PrintHeapAtGC                     # 打印GC前后的堆信息，如下图\n-Xloggc:<file>                         # 输出GC导指定路径下的文件中\n-XX:+TraceClassLoading                 # 监控类的加载\n-XX:+PrintGCApplicationStoppedTime     # 打印GC时线程的停顿时间\n-XX:+PrintGCApplicationConcurrentTime  # 打印垃圾收集之前应用未中断的执行时间\n-XX:+PrintReferenceGC                  # 打印回收了多少种不同引用类型的引用\n-XX:+PrintTenuringDistribution         # 打印JVM在每次MinorGC后当前使用的Survivor中对象的年龄分布\n-XX:+UseGCLogFileRotation              # 启用GC日志文件的自动转储\n-XX:NumberOfGCLogFiles=1               # 设置GC日志文件的循环数目\n-XX:GCLogFileSize=1M                   # 设置GC日志文件的大小\n```\n\n![image-20211020105935721](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20211020105935721.png)\n\n\n\n### 其他参数\n\n``` bash\n-XX:+DisableExplicitGC     # 禁用hotspot执行System.gc()，默认禁用\n-XX:ReservedCodeCacheSize=<n>[g|m|k]、-XX:InitialCodeCacheSize=<n>[g|m|k]  # 指定代码缓存的大小\n-XX:+UseCodeCacheFlushing  # 放弃一些被编译的代码，避免代码缓存被占满时JVM切换到interpreted-only的情况\n-XX:+DoEscapeAnalysis      # 开启逃逸分析\n-XX:+UseBiasedLocking      # 开启偏向锁\n-XX:+UseLargePages         # 开启使用大页面\n-XX:+PrintTLAB             # 打印TLAB的使用情况\n-XX:TLABSize               # 设置TLAB大小\n```\n\n\n\n### 通过 Java 代码获取 JVM 参数\n\nJava提供了`java.lang.management`包用于监视和管理Java虚拟机和Java运行时中的其他组件，它允许本地或远程监控和管理运行的Java虚拟机。其中`ManagementFactory`类较为常用，另外`Runtime`类可获取内存、CPU核数等相关的数据。通过使用这些api，可以监控应用服务器的堆内存使用情况，设置一些阈值进行报警等处理。\n\n``` java\npublic class MemoryMonitor {\n    public static void main(String[] args) {\n        MemoryMXBean memorymbean = ManagementFactory.getMemoryMXBean();\n        MemoryUsage usage = memorymbean.getHeapMemoryUsage();\n        System.out.println(\"INIT HEAP: \" + usage.getInit() / 1024 / 1024 + \"m\");\n        System.out.println(\"MAX HEAP: \" + usage.getMax() / 1024 / 1024 + \"m\");\n        System.out.println(\"USE HEAP: \" + usage.getUsed() / 1024 / 1024 + \"m\");\n        System.out.println(\"\\nFull Information:\");\n        System.out.println(\"Heap Memory Usage: \" + memorymbean.getHeapMemoryUsage());\n        System.out.println(\"Non-Heap Memory Usage: \" + memorymbean.getNonHeapMemoryUsage());\n\n        System.out.println(\"=======================通过java来获取相关系统状态============================ \");\n        System.out.println(\"当前堆内存大小totalMemory \" + (int) Runtime.getRuntime().totalMemory() / 1024 / 1024 + \"m\");// 当前堆内存大小\n        System.out.println(\"空闲堆内存大小freeMemory \" + (int) Runtime.getRuntime().freeMemory() / 1024 / 1024 + \"m\");// 空闲堆内存大小\n        System.out.println(\"最大可用总堆内存maxMemory \" + Runtime.getRuntime().maxMemory() / 1024 / 1024 + \"m\");// 最大可用总堆内存大小\n\n    }\n}\n```\n\n\n\n## GC 日志分析\n\n### GC 分类\n\n针对HotSpot VM的实现，它里面的GC按照回收区域又分为两大种类型：一种是部分收集（Partial GC），一种是整堆收集（Full GC）\n\n-  部分收集（Partial GC）：不是完整收集整个Java堆的垃圾收集。其中又分为： \n   -  新生代收集（Minor GC / Young GC）：只是新生代（Eden / S0, S1）的垃圾收集\n   -  老年代收集（Major GC / Old GC）：只是老年代的垃圾收集。目前，只有CMS GC会有单独收集老年代的行为。注意，很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。\n-  混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集。目前，只有G1 GC会有这种行为 \n-  整堆收集（Full GC）：收集整个java堆和方法区的垃圾收集。 \n\n\n\n### 参数解析\n\n**通过阅读GC日志，我们可以了解Java虚拟机内存分配与回收策略。**\n\n内存分配与垃圾回收的参数列表\n\n- `-XX:+PrintGC `：输出GC日志。类似：`-verbose:gc`\n- `-XX:+PrintGCDetails `：输出GC的详细日志\n- `-XX:+PrintGCTimestamps` ：输出GC的时间戳（以基准时间的形式）\n- `-XX:+PrintGCDatestamps` ：输出GC的时间戳（以日期的形式，如2013-05-04T21: 53: 59.234 +0800）\n- `-XX:+PrintHeapAtGC` ：在进行GC的前后打印出堆的信息\n- `-Xloggc:…/logs/gc.log` ：日志文件的输出路径\n\n> **verbose:gc**\n\n打开GC日志的 JVM 参数：\n\n```bash\n-verbose:gc\n```\n\n这个只会显示总的GC堆的变化，如下：\n\n![image-20200714081610474](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714081610474.png)\n\n参数解析：\n\n![image-20200714081622526](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714081622526.png)\n\n> **PrintGCDetails**\n\n打开GC日志\n\n```bash\n-XX:+PrintGCDetails\n```\n\n输入信息如下：\n\n![image-20200714081909309](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714081909309.png)\n\n参数解析：\n\n![image-20200714081925767](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714081925767.png)\n\n> **PrintGCTimestamps 和 PrintGCDatestamps**\n\n加上这两个参数后，打印的GC日志就会带上日期时间信息。\n\n### GC 日志补充说明\n\n- “[GC”和”[Full GC”说明了这次垃圾收集的停顿类型，如果有”Full”则说明GC发生了”Stop The World”\n- 使用Serial收集器在新生代的名字是Default New Generation，因此显示的是”[DefNew”\n- 使用ParNew收集器在新生代的名字会变成”[ParNew”，意思是”Parallel New Generation”\n- 使用Parallel scavenge收集器在新生代的名字是”[PSYoungGen”\n- 老年代的收集和新生代道理一样，名字也是收集器决定的\n- 使用G1收集器的话，会显示为”garbage-first heap”\n- Allocation Failure表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了。\n- [ PSYoungGen: 5986K->696K(8704K) ] 5986K->704K (9216K)\n  - 中括号内：GC回收前年轻代大小，回收后大小，（年轻代总大小）\n  - 括号外：GC回收前年轻代和老年代大小，回收后大小，（年轻代和老年代总大小）\n- user代表用户态回收耗时，sys内核态回收耗时，real实际耗时。由于多核线程切换的原因，时间总和可能会超过real时间\n\n### Young GC\n\n![image-20200714082555688](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714082555688.png)\n\n### Full GC\n\n![image-20200714082714690](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714082714690.png)\n\n### GC 日志结构剖析\n\n**透过日志看垃圾收集器**\n\n-  Serial收集器：新生代显示 \"[DefNew\"，即 Default New Generation \n-  ParNew收集器：新生代显示 \"[ParNew\"，即 Parallel New Generation \n-  Parallel Scavenge收集器：新生代显示\"[PSYoungGen\"，JDK1.7使用的即PSYoungGen \n-  Parallel Old收集器：老年代显示\"[ParoldGen\" \n-  G1收集器：显示”garbage-first heap“ \n\n\n\n**透过日志看 GC 原因**\n\n- Allocation Failure：表明本次引起GC的原因是因为新生代中没有足够的区域存放需要分配的数据\n- Metadata GC Threshold：Metaspace区不够用了\n- FErgonomics：JVM自适应调整导致的GC\n- System：调用了System.gc()方法\n\n\n\n**透过日志看 GC 前后情况**\n\n通过图示，我们可以发现GC日志格式的规律一般都是：GC前内存占用-＞GC后内存占用（该区域内存总大小）\n\n```java\n[PSYoungGen: 5986K->696K (8704K) ] 5986K->704K (9216K)\n```\n\n-  中括号内：GC回收前年轻代堆大小，回收后大小，（年轻代堆总大小） \n-  括号外：GC回收前年轻代和老年代大小，回收后大小，（年轻代和老年代总大小） \n\n**注意**：Minor GC堆内存总容量 = **9/10** 年轻代 + 老年代。原因是Survivor区只计算from部分，而JVM默认年轻代中Eden区和Survivor区的比例关系，Eden:S0:S1=8:1:1。\n\n> 面试题：为什么GC日志里显示的堆内存总容量比 `-Xms` 设置的要小？\n>\n> 因为GC日志里只显示了 **9/10** 年轻代 + 老年代，自然比设置的值要小。补充：这里的 9/10 要根据实际情况来定，可能开了自适应调整策略会导致该值变化。\n\n\n\n**透过日志看 GC 时间**\n\nGC日志中有三个时间：user，sys和real\n\n- user：进程执行用户态代码（核心之外）所使用的时间。这是执行此进程所使用的实际CPU 时间，其他进程和此进程阻塞的时间并不包括在内。在垃圾收集的情况下，表示GC线程执行所使用的 CPU 总时间。\n- sys：进程在内核态消耗的 CPU 时间，即在内核执行系统调用或等待系统事件所使用的CPU 时间\n- real：程序从开始到结束所用的时钟时间。这个时间包括其他进程使用的时间片和进程阻塞的时间（比如等待 I/O 完成）。对于并行gc，这个数字应该接近（用户时间＋系统时间）除以垃圾收集器使用的线程数。\n\n由于多核的原因，一般的GC事件中，real time是小于sys time＋user time的，因为一般是多个线程并发的去做GC，所以real time是要小于sys＋user time的。如果real＞sys＋user的话，则你的应用可能存在下列问题：IO负载非常重或CPU不够用。\n\n### GC 回收举例\n\n我们编写一个程序，用来说明GC收集的过程\n\n```java\npublic class GCUseTest {\n    static final Integer _1MB = 1024 * 1024;\n    public static void main(String[] args) {\n        byte [] allocation1, allocation2, allocation3, allocation4;\n        allocation1 = new byte[2 *_1MB];\n        allocation2 = new byte[2 *_1MB];\n        allocation3 = new byte[2 *_1MB];\n        allocation4 = new byte[4 *_1MB];\n    }\n}\n```\n\n我们设置JVM启动参数\n\n```bash\n-Xms10m -Xmx10m -XX:+PrintGCDetails\n```\n\n首先我们会将3个2M的数组存放到Eden区，然后后面4M的数组来了后，将无法存储，因为Eden区只剩下2M的剩余空间了，那么将会进行一次Young GC操作，将原来Eden区的内容，存放到Survivor区，但是Survivor区也存放不下，那么就会直接晋级存入Old 区\n\n![image-20200714083332238](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714083332238.png)\n\n然后我们将4M对象存入到Eden区中\n\n![image-20200714083526790](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714083526790.png)\n\n### 常用日志分析工具\n\n**保存日志文件**\n\n**JVM参数**：`-XLoggc:./logs/gc.log`， ./ 表示当前目录，在 IDEA中程序运行的当前目录是工程的根目录，而不是模块的根目录\n\n可以用一些工具去分析这些GC日志 gc.log。常用的日志分析工具有：GCViewer、GCEasy、GCHisto、GCLogViewer、Hpjmeter、garbagecat等\n\n**推荐：GCeasy**\n\n在线分析网址：gceasy.io\n\n![image-20200714084726824](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714084726824.png)\n\n**GCViewer**\n\n![image-20200714084921184](/images/%E3%80%90JVM%E3%80%91JVM%E7%9B%91%E6%8E%A7%E5%8F%8A%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7/image-20200714084921184.png)\n\n\n\n\n\n\n## 补充：OQL\n\nVisual VM 和 MAT 都支持一种类似于SQL的查询语言OQL（Object Query Language）。OQL使用类SQL语法，可以在堆中进行对象的查找和筛选。\n\n### SELECT 子句\n\n在MAT中，Select子句的格式与SQL基本一致，用于指定要显示的列。Select子句中可以使用“＊”，查看结果对象的引用实例（相当于outgoing references）。\n\n```sql\nSELECT * FROM java.util.Vector v\n```\n\n使用“\n\nOBJECTS”关键字，可以将返回结果集中的项以对象的形式显示。\n\n```sql\nSELECT objects v.elementData FROM java.util.Vector v\n\nSELECT OBJECTS s.value FROM java.lang.String s\n```\n\n在Select子句中，使用“AS RETAINED SET”关键字可以得到所得对象的保留集。\n\n```sql\nSELECT AS RETAINED SET *FROM com.zhao.mat.Student\n```\n\n“DISTINCT”关键字用于在结果集中去除重复对象。\n\n```sql\nSELECT DISTINCT OBJECTS classof(s) FROM java.lang.String s\n```\n\n### FROM 子句\n\nFrom子句用于指定查询范围，它可以指定类名、正则表达式或者对象地址。\n\n```sql\nSELECT * FROM java.lang.String s\n```\n\n使用正则表达式，限定搜索范围，输出所有com.zhao包下所有类的实例\n\n```sql\nSELECT * FROM \"com\\.zhao\\..*\"\n```\n\n使用类的地址进行搜索。使用类的地址的好处是可以区分被不同ClassLoader加载的同一种类型。\n\n```sql\nselect * from 0x37a0b4d\n```\n\n### WHERE 子句\n\nWhere子句用于指定OQL的查询条件。OQL查询将只返回满足Where子句指定条件的对象。Where子句的格式与传统SQL极为相似。\n\n返回长度大于10的char数组。\n\n```sql\nSELECT *FROM Ichar[] s WHERE s.@length>10\n```\n\n返回包含“java”子字符串的所有字符串，使用“LIKE”操作符，“LIKE”操作符的操作参数为正则表达式。\n\n```sql\nSELECT * FROM java.lang.String s WHERE toString(s) LIKE \".*java.*\"\n```\n\n返回所有value域不为null的字符串，使用“＝”操作符。\n\n```sql\nSELECT * FROM java.lang.String s where s.value!=null\n```\n\n返回数组长度大于15，并且深堆大于1000字节的所有Vector对象。\n\n```sql\nSELECT * FROM java.util.Vector v WHERE v.elementData.@length>15 AND v.@retainedHeapSize>1000\n```\n\nWhere子句用于指定OQL的查询条件。OQL查询将只返回满足Where子句指定条件的对象。Where子句的格式与传统SQL极为相似。\n\n返回长度大于10的char数组。\n\n```sql\nSELECT *FROM Ichar[] s WHERE s.@length>10\n```\n\n返回包含“java”子字符串的所有字符串，使用“LIKE”操作符，“LIKE”操作符的操作参数为正则表达式。\n\n```sql\nSELECT * FROM java.lang.String s WHERE toString(s) LIKE \".*java.*\"\n```\n\n返回所有value域不为null的字符串，使用“＝”操作符。\n\n```sql\nSELECT * FROM java.lang.String s where s.value!=null\n```\n\n返回数组长度大于15，并且深堆大于1000字节的所有Vector对象。\n\n```sql\nSELECT * FROM java.util.Vector v WHERE v.elementData.@length>15 AND v.@retainedHeapSize>1000\n```\n\n\n\n\n\n## 相关面试题\n\n支付宝：\n\n- 三面：JVM性能调优都做了什么？\n\n 小米：\n\n- 有做过JVM内存优化吗？从SQL、JVM、架构、数据库四个方面讲讲优化思路\n\n 蚂蚁金服：\n\n- JVM的编译优化\n- JVM性能调优都做了什么\n- JVM诊断调优工具用过哪些？\n- 二面：jvm怎样调优，堆内存、栈空间设置多少合适\n- 三面：JVM相关的分析工具使用过的有哪些？具体的性能调优步骤如何\n\n 阿里：\n\n- 如何进行JVM调优？有哪些方法？\n- 如何理解内存泄漏问题？有哪些情况会导致内存泄漏？如何解决？\n\n字节跳动：\n\n- 三面：JVM如何调优、参数怎么调？\n\n拼多多：\n\n- 从SQL、JVM、架构、数据库四个方面讲讲优化思路\n\n京东：\n\n- JVM诊断调优工具用过哪些？\n- 每秒几十万并发的秒杀系统为什么会频繁发生GC？\n- 日均百万级交易系统如何优化JVM？\n- 线上生产系统OOM如何监控及定位与解决？\n- 高并发系统如何基于G1垃圾回收器优化性能？\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【数据结构】图","url":"/2021/10/17/【数据结构】图/","content":"\n## 图的数据结构\n\n用 `Graph` 代表图的数据结构，其又由 `Node` 和 `Edge` 两种数据结构组成。\n\n```java\npublic class Graph {\n    public HashMap<Integer, Node> nodes;\n    public HashSet<Edge> edges;\n\n    public Graph() {\n        nodes = new HashMap<>();\n        edges = new HashSet<>();\n    }\n}\n```\n\n```java\npublic class Node {\n    public int value;\n    public int in;\n    public int out;\n    public ArrayList<Node> nexts;\n    public ArrayList<Edge> edges;\n\n    public Node(int value) {\n        this.value = value;\n        this.in = 0;\n        this.out = 0;\n        nexts = new ArrayList<>();\n        edges = new ArrayList<>();\n    }\n}\n```\n\n```java\npublic class Edge {\n    public int weight;\n    public Node from;\n    public Node to;\n\n    public Edge(int weight, Node from, Node to) {\n        this.weight = weight;\n        this.from = from;\n        this.to = to;\n    }\n}\n```\n\n<!-- More -->\n\n### 图结构的转换\n\n将邻接数组结构的表达形式转换为我们规定的结构：\n\n```java\npublic class GraphGenerator {\n    public Graph graphGenerator(Integer[][] matrix) {\n        Graph graph = new Graph();\n        for (int i = 0; i < matrix.length; i++) {\n            Integer weight = matrix[i][0];\n            Integer from = matrix[i][1];\n            Integer to = matrix[i][2];\n\n            // 如果图中已经有了当前节点，则不再加入\n            if (!graph.nodes.containsKey(from)) {\n                graph.nodes.put(from, new Node(from));\n            }\n            if (!graph.nodes.containsKey(to)) {\n                graph.nodes.put(to, new Node(to));\n            }\n\n            // 不能直接根据传入的矩阵创建出节点，而应该从图的Set集合中获取，这样能保证不重复\n            Node fromNode = graph.nodes.get(from);\n            Node toNode = graph.nodes.get(to);\n\n            // 创建新边\n            Edge newEdge = new Edge(weight, fromNode, toNode);\n\n            // 更新节点里的出度入度信息和顶点集、出边集信息\n            // 顶点集只包含当前节点指向的顶点，出边集只包含从当前顶点出去的边（当前顶点为弧尾）\n            fromNode.out++;\n            toNode.in++;\n            fromNode.nexts.add(toNode);\n            fromNode.edges.add(newEdge);\n\n            graph.edges.add(newEdge);\n        }\n        return graph;\n    }\n}\n```\n\n## 图的遍历\n\n### 广度优先遍历（BFS）\n\n图的广度优先遍历类似于树的层次遍历。\n\n思想：把当前顶点的相邻顶点都遍历完，再遍历其相邻顶点的相邻顶点（不能重复遍历）。\n\n- 首先准备一个队列存储当前节点的所有相邻顶点（不重复添加）\n- 再准备一个 HashSet 存储每一个遍历过的顶点（保证不重复遍历）。\n- 每次弹出队首顶点，然后将其相邻顶点一一入队（要先判断是否在 HashSet 中已存在）\n- 按照该顺序遍历道直到队列为空，即完成了图的广度优先遍历\n\n示意图：\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/20130429224200306)\n\n代码：\n\n```java\npublic class BFS {\n    public void bfs(Node node) {\n        if (node == null) {\n\t\t\treturn;\n\t\t}\n        \n        Queue<Node> queue = new LinkedList<>();\n        Set<Node> set = new HashSet<>();\n\n        queue.add(node);\n        set.add(node);\n\n        while (!queue.isEmpty()) {\n            Node curr = queue.poll();\n\n            // 来到了当前顶点，进行一些操作\n            // ....\n            System.out.println(curr.value);\n\n            // 将当前顶点的相邻节点都加入到 set 和队列中（不能重复包含）\n            // for (int i = 0; i < curr.nexts.size(); i++) {\n            //     if (!set.contains(curr.nexts.get(i))) {\n            //         set.add(curr.nexts.get(i));\n            //         queue.add(curr.nexts.get(i));\n            //     }\n            // }\n            for (Node next : curr.nexts) {\n                if (!set.contains(next)) {\n                    set.add(next);\n                    queue.add(next);\n                }\n            }\n        }\n    }\n}\n```\n\n### 深度优先遍历\n\n图的深度优先遍历类似于树的前序遍历。\n\n思想：选择当前顶点的某一个顶点进行遍历，一直到底，然后返回时再遍历其他未遍历过的顶点。\n\n- 首先准备一个栈结构用于存储遍历过程中的顶点\n- 再准备一个 HashSet 用于记录当前顶点是否已经被遍历过\n- 从给定顶点开始，先将其入栈入 Set，并打印\n- **栈结构不为空**就一直进行循环：\n  - 弹出栈顶顶点，**判断其是否有某个相邻顶点还未被遍历过**（体现在 Set 中不包含该顶点）\n  - 如果有，则**先将栈顶顶点入栈**，目的是为了在前序遍历到底后往回遍历时能够再沿着原先入栈的顺序遍历回去。**然后将当前顶点入栈**，入 Set，并打印\n  - 如果没有，则不再将当前顶点入栈，说明当前顶点以下的顶点都遍历完了（类比与树结构中当前顶点的子树都遍历完了）\n- 一直到栈结构为空，说明所有顶点都不重复地遍历了一次。\n\n打印操作都是在某一个节点入 Set 后操作的，代表刚遍历到他就打印。\n\n示意图：\n\n![图的遍历|深度优先遍历- 掘金](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/896eb98c42384286b0578884d5b68e8c~tplv-k3u1fbpfcp-watermark.image)\n\n> 将栈顶节点弹出后再压入栈的原因就是在上图中访问到了 H 顶点以后（到底了），再往回遍历时能够根据栈中保存的其上面所有顶点的顺序，逐个遍历回去。\n\n代码：\n\n```java\npublic class DFS {\n    public void dfs(Node node) {\n        if (node == null) {\n            return;\n        }\n\n        Stack<Node> stack = new Stack<>();\n        Set<Node> set = new HashSet<>();\n        // 根顶点入栈\n        stack.push(node);\n        set.add(node);\n\n        // 第一次来到根顶点\n        System.out.println(node.value);\n\n        while (!stack.isEmpty()) {\n            // 弹出栈顶的顶点\n            Node curr = stack.pop();\n            // 逐个判断当前顶点的相邻顶点是否还有没有遍历过的（体现在 Set 中不存在的）\n            // 如果没遍历过，就先将当前顶点再次压栈，然后再将该邻居节点压栈\n            for (Node next : curr.nexts) {\n                if (!set.contains(next)) {\n                    // 如果当前顶点有某一个邻居顶点还没遍历过，就先将当前顶点入栈\n                    // 将当前顶点压栈的目的是为了能记录当前顶点，\n                    // 在前序遍历到底后往回遍历时能够再沿着原先入栈的顺序遍历回去，\n                    // 从而不遗漏的遍历所有顶点（因为还要遍历回去找其他未遍历过的顶点，如果不记录当前顶点就找不回去了）\n                    stack.push(curr);\n                    stack.push(next);\n                    set.add(next);\n                    // 每次都是往 Set 中存储后打印（代表第一次遍历到）\n                    System.out.println(next.value);\n                    break;\n                }\n            }\n        }\n    }\n}\n```\n\n\n\n## 图的拓扑排序\n\n>  **有向无环**图的排序——拓扑排序\n\n在图论中，**拓扑排序（Topological Sorting）** 是一个**有向无环图（DAG, Directed Acyclic Graph）** 的所有顶点的线性序列。且该序列必须满足下面两个条件：\n\n1. 每个顶点出现且只出现一次。\n2. 若存在一条从顶点 A 到顶点 B 的路径，那么在序列中顶点 A 出现在顶点 B 的前面。\n\n**有向无环图（DAG）才有拓扑排序**，非 DAG 图没有拓扑排序一说。\n\n![image-20211104183243762](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/image-20211104183243762.png)\n\nDAG 的拓扑排序流程：\n\n- 找出图中入度为0的顶点；\n- 依次在图中删除这些顶点（并将与其关联的边删掉），再找出新的入度为0的顶点；\n- 然后再删除这些顶点并重复该过程，直至删除所有顶点，即完成拓扑排序\n\n图示：\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/20150507001759702)\n\n代码：\n\n```java\npublic class TopologySort {\n    public List<Node> topologySort(Graph graph) {\n        if (graph == null) {\n            return null;\n        }\n\n        List<Node> list = new ArrayList<>();\n        Queue<Node> queue = new LinkedList<>();\n        for (Node node : graph.nodes.values()) {\n            // 如果当前顶点入度为 0，则加入队列\n            if (node.in == 0) {\n                queue.add(node);\n                list.add(node);\n            }\n        }\n\n        // 队首顶点依次出队，并将其指向的顶点的入度减一\n        while (!queue.isEmpty()) {\n            Node curr = queue.poll();\n            for (Node next : curr.nexts) {\n                next.in--;\n                 // 减一后判断：如果入度为0，则该顶点加入到队列中\n                if (next.in == 0) {\n                    queue.add(next);\n                    list.add(next);\n                }\n            }\n        }\n\n        return list;\n    }\n}\n```\n\n\n\n\n\n## 生成图的最小生成树\n\n两种算法可用于生成图的最小生成树，返回的结果为 `Set<Edge>`：\n\n- Kruskal 算法：以**边**为目标。按照边的权重值大小依次将权重较小的边合并起来。时间复杂度为 O(e * loge)，其中 e 为边数\n- Prim 算法 ：以**顶点**为目标。从任意顶点出发，不断将当前访问过的顶点集中的最小权重边合并到最小生成树集合中。时间复杂度为 O(n^2)，其中 n 为顶点数\n\n一个是从边的角度出发，按照权重值从小到大的顺序遍历边并加入到结果集中；一个是从顶点的角度出发，每一次都从当前访问过的顶点集中找出最小权重边添加到结果集中。\n\nKruskal 算法主要针对边来展开，边数少的时候效率非常高，所以对于稀疏图有很大的优势；Prim 算法对于稠密图，即边数非常多的情况会更好一些。\n\n### Kruskal 算法\n\n算法思想：以边为目标。先将边按照权重值从小到大进行排序。然后从最小权重值的边开始，逐个组合边，一次加入一条边（要保证新加入的边的两个顶点必须不在同一个集合中），直至形成最小生成树。\n\n算法流程：\n\n- 将每个顶点分别创建其所在的并查集（开始时所有顶点都是独立的，从属于不同的集合中）\n- 将所有边加入到优先级队列中，按照边的权重值从小到大进行排序\n- 遍历该队列，从最小权重值的边开始遍历每一个边，判断该边两端的顶点是否是同一个集合：\n  - 若是，说明这两个顶点已经在一个连通树上了，因此当前边是多余的，不需要添加\n  - 若不是，说明这两个顶点还没不在一个连通树上，则将当前边加入到结果集中\n- 该队列遍历完成后，即生成了最小生成树\n\n在组合边的过程中可能会将两片原先完全不连通的顶点集合组合起来，即一片一片的组合。Prim 算法则不会一片一片的添加边，而是一次添加一个点所在的边。\n\n代码：\n\n```java\npackage com.zhao;\n\nimport java.util.*;\n\npublic class Kruskal {\n    // Union-Find Set\n    public static class UnionFind {\n        private HashMap<Node, Node> fatherMap;\n        private HashMap<Node, Integer> rankMap;\n\n        public UnionFind() {\n            fatherMap = new HashMap<Node, Node>();\n            rankMap = new HashMap<Node, Integer>();\n        }\n\n        private Node findFather(Node n) {\n            Node father = fatherMap.get(n);\n            if (father != n) {\n                father = findFather(father);\n            }\n            fatherMap.put(n, father);\n            return father;\n        }\n\n        public void makeSets(Collection<Node> nodes) {\n            fatherMap.clear();\n            rankMap.clear();\n            for (Node node : nodes) {\n                fatherMap.put(node, node);\n                rankMap.put(node, 1);\n            }\n        }\n\n        public boolean isSameSet(Node a, Node b) {\n            return findFather(a) == findFather(b);\n        }\n\n        public void union(Node a, Node b) {\n            if (a == null || b == null) {\n                return;\n            }\n            Node aFather = findFather(a);\n            Node bFather = findFather(b);\n            if (aFather != bFather) {\n                int aFrank = rankMap.get(aFather);\n                int bFrank = rankMap.get(bFather);\n                if (aFrank <= bFrank) {\n                    fatherMap.put(aFather, bFather);\n                    rankMap.put(bFather, aFrank + bFrank);\n                } else {\n                    fatherMap.put(bFather, aFather);\n                    rankMap.put(aFather, aFrank + bFrank);\n                }\n            }\n        }\n    }\n\n    public static class EdgeComparator implements Comparator<Edge> {\n        // 返回正整数代表 o1 大于 o2\n        // 返回负整数代表 o1 小于 o2\n        @Override\n        public int compare(Edge o1, Edge o2) {\n            return o1.weight - o2.weight;\n        }\n    }\n\n    public Set<Edge> kruskalMST(Graph graph) {\n        UnionFind unionFind = new UnionFind();\n        unionFind.makeSets(graph.nodes.values());\n\n        // 所有边先加到优先队列中，按照定制排序器排序，权值小的放前面\n        PriorityQueue<Edge> priorityQueue = new PriorityQueue<>(new EdgeComparator());\n        for (Edge edge : graph.edges) {\n            priorityQueue.add(edge);\n        }\n\n        Set<Edge> result = new HashSet<>();\n        while (!priorityQueue.isEmpty()) {\n            Edge edge = priorityQueue.poll();\n            // 如果当前边的两个顶点不在一个集合中，就将当前边加入到结果边集中，\n            // 并且将这两个顶点所在集合合并\n            if (!unionFind.isSameSet(edge.from, edge.to)) {\n                result.add(edge);\n                unionFind.union(edge.from, edge.to);\n            }\n        }\n        return result;\n    }\n}\n```\n\n其中，`priorityQueue` 是一个小根堆结构。\n\n\n\n### Prim 算法\n\n算法思路：以顶点为目标。从任意顶点出发，不断将当前访问过的顶点集中的最小权重边合并到最小生成树集合中。\n\n算法流程：\n\n- 创建一个优先级队列用于在遍历过程中动态存储当前访问过的顶点集所连接的边\n- 创建一个 HashSet 保存最小生成树上的顶点集 nodesSet，用于判断当前顶点是否已经被加入到生成树中，防止重复添加顶点导致闭环\n- 从任意一个顶点出发，先将其添加到顶点集 nodesSet 中，然后将当前顶点所连接的所有边都加入到优先级队列中。将会在接下来从这些边中找到最小权重边\n- while 循环遍历优先级队列：\n  - 获取当前边集中的最小权重边\n  - 获取该边的 to 顶点。该边已经在之前加入到了优先级队列中，说明该边的 from 点已经加入到了顶点集 nodesSet 中。此时获取 to 顶点是将其看为种子选手（因为该顶点和 from 顶点组成的边的权重值在当前阶段最小），如果其满足条件就可以加入到最小生成树中（条件是该点之前没被加入到树中过）\n  - 判断该 to 顶点是否在访问过的顶点集 Set 中，若在，则不再添加当前边（否则会闭环），若不在，则添加到顶点集 nodesSet 中\n  - 若在，则将当前边的 to 顶点（该顶点已被判断成功加入到生成树中）连接的边都加入到队列中。这些边将在接下来的 while 循环中继续找出最小权重边。进行判断+合并\n  - 重复进行上述操作，直到队空即完成了正科最小生成树的构建\n\n该过程只需要一个哈希表 nodesSet 存储已添加到最小生成树中的顶点，不需要额外的结构。不像 Kruskal 算法还需要并查集结构判断两个集合是否相同。这是因为 Kruskal 算法是以边为目标，每次添加一条边，可能会造成一片顶点合并一片顶点，因此要判断两片顶点是否重合。\n\nP 算法从任意一个点出发，寻找最小权重的边（之所以从任意一个点是因为所有点最后总归是要加入到树中的，所以从哪个点出发都一样，反正最后都得加入到树中，总归是要加入该顶点所连接的最小权重的边）\n\n每次新遍历到一个顶点，就将其连接的边加入到优先级队列中，接下来就会获取该队列里的最小权重边，也对应了开始时从任意一个点出发，因为每个顶点都会经历该过程：从该顶点连接的边中挑选一个最小权重边加入到最小生成树中（每个顶点都会从其连接的边中挑出来一条，所以谁先谁后无所谓）\n\n代码：\n\n```java\npublic class Prim {\n    public static class EdgeComparator implements Comparator<Edge> {\n        @Override\n        public int compare(Edge e1, Edge e2) {\n            return e1.weight - e2.weight;\n        }\n    }\n\n    public Set<Edge> prim(Graph graph) {\n        // 保存组成最小生成树的边集\n        Set<Edge> result = new HashSet<>();\n        // 保存最小生成树上的顶点集，用于判断当前顶点是否已经被加入到生成树中，防止重复添加顶点导致闭环\n        Set<Node> nodesSet = new HashSet<>();\n        // 优先级队列用于在遍历过程中动态存储当前访问过的顶点集所连接的边\n        PriorityQueue<Edge> priorityQueue = new PriorityQueue<>(new EdgeComparator());\n\n        // 该 for 循环的目的是防止图森林的存在：即多个互不相连的图组成的一个森林\n        // 如果题目表示是连通图，则可以省略该步骤\n        for (Node node : graph.nodes.values()) {\n            // 防止重复添加\n            // node 是随便选择的一个初始点\n            if (!nodesSet.contains(node)) {\n                nodesSet.add(node);\n                // 将当前顶点所连接的所有边都加入到优先级队列中\n                // 将会在接下来从这些边中找到最小权重边 \n                for (Edge edge : node.edges) {  // 由一个点解锁所有相连的边\n                    priorityQueue.add(edge);\n                }\n\n                while (!priorityQueue.isEmpty()) {\n                    // 获取当前边集中的最小权重边\n                    Edge currEdge = priorityQueue.poll(); // 弹出解锁的边中，最小的边\n                    // 当前边的 currEdge.to 为 node 顶点指向的 to 顶点 \n                    // 该顶点就是种子选手，如果其满足条件就可以加入到最小生成树中（条件是该点之前没被加入到树中过）\n                    Node toNode = currEdge.to;  // 可能的一个新点（种子选手）\n                    // 判断其是否在访问过的点集 Set 中，若在，则不再添加当前边（否则会闭环），若不在，则添加\n                    if (!nodesSet.contains(toNode)) {  // 如果不包含，则该种子选手就是新点，可以加入树中\n                        nodesSet.add(toNode);\n                        result.add(currEdge);\n                        // 将当前边的 to 顶点（该顶点已被判断成功加入到生成树中）连接的边都加入到队列中\n                        // 这些边将在接下来的 while 循环中继续找出最小权重边。进行判断+合并\n                        for (Edge nextEdge : toNode.edges) {\n                            priorityQueue.add(nextEdge);\n                        }\n                    }\n                }\n            }\n        }\n\n        return result;\n    }\n}\n```\n\n\n\n## Dijkstra 算法\n\n> https://www.cnblogs.com/goldsunshine/p/12978305.html#dijkstra-%E7%AE%97%E6%B3%95%E6%80%9D%E6%83%B3%E4%BB%8B%E7%BB%8D\n\n适用范围：**没有权值累加和为负数的环**。\n\n如下图是一个多节点，多路径图。下面以该图为例子讲解Dijkstra算法寻找最短路径的过程。\n[![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/1060878-20200530174625634-1955533179.png)](https://img2020.cnblogs.com/blog/1060878/202005/1060878-20200530174625634-1955533179.png)\n\n以A点为起始点，求A点到其他点 `B C D E F` 5个点的最短路径，最后得出A到其他点的最短路径。\n\n因为要求A到其他5个点的最短距离，所以构造一个数组记录A到`B C D E F` 5个点的路径距离。约定：\n\n- 如果A能够直接达到节点，则使用路径长度即权值作为其距离\n- 如果A节点不能直接达到节点则使用无穷大表示A到该点距离。\n- 任何点到自身都为0\n\n那么在最开始时，A点到图中所有点的距离数组如下：\n\n| A    | B    | C      | D    | E      | F      |\n| :--- | :--- | :----- | :--- | :----- | :----- |\n| 0    | 10   | 无穷大 | 4    | 无穷大 | 无穷大 |\n\nDijkstra 的算法思想是：从以上最短距离数组中每次选择一个最近的点，将其作为下一个点，然后重新计算从起始点经过该点到其他所有点的距离，更新最短距离数据。已经选取过的点就是确定了最短路径的点，不再参与下一次计算。\n\n算法流程：\n\n\n\n\n\n代码：\n\n```java\npublic class Dijkstra {\n    public Map<Node, Integer> dijkstra(Node head) {\n        // 保存从指定出发点head到其他点的距离，将在遍历时不断更新（就是那张距离数组表）\n        //    key: 顶点\n        //    value: head到该顶点的距离\n        Map<Node, Integer> distanceMap = new HashMap<>();\n        // 设置 head 到自己的距离为 0\n        distanceMap.put(head, 0);\n        // 保存已经锁定的顶点（已经确定的，不会再改变距离大小的顶点）\n        Set<Node> selectedNodes = new HashSet<>();\n\n        // 先找出初始状态的最小距离点：就是head本身\n        Node minDistanceNode = getMinDistanceAndUnselectedNode(distanceMap, selectedNodes);\n        while (minDistanceNode != null) {\n            // 将head加入到selectedSet中\n            // distance为head到当前顶点的距离\n            Integer distance = distanceMap.get(minDistanceNode);\n            // 将当前minDistanceNode的相邻顶点都加入到distanceMap中\n            for (Edge edge : minDistanceNode.edges) {\n                Node toNode = edge.to;\n                // 如果当前边的to顶点还没被锁定，则加入到distance中\n                if (!distanceMap.containsKey(toNode)) {\n                    // 第一次计算出从head到当前顶点的值\n                    distanceMap.put(toNode, distance + edge.weight);\n                } else {\n                    // 更新最小值\n                    // distanceMap.get(toNode) 是之前其他顶点更新的值，是暂定的\n                    // 可能随着遍历其他顶点的过程而更新\n                    distanceMap.put(toNode, Math.min(distanceMap.get(toNode),\n                           distance + edge.weight));\n                }\n            }\n\n            selectedNodes.add(minDistanceNode);\n            minDistanceNode = getMinDistanceAndUnselectedNode(distanceMap, selectedNodes);\n        }\n        return distanceMap;\n    }\n\n    // 用于从distanceMap中查找到head的距离最小，且还没有锁定的顶点（不在selectedNodes中）\n    // distanceMap中保存的就是到head的距离值，selectedNodes中保存的是已经锁定的顶点（已经确定的，不会再改变距离大小的顶点）\n    public Node getMinDistanceAndUnselectedNode(Map<Node, Integer> distanceMap, Set<Node> selectedNodes) {\n        // 遍历distanceMap中的每个顶点，找出最小的距离值\n        int minDistance = Integer.MAX_VALUE;\n        Node minNode = null;\n        for (Map.Entry<Node, Integer> entry : distanceMap.entrySet()) {\n            Node node = entry.getKey();\n            Integer distance = entry.getValue();\n\n            // 注意，需要满足两个条件：\n            //   1. 当前顶点还未锁定：不在selectedNodes中\n            //   2. 当前顶点距离head的距离小于当前最小值\n            if (!selectedNodes.contains(node) && distance < minDistance) {\n                minDistance = distance;\n                minNode = node;\n            }\n        }\n        // 将找到的最短距离的顶点返回\n        return minNode;\n    } \n}\n```\n\n\n\n## 图的常见题目\n\n### 岛屿问题\n\n[200. 岛屿数量](https://leetcode-cn.com/problems/number-of-islands/)：给你一个由 '1'（陆地）和 '0'（水）组成的的二维网格，请你计算网格中岛屿的数量。岛屿总是被水包围，并且每座岛屿只能由水平方向和/或竖直方向上相邻的陆地连接形成。此外，你可以假设该网格的四条边均被水包围。\n\n示例 1：\n\n``` \n输入：grid = [\n  [\"1\",\"1\",\"1\",\"1\",\"0\"],\n  [\"1\",\"1\",\"0\",\"1\",\"0\"],\n  [\"1\",\"1\",\"0\",\"0\",\"0\"],\n  [\"0\",\"0\",\"0\",\"0\",\"0\"]\n]\n输出：1\n```\n\n思路：使用深度优先遍历，对图中的每一个元素都进行深度优先遍历，将其连通的元素都设置为2，防止重复访问。\n\n代码：\n\n``` java\npublic int numIslands(char[][] grid) {\n    if (grid == null || grid.length < 1) {\n        return 0;\n    }\n\n    int count = 0;\n\n    // 遍历每一个元素，进行infect传染操作，将其连通的元素都设置为2\n    for (int i = 0; i < grid.length; i++) {\n        for (int j = 0; j < grid[0].length; j++) {\n            if (grid[i][j] == '1') {\n                // 如果当前位置为1，说明是一个岛屿，开始传染\n                infect(grid, i, j, grid.length, grid[0].length);\n                count++;\n            }\n        }\n    }\n    return count;\n}\n\n// M：矩阵的行数，N：矩阵的列数\n// i：当前行，j：当前列\npublic void infect(char[][] grid, int i, int j, int M, int N) {\n    // 如果当前位置超出矩阵范围，或值不为'1'，则代表当前位置不是岛屿\n    if (i < 0 || i >= M || j < 0 || j >= N || grid[i][j] != '1') {\n        return;\n    }\n\n    // 如果当前位置是岛屿，则将其设置为2\n    grid[i][j] = '2';\n\n    // 然后递归传染上下左右位置\n    infect(grid, i - 1, j, M, N); // 上\n    infect(grid, i + 1, j, M, N); // 下\n    infect(grid, i, j - 1, M, N); // 左\n    infect(grid, i, j + 1, M, N); // 右\n}\n```\n\n\n\n### 矩阵中的路径\n\n[矩阵中的路径](https://leetcode-cn.com/problems/ju-zhen-zhong-de-lu-jing-lcof/)：给定一个 m x n 二维字符网格 board 和一个字符串单词 word 。如果 word 存在于网格中，返回 true ；否则，返回 false 。单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。\n\n例如，在下面的 3×4 的矩阵中包含单词 \"ABCCED\"（单词中的字母已标出）。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/image-20211209154348176.png\" alt=\"image-20211209154348176\" style=\"zoom:50%;\" />\n\n思路：本问题是典型的矩阵搜索问题，可使用 **深度优先搜索（DFS）+ 剪枝** 解决。\n\n- **深度优先搜索：** 可以理解为暴力法遍历矩阵中所有字符串可能性。DFS 通过递归，先朝一个方向搜到底，再回溯至上个节点，沿另一个方向搜索，以此类推。\n- **剪枝：** 在搜索中，遇到 `这条路不可能和目标字符串匹配成功` 的情况（*例如：此矩阵元素和目标字符不同、此元素已被访问）*，则应立即返回，称之为 `可行性剪枝` 。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/image-20211209154502018.png\" alt=\"image-20211209154502018\" style=\"zoom:50%;\" />\n\n**DFS 解析**：\n\n- **递归参数：** 当前元素在矩阵 `board` 中的行列索引 `i` 和 `j` ，当前目标字符在 `word` 中的索引 `k` 。\n- **终止条件：**\n  - 返回 false： (1) 行或列索引越界 **或** (2) 当前矩阵元素与目标字符不同 **或** (3) 当前矩阵元素已访问过 （ (3) 可合并至 (2) ） \n  - 返回 true： `k = len(word) - 1` ，即字符串 `word` 已全部匹配。\n\n**递推工作：**\n\n1. 标记当前矩阵元素： 将 `board[i][j]` 修改为 **空字符** `''` ，代表此元素已访问过，防止之后搜索时重复访问。\n2. 搜索下一单元格： 朝当前元素的 **上、下、左、右** 四个方向开启下层递归，使用 `或` 连接 （代表只需找到一条可行路径就直接返回，不再做后续 DFS ），并记录结果至 `res` 。\n3. 还原当前矩阵元素： 将 `board[i][j]` 元素还原至初始值，即 `word[k]` 。\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E5%9B%BE/1600793567-lnVDIT-Picture13.png)\n\n**注意**：此类图的 DFS 问题都**需要遍历图中的每一个元素**，从其开始进行深度优先遍历。同时需要使用 || 的**短路原则**，缩短搜索时间。\n\n代码：\n\n``` java\npublic boolean exist(char[][] board, String word) {\n    if (board == null || board.length < 1 || word == null || board.length * board[0].length < word.length()) {\n        return false;\n    }\n    char[] words = word.toCharArray();\n    // 图的dfs问题，都需要遍历图的每一个元素，判断从其出发能否找到匹配的字符\n    // 类似于岛问题\n    for (int i = 0; i < board.length; i++) {\n        for (int j = 0; j < board[0].length; j++) {\n            if (dfs(i, j, 0, board, words)) {\n                return true;\n            }\n        }\n    }\n    return false;\n}\n\n// 换个思路：使用record无法处理这类问题，那么就可以修改原字符数组，将处理成功的设置为' '\n// 那么再重复找时就会直接返回false不会重复查找\n// 如果当前没成功，则其邻居再回来时发现又不满足等于curr的条件，还是会失败\npublic boolean dfs(int i, int j, int k, char[][] board, char[] words) {\n    // 1. 越界，返回false\n    if (i < 0 || i >= board.length || j < 0 || j >= board[0].length) {\n        return false;\n    }\n    // 2. 如果当前位置元素值不等于目标值，返回false\n    if (board[i][j] != words[k]) {\n        return false;\n    } \n    // ps：该情况其实无需额外判断，已经和上一条合并了\n    // 3， 如果当前位置已经搜索过，并且是成功的，代表当前分支重复访问了，返回false\n    // if (board[i][j] == ' ') {\n    //     return false;\n    // }\n\n    // 4. 如果当前元素等于目标值，且如果k到底了，说明匹配完毕，返回true\n    if (k == words.length - 1) {\n        return true;\n    }\n\n    // 5. 如果当前位置还没搜索过，并且匹配当前word的字符\n    // 先修改为' '防止其后的分支重复访问当前字符\n    char tmp = board[i][j]; // 暂存一下在回溯完成后重新赋值给原数组\n    board[i][j] = '\\0';\n\n    // 开始搜索\n    // 使用 || 的短路原则，缩短搜索时间，否则如果第一个分支就成功，后面的分支就会多余搜索，浪费了大量时间\n    boolean res = dfs(i + 1, j, k + 1, board, words) || dfs(i, j + 1, k + 1, board, words)\n        || dfs(i - 1, j, k + 1, board, words) || dfs(i, j - 1, k + 1, board, words);\n    // 恢复回去\n    board[i][j] = tmp;\n    // 四条搜索路线有一条为true即可代表当前路径搜索到了\n    return res;\n}\n```\n\n","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【数据结构】树","url":"/2021/10/15/【数据结构】树/","content":"\n## 二叉树的遍历\n\n二叉树的前序、中序、后序遍历本质上就是将打印语句放到 “第一次来到该节点、第二次回到该节点、第三次回到该节点” 的位置。\n\n```java\npublic static void traversal(Node head) {\n    if (head == null) {\n        return;\n    }\n\n    // --------------------------------\n    // 第一次来到该节点, 对应前序\n    // 访问其左右子树前, 就会来到这里\n    // --------------------------------\n\n    // 递归遍历左子树\n    traversal(head.left);\n\n    // --------------------------------\n    // 第二次回到该节点, 对应中序\n    // 访问完其整个左子树后, 才会来到这里\n    // --------------------------------\n\n    // 递归遍历右子树\n    traversal(head.right);\n\n    // --------------------------------\n    // 第三次回到该节点, 对应后序\n    // 访问完其整个右子树后, 才会来到这里\n    // --------------------------------\n}\n```\n\n### 前序遍历\n\n前序遍历：头 -> 左 -> 右\n\n#### 递归方式\n\n```java\npublic static void preOrderRecur(Node head) {\n    if (head == null) {\n        return;\n    }\n    System.out.print(head.value + \" \");\n    preOrderRecur(head.left);\n    preOrderRecur(head.right);\n}\n```\n\n#### 非递归方式：借助一个栈结构\n\n> 后序遍历的非递归方式需要借助两个栈，步骤和前序遍历相似，只不过将一个栈中的元素压入到另一个栈后再统一出栈打印\n\n非递归的前序遍历，需要使用一个栈结构。\n\n先将根节点入栈，然后不断循环，按照 “弹栈打印 -> 右孩子入栈 -> 左孩子入栈” 的顺序遍历，即可实现前序遍历。\n\n因为每次都将右孩子先入栈，同时弹出左孩子时就立刻再次压入其右孩子和左孩子，所以某个节点的右子树会堆积在栈底，一直到其左子树都弹栈后才会再遍历，从而达到了先序遍历的效果。\n\n```java\n//    1. 首先, 树的根结点先入栈,\n//       while (栈不空) {\n//    2.    弹出栈顶节点并打印\n//    3.    先将右孩子入栈, 再将左孩子入栈 (注意先后顺序要先右再左, 这样弹栈时就会先弹左再弹右)\n//       }\n// 因为每次都将右孩子先入栈，同时弹出左孩子时就立刻再次压入其右孩子和左孩子，所以某个节点的右子树\n// 会堆积在栈底，一直到其左子树都弹栈后才会再遍历，从而达到了先序遍历的效果\n// 总结: 先弹顶 -> 压左 -> 压右 -> 弹栈 -> 压左 -> 压右\n\n// 前序遍历的效果: 先把根结点的左子树上的所有节点遍历后才会遍历右子树\n//                并且每个子树都遵循该效果\npublic static void preOrderUnRecur(Node head) {\n    if (head != null) {\n        Stack<Node> stack = new Stack<>();\n        stack.push(head);\n        Node curr = null;\n        while (!stack.isEmpty()) {\n            curr = stack.pop();\n            System.out.print(curr.value + \" \");\n\n            if (curr.right != null) {\n                stack.push(curr.right);\n            }\n            if (curr.left != null) {\n                stack.push(curr.left);\n            }\n        }\n    }\n}\n```\n\n<!-- More -->\n\n### 中序遍历\n\n中序遍历：左 -> 头 -> 右\n\n#### 递归方式\n\n```java\npublic static void inOrderRecur(Node head) {\n    if (head == null) {\n        return;\n    }\n    inOrderRecur(head.left);\n    System.out.print(head.value + \" \");\n    inOrderRecur(head.right);\n}\n```\n\n#### 非递归方式：借助一个栈结构\n\n思路：把整棵树**按照左边界进行分解**，同时右孩子节点也按照左边界分解，将右子树的节点也依次左孩子节点入栈。即每打印一个节点后就**把右子树的节点也依次左孩子节点入栈**。\n\n```java\n// 直将当前节点的所有左孩子都入栈，直到当前节点没有了左孩子，\n//则将当前节点弹栈并打印，同时将当前节点的右孩子节点的所有左孩子节点都入栈\n\n// 遍历到某个叶子节点时, 其左右孩子节点都是 null\n//  先 if 发现是 null , 进入 else 弹出并打印该叶子节点，然后再获取右孩子, 又是 null\n//  再进一次  while  发现还是走 else，弹出了其父节点, 然后打印\n// 所以连起来看就是 左 -> 头 -> 右\n\n// 因为左边界是按照先入头再入左的顺序, 因此弹栈时就是先左再头\n// 每次都是先左再头, 然后再让其右子树进行先左再头, 周而复始\n\n// 思想: 把整棵树按照左边界进行分解, 同时右孩子节点也按照左边界分解,\n// 将右子树的节点也依次左孩子节点入栈\n// 左 -> 头 -> 右(左 -> 头 -> 右(左 -> 头 -> 右(...)))\npublic static void inOrderUnRecur(Node head) {\n    if (head != null) {\n        Stack<Node> stack = new Stack<>();\n        // 注意: 一开始不需要入根结点\n\n        // 注意循环终止条件需要加上 head != null\n        while (!stack.isEmpty() || head != null) {\n            // 每次循环到这里, 栈顶保存着当前 head 的父节点\n            if (head != null) {\n                // 一直将当前节点入栈, 每次压栈后栈顶保存的都是父节点, 也就是 头\n                stack.push(head);\n                // 注意是先压栈, 再指向左孩子, 这样在进入 else 时,\n                // 栈顶节点保存的就是当前父节点, 从而在弹出栈顶节点后, 就可以获取到其右孩子\n                head = head.left;\n            } else {\n                // 弹出当前栈顶节点, 引入入栈时是先入的左, 再入的头\n                // 所以这里弹出时先弹出的是左, 然后才是头,\n                // 接着将右子树进行分解, 再进行一次左边界的递归入栈\n                head = stack.pop();\n                System.out.print(head.value + \" \");\n                // 一个节点弹出时, 再让其右子树进行一次左边界的递归入栈:\n                // 令 head 指向当前节点的右孩子, 从而在接下来进入 if 判断后,\n                // 将当前节点的右孩子(已经变为了head)的所有左孩子节点入 栈\n                head = head.right;\n            }\n        }\n    }\n}\n```\n\n\n\n### 后序遍历\n\n后序遍历：左 -> 右 -> 头\n\n#### 递归方式\n\n```java\npublic static void posOrderRecur(Node head) {\n    if (head == null) {\n        return;\n    }\n    posOrderRecur(head.left);\n    posOrderRecur(head.right);\n    System.out.print(head.value + \" \");\n}\n```\n\n\n\n#### 非递归方式：借助两个栈结构\n\n> 后序遍历的非递归方式需要借助两个栈，步骤和前序遍历相似，只不过将一个栈中的元素压入到另一个栈后再统一出栈打印。\n\n非递归的后序遍历，需要使用两个栈结构，另一个栈用于存储第一个栈弹出的节点\n\n```java\n// 首先, 按照 先弹顶并压入栈2 -> 压左 -> 压右 的顺序执行\n// 然后依次弹出栈2中的节点并打印, 这样第二个栈再弹出时打印的顺序就是 左右头\n\n//   (头在最后打印的原因时, 入第一个栈时, 在压当前节点的左右孩子节点前先将当前节点弹出并压到了栈2\n//   然后弹其右孩子节点时就会存放到了当前节点的上面, 最后才是压入其左孩子节点\n//   所以从栈2弹出时的顺序就是  左 -> 右 -> 头)\n//\n//   流程:\n//    1. 首先, 树的根结点先入栈,\n//       while (栈1不空) {\n//    2.    弹出栈1的顶节点并压入栈2(不打印)\n//    3.    先将左孩子入栈, 再将右孩子入栈 (注意先后顺序和前序相反)\n//       }\n//    4. 依次弹出栈2的每个节点并打印\npublic static void posOrderUnRecur1(Node head) {\n    if (head != null) {\n        Stack<Node> stack1 = new Stack<>();\n        Stack<Node> stack2 = new Stack<>();\n        Node curr = head;\n        stack1.push(head);\n\n        while (!stack1.isEmpty()) {\n            curr = stack1.pop();\n            stack2.push(curr);\n            if (curr.left != null) {\n                stack1.push(curr.left);\n            }\n            if (curr.right != null) {\n                stack1.push(curr.right);\n            }\n        }\n\n        // 依次弹出栈2的节点\n        while (!stack2.isEmpty()) {\n            System.out.print(stack2.pop().value + \" \");\n        }\n    }\n}\n```\n\n\n\n### 前序、中序、后序遍历在数组中的体现\n\n- 知道**前序**遍历序列和**中序**遍历序列，可以唯一确定一颗二叉树\n- 知道后序遍历序列和**中序**遍历序列，可以唯一确定一颗二叉树\n\n但是只知道后序和前序无法唯一确定一棵二叉树，因为**需要中序序列中定位到根节点的位置**才可以进行左右侧划分，否则不知道前序或后序序列中**左右子树的划分边界**\n\n根节点位置：\n\n- 前序遍历：在数组的**第一个**位置\n- 中序遍历：在数组的**中间某个**位置（第一个位置为整棵树最左侧的节点）\n- 后序遍历：在数组的**最后一个**位置\n\n左右子树的分布特点：\n\n- 前序遍历：根 -> 左 -> 右\n- 中序遍历：左 -> 根 -> 右\n- 后序遍历：左 -> 右 -> 根\n\n具体分布可见下图：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211206145926473.png\" alt=\"image-20211206145926473\"  />\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211218190011688.png\" alt=\"image-20211218190011688\"  />\n\n相关题目可见：[重建二叉树](#重建二叉树)与[二叉搜索树的后续遍历序列](#二叉搜索树的后续遍历序列)。\n\n\n\n\n\n### 层次遍历\n\n层次遍历常用于和**树的宽度**相关或**需要知道当前节点所在层信息**的题目，例如求树的最大宽度，或者判断完全二叉树。\n\n**层次遍历常常与队列一起组合出现**，因为使用队列先进先出的特点才能保证做到层次遍历，如果是栈结构的先进后出，就无法做到层次遍历。\n\n层次遍历的一个技巧，可以在进入每层后，首先获取队列中节点的个数，其就代表了当前层的节点数目，那么就可以在开启一个内层 while 循环，一次性遍历当前层的所有节点。\n\n代码：\n\n```java\npublic void levelOrder(Node head) {\n    if (head == null)\n        return;\n\n    Queue<Node> queue = new LinkedList<>();\n    queue.add(head);\n\n    while (!queue.isEmpty()) {\n        int size = queue.size();\n        // 依次遍历当前层内所有节点\n        while (size-- > 0) {\n            Node curr = queue.poll();\n            System.out.println(curr.value);\n            if (curr.left != null)\n                queue.add(curr.left);\n            if (curr.right != null)\n                queue.add(curr.right);\n        }\n    }\n}\n```\n\n#### 按照之字形进行层次遍历\n\n之字形遍历即要求奇数层从左往右打印，偶数层从右往左打印。要实现该功能，有三种思路：\n\n- 仍然采用传统的层次遍历，只不过在最后对偶数层集合进行**逆序**；或在偶数层添加元素时从后往前加入到结果集合 `LinkedList<>#addLast()` 中\n- 使用**两个栈结构**。一个栈存储奇数层的节点，一个栈存储偶数层的节点\n  - 遍历奇数层时，向偶数栈中压入当前层的孩子；先左后右\n  - 遍历偶数层时，向奇数栈中压入当前层的孩子；先右后左\n- 使用**一个双端队列**结构。每次不止遍历两层，而是先遍历奇数层，再遍历偶数层\n  - 奇数层是从头出，从尾入；先左后右\n  - 偶数层是从尾出，从头入；先右后左\n  - 注意：出和入的方向肯定是相反的，不然就会导致刚入的，就要出了\n\n代码：\n\n``` java\npublic List<List<Integer>> levelOrder(TreeNode root) {\n    if (root == null) {\n        return new ArrayList<>();\n    }\n\n    // 1. 两个栈，一个栈存储奇数层的，一个栈存储偶数层的\n    // 遍历奇数层时，向偶数栈中压入当前层的孩子；先左后右\n    // 遍历偶数层时，向奇数栈中压入当前层的孩子；先右后左\n\n    // 2. 双端队列，每次不止遍历两层，而是先遍历奇数层，再遍历偶数层\n    // 奇数层是从头出，从尾入；先左后右\n    // 偶数层是从尾出，从头入；先右后左\n    // 注意：出和入的方向肯定是相反的，不然就会导致刚入的，就要出了\n\n    return levelOrderDeque(root);\n}\n\n// 1. 双栈\npublic List<List<Integer>> levelOrderTwoStack(TreeNode root) {\n    List<List<Integer>> res = new ArrayList<>();\n    Stack<TreeNode> stackOdd = new Stack<>();\n    Stack<TreeNode> stackEven = new Stack<>();\n    stackOdd.push(root);\n\n    // 两个栈分别存储奇数层和偶数层的元素\n    // 如果同时为空，说明遍历完了\n    while (!stackOdd.isEmpty() || !stackEven.isEmpty()) {\n        List<Integer> list = new ArrayList<>();\n        // 刚来到新的一层时只会有一个栈不为空\n        if (!stackOdd.isEmpty()) {\n            // 如果奇数层栈不为空，则当前是奇数层\n            // 奇数层先入左孩子，再入右孩子\n            while (!stackOdd.isEmpty()) {\n                root = stackOdd.pop();\n                list.add(root.val);\n                if (root.left != null) {\n                    stackEven.push(root.left);\n                }\n                if (root.right != null) {\n                    stackEven.push(root.right);\n                }\n            }\n        } else {\n            // 否则当前就是偶数层\n            // 偶数层先入右孩子，再入左孩子\n            while (!stackEven.isEmpty()) {\n                root = stackEven.pop();\n                list.add(root.val);\n                if (root.right != null) {\n                    stackOdd.push(root.right);\n                }\n                if (root.left != null) {\n                    stackOdd.push(root.left);\n                }\n            }\n        }\n        res.add(list);\n    }\n    return res;  \n}\n\n// 2. 双端队列\npublic List<List<Integer>> levelOrderDeque(TreeNode root) {\n    Deque<TreeNode> queue = new LinkedList<>();\n    List<List<Integer>> res = new ArrayList<>();\n    queue.addFirst(root);\n\n    while (!queue.isEmpty()) {\n        int size = queue.size();\n        List<Integer> list = new ArrayList<>();    \n        // 先遍历奇数层，然后紧接着判断是否还有偶数层，如果有就接着遍历\n        while (size-- > 0) {\n            // 奇：从头出，从尾入；先左后右\n            root = queue.removeFirst();\n            list.add(root.val);\n            if (root.left != null) {\n                queue.addLast(root.left);\n            }\n            if (root.right != null) {\n                queue.addLast(root.right);\n            }\n        }\n        res.add(list);\n\n        // 处理过奇数层，立刻处理偶数层\n        if (!queue.isEmpty()) {\n            size = queue.size();\n            list = new ArrayList<>();    \n            while (size-- > 0) {\n                // 偶：从尾出，从头入；先右后左\n                root = queue.removeLast();\n                list.add(root.val);\n                // 每次都是先右后左的顺序入队头，这样就会导致奇数层可以做到从左往右遍历\n                if (root.right != null) {\n                    queue.addFirst(root.right);\n                }\n                if (root.left != null) {\n                    queue.addFirst(root.left);\n                }\n            }\n            res.add(list);\n        }\n    }\n    return res;\n}\n\n```\n\n\n\n### Morris 遍历\n\n#### 实现流程\n\n假设来到当前节点 curr，开始时 curr 在头节点位置\n\n- 如果 curr 没有左孩子，则 curr 向右移动 `cur = cur.right`（这里会因为事先建立的线索而再次回到上层节点）\n- 如果 curr 有左孩子，找到 curr 的左子树上的最右侧节点 `mostRight`：\n  - 如果 `mostRight` 的右指针指向空（说明是第一次到该节点，还没建立线索），让其指向 curr（`mostRight.right = curr`），此时建立了当前节点左子树最右节点与当前节点间的**线索**。然后 curr 向左移动 `curr = curr.left`，**开始向左子树遍历**\n  - 如果 `mostRight` 的右指针指向 curr（说明是第二次到该节点，之前就建立过线索了），让其指向 null（取消线索），断开了之前建立的线索，恢复了最右节点的原始结构。然后 curr 向右移动 `cur = cur.right`。**开始向右子树遍历**\n- curr 为 null 时遍历停止\n\n上述流程可分为三个阶段：\n\n- **线索化**：第一次来到某节点 A，寻找其 mostRight 并赋值 `mostRight.right = A`。借助于该线索才能在访问过节点 A 的**左子树的全部节点**后再次回到节点 A。如果不线索化，访问了底层节点后就不能再回到节点 A 了。接着 `curr = curr.left`，即开始**向左子树遍历**\n- **遍历左子树**：A 完成线索化后，开始向左子树遍历。当遍历到刚才的 mostRight 时，将通过之前创建的**线索**进行回溯，重新回到 A：`curr = curr.right`\n- **取消线索化**：**第二次**回到节点 A 时，寻找其 mostRight 并赋值 `mostRight.right = null`。此时是第二次回到节点 A，其左子树上的全部节点都已经遍历完毕了，接着该向其**右子树**进行遍历了。因此 `curr = curr.right`\n\n上述三个阶段的图示：\n\n![image-20211202163945003](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211202163945003.png)\n\n![image-20211202163956413](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211202163956413.png)\n\n![image-20211202164003355](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211202164003355.png)\n\n建立线索——消除线索的过程：\n\n- 开始时所有子树的最右节点的 right 都是 null，此时还没建立起线索\n- 接着**第一次**来到某个节点 A 时，若其左子树的最右节点存在，则会**建立该最右节点与当前节点的线索**，具体方法是：`mostRight.right = A`。然后当前节点继续向左移动：`curr = A.left`。注意：这里建立的线索将会在后续遍历到 mostRight 节点时，执行 `curr = mostRight.right` 语句来再次回到节点 A\n- 当 curr 在向左子树不断遍历的过程中来到刚才建立线索的最右节点 mostRight 时，会执行  `curr = mostRight.right` 语句重新回到其线索指向的祖先节点 A，从而做到了**第二次**回到节点 A\n- 第二次回到节点 A 后，继续寻找其左子树上的最右节点 mostRight，然后取消线索化：`mostRight.right = null`，从而恢复其原始结构\n\n**线索化的目的**：在访问了底层节点后，依旧能借助该线索再次回到上层的节点，从而继续向右侧迭代遍历。如果不线索化，访问了底层节点后就不能再回到上层节点了。\n\n左子树上的线索化结果图示：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211206135410908.png\" alt=\"image-20211206135410908\" style=\"zoom:67%;\" />\n\n#### 算法复杂度\n\n没有左孩子的节点只会被遍历一次（因为找不到 mostRight，没有能回溯的线索）；有左孩子的节点会被遍历两次（第二次是通过线索回溯到的）：\n\n- 有左孩子，则该节点会被访问两次\n  - 第一次访问时，其**左子树上的最右节点**的右孩子为 null\n  - 第二次访问时，其**左子树上的最右节点**的右孩子为该节点\n- 没左孩子，则该节点只会被访问一次\n\n复杂度：\n\n- 时间复杂度：不同的节点寻找 mostRight 的路径是完全不重合的，因此时间复杂度并没有增加太多，最对是 O(2N)，也还是 O(N)。\n- 空间复杂度：O(1)。全局只需要存储 curr 和 mostRight，也没有利用系统栈，不耗费额外空间。\n\n#### 总结\n\n传统递归的方式进行遍历时，是通过系统压栈的方式告诉我们当前节点是第几次被访问，每个节点会被访问三次；但 Morris 遍历并不是，其只能模拟：在左子树上转一圈后回到自身，不能在右子树上转一圈后回到自身（即无法第三次回到自身）。它是利用线索化的机制回到当前节点。\n\nMorris 遍历的特点：可以选择是否要第二次回到当前节点（实现方式为通过当前节点左子树的底层节点的线索化，将right指针指向当前节点来实现）\n\n借助于 Morris 遍历，可以实现出时间复杂度为 O(N)，空间复杂度为 O(1) 的前序、中序以及后序遍历。\n\nMorris 遍历代码：\n\n``` java\npublic static void morrisTraversal(TreeNode root) {\n    if (root == null) {\n        return;\n    }\n    TreeNode curr = root;\n    TreeNode mostRight;\n    while (curr != null) {\n        // Morris 顺序打印位置:\n        System.out.print(curr.value + \" \");\n        // 有两种情况会来到某个节点:\n        // 1. 第一次来到当前节点, 通过 curr = curr.left 或 curr = curr.right 方式\n        // 2. 第二次回到当前节点, 通过线索节点的 curr = curr.right 进行回溯\n        // 只要某个节点有左孩子, 就能线索化, 从而就能第二次回到当前位置\n\n        // 先尝试寻找左子树上的最右节点\n        mostRight = curr.left;\n\n        // 如果当前节点存在左子树, 则开始寻找其 mostRight\n        if (mostRight != null) {\n            // 一直寻找 curr 左子树上的最右节点, 可能有两种情况:\n            // 1. mostRight.right == null, 则代表还未建立线索\n            // 2. mostRight.right == curr, 则代表已经建立了线索\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            // 1. mostRight.right == null, 则代表还未建立线索\n            // 此时是第一次到达 mostRight 与节点 A, 需要建立二者的线索\n            if (mostRight.right == null) {\n                mostRight.right = curr;\n                // ========================================================\n                // 此时是节点 A 第一次找到 mostRight, 同时也是第一次访问节点 A\n                // 因为只有在访问到节点 A 时, 才会去寻找其 mostRight\n                // ========================================================\n                // 在这里打印, 就能符合前序遍历中先打印头的要求\n                // System.out.print(curr.value + \" \");\n\n                // 线索化后, curr 开始遍历左子树\n                curr = curr.left;\n                // 进入下一次循环, 开始遍历左子树\n                // 这里的 continue 非常重要，能够令当前节点 A 不经过下面的 curr = curr.right; 直接进入到其左子树上进行遍历\n                // 这样就有效地做到了第一次到当前节点时不处理，第二次到当前节点时（在接下来的 else 里）处理，从而很好地实现了中序遍历\n                continue;\n            } else {\n                // 2. mostRight.right == curr, 则代表已经建立了线索\n                // ========================================================\n                // 此时为第二次到达 mostRight, 也是第二次到达之前访问过的节点 A\n                // (通过 mostRight 回溯到了 A), 需要取消二者的线索\n                // 此时是节点 A 第二次找到 mostRight, 同时也是第二次访问节点 A,\n                // 因为只有在访问到节点 A 时, 才会去寻找其 mostRight\n                // ========================================================\n                mostRight.right = null;\n                // 第二次到达节点 A 后, 就会走出这里, 到下面继续执行 curr = curr.right, 从而开始遍历右子树\n                // 通过在下面增加 else 分支就可以控制第二次到达节点 A 时不打印，从而实现中序遍历\n            }\n        }\n        // 两种情况:\n        // 1. 到达某个节点的 mostRight, 通过其 right 线索回溯到其祖先节点\n        // 2. 第二次回到祖先节点, 代表左子树遍历完毕了, 开始遍历右子树\n        curr = curr.right;\n    }\n    System.out.println(\" \");\n}\n```\n\n注意代码中，第一次和第二次来到节点 A 的时机，这对于修改成前序、中序以及后序遍历来说非常重要。\n\nMorris 版的前序遍历：\n\n``` java\npublic static void morrisPre(TreeNode root) {\n    if (root == null) {\n        return;\n    }\n    TreeNode curr = root;\n    TreeNode mostRight;\n\n    while (curr != null) {\n        // 这里是 morris 遍历的打印位置\n        // System.out.print(curr.value + \" \");\n\n        mostRight = curr.left;\n        if (curr.left != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                mostRight.right = curr;\n                // 此时是节点 A 第一次找到 mostRight, 同时也是第一次访问节点 A\n                // 因为只有在访问到节点 A 时, 才会去寻找其 mostRight\n                // 在更新 curr 向左子树遍历前, 先打印一下, 当前打印的顺序是要先于下面 else 里的打印的\n                System.out.print(curr.value + \" \");\n                curr = curr.left;\n                continue;\n            } else {\n                // 此时是节点 A 第二次找到 mostRight, 同时也是第二次访问节点 A,\n                // 因为只有在访问到节点 A 时, 才会去寻找其 mostRight\n                // 而第二次访问节点 A 后, 出了当前 if 后不会进入到下面的 else, 所以不会打印第二次\n                // 从而实现了前序遍历\n                mostRight.right = null;\n            }\n        } else {\n            // 第一次来的时候打印\n            // 当第二次访问到节点 A 时, 其从上面的寻找 mostRight 的 if 判断中出来后\n            // 是无法进入到当前 else 里的, 从而避免了第二次打印节点 A\n            // 而对于没有左孩子的节点, 因为根本不会进入上面的 if 里, 所以只会来到这里打印一次\n            System.out.print(curr.value + \" \");\n        }\n        curr = curr.right;\n    }\n    System.out.println(\" \");\n}\n```\n\nMorris 版的中序遍历：\n\n``` java\npublic static void morrisIn(TreeNode root) {\n    if (root == null) {\n        return;\n    }\n    TreeNode curr = root;\n    TreeNode mostRight;\n    while (curr != null) {\n        mostRight = curr.left;\n        if (mostRight != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                mostRight.right = curr;\n                curr = curr.left;\n                continue;\n            } else {\n                mostRight.right = null;\n            }\n        }\n        // 中序遍历只需要在这里打印即可, 因为第一次到达节点 A 时, 触发了 continue\n        // 导致第一次遍历不会执行到这里, 只有在第二次回到节点 A 时, 走出了上面的 if 后到达这里进行打印\n        System.out.print(curr.value + \" \");\n        curr = curr.right;\n    }\n    System.out.println(\" \");\n}\n```\n\nMorris 版的后序遍历：\n\n``` java\n// Morris 后序遍历的思路:\n//    第二次回到节点 A 时, 逆序打印其左子树的所有右侧节点, 所有节点遍历完后, 再逆序打印整棵树的右侧节点\n// 解释:\n//   不再需要额外打印任何其他节点, 只需要在回到节点 A 时打印其左子树的右侧节点,\n//   即可将那些只会遍历一次的节点(没有左孩子)给打印出来, 并且当前节点 A 也会在其祖先节点\n//   进行逆序打印时进行打印, 所以整体不漏也不重\n// 逆序打印的方法: 不需要栈存储, 直接用链表逆序打印的思路, 将左子树上的右侧节点视为一条链表, 进行逆序打印即可\npublic static void morrisPos(TreeNode root) {\n    if (root == null) {\n        return;\n    }\n    TreeNode curr = root;\n    TreeNode mostRight;\n    while (curr != null) {\n        mostRight = curr.left;\n        if (mostRight != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                mostRight.right = curr;\n                curr = curr.left;\n                continue;\n            } else {\n                mostRight.right = null;\n                // 只用在第二次回到当前节点时将其左子树上的右侧节点逆序打印\n                printEdge(curr.left);\n            }\n        }\n        curr = curr.right;\n    }\n    // 所有节点遍历完后, 再将整棵树的右侧节点逆序打印\n    printEdge(root);\n    System.out.println(\" \");\n}\n\n// 使用递归逆序打印\nprivate static void printEdge(TreeNode curr) {\n    if (curr == null) {\n        return;\n    }\n    printEdge(curr.right);\n    // 全部孩子都遍历完后再打印自己, 就实现了逆序\n    System.out.println(curr.value);\n}\n```\n\n直观的理解：每个节点左子树，从右下角向左上角划线逆序打印，整棵树的所有子节点都可以按照这种画法被不漏不重的画出来：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211206135831549.png\" alt=\"image-20211206135831549\" style=\"zoom:50%;\" />\n\n\n\n#### Morris 遍历的应用\n\nMorris 遍历通常用于以较低的空间复杂度遍历整棵树。\n\n**应用一：判断某棵树是否是搜索二叉树**\n\n思路：使用 Morris 中序遍历，判断当前值是否大于目前的最大值，若不大于，则不是搜索二叉树。\n\n**应用二：恢复搜索二叉树**\n\n思路：使用 Morris 中序遍历，判断前一个值 pred 是否大于当前值，若大于，则发现了错误点\n\n\n\n### 直观地打印一颗二叉树\n\n```java\npublic static void printTree(Node head) {\n    System.out.println(\"Binary Tree:\");\n    printInOrder(head, 0, \"H\", 17);\n    System.out.println();\n}\n\npublic static void printInOrder(Node head, int height, String to, int len) {\n    if (head == null) {\n        return;\n    }\n    printInOrder(head.right, height + 1, \"v\", len);\n    String val = to + head.value + to;\n    int lenM = val.length();\n    int lenL = (len - lenM) / 2;\n    int lenR = len - lenM - lenL;\n    val = getSpace(lenL) + val + getSpace(lenR);\n    System.out.println(getSpace(height * len) + val);\n    printInOrder(head.left, height + 1, \"^\", len);\n}\n\npublic static String getSpace(int num) {\n    String space = \" \";\n    StringBuffer buf = new StringBuffer(\"\");\n    for (int i = 0; i < num; i++) {\n        buf.append(space);\n    }\n    return buf.toString();\n}\n```\n\n\n\n## 几种特殊的二叉树\n\n### 搜索二叉树\n\n若一棵二叉树根节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值（等于都不行）； 它的左、右子树也分别为搜索二叉树。\n\n搜索二叉树（Binary Search Tree）作为一种经典的数据结构，它既有链表的快速插入与删除操作的特点，又有数组快速查找的优势；所以应用十分广泛，例如在文件系统和数据库系统一般会采用这种数据结构进行高效率的排序与检索操作。\n\n判断一棵树是否是搜索二叉树有三种方法。\n\n#### 方法一：中序遍历后，判断是否升序\n\n一种简单的方法是首先中序遍历这棵二叉树，并在遍历过程中将每个节点的值保存到一个数组里，遍历完成后，再判断该数组是否是升序的。\n\n代码：\n\n```java\npublic static boolean isSBT01(Node head) {\n    List<Integer> list = new ArrayList<>();\n    inOrderRecur(head, list);\n\n    // 接着判断数组是否为升序\n    for (int i = 0; i < list.size() - 1; i++) {\n        if (list.get(i) >= list.get(i+1)) {\n            return false;\n        }\n    }\n    return true;\n}\n\npublic static void inOrderRecur(Node head, List<Integer> list) {\n    if (head == null) {\n        return;\n    }\n\n    inOrderRecur(head.left, list);\n    list.add(head.value);\n    inOrderRecur(head.right, list);\n}\n```\n\n#### 方法二：中序遍历 + 不断保存当前最大值\n\n方法二需要借助一个静态变量 `preMaxValue` 存储递归过程中 **\"当前节点之前的所有节点\"的最大值** 。因为搜索二叉树是按照**中序遍历**的方式升序的，**所以当前节点后面的节点值都要大于该最大值**。递归过程中**不断保存当前已经遍历过的节点的最大值，并且令后续即将遍历的节点值都要大于该值**。\n\n整个方法栈调用时，是先从左下角的那颗子树开始的，按照 左 -> 头 -> 右 的顺序，依次判断当前节点的值是否大于其左侧的所有节点的最大值 `preMaxValue`，方法栈不断从左下角开始向右上方向扩展，直到整棵树完成遍历：\n\n```java\npublic static int preMaxValue = Integer.MIN_VALUE;\n\npublic static boolean isSBT02(Node head) {\n    // 注意这里如果到了边界条件，是返回的true，因为叶子结点必定是满足搜索二叉树条件的\n    if (head == null) {\n        return true;\n    }\n\n    // 先遍历左子树，返回其是否满足搜索二叉树条件\n    boolean isLeftBst = isSBT02(head.left);\n\n    // 如果左子树不是搜索二叉树，直接返回false\n    if (!isLeftBst) {\n        return false;\n    }\n\n    // 如果左子树上的点比当前节点的值还要大（或相等），则说明不是搜索二叉树，直接返回false\n    if (preMaxValue >= head.value) {\n        return false;\n    } else {\n        // 否则更新最小值为当前节点，令当前节点的右子树上的点都要比该值大\n        preMaxValue = head.value;\n    }\n\n    // 运行到这里时，当前节点的左子树里的最大值都要比当前节点要小，\n    // 说明到这里为止，都是符合搜索二叉树的，接着要遍历当前节点的右子树，判断其是否也满足搜索二叉树\n   return isSBT02(head.right);\n}\n```\n\n#### 方法三：Morris 中序遍历 + 不断保存当前最大值\n\n与方法二的区别在于使用 Morris 中序遍历节省空间，思路几乎一致。代码：\n\n``` java\npublic static void morrisIn(TreeNode root) {\n    if (root == null) {\n        return;\n    }\n    TreeNode curr = root;\n    TreeNode mostRight;\n    while (curr != null) {\n        mostRight = curr.left;\n        if (mostRight != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                mostRight.right = curr;\n                curr = curr.left;\n                continue;\n            } else {\n                mostRight.right = null;\n            }\n        }\n        // 中序遍历只需要在这里打印即可, 因为第一次到达节点 A 时, 触发了 continue\n        // 导致第一次遍历不会执行到这里, 只有在第二次回到节点 A 时, 走出了上面的 if 后到达这里进行打印\n        System.out.print(curr.value + \" \");\n        curr = curr.right;\n    }\n    System.out.println(\" \");\n}\n```\n\n#### 方法四：使用模板套路\n\n> 先介绍非标准模板的解法\n\n也可以使用模板套路进行解题，每个节点的左右子树都返回一个 `ReturnType` 对象，其内即保存了该子树上的最大值和最小值，也保存了该子树是否是搜索二叉树。该对象内保存的最小值是给右子树判断时用，最大值是给左子树判断时用。\n\n方法流程：\n\n- 遍历到每一个节点时，首先获取左子树的 `ReturnData`，判断左子树是否满足搜索二叉树：\n  - 如果返回值里的 `isBST` 为 false，说明其左子树不为搜索二叉树\n  - 如果当前节点的值**小于等于**左子树返回值里的**最大值**，则说明不是搜索二叉树\n  - 如果左子树不满足搜索二叉树，则向上返回一个 `new ReturnData(false)`，后续的右子树就不会再去判断了，直接方法栈返回到头结点后返回给主程序 false\n- 如果左子树满足搜索二叉树，则去获取其右子树的  `ReturnData`，判断右子树是否满足搜索二叉树：\n  - 如果返回值里的 `isBST `为 false，说明其右子树不为搜索二叉树\n  - 如果当前节点的值**大于等于**右子树返回值里的**最小值**，则说明不是搜索二叉树\n  - 如果右子树不满足搜索二叉树，则向上返回一个 `new ReturnData(false)`\n- 如果左右子树都满足搜索二叉树，则返回一个 `ReturnData(leftReturn.min, rightReturn.max)`，其内保存了当前子树上的最小值和最大值，其中：\n  - **当前子树的最小值是左子树上的最小值**\n  - **当前子树的最大值是右子树上的最大值**\n\n代码：\n\n```java\n// 创建模板返回值类，在其内保存当前子树上的最大值和最小值\npublic static class ReturnData {\n    public boolean isSBT = true;\n    public int min = Integer.MAX_VALUE;\n    public int max = Integer.MIN_VALUE;\n\n    public ReturnData(boolean isSBT) {\n        this.isSBT = isSBT;\n    }\n\n    public ReturnData(int min, int max) {\n        this.min = min;\n        this.max = max;\n    }\n}\n\npublic static boolean isSBT03(Node head) {\n    if (head == null) {\n        return true;\n    }\n\n    ReturnData result = checkIsSBT(head);\n    return result.isSBT;\n}\n\npublic static ReturnData checkIsSBT(Node head) {\n    if (head == null) {\n        return new ReturnData(true);\n    }\n\n    ReturnData leftReturn = checkIsSBT(head.left);\n\n    // 先判断左子树是否满足搜索二叉树：\n    //   1. 如果返回值里的 isBST 为 false，说明其左子树不为搜索二叉树\n    //   2. 如果当前节点的值小于等于左子树返回值里的最大值，则说明不是搜索二叉树\n    if (!leftReturn.isSBT || leftReturn.max >= head.value) {\n        return new ReturnData(false);\n    }\n\n    ReturnData rightReturn = checkIsSBT(head.right);\n\n    // 再判断右子树是否满足搜索二叉树：\n    //   1. 如果返回值里的 isBST 为 false，说明其右子树不为搜索二叉树\n    //   2. 如果当前节点的值大于等于右子树返回值里的最小值，则说明不是搜索二叉树\n    if (!rightReturn.isSBT || rightReturn.min <= head.value) {\n        return new ReturnData(false);\n    }\n\n    // 保存当前子树上的最大值和最小值\n    // 最小值给右子树判断时用，最大值给左子树判断时用\n    // 当前子树上的最小值是左子树上的最小值，最大值是右子树上的最大值\n    // 因为其按照中序遍历时是升序大小，说明左子树上的最左叶子结点是最小值，右子树上的最右节点是最大值\n    return new ReturnData(leftReturn.min, rightReturn.max);\n}\n```\n\n注意：上面这种写法并不是标准的模板套路。标准的模板套路是：只在方法的最后进行 return，在方法前面先调用两个递归获取到左右子树上的返回值，据此进行判断后再最后封装成 `ReturnData` 返回：\n\n```java\npublic static ReturnData f(Node head) {\n    if (head == null) {\n        // 根据具体场景返回相应的值\n        return ReturnData(xx, xx, xx);\n    }\n    \n    // 先获取左右子树上的返回值\n    ReturnData leftReturnData = f(head.left);\n    ReturnData rightReturnData = f(head.right);\n    \n    // 进行判断处理等，例如将 boolean 类型值设置为 true 或 false，设置最大最小值等\n    // ...\n    \n    // 在最后将设置好的值封装成 ReturnData 并向上返回\n    return new ReturnData(xx, xx, xx);\n}\n```\n\n在本问题中，使用标准模板的解法：\n\n```java\npublic static class ReturnData {\n    public boolean isSBT = true;\n    public int min = Integer.MAX_VALUE;\n    public int max = Integer.MIN_VALUE;\n\n    public ReturnData(boolean isSBT, int min, int max) {\n        this.min = min;\n        this.max = max;\n    }\n}\n\npublic static boolean isBST04(Node head) {\n    if (head == null) {\n        return true;\n    }\n\n    ReturnData result = checkBST02(head);\n    return result.isSBT;\n}\n\npublic static ReturnData checkIsSBT02(Node head) {\n    if (head == null) {\n        return null;\n    }\n\n    ReturnData leftReturn = checkIsSBT02(head.left);\n    ReturnData rightReturn = checkIsSBT02(head.right);\n\n    boolean isSBT = true;\n    // 如果左子树返回值不为空，且左子树不为搜索二叉树，或左子树最大值大于等于当前节点值，说明不构成搜索二叉树\n    if (leftReturn != null && (!leftReturn.isSBT || leftReturn.max >= head.value))\n        isSBT = false;\n    // 如果右子树返回值不为空，且右子树不为搜索二叉树，或右子树最小值小于等于当前节点值，说明不构成搜索二叉树\n    if (rightReturn != null && (!rightReturn.isSBT || rightReturn.min <= head.value))\n        isSBT = false;\n\n    int min = head.value;\n    int max = head.value;\n    // 计算左右子树与当前节点构成的子树上的最大值和最小值，返回给上一层节点使用\n    if (leftReturn != null) {\n        min = Math.min(leftReturn.min, min);\n        max = Math.min(leftReturn.max, max);\n    }\n    if (rightReturn != null) {\n        min = Math.min(rightReturn.min, min);\n        max = Math.min(rightReturn.max, max);\n    }\n\n    return new ReturnData(isSBT, min, max);\n}\n```\n\n这种标准模板的方式存在的缺点：一定会遍历整棵树，因为 return 在方法最后，只会在第三次回到该节点时 return，即只有在遍历过当前节点的左右子树后才会 return，这就导致效率相比上面的方式差了一些（上面的方式是只要在左子树上遇到不满足的子树就直接向上返回到根节点，不会再遍历右子树）\n\n#### 搜索二叉树的增删改查操作\n\n搜索二叉树**查找**节点的流程：\n\n- 如果目标节点值大于当前节点值，则向右递归遍历该树\n- 如果目标节点值小于当前节点值，则向左递归遍历该树\n- 直到找到**当前节点的值等于目标节点值**，即找到了目标节点\n\n搜索二叉树**插入**节点的流程：\n\n- 如果目标节点值大于当前节点值，则向右递归遍历该树\n- 如果目标节点值小于当前节点值，则向左递归遍历该树\n- 直到**遍历到底层**时（root == null），即找到了目标节点需要被插入的地方，将其父节点指向目标节点即可（目标节点肯定会被插入到树的**某个叶子节点的孩子处**）\n\n搜索二叉树**删除**节点的流程：\n\n- 若目标节点没有左右孩子，说明其是叶子节点，**直接将其父节点的对应孩子位置置空**（遍历过程中还需要记录当前节点的父节点，需要在删除了目标节点后将其父节点的对应孩子置空） \n- 若目标节点有左孩子或右孩子（但不同时存在左右孩子），则**将其父节点的对应孩子位置设置为目标节点的左或右孩子即可**（让目标节点的孩子代替自己）\n- 若目标节点同时有左孩子和右孩子，则**找到其右子树上最左的节点或左子树上最右的节点，令该节点代替自己**，并且：\n  - 若选择右子树的最左节点，则令该节点的父节点的左孩子指向该节点的右子树（令最左节点的右子树代替自己）\n  - 若选择左子树的最右节点，则令该节点的父节点的右孩子指向该节点的左子树（令最右节点的左子树代替自己）\n\n### 完全二叉树\n\n一棵深度为k的有n个结点的二叉树，对树中的结点按从上至下、从左到右的顺序进行编号，如果编号为i（1≤i≤n）的结点与**满二叉树**中编号为i的结点在二叉树中的位置相同，则这棵二叉树称为完全二叉树（Complete Binary Tree）。\n\n> 堆结构即为完全二叉树。\n\n#### 方法一：层次遍历 + 队列\n\n> 层次遍历常常与队列一起组合出现，因为使用队列先进先出的特点才能保证做到层次遍历，如果是栈结构的先进后出，就无法做到层次遍历\n\n准备一个队列，用于存放层次遍历过程中的每个节点。之所以选择层次遍历，是因为在判断是否满足完全二叉树时有两个判断条件，这两个条件需要依靠层次遍历来实现（因为需要一层一层的遍历，判断当前层内的节点是否满足这两个条件）：\n\n- 当前节点如果**只有右孩子**，则必定不满足完全二叉树（对应图中情况1）\n- 当前节点如果**左右孩子不双全**，那么当前层所在的后面节点都**必须不能有孩子节点**，即**后面的节点都必须是叶子结点**（对应图中情况2）\n\n可以看出，条件2中用到了判断**当前层后面节点**是否有孩子节点，所以必须使用层次遍历。\n\n![幻灯片1](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/%E5%B9%BB%E7%81%AF%E7%89%871-1634725344405.PNG)\n\n对上述两个条件进行解释：\n\n- 如果节点如果**只有右孩子**，则根据完全二叉树的定义，其必定不符合，因为完全二叉树里有右孩子的话必定得有左孩子\n- 当前节点如果**左右孩子不双全**，那么说明当前节点为**临界条件节点**，当前层所在的后面节点都**必须不能有孩子节点**，即**后面的节点都必须是叶子结点**，这样才满足完全二叉树的定义\n\n代码实现时：\n\n- 条件1较好实现，在遍历过程中添加条件判断即可。\n- 条件2的实现则需要借助一个布尔类型的 `flag`，其在遇到第一个**左右孩子不双全**的节点（上图中的绿色）时，将 `flag = true`，并且在每个节点遍历时，判断 `flag` 的值，如果为 true，就需要额外判断当前节点是否为叶子结点，如果不是则说明不符合完全二叉树。\n\n![幻灯片2](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/%E5%B9%BB%E7%81%AF%E7%89%872.PNG)\n\n代码：\n\n```java\npublic static boolean isCBT(Node head) {\n    if (head == null) {\n        return true;\n    }\n\n    Queue<Node> queue = new LinkedList<>();\n    queue.add(head);\n\n    Node left = null;\n    Node right = null;\n    boolean flag = false;\n\n    while (!queue.isEmpty()) {\n        head = queue.poll();\n        left = head.left;\n        right = head.right;\n\n        if (    // 条件1：\n                (left == null && right != null)\n                ||\n                // 条件2：\n                (flag == true && (left != null || right != null))) {\n            return false;\n        }\n\n        if (left != null) {\n            queue.add(left);\n        }\n        if (right != null) {\n            queue.add(right);\n        }\n\n        // 如果遇到临界条件节点（上文图中绿色节点），则将 flag = true\n        if (left == null || right == null) {\n            flag = true;\n        }\n    }\n\n    return true;\n}\n```\n\n\n\n### 满二叉树\n\n满二叉树（Full Binary Tree）：除最后一层无任何子节点外，每一层上的所有结点都有两个子结点的二叉树。一个二叉树，如果每一个层的结点数都达到最大值，则这个二叉树就是满二叉树。也就是说，如果一个二叉树的层数为K，且结点总数是(2^k) -1 ，则它就是满二叉树。\n\n#### 方法一：层次遍历 + 记录层数与总节点数\n\n判断是否是满二叉树的一种方法是使用层次遍历，在遍历的过程中一边记录层数，一边记录节点个数，遍历结束后判断总节点数和层数的关系是否满足满二叉树条件即可。\n\n```java\npublic static boolean isFBT01(Node head) {\n    if (head == null) {\n        return true;\n    }\n\n    Queue<Node> queue = new LinkedList<>();\n    queue.add(head);\n\n    Map<Node, Integer> layerMap = new HashMap<>();\n    layerMap.put(head, 1);\n\n    // 记录当前层\n    int currLayer = 0;\n    // 记录总节点数\n    int count = 0;\n\n    while (!queue.isEmpty()) {\n        Node curr = queue.poll();\n        count++;\n        // 如果 currLayer 小于当前节点的层数，说明需要换层：将层数加一\n        // 该判断成立的时机在 遍历到了下一层的第一个节点时\n        if (currLayer < layerMap.get(curr))\n            currLayer++;\n\n        if (curr.left != null) {\n            queue.add(curr.left);\n            layerMap.put(curr.left, currLayer + 1);\n        }\n        if (curr.right != null) {\n            queue.add(curr.right);\n            layerMap.put(curr.right, currLayer + 1);\n        }\n    }\n    // 判断 count == 2^k - 1\n    return count == ((1 << currLayer) - 1);\n}\n```\n\n#### 方法二：使用模板套路\n\n判断满二叉树的模板套路非常简单，只需在向左右孩子索要节点数与层数信息，从而更新自己的节点数与层数信息。递归该过程即可得到整棵树的节点数与层数。\n\n代码：\n\n```java\npublic static class ReturnData {\n    public int nodes;\n    public int layers;\n\n    public ReturnData(int nodes, int layers) {\n        this.nodes = nodes;\n        this.layers = layers;\n    }\n}\n\npublic static boolean isFBT02(Node head) {\n    if (head == null) {\n        return true;\n    }\n\n    ReturnData result = checkIsFull(head);\n    return result.nodes == ((1 << result.layers) - 1);\n}\n\npublic static ReturnData checkIsFull(Node head) {\n    if (head == null) {\n        return new ReturnData(0, 0);\n    }\n\n    ReturnData leftReturn = checkIsFull(head.left);\n    ReturnData rightReturn = checkIsFull(head.right);\n\n    // 计算出当前子树的高度和总节点数\n    int layers = Math.max(leftReturn.layers, rightReturn.layers) + 1;\n    int nodes = leftReturn.nodes + rightReturn.nodes + 1;\n\n    return new ReturnData(nodes, layers);\n}\n```\n\n\n\n### 平衡二叉树\n\n平衡二叉树（Balanced Binary Tree）又被称为 AVL 树。它具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。\n\n使用模板套路即可解该题，定义 `ReturnData` 记录子树上的节点个数以及是否是平衡二叉树，不断向上返回时判断即可。\n\n代码：\n\n```java\npublic static class ReturnData {\n    public int nodes;\n    public boolean isBBT;\n    public ReturnData(boolean isBBT, int data) {\n        this.isBBT = isBBT;\n        this.nodes = data;\n    }\n}\n\npublic static boolean isBBT(Node head) {\n    if (head == null) {\n        return true;\n    }\n\n    ReturnData result = checkIsBBT(head);\n\n    return result.isBBT;\n}\n\npublic static ReturnData checkIsBBT(Node head) {\n    if (head == null) {\n        return new ReturnData(true, 0);\n    }\n\n    ReturnData leftReturn = checkIsBBT(head.left);\n    ReturnData rightReturn = checkIsBBT(head.right);\n\n    boolean isBBT = true;\n    // 如果左右子树表明自己是非平衡二叉树或左右子树的节点数的绝对值之差大于1，则说明当前子树不是平衡二叉树\n    if (!leftReturn.isBBT || !rightReturn.isBBT)\n        isBBT = false;\n    if (Math.abs(leftReturn.nodes - rightReturn.nodes) > 1)\n        isBBT = false;\n\n    return new ReturnData(isBBT, leftReturn.nodes + rightReturn.nodes + 1);\n}\n```\n\n不使用模板的剪枝操作：\n\n``` java\npublic boolean isBalanced(TreeNode root) {\n    return recur(root) != -1;\n}\n\nprivate int recur(TreeNode root) {\n    if (root == null) return 0;\n    \n    int left = recur(root.left);\n    // 如果左子树不为平衡二叉树，则直接返回，完成剪枝\n    if(left == -1) return -1;\n    \n    int right = recur(root.right);\n    if(right == -1) return -1;\n    \n    return Math.abs(left - right) < 2 ? Math.max(left, right) + 1 : -1;\n}\n```\n\n\n\n### 将有序数组转换为二叉平衡搜索树\n\n给你一个整数数组 `nums` ，其中元素已经按**升序**排列，请你将其转换为一棵**高度平衡**二叉搜索树。高度平衡二叉树是一棵满足「每个节点的左右两个子树的高度差的绝对值不超过 1 」的二叉树。\n\n递归解决：使用递归的方式，每次取数组中间的值比如m作为当前节点，m前面的值作为他左子树的结点值，m后面的值作为他右子树的节点值，示例中一个可能的结果是\n\n![image-20211026100602967](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211026100602967.png)\n\n每次递归时，左子树对应数组 `[start, mid - 1]`，右子树对应数组 `[mid + 1, end]`。**注意是没有取到 mid 的**，因为 mid 位置的数字已经在当前方法栈中被创建成了一个节点添加到整棵树中，不能将其也放到左右子树的递归里，否则会重复创建节点。\n\n注意边界条件是 `start > end`。遇到这种情况说明在上一层递归中计算出的 mid 的左侧没有子数组，此时 `start == mid`，`end == mid -1`，故其左子树的递归方法里 `start > end` 。这种情况，说明上一层的 mid 没有了左孩子，因此其左侧递归的结果应该返回 null。\n\n代码：\n\n```java\n// 每次取数组中间的数字作为当前节点，其左右子数组作为当前节点的左右树上的节点    \npublic TreeNode sortedArrayToBST(int[] nums) {\n    return sortedArrayToBSTHelper(nums, 0, nums.length - 1);\n}\n\npublic TreeNode sortedArrayToBSTHelper(int[] nums, int start, int end) {\n    // 发生在划分叶子节点时，长度为2的子数组在计算[start, mid - 1] 时\n    // 可能出现 start > mid -1 的情况，例如 start == 0, end == 1，则计算出来的\n    // mid - 1 == -1 < start; 这种情况说明到了叶子节点，该返回null了\n    // 即：上一层递归中计算出的 mid 在左侧没有了子数组，所以其左侧递归的结果应该返回 null\n    if (start > end) {\n        return null;\n    }\n\n    int mid = (start + end) / 2;\n    TreeNode root = new TreeNode(nums[mid]);\n\n    // 左侧的范围注意是 [start, mid - 1]\n    root.left = sortedArrayToBSTHelper(nums, start, mid - 1);\n    root.right = sortedArrayToBSTHelper(nums, mid + 1, end);\n\n    return root;\n}\n```\n\n#### AVL 树原理\n\n\n\n\n\n\n\n### 二叉树的线索化\n\n定义一个 pre 节点，令其不断等于 node 的前一个节点，在第二次回到当前节点时，设置node的前驱为 pre，然后设置 pre 的后继为 node\n\n代码里的两个条件判断不是同时成立的，一个节点只可能某一个成立\n\n![image-20211027144627113](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211027144627113.png)\n\n二叉树线索化后，就等于一个双向链表（见书），可以直接按照某种顺序遍历整棵树\n\n### 自平衡二叉查找树\n\n> 自平衡二叉查找树又被称为**有序表**，主要是用它来**存储有序的数据**\n\n自平衡二叉查找的所有操作的时间复杂度都是 O(logN) 级别。具体实现为：\n\n- 平衡搜索二叉树（BST）系列\n  - 平衡二叉树（AVL树）\n  - 节点大小平衡树（Size Balanced Tree）\n  - 红黑树（Red–Black Tree）\n- 跳表（Skip List）\n\n四者的时间复杂度相同。\n\n#### 搜索二叉树的增删改查操作\n\n有序表都是搜索二叉树，因此首先介绍搜索二叉树的增删改查操作。\n\n搜索二叉树**查找**节点的流程：\n\n- 如果目标节点值大于当前节点值，则向右递归遍历该树\n- 如果目标节点值小于当前节点值，则向左递归遍历该树\n- 直到找到**当前节点的值等于目标节点值**，即找到了目标节点\n\n搜索二叉树**插入**节点的流程：\n\n- 如果目标节点值大于当前节点值，则向右递归遍历该树\n- 如果目标节点值小于当前节点值，则向左递归遍历该树\n- 直到**遍历到底层**时（root == null），即找到了目标节点需要被插入的地方，将其父节点指向目标节点即可（目标节点肯定会被插入到树的**某个叶子节点的孩子处**）\n\n搜索二叉树**删除**节点的流程：\n\n- 若目标节点没有左右孩子，说明其是叶子节点，**直接将其父节点的对应孩子位置置空**（遍历过程中还需要记录当前节点的父节点，需要在删除了目标节点后将其父节点的对应孩子置空） \n- 若目标节点有左孩子或右孩子（但不同时存在左右孩子），则**将其父节点的对应孩子位置设置为目标节点的左或右孩子即可**（让目标节点的孩子代替自己）\n- 若目标节点同时有左孩子和右孩子，则**找到其右子树上最左的节点或左子树上最右的节点，令该节点代替自己**，并且：\n  - 若选择右子树的最左节点，则令该节点的父节点的左孩子指向该节点的右子树（令最左节点的右子树代替自己）\n  - 若选择左子树的最右节点，则令该节点的父节点的右孩子指向该节点的左子树（令最右节点的左子树代替自己）\n\n#### 左旋与右旋\n\n> https://blog.csdn.net/blueliuyun/article/details/78523937\n\n如下图所示的操作被称为**对节点Q的右旋**，**对节点P的左旋**。二者互为逆操作。即，右旋——自己变为左孩子的右孩子；左旋——自己变为右孩子的左孩子。\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/20171113195048032)\n\n#### AVL 树的自平衡实现原理\n\n> AVL 树需要满足某节点的左右子树的高度差不大于1。\n\n当 AVL 插入一个节点或删除一个节点时，**从该节点的父节点开始不断向树的顶部遍历**，逐个判断当前节点的左右子树是否满足平衡性。如果不满足则开始进行自平衡调整，具体分四种情况：\n\n- LR 型：某个节点的左孩子的右子树 subTree 过长。先进行左旋，然后进行右旋，令该右子树 subTree 的根节点成为该子树的根节点\n- LL 型：某个节点的左孩子 A 的左子树过长。只需要进行一次右旋，令该左孩子 A 成为该子树的根节点\n- RL 型：某个节点的右孩子的左子树 subTree 过长。先进行右旋，然后进行左旋，令该左子树 subTree 的根节点成为该子树的根节点\n- RR 型：某个节点的右孩子的右子树过长。只需要进行一次左旋，令该右孩子 A 成为该子树的根节点\n\n> 更多细节参考文章：https://zhuanlan.zhihu.com/p/56066942\n\n#### 节点大小平衡树\n\nSize Balanced Tree 也是一种自平衡二叉查找树，它的平衡原理是**每棵树的大小，不小于其兄弟树的子树的大小**，即每颗叔叔树的大小，不小于其他任何侄子树的大小。\n\n该树的自平衡操作同样借助于左旋和右旋操作，区别在于：\n\n- 四种分型的定义区别：例如，LL 型指当前节点的左孩子的左子树的大小，大于当前节点的右子树的大小。LL 型需要将当前节点进行右旋\n- 左右旋的操作和 AVL 树一样\n- 左右旋后，递归判断哪些节点的左右孩子变化了，对左右孩子变化了的节点递归进行该过程，直到令所有节点都符合条件\n- 与 AVL 树一样，当前子树调整完毕后，继续去其父节点上重复该过程直到整棵树完成自平衡\n\n#### 红黑树\n\n红黑树也是一种自平衡二叉查找树。红黑树的特性：\n\n- 每个节点或者是黑色，或者是红色\n- 根节点是黑色\n- 每个叶子节点（NIL）是黑色 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]\n- **如果一个节点是红色的，则它的子节点必须是黑色的**（黑色节点却无此要求）\n- **从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点**（利用该性质实现的平衡性）\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/251730074203156.jpg)\n\n## 二叉树的常见问题\n\n### 树的序列化与反序列化\n\n[剑指 Offer 37. 序列化二叉树](https://leetcode-cn.com/problems/xu-lie-hua-er-cha-shu-lcof/)：内存里的一棵树如何变成字符串形式，又如何从字符串形式变成内存里的树？两种序列化的方式：\n\n- 前序遍历顺序\n- 层次遍历顺序\n\n#### 前序遍历序列化\n\n序列化时，进行前序遍历，如果孩子节点不为空就 `append` 当前节点的 `value`，中间以 `_` 分割，如果为空需要设置为 `#`（注意这很关键，需要根据 `#` 判断何时遇到了 null），。序列化示例： `100_21_37_#_#_#_-42_0_#_#_666_#_#_`。\n\n代码：\n\n``` java\npublic static String serialByPre(Node head) {\n    StringBuilder builder = new StringBuilder();\n\n    serializeProcessByPre(head, builder);\n\n    return builder.toString();\n}\n\n// 序列化时，孩子节点为空需要设置为 #（注意这很关键，需要根据 # 判断何时遇到了 null），\n// 不为空就添加数字，中间以 _ 分割\n// 序列化示例： 100_21_37_#_#_#_-42_0_#_#_666_#_#_\npublic static void serializeProcessByPre(Node head, StringBuilder builder) {\n    if (head == null) {\n        // 遇到空节点，就添加 #，注意，这很重要\n        builder.append(\"#_\");\n        return;\n    }\n\n    // 前序遍历过程中不断将当前节点加入到 builder 里\n    builder.append(head.value).append(\"_\");\n\n    serializeProcessByPre(head.left, builder);\n    serializeProcessByPre(head.right, builder);\n}\n```\n\n#### 前序遍历反序列化\n\n反序列化时，先将序列化后的字符串 `split` 拆成字符串数组，然后再进行前序遍历，不断创建节点拼接起来，注意遇到 `#` 说明当前分支到了底，需要返回 null\n\n代码：\n\n```java\npublic static Node reconByPreString(String serialString) {\n    String[] values = serialString.split(\"_\");\n    Queue<String> queue = new LinkedList<>();\n\n    for (String value : values) {\n        queue.add(value);\n    }\n\n    return reconProcess(queue);\n}\n\n\npublic static Node reconProcess(Queue<String> queue) {\n    String value = queue.poll();\n    if (value.equals(\"#\")) {\n        return null;\n    }\n\n    // 前序遍历时先恢复出当前节点\n    Node node = new Node(Integer.parseInt(value));\n    node.left = reconProcess(queue);\n    node.right = reconProcess(queue);\n\n    return node;\n}\n```\n\n#### 层次遍历序列化与反序列化\n\n效果：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211223101721124.png\" alt=\"image-20211223101721124\" style=\"zoom:67%;\" />\n\n代码：\n\n```java\npublic class Codec {\n    public String serialize(TreeNode root) {\n        if(root == null) return \"[]\";\n        StringBuilder res = new StringBuilder(\"[\");\n        Queue<TreeNode> queue = new LinkedList<>() {{ add(root); }};\n        while(!queue.isEmpty()) {\n            TreeNode node = queue.poll();\n            if(node != null) {\n                res.append(node.val + \",\");\n                queue.add(node.left);\n                queue.add(node.right);\n            }\n            else res.append(\"null,\");\n        }\n        res.deleteCharAt(res.length() - 1);\n        res.append(\"]\");\n        return res.toString();\n    }\n\n    public TreeNode deserialize(String data) {\n        if(data.equals(\"[]\")) return null;\n        String[] vals = data.substring(1, data.length() - 1).split(\",\");\n        TreeNode root = new TreeNode(Integer.parseInt(vals[0]));\n        Queue<TreeNode> queue = new LinkedList<>() {{ add(root); }};\n        int i = 1;\n        while(!queue.isEmpty()) {\n            TreeNode node = queue.poll();\n            if(!vals[i].equals(\"null\")) {\n                node.left = new TreeNode(Integer.parseInt(vals[i]));\n                queue.add(node.left);\n            }\n            i++;\n            if(!vals[i].equals(\"null\")) {\n                node.right = new TreeNode(Integer.parseInt(vals[i]));\n                queue.add(node.right);\n            }\n            i++;\n        }\n        return root;\n    }\n}\n```\n\n\n\n\n\n### 判断一颗二叉树是不是另一棵二叉树的子树\n\n可以先把两棵树序列化，变成两个字符串，然后 `str1.isContain(str2)` 直接判断二者是否为包含关系，如果是说明 str2 是 str1 的子树。\n\n\n\n### 求一颗二叉树的最大深度\n\n#### 方法一：递归 + 模板思想\n\n``` java\npublic int maxDepth(Node root) {\n    if (root == null) {\n        return 0;\n    }\n    \n    // 返回左子树和右子树上最大深度，再加一，即为当前子树的总深度\n    return Math.max(maxDepth(root.left), maxDepth(root.right)) + 1;\n}\n```\n\n#### 方法二：递归 + 计数\n\n第一次遍历到当前节点时，count++；最后一次回到当前节点时，count--；在遇到叶子节点时再更新一次 maxLayer：\n\n``` java\npublic int maxDepth(Node root) {\n    if (root == null) {    \n        this.maxLayer = Math.max(this.maxLayer, this.count);\n        return this.maxLayer;\n    }\n\n    // 第一次来到当前节点时计数加一\n    this.count++;\n\n    maxDepth(root.left);\n    maxDepth(root.right);\n    \n    // 最后一次回到当前节点时计数减一\n    this.count--;\n    return this.maxLayer;\n}\n```\n\n#### 方法三：层次遍历 + 计数\n\n使用层次遍历顺序，依次将每一层的节点入队，并且每次遍历一整层的节点，将其左右孩子依次入队，最后再更新一次树的深度。\n\n``` java\npublic int maxDepth(Node root) {\n    if (root == null) {\n        return 0;\n    }\n\n    // 准备队列用于层次遍历\n    Queue<Node> queue = new LinkedList<>();\n    queue.add(root);\n    int maxLayer;\n\n    while (!queue.isEmpty()) {\n        int size = queue.size();\n\n        // 将当前队列中存储的节点依次弹出，同时将每个节点的左右孩子都加进去\n        while (size-- > 0) {\n            Node curr = queue.poll();\n            if (curr.left != null)\n                queue.add(curr.left);\n            if (curr.right != null) \n                queue.add(curr.right);\n\n        }\n\n        // 当前层遍历完成后，更新最大深度\n        maxLayer++;   \n    }\n    return maxLayer;\n}\n```\n\n\n\n\n\n\n\n\n\n### 求一颗二叉树的最大宽度\n\n可以在**层次遍历**的基础上完成该问题的求解。\n\n首先设置几个关键变量：\n\n- `maxWidth`：要求的目标，整棵二叉树的最大宽度。该值将由最大的`nextWidth`决定\n- `nextWidth`：当前层的下一层的宽度，将在遍历当前层的孩子节点时不断增大\n- `currLayer`：当前层的编号，用于判断何时开始换层\n\n并且需要一个`HashMap`用于存储每一个节点的层编号信息。\n\n方法思路：\n\n- 首先将根节点入队，并在`HashMap`中设置其层数编号为1，初始化三个关键参数都为1\n- 弹出队首节点，获取其层数，并与当前层数`currLayer`对比\n  - 若当前层数小于弹出的队首节点，说明该换层了，则将变量进行更新：将下一层宽度`nextWidth`置空（因为换层后来到的新层还没开始遍历，所以新层的下一层宽度就是0，在后续遍历时才会开始逐渐增加），并更新最大宽度`maxWidth`\n  - 若当前层数等于弹出的队首节点，说明还在当前这一层，不需要做额外操作\n- 遍历当前层，获取当前节点的左右孩子，若存在则放入`HashMap`中，并保存其孩子的层数编号为`currLayer + 1`，同时将下一层宽度 `nextWidth++`，因为当前节点的某一个子孩子被遍历到了，所以下一层宽度加一（在最底层时，因为都没孩子节点了，所以 `nextWidth` 不会增加，这也符合逻辑）\n- 重复上面步骤，直到队列为空\n\n其中细节：\n\n- `nextWidth `保存的是下一层的节点数，其将在换层时，与 `maxWidth` 对比，为其赋值\n- 因为每次对比的时候，给 `maxWidth` 赋值的都是下一层的宽度，所以在跳到最后一层的第一个节点时，给 `maxWidth` 附上了最后一层的信息，所以避免了漏层\n- 每次更新`maxWidth`的时机都是在换层时，即遍历到下一层的第一个节点时，将原本下一层的宽度值 `nextWidth`（该值在其上一层遍历左右孩子的时候就已经被更新了，所以这里可以直接获取到，相当于提前更新了下一层的节点数）与当前最大宽度 `maxWidth` 对比并赋值。\n\n方法思想：层次遍历。提前计算好下一层的最大宽度，在换层时直接提前赋值给 `maxWidth` ，避免了漏层。\n\n代码：\n\n```java\npublic static void getTreeMaxWidth(Node head) {\n    if (head == null) {\n        return;\n    }\n\n    int maxWidth = 1;\n    int nextWidth = 1;\n    int currLayer = 1;\n    Map<Node, Integer> map = new HashMap<>();\n    Queue<Node> queue = new LinkedList<>();\n    queue.add(head);\n    map.put(head, 1);\n\n    while (!queue.isEmpty()) {\n        Node curr = queue.poll();\n        // 如果当前层数小于出队的节点的层数，说明该换层了\n        // 换层时，将下一层宽度置空 nextWidth = 0，并更新最大宽度\n        if (currLayer < map.get(curr)) {\n            maxWidth = Math.max(nextWidth, maxWidth);\n            currLayer++;\n            nextWidth = 0;\n        }\n\n        // 注意：nextWidth 记录的是下一层的节点数\n        if (curr.left != null) {\n            queue.add(curr.left);\n            // 左右孩子对应的层数是当前层数+1\n            map.put(curr.left, currLayer+1);\n            nextWidth++;\n        }\n        if (curr.right != null) {\n            queue.add(curr.right);\n            map.put(curr.right, currLayer+1);\n            nextWidth++;\n        }\n    }\n\n    System.out.println(\"max with = \" + maxWidth);\n}\n```\n\n#### 层次遍历优化\n\n可以对上述代码进行优化。层次遍历时，可以进行双层 while 循环，外层循环判断当前树的节点是否全部都遍历过，内层循环则负责**循环当前层的所有节点**。\n\n具体做法为：在内层 while 循环开始遍历前，首先计算当前队列内的节点个数。这个数字，其实就是**目前队列中当前层节点的个数**。\n\n> 原因：在内层 while 循环里，每次都将当前层的所有节点依次弹出，同时把其左右孩子都入队，这就导致了，第 N 层的 M 个节点都遍历后，队列里就 add 了第 N+1 层的所有节点，这样再进入下一次外层的 while 循环后，再次计算队列里的节点个数时，得到的数量就是第 N+1 层的节点个数。\n\n利用这种思想，可以一次性遍历一整层的节点，从而十分方便地计算当前层宽度\n\n> 记得当每进入一次外层循环时就令 count = 0，在每一次外层循环即将结束，更新 maxWidth\n\n优化后代码：\n\n```java\npublic static int getTreeMaxWidth3(Node head) {\n    if (head == null)\n        return 0;\n\n    Queue<Node> queue = new LinkedList<>();\n    queue.add(head);\n    int maxWidth = 0;\n    int count = 0;\n\n    while (!queue.isEmpty()) {\n        // 首先别忘了将当前层节点个数清空\n        count = 0;\n\n        int size = queue.size();\n        // 依次遍历当前层内所有节点\n        while (size-- > 0) {\n            Node curr = queue.poll();\n            if (curr.left != null)\n                queue.add(curr.left);\n            if (curr.right != null)\n                queue.add(curr.right);\n            // 每遍历一个当前层的节点，就更新一次最大宽度\n            count++;\n        }\n        // 每遍历一次当前层节点，就更新一次最大宽度\n        maxWidth = Math.max(maxWidth, count);\n    }\n    return maxWidth;\n}\n```\n\n### 重建二叉树\n\n输入某二叉树的前序遍历和中序遍历的结果，请构建该二叉树并返回其根节点。假设输入的前序遍历和中序遍历的结果中都不含重复的数字。\n\n思路：\n\n- 先将中序数组里的所有数字及其对应的索引都加入到一个**哈希表**中，用于快速查询到前序数组中某个根节点在中序数组中的位置，从而**根据该位置将中序数组划分为左右两半**\n- 递归方法传入参数：\n  - preRoot：**前序**数组中**当前子树的根节点的索引值**，使用该值创建出树结构，并去中序哈希表里查找该根节点在中序数组中的位置\n  - inleft, inright：**中序**数组中**当前子树的左右边界索引值**，代表当前子树包含的节点只可能在此区间内\n- 根据传入的 preRoot 创建出对应的树节点，然后利用中序哈希表定位到该节点在中序数组中的位置 i，并据此将中序数组划分为左右两个区间：\n  - 中序数组中左子树的范围：[inleft, i - 1]\n  - 中序数组中右子树的范围：[i + 1, inright]\n- 根据划分出来的左右子树范围，计算出当前节点的左右子树的根节点（新一轮递归中的根节点）在前序数组中的位置：\n  - preRoot 的左子树的根节点：preRoot + 1\n  - preRoot 的左子树的根节点：preRoot + leftLength + 1 = preRoot  + i - inleft + 1\n- 使用计算出的新根节点位置（在前序数组中）以及新根节点的左右边界范围（在中序数组中）进行递归，直到 left > right 时递归返回。\n\n![image-20211206145926473](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211206145926473.png)\n\n代码：\n\n``` java\nclass Solution {\n    Map<Integer, Integer> inorderMap;\n\n    public TreeNode buildTree(int[] preorder, int[] inorder) {\n        // inorder 先存储到哈希表中\n        this.inorderMap = new HashMap<>();\n        for (int i = 0; i < inorder.length; i++) {\n            // 存储每个元素值以及其对应的下标，用于快速定位该元素\n            inorderMap.put(inorder[i], i);\n        }\n        return buildTreeHelper(preorder, 0, 0, inorder.length - 1);\n    }\n\n    public TreeNode buildTreeHelper(int[] preorder, int preRoot, int inleft, int inright) {\n        // 如果中序数组的左边界大于右边界，则不能继续递归了\n        if (inleft > inright) {\n            return null;\n        }\n\n        TreeNode currRoot = new TreeNode(preorder[preRoot]);\n        // 从中序哈希表中找出当前根节点的位置\n        int i = this.inorderMap.get(preorder[preRoot]);\n\n        // 前序数组中左子树的根节点为 preRoot + 1\n        // 中序数组中左子树的范围：[inleft, i - 1]\n        currRoot.left = buildTreeHelper(preorder, preRoot + 1, inleft, i - 1);\n        // 左子树的长度为：i-1 - left + 1\n        int leftLength = i - inleft;\n        // 前序数组中右子树的根节点为 preRoot + leftLength + 1\n        // 中序数组中右子树的范围：[i + 1, inright]\n        currRoot.right = buildTreeHelper(preorder, preRoot + leftLength + 1, i + 1, inright);\n\n        return currRoot;\n    }\n}\n```\n\n\n\n### 二叉搜索树的最近公共祖先\n\n本题给定了两个重要条件：\n\n- 树为**二叉搜索树**\n- 树的所有节点的值都是**唯一**的。\n\n根据以上条件，可方便地判断 p，q 与 root 的子树关系，即：\n\n- 若 `root.val < p.val`，则 p 在 root 右子树 中；\n- 若 `root.val > p.val`，则 p 在 root 左子树 中；\n- 若 `root.val = p.val`，则 p 和 root 指向同一节点 。\n\n#### 方法一：迭代\n\n循环搜索： 当节点 root 为空时跳出；\n\n- 当 p，q 都在 root 的**右子树**中，则遍历至 root.right；\n- 否则，当 p，q 都在 root 的**左子树**中，则遍历至 root.left；\n- 否则，说明找到了**最近公共祖先 **，跳出。\n\n代码：\n\n``` java\n// 迭代版本\npublic TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {\n    while (true) {\n        if (root.val < p.val && root.val < q.val) {\n            // p,q 在 root 的右子树\n            root = root.right;\n        } else if (root.val > p.val && root.val > q.val) {\n            // p,q 在 root 的左子树\n            root = root.left;\n        } else {\n            break;\n        }\n    }\n    return root;\n}\n```\n\n#### 方法二：递归\n\n递推工作：\n\n- 当 p，q 都在 root 的**右子树**中，则开启递归 root.right 并返回；\n- 否则，当 p，q 都在 root 的**左子树**中，则开启递归 root.left 并返回；\n\n返回值：最近公共祖先 root 。\n\n代码：\n\n``` java\n// 递归版本\npublic TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {\n    if(root.val < p.val && root.val < q.val)\n        return lowestCommonAncestor(root.right, p, q);\n    if(root.val > p.val && root.val > q.val)\n        return lowestCommonAncestor(root.left, p, q);\n    return root;\n}\n```\n\n\n\n### 二叉树的最低公共祖先\n\n#### 方法一：递归\n\n本题是普通的树，而非二叉搜索树，因此不能简单的判断当前节点值是否小于或大于p，q的值。而应该在递归过程中判断当前节点的值是否等于 p 或 q：\n\n- 如果当前节点为空，则返回 null\n- 若相等，则找到了二者中的某一个，直接向上返回该节点（如果是 p 是 q 的祖先的情况，则此时返回的就是二者中更靠上层的节点，也就是另一个节点的最近祖先）\n- 若不相等，则继续递归向下寻找是够有节点等于 p 或 q\n\n递归方法的返回值共有四种情况：\n\n- 如果 **left，right 都为空**，则当前子树上不包含二者，直接返回 null\n- 如果**二者都不为空**，则当前 root 即为二者的最近公共祖先，返回 root（root 就是左右子树上的 p 和 q 的公共祖先节点）\n- 如果**左子树为空**，**右子树不为空**，则右子树上有 p 或 q（或者都有），左子树上肯定没有 p 和 q，返回 right（right 就是右子树递归向下寻找到的那个等于 p 或 q 的节点，或者是二者的某个祖先节点，该节点被一路向上返回，直到得到答案）\n- 如果**右子树为空**，**左子树不为空**，则左子树上有 p 或 q（或者都有），右子树上肯定没有 p 和 q，返回 left\n\n图解该过程：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211214214247676.png\" alt=\"image-20211214214247676\" style=\"zoom:67%;\" />\n\n代码：\n\n``` java\npublic TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) {\n    // base case，到底时返回null\n    if (root == null || p == null || q == null) {\n        return null;\n    }\n    if (p.val == root.val) {\n        return root;\n    } else if (q.val == root.val) {\n        return root;\n    }\n\n    TreeNode left = lowestCommonAncestor(root.left, p, q);\n    TreeNode right = lowestCommonAncestor(root.right, p, q);\n    // 共有四种情况\n    // 1. left,right 都为空，则当前子树上不包含二者，直接返回null\n    if (left == null && right == null) {\n        return null;\n    }\n    // 2. 如果二者都不为空，则当前root即为二者的最近公共祖先，返回root\n    if (left != null && right != null) {\n        return root;\n    }\n    // 3. 如果左子树为空，右子树不为空，则右子树上有p或q（或者都有），左子树上肯定没有p和q，返回right\n    if (left == null && right != null) {\n        return right;\n    }\n    // 4. 如果右子树为空，左子树不为空，则左子树上有p或q（或者都有），右子树上肯定没有p和q，返回left\n    if (right == null && left != null) {\n        return left;\n    }\n    // 应该不会来到这里的\n    return null;\n}\n```\n\n\n\n#### 方法二：哈希表记录每个节点的父节点\n\n思路：\n\n1. 第一次遍历二叉树时，使用一个 `HashMap` 存放每个节点的头节点\n2. 然后借助于第一步获取的 `HashMap` 遍历 o1 的祖先节点们，使用一个 `HashSet` 存放 o1 节点的祖先节点（注意要包含 o1 自身）\n3. 最后遍历 o2 的祖先节点们，判断当前节点是否在第二步创建的 `HashSet` 里（注意要包含 o2 自身），如果在，说明该节点就是二者的最低公共祖先\n\n需要注意步骤2,3里存储 o1 的祖先节点时需要将 o1 自身也存进去，遍历 o2 的祖先节点时需要将 o2 也进行判断。这是为了在 o1、o2 在同一条链上时不会漏掉 o1 或 o2 自身。\n\n代码：\n\n```java\npublic static Node lowestCommonAncestor(Node head, Node o1, Node o2) {\n    // 先将头结点自身添加到 map 中，设置头结点为自己\n    Map<Node, Node> fatherMap = new HashMap<>();\n    fatherMap.put(head, head);\n\n    process(head, fatherMap);\n\n    Set<Node> set1 = new HashSet<>();\n    Node curr = o1;\n\n    // 先将自身添加到 set1 里，避免 o1 就是 o2 祖先节点时漏放 o1 造成出错\n    // 注意：必须要把 o1 自身也加到 Set 里，不然如果出现 o1 和 o2 在同一条链上（例如 o1 是 o2 的祖先）的情况下\n    // 如果 o1 自身没加到 Set 里，o2 在找祖先节点时就会漏掉 o1\n    set1.add(o1);\n\n    // 从 o1 开始向上沿着自己的父节点遍历，直到找到根节点 head（因为只有 head 的 father 等于自身）\n    while (curr != fatherMap.get(curr)) {\n        // 先找到 curr 的父节点\n        // 然后不断将 o1 的祖先结点们添加到 set1 中，直到最后将 head 添加进去\n        curr = fatherMap.get(curr);\n        set1.add(curr);\n    }\n    // 上面那种顺序就不再需要将 head 添加到 set1 中，因为在临界条件时就已经加进去了\n    // set1.add(head);\n\n    curr = o2;\n    // 开始遍历 o2 的祖先节点们（注意，遍历时要包括 o2 自己）\n    while (curr != fatherMap.get(curr)) {\n        // 下面两句顺序不能反，必须先判断当前节点在不在 set1 里，因为可能 o2 就是其中的某一个节点\n        // 如果顺序反了，就漏掉了 o2\n        if (set1.contains(curr))\n            return curr;\n        curr = fatherMap.get(curr);\n    }\n\n    return null;\n}\n\npublic static void process(Node head, Map<Node, Node> fatherMap) {\n    if (head == null) {\n        return;\n    }\n\n    // 将当前节点的左右孩子节点添加到 map 中\n    if (head.left != null)\n        fatherMap.put(head.left, head);\n    if (head.right != null)\n        fatherMap.put(head.right, head);\n\n    // 递归，令子节点也添加自己的左右孩子节点到 map 中\n    process(head.left, fatherMap);\n    process(head.right, fatherMap);\n}\n```\n\n\n\n### 寻找二叉树的后继节点\n\n#### 方法一：中序遍历 + 存储节点到 List 中\n\n简单的想法是在中序遍历的过程中将每个节点保存到一个 List 中，然后再在该 List 里找到其下一个节点即为其后继节点。但是代价是时间复杂度为 O(N)，并且空间复杂度也为 O(N)。\n\n#### 方法二：借助父节点\n\n如果已知每一个节点的父节点，那么其实目标节点寻找距离自己 K 单位的后继节点所耗费的时间复杂度可以优化到 O(K)。\n\n共有三种情况：\n\n- 目标节点有右孩子：此时目标节点的右孩子所在的**右子树上最左边的节点**就是当前节点的后继节点，对应下图中的情况1\n- 目标节点没有右孩子：则一直向上遍历他的父节点，直到**当前节点是其父节点的左孩子**，则这个父节点就是目标节点的后继节点，对应下图中的情况2\n- 目标节点是整棵树最右侧的节点：其后继节点为 null，对应下图中的情况2中的黄色节点\n\n图解：\n\n![幻灯片1](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/%E5%B9%BB%E7%81%AF%E7%89%871-1634726617676.PNG)\n\n代码：\n\n```java\n// 传参只需要待求的节点\npublic static Node getSuccessorNode(Node node) {\n    if (node == null)\n        return null;\n\n    // 1. 如果目标节点有右孩子，则右孩子所在的右子树上最左边的节点就是 node 的后继节点\n    if (node.right != null) {\n        return getLeftMostNode(node.right);\n    }\n\n    // 2. 如果目标节点没有右孩子，则一直向上遍历他的父节点，直到当前节点是其父节点的左孩子\n    //    这种情况对应了 while 循环里的第二条判断条件，当其满足时即找到了后继节点\n    // 3. 同样包括了第三种情况：node 为整棵树最右的那个节点，其后继节点为 null，\n    //    这种情况对应了 while 循环里的第一条判断条件，当其满足时，node 就是 head，最后 return head.parent == null\n    while (node.parent != null && node != node.parent.left) {\n        node = node.parent;\n    }\n    // 注意要返回的是 parent 而不是 node，因为他跳出 while 循环时，node 是要求的后继节点的左孩子\n    // 需要返回 node.parent\n    return node.parent;\n}\n\n// 寻找子树上的最左节点，不需要递归，直接一直找左孩子即可\npublic static Node getLeftMostNode(Node node) {\n    if (node == null) {\n        return null;\n    }\n\n    while (node.left != null) {\n        node = node.left;\n    }\n    return node;\n}\n```\n\n\n\n### 翻转二叉树\n\n**翻转的本质是：交换每个节点的左右孩子**。\n\n#### 方法一：递归 + 交换左右孩子\n\n在递归时，不断交换当前节点的左右孩子节点，如此下去，最后就完成了整棵树的翻转。\n\n代码：\n\n```java\npublic Node invertTree(Node root) {\n    //递归函数的终止条件，节点为空时返回\n    if(root == null) {\n        return null;\n    }\n    //下面三句是将当前节点的左右子树交换\n    Node tmp = root.right;\n    root.right = root.left;\n    root.left = tmp;\n    //递归交换当前节点的 左子树\n    invertTree(root.left);\n    //递归交换当前节点的 右子树\n    invertTree(root.right);\n    //函数返回时就表示当前这个节点，以及它的左右子树\n    //都已经交换完了\n    return root;\n}\n```\n\n#### 方法二：层次遍历 + 交换左右孩子\n\n也可以使用层次遍历。在层次遍历的过程中，先将当前节点的左右孩子进行交换，然后再放入队列中。\n\n代码：\n\n```java\npublic Node invertTree(Node root) {\n    if(root==null) {\n        return null;\n    }\n    //将二叉树中的节点逐层放入队列中，再迭代处理队列中的元素\n    LinkedList<Node> queue = new LinkedList<>();\n    queue.add(root);\n    while(!queue.isEmpty()) {\n        //每次都从队列中拿一个节点，并交换这个节点的左右子树\n        Node tmp = queue.poll();\n        Node left = tmp.left;\n        tmp.left = tmp.right;\n        tmp.right = left;\n        //如果当前节点的左子树不为空，则放入队列等待后续处理\n        if(tmp.left!=null) {\n            queue.add(tmp.left);\n        }\n        //如果当前节点的右子树不为空，则放入队列等待后续处理\n        if(tmp.right!=null) {\n            queue.add(tmp.right);\n        }\n    }\n    //返回处理完的根节点\n    return root;\n}\n```\n\n该方法的空间复杂度会比第一种方法更大。\n\n\n\n### 对称的二叉树\n\n> https://leetcode-cn.com/problems/dui-cheng-de-er-cha-shu-lcof/\n\n请实现一个函数，用来判断一棵二叉树是不是对称的。如果一棵二叉树和它的镜像一样，那么它是对称的。例如，二叉树 [1,2,2,3,4,4,3] 是对称的。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/ebf894b723530a89cc9a1fe099f36c57c584d4987b080f625b33e228c0a02bec-Picture1.png\" alt=\"img\" style=\"zoom: 50%;\" />\n\n思路：递归时每次传入一对节点（这两个节点是位置对称的），例如传入 L.left  和 R.right；另一个递归方法传入 L.right 和 R.left。这样保证每次递归方法里的节点都是位置对称的，因此只需要判断这两个节点的值是否相同即可。\n\n代码：\n\n``` java\nclass Solution {\n    public boolean isSymmetric(TreeNode root) {\n        if (root == null) {\n            return true;\n        }\n        return recur(root.left, root.right);\n    }\n\n    public boolean recur(TreeNode leftSubTree, TreeNode rightSubTree) {\n        // 1. 判断 leftSubTree ?= rightSubTree\n\n        // 这两个判断不需要在当前层进行，将会在下一层进行比较\n        // 2. 判断 leftSubTree.left ?= rightSubTree.right\n        // 3. 判断 leftSubtree.right ?= rightSubTree.left \n        \n        // 一对一对的递归，递归时判断这一对是不是对称的\n        // 如果所有对都是对称的，整体就是对称的\n\n        if (leftSubTree == null || rightSubTree == null) {\n            return leftSubTree == rightSubTree ? true : false;\n        }\n\t\t\n        // 判断当前的这一对对称位置的节点是否值相等\n        if (leftSubTree.val != rightSubTree.val) {\n            return false;\n        }\n\n        // 将两对对称的节点继续递归\n        return recur(leftSubTree.left, rightSubTree.right) && recur(leftSubTree.right, rightSubTree.left);\n    }\n}\n```\n\n### 树的子结构\n\n> https://leetcode-cn.com/problems/shu-de-zi-jie-gou-lcof/solution/mian-shi-ti-26-shu-de-zi-jie-gou-xian-xu-bian-li-p/\n\n输入两棵二叉树A和B，判断B是不是A的子结构。（约定空树不是任意一个树的子结构）\n\nB是A的子结构， 即A中有出现和B相同的结构和节点值。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211202111942469.png\" alt=\"image-20211202111942469\" style=\"zoom: 67%;\" />\n\n思路：双递归，一个递归寻找A中哪个节点与B树的根节点相同；另一个递归在找到相同的节点后开始深入A的当前局部子树进行递归。示意图：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/27d9f65b79ae4982fb58835d468c2a23ec2ac399ba5f38138f49538537264d03-Picture1.png\" alt=\"img\" style=\"zoom: 50%;\" />\n\n算法流程：\n\n> 名词规定：**树 A\\*A\\*** 的根节点记作 **节点 A\\*A\\*** ，**树 B\\*B\\*** 的根节点称为 **节点 B\\*B\\*** 。\n\n**`recur(A, B)` 函数：**\n\n- 终止条件：\n  - 当节点 B 为空：说明树 B 已匹配完成（越过叶子节点），因此返回 true\n  - 当节点 A 为空：说明已经越过树 A 叶子节点，即匹配失败，返回 false\n  - 当节点 A 和 B 的值不同：说明匹配失败，返回 false\n- 返回值：\n  - 判断 A 和 B 的左子节点是否相等，即 `recur(A.left, B.left) `\n  - 判断 A 和 B 的右子节点是否相等，即 `recur(A.right, B.right)` \n\n**`isSubStructure(A, B)` 函数：**\n\n- 特例处理： 当 树 A 为空 或 树 B 为空 时，直接返回 false\n- 返回值： 若树 B 是树 A 的子结构，则必满足以下三种情况之一，因此用或 || 连接\n  - 以 节点 A 为根节点的子树 包含树 BB ，对应 `recur(A, B)`\n  - 树 B 是 树 A 左子树 的子结构，对应 `isSubStructure(A.left, B)`\n  - 树 B 是 树 A 右子树 的子结构，对应 `isSubStructure(A.right, B)`\n\n> 以上 `2.` `3.` 实质上是在对树 A*A* 做 **先序遍历** 。\n\n复杂度分析：\n\n- 时间复杂度 O(MN) ： 其中 M,N 分别为树 A 和 树 B 的节点数量；先序遍历树 A 占用 O(M) ，每次调用 `recur(A, B) `判断占用 O(N) 。\n- 空间复杂度 O(M)： 当树 A 和树 B 都退化为链表时，递归调用深度最大。当 M ≤ N 时，遍历树 A 与递归判断的总递归深度为 M ；当 M>N 时，最差情况为遍历至树 A 叶子节点，此时总递归深度为 M。\n\n代码：\n\n\n```java\n// 题解：简洁形式\npublic boolean isSubStructure(TreeNode A, TreeNode B) {\n    return (A != null && B != null) && (recur(A, B) || isSubStructure(A.left, B) || isSubStructure(A.right, B));\n}\n\nboolean recur(TreeNode A, TreeNode B) {\n    // 如果B为空，说明B遍历到底了，当前分支下是相同的子结构，递归返回开始判断其他分支是否也是相同子结构\n    if(B == null) return true;\n    // 如果B不为空，但A为空；或者B和A的值不同，说明B不是A的子结构\n    if(A == null || A.val != B.val) return false;\n    // 只有在左子树和右子树都为true才说明整体也是true\n    return recur(A.left, B.left) && recur(A.right, B.right);\n}\n\n// 我自己的：\npublic boolean isSubStructure(TreeNode A, TreeNode B) {\n    if(A == null || B == null){\n        return false;\n    }\n    boolean res = false;\n\n    // 注意是判断 值 是否相同，而不是节点是否相同\n    // 并且注意，不能直接返回！！因为可能目标位置很靠下，在书的上层就有一个A和值和B的值相同，如果在这里就返回了，就会漏掉下面的正确结构，直接返回false了，就错误了\n    if (A.val == B.val) {\n        res |= f(A, B);\n    }    \n    res |= isSubStructure(A.left, B);\n    res |= isSubStructure(A.right, B);\n    return res;\n    // 上面这几行也可以写成：\n    // 1. 当前A位置组成的子树是否包含B树 || 2. 当前左子树是否包含B树 || 3. 当前右子树是否包含B树\n    return f(A, B) || isSubStructure(A.left, B) || isSubStructure(A.right, B);\n    // 按照树形DP的模板套路可以理解为：\n    //    1. 考虑当前节点A的情况：f(A, B)\n    //    2. 不考虑当前节点A的情况：\n    //       2.1 左子树是否满足 isSubStructure(A.left, B)\n    //       2.2 右子树是否满足 isSubStructure(A.right, B)  \n        \n    // 再精简一下就是：    \n    // return (A != null && B != null) && (recur(A, B) || isSubStructure(A.left, B) || isSubStructure(A.right, B));\n}\n\npublic boolean f(TreeNode a, TreeNode b) {\n    // a为空说明走到底了，但是b又不为空，说明不是子结构返回false\n    if (a == null) {\n        return false;\n    }\n\n    // 二者如果不相等，说明肯定不是子结构（因为b能进这层循环就不为空，a经过前面判断也不为空，则说明a和b都有值也不相等，则不是子结构）\n    if (a.val != b.val) {\n        return false;\n    }\n\n    boolean res = true;\n\n    if (b.left != null) {\n        res &= f(a.left, b.left);\n    } \n    if (b.right != null) {\n        res &= f(a.right, b.right);\n    }\n    return res;\n}\n```\n\n### 二叉树中和为某一值的路径\n\n[剑指 Offer 34. 二叉树中和为某一值的路径](https://leetcode-cn.com/problems/er-cha-shu-zhong-he-wei-mou-yi-zhi-de-lu-jing-lcof/)：给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有从根节点到叶子节点 路径总和等于给定目标和的路径。叶子节点是指没有子节点的节点。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211210110655646.png\" alt=\"image-20211210110655646\" style=\"zoom: 50%;\" />\n\n#### 方法一：深度优先遍历\n\n- **前序遍历：** 按照 “根、左、右” 的顺序，遍历树的所有节点。\n- **路径记录：** 在先序遍历中，记录从根节点到当前节点的路径。当路径为 ① 根节点到叶节点形成的路径 **且** ② 各节点值的和等于目标值 `sum` 时，将此路径加入结果列表。\n\n> 注意：记录路径时若直接执行 res.append(path) ，则是将 path 对象加入了 res ；后续 path 改变时， res 中的 path 对象也会随之改变。正确做法：res.append(list(path)) ，相当于复制了一个 path 并加入到 res 。\n\n```java\nList<List<Integer>> res = new LinkedList<List<Integer>>();\nDeque<Integer> path = new LinkedList<Integer>();\n\npublic List<List<Integer>> pathSum(TreeNode root, int target) {\n    dfs(root, target);\n    return ret;\n}\n\npublic void dfs(TreeNode root, int target) {\n    if (root == null) {\n        return;\n    }\n    // 先添加当前节点的值，代表来过当前节点\n    path.offerLast(root.val);\n    // 更新target\n    target -= root.val;\n    // 如果当前节点时叶子节点，且 target == 0，则找到了一条符合题意的分支，进行保存\n    // 注意！！！保存时需要另外复制一份path，否则path其随着方法栈返回会被修改\n    if (root.left == null && root.right == null && target == 0) {\n        res.add(new LinkedList<Integer>(path));\n    }\n    dfs(root.left, target);\n    dfs(root.right, target);\n    // 左右子树遍历完后，记得删掉之前添加的值\n    path.pollLast();\n}\n```\n\n#### 方法二：广度优先搜索\n\n也可以采用广度优先搜索的方式遍历这棵树。当我们遍历到叶子节点，且此时路径和恰为目标和时，我们就找到了一条满足条件的路径。\n\n为了节省空间，我们**使用哈希表记录树中的每一个节点的父节点**。每次找到一个满足条件的节点，我们就**从该节点出发不断向父节点迭代**，即可还原出从根节点到当前节点的路径。\n\n代码：\n\n``` java\nList<List<Integer>> ret = new LinkedList<List<Integer>>();\nMap<TreeNode, TreeNode> map = new HashMap<TreeNode, TreeNode>();\n\npublic List<List<Integer>> pathSum(TreeNode root, int target) {\n    if (root == null) {\n        return ret;\n    }\n\n    Queue<TreeNode> queueNode = new LinkedList<TreeNode>();\n    Queue<Integer> queueSum = new LinkedList<Integer>();\n    queueNode.offer(root);\n    queueSum.offer(0);\n\n    while (!queueNode.isEmpty()) {\n        TreeNode node = queueNode.poll();\n        int rec = queueSum.poll() + node.val;\n\n        if (node.left == null && node.right == null) {\n            if (rec == target) {\n                getPath(node);\n            }\n        } else {\n            if (node.left != null) {\n                map.put(node.left, node);\n                queueNode.offer(node.left);\n                queueSum.offer(rec);\n            }\n            if (node.right != null) {\n                map.put(node.right, node);\n                queueNode.offer(node.right);\n                queueSum.offer(rec);\n            }\n        }\n    }\n\n    return ret;\n}\n\npublic void getPath(TreeNode node) {\n    List<Integer> temp = new LinkedList<Integer>();\n    while (node != null) {\n        temp.add(node.val);\n        node = map.get(node);\n    }\n    Collections.reverse(temp);\n    ret.add(new LinkedList<Integer>(temp));\n}\n```\n\n\n\n### 二叉搜索树的后序遍历序列\n\n[剑指 Offer 33. 二叉搜索树的后序遍历序列](https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-hou-xu-bian-li-xu-lie-lcof/)：输入一个整数数组，判断该数组是不是某二叉搜索树的后序遍历结果。如果是则返回 `true`，否则返回 `false`。假设输入的数组的任意两个数字都互不相同。\n\n解决该问题的关键在于理解后序遍历在数组中的体现：\n\n- 根节点位置：后序遍历：在数组的**最后一个**位置\n- 左右子树的分布特点：后序遍历：左 -> 右 -> 根\n\n因此重点在于**如何确定左右子树间的边界**。\n\n#### 方法一：递归分治\n\n一种思路是：根据二叉搜索树的特点，左子树区间内的值都应该小于当前根节点值，右子树区间内的值都应该大于当前根节点值。那么从左往右遍历一遍数组，定位到：第一个大于根节点值的位置 m，则 [left, m - 1] 为左子树区间；[m, right - 1] 为右子树区间。然后继续在右子树区间内遍历，直到与 right 位置相遇。如果无法相遇则代表当前子树不符合；如果可以相遇则代表当前子树符合，那么接着开始递归判断左子树 [left, m - 1] 是否符合，右子树 [m, right - 1] 是否符合。\n\n示意图：\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211218190011688.png\" alt=\"image-20211218190011688\" style=\"zoom: 67%;\" />\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211218190051540.png\" alt=\"image-20211218190051540\" style=\"zoom:67%;\" />\n\n代码：\n\n``` java\nclass Solution {\n    public boolean verifyPostorder(int[] postorder) {\n        return recur(postorder, 0, postorder.length - 1);\n    }\n\n    public boolean recur(int[] postorder, int left, int right) {\n        if (left >= right) {\n            return true;\n        }\n\n        // 当前子树的范围[left, right]，因为是后序遍历，所以当前子树的根节点必定是postorder[right]的值，\n        int i = left;\n        // 一直遍历到第一个大于postorder[right]的位置m，m-1就是当前根节点的左子树的根节点（子数组里的右边界right）\n        // 1. 当前遍历的是左子树\n        while (postorder[i] < postorder[right]) {\n            i++;\n        }\n        // 记录一下第一个大于根节点值的位置，该位置理论上来说是右子树的左边界（最左结点），m-1是左子树的右边界\n        int m = i;\n        // 2. 接着遍历右子树，如果是符合二叉搜索树，则肯定是都比rootValue大的，那么就能一直遍历到right\n        while (postorder[i] > postorder[right]) {\n            i++;\n        }\n        // 如果i != right，则i没有能顺利遍历到right位置，说明肯定不是二叉搜索树（否则肯定能遍历到right位置）\n\t\t// 如果i == right，则当前以postorder[right]为根节点的子树是符合二叉搜索树的，接着开始递归判断该树的左右子树是否也是满足的\n        // 根节点：right  左子树范围：[left, m - 1]，右子树范围：[m, right - 1]\n        return i == right && recur(postorder, left, m - 1) && recur(postorder, m, right - 1);\n    }\n}\n```\n\n#### 方法二：单调栈\n\n\n\n#### 方法三：倒序重建\n\n可以尝试倒序重建整棵二叉树，如果重建过程中发现不符合就返回 false。当然不是重建出整棵树的结构，而是判断当前根节点（当前子数组的最后一个节点）是否在合适区间内：\n\n- 当前根节点的右子树的根节点的值应该大于当前的值且小于最大值\n- 当前根节点的左子树的根节点的值应该小于当前的值且大于最小值\n\n参考的 python 代码：\n\n``` python\nclass Solution:\n    def verifyPostorder(self, postorder: List[int]) -> bool:\n        def build(postorder: List[int], ma: int, mi: int):\n            if not postorder: return\n            val = postorder[-1]\n            if not mi < val < ma: return\n            postorder.pop() # 根\n            build(postorder, ma, val) # 右\n            build(postorder, val, mi) # 左\n\n        build(postorder, sys.maxsize, -sys.maxsize)\n        return not postorder\n```\n\n\n\n## 二叉树中序遍历的常见题目\n\n### 模板\n\n许多二叉树问题都可以使用中序遍历 + `pre` 变量的套路解决。在中序遍历的过程中，使用 `pre` 变量不断记录当前节点的前一个节点，从而解决问题。其中中序遍历的实现既可以使用递归栈又可以使用 Morris 遍历。\n\n**模板一：递归**\n\n``` java\n// pre 变量不断记录当前节点的前一个节点\npublic Node pre;\n\npublic void template01(Node root) {\n    if (root == null) {\n        return null;\n    }\n    dfs(root);\n}\n\nvoid dfs(Node cur) {\n    if (cur == null) {\n        return;\n    }\n    dfs(cur.left);\n\n    // 如果 pre 已存在（后续的所有节点都符合该情况），则进行业务\n    if (pre != null) {\n        // 此处进行具体业务：例如比较pre和curr的大小等\n    } else {\n        // 如果还未设置，此时到达整棵树的最左侧节点（中序遍历的第一个节点），将该节点设置为 pre\n        // 记得更新pre\n        pre = curr;\n    }\n\n    dfs(cur.right);\n}\n```\n\n**模板二：Morris 遍历**\n\n``` java\npublic Node template(Node root) {\n    if (root == null) {\n        return null;\n    }\n\n    Node curr = root;\n    Node mostRight = null;\n    Node pre = null;\n    Node head = null;\n\n    while (curr != null) {\n        // 从当前节点的左子树开始找最右节点\n        mostRight = curr.left;\n        if (mostRight != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                // 第一次来到mostRight和节点A，建立线索\n                mostRight.right = curr;\n                // 开始遍历左子树\n                curr = curr.left;\n                continue;\n            }\n            if (mostRight.right == curr) {\n                // 第二次来到mostRight和节点A\n                // 断开线索\n                mostRight.right = null;\n            }\n        }\n        // =========================================================\n        // 上面都是 Morris 的标准模板，从下面开始才加入 pre 相关的代码\n        if (pre != null) {\n            // 具体业务\n            // 记得更新pre\n            pre = curr;\n        } else {\n            // 更新pre\n            pre = curr;\n        }\n        // =========================================================\n\n        // Morris 遍历标准模板：\n        curr = curr.right;\n    }\n    return head;\n}\n```\n\n### 二叉搜索树与双向链表\n\n[剑指 Offer 36. 二叉搜索树与双向链表](https://leetcode-cn.com/problems/er-cha-sou-suo-shu-yu-shuang-xiang-lian-biao-lcof/)：输入一棵二叉搜索树，将该二叉搜索树转换成一个排序的循环双向链表。要求不能创建任何新的节点，只能调整树中节点指针的指向。\n\n<img src=\"/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211210212721807.png\" alt=\"image-20211210212721807\" style=\"zoom: 50%;\" />\n\n #### 方法一：递归\n\n在\n\n``` java\npublic Node pre, head;\n\npublic Node treeToDoublyList01(Node root) {\n    if(root == null) return null;\n    dfs(root);\n    head.left = pre;\n    pre.right = head;\n    return head;\n}\n\nvoid dfs(Node cur) {\n    if(cur == null) return;\n    dfs(cur.left);\n    if(pre != null) pre.right = cur;\n    else head = cur;\n    cur.left = pre;\n    pre = cur;\n    dfs(cur.right);\n}\n```\n\n#### 方法二：Morris 遍历\n\n``` java\npublic Node treeToDoublyList02(Node root) {\n    if (root == null) {\n        return null;\n    }\n\n    Node curr = root;\n    Node mostRight = null;\n    Node pre = null;\n    Node head = null;\n\n    while (curr != null) {\n        // 从当前节点的左子树开始找最右节点\n        mostRight = curr.left;\n        if (mostRight != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                // 第一次来到mostRight和节点A，建立线索\n                mostRight.right = curr;\n                // 开始遍历左子树\n                curr = curr.left;\n                continue;\n            }\n            if (mostRight.right == curr) {\n                // 第二次来到mostRight和节点A\n                // 断开线索\n                mostRight.right = null;\n            }\n        }\n        if (pre != null) {\n            // 前后节点建立线索\n            pre.right = curr;\n            curr.left = pre;\n            // 记得更新pre\n            pre = curr;\n        } else {\n            // 更新pre\n            pre = curr;\n            // 第一次到的节点被标记为head\n            head = curr;\n        }\n        curr = curr.right;\n    }\n    // 退出循环时，pre指向树的最后一个节点\n    pre.right = head;\n    head.left = pre;\n    return head;\n}\n```\n\n#### 方法三：树形 DP \n\n``` java\npublic class ReturnData {\n    public Node mostLeft;\n    public Node mostRight;\n    public ReturnData(Node left, Node right) {\n        this.mostLeft = left;\n        this.mostRight = right;\n    }\n}\n\npublic Node treeToDoublyList01(Node root) {\n    if (root == null) {\n        return null;\n    }\n    // 先找到整棵树的最左侧节点\n    globalRoot = root;\n    head = root;\n\n    recur(root);\n    return head;\n}\n\npublic Node globalRoot;\npublic Node head;\n\npublic ReturnData recur(Node root) {\n    if (root == null) {\n        return new ReturnData(null, null);\n    }\n\n    ReturnData leftReturn = recur(root.left);\n    ReturnData rightReturn = recur(root.right);\n\n    // 获取左子树的最左节点和右子树的最右节点\n    Node currMostLeft = leftReturn.mostLeft;\n    Node currMostRight = rightReturn.mostRight;\n\n    // 左子树的最右节点要和当前节点建立线索\n    if (leftReturn.mostRight != null) {\n        leftReturn.mostRight.right = root;\n        root.left = leftReturn.mostRight;\n    }\n    // 右子树的最左节点要和当前节点建立线索\n    if (rightReturn.mostLeft != null) {\n        rightReturn.mostLeft.left = root;\n        root.right = rightReturn.mostLeft;\n    }\n\n    // 如果左子树不存在，则当前子树的最左节点就是自身\n    if (leftReturn.mostLeft == null) {\n        currMostLeft = root;\n    }\n    // 如果右子树不存在，则当前子树的最右节点就是自身\n    if (rightReturn.mostRight == null) {\n        currMostRight = root;\n    }\n\n    // 如果当前节点等于根节点，则将当前整棵树的最左节点和最右节点串起来\n    // 注意这里要用整棵树的最左和最右节点，因为可能左子树的最左节点是空，无法.left\n    if (root == globalRoot) {\n        head = currMostLeft;\n        currMostLeft.left = currMostRight;\n        currMostRight.right = currMostLeft;\n    }\n\n    // 返回当前子树的最左节点和最右节点\n    return new ReturnData(currMostLeft, currMostRight);\n}\n```\n\n\n\n### 恢复二叉搜索树\n\n给你二叉搜索树的根节点 `root` ，该树中的两个节点被错误地交换。请在不改变其结构的情况下，恢复这棵树。示例：\n\n![img](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/recover1.jpg)\n\n#### 方法一：递归中序遍历\n\n这道题的关键在于正确的分析错误的两个点的位置。例如 [1, 2, 3, 4, 5, 6, 7] 被交换成了 [1, 6, 3, 4, 5, 2, 7]，当中序遍历时，不断判断当前 i 是否大于 i+1\n\n- 如果是，则记录 i 是那个较大的错误点，即 index2，i+1 不是错误点（这点不能乱，错误的是 i，不是i+1）。\n- 当再次发现 i > i+1 时，即 5 > 2，此时错误的就不是 i 了，而是 i+1，这个点就是 index1 。\n- 最后交换 index1 和 index2\n\n具体实现：只需要在中序遍历的时候不断记录 pred 点（i），比较当前点（i+1）的值。如果pred更大，说明他就是 index2。再找下去，pred 再次大于 curr 时，curr 就是 index1。最后做交换即可\n\n代码：\n\n``` java\nclass Solution {\n    public TreeNode errorRoot;\n    public TreeNode errorcChild;\n\n    public TreeNode pred; // 当前节点的前辈节点（中序遍历的上一个）\n    public TreeNode node01;\n    public TreeNode node02;\n    public int count = 2;\n\n    public void recoverTree(TreeNode root) {\n        // 在递归的时候如果找到了 curr 所在子树不满足\n        // 递归时，记录左右子树上的最小值和最大值的节点对象\n        // 将 curr 的值与其交换即可\n        if (root == null)\n            return;\n        \n        // 官方方法一：中序遍历时记录前一个节点pre，并比较pre和当前节点curr的大小，若发现pre>curr，则记录pre，第二次记录curr\n        // 之所以这么定，是因为一个数组里交换两个数字后，第一个错误的数字是大于后面的数字的，第二个则是前一个大于当前的，所以两次取，一次是pre，一次是curr\n        inOrderRecurr(root);\n        \n        // 交换错误的两个节点\n        int tmp = node01.val;\n        node01.val = node02.val;\n        node02.val = tmp;\n    }\n\n    public void inOrderRecurr(TreeNode curr) {\n        if (curr == null) {\n            return;\n        }\n\n        inOrderRecurr(curr.left);\n\n        // 要放在中序遍历的位置\n        if (pred != null && pred.val > curr.val) {\n            // 成立时代表是第二次发现有异常条件，说明该赋值给node02 = curr\n            if (--count == 0) {\n                // 若能进来，说明两个错误的节点是不相邻的，则更新后者为 curr\n                node02 = curr;\n            } else {\n                // 否则说明是第一次来到当前节点，说明赋值给node01 = pred\n                node01 = pred;\n                // 并且需要将 curr 赋值给 node02，以免相邻两个数交换时\n                // count 只会减一次，永远不会进入上面\n                // 这里赋值就能记录到错误交换的两个节点\n                node02 = curr;\n            }\n        }\n        // 注意要在第二次回到当前节点时（中序遍历的顺序）将pred更新\n        // 接下来遍历其右子树时，pred就更新为了当前节点\n        pred = curr;\n\n        inOrderRecurr(curr.right);\n    }\n}\n```\n\n#### 方法二：Morris 中序遍历\n\n对于这种跟中序遍历相关的题目，可以考虑使用 Morris 中序遍历降低空间复杂度。思路同样是在中序遍历的过程中，比较 pred 与 curr 的大小。\n\n代码：\n\n``` java\npublic void recoverTree(TreeNode root) {\n    if (root == null) {\n        return;\n    }\n    TreeNode curr = root;\n    TreeNode mostRight;\n    TreeNode x = null;\n    TreeNode y = null;\n    TreeNode pred = null;\n\n    while (curr != null) {\n        mostRight = curr.left;\n        if (mostRight != null) {\n            while (mostRight.right != null && mostRight.right != curr) {\n                mostRight = mostRight.right;\n            }\n            if (mostRight.right == null) {\n                mostRight.right = curr;\n                curr = curr.left;\n                continue;\n            } else {\n                // 中序遍历第二次到达当前节点 A 时回来到这里，并顺利到达下面的 if 外的代码，第一次遍历会被continue给打断\n                mostRight.right = null;\n            }\n        }\n        // 这里是 Morris 中序遍历的位置，在这里判断即可\n        // 假设正确的顺序是 ... x ... y ...\n        // 那么交换后是    ... y ... x ...，\n        // y 要设置为 pred，并且只设置一次；x 要设置为 curr，需要设置两次（为了应对xy挨着的情况）\n        if (pred != null && pred.val > curr.val) {\n            x = curr;\n            if (y == null) {\n                y = pred;\n            }\n        }\n        // 更新pred和curr\n        pred = curr;\n        curr = curr.right;\n    }\n    // 交换 x y\n    int tmp = x.val;\n    x.val = y.val;\n    y.val = tmp;\n}\n```\n\n\n\n## 树型动态规划问题\n\n### 模板套路\n\n符合模板套路的特点：可以通过当前节点向左右子树索要一些信息（例如节点数，层数等），从而递归地解决问题。\n\n模板：\n\n```java\npublic static ReturnData f(Node head) {\n    if (head == null) {\n        // 根据具体场景返回相应的值\n        return ReturnData(xx, xx, xx);\n    }\n    \n    // 先获取左右子树上的返回值\n    ReturnData leftReturnData = f(head.left);\n    ReturnData rightReturnData = f(head.right);\n    \n    // 进行判断处理等，例如将 boolean 类型值设置为 true 或 false，设置最大最小值等\n    // ...\n    \n    // 在最后将设置好的值封装成 ReturnData 并向上返回\n    return new ReturnData(xx, xx, xx);\n}\n```\n\n一些问题需要在当前子树上进行分类：**考虑当前节点**或**不考虑当前节点**两种情况，分别计算两种情况中的最优解，进行返回。\n\n### 叉树节点间的最大距离问题\n\n从二叉树的节点a出发，可以向上或者向下走，但沿途的节点只能经过一次，到达节点b时路径上的节点个数叫作a到b的距离，那么二叉树任何两个节点之间都有距离，求整棵树上的最大距离。\n\n当前子树的最大距离分两种情况：\n\n- 考虑当前节点时：最大距离为左子树的高度 + 右子树高度 + 1\n- 不考虑当前节点时：最大距离为左子树上的最大距离或右子树上的最大距离\n\n最后返回二者中的最大值。\n\n代码：\n\n``` java\npublic class MaxDistance {\n    public static class TreeNode {\n        public int value;\n        TreeNode left;\n        TreeNode right;\n\n        public TreeNode(int data) {\n            this.value = data;\n        }\n    }\n\n    public static class ReturnData {\n        // 当前子树的高度\n        int height;\n        // 当前子树上的最长路径\n        int maxLength;\n        public ReturnData(int height, int count) {\n            this.height = height;\n            this.maxLength = count;\n        }\n    }\n\n    public static int maxDistance(TreeNode root) {\n        ReturnData res = process(root);\n        return res.maxLength;\n    }\n\n    public static ReturnData process(TreeNode root) {\n        if (root == null) {\n            return new ReturnData(0, 0);\n        }\n\n        // 先得到左右子树上的信息\n        ReturnData leftReturn = process(root.left);\n        ReturnData rightReturn = process(root.right);\n\n        // 先更新当前子树的最大高度\n        int currHeight = Math.max(leftReturn.height, rightReturn.height) + 1;\n\n        // 1. 考虑当前节点, 即最长路径包含当前节点\n        // 最长路径为: 从左子树上的某个节点一路连接经过当前节点, 到右子树上的另一个节点\n        // 最长路径为: 左子树的高度 + 右子树的高度 + 1\n        int length1 = leftReturn.height + rightReturn.height + 1;\n\n        // 2. 不考虑当前节点, 即最长路径包含当前节点\n        // 最长路径: 左右子树上的最长路径的最大值\n        int length2 = Math.max(leftReturn.maxLength, rightReturn.maxLength);\n\n        // 取两种情况的最大值, 返回\n        return new ReturnData(currHeight, Math.max(length1, length2));\n    }\n}\n```\n\n### 派对的最大快乐值\n\n![image-20211203151542500](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E6%A0%91/image-20211203151542500.png)\n\n情况：\n\n- 当前员工要来——其直接下级不能来\n- 当前员工不来——其直接下级可以选择：来或不来\n\n代码：\n\n``` java\nimport java.util.List;\n\npublic class MaxHappyValue {\n    public static class Employee {\n        public int happy; // 这名员工可以带来的快乐值\n        List<Employee> subordinates; // 这名员工有哪些直接下级\n    }\n\n    public static class ReturnData {\n        int happyValue;\n\n        public ReturnData(int v) {\n            this.happyValue = v;\n        }\n    }\n\n    public static int maxHappyValue(Employee boss) {\n        return Math.max(recur(boss, true), recur(boss, false));\n    }\n\n    public static int recur(Employee curr, boolean consider) {\n        // 在这里先判断是否有下级, 这样在下面代码里就不需要判断了\n        if (curr.subordinates == null) {\n            return consider ? curr.happy : 0;\n        }\n        int p1 = 0;\n        int p2 = 0;\n\n        // 两种情况: 1. 考虑当前员工  2. 不考虑当前员工\n        // 1. 如果考虑当前员工\n        if (consider) {\n            p1 += curr.happy;\n            // 判断当前员工有无下级:\n            // 如果有下级, 遍历所有下级, 同时不能考虑这些下级\n            for (Employee subordinate : curr.subordinates) {\n                p1 += recur(subordinate, false);\n            }\n        } else {\n            // 2. 如果不考虑当前员工\n            // 遍历所有下级, 同时要考虑这些下级\n            for (Employee subordinate : curr.subordinates) {\n                p2 += recur(subordinate, true);\n            }\n        }\n        return Math.max(p1, p2);\n    }\n\n    // 如果存下级, 要用 list 存储, 一对多\n    // 如果存上级, 就只用一个常数, 多对一\n    // dp[][]的形式：\n    public static int maxHappy(int[][] matrix) {\n        int[][] dp = new int[matrix.length][2];\n        boolean[] visited = new boolean[matrix.length];\n        // matrix[0]: 当前员工的上级编号\n        // 先找出 root 是谁\n        int root = 0;\n        for (int i = 0; i < matrix.length; i++) {\n            if (i == matrix[i][0]) {\n                root = i;\n            }\n        }\n        process(matrix, dp, visited, root);\n        return Math.max(dp[root][0], dp[root][1]);\n    }\n\n    public static void process(int[][] matrix, int[][] dp, boolean[] visited, int root) {\n        // 来到了root, 计算其值后, 就在表中缓存来到过当前位置, 其他分支就不需要再次访问当前位置了\n        visited[root] = true;\n        // dp[x][0]: 不考虑当前员工\n        // dp[x][1]: 考虑当前员工\n        // 考虑当前员工root时, 先初始化上matrix中其对应的快乐值\n        dp[root][1] = matrix[root][1];\n\n        // 遍历每一个员工, 判断是否为传入的root的下级(如果用树结构, 就是直接获取 list, 不用遍历)\n        for (int i = 0; i < matrix.length; i++) {\n            // 如果当前员工的上级等于传入的root, 并且当前员工没考虑过(还没遍历到)\n            // 就递归当前员工root的下级, 更新root的快乐值\n            // 这里的visited就是用来缓存的, 避免重复计算i\n            if (matrix[i][0] == root && !visited[i]) {\n                // 如果还没计算过i, 就先去计算i的情况, 算完后再回来算i的上级root\n                process(matrix, dp, visited, i);\n                // 1. 更新 \"当前员工i的上级员工root\" 考虑自身时的快乐值\n                // 考虑root时, 下级i的快乐值就不能算上, 所以要加上下级dp[i][0]: \"不考虑自身时的快乐值\"\n                dp[root][1] += dp[i][0];\n                // 2. 更新 root 不考虑自身时的快乐值\n                // 不考虑自身, 要取 \"考虑下级\" 和 \"不考虑下级\" 中的最大值\n                dp[root][0] += Math.max(dp[i][1], dp[i][0]);\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        int[][] matrix = { { 1, 8 }, { 1, 9 }, { 1, 10 } };\n        System.out.println(maxHappy(matrix));\n    }\n}\n```\n\n\n\n### 二叉树的不同种类个数\n\n给定一个非负整数n，代表二叉树的节点个数。返回能形成多少种不同的二叉树结构。\n\n思路：当前位置作为根节点时，左子树的节点个数从 0 开始遍历一直到 n - 1，累加各种情况下当前子树的结构种类： \n\n``` java\n// 当前子树上有n个节点的前提下：当左子树上有i个节点时, 右子树上有n-1-i个节点(要排除掉root)\nres += process(i, record) * process(n - 1 - i, record);\n```\n\n代码：\n\n```java\npublic class NumberOfTree {\n\n    public static int numberOfTree(int n) {\n        int[] record = new int[n + 1];\n        return process(n, record);\n    }\n\n    private static int process(int n, int[] record) {\n        // n: 当前子树上拥有的节点个数\n        if (n < 0) {\n            return 0;\n        }\n        // root = null\n        if (n == 0) {\n            return 1;\n        }\n        // null <- root -> null\n        if (n == 1) {\n            return 1;\n        }\n        // left <- root -> null 或 null <- root -> right\n        if (n == 2) {\n            return 2;\n        }\n        // 缓存表, 避免重复计算\n        if (record[n] != 0) {\n            return record[n];\n        }\n\n        int res = 1;\n        // 遍历决定当前节点的左子树上有多少个节点, 范围: 从0到n-1\n        for (int i = 0; i <= n - 1; i++) {\n            // 当左子树上有i个节点时, 右子树上有n-1-i个节点(要排除掉root)\n            res += process(i, record) * process(n - 1 - i, record);\n        }\n        return res;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(numberOfTree(4));\n    }\n}\n```","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【数据结构】链表","url":"/2021/10/10/【数据结构】链表/","content":"\n## 链表基础操作\n\n### 链表逆序打印\n\n使用递归将链表逆序打印，最先打印的是链表的尾结点，他是从后往前打印的：\n\n``` java\nprivate void printListNode(ListNode head) {\n    if (head == null)\n        return;\n    printListNode(head.next);\n    System.out.println(head.val);\n}\n```\n\n说明要想实现链表的逆序操作，可以使用递归实现。链表的题目常常可以用递归解决。\n\n### 反转链表\n\n#### 方法一：使用栈结构\n\n因为**栈是先进后出**的。实现原理就是把**链表节点一个个入栈，当全部入栈完之后再一个个出栈，出栈的时候在把出栈的结点串成一个新的链表**。但是效率较低。原理如下：\n\n![image.png](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/343fd7cce80394422565b4beef398236832cc9ae0f77a85ebceacebe214785af-image.png)\n\n代码：\n\n``` java\npublic ListNode reverseList(ListNode head) {\n    Stack<ListNode> stack = new Stack<>();\n    // 把链表节点全部摘掉放到栈中\n    while (head != null) {\n        stack.push(head);\n        head = head.next;\n    }\n    if (stack.isEmpty())\n        return null;\n    ListNode node = stack.pop();\n    ListNode dummy = node;\n\n    // 栈中的结点全部出栈，然后重新连成一个新的链表\n    while (!stack.isEmpty()) {\n        ListNode tempNode = stack.pop();\n        node.next = tempNode;\n        node = node.next;\n    }\n\n    // 最后一个结点就是反转前的头结点，一定要让他的next\n    // 等于空，否则会构成环\n    node.next = null;\n    return dummy;\n}\n```\n\n<!-- More -->\n\n#### 方法二：双链表求解（推荐）\n\n双链表求解是把原链表的结点一个个摘掉，**每次摘掉的链表都让他成为新的链表的头结点**，然后更新新链表。下面以链表`1→2→3→4`为例画个图来看下。\n\n![image.png](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/0aff36d2713c964b35c8b90e62c2fa1c16a6dcae372d991724b7b56c46a53870-image.png)\n\n他每次访问的原链表节点都会成为新链表的头结点。代码：\n\n``` java\npublic ListNode reverseList(ListNode head) {\n    //新链表\n    ListNode newHead = null;\n    while (head != null) {\n        //先保存访问的节点的下一个节点，保存起来\n        //留着下一步访问的\n        ListNode temp = head.next;\n        //每次访问的原链表节点都会成为新链表的头结点，\n        //其实就是把新链表挂到访问的原链表节点的\n        //后面就行了\n        head.next = newHead;\n        //更新新链表\n        newHead = head;\n        //重新赋值，继续访问\n        head = temp;\n    }\n    //返回新链表\n    return newHead;\n}\n```\n\n\n\n#### 方法三：递归解决\n\n递归调用是要从当前节点的下一个结点开始递归。逻辑处理这块是要把当前节点挂到递归之后的链表的末尾。代码：\n\n``` java\npublic static Node reverse03(Node head) {\n    //终止条件\n    if (head == null || head.next == null)\n        return head;\n\n    //保存当前节点的下一个结点\n    Node next = head.next;\n\n    // 从当前节点的下一个结点开始递归调用\n    // reverse 指向反转后链表的头节点, 其被赋值的时机为递归到底时reverse = return head,\n    // 因此指向的是原链表的尾节点\n    Node reverse = reverse03(next);\n    // reverse是反转之后的链表，因为函数reverseList\n    // 表示的是对链表的反转，所以反转完之后next肯定\n    // 是链表reverse的尾结点，然后我们再把当前节点\n    // head挂到next节点的后面就完成了链表的反转。\n    next.next = head;\n\n    // 这里head相当于变成了尾结点，尾结点都是为空的，\n    // 否则会构成环\n    // 这里的赋值操作是为了全部递归调用完成后, 当前的链表尾节点指向null\n    // 除此之外, 在每次递归返回时, head.next指向的null又会被调用它的方法栈里的next.next = head 所覆盖\n    // 因此只有全部递归调用完成后,这句话才有意义\n    head.next = null;\n    return reverse;\n}\n```\n\n\n\n### 快慢指针遍历链表\n\n常常可以用快慢指针解决链表问题，其思想是使用两个指针，fast 和 slow。\n\n每次移动时 fast 移动两步，slow 移动一步，这样只要设置好终止条件，就可以实现跳出循环时，slow 指向不同的位置。下面是三种不同判断条件下跳出循环时，slow指向的位置：\n\n- `while (fast.next != null)`：奇数长度链表的正中间节点\n- `while (fast != null)`：偶数长度链表的右侧中间节点\n- `while (fast.next.next != null)` ：偶数长度链表的左侧中间节点\n\n![链表](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/%E9%93%BE%E8%A1%A8.png)\n\n奇数长度链表的判断条件**必须**要和偶数长度链表的判断条件**进行组合**（不组合的后果见下文分析），从而达到不同的终止位置：\n\n- `while (fast != null && fast.next != null)`：奇数长度链表的正中间节点 + 偶数长度链表的**右侧**中间链表\n- `while (fast.next != null && fast.next.next != null)`：奇数长度链表的正中间节点 + 偶数长度链表的**左侧**中间链表\n\n上述二者的区别就在于——当 fast 的位置指向偶数长度链表的**倒数第二个**节点并进入判断时：\n\n- 第一种情况，只判断了 `fast.next != null`，这时 fast.next 是指向的最后一个节点，不为null，可以进入循环体，比第二种情况多执行了一次 `fast = fast.next.next;`和 `slow = slow.next;`，令 slow 多移动了一步，因此指向了右侧的位置。\n- 第二种情况，不仅判断了  `fast.next != null`，还判断了 `fast.next.next != null`，这时该条件显然不满足（因为倒数第二个节点的下下个节点就是null），因此没有再进入一次循环体。导致比情况一少移动一步，指向了左侧的位置；\n\n具体代码：\n\n```java\n// 第一种情况：\n// 1. 奇数的情况下, 每次进循环需要使用 fast.next != null 判断\n//    因为奇数情况下, 最后一次进循环时的 fast 指向的是最后一个节点, 其 .next 为 null\n//    因此判断条件需要使用 fast.next != null 才能保证进入循环后的fast.next有值\n//    循环结束时, slow 指向正中间的节点\n// 2. 偶数的情况下, 每次进循环需要使用 fast != null 判断\n//    因为偶数情况下, 最后一次进循环时的 fast 指向的是倒数第二个节点, 再移动两次就指向了 null\n//    因此判断条件需要用 fast != null 保证 fast 指向倒数第二个节点后就停止循环\n//    循环结束时, slow 指向右侧中间的节点\nwhile (fast != null && fast.next != null) {\n    fast = fast.next.next;\n    slow = slow.next;\n}\n\n// 第二种情况：\n// 1. 奇数的情况下, 每次进循环需要使用 fast.next != null 判断\n//    因为奇数情况下, 最后一次进循环时的 fast 指向的是最后一个节点, 其 .next 为 null\n//    因此判断条件需要使用 fast.next != null 才能保证进入循环后的fast.next有值\n//    循环结束时, slow 指向正中间的节点\n// 2. 偶数的情况下, 每次进循环需要使用 fast.next.next != null 判断\n//    因为偶数情况下, 最后一次进循环时的 fast 指向的是倒数第二个节点, 再移动两次就指向了 null\n//    因此判断条件需要用 fast.next.next != null 保证 fast 指向倒数第二个节点时就停止循环\n//    比情况一少进入了一次循环\n//    循环结束时, slow 指向左侧中间的节点\nwhile (fast.next != null && fast.next.next != null) {\n    fast = fast.next.next;\n    slow = slow.next;\n}\n```\n\n**注意**：绝对不能只写 `while (fast.next != null)`，因为这样奇数长度虽然正常，但是偶数长度的最后一次 fast 将指向倒数第二个节点，这时while判断是成立的，还会进入循环中，但这样在其内进行  `fast = fast.next.next;` 操作时就会报 `NullPointerException`。\n\n> `fast.next.next != null` 的终止条件和 `fast.next != null` 的终止条件对于奇数长度的链表肯定是同时满足的，这是因为其奇数长度的特性，但对于偶数长度的链表并不是同时满足的。因为当偶数长度时，最后一次 fast 将指向倒数第二个节点，这时如果不加 `fast.next.next != null` 判断的话，还会进入循环中，这样在其内进行  `fast = fast.next.next;` 操作时就会报 `NullPointerException`\n\n\n\n#### 应用\n\n通常可以在定位到中间位置后，将 slow 指向右半部分链表的第一个节点，这种需求下：\n\n- 偶数长度链表使用第一种情况的判断，跳出循环时自然就是右半部分的第一个节点\n- 奇数长度链表还需要将 slow 再移动一步：\n\n``` java\n// 如果是奇数情况, 将 slow 移动一位指向右半侧的第一个节点\n// 如果是偶数情况, 上面循环完就已经是指向的右半侧的第一个节点了\nif (fast != null) {\n    slow = slow.next;\n}\n```\n\n\n\n\n\n### 总结\n\n![image-20211011194935036](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211011194935036.png)\n\n## 链表常见题目\n\n### 打印两个有序链表的公共部分\n\n![image-20211011193524728](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211011193524728.png)\n\n思路：两个链表一起遍历，遇到相等时就打印，并且两个指针一起后移一步。如果不相等，较小的指针后移一步进入下一次循环判断。\n\n代码：\n\n``` java\npublic static void printCommonPart(ListNode l1, ListNode l2) {\n    while (l1 != null && l2 != null) {\n        if (l1.val < l2.val) {\n            l1 = l1.next;\n        } else if (l1.val > l2.val) {\n            l2 = l2.next;\n        } else {\n            System.out.println(l1.val);\n            // 两个指针一起后移\n            l1 = l1.next;\n            l2 = l2.next;\n        }\n    }\n}\n```\n\n\n\n\n\n### 删除链表的倒数第 N 个节点\n\n#### 方法一：非递归解决\n\n先求出链表的长度 `length`，然后就可以找到要删除链表的前一个结点，让他的前一个结点指向要删除结点的下一个结点即可。\n\n![image.png](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/1602254558-HryNTe-image.png)\n\n``` java\npublic ListNode removeNthFromEnd(ListNode head, int n) {\n    ListNode curr = head;\n    // 计算倒数第 N 个节点所处的位置\n    int last = length(head) - n;\n\n    // 注意：如果last等于0表示删除的是头结点, 直接返回下一个节点即可\n    if (last == 0)\n        return head.next;\n\n    // 这里首先要找到要删除链表的前一个结点\n    for (int i = 0; i < last - 1; i++) {\n        curr = curr.next;\n    }\n\n    // 然后让前一个结点的next指向要删除节点的next\n    curr.next = curr.next.next;\n    return head;\n}\n\n// 求链表的长度\nprivate int length(ListNode head) {\n    int len = 0;\n    while (head != null) {\n        len++;\n        head = head.next;\n    }\n    return len;\n}\n```\n\n\n\n#### 方法二：双指针求解（推荐）\n\n上面是先计算链表的长度，其实不计算链表的长度也是可以，我们可以使用两个指针，一个指针fast先走n步，然后另一个指针slow从头结点开始，找到要删除结点的前一个结点，这样就可以完成结点的删除了。\n\n``` java\npublic ListNode removeNthFromEnd(ListNode head, int n) {\n    ListNode fast = head;\n    ListNode slow = head;\n    // fast移n步，\n    for (int i = 0; i < n; i++) {\n        fast = fast.next;\n    }\n\n    // 如果fast为空，表示删除的是头结点\n    if (fast == null)\n        return head.next;\n\n    while (fast.next != null) {\n        fast = fast.next;\n        slow = slow.next;\n    }\n\n    // 这里最终slow不是倒数第n个节点，他是倒数第n+1个节点，\n    // 他的下一个结点是倒数第n个节点,所以删除的是他的下一个结点\n    slow.next = slow.next.next;\n    return head;\n}\n```\n\n\n\n#### 方法三：递归解决\n\n我们知道获取链表的长度除了上面介绍的一种方式以外，还可以写成递归的方式，比如：\n\n``` java\n// 求链表的长度\nprivate int length(ListNode head) {\n    if (head == null)\n        return 0;\n    return length(head.next) + 1;\n}\n```\n\n上面计算链表长度的递归其实可以把它看做是**从后往前**计算，当计算的长度是n的时候就表示遍历到了倒数第n个节点了，这里只要求出倒数第n+1个节点，问题就迎刃而解了，来看下代码：\n\n``` java\npublic ListNode removeNthFromEnd(ListNode head, int n) {\n    int pos = length(head, n);\n    // 说明删除的是头节点\n    if (pos == n)\n        return head.next;\n    return head;\n}\n\n// 获取节点所在位置，逆序\npublic int length(ListNode node, int n) {\n    if (node == null)\n        return 0;\n    int pos = length(node.next, n) + 1;\n    // 获取要删除链表的前一个结点，就可以完成链表的删除\n    if (pos == n + 1)\n        node.next = node.next.next;\n    return pos;\n}\n```\n\n\n\n### 合并两个有序链表\n\n因为链表是升序的，我们只需要遍历每个链表的头，**比较一下哪个小就把哪个链表的头拿出来放到新的链表中**，一直这样循环，直到有一个链表为空，然后我们再把另一个不为空的链表挂到新的链表中。\n\n该过程类似于**归并排序**里的 merge 操作。\n\n![image.png](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/8056ae02cbcd1b170ef27d7553d0281accfd31f2673353dd6fc472f80301c4f1-image.png)\n\n```java\npublic static ListNode mergeTwoLists(ListNode l1, ListNode l2) {\n    // 下面4行是空判断\n    if (l1 == null)\n        return l2;\n    if (l2 == null)\n        return l1;\n\n    // head 指向合并后的链表的头节点的前一个节点\n    // 其本身只起标志位, 最后返回时记得返回 head.next\n    ListNode head = new ListNode(-1);\n\n    // 还需要创建一个临时节点, 后续遍历增加节点时使用该临时节点, 避免污染 head\n    ListNode tmp = head;\n\n    while (l1 != null && l2 != null) {\n        if (l1.val < l2.val) {\n            tmp.next = l1;\n            l1 = l1.next;\n        } else {\n            tmp.next = l2;\n            l2 = l2.next;\n        }\n        // 记得更新 head\n        tmp = tmp.next;\n    }\n\n    //然后把那个不为空的链表挂到新的链表中\n    tmp.next = l1 == null ? l2 : l1;\n\n    // 以下归并排序里的方式可以直接被上面的便捷方式替代\n//        while (l1 != null) {\n//            tmp.next = l1;\n//            l1 = l1.next;\n//            tmp = tmp.next;\n//        }\n//        while (l2 != null) {\n//            tmp.next = l2;\n//            l2 = l2.next;\n//            tmp = tmp.next;\n//        }\n\n    return head.next;\n\n}\n```\n\n还可以把它改为递归的形式，看下递归的代码：\n\n```java\n// 方法二: 递归\npublic static ListNode mergeTwoListsV2(ListNode l1, ListNode l2) {\n    if (l1 == null)\n        return l2;\n    if (l2 == null)\n        return l1;\n    if (l1.val < l2.val) {\n        l1.next = mergeTwoLists(l1.next, l2);\n        return l1;\n    } else {\n        l2.next = mergeTwoLists(l1, l2.next);\n        return l2;\n    }\n}\n```\n\n递归代码我们还可以再改一下：\n\n``` java\npublic ListNode mergeTwoLists(ListNode linked1, ListNode linked2) {\n    //只要有一个为空，就返回另一个\n    if (linked1 == null || linked2 == null)\n        return linked2 == null ? linked1 : linked2;\n    //把小的赋值给first\n    ListNode first = (linked2.val < linked1.val) ? linked2 : linked1;\n    first.next = mergeTwoLists(first.next, first == linked1 ? linked2 : linked1);\n    return first;\n}\n```\n\n### 回文链表\n\n![image-20211011194950806](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211011194950806.png)\n\n#### 方法一：反转后半部分链表\n\n所谓的回文链表就是**以链表中间为中心点两边对称**。我们常见的有判断一个**字符串**是否是回文字符串，这个比较简单，可以使用两个指针，一个最左边一个最右边，两个指针同时往中间靠，判断所指的字符是否相等。\n\n但因为这里是单向链表，只能从前往后访问，不能从后往前访问，所以使用判断字符串的那种方式是行不通的。但我们可以**通过找到链表的中间节点然后把链表后半部分反转**，**最后再用后半部分反转的链表和前半部分一个个比较即可**。\n\n这种方式效率较高，时间复杂度为 O(N)，空间复杂度为 O(1)。\n\n找到中间节点的思路是使用**快慢指针**。\n\n![image.png](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/1603414119-KfHINu-image.png)\n\n![image.png](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/1603414128-PsmRse-image.png)\n\n代码：\n\n```java\npublic class IsPalindrome {\n    // 方法一: 先使用快慢指针定位到后半部分的链表, 然后反转后半部分链表\n    // 再同时遍历前半部分和后半部分, 判断当前元素是否相同\n    public static boolean isPalindrome01(Node head) {\n        Node fast = head;\n        Node slow = head;\n\n        // fast != null ---> 奇数情况\n        // fast.next != null ---> 偶数情况\n        // 循环结束后, 奇数长度的 slow 指向正中间的节点\n        // 偶数长度的 slow 指向右侧中间的节点\n        while (fast != null && fast.next != null) {\n            fast = fast.next.next;\n            slow = slow.next;\n        }\n\n\n        // 如果是奇数情况, 将 slow 移动一位指向右半侧的第一个节点\n        // 如果是偶数情况, 上面循环完就已经是指向的右半侧的第一个节点了\n        if (fast != null) {\n            slow = slow.next;\n        }\n\n        // 反转后半部分链表, 此时 slow 指向的就是右半部分链表的头节点\n        Node newHead = reverseList(slow);\n\n        // newHead 指向反转后的头结点\n        while (newHead != null) {\n            if (newHead.value != head.value)\n                return false;\n            newHead = newHead.next;\n            head = head.next;\n        }\n\n        // 如果题目要求链表保持不动，最后还需要再把链表给反转回去\n        return true;\n    }\n\n    public static Node reverseList(Node head) {\n        Node newHead = null;\n        Node tmp = null;\n\n        while (head != null) {\n            //先保存访问的节点的下一个节点，保存起来\n            //留着下一步访问的\n            tmp = head.next;\n            //每次访问的原链表节点都会成为新链表的头结点，\n            //其实就是把新链表挂到访问的原链表节点的\n            //后面就行了\n            head.next = newHead;\n            //更新新链表\n            newHead = head;\n            //重新赋值，继续访问\n            head = tmp;\n        }\n\n        return newHead;\n    }\n\n}\n```\n\n#### 方法二：使用栈结构\n\n我们知道栈是先进后出的一种数据结构，这里还可以使用栈先把链表的节点**存储的值**全部存放到栈中，然后再一个个出栈，这样就相当于链表从后往前访问了，通过这种方式也能解决（但是效率远不如上面的方式）。这种方式效率较低，时间复杂度为 O(N)，空间复杂度为 O(N)。\n\n代码：\n\n```java\n// 方法二: 使用栈结构存储链表元素, 再依次弹栈后判读是否相等\npublic static boolean isPalindrome02(ListNode head) {\n    Stack<Integer> stack = new Stack<>();\n    ListNode tmp = head;\n    int length = 0;\n\n    // 链表内元素依次压栈 (这里的优化可以使用快慢指针只存储后半部分的内容)\n    while (tmp != null) {\n        stack.push(tmp.val);\n        tmp = tmp.next;\n        length++;\n    }\n\n    // 当过半时停止遍历\n    int count = 0;\n    while (head != null && count < length) {\n        if (head.val != stack.pop())\n            return false;\n        head = head.next;\n        count++;\n    }\n\n    return true;\n}\n```\n当然也可以直接将链表的每个节点存储到栈中：\n\n``` java\npublic static boolean isPalindrome02(ListNode head) {\n    Stack<Integer> stack = new Stack<>;\n    ListNode curr = head;\n    int length = 0;\n    \n    while (curr != null) {\n        stack.push(curr);\n        curr = curr.next;\n        length++;\n    }\n    \n    // 用于计数，在到达一半时跳出循环\n    int count = 0;\n    while (head != null && count < length) {\n        if (head.val != stack.pop().val)\n            return false;\n    }\n    \n    return true;\n}\n```\n\n\n\n#### 方法三：递归方式解决\n\n``` java\nListNode temp;\n\npublic boolean isPalindrome03(ListNode head) {\n    temp = head;\n    return check(head);\n}\n\nprivate boolean check(ListNode head) {\n    if (head == null)\n        return true;\n    boolean res = check(head.next) && (temp.val == head.val);\n    temp = temp.next;\n    return res;\n}\n```\n\n\n\n### 链表分区\n\n![image-20211011195009886](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211011195009886.png)\n\n#### 方法一：将链表转为数组后分区\n\n先将链表内的节点放到一个数组里，然后用归并排序中的数组的分区方式将链表节点进行分区，然后再将节点数组中的节点依次串起来组成新的链表（注意将最后一个节点的 next 置空）。缺点是节点间的顺序不能保证，并且算法效率较低。\n\n```java\n// 方法一：先将链表内的节点放到一个数组里，然后用数组的分区方式将链表分区\n// 缺点是节点间的顺序不能保证\npublic static ListNode listPartition1(ListNode head, int pivot) {\n    if (head == null) {\n        return head;\n    }\n\n    ListNode curr = head;\n    int length = 0;\n    while (curr != null) {\n        curr = curr.next;\n        length++;\n    }\n\n    // 创建一个数组，将节点依次存入其中\n    ListNode[] nodeArr = new ListNode[length];\n    int index = 0;\n    while (head != null) {\n        nodeArr[index++] = head;\n        head = head.next;\n    }\n\n    arrPartition(nodeArr, pivot);\n\n    // 将数组中前一个节点的 next 指向当前节点\n    int i = 0;\n    for (i = 1; i != nodeArr.length; i++) {\n        nodeArr[i - 1].next = nodeArr[i];\n    }\n\n    // 记得要把最后一个节点的尾结点置空\n    nodeArr[i - 1].next = null;\n\n    printLinkedList(nodeArr[0]);\n    return nodeArr[0];\n}\n\npublic static void arrPartition(ListNode[] nodeArr, int pivot) {\n    int left = -1;\n    int right = nodeArr.length - 1;\n    int i = 0;\n\n    while (i <= right) {\n        if (nodeArr[i].val < pivot) {\n            swap(nodeArr, i++, ++left);\n        } else if (nodeArr[i].val > pivot) {\n            swap(nodeArr, i, right--);\n        } else {\n            i++;\n        }\n    }\n}\n\npublic static void swap(ListNode[] nodeArr, int i, int j) {\n    ListNode tmp = nodeArr[i];\n    nodeArr[i] = nodeArr[j];\n    nodeArr[j] = tmp;\n}\n\npublic static void printLinkedList(ListNode node) {\n    System.out.print(\"Linked List: \");\n    while (node != null) {\n        System.out.print(node.val + \" \");\n        node = node.next;\n    }\n    System.out.println();\n}\n\npublic static void main(String[] args) {\n    ListNode head1 = new ListNode(7);\n    head1.next = new ListNode(9);\n    head1.next.next = new ListNode(1);\n    head1.next.next.next = new ListNode(8);\n    head1.next.next.next.next = new ListNode(5);\n    head1.next.next.next.next.next = new ListNode(2);\n    head1.next.next.next.next.next.next = new ListNode(5);\n    printLinkedList(head1);\n    listPartition1(head1, 5);\n}\n```\n\n#### 方法二：六个指针\n\n可以使用六个指针，分为三组：小于区域两个指针，等于区域两个指针，大于区域两个指针。在遍历链表时，遇到小于目标值的节点，则**先断开其与链表的连接**，然后使用小于区域的尾结点指向它；大于和等于的情况类似，最后将三个区域进行合并即可得到**保持原有顺序**的分区结果。\n\n![image-20211011210623585](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211011210623585.png)\n\n这种方法的时间复杂度为 O(N)，空间复杂度为 O(1)。同时能保证原节点间的相对顺序。\n\n需要特别注意的是：\n\n- 遍历链表时，需要将当前节点与原先链表断开连接，因为如果不断开的话，每个区域的尾结点都不是null，而是可能会连着其他节点这样再串起来时就不对了，因此必须要在分区前先断开连接，就会比较麻烦\n- 最后合并三个区域时使用的技巧是交叉两两合并的：先合并小于区域和等于区域，再合并等于区域和大于区域，可以看到等于区域是重叠的，这是因为小于区域和大于区域都需要和等于区域进行连接。所以，分两步进行连接，先连接小于区域和等于区域，再将二者连接后的结果与大于区域连接。\n- 最后方法返回新链表的头结点时，需要将三个区域的头结点中第一个不为空的返回\n\n详细见代码：\n\n```java\n// 方式二：使用六个指针，分为三组：小于区域两个指针，等于区域两个指针，大于区域两个指针\npublic static ListNode listPartition2(ListNode head, int pivot) {\n    ListNode sH = null; // small head\n    ListNode sT = null; // small tail\n    ListNode eH = null; // equal head\n    ListNode eT = null; // equal tail\n    ListNode bH = null; // big head\n    ListNode bT = null; // big tail\n\n    ListNode next = null; // save next node\n\n    // 遍历一次链表，将整个链表拆成三个区域，尾指针不断更新，头指针保持不动\n    while (head != null) {\n        // 注意：需要将当前节点与原先链表断开连接\n        // 如果不断开的话，每个区域的尾结点都不是null，而是可能会连着其他节点\n        // 这样再串起来时就不对了，因此必须要在分区前先断开连接\n        next = head.next;\n        head.next = null;\n\n        if (head.val < pivot) {\n            if (sH == null) {\n                sH = head;\n                sT = head;\n            } else {\n                sT.next = head;\n                sT = head;\n            }\n        } else if (head.val > pivot) {\n            if (bH == null) {\n                bH = head;\n                bT = head;\n            } else {\n                bT.next = head;\n                bT = head;\n            }\n        } else {\n            if (eH == null) {\n                eH = head;\n                eT = head;\n            } else {\n                eT.next = head;\n                eT = head;\n            }\n        }\n        head = next;\n    }\n\n    // 如果上面不断开连接，这里就必须得手动断开，但是这样还必须保证 sT eT bT 不为空\n    // sT.next = null;\n    // eT.next = null;\n    // bT.next = null;\n\n\n    // 将三个区域的子链表进行合并\n    // 下面两个判断是交叉合并的，先合并小于区域和等于区域，再合并等于区域和大于区域\n    // 可以看到等于区域是重叠的，因为小于区域和大于区域都需要和等于区域进行连接\n    // 所以，分两步进行连接，先连接小于区域和等于区域，再将二者连接后的结果与大于区域连接\n    // small and equal reconnect\n    if (sT != null) {\n        sT.next = eH;\n        // 这一步的目的是，如果等与区域为空，则将 eT 指向 sT\n        // 这样在下一步连接大于区域时，如果等于区域为空则直接将大于区域连在小于区域后面\n        eT = eT == null ? sT : eT;\n    }\n    // all reconnect\n    if (eT != null) {\n        eT.next = bH;\n    }\n\n    // 返回头结点时，将三个区域的头结点中第一个不为空的返回\n    return sH != null ? sH : eH != null ? eH : bH;\n}\n```\n\n\n\n### 复制含有随机节点的链表\n\n![image-20211012132838017](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211012132838017.png)\n\n#### 方法一：使用哈希表\n\n使用哈希表开辟一段额外空间，将原链表中的节点作为 map 中的 key，new一个新的节点作为 map 中的 value。但这需要额外空间复杂度 O(N)。代码：\n\n```java\npublic static ListNode copyListWithRand1(ListNode head) {\n    HashMap<ListNode, ListNode> map = new HashMap<>();\n    ListNode curr = head;\n\n    // 将数据放到哈希表中\n    while (curr != null) {\n        map.put(curr, new ListNode(curr.val));\n        curr = curr.next;\n    }\n\n    // map.get(curr) 返回的是原链表中 curr 节点对应的复制节点\n    curr = head;\n    while (curr != null) {\n        // 注意后面要用 map.get(curr.xxx)\n        // 这样取出来的才是复制出的节点，不然的话取出的就是原节点了，就不符合题意了\n        map.get(curr).next = map.get(curr.next);\n        map.get(curr).rand = map.get(curr.rand);\n        curr = curr.next;\n    }\n\n    // 返回复制出的头结点\n    return map.get(head);\n}\n```\n\n#### 方法二：原地插入复制节点\n\n先在原链表结构中的每一个节点后面插入其对应的复制节点，再依次为复制节点赋上 rand 值，最后将新旧链表分离开。\n\n下图中的 1 2 3 代表原节点，1’ 2’ 3’ 代表复制节点。先遍历一次原链表，将复制节点依次插入到其对应的原节点的后面；再遍历一次组合后的链表，将每个复制节点的 next 和 rand 进行设置；最后遍历一次组合后的链表，将新旧节点拆分开，组合成新的链表。\n\n![image-20211012133623570](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211012133623570.png)\n\n代码：\n\n```java\npublic static ListNode copyListWithRand2(ListNode head) {\n    if (head == null) {\n        return null;\n    }\n\n    ListNode curr = head;\n    ListNode next = null;\n\n    // 在原链表的每个节点后插入一个其复制出的节点\n    while (curr != null) {\n        next = curr.next;\n        curr.next = new ListNode(curr.val);;\n        curr.next.next = next;\n        curr = next;\n    }\n\n    curr = head;\n    // 设置 rand 值：curr 每次移动两步（遍历每一对原/新节点）\n    // 令当前的复制节点和原节点的 rand 节点指向一致（但注意，复制节点指向的是原节点的 rand.next 节点）\n    while (curr != null) {\n        // 注意需要判断当前原节点的 rand 是否为空，不然会报空指针异常\n        curr.next.rand = curr.rand != null ? curr.rand.next : null;\n        curr = curr.next.next;\n    }\n\n    // 将新节点和原节点断开连接，并且同时恢复原链表的顺序\n    ListNode newHead = head.next;\n    ListNode copyCurr;\n    curr = head;\n    while (curr != null) {\n        // 先将接下来要连接的两个新旧节点给保存下来\n        next = curr.next.next;\n        copyCurr = curr.next;\n        // 连接新节点\n        copyCurr.next =  copyCurr.next != null ? copyCurr.next.next : null;\n        // 恢复原节点的顺序\n        curr.next = next;\n        curr = next;\n    }\n\n\n    // 下面这种做法无法将原链表恢复，原先的结构被破坏了\n    // ListNode newHead = head.next;\n    // curr = newHead;\n    // while (curr.next != null) {\n    //     curr.next = curr.next.next;\n    //     curr = curr.next;\n    // }\n\n    return newHead;\n}\n```\n\n\n\n### 环形链表\n\n给定一个链表，判断链表中是否有环，若有环，返回入环节点，若无环，则返回 null。\n\n思路：使用快慢指针，快指针每次走两步，慢指针每次走一步。\n\n- 外层循环中判断若快指针已经为 null 或 fast.next == null，则代表肯定没有环，直接返回 null\n- 每次循环体中都判断一下 slow 是否和 fast 相等，若相等，说明二者相遇了，代表肯定有环\n- 这时保持 slow 位置不动，将 fast 移回 head 位置\n- 再创建一个内层循环，令 fast 和 slow 一起每次移动一步，二者相遇时即在头结点位置\n\n``` java\npublic ListNode hasCycle(ListNode head) {\n    // 边界条件\n    // 如果链表节点的长度小于3，则直接返回Null\n    if (head == null || head.next == null) {\n        return null;\n    }\n\n    // 使用快慢指针\n    ListNode slow = head.next;\n    ListNode fast = head.next.next;\n\n    // 如果跳出了 while 循环，说明肯定无环\n    while (fast != null && fast.next != null) {\n        // 如果二者相遇了，说明肯定有环\n        // 这时保持 slow 位置不动，将 fast 移回 head\n        // 再和 slow 一起每次移动一步，二者相遇时即在头结点位置\n        if (slow == fast) {\n            fast = head;\n            while (slow != fast) {\n                slow = slow.next;\n                fast = fast.next;\n            }\n            return slow;\n        }\n\n        slow = slow.next;\n        fast = fast.next.next;\n    }\n\n    return null;\n}\n```\n\n\n\n### 两条单链表相交的一系列问题\n\n![image-20211013202906408](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211013202906408.png)\n\n两条单链表，可能有环也可能无环，求其相交部位的节点。该问题需要分类讨论：\n\n- 两条链表都无环：可能相交也可能不相交，若相交则入环节点相同\n- 一条有环一条无环：不可能相交\n- 两条都有环：又分为三种情况（见下图）\n  - 两条链表的环不相交\n  - 两条链表的环相交并且入环节点相同\n  - 两条链表的环相交并且入环节点不同\n\n![image-20211013203304962](/images/%E3%80%90%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E3%80%91%E9%93%BE%E8%A1%A8/image-20211013203304962.png)\n\n程序思路：\n\n- 首先判断两条链表是否都有环，如果一条有环一条无环，不可能相交，直接返回 null \n- 如果都无环，则可能相交也可能不相交；\n  - 先从头到尾遍历一次链表，计算出各自的长度。并且判断一下两条链表的尾结点是否相等，如果不相同代表肯定不相交，可以直接返回。\n  - 若二者尾结点相等，则代表相交，让长的链表的指针先移动 n 步（n 为长的链表长度减去短的链表长度）\n  - 然后两条链表的指针一起移动：\n    - 若在二者遍历到链表尾部时还未相遇，说明无相交，返回 null\n    - 若在遍历过程中二者相遇了，说明找到了相交节点\n- 如果都有环，则：\n  - 如果两条链表的入环节点相同，则说明是上图的情况2，此情况下想求相交的节点就退化为了求两条无环链表的相交节点问题，上文已分析过\n  - 若想区分情况1和情况3，则只需要让第一条链表的入环节点绕着自己的环在走一圈，如果能在途中遇到第二条链表的入环节点，即代表是情况3，否则就是情况1\n  - 情况1时，返回 null\n  - 情况3时，任意返回一个节点即可\n\n``` java\npublic class FindFirstIntersectNode {\n\n    public static ListNode getIntersectNode(ListNode head1, ListNode head2) {\n        if (head1 == null || head2 == null)\n            return null;\n\n        ListNode loop1 = getLoopNode(head1);\n        ListNode loop2 = getLoopNode(head2);\n\n        // 如果都无环\n        if (loop1 == null && loop2 == null) {\n            // 先让长的链表先走 n 步，再和短的链表一起移动，判断是否会相遇\n            return noLoop(head1, head2);\n        } else if (loop1 != null && loop2 != null) {\n            return bothLoop(head1, head2, loop1, loop2);\n        }\n\n\n        return null;\n    }\n\n\n    public static ListNode getLoopNode(ListNode head) {\n        // 边界条件\n        // 如果链表节点的长度小于3，则直接返回Null\n        if (head == null || head.next == null) {\n            return null;\n        }\n\n        // 使用快慢指针\n        ListNode slow = head.next;\n        ListNode fast = head.next.next;\n\n        // 如果跳出了 while 循环，说明肯定无环\n        while (fast != null && fast.next != null) {\n            // 如果二者相遇了，说明肯定有环\n            // 这时保持 slow 位置不动，将 fast 移回 head\n            // 再和 slow 一起每次移动一步，二者相遇时即在头结点位置\n            if (slow == fast) {\n                fast = head;\n                while (slow != fast) {\n                    slow = slow.next;\n                    fast = fast.next;\n                }\n                return slow;\n            }\n\n            slow = slow.next;\n            fast = fast.next.next;\n        }\n\n        return null;\n    }\n\n    // 都无环分两种情况：\n    //    1. 两条链表的尾结点若不相等，则不相交\n    //    2. 若尾结点相等，则肯定相交，先让长的链表走 n 步，然后二者再一起走，就能相遇\n    public static ListNode noLoop(ListNode head1, ListNode head2) {\n        if (head1 == null || head2 == null) {\n            return null;\n        }\n\n        ListNode curr1 = head1;\n        ListNode curr2 = head2;\n        int length1 = 0;\n        int length2 = 0;\n\n        // 先统计出各自的长度\n        while (curr1.next != null) {\n            curr1 = curr1.next;\n            length1++;\n        }\n        while (curr2.next != null) {\n            curr2 = curr2.next;\n            length2++;\n        }\n\n        // 在这里先判断一下两条链表的尾结点是否相等\n        // 注意：处于这种考虑，上面的 while 循环里要使用 curr.next 而不是 curr，\n        //      否则跳出循环时必定为都是 null\n        if (curr1 != curr2) {\n            return null;\n        }\n        // 能通过上面的判断，说明肯定相交\n\n        // 找出长的链表和短的链表\n        int n = length1 - length2;\n        ListNode longNode = n > 0 ? head1 : head2;\n        ListNode shortNode = longNode == head1 ? head2 : head1;\n        n = Math.abs(n);\n\n        // 长的链表先走 n 步\n        for (int i = 0; i < n; i++) {\n            longNode = longNode.next;\n        }\n\n        // 长短链表一起移动，判断在哪里相遇\n        // ps: 因为上面提前断定了肯定相交，所以可以直接这么写\n        while (longNode != shortNode) {\n            longNode = longNode.next;\n            shortNode = shortNode.next;\n        }\n\n        return longNode;\n    }\n\n    // 都有环分三种情况\n    //    1. 让其中一个入环节点 loop1 绕着自己的环走一圈，若始终没遇到 loop2 则说明不相交\n    //    2. 若两个入环节点相同 loop1 == loop2，则相交的点退化为 nonLoop 的情况\n    //    3. 让其中一个入环节点 loop1 绕着自己的环走一圈，若中途遇到了 loop2 则说明相交，返回任意一个节点即可\n    public static ListNode bothLoop(ListNode head1, ListNode head2, ListNode loop1, ListNode loop2) {\n        ListNode curr1 = null;\n        ListNode curr2 = null;\n\n        if (loop1 == loop2) {\n            // 如果相等，说明是情况2，退化为 nonLoop 情况\n            curr1 = head1;\n            curr2 = head2;\n            int length1 = 0;\n            int length2 = 0;\n\n            // 注意：这里不能写 curr1.next != loop1 ！！！\n            // 因为 curr1 自身可能就等于 loop1，这种极端情况下就会永远也遍历不到 loop1\n            while (curr1 != loop1) {\n                curr1 = curr1.next;\n                length1++;\n            }\n            while (curr2 != loop2) {\n                curr2 = curr2.next;\n                length2++;\n            }\n            int n = length1 - length2;\n            ListNode longNode = n > 0 ? head1 : head2;\n            ListNode shortNode = longNode == head1 ? head2 : head1;\n            n = Math.abs(n);\n\n            for (int i = 0; i < n; i++) {\n                longNode = longNode.next;\n            }\n\n            while (longNode != shortNode) {\n                longNode = longNode.next;\n                shortNode = shortNode.next;\n            }\n\n            return longNode;\n        } else {\n            // 为区分情况1 3，只需将 loop1 沿着自己的环走一圈\n            // 若在再次走回到 loop1 自己前如果遇到了 loop2 说明是情况3，否则就是情况1\n            curr1 = loop1.next;\n            while (curr1 != loop1) {\n                if (curr1 == loop2)\n                    return loop2;\n                curr1 = curr1.next;\n            }\n\n            // 别忘了这里\n            return null;\n        }\n\n    }\n\n    public static void main(String[] args) {\n        // 1->2->3->4->5->6->7->null\n        ListNode head1 = new ListNode(1);\n        head1.next = new ListNode(2);\n        head1.next.next = new ListNode(3);\n        head1.next.next.next = new ListNode(4);\n        head1.next.next.next.next = new ListNode(5);\n        head1.next.next.next.next.next = new ListNode(6);\n        head1.next.next.next.next.next.next = new ListNode(7);\n\n        // 0->9->8->6->7->null\n        ListNode head2 = new ListNode(0);\n        head2.next = new ListNode(9);\n        head2.next.next = new ListNode(8);\n        head2.next.next.next = head1.next.next.next.next.next; // 8->6\n        System.out.println(getIntersectNode(head1, head2).val);\n\n        // 1->2->3->4->5->6->7->4...\n        head1 = new ListNode(1);\n        head1.next = new ListNode(2);\n        head1.next.next = new ListNode(3);\n        head1.next.next.next = new ListNode(4);\n        head1.next.next.next.next = new ListNode(5);\n        head1.next.next.next.next.next = new ListNode(6);\n        head1.next.next.next.next.next.next = new ListNode(7);\n        head1.next.next.next.next.next.next = head1.next.next.next; // 7->4\n\n        // 0->9->8->2...\n        head2 = new ListNode(0);\n        head2.next = new ListNode(9);\n        head2.next.next = new ListNode(8);\n        head2.next.next.next = head1.next; // 8->2\n        System.out.println(getIntersectNode(head1, head2).val);\n\n        // 0->9->8->6->4->5->6..\n        head2 = new ListNode(0);\n        head2.next = new ListNode(9);\n        head2.next.next = new ListNode(8);\n        head2.next.next.next = head1.next.next.next.next.next; // 8->6\n        System.out.println(getIntersectNode(head1, head2).val);\n    }\n}\n```\n\n\n\n\n\n","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【JVM】JVM 垃圾回收器","url":"/2021/10/08/【JVM】JVM垃圾回收器/","content":"\n## 垃圾回收的相关概念\n\n在介绍垃圾回收器之前，首先介绍一下垃圾回收的相关概念\n\n### System.gc() 的理解\n\n在默认情况下，通过`System.gc()`或者`Runtime.getRuntime().gc(`) 的调用，**会显式触发Full GC**，同时对老年代和新生代进行回收，尝试释放被丢弃对象占用的内存。\n\n然而`System.gc()`调用附带一个免责声明，无法保证对垃圾收集器的调用（不能确保立即生效）\n\nJVM实现者可以通过 `System.gc()` 调用来决定JVM的GC行为。而一般情况下，垃圾回收应该是自动进行的，**无须手动触发，否则就太过于麻烦了**。在一些特殊情况下，如我们正在编写一个性能基准，我们可以在运行之间调用`System.gc()`\n\n<!-- More -->\n\n代码演示是否触发GC操作\n\n```java\npublic class SystemGCTest {\n    public static void main(String[] args) {\n        new SystemGCTest();\n        System.gc();// 提醒jvm的垃圾回收器执行gc,但是不确定是否马上执行gc\n        // 与Runtime.getRuntime().gc();的作用一样。\n\n        // System.runFinalization();//强制调用使用引用的对象的finalize()方法\n    }\n    \n    // 如果发生了GC，这个finalize()一定会被调用\n    @Override\n    protected void finalize() throws Throwable {\n        super.finalize();\n        System.out.println(\"SystemGCTest 重写了finalize()\");\n    }\n}\n```\n\n运行结果，但是不一定会触发销毁的方法，调用`System.runFinalization()`会强制调用失去引用对象的`finalize()`\n\n```\nSystemGCTest 执行了 finalize方法\n```\n\n### 手动 GC 来理解不可达对象的回收\n\n代码如下所示：\n\n```java\npublic class LocalVarGC {\n\n    /**\n     * 触发Minor GC没有回收对象，然后在触发Full GC将该对象存入old区\n     */\n    public void localvarGC1() {\n        byte[] buffer = new byte[10*1024*1024];\n        System.gc();\n    }\n\n    /**\n     * 触发YoungGC的时候，已经被回收了\n     */\n    public void localvarGC2() {\n        byte[] buffer = new byte[10*1024*1024];\n        buffer = null;\n        System.gc();\n    }\n\n    /**\n     * 不会被回收，因为它还存放在局部变量表索引为1的槽中\n     */\n    public void localvarGC3() {\n        {\n            byte[] buffer = new byte[10*1024*1024];\n        }\n        System.gc();\n    }\n\n    /**\n     * 会被回收，因为它还存放在局部变量表索引为1的槽中，但是后面定义的value把这个槽给替换了\n     */\n    public void localvarGC4() {\n        {\n            byte[] buffer = new byte[10*1024*1024];\n        }\n        int value = 10;\n        System.gc();\n    }\n\n    /**\n     * localvarGC5中的数组已经被回收\n     */\n    public void localvarGC5() {\n        localvarGC1();\n        System.gc();\n    }\n\n    public static void main(String[] args) {\n        LocalVarGC localVarGC = new LocalVarGC();\n        localVarGC.localvarGC3();\n    }\n}\n```\n\n上述五个方法的详细分析见博客：https://imlql.cn/post/4d401a8b.html\n\n### 内存溢出\n\n内存溢出相对于内存泄漏来说，尽管更容易被理解，但是同样的，内存溢出也是引发程序崩溃的罪魁祸首之一。\n\n由于GC一直在发展，所有一般情况下，除非应用程序占用的内存增长速度非常快，造成垃圾回收已经跟不上内存消耗的速度，否则不太容易出现OOM的情况。大多数情况下，GC会进行各种年龄段的垃圾回收，实在不行了就放大招，来一次独占式的Full GC操作，这时候会回收大量的内存，供应用程序继续使用。\n\n**javadoc中对OutOfMemoryError的解释是，没有空闲内存，并且垃圾收集器也无法提供更多内存**。\n\n#### 内存溢出（OOM）原因分析\n\n首先说没有空闲内存的情况：说明Java虚拟机的堆内存不够。原因有二：\n\n- Java虚拟机的**堆内存设置不够**。\n  - 比如：可能存在内存泄漏问题；也很有可能就是堆的大小不合理，比如我们要处理比较可观的数据量，但是没有显式指定JVM堆大小或者指定数值偏小。我们可以通过参数`-Xms` 、`-Xmx`来调整。\n- 代码中创建了**大量大对象**，并且长时间不能被垃圾收集器收集（存在被引用）。\n  - 对于老版本的oracle JDK，因为永久代的大小是有限的，并且JVM对永久代垃圾回收（如，常量池回收、卸载不再需要的类型）非常不积极，所以当我们不断添加新类型的时候，永久代出现`OutOfMemoryError`也非常多见，尤其是在运行时存在大量动态类型生成的场合；类似intern字符串缓存占用太多空间，也会导致OOM问题。对应的异常信息，会标记出来和永久代相关：“`java.lang.OutOfMemoryError:PermGen space`\"。\n  - 随着元数据区的引入，方法区内存已经不再那么窘迫，所以相应的OOM有所改观，出现OOM，异常信息则变成了：“`java.lang.OutofMemoryError:Metaspace`\"。直接内存不足，也会导致OOM。\n\n这里面隐含着一层意思是，在抛出`OutOfMemoryError`之前，通常垃圾收集器会被触发，尽其所能去清理出空间。\n\n- 例如：在引用机制分析中，涉及到JVM会去尝试**回收软引用指向的对象**等。\n- 在`java.nio.Bits.reserveMemory()`方法中，我们能清楚的看到，`System.gc()`会被调用，以清理空间。\n\n当然，也不是在任何情况下垃圾收集器都会被触发的。比如，我们去分配一个超大对象，类似一个超大数组超过堆的最大值，JVM可以判断出垃圾收集并不能解决这个问题，所以直接抛出`OutOfMemoryError`。\n\n### 内存泄漏\n\n也称作“存储渗漏”。严格来说，**只有对象不会再被程序用到了，但是GC又不能回收他们的情况，才叫内存泄漏**。但实际情况很多时候一些不太好的实践（或疏忽）会导致对象的生命周期变得很长甚至导致OOM，也可以叫做宽泛意义上的“内存泄漏”。\n\n> 例如创建一个数组中存储若干对象，该数组对象不再被引用了，但是其内存储的对象因为还有被这个数组所引用，因此一直不会被释放，造成了内存泄漏\n\n尽管内存泄漏并不会立刻引起程序崩溃，但是一旦发生内存泄漏，程序中的可用内存就会被逐步蚕食，直至耗尽所有内存，最终出现`OutOfMemory`异常，导致程序崩溃。\n\n注意，这里的存储空间并不是指物理内存，而是指虚拟内存大小，这个虚拟内存大小取决于磁盘交换区设定的大小。\n\n> 买房子：80平的房子，但是有10平是公摊的面积，我们是无法使用这10平的空间，这就是所谓的内存泄漏\n\n#### 内存泄露官方例子\n\n- 左边的图：Java使用可达性分析算法，最上面的数据不可达，就是需要被回收的对象。\n- 右边的图：后期有一些对象不用了，按道理应该断开引用，但是存在一些链没有断开（图示中的Forgotten Reference Memory Leak），从而导致没有办法被回收。\n\n![image-20200712195158470](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712195158470.png)\n\n#### 内存泄漏常见例子\n\n- **单例模式**。单例的生命周期和应用程序是一样长的，所以单例程序中，如果持有对外部对象的引用的话，那么这个外部对象是不能被回收的，则会导致内存泄漏的产生。\n- **提供`close()`的资源未关闭**导致内存泄漏。数据库连接（`dataSourse.getConnection()` ），网络连接（socket）和io连接必须手动`close()`，否则是不能被回收的。\n\n内存泄漏的更多例子见文章[【JVM】JVM 调优实战案例](https://yuyun-zhao.github.io/2021/10/19/%E3%80%90JVM%E3%80%91JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B/)。\n\n### Stop The World\n\nStop-The-World，简称STW，指的是GC事件发生过程中，会产生应用程序的停顿。**停顿产生时整个应用程序线程都会被暂停，没有任何响应**，有点像卡死的感觉，这个停顿称为STW。\n\n**可达性分析算法中枚举根节点（GC Roots）会导致所有Java执行线程停顿**。\n\n- 分析工作必须在一个**能确保一致性的快照**中进行\n- 一致性指整个分析期间整个执行系统看起来像被冻结在某个时间点上\n- 如果出现分析过程中对象引用关系还在不断变化，则分析结果的准确性无法保证\n\n被STW中断的应用程序线程会在完成GC之后恢复，频繁中断会让用户感觉像是网速不快造成电影卡带一样，所以我们需要减少STW的发生。\n\nSTW事件和采用哪款GC无关，所有的GC都有这个事件。哪怕是G1也不能完全避免Stop-The-World情况发生，只能说垃圾回收器越来越优秀，回收效率越来越高，**尽可能地**缩短了暂停时间。\n\nSTW是JVM在后台自动发起和自动完成的。在用户不可见的情况下，把用户正常的工作线程全部停掉。\n\n开发中不要主动调用 `system.gc()` ，这会导致Stop-The-World的发生。\n\n### 安全点与安全区域\n\n#### 安全点（Safepoint）\n\n程序执行时并非在所有地方都能停顿下来开始GC，只有在特定的位置才能停顿下来开始GC，这些位置称为“安全点（Safepoint）”。\n\nSafe Point的选择很重要，**如果太少可能导致GC等待的时间太长，如果太频繁可能导致运行时的性能问题**。大部分指令的执行时间都非常短暂，通常会根据“**是否具有让程序长时间执行的特征**”为标准。比如：选择一些执行时间较长的指令作为Safe Point，**如方法调用、循环跳转和异常跳转等**。\n\n如何在GC发生时，检查所有线程都跑到最近的安全点停顿下来呢？\n\n- **抢先式中断**：（目前没有虚拟机采用了）首先中断所有线程。如果还有线程不在安全点，就恢复线程，让线程跑到安全点。\n- **主动式中断**：设置一个中断标志，各个线程运行到Safe Point的时候**主动轮询**这个标志，如果中断标志为真，则将自己进行中断挂起。（有轮询的机制）\n\n#### 安全区域（Safe Region）\n\nSafepoint 机制保证了程序执行时，在不太长的时间内就会遇到可进入GC的Safepoint。但是，程序“不执行”的时候呢？例如线程处于sleep状态或Blocked 状态，这时候线程无法响应JVM的中断请求，“走”到安全点去中断挂起，JVM也不太可能等待线程被唤醒。对于这种情况，就需要安全区域（Safe Region）来解决。\n\n**安全区域是指在一段代码片段中，对象的引用关系不会发生变化，在这个区域中的任何位置开始GC都是安全的**。我们也可以把Safe Region看做是被扩展了的Safepoint。\n\n**安全区域的执行流程：**\n\n- 当线程运行到Safe Region的代码时，首先标识已经进入了Safe Region，如果这段时间内发生GC，**JVM会忽略标识为Safe Region状态的线程**\n- 当线程即将离开Safe Region时，会检查JVM是否已经完成GC，如果完成了，则继续运行，否则线程必须等待直到收到可以安全离开Safe Region的信号为止；\n\n因为线程在安全区域内不会改变对象间的引用关系，这就保证了其在安全区域内执行代码不会影响到GC，因此可以不需要STW，继续在安全区域内执行代码。\n\n### 记忆集与卡表\n\n#### 什么是跨代引用？\n\n一般的垃圾回收算法至少会划分出两个代：年轻代和老年代。但是单纯的分代理论在垃圾回收的时候存在一个巨大的缺陷：**为了找到年轻代中的存活对象，却不得不遍历整个老年代，反过来也是一样的**。\n\n这是因为可能某些年轻代的对象被老年代的对象所引用，这样如果某个垃圾回收器只回收年轻代的对象，那么其必须还要再额外遍历老年代的对象判断是否有引用年代的对象，这无疑浪费了很多时间。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/0011.png)\n\n如果我们从年轻代开始遍历，那么可以断定N, S, P, Q都是存活对象。但是，V却不会被认为是存活对象，其占据的内存会被回收了。这就是一个惊天的大漏洞！因为U本身是老年代对象，而且有外部引用指向它，也就是说U是存活对象，而U指向了V，也就是说V也应该是存活对象才是！而这都是因为我们只遍历年轻代对象！\n\n所以，为了解决这种跨代引用的问题，最笨的办法就是遍历老年代的对象，找出这些跨代引用来。这种方案存在极大的性能浪费。因为从两个分代假说里面，其实隐含了一个推论：跨代引用是极少的。也就是为了找出那么一点点跨代引用，我们却得遍历整个老年代！从上图来说，很显然的是，我们根本不必遍历R。\n\n因此，为了避免这种遍历老年代的性能开销，通常的分代垃圾回收器会引入一种称为**记忆集 Remembered Set（RSet）**的技术。**简单来说，记忆集就是用来记录跨代引用的表。**\n\n#### 记忆集 Remembered Set\n\n为解决对象跨代引用所带来的问题，垃圾收集器在新生代中建立了名为**记忆集（Remembered Set）的数据结构**，用以避免把整个老年代加进GC Roots扫描范围。事实上并不只是新生代、老年代之间才有跨代引用的问题，所有涉及**部分区域收集**（Partial GC）行为的垃圾收集器，典型的如G1、ZGC和Shenandoah收集器，都会面临相同的问题，因此我们有必要进一步理清记忆集的原理和实现方式，以便在后续章节里介绍几款最新的收集器相关知识时能更好地理解。\n\n记忆集 Remembered Set 是一种用于记录**从非收集区域指向收集区域的指针集合的==抽象==数据结构**。如果我们不考虑效率和成本的话，最简单的实现可以用非收集区域中所有含跨代引用的对象数组来实现这个数据结构。\n\n> 比如说我们有老年代（非收集区域）和年轻代（收集区域）的对象之间有一条引用链\n\n#### 卡表 Card Table\n\n> 记忆集是一种抽象的概念，卡表是记忆集的一种具体实现。\n\n这种记录全部含跨代引用对象的实现方案，无论是空间占用还是维护成本都相当高昂。而在垃圾收集的场景中，**收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了**，并不需要了解这些跨代指针的全部细节。那设计者在实现记忆集的时候，便可以选择更为粗犷的记录粒度来节省记忆集的存储和维护成本，下面列举了一些可供选择（当然也可以选择这个范 围以外的）的记录精度：\n\n- 字长精度：每个记录精确到**一个机器字长**（就是处理器的寻址位数，如常见的32位或64位，这个 精度决定了机器访问物理内存地址的指针长度），该字包含跨代指针。\n- 对象精度：每个记录精确到**一个对象**，该对象里有字段含有跨代指针。\n- **卡精度**：每个记录精确到**一块内存区域**，该区域内有对象含有跨代指针。\n\n其中，第三种“卡精度”所指的是用一种称为“卡表”（Card Table）的方式去实现记忆集，这也是目前**最常用**的一种记忆集实现形式，一些资料中甚至直接把它和记忆集混为一谈。\n\n前面定义中提到记忆集其实是一种“**抽象**”的数据结构，抽象的意思是**只定义了记忆集的行为意图，并没有定义其行为的具体实现**。**卡表就是记忆集的一种具体实现**，它定义了记忆集的记录精度、与堆内存的映射关系等。 \n\n关于卡表与记忆集的关系，我们不妨按照Java语言中HashMap与Map的关系来类比理解。 卡表最简单的形式**可以只是一个字节数组，而HotSpot虚拟机确实也是这样做的**\n\n> 读者只需要知道有这个东西，面试的时候能说出来，再细致一点的就需要看周志明老师的第三版书了\n\n\n\n## 垃圾回收的并行与并发\n\n### 并发的概念\n\n在操作系统中，是指**一个时间段内**有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理器上运行。\n\n并发不是真正意义上的“同时进行”，只是CPU把一个时间段划分成几个时间片段（时间区间），然后在这几个时间区间之间来回切换，由于CPU处理的速度非常快，只要时间间隔处理得当，即可让用户感觉是多个应用程序同时在进行。\n\n![image-20200712202522051](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712202522051.png)\n\n### 并行的概念\n\n当系统**有一个以上CPU时**，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，我们称之为并行（Parallel）。\n\n决定并行的因素不是CPU的数量，而是CPU的**核心数量**，比如一个CPU多个核也可以并行。\n\n并行适合科学计算，后台处理等**弱交互场景**。因为一旦后台任务开始并行计算，用户的交互线程就会STW。\n\n![image-20200712202822129](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712202822129.png)\n\n### 并发和并行对比\n\n- **并发**，指的是多个事情，在**同一时间段内**看似同时的发生了（本质上还是多个线程交替抢占CPU）。\n- **并行**，指的是多个事情，在**同一时刻**上真正同时的发生了。\n\n并发的多个任务之间是互相抢占资源的。并行的多个任务之间是不互相抢占资源的。\n\n只有在多CPU或者一个CPU多核的情况中，才会发生并行。否则，看似同时发生的事情，其实都是并发执行的。\n\n### 垃圾回收的并行与并发\n\n并发和并行，在谈论垃圾收集器的上下文语境中，它们可以解释如下：\n\n- 并行（Parallel）：GC时多条垃圾收集线程并行工作，但**用户线程需要处于STW状态**。如ParNew、Parallel Scavenge、Parallel Old都是并行的垃圾处理器。适合**高吞吐量**的场景，但是低延迟无法满足。\n\n- 串行（Serial）：GC只在一个线程中执行，用户线程需要处于STW状态。在单核CPU的串行的垃圾回收器可能性能还要优于并行的垃圾回收器\n\n\n![image-20200712203607845](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712203607845.png)\n\n- 并发（Concurrent）：指**用户线程与垃圾收集线程同时执行**（但不一定是并行的，可能会交替执行），垃圾回收线程在执行时**不会停顿用户程序的运行**（STW）。如：CMS、G1垃圾回收器都有并发的阶段。适合**低延迟**的应用场景，其吞吐量相应就会变差。\n\n![image-20200712203815517](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712203815517.png)\n\n## 四种引用\n\n> 【既偏门又非常高频的面试题】强引用、软引用、弱引用、虚引用有什么区别？具体使用场景是什么？\n\n我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存中；如果内存空间在进行垃圾收集后还是很紧张，则可以抛弃这些对象。\n\n在JDK1.2版之后，Java对引用的概念进行了扩充，将引用分为：\n\n- 强引用（Strong Reference）\n- 软引用（Soft Reference）\n- 弱引用（Weak Reference）\n- 虚引用（Phantom Reference）\n\n这4种引用强度依次逐渐减弱。除强引用外，其他3种引用均可以在`java.lang.ref`包中找到它们的身影。如下图，显示了这3种引用类型对应的类，开发人员可以在应用程序中直接使用它们。\n\n![image-20200712205813321](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712205813321.png)\n\nReference子类中只有**终结器引用**是包内可见的，其他3种引用类型均为public，可以在应用程序中直接使用。四种引用：\n\n- 强引用（StrongReference）：最传统的“引用”的定义，是指在程序代码之中普遍存在的引用赋值，即类似“`Object obj = new Object()`”这种引用关系。无论任何情况下，**只要强引用关系还存在，垃圾收集器就永远不会回收掉被引用的对象**。\n- 软引用（SoftReference）：在系统将要**发生内存溢出之前，将会把这些对象列入回收范围之中进行第二次回收**。如果这次回收后还没有足够的内存，才会抛出内存流出异常。\n- 弱引用（WeakReference）：被弱引用关联的对象只能生存到下一次垃圾收集之前。当垃圾收集器工作时，**无论内存空间是否足够，都会回收掉被弱引用关联的对象**。\n- 虚引用（PhantomReference）：一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来获得一个对象的实例。**为一个对象设置虚引用关联的唯一目的就是能在这个对象被收集器回收时收到一个系统通知**。\n\n快速记忆：\n\n- 强引用：不论如何，只要引用关系还在就不会被回收，哪怕OOM\n- 软引用：GC后，如果内存还是要OOM，就把软引用给清除掉\n- 弱引用：只要一开始GC，就把弱引用给清除掉，无论后面会不会OOM\n- 虚引用：一个虚引用对象等于没有引用，GC时直接清除，但是其所在的引用队列会在被GC时通知应用程序对象的回收情况\n\n### 强引用\n\n在Java程序中，最常见的引用类型是强引用（普通系统99%以上都是强引用），也就是我们最常见的普通对象引用，也是**默认的引用类型**。当在Java语言中使用new操作符创建一个新的对象，并将其赋值给一个变量的时候，这个变量就成为指向该对象的一个强引用。\n\n强引用的对象是可触及的，垃圾收集器就**永远不会回收掉被引用的对象**。\n\n对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，就是可以当做垃圾被收集了，当然具体回收时机还是要看垃圾收集策略。\n\n相对的，软引用、弱引用和虚引用的对象是**软可触及**、**弱可触及**和**虚可触及**的，在一定条件下，都是可以被回收的。所以，强引用是造成Java内存泄漏的主要原因之一。\n\n强引用的案例说明\n\n```java\nStringBuffer str = new StringBuffer(\"hello world\");\n```\n\n局部变量str指向`stringBuffer`实例所在堆空间，通过str可以操作该实例，那么str就是stringBuffer实例的强引用对应内存结构：\n\n![image-20200712211501377](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712211501377.png)\n\n如果此时，在运行一个赋值语句\n\n```java\nStringBuffer str = new StringBuffer(\"hello world\");\nStringBuffer str1 = str;\n```\n\n对应的内存结构为:\n\n![image-20200712211732976](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200712211732976.png)\n\n那么我们将 `str = null`，原来堆中的对象也不会被回收，因为还有其它对象指向该区域\n\n总结：本例中的两个引用，都是强引用，强引用具备以下特点：\n\n- 强引用可以直接访问目标对象。\n- 强引用所指向的对象在任何时候都不会被系统回收，虚拟机宁愿抛出OOM异常，也不会回收强引用所指向对象。\n- 强引用可能导致内存泄漏。\n\n### 软引用\n\n> **软引用（Soft Reference）：内存不足即回收**\n\n软引用是用来描述一些**还有用，但非必需**的对象。只被软引用关联着的对象，在系统将要发生内存溢出异常前，会把这些对象列进回收范围之中进行第二次回收，如果这次回收还没有足够的内存，才会抛出内存溢出异常。\n\n> 注意，这里的第一次回收是不可达的对象\n\n软引用通常用来实现**内存敏感的缓存**。比如：高速缓存就有用到软引用。如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。\n\n> MyBatis 的底层就用到了软引用，其缓存对象在OOM时将被清除\n\n垃圾回收器在某个时刻决定回收软可达的对象的时候，会清理软引用，并可选地把引用存放到一个**引用队列**（Reference Queue）。\n\n类似弱引用，只不过Java虚拟机会尽量让软引用的存活时间长一些，迫不得已才清理。\n\n> 一句话概括：当内存足够时，不会回收软引用可达的对象。内存不够时，会回收软引用的可达对象\n\n在JDK1.2版之后提供了`SoftReference`类来实现软引用\n\n```java\n// 声明强引用\nObject obj = new Object();\n// 创建一个软引用\nSoftReference<Object> sf = new SoftReference<>(obj);\nobj = null; // 销毁强引用，这是必须的，不然会存在强引用和软引用\n```\n\n### 弱引用\n\n> **弱引用：一旦 GC 即回收**\n\n弱引用也是用来描述那些非必需对象，**只被弱引用关联的对象只能生存到下一次垃圾收集发生为止。在系统GC时，只要发现弱引用，不管系统堆空间使用是否充足，都会回收掉只被弱引用关联的对象**。\n\n但是，由于垃圾回收器的线程通常优先级很低，因此，并不一定能很快地发现持有弱引用的对象。在这种情况下，弱引用对象可以存在较长的时间。\n\n弱引用和软引用一样，在构造弱引用时，也可以指定一个引用队列，当弱引用对象被回收时，就会加入指定的引用队列，通过这个队列可以跟踪对象的回收情况。\n\n软引用、弱引用都非常适合来保存那些**可有可无的缓存数据**。如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。\n\n在JDK1.2版之后提供了`WeakReference`类来实现弱引用\n\n```java\n// 声明强引用\nObject obj = new Object();\n// 创建一个弱引用\nWeakReference<Object> sf = new WeakReference<>(obj);\nobj = null; // 销毁强引用，这是必须的，不然会存在强引用和弱引用\n```\n\n弱引用对象与软引用对象的最大不同就在于，当GC在进行回收时，需要通过算法检查是否回收软引用对象，而对于弱引用对象，GC总是进行回收。**弱引用对象更容易、更快被GC回收**。\n\n---\n\n面试题：你开发中使用过`WeakHashMap`吗？\n\n`WeakHashMap`可以用来存储图片等缓存信息，可以在内存不足的时候，及时回收，避免了OOM。其底层就是采用的弱引用实现。\n\n代码：\n\n```java\npublic class WeakReferenceTest {\n    public static void main(String[] args) {\n        // 构造了弱引用\n        WeakReference<User> userWeakRef = new WeakReference<User>(new User(1, \"zhangsan\"));\n        // 从弱引用中重新获取对象\n        System.out.println(userWeakRef.get());\n\n        System.gc();\n        // 不管当前内存空间足够与否，都会回收它的内存\n        System.out.println(\"After GC:\");\n        // 重新尝试从弱引用中获取对象\n        System.out.println(userWeakRef.get());\n    }\n}\n```\n\n执行垃圾回收后，软引用对象必定被清除。\n\n---\n\n### 虚引用\n\n> **虚引用（Phantom Reference）：对象回收跟踪**\n\n虚引用也称为“幽灵引用”或者“幻影引用”，是所有引用类型中最弱的一个。\n\n一个对象是否有虚引用的存在，**完全不会决定对象的生命周期**。**如果一个对象仅持有虚引用，那么它和没有引用几乎是一样的，随时都可能被垃圾回收器回收**。\n\n**它不能单独使用，也无法通过虚引用来获取被引用的对象**。当试图通过虚引用的`get()`方法取得对象时，总是null。\n\n为一个对象设置虚引用关联的唯一目的在于**跟踪垃圾回收过程**。比如：**能在这个对象被收集器回收时收到一个系统通知**。\n\n虚引用必须和引用队列一起使用。虚引用在创建时必须提供一个引用队列作为参数。**当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象后，将这个虚引用加入引用队列，以通知应用程序对象的回收情况**。\n\n由于虚引用可以跟踪对象的回收时间，因此，也可以将一些**资源释放操作**放置在虚引用中执行和记录。\n\n> 虚引用无法获取到我们的数据\n\n在JDK1.2版之后提供了`PhantomReference`类来实现虚引用。\n\n```java\n// 声明强引用\nObject obj = new Object();\n// 声明引用队列\nReferenceQueue phantomQueue = new ReferenceQueue();\n// 声明虚引用（还需要传入引用队列）\nPhantomReference<Object> sf = new PhantomReference<>(obj, phantomQueue);\nobj = null; \n```\n\n我们使用一个案例，来结合虚引用，引用队列，finalize进行讲解\n\n```java\npublic class PhantomReferenceTest {\n    // 当前类对象的声明\n    public static PhantomReferenceTest obj;\n    // 引用队列\n    static ReferenceQueue<PhantomReferenceTest> phantomQueue = null;\n\n    @Override\n    protected void finalize() throws Throwable {\n        super.finalize();\n        System.out.println(\"调用当前类的finalize方法\");\n        obj = this;\n    }\n\n    public static void main(String[] args) {\n        Thread thread = new Thread(() -> {\n            while(true) {\n                if (phantomQueue != null) {\n                    PhantomReference<PhantomReferenceTest> objt = null;\n                    try {\n                        objt = (PhantomReference<PhantomReferenceTest>) phantomQueue.remove();\n                    } catch (Exception e) {\n                        e.getStackTrace();\n                    }\n                    if (objt != null) {\n                        System.out.println(\"追踪垃圾回收过程：PhantomReferenceTest实例被GC了\");\n                    }\n                }\n            }\n        }, \"t1\");\n        thread.setDaemon(true);\n        thread.start();\n\n        phantomQueue = new ReferenceQueue<>();\n        obj = new PhantomReferenceTest();\n        // 构造了PhantomReferenceTest对象的虚引用，并指定了引用队列\n        PhantomReference<PhantomReferenceTest> phantomReference = new PhantomReference<>(obj, phantomQueue);\n        try {\n            System.out.println(phantomReference.get());\n            // 去除强引用\n            obj = null;\n            // 第一次进行GC，由于对象可复活，GC无法回收该对象\n            System.out.println(\"第一次GC操作\");\n            System.gc();\n            Thread.sleep(1000);\n            if (obj == null) {\n                System.out.println(\"obj 是 null\");\n            } else {\n                System.out.println(\"obj 不是 null\");\n            }\n            System.out.println(\"第二次GC操作\");\n            obj = null;\n            System.gc();\n            Thread.sleep(1000);\n            if (obj == null) {\n                System.out.println(\"obj 是 null\");\n            } else {\n                System.out.println(\"obj 不是 null\");\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n\n        }\n    }\n}\n```\n\n最后运行结果\n\n```java\nnull\n第一次GC操作\n调用当前类的finalize方法\nobj 不是 null\n第二次GC操作\n追踪垃圾回收过程：PhantomReferenceTest实例被GC了\nobj 是 null\n```\n\n从上述运行结果我们知道，第一次尝试获取虚引用的值，发现无法获取的，这是因为虚引用是无法直接获取对象的值，然后进行第一次gc，因为会调用`finalize()`方法，将对象复活了，所以对象没有被回收。\n\n但是调用第二次gc操作的时候，因为`finalize()`方法只能执行一次，所以就触发了GC操作，将对象回收了，同时将会触发第二个操作：将回收的值存入到引用队列中。\n\n### 终结器引用\n\n它用于实现对象的` finalize()` 方法，也可以称为终结器引用。\n\n无需手动编码，其内部配合引用队列使用。在GC时，终结器引用入队。**由Finalizer线程通过终结器引用找到被引用对象调用它的`finalize()`方法**，第二次GC时才回收被引用的对象。\n\n\n\n## 垃圾回收器的分类与性能指标\n\n### 垃圾回收器概述\n\n垃圾收集器没有在规范中进行过多的规定，可以由不同的厂商、不同版本的JVM来实现。由于JDK的版本处于高速迭代过程中，因此Java发展至今已经衍生了众多的GC版本。从不同角度分析垃圾收集器，可以将GC分为不同的类型。\n\n**Java 不同版本新特性**\n\n1. 语法层面：Lambda表达式、switch、自动拆箱装箱、enum、泛型\n2. API层面：Stream API、新的日期时间、Optional、String、集合框架\n3. 底层优化：JVM优化、GC的变化、元空间、静态域、字符串常量池等\n\n### 垃圾收集器分类\n\n**1、按线程数分（垃圾回收线程数），可以分为串行垃圾回收器和并行垃圾回收器**。\n\n![image-20200713083030867](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713083030867.png)\n\n- 串行回收：指的是在同一时间段内只允许有一个CPU用于执行垃圾回收操作，此时工作线程被暂停，直至垃圾收集工作结束\n  - 在诸如**单CPU处理器或者较小的应用内存等硬件平台不是特别优越的场合**，串行回收器的性能表现可以超过并行回收器和并发回收器。所以，串行回收默认被应用在**客户端的Client模式**下的JVM中\n  - 在并发能力比较强的CPU上，并行回收器产生的停顿时间要短于串行回收器\n- 并行回收：和串行回收相反，并行回收可以运用多个CPU同时执行垃圾回收，因此提升了应用的吞吐量，不过并行回收仍然与串行回收一样，采用**独占式**，使用了“stop-the-world”机制，工作期间用户线程将STW。\n\n**2、按照工作模式分，可以分为并发式垃圾回收器和独占式垃圾回收器**。\n\n- 并发式垃圾回收器与应用程序线程**交替**工作，以尽可能减少应用程序的停顿时间。\n- 独占式垃圾回收器（Stop the World）一旦运行，就停止应用程序中的所有用户线程，直到垃圾回收过程完全结束。即用户线程会STW。\n\n![image-20200713083443486](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713083443486.png)\n\n**3、按碎片处理方式分，可分为压缩式垃圾回收器和非压缩式垃圾回收器**\n\n- 压缩式垃圾回收器会在回收完成后，对存活对象进行**压缩整理**，消除回收后的碎片。\n- 非压缩式的垃圾回收器不进行这步操作。\n\n**4、按工作的内存区间分，又可分为年轻代垃圾回收器和老年代垃圾回收器**。\n\n### 评估 GC 的性能指标\n\n- ==**吞吐量**==：运行用户代码的时间占总运行时间的比例（总运行时间 = 程序的运行时间 + 内存回收的时间）\n- **垃圾收集开销**：吞吐量的补数，垃圾收集所用时间与总运行时间的比例。\n- ==**暂停时间**==：执行垃圾收集时，程序的工作线程被暂停的时间，即STW时间。\n- **收集频率**：相对于应用程序的执行，收集操作发生的频率。\n- **内存占用**：Java堆区所占的内存大小。\n- **快速**：一个对象从诞生到被回收所经历的时间。\n\n吞吐量、暂停时间、内存占用这三者共同构成一个“不可能三角”。三者总体的表现会随着技术进步而越来越好。一款优秀的收集器通常最多同时满足其中的两项。\n\n这三项里，暂停时间的重要性日益凸显。因为随着硬件发展，内存占用多些越来越能容忍，硬件性能的提升也有助于降低收集器运行时对应用程序的影响，即提高了吞吐量。而内存的扩大，对延迟反而带来负面效果。\n\n简单来说，最重要的两点：\n\n- **吞吐量**\n- **暂停时间**\n\n### 性能指标：吞吐量\n\n吞吐量就是CPU用于**运行用户代码的时间**与CPU**总消耗时间**的比值，即吞吐量=运行用户代码时间 /（运行用户代码时间+垃圾收集时间）\n\n>比如：虚拟机总共运行了100分钟，其中垃圾收集花掉1分钟，那吞吐量就是99%。\n\n这种情况下，应用程序能容忍较高的暂停时间，因此，高吞吐量的应用程序有更长的时间基准，快速响应是不必考虑的。\n\n吞吐量优先，意味着在单位时间内，STW的时间最短：0.2+0.2=0.4\n\n![image-20200713084726176](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713084726176.png)\n\n### 性能指标：暂停时间\n\n“暂停时间”是指一个时间段内应用程序线程暂停STW，让GC线程执行的状态\n\n例如，GC期间100毫秒的暂停时间意味着在这100毫秒期间内没有应用程序线程是活动的。暂停时间优先，意味着尽可能让单次STW的时间最短：0.1+0.1 + 0.1+ 0.1+ 0.1=0.5\n\n![image-20200713085306400](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713085306400.png)\n\n### 吞吐量 vs 暂停时间\n\n- 高吞吐量较好因为这会让应用程序的最终用户感觉只有应用程序线程在做“生产性”工作。直觉上，吞吐量越高程序运行越快。\n- 低暂停时间（低延迟）较好因为从最终用户的角度来看不管是GC还是其他原因导致一个应用被挂起始终是不好的。这取决于应用程序的类型，有时候甚至短暂的200毫秒暂停都可能打断终端用户体验。因此，具有低的较大暂停时间是非常重要的，特别是对于一个交互式应用程序。\n\n不幸的是“高吞吐量”和“低暂停时间”是一对**相互竞争的目标**（矛盾）。\n\n- 因为如果选择以吞吐量优先，那么必然需要降低内存回收的执行频率，但是这样会导致GC需要更长的暂停时间来执行内存回收（因为STW的频率越高，说明CPU要切换的次数越多，切换CPU造成的时间总停顿数越多，从而吞吐量下降）。\n- 相反的，如果选择以低延迟优先为原则，那么为了降低每次执行内存回收时的暂停时间，也只能频繁地执行内存回收，但这又引起了年轻代内存的缩减和导致程序吞吐量的下降。\n\n在设计（或使用）GC算法时，我们必须确定我们的目标：一个GC算法只可能针对两个目标之一（即只专注于较大吞吐量或最小暂停时间），或尝试找到一个二者的折衷。\n\n现在标准：**在最大吞吐量优先的情况下，降低停顿时间**\n\n## 垃圾回收器概述\n\nJava常见的垃圾收集器有哪些？\n\n> GC垃圾收集器是和JVM一脉相承的，它是和JVM进行搭配使用，在不同的使用场景对应的收集器也是有区别\n\n### 垃圾回收器发展史\n\n有了虚拟机，就一定需要收集垃圾的机制，这就是Garbage Collection，对应的产品我们称为Garbage Collector。\n\n- 1999年随JDK 1.3.1一起来的是串行方式的Serial GC，它是第一款GC。ParNew垃圾收集器是Serial收集器的多线程版本\n- 2002年2月26日，Parallel GC和Concurrent Mark Sweep GC跟随JDK1.4.2一起发布·\n- Parallel GC在JDK 6之后成为HotSpot默认GC。\n- 2012年，在JDK 1.7u4版本中，G1可用。\n- 2017年，**JDK 9中G1变成默认的垃圾收集器**，以替代CMS。\n- 2018年3月，JDK 10中G1垃圾回收器的并行完整垃圾回收，实现并行性来改善最坏情况下的延迟。\n- 2018年9月，JDK 11发布。引入Epsilon 垃圾回收器，又被称为 \"No-Op(无操作)“ 回收器。同时，引入 **ZGC：可伸缩的低延迟垃圾回收器（Experimental）**。ZGC处于实验阶段。\n- 2019年3月，JDK 12发布。增强G1，自动返回未用堆内存给操作系统。同时，引入Shenandoah GC：低停顿时间的GC（Experimental）。·2019年9月，JDK13发布。增强ZGC，自动返回未用堆内存给操作系统。\n- 2020年3月，JDK 14发布。**删除CMS垃圾回收器**。扩展ZGC在macos和Windows上的应用。ZGC仍处于实验阶段。\n- 2020年9月，JDK 15发布。ZGC正式进入可用阶段，但并不是默认的GC\n\n### 7种经典的垃圾收集器\n\n- 串行回收器：Serial、Serial Old\n- 并行回收器：ParNew、Parallel Scavenge、Parallel Old\n- 并发回收器：CMS、G1\n\n![image-20200713093551365](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713093551365.png)\n\n### 7款经典收集器与垃圾分代之间的关系\n\n![image-20200713093757644](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713093757644.png)\n\n- 新生代收集器：Serial、ParNew、Parallel Scavenge\n- 老年代收集器：Serial old、Parallel old、CMS\n- 整堆收集器：G1\n\n### 垃圾收集器的组合关系\n\n![image-20200713094745366](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713094745366.png)\n\n两个收集器间有连线，表明它们可以搭配使用：\n\n- **Serial / Serial Old**（在单核场景下效果较好）\n- Serial / CMS （红色虚线，JDK 9废弃）\n- ParNew / Serial Old （红色虚线，JDK 9废弃）\n- ParNew / CMS\n- Parallel Scavenge / Serial Old （绿色虚线，JDK 14废弃）\n- **Parallel Scavenge / Parallel Old**（并行GC组合，JDK 8默认的GC组合）\n- **G1**（JDK 9以后默认的GC）\n\n解释，只有上面粗体的组合在以后的版本仍然使用，其他组合都已被废弃：\n\n- 其中Serial Old作为CMS出现\"Concurrent Mode Failure\"失败的后备预案。\n- ParNew GC 和 Parallel Scavenge / Parallel Old虽然都是并行的GC，但是二者的设计架构完全不同，后者的性能更好，更推荐使用。\n- （红色虚线）由于维护和兼容性测试的成本，在**JDK 8**时将Serial+CMS、ParNew+Serial Old这两个组合声明为**废弃**（JEP173），并在**JDK 9中完全取消**了这些组合的支持（JEP214），即：**移除**。\n- （绿色虚线）JDK 14中：弃用Parallel Scavenge和Serial Old GC组合（JEP366）\n- （青色虚线）JDK 14中：**删除CMS垃圾回收器**（JEP363）\n\n垃圾回收器中的并发和并行的区别：\n\n- 并行更在意**吞吐量**，要求吞吐量必须要高，可以接受⼀定的STW延迟时间\n- 并发更在意**低延迟**，要求STW要小⼀些，用户交互性要更好，并发地执行用户线程和GC线程\n\n为什么要有很多收集器，一个不够吗？因为Java的使用场景很多，移动端，服务器等。所以就需要针对不同的场景，提供不同的垃圾收集器，提高垃圾收集的性能。\n\n虽然我们会对各个收集器进行比较，但并非为了挑选一个最好的收集器出来。没有一种放之四海皆准、任何场景下都适用的完美收集器存在，更加没有万能的收集器。所以我们选择的只是对具体应用最合适的收集器。\n\n> 除了CMS外，其他老年代的GC都不会单独回收老年代，而是**先回收年轻代，如果回收后空间还不足，再回收老年代**\n\n### 如何查看默认垃圾收集器\n\n- `-XX:+PrintcommandLineFlags`：查看命令行相关参数（包含使用的垃圾收集器）\n- 使用命令行指令：`jinfo -flag  相关垃圾回收器参数  进程ID`\n\nJDK 8 中默认使用 ParallelGC 和 ParallelOldGC 的组合，JDK 9 中默认使用 G1\n\n## Serial 回收器：串行回收\n\nSerial GC是最基本、历史最悠久的垃圾收集器了。JDK1.3之前回收新生代唯一的选择。\n\n- Serial 作为HotSpot中**Client模式**下的默认**新生代**垃圾收集器。\n- Serial 采用**复制算法**、**串行回收**和\"**Stop-The-World**\"机制的方式执行内存回收。\n\n除了年轻代之外，Serial GC还提供用于执行老年代垃圾收集的Serial Old。Serial Old同样也采用了串行回收和\"Stop The World\"机制，只不过内存回收算法使用的是**标记-压缩**算法。\n\n- Serial Old是运行在**Client模式**下默认的**老年代**的垃圾回收器\n- Serial Old在Server模式下主要有两个用途：\n  - 与新生代的Parallel Scavenge配合使用（后被废弃）\n  - 作为老年代CMS收集器的后备垃圾收集方案（CMS后被废弃）\n\n![image-20200713100703799](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713100703799.png)\n\n这个收集器是一个单线程的收集器，但它的“单线程”的意义并不仅仅说明它只会使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在它进行垃圾收集时，**必须暂停其他所有的工作线程**，直到它收集结束（Stop The World）\n\n### Serial 回收器的优势\n\n- **简单而高效**（与其他收集器的单线程比），对于限定单个CPU的环境来说，Serial收集器由于**没有线程交互的开销**，专心做垃圾收集自然可以获得最高的单线程收集效率。运行在Client模式下的虚拟机是个不错的选择。\n- 在用户的桌面应用场景中，可用内存一般不大（几十MB至一两百MB），可以在较短时间内完成垃圾收集（几十ms至一百多ms），只要不频繁发生，使用串行回收器是可以接受的。\n\n在HotSpot虚拟机中，使用`-XX:+UseSerialGC`参数可以指定年轻代和老年代都使用串行收集器。等价于新生代用Serial GC，且老年代用Serial Old GC\n\n### 总结\n\nSerial 回收器现在应用较少，只适合在单核cpu或嵌入式系统等硬件条件一般的场景下使用。Server端一般不会使用 Serial 回收器。\n\n对于**交互较强**的应用而言，这种垃圾收集器是不能接受的。**一般在Java Web应用程序中是不会采用串行垃圾收集器的。**\n\n## ParNew 回收器：并行回收\n\n如果说Serial GC是年轻代中的单线程垃圾收集器，那么**ParNew收集器则是Serial收集器的多线程版本**。Par是Parallel的缩写，**New：只能处理的是新生代**\n\n**ParNew 收集器除了采用并行回收的方式执行内存回收外，两款垃圾收集器之间几乎没有任何区别**。ParNew收集器在年轻代中同样也是采用**复制算法**、\"Stop-The-World\"机制。\n\nParNew 是很多JVM运行在Server模式下新生代的默认垃圾收集器。\n\n![image-20200713102030127](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713102030127.png)\n\n- 对于新生代，回收次数频繁，使用并行方式高效。\n- 对于老年代，回收次数少，使用串行方式节省资源。（CPU并行需要切换线程，串行可以省去切换线程的资源）\n\n### ParNew 回收器与 Serial 回收器比较\n\n>  Q：由于ParNew收集器基于并行回收，那么是否可以断定ParNew收集器的回收效率在任何场景下都会比Serial收集器更高效？\n> A：**不能**\n\n- ParNew收集器运行在多CPU的环境下，由于可以充分利用多CPU、多核心等物理硬件资源优势，可以更快速地完成垃圾收集，提升程序的吞吐量。\n- 但是**在单个CPU的环境下，ParNew收集器不比Serial收集器更高效**。虽然Serial收集器是基于串行回收，但是由于CPU不需要频繁地做任务切换，因此可以有效避免多线程交互过程中产生的一些额外开销。\n- 除Serial外，目前只有ParNew GC能与CMS收集器配合工作\n\n**设置 ParNew 垃圾回收器**\n\n1. 在程序中，开发人员可以通过选项`-XX:+UseParNewGC`手动指定使用ParNew收集器执行内存回收任务。它表示年轻代使用并行收集器，不影响老年代。\n2. `-XX:ParallelGCThreads`：限制线程数量，默认开启**和CPU核心数相同**的线程数。\n\n## Parallel 回收器：吞吐量优先\n\n> Parallel Scavenge 和 Parallel Old 回收器的设计架构和 ParNew 并不相同，性能较前者更好。\n\nHotSpot的年轻代中除了拥有ParNew收集器是基于并行回收的以外，**Parallel Scavenge收集器同样也采用了复制算法、并行回收和\"Stop The World\"机制**。\n\n那么Parallel 收集器的出现是否多此一举？\n\n- 和ParNew收集器不同，Parallel Scavenge收集器的目标则是达到一个**可控制的吞吐量（Throughput）**，它也被称为**吞吐量优先**的垃圾收集器。\n- **自适应调节策略**也是Parallel Scavenge与ParNew一个重要区别。\n\n高吞吐量则可以高效率地利用CPU时间，尽快完成程序的运算任务，主要适合在**后台运算而不需要太多交互的任务**。因此，**常见在服务器环境中使用**。例如，那些执行**批量处理、订单处理、工资支付、科学计算**的应用程序。\n\nParallel收集器在JDK1.6时提供了用于执行老年代垃圾收集的Parallel Old收集器，用来代替老年代的Serial Old收集器。\n\nParallel Old收集器采用了**标记-压缩**算法，但同样也是基于并行回收和\"stop-the-World\"机制。\n\n![image-20200713110359441](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713110359441.png)\n\n程序吞吐量优先的应用场景中，Parallel Scanvenge收集器和Parallel Old收集器的组合，在server模式下的内存回收性能很不错。\n\n**在JDK 8中，默认是Parallel Scanvenge + Parallel Old 组合**。\n\n### Parallel Scavenge 回收器参数设置\n\n- `-XX:+UseParallelGC` ：手动指定年轻代使用Parallel并行收集器执行内存回收任务。\n- `-XX:+UseParallelOldGC`：手动指定老年代都是使用并行回收收集器。\n  - 分别适用于新生代和老年代\n  - 上面两个参数分别适用于新生代和老年代。默认jdk8是开启的。默认开启一个，另一个也会被开启。（互相激活）\n- `-XX:ParallelGCThreads`：设置年轻代并行收集器的线程数。一般地，最好与CPU数量相等，以避免过多的线程数影响垃圾收集性能。\n  - 在默认情况下，当CPU数量小于8个，ParallelGCThreads的值等于CPU数量。\n  - 当CPU数量大于8个，ParallelGCThreads的值等于3+[5*CPU_Count]/8]\n- `-XX:MaxGCPauseMillis`：设置垃圾收集器**最大停顿时间**（即STW的时间）。单位是毫秒。\n  - 为了尽可能地把停顿时间控制在`-XX:MaxGCPauseMillis `以内，收集器在工作时**会调整Java堆大小或者其他一些参数**。\n  - 对于用户来讲，停顿时间越短体验越好。但是在服务器端，我们注重高并发，整体的吞吐量。所以服务器端适合Parallel，进行控制。\n  - 该参数使用需谨慎。\n- `-XX:GCTimeRatio`：垃圾收集时间占总时间的比例，即等于 1 / (N+1) ，用于衡量吞吐量的大小。\n  - 取值范围(0, 100)。默认值99，也就是垃圾回收时间占比不超过1。\n  - 与前一个`-XX:MaxGCPauseMillis`参数**有一定矛盾性**，STW暂停时间越长，Radio参数就容易超过设定的比例。\n- `-XX:+UseAdaptiveSizePolicy`：设置Parallel Scavenge收集器具有**自适应调节策略**\n  - 在这种模式下，年轻代的大小、Eden和Survivor的比例、晋升老年代的对象年龄等参数**会被自动调整**，已达到在堆大小、吞吐量和停顿时间之间的平衡点。\n  - 在手动调优比较困难的场合，可以直接使用这种自适应的方式，仅指定虚拟机的最大堆、目标的吞吐量（GCTimeRatio）和停顿时间（MaxGCPauseMillis），让虚拟机自己完成调优工作。\n\n\n\n## CMS 回收器：低延迟\n\n### CMS 介绍\n\n> CMS（**Concurrent-Mark-Sweep**）：**并发标记清除**回收器，唯一一个用清除算法的回收器\n\n在JDK1.5时期，Hotspot推出了一款在**强交互应用**中几乎可认为有划时代意义的垃圾收集器：CMS（**Concurrent-Mark-Sweep**）收集器，这款收集器是HotSpot虚拟机中第一款真正意义上的**并发**收集器，**它第一次实现了让垃圾收集线程与用户线程同时工作**。\n\nCMS收集器的关注点是**尽可能缩短垃圾收集时用户线程的停顿时间**。停顿时间越短（低延迟）就越适合与用户交互的程序，良好的响应速度能提升用户体验。\n\n目前很大一部分的Java应用集中在互联网站或者B/S系统的服务端上，这类应用尤其重视服务的响应速度，希望系统停顿时间最短，以给用户带来较好的体验。CMS收集器就非常符合这类应用的需求。\n\nCMS的垃圾收集算法采用**标记-清除**算法（**唯一一个使用清除算法的GC**），并且也会\"Stop-The-World\"\n\n不幸的是，CMS作为老年代的收集器，却无法与JDK1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作，所以在JDK1.5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者Serial收集器中的一个。\n\n在G1出现之前，CMS使用还是非常广泛的。一直到今天，仍然有很多系统使用CMS GC。\n\n![image-20200713205154007](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713205154007.png)\n\n### CMS 工作流程\n\nCMS整个过程比之前的收集器要复杂，整个过程分为4个主要阶段，即**初始标记阶段**、**并发标记阶段**、**重新标记阶段**和**并发清除阶段**。(涉及STW的阶段主要是：初始标记和重新标记)\n\n- **初始标记**（Initial-Mark）阶段：在这个阶段中，程序中所有的工作线程都将会因为“Stop-The-World”机制而出现短暂的暂停，这个阶段的主要任务仅仅只是**标记出GCRoots能直接关联到的对象**。一旦标记完成之后就会恢复之前被暂停的所有应用线程。**由于直接关联对象比较小，所以这里的速度非常快。**\n- **并发标记**（Concurrent-Mark）阶段：从GC Roots的直接关联对象开始遍历整个对象图的过程，**这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行**。\n- **重新标记**（Remark）阶段：由于在并发标记阶段中，程序的工作线程会和垃圾收集线程同时运行或者交叉运行，因此为了**修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录**，这个阶段的停顿时间通常会比初始标记阶段稍长一些，并且也会导致“Stop-The-World”的发生，但也远比并发标记阶段的时间短。但是无法删除浮动垃圾（一开始不是垃圾，但是后面变成了垃圾的对象被称为浮动垃圾）\n- **并发清除**（Concurrent-Sweep）阶段：此阶段清理删除掉标记阶段判断的已经死亡的对象，释放内存空间。**由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的**\n\n> 重新标记阶段的意义是：可能有些对象在第⼀次标记时被发现没有被引用，但是在第二次标记时，可能恰好别的线程对这个对象进行了引用，因此需要再次判断一下有没有哪个第一次认为是垃圾的对象又有了引用。这些对象是绝对不能错删的！\n>\n> 而浮动垃圾是指，并发标记和清除阶段产生的新垃圾。即第一次还不是垃圾，但是第二次这个对象就不再有引用了，然而还是没清除，因为第一次标记时发现他在引用链里，所以第二次就直接没去判断他还是不是垃圾。\n>\n> 但是前一种引用，一开始是垃圾，后来不是垃圾的，必须要在判断清楚，以免删错对象。这个思想就是，可以容忍一些还存活的垃圾，但绝对不能误删正常对象\n\n尽管CMS收集器采用的是并发回收（非独占式），但是在其初始化标记和再次标记这两个阶段中仍然需要执行“Stop-The-World”机制暂停程序中的工作线程，不过暂停时间并不会太长，因此可以说明目前所有的垃圾收集器都做不到完全不需要“Stop-The-World”，只是尽可能地缩短暂停时间。\n\n**由于最耗费时间的并发标记与并发清除阶段都不需要暂停工作，所以整体的回收是低停顿的**。\n\n另外，由于在垃圾收集阶段用户线程没有中断，所以在CMS回收过程中，还应该确保应用程序用户线程有足够的内存可用。因此，CMS收集器不能像其他收集器那样等到老年代几乎完全被填满了再进行收集，而是**当堆内存使用率达到某一阈值时，便开始进行回收**，以确保应用程序在CMS工作过程中依然有足够的空间支持应用程序运行。要是CMS运行期间预留的内存无法满足程序需要，就会出现一次“**Concurrent Mode Failure**”失败，这时虚拟机将启动**后备预案**：**临时启用Serial Old收集器**来重新进行老年代的垃圾收集，这样停顿时间就很长了。\n\nCMS收集器的垃圾收集算法采用的是**标记清除算法**，这意味着每次执行完内存回收后，由于被执行内存回收的无用对象所占用的内存空间极有可能是不连续的一些内存块，不可避免地将会产生一些内存碎片。那么CMS在为新对象分配内存空间时，将无法使用指针碰撞（Bump the Pointer）技术，而只能够选择空闲列表（Free List）执行内存分配。\n\n![image-20200713212230352](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713212230352.png)\n\n> G1 和 CMS 里并发标记阶段所设计到的重新标记环节详解：https://segmentfault.com/a/1190000021820577 与 https://segmentfault.com/a/1190000021946606\n\n可以简单地理解并发标记阶段的重新标记原理：在并发标记阶段中，用户线程对某些引用进行了增加操作，那么JVM就会记录下来这些操作，待并发标记阶段结束，再根据这些操作重新判断一次引用关系是否变化了。\n\n### CMS 为什么不使用标记整理算法？\n\n答案其实很简答，因为当并发清除的时候，用Compact整理内存的话，原来的用户线程使用的内存还怎么用呢？要保证用户线程能继续执行，前提的它运行的资源不受影响嘛。Mark Compact更适合“Stop The World”这种场景下使用\n\n### CMS 的优点与弊端\n\n**优点**\n\n- 并发收集\n- **低延迟**\n\n**弊端**\n\n- **会产生内存碎片**，导致并发清除后，用户线程可用的空间不足。在无法分配大对象的情况下，不得\n- 不提前触发Full GC。\n- **CMS收集器对CPU资源非常敏感**。在并发阶段，它虽然不会导致用户停顿，但是会因为占用了一部分线程而导致应用程序变慢，总吞吐量会降低。\n- **CMS收集器无法处理浮动垃圾**。可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。在并发标记阶段由于程序的工作线程和垃圾收集线程是同时运行或者交叉运行的，**那么在并发标记阶段如果产生新的垃圾对象，CMS将无法对这些垃圾对象进行标记，最终会导致这些新产生的垃圾对象没有被及时回收，**从而只能在下一次执行GC时释放这些之前未被回收的内存空间。\n\nCms 最大的缺点：会产生内存碎片化，这样在业务高峰期时，如果瞬间来了大量数据，内存碎片化可能导致放不下这些对象，从而会出现 \"Concurrent Mode Failure\"，然后使用 Serial Old 进行串行回收， 这样的效率会很低，在高峰期时难以承受。\n\n### CMS 参数配置\n\n- `-XX:+UseConcMarkSweepGC`：手动指定使用CMS收集器执行内存回收任务。\n\n  开启该参数后会自动将`-XX:+UseParNewGC`打开。即：ParNew（Young区）+CMS（Old区）+Serial Old（Old区备选方案）的组合。\n\n- `-XX:CMSInitiatingOccupanyFraction`：设置堆内存使用率的**阈值**，一旦达到该阈值，便开始进行回收。\n  - JDK5及以前版本的默认值为68，即当老年代的空间使用率达到68%时，会执行一次CMS回收。JDK6及以上版本默认值为92%\n  - 如果内存增长缓慢，则可以设置一个稍大的值，大的阀值可以有效降低CMS的触发频率，减少老年代回收的次数可以较为明显地改善应用程序性能。反之，如果应用程序内存使用率增长很快，则应该降低这个阈值，以避免频繁触发老年代串行收集器。因此通过该选项便可以有效降低Full GC的执行次数。\n- `-XX:+UseCMSCompactAtFullCollection`：用于指定在执行完Full GC后对内存空间**进行压缩整理**，以此避免内存碎片的产生。不过由于内存压缩整理过程无法并发执行，所带来的问题就是停顿时间变得更长了。\n- `-XX:CMSFullGCsBeforeCompaction`：设置在执行多少次Full GC后对内存空间进行压缩整理。\n- `-XX:ParallelCMSThreads`：设置CMS的线程数量。\n  \n  - CMS默认启动的线程数是 (ParallelGCThreads + 3) / 4，ParallelGCThreads是年轻代并行收集器的线程数，可以当做是 CPU 最大支持的线程数。当CPU资源比较紧张时，受到CMS收集器线程的影响，应用程序的性能在垃圾回收阶段可能会非常糟糕。\n\n### 小结\n\nHotSpot有这么多的垃圾回收器，那么如果有人问，Serial GC、Parallel GC、Concurrent Mark Sweep GC这三个GC有什么不同呢？\n\n- 如果你想要**最小化地使用内存和并行开销**，请选Serial GC；\n- 如果你想要**最大化应用程序的吞吐量**，请选Parallel GC；\n- 如果你想要**最小化GC的中断或停顿时间**，请选CMS GC。\n\n### JDK 后续版本中 CMS 的变化\n\n- **JDK 9 新特性**：CMS被标记为**Deprecate**了（JEP291）如果对JDK 及以上版本的HotSpot虚拟机使用参数`-XX:+UseConcMarkSweepGC`来开启CMS收集器的话，用户会收到一个警告信息，提示CMS未来将会被废弃。\n- **JDK 14新特性**：**删除**CMS垃圾回收器（JEP363），如果在JDK14中使用`-XX:+UseConcMarkSweepGC`的话，JVM不会报错，只是给出一个warning信息，但是不会exit。JVM会自动回退以默认GC方式启动JVM\n\n## G1 回收器：区域化分代式\n\n既然我们已经有了前面几个强大的GC，为什么还要发布Garbage First（G1）？\n\n原因就在于应用程序所应对的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序正常进行，而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。G1（Garbage-First）垃圾回收器是在Java7 update4之后引入的一个新的垃圾回收器，是当今收集器技术发展的最前沿成果之一。\n\n与此同时，为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。\n\n官方给G1设定的目标是**在延迟可控的情况下获得尽可能高的吞吐量**，所以才担当起“全功能收集器”的重任与期望。\n\n### 为什么名字叫 Garbage First (G1) 呢？\n\n> 优先回收垃圾占比较大的 Region\n\n因为G1是一个并行回收器，它把堆内存分割为很多不相关的区域（Region）（物理上不连续的）。使用不同的Region来表示Eden、幸存者0区，幸存者1区，老年代等。\n\nG1 GC有计划地避免在整个Java堆中进行全区域的垃圾收集。G1跟踪各个Region里面的垃圾堆积的价值大小（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个**优先列表**，**每次根据允许的收集时间，优先回收价值最大的Region**。由于这种方式的侧重点在于回收**垃圾最大量的区域**（Region），所以我们给G1一个名字：**垃圾优先**（Garbage First）。\n\nG1（Garbage-First）是一款**面向服务端应用**的垃圾收集器，主要针对配备多核CPU及大容量内存的机器，**以极高概率满足GC停顿时间的同时，还兼具高吞吐量的性能特征**。\n\n在JDK 7版本正式启用，移除了Experimental的标识，是JDK 9以后的默认垃圾回收器，取代了CMS回收器以及Parallel Scanvenge + Parallel Old组合。被oracle官方称为“全功能的垃圾收集器”。\n\n与此同时，CMS已经在JDK 9中被标记为废弃（deprecated）。在JDK 8中还不是默认的垃圾回收器，需要使用`-xx:+UseG1GC`来启用。\n\n### G1 垃圾收集器的优点\n\n与其他GC收集器相比，G1使用了全新的分区算法，其特点如下所示：\n\n**1、并行与并发**\n\n- 并行性：G1在回收期间，可以有多个GC线程同时工作，有效利用多核计算能力。此时用户线程STW\n- 并发性：G1拥有与应用程序交替执行的能力，部分工作可以和应用程序同时执行，因此，一般来说，不会在整个回收阶段发生完全阻塞应用程序的情况\n\n**2、分代收集**\n\n- 从分代上看，G1依然属于分代型垃圾回收器，它会区分年轻代和老年代，年轻代依然有Eden区和Survivor区。但从堆的结构上看，它不要求整个Eden区、年轻代或者老年代都是连续的，也不再坚持固定大小和固定数量。\n- 将堆空间分为若干个区域（Region），这些区域中包含了逻辑上的年轻代和老年代。\n- 和之前的各类回收器不同，它同时兼顾年轻代和老年代。对比其他回收器，或者工作在年轻代，或者工作在老年代；\n\nG1所谓的分代，已经不是下面这样的了\n\n![image-20200713215105293](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713215105293.png)\n\n而是这样的一个区域：\n\n![image-20200713215133839](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713215133839.png)\n\n**3、空间整合**\n\n- CMS：“标记-清除”算法、内存碎片、若干次GC后进行一次碎片整理\n- G1将内存划分为一个个的Region。内存的回收是以Region作为基本单位的。**Region之间是复制算法**，但**整体上实际可看作是标记-压缩（Mark-Compact）算法**，两种算法都可以避免内存碎片。这种特性有利于程序长时间运行，分配大对象时不会因为无法找到连续内存空间而提前触发下一次GC。尤其是当Java堆非常大的时候，G1的优势更加明显。\n\n**4、可预测的停顿时间模型（即：软实时soft real-time）**\n\n这是G1相对于CMS的另一大优势，G1除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。\n\n- 由于分区的原因，G1可以**只选取部分区域进行内存回收**，这样缩小了回收的范围，因此对于全局停顿情况的发生也能得到较好的控制。\n- G1跟踪各个Region里面的垃圾堆积的**价值大小**（回收所获得的空间大小以及回收所需时间的经验值），在后台维护一个**优先列表**，每次根据允许的收集时间，**优先回收价值最大的Region**。保证了G1收集器在有限的时间内可以获取尽可能高的收集效率。\n- 相比于CMS，G1未必能做到CMS在最好情况下的延时停顿，但是最差情况要好很多。\n\n### G1 垃圾收集器的缺点\n\n相较于CMS，G1还不具备全方位、压倒性优势。比如在用户程序运行过程中，G1无论是为了垃圾收集产生的内存占用（Footprint）还是程序运行时的额外执行负载（overload）都要比CMS要高。\n\n从经验上来说，**在小内存应用上CMS的表现大概率会优于G1，而G1在大内存应用上则发挥其优势。平衡点在6-8GB之间**。\n\n### G1 参数设置\n\n- `-XX:+UseG1GC`：手动指定使用G1垃圾收集器执行内存回收任务\n- `-XX:G1HeapRegionSize`：设置每个Region的大小。值是2的幂，范围是1MB到32MB之间，目标是根据最小的Java堆大小划分出约2048个区域。默认是堆内存的1/2000。\n- `-XX:MaxGCPauseMillis`：设置期望达到的最大GC停顿时间指标，JVM会尽力实现，但不保证达到。默认值是200ms\n- `-XX:+ParallelGCThread`：设置STW工作线程数的值。最多设置为8\n- `-XX:ConcGCThreads`：设置并发标记的线程数。将n设置为并行垃圾回收线程数（ParallelGcThreads）的1/4左右。\n- `-XX:InitiatingHeapOccupancyPercent`：设置触发并发GC周期的Java堆占用率阈值。超过此值，就触发GC。默认值是45。\n\n### G1 收集器的常见操作步骤\n\nG1的设计原则就是简化JVM性能调优，开发人员只需要简单的三步即可完成调优：\n\n- 第一步：开启G1垃圾收集器\n- 第二步：设置堆的最大内存\n- 第三步：设置最大的停顿时间\n\nG1中提供了三种垃圾回收模式：Young GC、Mixed GC和Full GC，在不同的条件下被触发。\n\n### G1 收集器的适用场景\n\n面向**服务端**应用，针对具有**大内存**、**多处理器**的机器。（在普通大小的堆里表现并不惊喜）。最主要的应用是**需要低GC延迟**，并具有大堆的应用程序提供解决方案；\n\n如：在堆大小约6GB或更大时，可预测的暂停时间可以低于0.5秒；（G1通过每次只清理一部分而不是全部的Region的增量式清理来保证每次Gc停顿时间不会过长）。\n\nG1用来替换掉JDK1.5中的CMS收集器；在下面的情况时，使用G1可能比CMS好：\n\n- 超过50%的Java堆被活动数据占用；\n- 对象分配频率或年代提升频率变化很大；\n- GC停顿时间过长（长于0.5至1秒）\n\nHotSpot垃圾收集器里，除了G1以外，其他的垃圾收集器使用内置的JVM线程执行GC的多线程操作，而G1可以采用应用线程承担后台运行的GC工作，即当JVM的GC线程处理速度慢时，系统会调用应用程序线程帮助加速垃圾回收过程。\n\n### 分区 Region：化整为零\n\n使用G1收集器时，它将整个Java堆划分成约2048个大小相同的独立Region块，每个Region块大小根据堆空间的实际大小而定，整体被控制在1MB到32MB之间，且为2的N次幂，即1MB，2MB，4MB，8MB，16MB，32MB。可以通过`-XX:G1HeapRegionsize`设定。**所有的Region大小相同，且在JVM生命周期内不会被改变**。\n\n虽然还保留有新生代和老年代的概念，但新生代和老年代不再是物理隔离的了，它们都是一部分Region（不需要连续）的集合。通过Region的动态分配方式实现逻辑上的连续。\n\n![image-20200713223244886](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713223244886.png)\n\n一个Region有可能属于Eden，Survivor或者Old/Tenured内存区域。但是一个Region只可能属于一个角色。图中的E表示该Region属于Eden内存区域，S表示属于Survivor内存区域，O表示属于Old内存区域。图中空白的表示未使用的内存空间。\n\nG1垃圾收集器还增加了一种新的内存区域，叫做**Humongous**内存区域，如图中的H块。**主要用于存储大对象，如果超过0.5个Region，就放到H**。\n\n**设置H的原因：**对于堆中的大对象，默认直接会被分配到老年代，但是如果它是一个**短期存在的大对象**就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放大对象。**如果一个H区装不下一个大对象，那么G1会寻找连续的H区来存储**。为了能找到连续的H区，有时候不得不启动Full GC。G1的大多数行为都把H区作为老年代的一部分来看待。\n\n**Region 的细节**\n\n- 每个Region内部都是通过**指针碰撞**来分配空间\n- G1为每一个Region设计了两个名为TAMS（Top at Mark Start）的指针，把Region中的一部分空间划分出来**用于并发回收过程中的新对象分配**，并发回收时新分配的对象地址都必须要在这两个指针位置以上。\n- TLAB还是用来保证并发性\n\n![image-20200713223509993](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713223509993.png)\n\n### G1 垃圾回收器的回收过程\n\nG1 的垃圾回收过程主要包括如下三个环节：\n\n- **年轻代GC**（Young GC）\n- **老年代并发标记过程**（Concurrent Marking）\n- **混合回收**（Mixed GC）\n\n（如果需要，单线程、独占式、高强度的Full GC还是继续存在的。它针对GC的评估失败提供了一种失败保护机制，即强力回收。）\n\n![image-20200713224113996](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713224113996.png)\n\n顺时针，Young GC -> Young GC + Concurrent Mark -> Mixed GC顺序，进行垃圾回收。\n\n**回收流程**\n\n- 应用程序分配内存，当年轻代的Eden区用尽时开始年轻代回收过程；G1的年轻代收集阶段是一个**并行的独占式**收集器。在年轻代回收期，G1 GC暂停所有应用程序线程，启动多线程执行年轻代回收。然后从年轻代区间移动存活对象到Survivor区间或者老年区间，也有可能是两个区间都会涉及。\n- 当堆内存使用达到一定值（默认45%）时，开始**老年代并发标记过程**。\n- **标记完成马上开始混合回收过程**。对于一个混合回收期，G1 GC从老年区间移动存活对象到空闲区间，这些空闲区间也就成为了老年代的一部分。和年轻代不同，老年代的G1回收器和其他GC不同，**G1的老年代回收器不需要整个老年代被回收，一次只需要扫描/回收一小部分老年代的Region就可以了**。同时，这个老年代Region是和年轻代一起被回收的。\n- 举个例子：一个Web服务器，Java进程最大堆内存为4G，每分钟响应1500个请求，每45秒钟会新分配大约2G的内存。G1会每45秒钟进行一次年轻代回收，每31个小时整个堆的使用率会达到45%，会**开始老年代并发标记过程，标记完成后开始四到五次的混合回收**。\n\n### Remembered Set（记忆集）\n\n一个对象被不同区域引用的问题。一个Region不可能是孤立的，一个Region中的对象可能被其他任意Region中对象引用，判断对象存活时，是否需要扫描整个Java堆才能保证准确？\n\n在其他的分代收集器，也存在这样的问题（而G1更突出）回收新生代也不得不同时扫描老年代？这样的话会降低MinorGC的效率；\n\n**解决方法**：无论G1还是其他分代收集器，JVM都是使用Remembered Set来避免全局扫描：\n\n每个Region都有一个对应的Remembered Set；每次Reference类型数据写操作时，都会产生一个Write Barrier暂时中断操作；\n\n然后检查将要写入的引用指向的对象是否和该Reference类型数据在不同的Region（其他收集器：检查老年代对象是否引用了新生代对象）；如果不同，通过卡表 CardTable把相关引用信息记录到引用指向对象的所在Region对应的Remembered Set中；当进行垃圾收集时，在GC根节点的枚举范围加入Remembered Set；就可以保证不进行全局扫描，也不会有遗漏。\n\n![image-20200713224716715](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713224716715.png)\n\n在回收 Region 时，为了不进行全堆的扫描，引入了 Remembered Set。Remembered Set 记录了当前 Region 中的对象被哪个对象引用了。\n\n- 这样在进行 Region 复制时，就不要扫描整个堆，只需要去 Remembered Set 里面找到引用了当前 Region 的对象。\n- Region 复制完毕后，修改 Remembered Set 中对象的引用即可。\n\n### G1 回收过程一：年轻代GC\n\nJVM启动时，G1先准备好Eden区，程序在运行过程中不断创建对象到Eden区，当Eden空间耗尽时，G1会启动一次年轻代垃圾回收过程。\n\nYGC时，首先G1停止应用程序的执行（Stop-The-Wor1d），G1创建回收集（Collection Set），回收集是指需要被回收的内存分段的集合，年轻代回收过程的回收集包含年轻代Eden区和Survivor区所有的内存分段。\n\n![image-20200713225100632](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713225100632.png)\n\n图的大致意思就是：\n\n- 回收完E和S区，剩余存活的对象会复制到新的S区\n- S区达到一定的阈值可以晋升为O区\n\n详细回收过程：\n\n- **第一阶段，扫描根 GC Roots**\n\n根是指static变量指向的对象，正在执行的方法调用链条上的局部变量等。根引用连同RSet记录的外部引用作为扫描存活对象的入口。\n\n- **第二阶段，更新RSet**\n\n处理dirty card queue（见备注）中的card，更新RSet。此阶段完成后，RSet可以准确的反映老年代对所在的内存分段中对象的引用。\n\n- **第三阶段，处理RSet**\n\n识别被老年代对象指向的Eden中的对象，这些被指向的Eden中的对象被认为是存活的对象。\n\n- **第阶段，复制对象**\n\n此阶段，对象树被遍历，Eden区内存段中存活的对象会被复制到Survivor区中空的内存分段，Survivor区内存段中存活的对象如果年龄未达阈值，年龄会加1，达到阀值会被会被复制到Old区中空的内存分段。如果Survivor空间不够，Eden空间的部分数据会直接晋升到老年代空间。\n\n- **第五阶段，处理引用**\n\n处理Soft，Weak，Phantom，Final，JNI Weak 等引用。最终Eden空间的数据为空，GC停止工作，而目标内存中的对象都是连续存储的，没有碎片，**所以复制过程可以达到内存整理的效果，减少碎片**。\n\n> **备注：**\n>\n> 1. 对于应用程序的引用赋值语句 oldObject.field（这个是老年代）=object（这个是新生代），JVM会在之前和之后执行特殊的操作以在dirty card queue中入队一个保存了对象引用信息的card。在年轻代回收的时候，G1会对Dirty Card Queue中所有的card进行处理，以更新RSet，保证RSet实时准确的反映引用关系。\n> 2. 那为什么不在引用赋值语句处直接更新RSet呢？这是为了性能的需要，RSet的处理需要线程同步，开销会很大，使用队列性能会好很多。\n\n### G1 回收过程二：并发标记过程\n\n- **初始标记阶段**（STW）：标记从根节点**直接可达**的对象。这个阶段是STW的，并且**会触发一次年轻代GC**。\n- **根区域扫描**（Root Region Scanning）：G1 GC扫描Survivor区直接可达的老年代区域对象，并标记被引用的对象。这一过程必须在Young GC之前完成。\n- **并发标记**（Concurrent Marking）：在整个堆中进行并发标记（和应用程序并发执行），此过程可能被Young GC中断。在并发标记阶段，**若发现区域对象中的所有对象都是垃圾，那这个区域会被立即回收**。同时，并发标记过程中，会计算每个区域的**对象活性**（区域中存活对象的比例）。\n- **再次标记**（Remark）：该过程同CMS类似，由于应用程序持续进行，需要修正上一次的标记结果，是STW的。G1中采用了比CMS更快的[初始快照算法SATB](https://segmentfault.com/a/1190000021946606)：Snapshot-At-The-Beginning（SATB）。\n- **独占清理**（Cleanup，STW）：计算各个区域的存活对象和GC回收比例，并进行排序，识别可以混合回收的区域**。为下阶段——混合回收做铺垫**。是STW的。**这个阶段并不会实际上去做垃圾的收集**\n- **并发清理阶段**：识别并清理**完全为垃圾**的区域（并发标记阶段只清除全部为垃圾的Region）。\n\n并发标记过程的主要目的是为了并发标记垃圾对象，本身不是为了清理垃圾，只是为了给下一阶段——混合回收做准备：**并发标记完成后开始四到五次的混合回收**\n\n### G1 回收过程三：混合回收\n\n> 混合回收时先回收年轻代，如果年轻代GC后空间足够，新来的数据就直接放到年轻代里，不再需要给老年代做GC了\n\n当越来越多的对象晋升到老年代Old Region时，为了避免堆内存被耗尽，虚拟机会触发一个混合的垃圾收集器，即Mixed GC，该算法并不是一个Old GC，除了回收整个Young Region，还会回收一部分的Old Region。这里需要注意：**是一部分老年代，而不是全部老年代**。可以选择哪些Old Region进行收集，从而可以对垃圾回收的耗时时间进行控制。**也要注意的是Mixed GC并不是Full GC**。\n\n![image-20200713225810871](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200713225810871.png)\n\n**混合回收的细节**\n\n- 并发标记结束以后，老年代中百分百为垃圾的内存分段被回收了，部分为垃圾的内存分段被计算了出来。默认情况下，**这些老年代的内存分段会分8次被回收**（可以通过`-XX:G1MixedGCCountTarget`设置）\n- 混合回收的回收集（Collection Set）**包括八分之一的老年代内存分段**，**Eden区内存分段**，**Survivor区内存分段**。**混合回收的算法和年轻代回收的算法完全一样，只是回收集多了老年代的内存分段**。具体过程请参考上面的年轻代回收过程。\n- 由于老年代中的内存分段默认分8次回收，**G1会优先回收垃圾多的内存分段**。垃圾占内存分段比例越高的，越会被先回收。并且有一个阈值会决定内存分段是否被回：`-XX:G1MixedGCLiveThresholdPercent`，默认为65%，意思是垃圾占内存分段比例要达到65%才会被回收。如果垃圾占比太低，意味着存活的对象占比高，在复制的时候会花费更多的时间。\n- 混合回收并不一定要进行8次。有一个阈值`-XX:G1HeapWastePercent`，默认值为10%，意思是允许整个堆内存中有10%的空间被浪费，意味着如果发现可以回收的垃圾占堆内存的比例低于10%，则不再进行混合回收。因为GC会花费很多的时间但是回收到的内存却很少。\n\n### G1 回收可选的过程四：Full GC\n\n> G1的目标就是尽可能避免Full GC，除非混合回收（里面涉及到Major GC）后堆空间内存仍然是不足的\n\nG1的初衷就是要避免Full GC的出现。但是如果上述方式不能正常工作，G1会停止应用程序的执行（Stop-The-World），使用**单线程**的内存回收算法进行垃圾回收，性能会非常差，应用程序停顿时间会很长。\n\n避免Full GC的发生，一旦发生Full GC，需要对JVM参数进行调整。什么时候会发生Full GC呢？比如堆内存太小，当G1在复制存活对象的时候没有空的内存分段可用，则会回退到Full GC，这种情况可以**通过增大内存解决**。\n\nFull GC 的时机：很少执行，只要在老年代也满了，或者因为并发存放数据的速度快于GC的速度，堆空间即将满了，才会 Full GC。\n\n导致G1 Full GC的原因可能有两个：\n\n- Evacuation的时候没有足够的to-space来存放晋升的对象；\n- **并发处理过程完成之前空间耗尽**。\n\n### G1 回收的优化建议\n\n从Oracle官方透露出来的信息可获知，回收阶段（Evacuation）其实本也有想过设计成与用户程序一起并发执行，但这件事情做起来比较复杂，考虑到G1只是回一部分Region，停顿时间是用户可控制的，所以并不迫切去实现，**而选择把这个特性放到了G1之后出现的低延迟垃圾收集器（即ZGC）中。**另外，还考虑到G1不是仅仅面向低延迟，停顿用户线程能够最大幅度提高垃圾收集效率，为了保证吞吐量所以才选择了完全暂停用户线程的实现方案。\n\n**G1 回收器的优化建议**\n\n- 年轻代大小避免使用`-Xmn`或`-XX:NewRatio`等相关选项显式设置年轻代大小，因为固定年轻代的大小**会覆盖可预测的暂停时间目标**。我们应该让G1自己去调整\n- **暂停时间目标不要太过严苛**\n  - G1 GC的吞吐量目标是**90%的应用程序时间和10%的垃圾回收时间**\n  - 评估G1 GC的吞吐量时，暂停时间目标不要太严苛。目标太过严苛表示你愿意承受更多的垃圾回收开销，而这些会直接影响到吞吐量。\n\n## 垃圾回收器总结\n\n截止 JDK 8，一共有7款不同的垃圾收集器。每一款的垃圾收集器都有不同的特点，在具体使用的时候，需要根据具体的情况选用不同的垃圾收集器。\n\n![image-20200714075738203](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714075738203.png)\n\nGC发展阶段：Serial => Parallel（并行）=> CMS（并发）=> G1 => ZGC\n\n不同厂商、不同版本的虚拟机实现差距比较大。HotSpot虚拟机在JDK7/8后所有收集器及组合如下图\n\n![image-20200714080151020](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714080151020.png)\n\n\n\n- 年轻代的GC都使用复制算法\n- CMS因为是并发回收所以只能用标记-清除算法\n- 其他的老年代的GC都使用标记-压缩算法\n\n### 怎么选择垃圾回收器\n\nJava垃圾收集器的配置对于JVM优化来说是一个很重要的选择，选择合适的垃圾收集器可以让JVM的性能有一个很大的提升。怎么选择垃圾收集器？\n\n- 优先调整堆的大小让JVM自适应完成。\n- 如果内存小于100M，使用串行收集器\n- 如果是**单核、单机程序**，并且没有停顿时间的要求，串行收集器\n- 如果是多CPU、需要**高吞吐量**、允许停顿时间超过1秒，选择并行或者JVM自己选择\n- 如果是多CPU、追求**低停顿时间**，需快速响应（比如延迟不能超过1秒，如互联网应用），使用并发收集器\n- **官方推荐G1，性能高**。现在互联网的项目，基本都是使用G1。\n\n最后需要明确一个观点：\n\n- 没有最好的收集器，更没有万能的收集\n- 调优永远是针对特定场景、特定需求，不存在一劳永逸的收集器\n\n### 面试\n\n对于垃圾收集，面试官可以循序渐进从理论、实践各种角度深入，也未必是要求面试者什么都懂。但如果你懂得原理，一定会成为面试中的加分项。这里较通用、基础性的部分如下：\n\n- 垃圾收集的算法有哪些？如何判断一个对象是否可以回收？\n- 垃圾收集器工作的基本流程\n- 另外，需要多关注垃圾回收器这一章的各种常用的参数\n\n## GC 日志分析\n\n**通过阅读GC日志，我们可以了解Java虚拟机内存分配与回收策略。**\n\n内存分配与垃圾回收的参数列表\n\n- `-XX:+PrintGC `：输出GC日志。类似：`-verbose:gc`\n- `-XX:+PrintGCDetails `：输出GC的详细日志\n- `-XX:+PrintGCTimestamps` ：输出GC的时间戳（以基准时间的形式）\n- `-XX:+PrintGCDatestamps` ：输出GC的时间戳（以日期的形式，如2013-05-04T21: 53: 59.234 +0800）\n- `-XX:+PrintHeapAtGC` ：在进行GC的前后打印出堆的信息\n- `-Xloggc:…/logs/gc.log` ：日志文件的输出路径\n\n> **verbose:gc**\n\n打开GC日志的 JVM 参数：\n\n```bash\n-verbose:gc\n```\n\n这个只会显示总的GC堆的变化，如下：\n\n![image-20200714081610474](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714081610474.png)\n\n参数解析：\n\n![image-20200714081622526](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714081622526.png)\n\n> **PrintGCDetails**\n\n打开GC日志\n\n```bash\n-XX:+PrintGCDetails\n```\n\n输入信息如下：\n\n![image-20200714081909309](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714081909309.png)\n\n参数解析：\n\n![image-20200714081925767](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714081925767.png)\n\n> **PrintGCTimestamps 和 PrintGCDatestamps**\n\n加上这两个参数后，打印的GC日志就会带上日期时间信息。\n\n### GC 日志补充说明\n\n- “[GC”和”[Full GC”说明了这次垃圾收集的停顿类型，如果有”Full”则说明GC发生了”Stop The World”\n- 使用Serial收集器在新生代的名字是Default New Generation，因此显示的是”[DefNew”\n- 使用ParNew收集器在新生代的名字会变成”[ParNew”，意思是”Parallel New Generation”\n- 使用Parallel scavenge收集器在新生代的名字是”[PSYoungGen”\n- 老年代的收集和新生代道理一样，名字也是收集器决定的\n- 使用G1收集器的话，会显示为”garbage-first heap”\n- Allocation Failure表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了。\n- [ PSYoungGen: 5986K->696K(8704K) ] 5986K->704K (9216K)\n  - 中括号内：GC回收前年轻代大小，回收后大小，（年轻代总大小）\n  - 括号外：GC回收前年轻代和老年代大小，回收后大小，（年轻代和老年代总大小）\n- user代表用户态回收耗时，sys内核态回收耗时，real实际耗时。由于多核线程切换的原因，时间总和可能会超过real时间\n\n### Young GC\n\n![image-20200714082555688](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714082555688.png)\n\n### Full GC\n\n![image-20200714082714690](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714082714690.png)\n\n### GC 日志结构剖析\n\n**透过日志看垃圾收集器**\n\n-  Serial收集器：新生代显示 \"[DefNew\"，即 Default New Generation \n- ParNew收集器：新生代显示 \"[ParNew\"，即 Parallel New Generation \n- Parallel Scavenge收集器：新生代显示\"[PSYoungGen\"，JDK1.7使用的即PSYoungGen \n- Parallel Old收集器：老年代显示\"[ParoldGen\" \n- G1收集器：显示”garbage-first heap“ \n\n\n\n**透过日志看 GC 原因**\n\n- Allocation Failure：表明本次引起GC的原因是因为新生代中没有足够的区域存放需要分配的数据\n- Metadata GCThreshold：Metaspace区不够用了\n- FErgonomics：JVM自适应调整导致的GC\n- System：调用了System.gc()方法\n\n**透过日志看 GC 前后情况**\n\n通过图示，我们可以发现GC日志格式的规律一般都是：GC前内存占用-＞GC后内存占用（该区域内存总大小）\n\n```java\n[PSYoungGen: 5986K->696K (8704K) ] 5986K->704K (9216K)\n```\n\n-  中括号内：GC回收前年轻代堆大小，回收后大小，（年轻代堆总大小） \n-  括号外：GC回收前年轻代和老年代大小，回收后大小，（年轻代和老年代总大小） \n\n**注意**：Minor GC堆内存总容量 = **9/10** 年轻代 + 老年代。原因是Survivor区只计算from部分，而JVM默认年轻代中Eden区和Survivor区的比例关系，Eden:S0:S1=8:1:1。\n\n> 面试题：为什么GC日志里显示的堆内存总容量比 `-Xms` 设置的要小？\n>\n> 因为GC日志里只显示了 **9/10** 年轻代 + 老年代，自然比设置的值要小。补充：这里的 9/10 要根据实际情况来定，可能开了自适应调整策略会导致该值变化\n\n\n\n**透过日志看 GC 时间**\n\nGC日志中有三个时间：user，sys和real\n\n- user：进程执行用户态代码（核心之外）所使用的时间。这是执行此进程所使用的实际CPU 时间，其他进程和此进程阻塞的时间并不包括在内。在垃圾收集的情况下，表示GC线程执行所使用的 CPU 总时间。\n- sys：进程在内核态消耗的 CPU 时间，即在内核执行系统调用或等待系统事件所使用的CPU 时间\n- real：程序从开始到结束所用的时钟时间。这个时间包括其他进程使用的时间片和进程阻塞的时间（比如等待 I/O 完成）。对于并行gc，这个数字应该接近（用户时间＋系统时间）除以垃圾收集器使用的线程数。\n\n由于多核的原因，一般的GC事件中，real time是小于sys time＋user time的，因为一般是多个线程并发的去做GC，所以real time是要小于sys＋user time的。如果real＞sys＋user的话，则你的应用可能存在下列问题：IO负载非常重或CPU不够用。\n\n\n\n### GC 回收举例\n\n我们编写一个程序，用来说明GC收集的过程\n\n```java\npublic class GCUseTest {\n    static final Integer _1MB = 1024 * 1024;\n    public static void main(String[] args) {\n        byte [] allocation1, allocation2, allocation3, allocation4;\n        allocation1 = new byte[2 *_1MB];\n        allocation2 = new byte[2 *_1MB];\n        allocation3 = new byte[2 *_1MB];\n        allocation4 = new byte[4 *_1MB];\n    }\n}\n```\n\n我们设置JVM启动参数\n\n```bash\n-Xms10m -Xmx10m -XX:+PrintGCDetails\n```\n\n首先我们会将3个2M的数组存放到Eden区，然后后面4M的数组来了后，将无法存储，因为Eden区只剩下2M的剩余空间了，那么将会进行一次Young GC操作，将原来Eden区的内容，存放到Survivor区，但是Survivor区也存放不下，那么就会直接晋级存入Old 区\n\n![image-20200714083332238](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714083332238.png)\n\n然后我们将4M对象存入到Eden区中\n\n![image-20200714083526790](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714083526790.png)\n\n### 常用日志分析工具\n\n**保存日志文件**\n\n**JVM参数**：`-XLoggc:./logs/gc.log`， ./ 表示当前目录，在 IDEA中程序运行的当前目录是工程的根目录，而不是模块的根目录\n\n可以用一些工具去分析这些GC日志 gc.log。常用的日志分析工具有：GCViewer、GCEasy、GCHisto、GCLogViewer、Hpjmeter、garbagecat等\n\n**推荐：GCeasy**\n\n在线分析网址：gceasy.io\n\n![image-20200714084726824](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714084726824.png)\n\n**GCViewer**\n\n![image-20200714084921184](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714084921184.png)\n\n\n\n## 垃圾回收器的新发展\n\nGC仍然处于飞速发展之中，目前的默认选项G1 GC在不断的进行改进，很多我们原来认为的缺点，例如串行的Full GC、Card Table扫描的低效等，都已经被大幅改进，例如，JDK10以后，Fu11GC已经是并行运行，在很多场景下，其表现还略优于ParallelGC的并行Ful1GC实现。\n\n即使是SerialGC，虽然比较古老，但是简单的设计和实现未必就是过时的，它本身的开销，不管是GC相关数据结构的开销，还是线程的开销，都是非常小的，所以随着云计算的兴起，在serverless等新的应用场景下，Serial Gc找到了新的舞台。\n\n比较不幸的是CMS GC，因为**其算法的理论缺陷**等原因，虽然现在还有非常大的用户群体，但在JDK9中已经被标记为废弃，并在JDK14版本中移除（**什么缺陷？**）\n\n现在G1回收器已成为默认回收器好几年了。我们还看到了引入了两个新的收集器：ZGC（JDK11出现）和Shenandoah（Open JDK12），其特点：**主打低停顿时间**\n\n- Epsilon:A No-Op GarbageCollector（Epsilon垃圾回收器，\"No-Op（无操作）\"回收器）http://openidk.iava.net/iep s/318\n- ZGC:A Scalable Low-Latency Garbage Collector（Experimental）（ZGC：可伸缩的低延迟垃圾回收器，处于实验性阶段）\n\n现在G1回收器已成为默认回收器好几年了。我们还看到了引入了两个新的收集器：ZGC（JDK11出现）和 Shenandoah（Open JDK12）\n\n>这两个新诞生的收集器的主打特点都是：**低停顿时间**\n\n### Open JDK 12 的 Shenandoash GC\n\nShenandoash GC：**低停顿时间的GC（实验性）**\n\nShenandoah，无疑是众多GC中最孤独的一个。是第一款不由oracle公司团队领导开发的Hotspot垃圾收集器。**不可避免的受到官方的排挤**。比如号称openJDK和OracleJDk没有区别的Oracle公司仍**拒绝在oracleJDK12中支持Shenandoah**。\n\nShenandoah垃圾回收器最初由RedHat进行的一项垃圾收集器研究项目Pauseless GC的实现，旨在针对JVM上的内存回收实现低停顿的需求。在2014年贡献给OpenJDK。\n\nRed Hat研发Shenandoah团队对外宣称，Shenandoah垃圾回收器的暂停时间与堆大小无关，这意味着无论将堆设置为200MB还是200GB，99.9%的目标都可以把垃圾收集的停顿时间限制在十毫秒以内。不过实际使用性能将取决于实际工作堆的大小和工作负载。\n\n![image-20200714090608807](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714090608807.png)\n\n这是RedHat在2016年发表的论文数据，测试内容是使用Es对200GB的维基百科数据进行索引。从结果看：\n\n>停顿时间比其他几款收集器确实有了质的飞跃，但也未实现最大停顿时间控制在十毫秒以内的目标。\n>而吞吐量方面出现了明显的下降，总运行时间是所有测试收集器里最长的。\n\n总结\n\n- Shenandoah GC的弱项：**高运行负担下的吞吐量下降**。\n- Shenandoah GC的强项：**低延迟时间**。\n\n### 革命性的 ZGC\n\nZGC与Shenandoah目标高度相似，在尽可能对吞吐量影响不大的前提下，实现在任意堆内存大小下都可以把垃圾收集的停颇时间限制在十毫秒以内的低延迟。\n\n《深入理解Java虚拟机》一书中这样定义ZGC：ZGC收集器是一款**基于Region内存布局**的，（暂时）不设分代的，使用了**读屏障**、**染色指针**和**内存多重映射**等技术来实现 ==**可并发的标记-压缩算法**== 的， ==**以低延迟为首要目标**== 的一款垃圾收集器。\n\nZGC的工作过程可以分为4个阶段：**并发标记 - 并发预备重分配 - 并发重分配 - 并发重映射** 等。\n\n**ZGC几乎在所有地方并发执行的，除了初始标记的是STW的**。所以停顿时间几乎就耗费在初始标记上，这部分的实际时间是非常少的。\n\n**吞吐量对比**\n\n![image-20200714091201073](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714091201073.png)\n\n- max-JOPS：以低延迟为首要前提下的数据\n- critical-JOPS：不考虑低延迟下的数据\n\n**停顿时间对比**\n\n![image-20200714091401511](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714091401511.png)\n\n在ZGC的强项停顿时间测试上，它毫不留情的将Parallel、G1拉开了两个数量级的差距。无论平均停顿、95%停顿、998停顿、99. 98停顿，还是最大停顿时间，ZGC都能毫不费劲控制在10毫秒以内。\n\n虽然ZGC还在试验状态，没有完成所有特性，但此时性能已经相当亮眼，用“令人震惊、革命性”来形容，不为过。**未来将在服务端、大内存、低延迟应用的首选垃圾收集器**。\n\nJDK14之前，ZGC仅Linux才支持。尽管许多使用Z的GC用户都使用类Linux的环境，但在Windows和MacOS上，人们也需要ZGC进行开发部署和测试。许多桌面应用也可以从ZGC中受益。因此，ZGC特性被移植到了Windows和MacOS上。\n\n现在Mac或Windows上也能使用ZGC了，示例如下：\n\n```bash\n-XX:+UnlockExperimentalVMOptions-XX：+UseZGC\n```\n\n### AliGC \n\nAliGC是阿里巴巴JVM团队基于G1算法，面向大堆（LargeHeap）应用场景。指定场景下的对比：\n\n![image-20200714093604012](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8/image-20200714093604012.png)\n\n当然，其它厂商也提供了各种别具一格的GC实现，例如比较有名的低延迟GC Zing","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 垃圾回收算法","url":"/2021/10/07/【JVM】JVM垃圾回收算法/","content":"\n## 垃圾回收概述\n\n### 前言\n\n在提到什么是垃圾之前，我们先看下面一张图\n\n![image-20200712085456113](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712085456113.png)\n\n从上图我们可以很明确的知道，Java 和 C++语言的区别，就在于垃圾收集技术和内存动态分配上，C语言没有垃圾收集技术，需要程序员手动收集。\n\n垃圾收集，不是Java语言的伴生产物。早在1960年，第一门开始使用内存动态分配和垃圾收集技术的Lisp语言诞生。\n\n关于垃圾收集有三个经典问题：\n\n- 哪些内存需要回收？\n- 什么时候回收？\n- 如何回收？\n\n垃圾收集机制是Java的招牌能力，极大地提高了开发效率。如今，垃圾收集几乎成为现代语言的标配，即使经过如此长时间的发展，Java的垃圾收集机制仍然在不断的演进中，不同大小的设备、不同特征的应用场景，对垃圾收集提出了新的挑战，这当然也是面试的热点。\n\n### 什么是垃圾？\n\n垃圾是指在运行程序中没有任何指针指向的对象，这个对象就是需要被回收的垃圾。\n\n如果不及时对内存中的垃圾进行清理，那么，这些垃圾对象所占的内存空间会一直保留到应用程序的结束，被保留的空间无法被其它对象使用，甚至可能导致内存溢出。\n\n### 磁盘碎片整理\n\n机械硬盘需要进行磁盘整理，同时还有坏道\n\n![image-20200712090848669](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712090848669.png)\n\n<!-- More -->\n\n### 垃圾回收部分的面试题\n\n#### 蚂蚁金服\n\n- 你知道哪几种垃圾回收器，各自的优缺点，重点讲一下cms和G1？\n- JVM GC算法有哪些，目前的JDK版本采用什么回收算法？\n- G1回收器讲下回收过程GC是什么？为什么要有GC？\n- GC的两种判定方法？CMS收集器与G1收集器的特点\n\n#### 百度\n\n- 说一下GC算法，分代回收说下\n- 垃圾收集策略和算法\n\n#### 天猫\n\n- JVM GC原理，JVM怎么回收内存\n- CMS特点，垃圾回收算法有哪些？各自的优缺点，他们共同的缺点是什么？\n\n#### 滴滴\n\nJava的垃圾回收器都有哪些，说下g1的应用场景，平时你是如何搭配使用垃圾回收器的\n\n#### 京东\n\n- 你知道哪几种垃圾收集器，各自的优缺点，重点讲下cms和G1，\n- 包括原理，流程，优缺点。垃圾回收算法的实现原理\n\n#### 阿里\n\n- 讲一讲垃圾回收算法。\n- 什么情况下触发垃圾回收？\n- 如何选择合适的垃圾收集算法？\n- JVM有哪三种垃圾回收器？\n\n#### 字节跳动\n\n- 常见的垃圾回收器算法有哪些，各有什么优劣？\n- `System.gc()` 和 `Runtime.gc()` 会做什么事情？\n- Java GC机制？GC Roots有哪些？\n- Java对象的回收方式，回收算法。\n- CMS和G1了解么，CMS解决什么问题，说一下回收的过程。\n- CMS回收停顿了几次，为什么要停顿两次?\n\n### 为什么需要 GC\n\n对于高级语言来说，一个基本认知是如果不进行垃圾回收，内存迟早都会被消耗完，因为不断地分配内存空间而不进行回收，就好像不停地生产生活垃圾而从来不打扫一样。\n\n除了释放没用的对象，垃圾回收也可以清除内存里的记录碎片。碎片整理将所占用的堆内存移到堆的一端，以便JVM将整理出的内存分配给新的对象。\n\n随着应用程序所应付的业务越来越庞大、复杂，用户越来越多，没有GC就不能保证应用程序的正常进行。而经常造成STW的GC又跟不上实际的需求，所以才会不断地尝试对GC进行优化。\n\n### 早期垃圾回收\n\n在早期的C/C++时代，垃圾回收基本上是手工进行的。开发人员可以使用new关键字进行内存申请，并使用delete关键字进行内存释放。比如以下代码：\n\n```c++\nMibBridge *pBridge= new cmBaseGroupBridge（）；\n// 如果注册失败，使用Delete释放该对象所占内存区域\nif（pBridge->Register（kDestroy）！=NO ERROR）\n\tdelete pBridge；\n```\n\n这种方式可以灵活控制内存释放的时间，但是会给开发人员带来频繁申请和释放内存的管理负担。倘若有一处内存区间由于程序员编码的问题忘记被回收，那么就会产生内存泄漏，垃圾对象永远无法被清除，随着系统运行时间的不断增长，垃圾对象所耗内存可能持续上升，直到出现内存溢出并造成应用程序崩溃。 \n\n有了垃圾回收机制后，上述代码极有可能变成这样\n\n```c++\nMibBridge *pBridge=new cmBaseGroupBridge(); \npBridge->Register(kDestroy);\n```\n\n现在，除了Java以外，C#、Python、Ruby等语言都使用了自动垃圾回收的思想，也是未来发展趋势，可以说这种自动化的内存分配和来及回收方式已经成为了线代开发语言必备的标准。\n\n### Java 垃圾回收机制\n\n> oracle官网关于垃圾回收的介绍\n> https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/toc.html\n\n#### 优点\n\n- 自动内存管理，无需开发人员手动参与内存的分配与回收，这样降低内存泄漏和内存溢出的风险\n- 没有垃圾回收器，java也会和cpp一样，各种悬垂指针，野指针，泄露问题让你头疼不已。\n- 自动内存管理机制，将程序员从繁重的内存管理中释放出来，可以更专心地专注于业务开发\n\n#### 担忧\n\n对于Java开发人员而言，自动内存管理就像是一个黑匣子，如果过度依赖于“自动”，那么这将会是一场灾难，最严重的就会弱化Java开发人员在程序出现内存溢出时定位问题和解决问题的能力。\n\n此时，了解JVM的自动内存分配和内存回收原理就显得非常重要，只有在真正了解JVM是如何管理内存后，我们才能够在遇见outofMemoryError时，快速地根据错误异常日志定位问题和解决问题。\n\n当需要排查各种内存溢出、内存泄漏问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，我们就必须对这些“自动化”的技术实施必要的监控和调节。\n\n### GC 主要关注的区域\n\nGC 主要关注于**方法区**和**堆**中的垃圾收集\n\n![image-20200712092427246](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712092427246.png)\n\n垃圾收集器可以对年轻代回收，也可以对老年代回收，甚至是全栈和方法区的回收。其中，**堆是垃圾收集器的工作重点**\n\n从次数上讲：\n\n- 频繁收集Young区\n- 较少收集Old区\n- 基本不收集Perm区（元空间）\n\n## 垃圾回收算法——标记阶段\n\n> **垃圾标记阶段：主要是为了判断对象是否存活**\n\n在堆里存放着几乎所有的Java对象实例，在GC执行垃圾回收之前，首先需要区分出内存中哪些是存活对象，哪些是已经死亡的对象。只有被标记为己经死亡的对象，GC才会在执行垃圾回收时，释放掉其所占用的内存空间，因此这个过程我们可以称为**垃圾标记阶段**。\n\n那么在JVM中究竟是如何标记一个死亡对象呢？简单来说，**当一个对象已经不再被任何的存活对象继续引用时**，就可以宣判为已经死亡。\n\n判断对象存活一般有两种方式：**引用计数算法**和**可达性分析算法**。**Java 使用的标记阶段算法是可达性分析算法**。\n\n### 引用计数算法\n\n引用计数算法（Reference Counting）比较简单，对每个对象保存一个整型的引用计数器属性。用于记录对象被引用的情况。\n\n对于一个对象A，只要有任何一个对象引用了A，则A的引用计数器就加1；当引用失效时，引用计数器就减1。只要对象A的引用计数器的值为0，即表示对象A不可能再被使用，可进行回收。\n\n- 优点：实现简单，垃圾对象便于辨识；判定效率高，回收没有延迟性。\n- 缺点：\n  - 它需要单独的字段存储计数器，这样的做法增加了**存储空间的开销**。\n  - 每次赋值都需要更新计数器，伴随着加法和减法操作，这增加了**时间开销**。\n  - 引用计数器有一个严重的问题，即**无法处理循环引用**的情况。这是一条致命缺陷，导致在Java的垃圾回收器中没有使用这类算法。\n\n### 循环引用\n\n当p的指针断开的时候，内部的引用形成一个循环，这就是循环引用，从而造成内存泄漏\n\n![image-20200712102205795](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712102205795.png)\n\n引用计数算法，是很多语言的资源回收选择，例如因人工智能而更加火热的Python，它更是同时支持引用计数和垃圾收集机制。\n\n具体哪种最优是要看场景的，业界有大规模实践中仅保留引用计数机制，以提高吞吐量的尝试。\n\n**Java并没有选择引用计数，是因为其存在一个基本的难题，也就是很难处理循环引用关系。**Python如何解决循环引用：\n\n- 手动解除：很好理解，就是在合适的时机，解除引用关系\n- 使用弱引用weakref，weakref是Python提供的标准库，旨在解决循环引用。\n\n### 可达性分析算法\n\n> 可达性分析算法：也可以称为**根搜索算法、追踪性垃圾收集**\n\n相对于引用计数算法而言，可达性分析算法不仅同样具备实现简单和执行高效等特点，更重要的是该算法**可以有效地解决在引用计数算法中循环引用的问题，防止内存泄漏的发生**。\n\n相较于引用计数算法，这里的可达性分析就是Java、C#选择的。这种类型的垃圾收集通常也叫作**追踪性垃圾收集**（Tracing Garbage Collection）\n\n> 并发的可达性分析算法： https://segmentfault.com/a/1190000021820577\n\n#### 思路\n\n所谓\"GCRoots”根集合就是一组必须活跃的引用。\n\n基本思路：\n\n- 可达性分析算法是以根对象集合（GCRoots）为起始点，按照从上至下的方式**搜索被根对象集合所连接的目标对象是否可达**。\n- 使用可达性分析算法后，内存中的存活对象都会被根对象集合直接或间接连接着，搜索所走过的路径称为引用链（Reference Chain）\n- 如果目标对象没有任何引用链相连，则是不可达的，就意味着该对象己经死亡，可以标记为垃圾对象。\n- 在可达性分析算法中，只有能够被根对象集合直接或者间接连接的对象才是存活对象。\n\n![image-20200712104149246](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712104149246.png)\n\n如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个**能保障一致性的快照**中进行。这点不满足的话分析结果的准确性就无法保证。\n\n这点也是导致GC进行时必须“Stop The World”的一个重要原因。即使是号称（几乎）不会发生停顿的CMS收集器中，**枚举根节点时也是必须要停顿的**。\n\n### GC Roots 可以是哪些？\n\n- **虚拟机栈**中的变量所引用的对象。比如：各个线程被调用的方法中使用到的参数、局部变量等。\n- 本地方法栈内JNI（通常说的本地方法）引用的对象\n- 方法区中类 static 静态成员变量所引用的对象。比如：Java类的引用类型静态变量 \n- 方法区中常量所引用的对象。比如：字符串常量池（StringTable）里的引用\n- 所有被同步锁synchronized持有的对象\n- Java虚拟机内部的引用。比如：基本数据类型对应的Class对象，一些常驻的异常对象（如：NullPointerException、OutOfMemoryError），系统类加载器。\n- 反映java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地代码缓存等。\n\n![image-20200712104622677](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712104622677.png)\n\n总结：\n\n- 虚拟机栈中的引用\n- 本地方法栈中的引用\n- 方法区中静态成员属性的引用\n- 方法区中常量的引用\n- 被同步锁锁住的类引用\n- 其他引用\n\n虚拟机栈、本地方法栈、方法区、字符串常量池等地方对堆空间进行引用的，都可以作为GC Roots进行可达性分析。\n\n### GC Roots 概念的扩大\n\n除了这些固定的GC Roots集合以外，根据用户所选用的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象**“临时性”**地加入，共同构成完整GC Roots集合。比如：**分代收集**和**局部回收**（PartialGC）。\n\n> 例如在 G1 垃圾回收器的标记阶段，GC Roots 的概念就会扩大，不仅有上文中的结构外，还会包含堆中的对象。\n\n如果**只针对Java堆中的某一块区域**进行垃圾回收（比如：典型的只针对新生代），必须考虑到这个区域的对象完全有可能被其他区域的对象所引用，这时候就需要一并**将关联的区域对象也加入GC Roots集合中去考虑**，才能保证可达性分析的准确性。\n\n即 GC Roots 的概念会可能**扩大**：在**分代收集**或**局部回收**的情况下，伊甸园区中的某些对象可能会被老年代的一些对象所引用。这种情况下，在当回收伊甸园区时 GC Roots 的范围就会扩大，即包含了老年代的这些对象，在标记阶段时，也需要扫描老年代的对象，判断有没有伊甸园区的对象被引用。而扫描这些对象将耗费很多的时间，因此提出了Remember Set技术，只需要扫描这个表即可得知哪些伊甸园区的对象被引用（见后文介绍）\n\n#### 小技巧\n\n由于Root采用栈方式存放变量和指针，所以如果一个指针，它保存了堆内存里面的对象，但是自己又不存放在堆内存里面，那它就是一个Root。\n\n### MAT 的 GC Roots 溯源\n\nMAT是Memory Analyzer的简称，它是一款功能强大的Java堆内存分析器。用于查找内存泄漏以及查看内存消耗情况。\n\nMAT是基于Eclipse开发的，是一款免费的性能分析工具。\n\n可以在http://www.eclipse.org/mat/下载并使用MAT。\n\n> 虽然JVisualVM很强大，但是在内存分析方面，还是MAT更好用一些。此小节主要是为了实时分析GC Roots是哪些东西，中间需要用到一个dump的文件\n\n#### 获取 dump 文件方式\n\n**方式一：命令行使用 jmap**\n\n![image-20200712112026317](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712112026317.png)\n\n**方式二：使用 Java VisualVM**\n\n> https://imlql.cn/post/d54daa0f.html\n\n捕获的heap dump文件是一个临时文件，关闭JVisualVM后自动删除，若要保留，需要将其另存为文件。可通过以下方法捕获heap dump：\n\n- 在左侧“Application\"（应用程序）子窗口中右击相应的应用程序，选择Heap Dump（堆Dump）。\n- 在Monitor（监视）子标签页中点击Heap Dump（堆Dump）按钮。\n- 本地应用程序的Heap dumps作为应用程序标签页的一个子标签页打开。同时，heap dump在左侧的Application（应用程序）栏中对应一个含有时间戳的节点。\n\n右击这个节点选择save as（另存为）即可将heap dump保存到本地。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/0012.jpg)\n\n#### 使用 MAT 打开 Dump 文件\n\n打开后，我们就可以看到有哪些可以作为GC Roots的对象\n\n![image-20200712112512720](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712112512720.png)\n\n里面我们能够看到有一些常用的Java类，和Thread线程。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/0017.jpg)\n\n### JProfiler 的 GC Roots 溯源\n\n> https://imlql.cn/post/d54daa0f.html\n\n我们在实际的开发中，一般不会查找全部的GC Roots，可能只是查找某个对象的整个链路，或者称为GC Roots溯源，这个时候，我们就可以使用JProfiler\n\n![image-20200712113256075](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712113256075.png)\n\n### 如何判断什么原因造成 OOM\n\n当我们程序出现OOM的时候，我们就需要进行排查，我们首先使用下面的例子进行说明\n\n```java\n/**\n * 内存溢出排查\n * -Xms8m -Xmx8m -XX:HeapDumpOnOutOfMemoryError\n */\npublic class HeapOOM {\n    // 创建1M的文件\n    byte [] buffer = new byte[1 * 1024 * 1024];\n\n    public static void main(String[] args) {\n        ArrayList<HeapOOM> list = new ArrayList<>();\n        int count = 0;\n        try {\n            while (true) {\n                list.add(new HeapOOM());\n                count++;\n            }\n        } catch (Exception e) {\n            e.getStackTrace();\n            System.out.println(\"count:\" + count);\n        }\n    }\n}\n```\n\n上述代码就是不断的创建一个1M小字节数组，然后让内存溢出，我们需要限制一下内存大小，同时使用`-XX:HeapDumpOnOutOfMemoryError`将出错时候的dump文件输出\n\n```\n-Xms8m -Xmx8m -XX:HeapDumpOnOutOfMemoryError\n```\n\n我们将生成的dump文件打开，然后点击Biggest Objects就能够看到超大对象\n\n![image-20200712150229048](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712150229048.png)\n\n然后我们通过线程，还能够定位到哪里出现OOM\n\n![image-20200712150303710](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712150303710.png)\n\n### HotSpot OopMap\n\n固定可作为GC Roots的节点主要在**全局性的引用**（例如常量或类静态属性）与**执行上下文**（例如栈帧中的本地变量表）中，尽管目标明确，但查找过程要做到高效并非一件容易的事情，现在Java应用越做越庞大，光是方法区的大小就常有数百上千兆，里面的类、常量等更是恒河沙数，若要逐个检查以这里为起源的引用肯定得消耗不少时间。\n\n迄今为止，**所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的**，因此毫无疑问根节点枚举与之前提及的整理内存碎片一样会面临相似的“Stop The World”的困扰。现在可达性分析算法耗时最长的查找引用链的过程已经可以做到与用户线程一起并发，**但根节点枚举始终还是必须在一个能保障一致性的快照中才得以进行**——这里“一致性”的意思是整个枚举期间执行子系统看起来就像被冻结在某个时间点上，不会出现分析过程中，根节点集合的对象引用关系还在不断变化的情况，若这点不能满足的话，分析结果准确性也就无法保证。这是导致垃圾收集过程必须停顿所有用户线程的其中一个重要原因，即使是号称停顿时间可控，或者（几乎）不会发生停顿的CMS、G1、 ZGC等收集器，枚举根节点时也是必须要停顿的。\n\n由于目前主流Java虚拟机使用的都是**准确式垃圾收集**，所以当用户线程停顿下来之后，其实并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得到哪些地方存放着对象引用的。在HotSpot 的解决方案里，是使用一组称为**OopMap的数据结构**来达到这个目的。**一旦类加载动作完成的时候， HotSpot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用**。这样收集器在扫描时就可以直接得知这些信息了，**并不需要真正一个不漏地从方法区等GC Roots开始查找**。\n\n> 可达性分析的在**根节点枚举**的过程中，由于GC Roots是远远少于整个java堆中的全部对象的，而且在**OopMap此类优化技巧**的加持下，它带来的停顿时间是非常短暂且相对固定的，**可以理解为不会随着堆里面的对象的增加而增加** https://segmentfault.com/a/1190000021946606\n\nExact VM因它使用**准确式内存管理**（Exact Memory Management，也可以叫Non-Con- servative/Accurate Memory Management）而得名。准确式内存管理是指虚拟机可以知道内存中某个位 置的数据具体是什么类型。譬如内存中有一个32bit的整数123456，虚拟机将有能力分辨出它到底是一 个指向了123456的内存地址的引用类型还是一个数值为123456的整数，准确分辨出哪些内存是引用类 型，这也是在垃圾收集时准确判断堆上的数据是否还可能被使用的前提。【**这个不是特别重要，了解一下即可**】\n\n> 常考面试：**在OopMap的协助下，HotSpot可以快速准确地完成GC Roots枚举**\n\n\n\n\n\n## 对象的 finalization 机制\n\n### finalize() 方法机制\n\n**对象销毁前的回调函数：finalize()**\n\nJava语言提供了对象终止（finalization）机制来允许开发人员提供**对象被销毁之前的自定义处理逻辑**。\n\n当垃圾回收器发现没有引用指向一个对象，即：垃圾回收此对象之前，总会先调用这个对象的 `finalize()` 方法。\n\n`finalize()` 方法允许在子类中被重写，**用于在对象被回收时进行资源释放**。通常在这个方法中进行一些资源释放和清理的工作，比如**关闭文件、套接字和数据库连接**等。\n\nObject 类中 `finalize()` 源码\n\n```java\n// 等待被重写\nprotected void finalize() throws Throwable { }\n```\n\n永远**不要主动调用**某个对象的 `finalize()` 方法，**应该交给垃圾回收机制调用**。理由包括下面三点：\n\n- 在 `finalize()` 时**可能会导致对象复活**。\n- `finalize()` 方法的执行时间是没有保障的，它完全由GC线程决定，极端情况下，若不发生GC，则 `finalize()` 方法将没有执行机会。\n- 一个糟糕的 `finalize()` 会严重影响GC的性能。比如是个死循\n\n从功能上来说，`finalize()` 方法与C\\+\\+中的析构函数比较相似，但是Java采用的是基于垃圾回收器的自动内存管理机制，所以 `finalize()` 方法在**本质上不同于C++中的析构函数**。\n\n`finalize()` 方法对应了一个 finalizer 线程，因为优先级比较低，即使主动调用该方法，也不会因此就直接进行回收\n\n### 生存还是死亡？\n\n由于 `finalize()` 方法的存在，**虚拟机中的对象一般处于三种可能的状态。**\n\n如果从所有的根节点都无法访问到某个对象，说明对象己经不再使用了。一般来说，此对象需要被回收。但事实上，也并非是“非死不可”的，这时候它们暂时处于“缓刑”阶段。**一个无法触及的对象有可能在某一个条件下“复活”自己**，如果这样，那么对它立即进行回收就是不合理的。为此，定义虚拟机中的对象可能的三种状态。如下：\n\n- 可触及的：从根节点开始，可以到达这个对象。\n- 可复活的：对象的所有引用都被释放，但是对象有可能在 `finalize()` 中复活。\n- 不可触及的：对象的 `finalize()` 被调用，并且没有复活，那么就会进入不可触及状态。不可触及的对象不可能被复活，**因为finalize()只会被调用一次**。\n\n以上3种状态中，是由于 `finalize()` 方法的存在进行的区分。只有在对象不可触及时才可以被回收。\n\n### 具体过程\n\n判定一个对象objA是否可回收，至少要经历两次标记过程：\n\n- 如果对象objA到GC Roots没有引用链，则进行**第一次标记**。\n- 进行筛选，判断此对象是否有必要执行 `finalize()` 方法：\n  - 如果对象objA没有重写 `finalize()` 方法，或者`finalize()`方法已经被虚拟机调用过，则虚拟机视为“没有必要执行”，objA被判定为**不可触及**的。\n  - 如果对象objA重写了`finalize()`方法，且还未执行过，那么objA会被插入到F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其`finalize()`方法执行。\n  - `finalize()`方法是对象逃脱死亡的最后机会，稍后GC会对F-Queue队列中的对象进行**第二次标记**。如果objA在`finalize()`方法中与引用链上的任何一个对象建立了联系，那么在第二次标记时，objA会被移出“即将回收”集合。之后，对象会再次出现没有引用存在的情况。在这个情况下，`finalize()`方法不会被再次调用，对象会直接变成不可触及的状态，也就是说，**一个对象的`finalize()`方法只会被调用一次。**\n\n![image-20200712110411885](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712110411885.png)\n\n上图就是我们看到的Finalizer线程\n\n### 代码演示\n\n我们使用重写 `finalize()` 方法，然后在方法的内部，重写将其存放到GC Roots中\n\n```java\n/**\n * 测试Object类中finalize()方法\n * 对象复活场景\n */\npublic class CanReliveObj {\n    // 类变量，属于GC Roots的一部分\n    public static CanReliveObj canReliveObj;\n\n    @Override\n    protected void finalize() throws Throwable {\n        super.finalize();\n        System.out.println(\"调用当前类重写的finalize()方法\");\n        canReliveObj = this;\n    }\n\n    public static void main(String[] args) throws InterruptedException {\n        canReliveObj = new CanReliveObj();\n        canReliveObj = null;\n        System.gc();\n        System.out.println(\"-----------------第一次gc操作------------\");\n        // 因为Finalizer线程的优先级比较低，暂停2秒，以等待它\n        Thread.sleep(2000);\n        if (canReliveObj == null) {\n            System.out.println(\"obj is dead\");\n        } else {\n            System.out.println(\"obj is still alive\");\n        }\n\n        System.out.println(\"-----------------第二次gc操作------------\");\n        canReliveObj = null;\n        System.gc();\n        // 下面代码和上面代码是一样的，但是 canReliveObj却自救失败了\n        Thread.sleep(2000);\n        if (canReliveObj == null) {\n            System.out.println(\"obj is dead\");\n        } else {\n            System.out.println(\"obj is still alive\");\n        }\n\n    }\n}\n```\n\n最后运行结果\n\n```\n-----------------第一次gc操作------------\n调用当前类重写的finalize()方法\nobj is still alive\n-----------------第二次gc操作------------\nobj is dead\n```\n\n在进行第一次清除的时候，我们会执行 `finalize()` 方法，然后对象进行了一次自救操作，但是因为 `finalize()` 方法只会被调用一次，因此第二次该对象将会被垃圾清除。\n\n\n\n\n\n## 垃圾回收算法——清除阶段\n\n当使用上文中介绍的标记算法——可达性分析算法成功区分出内存中存活对象和死亡对象后，GC接下来的任务就是执行垃圾回收，释放掉无用对象所占用的内存空间，以便有足够的可用内存空间为新对象分配内存。目前在JVM中比较常见的三种垃圾收集算法是：\n\n- 标记一清除算法（Mark-Sweep）\n- 复制算法（copying）\n- 标记-压缩算法（Mark-Compact）\n\n### 标记-清除算法\n\n标记-清除算法（Mark-Sweep）是一种非常基础和常见的垃圾收集算法，该算法被J.McCarthy等人在1960年提出并并应用于Lisp语言。\n\n#### 执行过程\n\n当堆中的有效内存空间（available memory）被耗尽的时候，就会停止整个程序（也被称为stop the world），然后进行两阶段工作，第一阶段是标记阶段，第二阶段是清除阶段：\n\n- **标记阶段**：Collector从引用根节点开始遍历，**标记所有被引用的对象**。一般是**在对象的对象头Header中记录为可达对象**。注意：**标记的是引用的对象，不是垃圾对象！**因为沿着 GC Roots 引用链查找对象时只能找到被引用的对象，找不到垃圾对象。标记阶段即可使用上文介绍的可达性分析算法。\n- **清除阶段**：Collector对堆内存**从头到尾**进行**线性的遍历**，如果发现某个对象的对象头Header中没有标记为可达对象，则将其回收\n\n总结：先沿着GC Roots链式遍历所有可达对象，将其标记为可达；然后遍历整个内存区域，将标记为不可达的都清除。其实是两步操作，先链式标记，再遍历整个内存区域清除不可达。\n\n![image-20200712150935078](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712150935078.png)\n\n#### 什么是清除？\n\n这里所谓的清除**并不是真的置空**，而是把需要清除的对象**地址保存在空闲的地址列表里**。下次有新对象需要加载时，判断垃圾的位置空间是否够，**如果够，就存放覆盖原有的地址**。固态硬盘的数据删除和覆盖也是这种思想，删掉的数据并不是真的消失，而是将其地址放到空闲列表中，新来的数据会直接覆盖原始数据。\n\n关于空闲列表：\n\n- 如果内存规整\n  - 采用指针碰撞的方式进行内存分配\n- 如果内存不规整\n  - 虚拟机需要维护一个空闲列表\n  - 采用空闲列表分配内存\n\n**标记-清除算法的缺点**\n\n- 标记清除算法的效率不算高\n- 在进行GC的时候，需要停止整个应用程序，用户体验较差\n- 这种方式清理出来的空闲内存是不连续的，产生内碎片，需要维护一个空闲列表\n\n### 复制算法\n\n为了解决标记-清除算法在垃圾收集效率方面的缺陷，M.L.Minsky于1963年发表了著名的论文，“使用双存储区的Lisp语言垃圾收集器CA LISP Garbage Collector Algorithm Using Serial Secondary Storage）”。M.L.Minsky在该论文中描述的算法被人们称为复制（Copying）算法，它也被M.L.Minsky本人成功地引入到了Lisp语言的一个实现版本中。\n\n>  新生代的 Young GC 就用到了复制算法，Eden区和S0区存活对象整体复制到S1区\n\n#### 核心思想\n\n将存活对象的内存空间分为两块，每次只使用其中一块，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象（不是真正的清空，见上文），交换两个内存的角色，最后完成垃圾回收。\n\n复制算法**不需要线性遍历整个堆空间**，其只需要在标记阶段链式**寻找可达对象的同时直接将对象复制到另一半内存区域**，无需去遍历那些空闲区域和垃圾区域，这显然节省了大量的时间。这也是其速度最快的原因：**只链式遍历了可达对象，没有遍历其他区域**。\n\n![image-20200712151916991](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712151916991.png)\n\n新生代的 Young GC 就用到了复制算法，Eden区和S0区存活对象整体复制到S1区\n\n![image-20200712152029615](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712152029615.png)\n\n**优点**\n\n1. 没有标记和清除过程，实现简单，运行高效\n2. 复制过去以后保证空间的连续性，不会出现“碎片”问题。\n\n**缺点**\n\n1. 此算法的缺点也是很明显的，就是**需要两倍的内存空间**。\n2. 对于G1这种分拆成为大量region的GC，复制而不是移动，意味着GC需要维护region之间对象引用关系，不管是内存占用或者时间开销也不小\n\n#### 复制算法的应用场景\n\n- 如果系统中的垃圾对象很多，复制算法需要复制的存活对象数量并不会太大，效率较高\n- 老年代大量的对象存活，那么复制的对象将会有很多，效率会很低，并且老年代也没有开辟另一块同样大小区域的资本\n- 在新生代，对常规应用的垃圾回收，一次通常可以回收 70% - 99% 的内存空间。回收性价比很高。所以现在的商业虚拟机都是用这种收集算法回收新生代。\n\n![image-20200712152847218](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712152847218.png)\n\n### 标记-压缩算法\n\n>  标记-压缩算法又被称为标记-整理算法、Mark-Compact算法\n\n复制算法的高效性是建立在存活对象少、垃圾对象多的前提下的。这种情况在新生代经常发生，但是在老年代，更常见的情况是大部分对象都是存活对象。如果依然使用复制算法，由于存活对象较多，复制的成本也将很高。因此，**基于老年代垃圾回收的特性，不能使用复制算法，需要使用其他的算法。**\n\n标记-清除算法的确可以应用在老年代中，但**是该算法不仅执行效率低下，而且在执行完内存回收后还会产生内存碎片**，所以JVM的设计者需要在此基础之上进行改进。标记-压缩（Mark-Compact）算法由此诞生。\n\n1970年前后，G.L.Steele、C.J.Chene和D.s.Wise等研究者发布标记-压缩算法。在许多现代的垃圾收集器中，人们都使用了标记-压缩算法或其改进版本。\n\n#### 执行过程\n\n- 第一阶段和标记清除算法一样，从根节点开始标记所有被引用对象\n- 第二阶段将所有的存活对象压缩到内存的一端，按顺序排放。之后，清理边界外所有的空间。\n\n#### 特点\n\n- 只有复制算法不需要先标记再遍历整个堆空间（因为在可达性分析的链式遍历时⼀旦找到⼀个存活对象就可以直接复制）。\n- 标记-压缩算法需要先标记再遍历整个堆空间，因为当你找到⼀个存活对象的时候你不知道要往哪个地址复制，只有所有存活对象都标记完才能确认可以复制的地址\n\n> 标记-压缩算法里移动到空闲区域的原理可能是：使用双指针，一个指针指向有空闲的区域，然后另⼀个指针不断遍历内存空间，遇到有存活的就复制到前一个指针的位置\n\n![image-20200712153236508](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712153236508.png)\n\n**标记-压缩算法与标记-清除算法的比较**\n\n- 标记-压缩算法的最终效果等同于标记-清除算法执行完成后，再进行一次**内存碎片整理**，因此，也可以把它称为**标记-清除-压缩**（Mark-Sweep-Compact）算法。\n- 二者的本质差异在于标记-清除算法是一种**非移动式的回收算法**，标记-压缩是**移动式的**。是否移动回收后的存活对象是一项优缺点并存的风险决策。\n- 可以看到，标记的存活对象将会被整理，按照内存地址依次排列，而未被标记的内存会被清理掉。如此一来，当我们需要给新对象分配内存时，**JVM只需要持有一个内存的起始地址即可，这比维护一个空闲列表显然少了许多开销**。\n\n#### 优点\n\n- 消除了标记-清除算法当中，内存区域分散（内存碎片化）的缺点，我们需要给新对象分配内存时，**JVM只需要持有一个内存的起始地址即可**。\n- 消除了复制算法当中，内存减半的高额代价。\n\n#### 缺点\n\n- 从效率上来说，**标记-整理算法要低于复制算法**。\n- 移动对象的同时，**如果对象被其他对象引用，则还需要调整引用的地址**（因为 hotspot 虚拟机中对象的访问方式为**直接指针**，而非句柄访问，当对象的内存地址变化时，需要修改引用该对象的其他对象中存储的地址指，详细见 [【JVM】JVM对象实例化过程](https://yuyun-zhao.github.io/2021/10/01/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/)）\n- 移动过程中，需要全程暂停用户应用程序。即：STW\n\n### 清除算法小结\n\n效率上来说，复制算法当之无愧最高效，但是却浪费了太多内存。\n\n而为了尽量兼顾上面提到的三个指标，标记-整理算法相对来说更平滑一些，但是效率上不尽如人意，**它比复制算法多了一个标记的阶段，比标记-清除多了一个整理内存的阶段。**\n\n|              | 标记-清除          | 标记-整理        | 复制                                    |\n| ------------ | ------------------ | ---------------- | --------------------------------------- |\n| **速率**     | 中等               | 最慢             | 最快                                    |\n| **空间开销** | 少（但会堆积碎片） | 少（不堆积碎片） | 通常需要存活对象的2倍空间（不堆积碎片） |\n| **移动对象** | 否                 | 是               | 是                                      |\n\n\n## 分代收集算法\n\n前面所有这些算法中，并没有一种算法可以完全替代其他算法，它们都具有自己独特的优势和特点。分代收集算法应运而生。\n\n分代收集算法，是基于这样一个事实：不同的对象的生命周期是不一样的。因此，**不同生命周期的对象可以采取不同的收集方式**，以便提高回收效率。一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。\n\n在Java程序运行的过程中，会产生大量的对象，其中有些对象是与业务信息相关，比如Http请求中的Session对象、线程、Socket连接，这类对象跟业务直接挂钩，因此生命周期比较长。但是还有一些对象，主要是程序运行过程中生成的临时变量，这些对象生命周期会比较短，比如：String对象，由于其不变类的特性，系统会产生大量的这些对象，有些对象甚至只用一次即可回收。\n\n**目前几乎所有的GC都采用分代收集算法执行垃圾回收的。**\n\n在HotSpot中，基于分代的概念，GC所使用的内存回收算法必须结合年轻代和老年代各自的特点。\n\n年轻代（Young Gen）\n\n- 年轻代特点：区域相对老年代较小，对象生命周期短、存活率低，回收频繁。\n- **这种情况复制算法的回收整理，速度是最快的**。复制算法的效率只和当前存活对象大小有关，因此很适用于年轻代的回收。而复制算法内存利用率不高的问题，通过hotspot中的两个survivor的设计得到缓解。\n\n老年代（Tenured Gen）\n\n- 老年代特点：区域较大，对象生命周期长、存活率高，回收不及年轻代频繁。\n- 这种情况存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记-清除或者是标记-清除与标记-整理的混合实现。\n  - Mark阶段的开销与存活对象的数量成正比。\n  - Sweep阶段的开销与所管理区域的大小成正相关。\n  - Compact阶段的开销与存活对象的数据成正比。\n\n以HotSpot中的CMS回收器为例，CMS是基于Mark-Sweep实现的，对于对象的回收效率很高。而对于碎片问题，CMS采用基于Mark-Compact算法的Serial Old回收器作为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采Serial Old执行Full GC以达到对老年代内存的整理。\n\n分代的思想被现有的虚拟机广泛使用。几乎所有的垃圾回收器都区分新生代和老年代。\n\n## 增量收集算法\n\n### 概述\n\n上述现有的算法，在垃圾回收过程中，应用软件将处于一种Stop The World的状态。在Stop The World状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，对**实时垃圾收集算法**的研究直接导致了**增量收集**（Incremental Collecting）算法的诞生。\n\n如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以**让垃圾收集线程和应用程序线程交替执行**。**每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成**。\n\n总的来说，增量收集算法的基础仍是传统的标记-清除和复制算法。**增量收集算法通过对线程间冲突的妥善处理**，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作\n\n### 缺点\n\n使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，造成系统**吞吐量的下降**。\n\n## 分区算法\n\n一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。\n\n**分代算法将按照对象的生命周期长短划分成两个部分，分区算法将整个堆空间划分成连续的不同小区间。**\n\n每一个小区间都独立使用，独立回收。这种算法的好处是可以控制一次回收多少个小区间。\n\n![image-20200712165318590](/images/%E3%80%90JVM%E3%80%91JVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%AE%97%E6%B3%95/image-20200712165318590.png)\n\n注意，上文中介绍的只是基本的算法思路，实际GC实现过程要复杂的多，目前还在发展中的前沿GC都是复合算法，并且**并行和并发兼备**。\n\n\n\n\n\n\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 字符串常量池","url":"/2021/10/06/【JVM】JVM字符串常量池/","content":"\n## String 的基本特性\n\nString：字符串，使用一对 `\"\"` 引起来表示。Java 程序中的所有字符串**字面值**（如`\"abc\"`）都作为此类的实例实现。\n\n```java\nString s1 = \"hello\";                // 字面量的定义方式\nString s2 =  new String(\"hello\");   // new 对象的方式\n```\n\n- `String`是一个**final**类，代表**不可变**的**字符序列**，其不可被继承。\n- 字符串是**常量**，用双引号引起来表示。它们的值在创建之后**不能更改**。\n- `String`对象的字符内容是存储在一个**字符数组常量**`final char value[]`中的。\n- `String`实现了`Serializable`接口：表示字符串是支持**序列化**的。实现了`Comparable`接口：表示`String`可以**比较大小**。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20210625102721429.png)\n\n### String 的不可变性\n\nString：代表**不可变的字符序列**。简称：不可变性。\n\n1. 当对字符串重新赋值时，需要**重新指定内存区域赋值**，不能使用原有的value进行赋值。\n2. 当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值。\n3. 当调用`String`的`replace()`方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值。\n4. 通过**字面量**（如`\"abc\"`）的方式（**区别于new**）给一个字符串赋值，此时的字符串值声明在**字符串常量池**中\n5. 字符串常量池中是**不会存储相同内容**的字符串的。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20210625102749139.png)\n\n> 字面量包含：文本字符串、声明为 final 的常量值\n\n<!-- More -->\n\n代码\n\n```java\n@Test\npublic void test1(){\n    String s1 = \"abc\"; //字面量的定义方式\n    String s2 = \"abc\";\n    s1 = \"hello\";\n\n    System.out.println(s1 == s2);//比较s1和s2的地址值 false\n    System.out.println(s1);//hello\n    System.out.println(s2);//abc\n\n    System.out.println(\"*****************\");\n\n    String s3 = \"abc\";\n    s3 += \"def\";\n    System.out.println(s3);//abcdef\n    System.out.println(s2);//abc\n\n    System.out.println(\"*****************\");\n\n    String s4 = \"abc\";\n    String s5 = s4.replace('a', 'm');\n    System.out.println(s4);//abc\n    System.out.println(s5);//mbc\n}\n```\n\n### String 的实例化方式\n\n- 方式一：通过**字面量**定义的方式 `String str1 = \"abc\";`，此对象存储在字符串常量池中\n- 方式二：通过**new + 构造器**的方式 `String str2 = new String(\"abc\");`，此时创建两个对象，一个 String 对象 `\"abc \"` 存储在字符串常量池中，另一个 `str2` 存储在普通堆空间中\n\n二者区别：\n\n- 下图中的两个橙色块代表两个 String 对象\n- 直接用字面量形式创建的对象 `str1` 存在于**字符串常量池**中，其内维护了一份唯一的字符串数据 `char[] value = \"abc\"`\n- 用 new 的方式创建的 String 对象存在于**堆区**中，和上一种方式的对象是不同的\n\n二者的联系在于普通堆区内的 String 对象内部维护的 `char[] value` 数组其实指向的是常量池中的 String 对象内部维护的 `char[] value`，即同一个字符串数据只存在一份于字符串常量池中，普通堆区的 String 对象只是引用了该数据\n\n![image-20210625103416513](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20210625103416513.png)\n\n---\n\n问：`String str = new String(\"abc\");`方式创建对象，在内存中创建了几个对象？\n\n答：两个。一个 `String` 对象 `\"abc \"` 存储在字符串常量池中（在常量池的 `Hashtable` 结构中），另一个 `str` 存储在普通堆空间中。\n\n注意这个 `str` 内部的 `char[]` 数组的地址就是在字符串常量池中 `\"abc\"` 对象的 `char[]` 数组地址，即在普通堆区 new 出来的多个 String 对象，他们如果内容相同，那么内部的 `char[]` 数组的地址就是同一个地址（指向存储在字符串常量池中的真正数据 `\"abc \"` ），本身不会再去创建新的` char[]` 数据了，而是共享常量池中的同一份 ` char[]`。\n\n同时，在普通堆内存空间中存在的 String 对象 `str` 是会被 GC 的，但是在字符串常量池中的匿名 `String` 对象 `\"abc \"` 不会被轻易 GC，只有当所有引用该对象内的 `char[] value` 的 String 对象都不存在了才会被回收。 \n\n---\n\n我们也可以从字节码角度分析这两种创建方式的差异：\n\n```java\npublic static void main(String[] args) {\n    String a = \"a\";\n    String b = new String(\"b\");\n}\n```\n\n![image-20211013151732410](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20211013151732410.png)\n\n- `0  ldc #2 <a>`：从字符串常量池中加载` \"a\"` 这个字符串到操作数栈中\n- `2  asrore_1`：将操作数栈中存储的 `\"a\"` 保存到局部变量表中索引位置为1的位置（即赋值给对象 a）\n- `3  new #3 <java/lang/String>`：new 一个 String 对象（即 b 对象，但此时还未初始化，对象属性只是初始值）放到操作数栈中\n- `6  dup`：将 new 的 String 对象复制一份同样放到操作数栈中\n- `7  ldc #4 <b>`：从字符串常量池中加载 `\"b\"` 这个字符串到操作数栈中\n- `9  invokespecial #5 <java/lang/String.<init>>`：调用 String 类的 `<init>` 方法（包含构造器），将 6 中复制出的 String 和 7 中载入的 \"b\" 字符串弹栈，传入到该方法中，从而真正地完成了一个 String 类型对象（此时已经做了初始化）的创建和初始化，将该对象放回到操作数栈中\n- `12  astore_2`：将 9 中初始化完毕的 String 对象存储到局部变量表中索引位置为1的位置（即赋值给对象 b）\n- `13  return`：方法返回\n\n从上述流程中可以看出：\n\n- 字面量形式的对象在程序启动加载阶段就已经被创建好放到了字符串常量池中，而不是等到执行该方法时才创建\n- 字面量形式没有再 new 一个对象，而是把字符串常量池里已经存在的对象的地址赋给了引用对象 a\n\n### 字符串对象存储方式\n\n下图中堆区value指向 `\"javaEE\"` 的红色箭头代表每个对象内的 `char[] value` 都是共享的常量池中的唯一一份 `char[] value`（它同样存储在一个 String 对象中）：\n\n![image-20210625103432649](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20210625103432649.png)\n\n![image-20210625103730602](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20210625103730602.png)\n\n字符串的特性：\n\n![image-20210625103806711](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20210625103806711.png)\n\n结论：\n\n- 常量与常量的拼接结果在常量池。且常量池中不会存在相同内容的常量。\n- **只要其中有一个是变量，结果就在堆中**。原理是底层创建了一个 `StringBuilder` 对象，将字符串拼接完毕后返回了一个存储在堆中的 `String` 类型对象\n- 如果拼接的结果调用`intern()`方法，返回值就在常量池中。\n\n测试代码：\n\n```java\n@Test\npublic void test2(){\n    //通过字面量定义的方式：此时的s1和s2的数据javaEE声明在方法区中的字符串常量池中。\n    String s1 = \"javaEE\";\n    String s2 = \"javaEE\";\n    //通过new + 构造器的方式:此时的s3和s4保存的地址值，是数据在堆空间中开辟空间以后对应的地址值。\n    String s3 = new String(\"javaEE\");\n    String s4 = new String(\"javaEE\");\n\n    System.out.println(s1 == s2);//true\n    System.out.println(s1 == s3);//false\n    System.out.println(s1 == s4);//false\n    System.out.println(s3 == s4);//false\n\n    System.out.println(\"***********************\");\n    Person p1 = new Person(\"Tom\",12);\n    Person p2 = new Person(\"Tom\",12);\n\n    System.out.println(p1.name.equals(p2.name));//true\n    System.out.println(p1.name == p2.name);//true\n\n    p1.name = \"Jerry\";\n    System.out.println(p2.name);//Tom\n}\n\n@Test\npublic void test3(){\n    String s1 = \"javaEE\";\n    String s2 = \"hadoop\";\n\n    String s3 = \"javaEEhadoop\";\n    String s4 = \"javaEE\" + \"hadoop\";\n    String s5 = s1 + \"hadoop\";\n    String s6 = \"javaEE\" + s2;\n    String s7 = s1 + s2;\n\n    System.out.println(s3 == s4);//true\n    System.out.println(s3 == s5);//false\n    System.out.println(s3 == s6);//false\n    System.out.println(s3 == s7);//false\n    System.out.println(s5 == s6);//false\n    System.out.println(s5 == s7);//false\n    System.out.println(s6 == s7);//false\n\n    String s8 = s6.intern();//返回值得到的s8使用的常量值中已经存在的“javaEEhadoop”\n    System.out.println(s3 == s8);//true\n\n}\n\n/*\n    结论：\n    1.常量与常量的拼接结果在常量池。且常量池中不会存在相同内容的常量。\n    2.只要其中有一个是变量，结果就在堆中。\n    3.如果拼接的结果调用intern()方法，返回值就在常量池中\n*/\n@Test\npublic void test4(){\n    String s1 = \"javaEEhadoop\";\n    String s2 = \"javaEE\";\n    String s3 = s2 + \"hadoop\";\n    System.out.println(s1 == s3);//false\n\n    final String s4 = \"javaEE\";//s4:常量\n    String s5 = s4 + \"hadoop\";\n    System.out.println(s1 == s5);//true\n\n}\n```\n\n面试题\n\n```java\npublic class StringExer {\n    String str = new String(\"good\");\n    char [] ch = {'t','e','s','t'};\n\n    public void change(String str, char[] ch) {\n        str = \"test ok\";\n        ch[0] = 'b';\n    }\n\n    public static void main(String[] args) {\n        StringExer ex = new StringExer();\n        ex.change(ex.str, ex.ch);\n        System.out.println(ex.str);\n        System.out.println(ex.ch);\n    }\n}\n```\n\n输出结果\n\n```\ngood\nbest\n```\n\n原因：\n\n- `ex.str`传入`change()`方法后，在栈中创建了一个局部变量`str`，其同样指向字符串常量池中的`\"good\"`匿名对象，此时`str = \"test ok\"`执行后，将在字符串常量池中新建一个匿名字符串对象 `\"test ok\"`，并且被局部变量 `str` 所指向，但`ex.str`的内容保持不变（仍然指向字符串常量 `\"good\"`）；\n- `ex.ch`传入`change()`方法后，在栈中创建了局部变量`ch[]`，其同样指向`ex.ch`数组，但修改`ch[0]`会导致`ex.ch`的内容同样被修改。\n\n二者的区别在于：`String`类对象和`char[]`数组对象作为形参传入时都是引用类型，修改形参时原本对象也应该被修改，但`String`类的不可变性导致修改形参时在常量池中创建了新的字符串内容，因此原本对象内容没有改变，但`char`数组并无此特性，因此会被修改。\n\n\n\n### String 的底层结构\n\n**字符串常量池是不会存储相同内容的字符串的**\n\nString 的 String Pool（字符串常量池）是一个固定大小的`Hashtable`，默认值大小长度是1009。如果放进String Pool的String对象非常多，就会造成Hash冲突严重，从而导致链表会很长，而链表长了以后直接会造成的影响就是当调用`String.intern()`方法时去常量池中查找是否已经存在某个字符串时性能会大幅下降。\n\n使用`-XX:StringTablesize`可设置StringTable的长度\n\n- 在JDK 6中`StringTable`是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快，`StringTablesize`设置没有要求\n- 在JDK 7中，`StringTable`的长度默认值是60013，`StringTablesize`设置没有要求\n- 在JDK 8中，`StringTable`的长度默认值是60013，`StringTable`可以设置的最小值为1009\n\n\n\n### 为什么 JDK 9 改变了 String 结构\n\n> **官方文档**：http://openjdk.java.net/jeps/254\n\n**为什么改为 byte[] 存储？**\n\nString类的当前实现将字符存储在char[]数组中，每个字符使用两个字节(16位)。\n\n从许多不同的应用程序收集的数据表明，**字符串是堆使用的主要组成部分**，而且大多数字符串对象**只包含拉丁字符**（Latin-1）。这些字符只需要一个字节的存储空间，**因此这些字符串对象的内部char数组中有一半的空间将不会使用，产生了大量浪费。**\n\n之前 String 类使用 UTF-16 的 `char[]` 数组存储，JDK 9改为 `byte[]` 数组 外加一个**编码标识存储**。该编码表示如果你的字符是ISO-8859-1或者Latin-1，那么只需要一个字节存。如果你是其它字符集，比如UTF-8，你仍然用两个字节存\n\n结论：在 JDK 9 之后，String再也不用 `char[]` 来存储了，改成了 `byte []` 加上编码标记，节约了一些空间。\n\n```java\n// 之前\nprivate final char value[];\n// 之后\nprivate final byte[] value\n```\n\n同时基于String的数据结构，例如`StringBuffer`和`StringBuilder`也同样做了修改。\n\n\n\n## String 的内存分配\n\n在Java语言中有8种基本数据类型和一种比较特殊的类型String。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。\n\n常量池就类似一个Java系统级别提供的缓存。8种基本数据类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种：\n\n- 直接使用双引号声明出来的字面量String对象会直接存储在常量池中。比如：`String info=\"hello\";`\n- 如果不是用双引号声明的String对象，可以使用String提供的`intern()`方法将对象存储在常量池中。这个后面重点谈\n\n存放位置调整：\n\n- Java 6及以前，字符串常量池存放在**永久代**\n- Java 7后oracle的工程师对字符串池的逻辑做了很大的改变，即将字符串常量池的位置调整到Java**堆内**\n\n>所有的字符串都保存在堆（Heap）中，和其他普通对象一样，这样可以让你在进行调优应用时仅需要调整堆大小就可以了。\n>\n>字符串常量池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在Java 7中使用String.intern（）。\n\nJava 8 元空间，字符串常量在堆区：\n\n![image-20200711093546398](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20200711093546398.png)\n\n![image-20200711093558709](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20200711093558709.png)\n\n### 为什么 StringTable 从永久代调整到堆中\n\n为什么要调整位置？\n\n- 永久代的默认空间大小比较小\n- 永久代垃圾回收频率低，大量的字符串无法及时回收，容易进行Full GC产生STW或者容易产生`OOM：PermGen Space`\n- 堆中空间足够大，字符串可被及时回收\n\n在JDK 7中，interned字符串不再在Java堆的永久代中分配，而是在Java堆的主要部分（称为年轻代和年老代）中分配，与应用程序创建的其他对象一起分配。\n\n此更改将导致驻留在主Java堆中的数据更多，驻留在永久生成中的数据更少，因此可能需要调整堆大小。\n\n## String 的基本操作\n\nJava语言规范里要求完全相同的字符串字面量，应该包含同样的Unicode字符序列（包含同一份码点序列的常量），并且必须是指向同一个String类实例。\n\n``` java\n//官方示例代码\nclass Memory {\n    public static void main(String[] args) {//line 1\n        int i = 1;//line 2\n        Object obj = new Object();//line 3\n        Memory mem = new Memory();//line 4\n        mem.foo(obj);//line 5\n    }//line 9\n\n    private void foo(Object param) {//line 6\n        String str = param.toString();//line 7\n        System.out.println(str);\n    }//line 8\n}\n```\n\n分析运行时内存（`foo()` 方法是实例方法，其实图中少了一个 `this` 局部变量）\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/0010.png)\n\n\n\n\n\n## 字符串拼接操作\n\n- 常量与常量的拼接结果在常量池，原理是**编译期优化**\n- 常量池中不会存在相同内容的变量\n- **只要其中有一个是变量，结果就在堆中**。变量拼接的原理是使用 `StringBuilder`\n- 如果拼接的结果调用 `intern()` 方法，则**主动将常量池中还没有的字符串对象放入池中，并返回此对象地址**\n\n### 字符串常量间的拼接\n\n字符串常量与常量的拼接结果在常量池，原理是**编译期优化**\n\n```java\n@Test\npublic void test1() {\n    String s1 = \"a\" + \"b\" + \"c\"; //编译期优化：等同于\"abc\"\n    String s2 = \"abc\"; //\"abc\"一定是放在字符串常量池中，将此地址赋给s2\n    /*\n         * 最终.java编译成.class,再执行.class\n         * String s1 = \"abc\";\n         * String s2 = \"abc\"\n         */\n    System.out.println(s1 == s2); //true\n    System.out.println(s1.equals(s2)); //true\n}\n```\n\n从字节码指令看出：编译器做了优化，将 `\"a\" + \"b\" + \"c\"` 优化成了 `\"abc\"`\n\n```\n0 ldc #2 <abc>   <--------  这里直接载入的是 \"abc\" \n2 astore_1\n3 ldc #2 <abc>\n5 astore_2\n6 getstatic #3 <java/lang/System.out>\n9 aload_1\n10 aload_2\n11 if_acmpne 18 (+7)\n14 iconst_1\n15 goto 19 (+4)\n18 iconst_0\n19 invokevirtual #4 <java/io/PrintStream.println>\n22 getstatic #3 <java/lang/System.out>\n25 aload_1\n26 aload_2\n27 invokevirtual #5 <java/lang/String.equals>\n30 invokevirtual #4 <java/io/PrintStream.println>\n33 return\n```\n\n### 字符串变量间的拼接\n\n- 拼接前后，**只要其中有一个是变量，结果就在堆中**\n- 调用 `intern()` 方法，则主动将字符串对象存入字符串常量池中，并将其地址返回\n\n```java\n@Test\npublic void test2(){\n    String s1 = \"javaEE\";\n    String s2 = \"hadoop\";\n\n    String s3 = \"javaEEhadoop\";\n    String s4 = \"javaEE\" + \"hadoop\";//编译期优化\n    //如果拼接符号的前后出现了变量，则相当于在堆空间中new String()，具体的内容为拼接的结果：javaEEhadoop\n    String s5 = s1 + \"hadoop\";\n    String s6 = \"javaEE\" + s2;\n    String s7 = s1 + s2;\n\n    System.out.println(s3 == s4);//true\n    System.out.println(s3 == s5);//false\n    System.out.println(s3 == s6);//false\n    System.out.println(s3 == s7);//false\n    System.out.println(s5 == s6);//false\n    System.out.println(s5 == s7);//false\n    System.out.println(s6 == s7);//false\n\n    //intern():判断字符串常量池中是否存在javaEEhadoop值，如果存在，则返回常量池中javaEEhadoop的地址；\n    //如果字符串常量池中不存在javaEEhadoop，则在常量池中加载一份javaEEhadoop，并返回次对象的地址。\n    String s8 = s6.intern();\n    System.out.println(s3 == s8);//true\n}\n```\n\n底层原理：字符串变量间的拼接操作的**底层其实使用了 `StringBuilder`**\n\n![image-20200711102231129](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20200711102231129.png)\n\n`s1 + s2` 的执行细节：\n\n- `StringBuilder s = new StringBuilder();`\n- `s.append(s1);`\n- `s.append(s2);`\n- `s.toString();`  -> 类似于`new String(\"ab\");`\n\n在JDK 5之后，使用的是 `StringBuilder`，在JDK5之前使用的是 `StringBuffer`\n\n| String                                                       | StringBuffer                                                 | StringBuilder    |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------- |\n| String的值是不可变的，这就导致每次对String的操作都会生成新的String对象，不仅效率低下，而且浪费大量优先的内存空间 | StringBuffer是可变类，和线程安全的字符串操作类，任何对它指向的字符串的操作都不会产生新的对象。每个StringBuffer对象都有一定的缓冲区容量，当字符串大小没有超过容量时，不会分配新的容量，当字符串大小超过容量时，会自动增加容量 | 可变类，速度更快 |\n| 不可变                                                       | 可变                                                         | 可变             |\n|                                                              | 线程安全                                                     | 线程不安全       |\n|                                                              | 多线程操作字符串                                             | 单线程操作字符串 |\n\n注意，我们左右两边如果是变量的话，就是需要`new StringBuilder`进行拼接，但是如果使用的是 `final` 修饰，则是从常量池中获取。\n\n所以说拼接符号左右两边都是字符串常量或常量引用，则仍然使用编译器优化。也就是说被 `final` 修饰的变量，将会变成常量。\n\n在开发中，能够使用 `final` 的时候，建议使用上\n\n```java\npublic static void test4() {\n    final String s1 = \"a\";\n    final String s2 = \"b\";\n    String s3 = \"ab\";\n    String s4 = s1 + s2;\n    System.out.println(s3 == s4);\n}\n```\n\n运行结果\n\n```\ntrue\n```\n\n### 拼接操作和 append() 性能对比\n\n```java\npublic static void method1(int highLevel) {\n    String src = \"\";\n    for (int i = 0; i < highLevel; i++) {\n        src += \"a\"; // 每次循环都会创建一个StringBuilder对象\n    }\n}\n\npublic static void method2(int highLevel) {\n    StringBuilder sb = new StringBuilder();\n    for (int i = 0; i < highLevel; i++) {\n        sb.append(\"a\");\n    }\n}\n```\n\n方法1耗费的时间：4005ms，方法2消耗时间：7ms\n\n结论：通过 `StringBuilder` 的 `append()` 方式添加字符串的效率，要远远高于 String 的字符串拼接方法\n\n `StringBuilder` 的 `append()` 方式，自始至终只创建一个 `StringBuilder` 的对象\n\n而使用String的字符串拼接方式：\n\n- 还需要创建很多 `StringBuilder` 对象和调用 `toString()` 时候创建的 String 对象\n- 内存中由于创建了较多的 `StringBuilder` 和 String 对象，内存占用过大，如果进行GC那么将会耗费更多的时间\n\n改进的空间：\n\n- 在实际开发中，如果基本确定要前前后后添加的字符串长度不高于某个限定值highLevel的情况下，建议使用构造器实例化：\n- `StringBuilder s = new StringBuilder(highLevel);  // new char[highLevel]`\n- 这样可以避免频繁扩容\n\n## intern() 的使用\n\n> intern()：将字符串对象放到字符串常量池的**内部**，作用：节省内存空间\n\n```java\npublic native String intern();\n```\n\n`intern()` 是一个 native方法，调用的是底层C的方法\n\n字符串池最初是空的，由String类私有地维护。在调用 `intern()` 方法时，如果池中已经包含了由 `equals(object)` 方法确定的与该字符串对象相等的字符串，**则返回池中的字符串对象的地址**。否则，**该字符串对象将被添加到池中，并返回对该字符串对象的引用。**\n\n如果不是用双引号声明的String对象，可以使用String提供的 `intern()` 方法：`intern()` 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中（好处是可以减少堆中存放的大量冗余字符串对象），并将常量池中该对象的地址返回给引用对象。\n\n比如：\n\n```\nString myInfo = new string(\"hello\").intern();\n```\n\n也就是说，如果在任意字符串上调用 `String.intern()` 方法，**那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同**。因此，下列表达式的值必定是true\n\n```java\n(\"a\"+\"b\"+\"c\").intern（）==\"abc\"\n```\n\n通俗点讲，**`intern()` 就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度**。注意，这个值会被存放在字符串内部池（String Intern Pool）\n\n### intern() 的空间效率测试\n\n我们通过测试一下，使用了 `intern()` 和不使用的时候，其实相差还挺多的\n\n```java\npublic class StringIntern2 {\n    static final int MAX_COUNT = 1000 * 10000;\n    static final String[] arr = new String[MAX_COUNT];\n\n    public static void main(String[] args) {\n        Integer [] data = new Integer[]{1,2,3,4,5,6,7,8,9,10};\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < MAX_COUNT; i++) {\n            arr[i] = new String(String.valueOf(data[i%data.length])).intern();\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(\"花费的时间为：\" + (end - start));\n\n        try {\n            Thread.sleep(1000000);\n        } catch (Exception e) {\n            e.getStackTrace();\n        }\n    }\n}\n```\n\n**结论**：对于程序中大量使用存在的字符串时，尤其存在很多已经重复的字符串时，**使用 `intern()` 方法能够节省内存空间**，因为其将冗余的对象都GC，只在常量池里保存一份字符串数据。\n\n大的网站平台，需要内存中存储大量的字符串。比如社交网站，很多人都存储：北京市、海淀区等信息。这时候如果字符串都调用 `intern()` 方法，就会很明显降低内存的大小。\n\n## String 相关的面试题\n\n### new String(\"ab\") 会创建几个对象\n\n```java\n/**\n * 题目：\n * new String(\"ab\")会创建几个对象？看字节码，就知道是两个。\n *     一个对象是：new关键字在堆空间创建的\n *     另一个对象是：字符串常量池中的对象\"ab\"。 字节码指令：ldc\n *\n */\npublic class StringNewTest {\n    public static void main(String[] args) {\n        String str = new String(\"ab\");\n    }\n}\n```\n\n我们转换成字节码来查看\n\n```\n 0 new #2 <java/lang/String>\n 3 dup\n 4 ldc #3 <ab>\n 6 invokespecial #4 <java/lang/String.<init>>\n 9 astore_1\n10 return\n```\n\n这里面就是两个对象\n\n- 一个对象是：new关键字在堆空间中创建\n- 另一个对象：字符串常量池中的对象\n\n### new String(\"a\") + new String(\"b\") 会创建几个对象\n\n```java\n/**\n * 思考：\n * new String(\"a\") + new String(\"b\")呢？\n *  对象1： new StringBuilder()\n *  对象2： new String(\"a\")\n *  对象3： 常量池中的\"a\"\n *  对象4： new String(\"b\")\n *  对象5： 常量池中的\"b\"\n *\n *  深入剖析： StringBuilder的toString():\n *       对象6 ：new String(\"ab\")\n *       强调一下，toString()的调用，在字符串常量池中，没有生成\"ab\"\n *\n */\npublic class StringNewTest {\n    public static void main(String[] args) {\n        String str = new String(\"a\") + new String(\"b\");\n    }\n}\n```\n\n字节码文件为\n\n```\n 0 new #2 <java/lang/StringBuilder>\n 3 dup\n 4 invokespecial #3 <java/lang/StringBuilder.<init>>\n 7 new #4 <java/lang/String>\n10 dup\n11 ldc #5 <a>\n13 invokespecial #6 <java/lang/String.<init>>\n16 invokevirtual #7 <java/lang/StringBuilder.append>\n19 new #4 <java/lang/String>\n22 dup\n23 ldc #8 <b>\n25 invokespecial #6 <java/lang/String.<init>>\n28 invokevirtual #7 <java/lang/StringBuilder.append>\n31 invokevirtual #9 <java/lang/StringBuilder.toString>\n34 astore_1\n35 return\n```\n\n我们创建了6个对象\n\n- 对象1：new StringBuilder()\n- 对象2：new String(\"a\")\n- 对象3：常量池的 a\n- 对象4：new String(\"b\")\n- 对象5：常量池的 b\n- 对象6：toString中会创建一个 new String(\"ab\")\n  - 调用toString方法，不会在常量池中生成ab\n\n字节码指令分析：\n\n1. `0 new #2 <java/lang/StringBuilder>` ：拼接字符串会创建一个 `StringBuilder` 对象\n2. `7 new #4 <java/lang/String>` ：创建 String 对象，对应于 `new String(\"a\")`\n3. `11 ldc #5 <a>` ：在字符串常量池中放入 `\"a\"`（如果之前字符串常量池中没有 `\"a\"` 的话）\n4. `19 new #4 <java/lang/String>` ：创建 String 对象，对应于 `new String(\"b\")`\n5. `23 ldc #8 <b>` ：在字符串常量池中放入 `\"b\"`（如果之前字符串常量池中没有 `\"b\"` 的话）\n6. `31 invokevirtual #9 <java/lang/StringBuilder.toString>` ：调用 `StringBuilder` 的 `toString() `方法，会生成一个 String 对象\n\n但是需要注意，`StringBuilder` 的 `toString() `方法是直接将其内维护的 `char[] value`数组内的元素通过构造器赋值给新建的 String 对象，而并没有以字面量的形式出现这个拼接后的字符串，因此不会在字符串常量池中创建 `\"ab\"` 对象，只有通过 `intern()` 方法才会将该对象存储到常量池中。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/0012.png)\n\n### intern() 相关的面试题\n\n```java\n/**\n * 如何保证变量s指向的是字符串常量池中的数据呢？\n * 有两种方式：\n * 方式一： String s = \"shkstart\"; // 字面量定义的方式\n * 方式二： 调用intern()\n *         String s = new String(\"shkstart\").intern();\n *         String s = new StringBuilder(\"shkstart\").toString().intern();\n *\n */\npublic class \tStringIntern {\n    public static void main(String[] args) {\n\n        String s = new String(\"1\");\n        s.intern();//调用此方法之前，字符串常量池中已经存在了\"1\"\n        String s2 = \"1\";\n        System.out.println(s == s2);//jdk6：false   jdk7/8：false\n\n        /*\n         1、s3变量记录的地址为：new String(\"11\")\n         2、经过上面的分析，我们已经知道执行完pos_1的代码，在堆中有了一个new String(\"11\")\n         这样的String对象。但是在字符串常量池中没有\"11\"\n         3、接着执行s3.intern()，在字符串常量池中生成\"11\"\n           3-1、在JDK6的版本中，字符串常量池还在永久代，所以直接在永久代生成\"11\",也就有了新的地址\n           3-2、而在JDK7的后续版本中，字符串常量池被移动到了堆中，此时堆里已经有new String（\"11\"）了\n           出于节省空间的目的，直接将堆中的那个字符串的引用地址储存在字符串常量池中。没错，字符串常量池中存的是new String(\"11\")在堆中的地址\n         4、所以在JDK7后续版本中，s3和s4指向的完全是同一个地址。\n         */\n        String s3 = new String(\"1\") + new String(\"1\");//pos_1\n        s3.intern();\n\n        String s4 = \"11\";//s4变量记录的地址：使用的是上一行代码代码执行时，在常量池中生成的\"11\"的地址\n        System.out.println(s3 == s4);//jdk6：false  jdk7/8：true\n    }\n}\n```\n\n解释的已经比较清楚了，下面看一下内存图\n\n**内存分析**\n\nJDK 6 ：正常眼光判断即可\n\n- `new String()` 即在堆中\n- `str.intern()` 则把字符串放入常量池中\n\n因为 JDK 6 中字符串常量池存储在永久代，其不在堆中，因此就是单纯的将字符串放到常量池中（不像 JDK 7 后的操作，将引用保存在常量池里）\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/0013.png)\n\nJDK 7 及后续版本，**注意大坑**：因为字符串常量池移动到了堆区，因此为了节省空间，就不再常量池里拷贝一份字符串副本了，而是直接创建一个对象引用已经存在于堆区中的字符串对象（后续再引用该常量池里的对象时，其地址直接等于了存在于堆区的对象）\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/0014.png)\n\n#### 面试题的拓展\n\n```java\n/**\n * StringIntern.java中练习的拓展：\n *\n */\npublic class StringIntern1 {\n    public static void main(String[] args) {\n        //执行完下一行代码以后，字符串常量池中，是否存在\"11\"呢？答案：不存在！！\n        String s3 = new String(\"1\") + new String(\"1\");//new String(\"11\")\n        //在字符串常量池中生成对象\"11\"，代码顺序换一下，实打实的在字符串常量池里有一个\"11\"对象\n        String s4 = \"11\";  \n        String s5 = s3.intern();\n\n        // s3 是堆中的 \"ab\" ，s4 是字符串常量池中的 \"ab\"\n        System.out.println(s3 == s4);//false\n\n        // s5 是从字符串常量池中取回来的引用，当然和 s4 相等\n        System.out.println(s5 == s4);//true\n    }\n}\n```\n\n### intern() 方法的练习\n\n**练习 1**\n\n```java\npublic class StringExer1 {\n  public static void main(String[] args) {\n\n    String s = new String(\"a\") + new String(\"b\");//new String(\"ab\")\n    //在上一行代码执行完以后，字符串常量池中并没有\"ab\"\n    /*\n\t\t1、jdk6中：在字符串常量池（此时在永久代）中创建一个字符串\"ab\"\n        2、jdk8中：字符串常量池（此时在堆中）中没有创建字符串\"ab\",而是创建一个引用，指向new String(\"ab\")，\t\t  将此引用返回\n        3、详解看上面\n\t\t*/\n    String s2 = s.intern();\n\n    System.out.println(s2 == \"ab\"); // jdk6:true  jdk8:true\n    System.out.println(s == \"ab\");  // jdk6:false  jdk8:true\n  }\n}\n```\n\n**JDK 6**\n\n[![image-20201116113423492](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/0015.png)](https://cdn.jsdelivr.net/gh/youthlql/lqlp@v1.1.0/JVM/chapter_009/0015.png)\n\n**JDK 7/8**\n\n![image-20200711151326909](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20200711151326909.png)\n\n**练习 2**\n\n```java\npublic class StringExer1 {\n    public static void main(String[] args) {\n        // 相比于 练习1 多了这一行\n        String x = \"ab\";\n        String s = new String(\"a\") + new String(\"b\");//new String(\"ab\")\n\n        String s2 = s.intern();\n\n        System.out.println(s2 == \"ab\"); // jdk6:true  jdk8:true\n        System.out.println(s == \"ab\");  // jdk6:false  jdk8:false\n    }\n}\n```\n\n这种情况下，因为已经使用字面量的形式将 `\"ab\"` 添加到了常量池中，所以后续的 `intern()` 就不会再像 练习1 一样指向 `s` 了\n\n![image-20200711151433277](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0/image-20200711151433277.png)\n\n**练习 3**\n\n```java\npublic class StringExer2 {\n    public static void main(String[] args) {\n        String s1 = new String(\"ab\");//执行完以后，会在字符串常量池中会生成\"ab\"\n\n        // 注意没有返回值时，s1指向的仍然不变\n        // 只有intern()方法的返回值才会指向常量池里的地址，调用者自身不会改变地址\n        s1.intern();\n        String s2 = \"ab\";\n        System.out.println(s1 == s2); // false\n    }\n}\n```\n\n**练习 4**\n\n```java\npublic class StringExer2 {\n    // 对象内存地址可以使用System.identityHashCode(object)方法获取\n    public static void main(String[] args) {\n        String s1 = new String(\"a\") + new String(\"b\");//执行完以后，不会在字符串常量池中会生成\"ab\"\n        System.out.println(System.identityHashCode(s1));\n\n        // 注意，上面拼接的方式没有在常量池中创建字符串\n        // 因此这里会在常量池里创建对象引用 s1\n        s1.intern();\n        System.out.println(System.identityHashCode(s1));\n\n        String s2 = \"ab\";\n        System.out.println(System.identityHashCode(s2));\n        System.out.println(s1 == s2); // true\n    }\n}\n```\n\n输出结果：\n\n```\n1836019240\n1836019240\n1836019240\ntrue\n```\n\n## 字符串常量池 StringTable 的垃圾回收\n\n```java\n/**\n * String的垃圾回收\n * -Xms15m -Xmx15m -XX:+PrintStringTableStatistics -XX:+PrintGCDetails\n */\npublic class StringGCTest {\n    public static void main(String[] args) {\n        for (int i = 0; i < 100000; i++) {\n            String.valueOf(i).intern();\n        }\n    }\n}\n```\n\n## G1 中的 String 去重操作\n\n注意这里说的重复，指的是在堆中的数据，而不是常量池中的，因为常量池中的本身就不会重复\n\n### 描述\n\n背景：对许多Java应用（有大的也有小的）做的测试得出以下结果：\n\n- 堆存活数据集合里面String对象占了25%\n- 堆存活数据集合里面重复的String对象有13.5%\n- String对象的平均长度是45\n\n许多大规模的Java应用的瓶颈在于内存，测试表明，在这些类型的应用里面，Java堆中存活的数据集合差不多25%是String对象。更进一步，这里面差不多一半String对象是重复的。堆上存在重复的String对象必然是一种内存的浪费。这个项目将在G1垃圾收集器中实现自动持续对重复的String对象进行去重，这样就能避免浪费内存。\n\n### 实现\n\n- 当垃圾收集器工作的时候，会访问堆上存活的对象。对每一个访问的对象都会检查是否是候选的要去重的String对象。\n- 如果是，把这个对象的一个引用插入到队列中等待后续的处理。一个去重的线程在后台运行，处理这个队列。处理队列的一个元素意味着从队列删除这个元素，然后尝试去重它引用的String对象。\n- 使用一个Hashtable来记录所有的被String对象使用的不重复的char数组。当去重的时候，会查这个Hashtable，来看堆上是否已经存在一个一模一样的char数组。\n- 如果存在，String对象会被调整引用那个数组，释放对原来的数组的引用，最终会被垃圾收集器回收掉。\n- 如果查找失败，char数组会被插入到Hashtable，这样以后的时候就可以共享这个数组了。\n\n**命令行选项**\n\n- `UseStringDeduplication(bool) `：开启String去重，默认是不开启的，需要手动开启。\n- `PrintStringDeduplicationStatistics(bool)` ：打印详细的去重统计信息\n- `stringDeduplicationAgeThreshold(uintx) `：达到这个年龄的String对象被认为是去重的候选对象\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 执行引擎","url":"/2021/10/02/【JVM】JVM执行引擎/","content":"\n## 执行引擎概述\n\n执行引擎属于JVM的下层，里面包括**解释器**、**及时编译器**、**垃圾回收器**\n\n![image-20200710080707873](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710080707873.png)\n\n执行引擎是Java虚拟机核心的组成部分之一。\n\n“虚拟机”是一个相对于“物理机”的概念，这两种机器都有代码执行能力，其区别是物理机的执行引擎是直接建立在处理器、缓存、指令集和操作系统层面上的，而**虚拟机的执行引擎则是由软件自行实现的**，因此可以**不受物理条件制约**地定制指令集与执行引擎的结构体系，**能够执行那些不被硬件直接支持的指令集格式**。\n\nJVM的主要任务是负责装载字节码到其内部，但字节码并不能够直接运行在操作系统之上，因为字节码指令并非等价于本地机器指令，它内部包含的仅仅只是一些能够被JVM所识别的字节码指令、符号表，以及其他辅助信息。\n\n那么，如果想要让一个Java程序运行起来，执行引擎（Execution Engine）的任务就是将**字节码指令解释/编译**为对应平台上的本地机器指令才可以。简单来说，JVM中的执行引擎充当了将高级语言翻译为机器语言的译者。\n\n![image-20200710081118053](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710081118053.png)\n\n- 前端编译：从Java程序员-字节码文件的这个过程叫前端编译\n- 执行引擎这里有两种行为：一种是**解释执行**，一种是**编译执行**（被称为后端编译）。\n\n<!-- More -->\n\n### 执行引擎的工作流程\n\n- 执行引擎在执行的过程中究竟需要执行什么样的字节码指令完全依赖于PC寄存器。\n- 每当执行完一项指令操作后，PC寄存器就会更新下一条需要被执行的指令地址。\n- 当然方法在执行的过程中，执行引擎有可能会通过存储在局部变量表中的对象引用准确定位到存储在Java堆区中的对象实例信息，以及通过对象头中的元数据指针定位到目标对象的类型信息。\n\n![image-20200710081627217](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710081627217.png)\n\n从外观上来看，所有的Java虚拟机的执行引擎输入，输出都是一致的：输入的是字节码二进制流，处理过程是字节码解析执行的等效过程，输出的是执行过程。\n\n## Java 代码编译和执行过程\n\n大部分的程序代码转换成物理机的目标代码或虚拟机能执行的指令集之前，都需要经过上图中的各个步骤：\n\n- 前面橙色部分是生成字节码文件的过程，和JVM无关（前端编译）\n- 后面蓝色（后端编译）和绿色（解释器）才是JVM需要考虑的过程\n\n![image-20200710082141643](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710082141643.png)\n\nJava代码编译是由Java源码编译器来完成，流程图如下所示：\n\n![image-20200710082433146](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710082433146.png)\n\n---\n\n具体：\n\n1、准备阶段：初始化插入式注解处理器\n\n2、处理阶段：\n\n- 解析与填充符号表\n  1. **词法分析: 将Java源代码的字符流转变为token(标记)流**\n     - 字符: 程序编写的最小单位\n     - 标记(token) : 编译的最小单位\n     - 比如 关键字 static 是一个标记 / 6个字符\n  2. **语法分析: 将token流构造成抽象语法树**\n  3. **填充符号表: 产生符号信息和符号地址**\n     - 符号表是一组符号信息和符号地址构成的数据结构\n     - 比如: 目标代码生成阶段,对符号名分配地址时,要查看符号表上该符号名对应的符号地址\n- 插入式注解处理器的注解处理\n  1. 注解处理器处理特殊注解: 在编译器允许注解处理器对源代码中特殊注解作处理,可以读写抽象语法树中任意元素,如果发生了写操作,就要重新解析,填充符号表\n     - 比如: Lombok通过特殊注解,生成get/set/构造器等方法\n- 语义分析与字节码生成\n  1. **标注检查: 对语义静态信息的检查以及常量折叠优化**\n\n     ```\n     int i = 1;\n     char c1 = 'a';\n     int i2 = 1 + 2;//编译成 int i2 = 3 常量折叠优化\n     char c2 = i + c1; //编译错误 标注检查 检查语法静态信息 \n     ```\n\n     ![image-20210524202623150](https://gitee.com/tcl192243051/studyJVM/raw/master/2_%E5%AD%97%E8%8A%82%E7%A0%81%E4%B8%8E%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%AF%87/%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E.assets/image-20210524202623150.png)\n\n  2. **数据及控制流分析: 对程序运行时动态检查**\n     \n     - 比如方法中流程控制产生的各条路是否有合适的返回值\n  3. **解语法糖: 将(方便程序员使用的简洁代码)语法糖转换为原始结构**\n  4. **字节码生成: 生成`<init>,<clinit>`方法,并根据上述信息生成字节码文件**\n\n> 总结流程图\n\n![image-20210524205803664](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20210524205803664.png)\n\n> 源码分析\n\n![image-20210524222754508](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20210524222754508.png)\n\n代码位置在JavaCompiler的compile方法中\n\n![image-20210524221445424](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20210524221445424.png)\n\n\n\n\n\n---\n\nJava字节码的执行是由JVM执行引擎来完成，流程图如下所示\n\n![image-20200710083036258](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710083036258.png)\n\n我们用一个总的图，来说说解释器和编译器\n\n![image-20200710083656277](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710083656277.png)\n\n### 什么是解释器（Interpreter）\n\n当Java虚拟机启动时会根据预定义的规范对字节码采用**逐行**解释的方式**执行**，将每条字节码文件中的内容“翻译”为对应平台的本地机器指令执行。\n\n### 什么是 JIT 编译器\n\nJIT（Just In Time Compiler）编译器：就是虚拟机将源代码里的一些**常用方法和循环体**一次性直接编译成和本地机器平台相关的机器语言，**但并不是马上执行**。\n\n### 为什么 Java 是半编译半解释型语言\n\n1. JDK 1.0时代，将Java语言定位为“解释执行”还是比较准确的。再后来，Java也发展出可以直接生成本地代码的编译器。\n2. 现在JVM在执行Java代码的时候，**通常都会将解释执行与编译执行二者结合起来进行。**\n3. JIT编译器将字节码翻译成本地代码后，就可以做一个**缓存**操作，**存储在方法区的JIT 代码缓存中**（执行效率更高了），并且在翻译成本地代码的过程中可以做优化。\n\n## 机器码、指令、汇编语言\n\n### 机器码\n\n各种用二进制编码方式表示的指令，叫做机器指令码。开始，人们就用它采编写程序，这就是机器语言。\n\n机器语言虽然能够被计算机理解和接受，但和人们的语言差别太大，不易被人们理解和记忆，并且用它编程容易出差错。\n\n用它编写的程序一经输入计算机，CPU直接读取运行，因此和其他语言编的程序相比，执行速度最快。\n\n机器指令与CPU紧密相关，所以不同种类的CPU所对应的机器指令也就不同。\n\n### 指令\n\n由于机器码是有0和1组成的二进制序列，可读性实在太差，于是人们发明了指令。\n\n指令就是把机器码中特定的0和1序列，简化成对应的指令（一般为英文简写，如mov，inc等），可读性稍好\n\n由于不同的硬件平台，执行同一个操作，对应的机器码可能不同，所以不同的硬件平台的同一种指令（比如mov），对应的机器码也可能不同。\n\n### 指令集\n\n不同的硬件平台，各自支持的指令，是有差别的。因此每个平台所支持的指令，称之为对应平台的指令集。\n如常见的\n\n- x86指令集，对应的是x86架构的平台\n- ARM指令集，对应的是ARM架构的平台\n\n### 汇编语言\n\n由于指令的可读性还是太差，于是人们又发明了汇编语言。\n\n在汇编语言中，用助记符（Memonics）代替机器指令的操作码，用地址符号（Symbol）或标号（Label）代替指令或操作数的地址。在不同的硬件平台，汇编语言对应着不同的机器语言指令集，通过汇编过程转换成机器指令。\n\n>由于计算机只认识指令码，所以用汇编语言编写的程序还必须翻译成机器指令码，计算机才能识别和执行。\n\n### 高级语言\n\n为了使计算机用户编程序更容易些，后来就出现了各种高级计算机语言。\n\n高级语言比机器语言、汇编语言更接近人的语言当计算机执行高级语言编写的程序时，仍然需要把程序解释和编译成机器的指令码。完成这个过程的程序就叫做解释程序或编译程序。\n\n![image-20200710085323733](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710085323733.png)\n\n高级语言也不是直接翻译成 机器指令，而是翻译成汇编语言吗，如下面说的C和C++\n\n### 字节码\n\n字节码是一种中间状态（中间码）的二进制代码（文件），它比机器码更抽象，需要直译器转译后才能成为机器码\n\n字节码主要为了实现特定软件运行和软件环境、与硬件环境无关。\n\n字节码的实现方式是通过编译器和虚拟机器。编译器将源码编译成字节码，特定平台上的虚拟机器将字节码转译为可以直接执行的指令。\n\n- 字节码典型的应用为：Java bytecode\n\n### C、C++源程序执行过程\n\n编译过程又可以分成两个阶段：编译和汇编。\n\n- 编译过程：是读取源程序（字符流），对之进行词法和语法的分析，将高级语言指令转换为功能等效的汇编代码\n- 汇编过程：实际上指把汇编语言代码翻译成目标机器指令的过程。\n\n![image-20200710085553258](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710085553258.png)\n\n## 解释器\n\nJVM设计者们的初衷仅仅只是单纯地为了满足Java程序实现跨平台特性，因此**避免采用静态编译的方式直接生成本地机器指令**，从而诞生了实现解释器在运行时采用逐行解释字节码执行程序的想法。\n\n![image-20200710090203674](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710090203674.png)\n\n为什么Java源文件不直接翻译成机器码，而是翻译成字节码文件？可能是因为直接翻译的代码是比较大的或者如果直接翻译成机器码，就失去了跨平台特性，因为不同平台的机器码可能是不一样的，如果直接前端编译期就把源代码编译成了机器码，那么可能就不能跨平台了。\n\n解释器真正意义上所承担的角色就是一个运行时“翻译者”，**将字节码文件中的内容“翻译”为对应平台的本地机器指令执行**。\n\n当一条字节码指令被解释执行完成后，接着再根据PC寄存器中记录的下一条需要被执行的字节码指令执行解释操作。\n\n### 解释器分类\n\n在Java的发展历史里，一共有两套解释执行器，即古老的字节码解释器、现在普遍使用的**模板解释器**。\n\n- 字节码解释器在执行时通过纯软件代码模拟字节码的执行，效率非常低下。\n- 而模板解释器将每一条字节码和一个模板函数相关联，模板函数中直接产生这条字节码执行时的机器码，从而很大程度上提高了解释器的性能。\n\n在HotSpot VM中，解释器主要由Interpreter模块和Code模块构成。\n\n- Interpreter模块：实现了解释器的核心功能\n- Code模块：用于管理HotSpot VM在运行时生成的本地机器指令\n\n### 现状\n\n由于解释器在设计和实现上非常简单，因此除了Java语言之外，还有许多高级语言同样也是基于解释器执行的，比如Python、Perl、Ruby等。但是在今天，基于解释器执行已经沦落为低效的代名词，并且时常被一些C/C++程序员所调侃。\n\n为了解决这个问题，JVM平台支持一种叫作**即时编译**的技术。**即时编译的目的是避免函数被解释执行，而是将整个函数体编译成为机器码**，每次函数执行时，只执行编译后的机器码即可，这种方式可以使执行效率大幅度提升。\n\n不过无论如何，基于解释器的执行模式仍然为中间语言的发展做出了不可磨灭的贡献。\n\n## JIT 编译器\n\nJIT 编译器可以将代码中的一些**常用方法和循环体**编译成机器码，并达到一定条件后**缓存到方法区内**，这样之后再运行这些方法和循环体时直接从**方法区内**获取这些机器码执行，效率就会非常高（HotSpot JDK 8以后元空间使用**本地内存**，访问更快速）。\n\n但是在程序启动前期，系统还处于预热状态，这时JIT方式的效率较低，此时就需要解释器帮忙分摊一些压力，待程序运行时间稍长一些后，一些常用方法和循环体就达到了热点代码的条件，即可被缓存起来，后续执行就会非常迅速。\n\n> 最佳实践：在应用正式上线前，可以先使用jmeter对核心接口进行压测，让JIT编译器进行“热身”，将一些常用的方法和循环体编译成机器码并缓存到方法区中，以提高应用上线后的执行效率。\n\nJIT 编译器的执行流程见[方法调用计数器](#方法调用计数器)。\n\n### Java 代码的执行分类\n\n- 第一种是将源代码编译成字节码文件（前端编译），然后在运行时通过解释器将字节码文件转为机器码执行（解释阶段）\n- 第二种是后端编译执行（直接编译成机器码）。现代虚拟机为了提高执行效率，会使用即时编译技术（JIT，Just In Time）将一些**常用的方法或循环体**编译成机器码后再执行\n\nHotSpot VM是目前市面上高性能虚拟机的代表作之一。它采用解释器与即时编译器并存的架构。在Java虚拟机运行时，**解释器和即时编译器能够相互协作，各自取长补短，尽力去选择最合适的方式来权衡编译本地代码的时间和直接解释执行代码的时间**。\n\n在今天，Java程序的运行性能早已脱胎换骨，已经达到了可以和C/C++ 程序一较高下的地步。\n\n### 问题来了\n\n有些开发人员会感觉到诧异，既然HotSpot VM中已经内置JIT编译器了，那么为什么还需要再使用解释器来“拖累”程序的执行性能呢？比如JRockit VM内部就不包含解释器，字节码全部都依靠即时编译器编译后执行。\n\nJRockit虚拟机是砍掉了解释器，也就是只采及时编译器。那是因为呢JRockit只部署在服务器上，一般已经有时间让他进行指令编译的过程了，对于响应来说要求不高，等及时编译器的编译完成后，就会提供更好的性能\n\n**首先明确两点：**\n\n- 当程序启动后，解释器可以马上发挥作用，**响应速度快**，省去编译的时间，立即执行。\n- JIT编译器要想发挥作用，把一些**常用的方法或循环体**编译成本地代码，**需要一定的执行时间**，但编译为本地代码并缓存后，执行效率高。\n\n**所以：**\n\n- 尽管JRockit VM中程序的执行性能会非常高效，但程序在启动时必然需要花费更长的时间来进行编译。对于服务端应用来说，启动时间并非是关注重点，但对于那些看中启动时间的应用场景而言，或许就需要采用解释器与即时编译器并存的架构来换取一个平衡点。\n- 在此模式下，**当Java虚拟器启动时，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成后再执行，这样可以省去许多不必要的编译时间。随着时间的推移，编译器发挥作用，把越来越多的代码编译成本地代码并缓存，获得更高的执行效率**。\n- 同时，解释执行在编译器进行激进优化不成立的时候，作为编译器的“逃生门”（后备方案）。\n\n### HotSpot JVM 执行方式\n\n当虚拟机启动的时候，解释器可以首先发挥作用，而不必等待即时编译器全部编译完成再执行，这样可以省去许多不必要的编译时间。并且随着程序运行时间的推移，即时编译器逐渐发挥作用，根据**热点探测功能**，将有价值的字节码编译为本地机器指令，以换取更高的程序执行效率。\n\n### 案例\n\n注意解释执行与编译执行在线上环境微妙的辩证关系。**机器在热机状态（已经运行了一段时间叫热机状态）可以承受的负载要大于冷机状态（刚启动的时候叫冷机状态）**。如果以热机状态时的流量进行切流，可能使处于冷机状态的服务器因无法承载流量而假死。\n\n在生产环境发布过程中，以分批的方式进行发布，根据机器数量划分成多个批次，每个批次的机器数至多占到整个集群的1/8。曾经有这样的故障案例：某程序员在发布平台进行分批发布，在输入发布总批数时，误填写成分为两批发布。如果是热机状态，在正常情况下一半的机器可以勉强承载流量，但由于刚启动的JVM均是解释执行，还没有进行热点代码统计和JIT动态编译，导致机器启动之后，当前1/2发布成功的服务器马上全部宕机，此故障说明了JIT的存在。—**阿里团队**\n\n![image-20200710095417462](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710095417462.png)\n\n### 概念解释\n\nJava 语言的“编译期”其实是一段“不确定”的操作过程，\n\n- 因为它可能是指一个前端编译器（其实叫“编译器的前端”更准确一些）把.java文件转变成.class文件的过程。\n- 也可能是指虚拟机的后端运行期编译器（JIT编译器，Just In Time Compiler）把字节码转变成机器码的过程。\n- 还可能是指使用静态提前编译器（AOT编译器，Ahead of Time Compiler）直接把.java文件编译成本地机器代码的过程。（可能是后续发展的趋势）\n\n**典型的编译器：**\n\n- 前端编译器：Sun的javac、Eclipse JDT中的增量式编译器（ECJ）。\n- JIT编译器：HotSpot VM的C1、C2编译器。\n- AOT 编译器：GNU Compiler for the Java（GCJ）、Excelsior JET。\n\n### 热点探测技术\n\n一个被多次调用的**方法**，或者是一个方法体内部循环次数较多的**循环体**都可以被称之为“**热点代码**”，因此都可以通过JIT编译器编译为本地机器指令。由于这种编译方式发生在方法的执行过程中，因此被称之为栈上替换，或简称为OSR（On Stack Replacement）编译。\n\n一个方法究竟要被调用多少次，或者一个循环体究竟需要执行多少次循环才可以达到这个标准？必然需要一个明确的阈值，JIT编译器才会将这些“热点代码”编译为本地机器指令执行。这里主要依靠**热点探测功能**。\n\n目前HotSpot VM所采用的热点探测方式是**基于计数器**的热点探测。\n\n采用基于计数器的热点探测，HotSpot V将会为每一个方法都建立2个不同类型的计数器，分别为**方法调用计数器**（Invocation Counter）和**回边计数器**（Back Edge Counter）。\n\n- 方法调用计数器用于统计方法的调用次数\n- 回边计数器则用于统计循环体执行的循环次数\n\n### 方法调用计数器\n\n1. 这个计数器就用于统计方法被调用的次数，它的默认阀值在Client模式下是1500次，在Server模式下是10000次。超过这个阈值，就会触发JIT编译。\n2. 这个阀值可以通过虚拟机参数 `-XX:CompileThreshold` 来人为设定。\n3. 当一个方法被调用时，会先检查该方法是否存在被JIT编译过的版本\n   - 如果存在，则优先使用编译后的本地代码来执行\n   - 如果不存在已被编译过的版本，则将此方法的调用计数器值加1，然后判断方法调用计数器与回边计数器值之和是否超过方法调用计数器的阀值。\n     - 如果已超过阈值，那么将会向即时编译器提交一个该方法的代码编译请求。\n     - 如果未超过阈值，则**使用解释器**对字节码文件解释执行\n\n![image-20200710101829934](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710101829934.png)\n\n\n\n### 热点衰减\n\n 如果不做任何设置，方法调用计数器统计的并不是方法被调用的绝对次数，而是一个相对的执行频率，即**一段时间之内方法被调用的次数**。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的调用计数器就会被减少一半，这个过程称为方法调用计数器热度的衰减（Counter Decay），而这段时间就称为此方法统计的半衰周期（Counter Half Life Time）\n\n- 半衰周期是化学中的概念，比如出土的文物通过查看C60来获得文物的年龄\n\n进行热度衰减的动作是在虚拟机进行垃圾收集时顺便进行的，可以使用虚拟机参数\n`-XX:-UseCounterDecay` 来关闭热度衰减，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码。\n\n另外，可以使用`-XX:CounterHalfLifeTime`参数设置半衰周期的时间，单位是秒。\n\n### 回边计数器\n\n它的作用是统计一个方法中循环体代码执行的次数，在字节码中遇到控制流向后跳转的指令称为“回边”（Back Edge）。显然，建立回边计数器统计的目的就是为了触发OSR编译。\n\n![image-20200710103103869](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710103103869.png)\n\n### HotSpotVM 可以设置程序执行方法\n\n缺省情况下HotSpot VM是采用解释器与即时编译器并存的架构，当然开发人员可以根据具体的应用场景，通过命令显式地为Java虚拟机指定在运行时到底是完全采用解释器执行，还是完全采用即时编译器执行。如下所示：\n\n- `-Xint`：完全采用解释器模式执行程序；\n- `-Xcomp`：完全采用即时编译器模式执行程序。如果即时编译出现问题，解释器会介入执行\n- `-Xmixed`：采用解释器+即时编译器的混合模式共同执行程序。\n\n![image-20200710103340273](/images/%E3%80%90JVM%E3%80%91JVM%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E/image-20200710103340273.png)\n\n\n\n### HotSpotVM中 JIT 分类\n\nJIT的编译器还分为了两种，分别是C1和C2，在HotSpot VM中内嵌有两个JIT编译器，分别为Client Compiler和Server Compiler，但大多数情况下我们简称为 C1编译器 和 C2编译器。开发人员可以通过如下命令显式指定Java虚拟机在运行时到底使用哪一种即时编译器，如下所示：\n\n- `-client`：指定Java虚拟机运行在Client模式下，并使用C1编译器；\n  - C1编译器会对字节码进行简单和可靠的优化，耗时短。以达到更快的编译速度。\n\n- `-server`：指定Java虚拟机运行在server模式下，并使用C2编译器。\n  - C2进行耗时较长的优化，以及激进优化。但优化的代码执行效率更高。（使用C++）\n\n### C1 和 C2 编译器不同的优化策略\n\n在不同的编译器上有不同的优化策略，C1编译器上主要有方法内联，去虚拟化、元余消除。\n\n- 方法内联：将引用的函数代码编译到引用点处，这样可以减少栈帧的生成，减少参数传递以及跳转过程\n- 去虚拟化：对唯一的实现方法进行内联\n- 冗余消除：在运行期间把一些不会执行的代码折叠掉\n\nC2的优化主要是在全局层面，逃逸分析是优化的基础。基于逃逸分析在C2上有如下几种优化：\n\n- 标量替换：用标量值代替聚合对象的属性值\n- 栈上分配：对于未逃逸的对象分配对象在栈而不是堆\n- 同步消除：清除同步操作，通常指synchronized\n\n### 分层编译策略\n\n分层编译（Tiered Compilation）策略：程序解释执行（不开启性能监控）可以触发C1编译，将字节码编译成机器码，可以进行简单优化，也可以加上性能监控，C2编译会根据性能监控信息进行激进优化。\n\n不过在Java7版本之后，一旦开发人员在程序中显式指定命令“-server\"时，默认将会开启分层编译策略，由C1编译器和C2编译器相互协作共同来执行编译任务。\n\n### 总结\n\n- 一般来讲，JIT编译出来的机器码性能比解释器高\n- C2编译器启动时长比C1慢，系统稳定执行以后，C2编译器执行速度远快于C1编译器\n\n### AOT 编译器\n\njdk 9引入了AOT编译器（静态提前编译器，Ahead of Time Compiler）\n\nJava 9引入了实验性AOT编译工具aotc。它借助了Graal编译器，将所输入的Java类文件转换为机器码，并存放至生成的动态共享库之中。\n\n所谓AOT编译，是与即时编译相对立的一个概念。我们知道，即时编译指的是在程序的运行过程中，将字节码转换为可在硬件上直接运行的机器码，并部署至托管环境中的过程。而AOT编译指的则是，在程序运行之前，便将字节码转换为机器码的过程。\n\n```\n.java -> .class -> (使用jaotc) -> .so\n```\n\n最大的好处：Java虚拟机加载已经预编译成二进制库，可以直接执行。不必等待及时编译器的预热，减少Java应用给人带来“第一次运行慢” 的不良体验\n\n缺点：\n\n- 破坏了 java  “ 一次编译，到处运行”，必须为每个不同的硬件，OS编译对应的发行包\n- 降低了Java链接过程的动态性，加载的代码在编译器就必须全部已知。\n- 还需要继续优化中，最初只支持Linux X64 java base\n\n### 写到最后\n\n- 自JDK 10起，HotSpot又加入了一个全新的及时编译器：Graal编译器\n- 编译效果短短几年时间就追评了C2编译器，未来可期\n- 目前，带着实验状态标签，需要使用开关参数去激活才能使用\n\n```\n-XX:+UnlockExperimentalvMOptions -XX:+UseJVMCICompiler\n```","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 对象实例化过程","url":"/2021/10/01/【JVM】JVM对象实例化过程/","content":"\n## 对象实例化\n\n### 面试题\n\n- 对象在JVM中是怎么存储的？\n- **对象头**信息里面有哪些东西？\n- Java对象头有什么？\n\n![image-20200709095356247](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709095356247.png)\n\n## 对象创建方式\n\n- new：最常见的方式、单例类中调用`getInstance()`的静态类方法，`XxxFactory`的静态方法\n- Class的`newInstance()`方法：在JDK 9 里面被标记为过时的方法，因为只能调用空参构造器\n- Constructor的`newInstance(xxx)`：**反射**的方式，可以调用空参的，或者带参的构造器\n- 使用`clone()`：不调用任何的构造器，要求当前的类需要实现`Cloneable`接口中的`clone()`接口（`Cloneable`接口只是标识接口，不带任何方法，实际上是重写 Object 父类的 `clone()` 方法，这属于原型模式）\n- 使用**序列化**：序列化一般用于`Socket`的网络传输\n- 第三方库 `Objenesis`\n\n## 创建对象的步骤\n\n### 对象实例化的过程\n\n- 加载类元信息\n- 为对象分配内存\n- 处理并发问题\n- 属性的默认初始化（只进行零值初始化）\n- 设置对象头信息\n- `init()` 方法：属性的显示初始化、代码块中初始化、构造器中初始化\n\n### 为对象属性赋值的顺序\n\n给对象的属性赋值的操作：\n\n *  属性的默认初始化\n *  属性的显式初始化 / 代码块中初始化（执行顺序取决于代码中的编写顺序）\n *  构造器中初始化\n\n<!-- More -->\n\n> 从字节码角度看对象的实例化过程\n\n```java\n/**\n * 测试对象实例化的过程\n *  ① 加载类元信息 - ② 为对象分配内存 - ③ 处理并发问题  - ④ 属性的默认初始化（零值初始化）\n *  - ⑤ 设置对象头的信息 - ⑥ 属性的显式初始化、代码块中初始化、构造器中初始化\n *\n *\n *  给对象的属性赋值的操作：\n *  ① 属性的默认初始化 - ② 显式初始化 / ③ 代码块中初始化 - ④ 构造器中初始化\n */\n\npublic class Customer{\n    int id = 1001;\n    String name;\n    Account acct;\n\n    {\n        name = \"匿名客户\";\n    }\n    public Customer(){\n        acct = new Account();\n    }\n\n}\nclass Account{\n\n}\n```\n\n**Customer 类 init() 方法的字节码**\n\n```\n 0 aload_0\n 1 invokespecial #1 <java/lang/Object.<init>>\n 4 aload_0\n 5 sipush 1001\n 8 putfield #2 <com/atguigu/java/Customer.id>\n11 aload_0\n12 ldc #3 <匿名客户>\n14 putfield #4 <com/atguigu/java/Customer.name>\n17 aload_0\n18 new #5 <com/atguigu/java/Account>\n21 dup\n22 invokespecial #6 <com/atguigu/java/Account.<init>>\n25 putfield #7 <com/atguigu/java/Customer.acct>\n28 return\n```\n\n`init()` 方法的字节码指令：\n\n- 属性的显式初始化：`id = 1001;`\n- 代码块的显式初始化：`name = \"匿名客户\";`\n- 构造器初始化：`acct = new Account();`\n\n下面详细介绍每个步骤：\n\n#### 1、判断对象对应的类是否加载、链接、初始化\n\n虚拟机遇到一条new指令，首先去检查这个指令的参数能否在Metaspace的常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类**是否已经被加载，解析和初始化**。即**判断类元信息是否存在**。\n\n如果没有，那么在双亲委派模式下，使用当前类加载器以ClassLoader + 包名 + 类名为key进行查找对应的 `.class` 文件，如果没有找到文件，则抛出 `ClassNotFoundException` 异常，如果找到，则进行类加载，并生成对应的Class对象。\n\n#### 2、为对象分配内存\n\n首先计算对象占用空间的大小，接着**在堆中划分一块内存**给新对象。如果实例成员变量是引用变量，仅分配引用变量空间即可，即4个字节大小\n\n- 如果内存规整：指针碰撞（对应垃圾回收算法里的**复制算法**）\n  - 如果内存是规整的，那么虚拟机将采用的是**指针碰撞法**（Bump The Point）来为对象分配内存。\n  - 意思是**所有用过的内存在一边，空闲的内存放另外一边，中间放着一个指针作为分界点的指示器**，分配内存就仅仅是把指针往空闲内存那边挪动一段与对象大小相等的距离罢了。\n  - 如果垃圾收集器选择的是Serial ，ParNew这种基于压缩算法的，虚拟机采用这种分配方式。一般使用带Compact（整理）过程的收集器时，使用指针碰撞。\n  - 标记压缩（整理）算法会整理内存碎片，堆内存一存对象，另一边为空闲区域\n- 如果内存不规整：虚拟表需要维护一个列表、使用**空闲列表**分配（对应垃圾回收算法里的**标记清除算法**）\n  - 如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是**空闲列表**来为对象分配内存。\n  - 意思是虚拟机**维护了一个列表**，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。这种分配方式成为了 “空闲列表（Free List）”\n  - 标记清除算法清理过后的堆内存，就会存在很多内存碎片。\n\n选择哪种分配方式由Java堆是否规整所决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n\n#### 3、堆中开辟空间时处理并发问题\n\n- 采用**CAS+失败重试**保证更新的**原子性**\n- 每个线程预先分配**TLAB** - 通过设置 `-XX:+UseTLAB` 参数来设置（区域加锁机制），TLAB（Thread Local Allocation Buffer） 是每个线程独享的，在Eden区给每个线程分配一块区域，在其内开辟空间是**线程安全**的。\n\n#### 4、初始化分配到的内存空间\n\n该步骤为所有属性设置**默认值**，保证对象实例字段在不赋值也可以直接使用。\n\n注意：这一步只为属性进行**默认初始化**（即为属性**赋零值**），显式赋值在 `init()` 方法调用步骤才执行。\n\n#### 5、设置对象的对象头\n\n将对象的所属类（即**类的元数据信息**）、对象的**HashCode**和对象的**GC信息**、**锁信息**等数据存储在对象的对象头中。这个过程的具体设置方式取决于JVM实现。\n\n#### 6、执行 init 方法进行初始化\n\n在Java程序的视角看来，初始化才正式开始。**初始化成员变量**，**执行实例化代码块**，**调用类的构造方法**，并把堆内对象的首地址赋值给引用变量。\n\n`init()` 初始化的步骤：\n\n- 属性的显式初始化 / 代码块初始化，这里才为属性赋上程序中写的值（并列关系，谁先谁后看代码编写的顺序）\n- 构造器初始化\n\n因此一般来说（由字节码中跟随`invokespecial`指令所决定），new指令之后会接着就是执行方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完成创建出来。\n\n\n\n## 对象内存布局\n\n![image-20200709151033237](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709151033237.png)\n\n![image-20200709152801713](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709152801713.png)\n\n### 对象头（Header）\n\n对象头包含了两部分：\n\n- **运行时元数据**（Mark Word）\n- **类型指针**\n\n> 如果是数组，还需要记录数组的长度\n\n#### 运行时元数据\n\n- 哈希值（HashCode）\n- GC分代年龄\n- 锁状态标志\n- 线程持有的锁\n- 偏向线程ID\n- 翩向时间戳\n\n#### 类型指针\n\n指向类元数据`InstanceKlass`，确定该对象所属的类型。指向的其实是方法区中存放的**类元信息**\n\n### 实例数据（Instance Data）\n\n他是对象真正存储的有效信息，包括程序代码中定义的各种类型的代码（包括从父类继承下来的和本身拥有的字段）\n\n### 对齐填充（Padding）\n\n不是必须的，也没有特别的含义，仅仅起到占位符的作用\n\n### 小结\n\n![image-20200709152801713](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709152801713.png)\n\n> Klass 是虚拟机源码里定义的类型。其是C++的对象，不是Java的Class对象。类元信息是作为Klass对象的属性存储在方法区的。\n\n## 对象的访问定位\n\nJVM是如何通过栈帧中的对象引用访问到其内部的对象实例呢？\n\n![image-20200709164149920](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709164149920.png)\n\n定位，通过栈上reference访问\n\n\n\n### 对象访问的两种方式\n\n对象的两种访问方式：**句柄访问和直接指针**\n\n#### 句柄访问\n\n![image-20200709164342002](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709164342002.png)\n\n句柄访问就是说栈的局部变量表中，记录的对象的引用，然后在堆空间中开辟了一块空间，也就是\n\n**句柄池**\n\n- 缺点：在堆空间中开辟了一块空间作为句柄池，句柄池本身也会占用空间；通过两次指针访问才能访问到堆中的对象，**效率低**\n- 优点：reference中存储稳定句柄地址，对象被移动（垃圾收集时移动对象很普遍）时只会改变句柄中实例数据指针即可，reference本身不需要被修改\n\n#### 直接指针（HotSpot采用）\n\n![image-20200709164350466](/images/%E3%80%90JVM%E3%80%91JVM%E5%AF%B9%E8%B1%A1%E5%AE%9E%E4%BE%8B%E5%8C%96%E8%BF%87%E7%A8%8B/image-20200709164350466.png)\n\n直接指针是局部变量表中的引用，直接指向堆中的实例，在对象实例中有类型指针，指向的是方法区中的对象类型数据\n\n- 优点：直接指针是局部变量表中的引用，直接指向堆中的实例，在对象实例中有类型指针，指向的是方法区中的对象类型数据\n- 缺点：对象被移动（垃圾收集时移动对象很普遍，例如复制算法，每次GC时都会将数据复制到另一个内存空间）时**需要修改 reference 的值**","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 方法区","url":"/2021/09/28/【JVM】JVM方法区/","content":"\n## 栈、堆、方法区的交互关系\n\n内存区域划分：\n\n![image-20200708094507624](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708094507624.png)\n\n对象的访问定位：\n\n![image-20200708094747667](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708094747667.png)\n\n- `Person`：**类信息**（类型信息、方法信息、属性信息等）存放在元空间，也可以说方法区\n- `person`：类的实例**对象名**存放在Java栈的局部变量表中\n- `new Person()`：类的实例**对象数据**存放在Java堆中\n\n<!-- More -->\n\n## 方法区的理解\n\n> 《Java虚拟机规范》中明确说明：“尽管所有的方法区在逻辑上是属于堆的一部分，但一些简单的实现可能不会选择去进行垃圾收集或者进行压缩。”\n\n但对于HotSpot JVM而言，方法区还有一个别名叫做**Non-Heap**（非堆），目的就是要和堆分开。所以，方法区可以看作是一块**独立于Java堆**的内存空间。\n\n**方法区和元空间的区别：**\n\n- 方法区是**Java虚拟机规范**里定义的抽象名词\n- 元空间则是一些JVM厂商根据规范对方法区进行**具体实现**时起的名称\n\n![image-20200708095853544](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708095853544.png)\n\n方法区主要存放的是 `Class`（类的信息），而堆中主要存放的是**实例化的对象数据**\n\n- 方法区（Method Area）与Java堆一样，是各个线程**共享的**内存区域。\n- 方法区在JVM启动的时候被创建，并且它的实际的物理内存空间中和Java堆区一样都可以**是不连续的**。\n- 方法区的大小，跟堆空间一样，**可以选择固定大小或者可扩展**。\n- 方法区的大小决定了系统可以保存多少个类，如果系统**定义了太多的类，导致方法区溢出**，虚拟机同样会抛出内存溢出错误：`java.lang.OutOfMemoryError:PermGen space` 或者`java.lang.OutOfMemoryError:Metaspace`\n  - 加载大量的第三方的jar包\n  - Tomcat部署的工程过多（30~50个）\n  - 大量动态的生成反射类\n- 关闭JVM就会释放这个区域的内存。\n\n## 方法区的演进\n\n- JDK 1.7 及以前，习惯上把方法区称为**永久代**，永久代内的数据还是存在虚拟机内存\n- JDK 1.8 后，使用**元空间取代了永久代**，并且元空间存放在**堆外内存**（本地内存）中\n\n元空间和永久代之间最大的区别在于：**元空间并不在虚拟机中，而是使用本地内存**\n\n> 从元空间开始数据存放在本地内存中，**本地内存的数据不再有JVM的GC回收机制**\n\n本质上，方法区和永久代并不等价。仅是对hotspot而言的，其他许多厂商的JVM没有永久代的概念。《Java虚拟机规范》对如何实现方法区，不做统一要求。例如：BEAJRockit / IBM J9 中不存在永久代的概念。\n\n>现在来看，当年使用永久代，不是好的idea。导致Java程序更容易oom（超过`-XX:MaxPermsize`上限）\n\n![image-20200708102919149](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708102919149.png)\n\n而到了JDK 1.8，终于完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间（Metaspace）来代替\n\n![image-20200708103055914](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708103055914.png)\n\n**方法区和元空间的区别：**\n\n- 方法区是**Java虚拟机规范**里定义的抽象名词\n- 元空间则是一些JVM厂商根据规范对方法区进行**具体实现**时起的名称\n\n元空间的本质和永久代类似，**都是对JVM规范中方法区的实现**。不过元空间与永久代最大的区别在于：**元空间不在虚拟机设置的内存中，而是使用本地内存**。永久代、元空间二者并不只是名字变了，内部结构也调整了。根据《Java虚拟机规范》的规定，如果方法区无法满足新的内存分配需求时，将抛出OOM异常。\n\n### 方法区的更多演进细节\n\n首先明确：**只有Hotspot才有永久代**。BEA JRockit、IBMJ9等来说，是不存在永久代的概念的。原则上如何实现方法区属于虚拟机实现细节，不受《Java虚拟机规范》管束，并不要求统一。\n\nHotspot中方法区的变化：\n\n- JDK 1.6 及以前：有永久代，**静态变量存储在永久代上**\n- JDK 1.7：有永久代，但已经逐步 “去永久代”，**字符串常量池和静态变量移，保存在堆中**\n- JDK 1.8：**无永久代**，类型信息，字段，方法，运行时常量池保存在**本地内存**的元空间，但**字符串常量池、静态变量仍然在堆中**\n\nJDK 1.7 是一个**过度版本**，逐渐从永久代转变为元空间，并且字符串常量池、静态变量逐渐保存在堆中。\n\n在 JDK 1.8 后，元空间里只保存类型信息/方法信息等（在本地内存中）。字符串常量和静态变量被保存在了堆中方便 GC。\n\n注意：**运行时常量池仍然在元空间**，其内存储一些静态全局常量（static final）\n\nJDK 1.6 的时候：\n\n![image-20200708211541300](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708211541300.png)\n\nJDK 1.7 的时候：\n\n![image-20200708211609911](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708211609911.png)\n\nJDK 1.8 的时候，元空间大小只受**物理内存**影响：\n\n![image-20200708211637952](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708211637952.png)\n\n\n\n### StringTable 为什么要调整位置\n\n> 因为之前存放在永久代里只有Full GC才会回收，效率太低。JDK 1.8后放到堆里回收效率高，Major GC时就会回收，不需要等待Full GC\n\nJDK 7中将`StringTable`放到了**堆空间**中。因为**永久代的回收效率很低**，**在Full GC的时候才会触发**。而Full GC是老年代的空间不足、永久代不足时才会触发。\n\n这就导致`StringTable`回收效率不高。而我们开发中会有大量的字符串被创建，回收效率低，导致永久代内存不足。将字符串常量池放到堆里能及时回收内存。\n\n### 静态变量存放在哪里？\n\n- 对象**实体数据始终存放在堆空间**\n- 对象的**引用变量名**在JDK6，JDK7，JDK8存放位置中有所变化\n\n#### 对象实体在哪里放着？\n\n静态引用对应的对象**实体数据**始终都存在堆空间（new出来的对象实体数据）\n\n```java\n/**\n * 结论：\n * 1、静态引用对应的对象实体(也就是这个new byte[1024 * 1024 * 100])始终都存在堆空间，\n * 2、只是那个变量(相当于下面的arr变量名)在JDK6,JDK7,JDK8存放位置中有所变化\n *\n * jdk7：\n * -Xms200m -Xmx200m -XX:PermSize=300m -XX:MaxPermSize=300m -XX:+PrintGCDetails\n * jdk 8：\n * -Xms200m -Xmx200m -XX:MetaspaceSize=300m -XX:MaxMetaspaceSize=300m -XX:+PrintGCDetails\n */\npublic class StaticFieldTest {\n    private static byte[] arr = new byte[1024 * 1024 * 100];//100MB\n\n    public static void main(String[] args) {\n        System.out.println(StaticFieldTest.arr);\n    }\n}\n```\n\n静态引用对应的对象实体（也就是这个`new byte[1024 * 1024 * 100]`）**始终都存在堆空间**，只是那个变量（相当于下面的arr变量名）在JDK6，JDK7，JDK8存放位置中有所变化。\n\n#### 变量（名）存放在哪里？\n\n这个问题需要用JHSDB工具来进行分析，这个工具是JDK9开始自带的，在`bin`目录下可以找到\n\n```java\npackage com.zhao.java1;\n\n/**\n * 《深入理解Java虚拟机》中的案例：\n * staticObj、instanceObj、localObj存放在哪里？\n */\npublic class StaticObjTest {\n    static class Test {\n        static ObjectHolder staticObj = new ObjectHolder();\n        ObjectHolder instanceObj = new ObjectHolder();\n\n        void foo() {\n            ObjectHolder localObj = new ObjectHolder();\n            System.out.println(\"done\");\n        }\n    }\n\n    private static class ObjectHolder {\n    }\n\n    public static void main(String[] args) {\n        Test test = new StaticObjTest.Test();\n        test.foo();\n    }\n}\n```\n\n三者的存放位置：\n\n- `staticobj`：静态属性，随着`Test`的类型信息存放在**方法区**\n- `instanceobj`：类的普通属性，随着`Test`的对象实例存放在**堆区**\n- `localobject`：局部变量，是存放在`foo()`方法栈帧的**局部变量表**中。\n\n![image-20200708215025527](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708215025527.png)\n\n测试发现：三个对象的实体数据在内存中的地址都落在Eden区范围内，所以结论：只要是对象实例必然会在Java堆中分配。\n\n接着，找到了一个引用该`staticobj`对象的地方，是在一个`java.lang.Class`的实例里，并且给出了这个实例的地址，通过Inspector查看该对象实例，可以清楚看到这确实是一个`java.lang.Class`类型的对象实例，里面有一个名为`staticobj`的实例字段：\n\n![image-20200708215218078](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708215218078.png)\n\n> 从《Java虚拟机规范》所定义的概念模型来看，所有Class相关的信息都应该存放在方法区之中，但方法区该如何实现，《Java虚拟机规范》并未做出规定，这就成了一件允许不同虚拟机自己灵活把握的事情。\n\nJDK 7及其以后版本的HotSpot虚拟机选择把静态变量与类型在Java语言一端的映射Class对象存放在一起，**存储于Java堆之中**，从我们的实验中也明确验证了这一点\n\n\n\n## 方法区的内部结构\n\n![image-20210929165800059](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20210929165800059.png)\n\n> **字符串常量池在JDK 8中被存放在堆区**\n\n《深入理解Java虚拟机》书中对方法区（Method Area）存储内容描述如下：它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。\n\n![image-20200708161856504](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708161856504.png)\n\n### 类型信息\n\n对每个加载的类型（类class、接口interface、枚举enum、注解annotation），JVM必须在方法区中存储以下类型信息：\n\n- 这个类型的完整有效名称（全名=包名.类名）\n- 这个类型直接父类的完整有效名（对于interface或是`java.lang.Object`，都没有父类）\n- 这个类型的修饰符（public，abstract，final的某个子集）\n- 这个类型直接接口的一个有序列表\n\n### 域（Field）信息\n\n> 也就是我们常说的类的成员变量，域信息是比较官方的称呼\n\nJVM必须在方法区中保存类型的所有域的相关信息以及域的声明顺序。\n\n域的相关信息包括：域名称、域类型、域修饰符（public，private，protected，static，final，volatile，transient的某个子集）\n\n### 方法（Method）信息\n\nJVM必须保存所有方法的以下信息，同域信息一样包括声明顺序：\n\n- 方法名称\n- 方法的返回类型（或void）\n- 方法参数的数量和类型（按顺序）\n- 方法的修饰符（public，private，protected，static，final，synchronized，native，abstract的一个子集）\n- 方法的字节码（bytecodes）、操作数栈、局部变量表及大小（abstract和native方法除外）\n- 异常表（abstract和native方法除外）\n\n>每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引\n\n### 示例\n\n```java\n/**\n * 测试方法区的内部构成\n */\npublic class MethodInnerStrucTest extends Object implements Comparable<String>,Serializable {\n    //属性\n    public int num = 10;\n    private static String str = \"测试方法的内部结构\";\n    //构造器\n    //方法\n    public void test1(){\n        int count = 20;\n        System.out.println(\"count = \" + count);\n    }\n    public static int test2(int cal){\n        int result = 0;\n        try {\n            int value = 30;\n            result = value / cal;\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return result;\n    }\n\n    @Override\n    public int compareTo(String o) {\n        return 0;\n    }\n}\n```\n\n反编译字节码文件，并输出值文本文件中，便于查看。参数 `-p` 确保能查看 private 权限类型的字段或方法：\n\n```\njavap -v -p MethodInnerStrucTest.class > test.txt\n```\n\n```\nClassfile /F:/IDEAWorkSpaceSourceCode/JVMDemo/out/production/chapter09/com/atguigu/java/MethodInnerStrucTest.class\n  Last modified 2020-11-13; size 1626 bytes\n  MD5 checksum 0d0fcb54854d4ce183063df985141ad0\n  Compiled from \"MethodInnerStrucTest.java\"\n//类型信息      \npublic class com.atguigu.java.MethodInnerStrucTest extends java.lang.Object implements java.lang.Comparable<java.lang.String>, java.io.Serializable\n  minor version: 0\n  major version: 52\n  flags: ACC_PUBLIC, ACC_SUPER\nConstant pool:\n   #1 = Methodref          #18.#52        // java/lang/Object.\"<init>\":()V\n   #2 = Fieldref           #17.#53        // com/atguigu/java/MethodInnerStrucTest.num:I\n   #3 = Fieldref           #54.#55        // java/lang/System.out:Ljava/io/PrintStream;\n   #4 = Class              #56            // java/lang/StringBuilder\n   #5 = Methodref          #4.#52         // java/lang/StringBuilder.\"<init>\":()V\n   #6 = String             #57            // count =\n   #7 = Methodref          #4.#58         // java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n   #8 = Methodref          #4.#59         // java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;\n   #9 = Methodref          #4.#60         // java/lang/StringBuilder.toString:()Ljava/lang/String;\n  #10 = Methodref          #61.#62        // java/io/PrintStream.println:(Ljava/lang/String;)V\n  #11 = Class              #63            // java/lang/Exception\n  #12 = Methodref          #11.#64        // java/lang/Exception.printStackTrace:()V\n  #13 = Class              #65            // java/lang/String\n  #14 = Methodref          #17.#66        // com/atguigu/java/MethodInnerStrucTest.compareTo:(Ljava/lang/String;)I\n  #15 = String             #67            // 测试方法的内部结构\n  #16 = Fieldref           #17.#68        // com/atguigu/java/MethodInnerStrucTest.str:Ljava/lang/String;\n  #17 = Class              #69            // com/atguigu/java/MethodInnerStrucTest\n  #18 = Class              #70            // java/lang/Object\n  #19 = Class              #71            // java/lang/Comparable\n  #20 = Class              #72            // java/io/Serializable\n  #21 = Utf8               num\n  #22 = Utf8               I\n  #23 = Utf8               str\n  #24 = Utf8               Ljava/lang/String;\n  #25 = Utf8               <init>\n  #26 = Utf8               ()V\n  #27 = Utf8               Code\n  #28 = Utf8               LineNumberTable\n  #29 = Utf8               LocalVariableTable\n  #30 = Utf8               this\n  #31 = Utf8               Lcom/atguigu/java/MethodInnerStrucTest;\n  #32 = Utf8               test1\n  #33 = Utf8               count\n  #34 = Utf8               test2\n  #35 = Utf8               (I)I\n  #36 = Utf8               value\n  #37 = Utf8               e\n  #38 = Utf8               Ljava/lang/Exception;\n  #39 = Utf8               cal\n  #40 = Utf8               result\n  #41 = Utf8               StackMapTable\n  #42 = Class              #63            // java/lang/Exception\n  #43 = Utf8               compareTo\n  #44 = Utf8               (Ljava/lang/String;)I\n  #45 = Utf8               o\n  #46 = Utf8               (Ljava/lang/Object;)I\n  #47 = Utf8               <clinit>\n  #48 = Utf8               Signature\n  #49 = Utf8               Ljava/lang/Object;Ljava/lang/Comparable<Ljava/lang/String;>;Ljava/io/Serializable;\n  #50 = Utf8               SourceFile\n  #51 = Utf8               MethodInnerStrucTest.java\n  #52 = NameAndType        #25:#26        // \"<init>\":()V\n  #53 = NameAndType        #21:#22        // num:I\n  #54 = Class              #73            // java/lang/System\n  #55 = NameAndType        #74:#75        // out:Ljava/io/PrintStream;\n  #56 = Utf8               java/lang/StringBuilder\n  #57 = Utf8               count =\n  #58 = NameAndType        #76:#77        // append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n  #59 = NameAndType        #76:#78        // append:(I)Ljava/lang/StringBuilder;\n  #60 = NameAndType        #79:#80        // toString:()Ljava/lang/String;\n  #61 = Class              #81            // java/io/PrintStream\n  #62 = NameAndType        #82:#83        // println:(Ljava/lang/String;)V\n  #63 = Utf8               java/lang/Exception\n  #64 = NameAndType        #84:#26        // printStackTrace:()V\n  #65 = Utf8               java/lang/String\n  #66 = NameAndType        #43:#44        // compareTo:(Ljava/lang/String;)I\n  #67 = Utf8               测试方法的内部结构\n  #68 = NameAndType        #23:#24        // str:Ljava/lang/String;\n  #69 = Utf8               com/atguigu/java/MethodInnerStrucTest\n  #70 = Utf8               java/lang/Object\n  #71 = Utf8               java/lang/Comparable\n  #72 = Utf8               java/io/Serializable\n  #73 = Utf8               java/lang/System\n  #74 = Utf8               out\n  #75 = Utf8               Ljava/io/PrintStream;\n  #76 = Utf8               append\n  #77 = Utf8               (Ljava/lang/String;)Ljava/lang/StringBuilder;\n  #78 = Utf8               (I)Ljava/lang/StringBuilder;\n  #79 = Utf8               toString\n  #80 = Utf8               ()Ljava/lang/String;\n  #81 = Utf8               java/io/PrintStream\n  #82 = Utf8               println\n  #83 = Utf8               (Ljava/lang/String;)V\n  #84 = Utf8               printStackTrace\n{\n//域信息\n  public int num;\n    descriptor: I\n    flags: ACC_PUBLIC\n\n  private static java.lang.String str;\n    descriptor: Ljava/lang/String;\n    flags: ACC_PRIVATE, ACC_STATIC\n\n  //方法信息\n  public com.atguigu.java.MethodInnerStrucTest();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n         4: aload_0\n         5: bipush        10\n         7: putfield      #2                  // Field num:I\n        10: return\n      LineNumberTable:\n        line 10: 0\n        line 12: 4\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      11     0  this   Lcom/atguigu/java/MethodInnerStrucTest;\n\n  public void test1();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=3, locals=2, args_size=1\n         0: bipush        20\n         2: istore_1\n         3: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         6: new           #4                  // class java/lang/StringBuilder\n         9: dup\n        10: invokespecial #5                  // Method java/lang/StringBuilder.\"<init>\":()V\n        13: ldc           #6                  // String count =\n        15: invokevirtual #7                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n        18: iload_1\n        19: invokevirtual #8                  // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;\n        22: invokevirtual #9                  // Method java/lang/StringBuilder.toString:()Ljava/lang/String;\n        25: invokevirtual #10                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n        28: return\n      LineNumberTable:\n        line 17: 0\n        line 18: 3\n        line 19: 28\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      29     0  this   Lcom/atguigu/java/MethodInnerStrucTest;\n            3      26     1 count   I\n\n  public static int test2(int);\n    descriptor: (I)I\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n      stack=2, locals=3, args_size=1\n         0: iconst_0\n         1: istore_1\n         2: bipush        30\n         4: istore_2\n         5: iload_2\n         6: iload_0\n         7: idiv\n         8: istore_1\n         9: goto          17\n        12: astore_2\n        13: aload_2\n        14: invokevirtual #12                 // Method java/lang/Exception.printStackTrace:()V\n        17: iload_1\n        18: ireturn\n      Exception table:\n         from    to  target type\n             2     9    12   Class java/lang/Exception\n      LineNumberTable:\n        line 21: 0\n        line 23: 2\n        line 24: 5\n        line 27: 9\n        line 25: 12\n        line 26: 13\n        line 28: 17\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            5       4     2 value   I\n           13       4     2     e   Ljava/lang/Exception;\n            0      19     0   cal   I\n            2      17     1 result   I\n      StackMapTable: number_of_entries = 2\n        frame_type = 255 /* full_frame */\n          offset_delta = 12\n          locals = [ int, int ]\n          stack = [ class java/lang/Exception ]\n        frame_type = 4 /* same */\n\n  public int compareTo(java.lang.String);\n    descriptor: (Ljava/lang/String;)I\n    flags: ACC_PUBLIC\n    Code:\n      stack=1, locals=2, args_size=2\n         0: iconst_0\n         1: ireturn\n      LineNumberTable:\n        line 33: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       2     0  this   Lcom/atguigu/java/MethodInnerStrucTest;\n            0       2     1     o   Ljava/lang/String;\n\n  public int compareTo(java.lang.Object);\n    descriptor: (Ljava/lang/Object;)I\n    flags: ACC_PUBLIC, ACC_BRIDGE, ACC_SYNTHETIC\n    Code:\n      stack=2, locals=2, args_size=2\n         0: aload_0\n         1: aload_1\n         2: checkcast     #13                 // class java/lang/String\n         5: invokevirtual #14                 // Method compareTo:(Ljava/lang/String;)I\n         8: ireturn\n      LineNumberTable:\n        line 10: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  this   Lcom/atguigu/java/MethodInnerStrucTest;\n\n  static {};\n    descriptor: ()V\n    flags: ACC_STATIC\n    Code:\n      stack=1, locals=0, args_size=0\n         0: ldc           #15                 // String 测试方法的内部结构\n         2: putstatic     #16                 // Field str:Ljava/lang/String;\n         5: return\n      LineNumberTable:\n        line 13: 0\n}\nSignature: #49                          // Ljava/lang/Object;Ljava/lang/Comparable<Ljava/lang/String;>;Ljava/io/Serializable;\nSourceFile: \"MethodInnerStrucTest.java\"\n```\n\n分析上面字节码的内容：\n\n**类型信息**\n\n在运行时方法区中，类信息中记录了哪个加载器加载了该类，同时类加载器也记录了它加载了哪些类\n\n```\n// 类型信息      \npublic class com.atguigu.java.MethodInnerStrucTest extends java.lang.Object implements java.lang.Comparable<java.lang.String>, java.io.Serializable\n```\n\n**域信息**\n\n1. `descriptor`：表示字段类型为 Integer\n2. `flags: ACC_PUBLIC`：表示字段权限修饰符为 public\n\n```\n// 域信息\n  public int num;\n    descriptor: I\n    flags: ACC_PUBLIC\n\n  private static java.lang.String str;\n    descriptor: Ljava/lang/String;\n    flags: ACC_PRIVATE, ACC_STATIC\n```\n\n**方法信息**\n\n1. `descriptor: ()V` 表示方法返回值类型为 void\n2. `flags: ACC_PUBLIC` 表示方法权限修饰符为 public\n3. `stack=3` 表示操作数栈深度为 3\n4. `locals=2` 表示局部变量个数为 2 个（实力方法包含 this）\n5. `test1()` 方法虽然没有参数，但是其 `args_size=1` ，这时因为将 this 作为了参数\n\n```\npublic void test1();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=3, locals=2, args_size=1\n         0: bipush        20\n         2: istore_1\n         3: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         6: new           #4                  // class java/lang/StringBuilder\n         9: dup\n        10: invokespecial #5                  // Method java/lang/StringBuilder.\"<init>\":()V\n        13: ldc           #6                  // String count =\n        15: invokevirtual #7                  // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;\n        18: iload_1\n        19: invokevirtual #8                  // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder;\n        22: invokevirtual #9                  // Method java/lang/StringBuilder.toString:()Ljava/lang/String;\n        25: invokevirtual #10                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n        28: return\n      LineNumberTable:\n        line 17: 0\n        line 18: 3\n        line 19: 28\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      29     0  this   Lcom/atguigu/java/MethodInnerStrucTest;\n            3      26     1 count   I\n```\n\n### non-final static 的类静态变量 \n\n类的静态成员变量和类关联在一起，随着类的加载而加载，他们成为类数据在逻辑上的一部分变量。其被类的所有实例共享，即使没有类实例时，你也可以访问它。\n\n**举例**\n\n1. 如下代码所示，即使我们把`order`设置为`null`，也不会出现空指针异常\n2. 这更加表明了 `static` 类型的字段和方法随着类的加载而加载，并不属于特定的类实例\n\n```java\n/**\n * non-final的类变量\n */\npublic class MethodAreaTest {\n    public static void main(String[] args) {\n        Order order = new Order();\n        order.hello();\n        System.out.println(order.count);\n    }\n}\nclass Order {\n    public static int count = 1;\n    public static final int number = 2;\n    public static void hello() {\n        System.out.println(\"hello!\");\n    }\n}\n```\n\n###  static final 全局常量\n\n> 没有 final 修饰的成员变量并不会存放到方法区\n\n全局常量就是使用 `static final` 进行修饰。**每个全局常量在编译的时候就会被分配了**。 \n\n查看上面代码，这部分的字节码指令\n\n```java\nclass Order {\n    public static int count = 1;\n    public static final int number = 2;\n    ...\n}\n```\n\n字节码文件：\n\n```\npublic static int count;\n    descriptor: I\n    flags: ACC_PUBLIC, ACC_STATIC\n\n  public static final int number;\n    descriptor: I\n    flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL\n    ConstantValue: int 2\n```\n\n可以发现 `staitc` 和 `final` 同时修饰的 `number` 的值**在编译的时候已经写死在字节码文件中了**。\n\n### 运行时常量池 VS 常量池\n\n运行时常量池，就是运行时的常量池\n\n![image-20200708171151384](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708171151384.png)\n\n- 方法区内部包含了运行时常量池\n- 字节码文件内部包含了常量池\n- 要弄清楚方法区，需要理解清楚ClassFile，因为加载类的信息都在方法区。\n- 要弄清楚方法区的运行时常量池，需要理解清楚ClassFile中的常量池。\n\n### 常量池\n\n![image-20200708172357052](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708172357052.png)\n\n一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述符信息外，还包含一项信息就是常量池表（Constant Pool Table），包括各种字面量和对类型、域和方法的符号引用\n\n#### 为什么需要常量池\n\n一个java源文件中的类、接口，编译后产生一个字节码文件。而Java中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候会用到运行时常量池，之前有介绍。\n\n比如：如下的代码：\n\n```java\npublic class SimpleClass {\n    public void sayHello() {\n        System.out.println(\"hello\");\n    }\n}\n```\n\n虽然上述代码只有194字节，但是里面却使用了`String`、`System`、`PrintStream`及`Object`等结构。这里的代码量其实很少了，如果代码多的话，引用的结构将会更多，这里就需要用到常量池了。\n\n#### 常量池中有什么\n\n- 数量值\n- 字符串值\n- 类引用\n- 字段引用\n- 方法引用\n\n例如下面这段代码\n\n```java\npublic class MethodAreaTest2 {\n    public static void main(String args[]) {\n        Object obj = new Object();\n    }\n}\n```\n\n将会被翻译成如下字节码\n\n```bash\nnew #2  \ndup\ninvokespecial\n```\n\n其中带#的就是引用了常量池里的符号。\n\n#### 小结\n\n常量池、可以看做是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型\n\n### 运行时常量池\n\n运行时常量池（Runtime Constant Pool）是方法区的一部分。\n\n常量池表（Constant Pool Table）是Class文件的一部分，用于存放编译期生成的各种**字面量**与**符号引用**，**这部分内容将在类加载后存放到方法区的运行时常量池中**。在加载类和接口到虚拟机后，就会创建对应的运行时常量池。\n\nJVM为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的。\n\n运行时常量池中包含多种不同的常量，包括编译期就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或者字段引用。此时不再是常量池中的符号地址了，在Linking阶段的Resolve阶段价格符号引用转换为真实地址。\n\n运行时常量池，相对于Class文件常量池的另一重要特征是：**具备动态性**。运行时常量池类似于传统编程语言中的符号表（symboltable），但是它所包含的数据却比符号表要更加丰富一些。\n\n当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则JVM会抛outofMemoryError异常。\n\n## 方法区使用举例\n\n如下代码\n\n```java\npublic class MethodAreaDemo {\n    public static void main(String args[]) {\n        int x = 500;\n        int y = 100;\n        int a = x / y;\n        int b = 50;\n        System.out.println(a+b);\n    }\n}\n```\n\n字节码执行过程展示\n\n![image-20200708204750374](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708204750374.png)\n\n首先现将操作数500放入到操作数栈中\n\n![image-20200708204953552](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708204953552.png)\n\n然后存储到局部变量表中\n\n![image-20200708205029376](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708205029376.png)\n\n然后重复一次，把100放入局部变量表中，最后再将变量表中的500 和 100 取出，进行操作\n\n![image-20200708205221737](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708205221737.png)\n\n将500 和 100 进行一个除法运算，在把结果入栈\n\n![image-20200708205413721](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708205413721.png)\n\n在最后就是输出流，需要调用运行时常量池的常量\n\n![image-20200708205708057](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708205708057.png)\n\n最后调用`invokevirtual`（虚方法调用），然后返回\n\n![image-20200708205909176](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708205909176.png)\n\n返回时\n\n![image-20200708210540696](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708210540696.png)\n\n**符号引用 –> 直接引用**\n\n1. 上面代码调用 `System.out.println()` 方法时，首先需要看看 `System` 类有没有加载，再看看 `PrintStream` 类有没有加载\n2. 如果没有加载，则执行加载。在类加载的**Resolve解析阶段**时，将常量池中的符号引用（字面量）转换为运行时常量池的直接引用（真正的地址值）\n\n> 程序计数器始终计算的都是**当前代码**运行的位置，目的是为了方便记录 方法调用后能够正常返回，或者是进行了CPU切换后，也能回来到原来的代码进行执行。\n\n\n\n## 设置方法区大小与 OOM\n\n方法区的大小**不必是固定的**，JVM可以根据应用的需要动态调整。 \n\n### JDK 7 及以前\n\n- 通过`-XX:Permsize`来设置永久代**初始**分配空间。默认值是20.75M\n- 通过`-XX:MaxPermsize`来设定永久代**最大**可分配空间。32位机器默认是64M，64位机器模式是82M\n- 当JVM加载的类信息容量超过了这个值，会报异常`OutofMemoryError:PermGen space`\n\n![image-20200708111756800](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708111756800.png)\n\n### JDK 8 以后\n\n元数据区大小可以使用参数 `-XX:MetaspaceSize` 和 -`XX:MaxMetaspaceSize` 指定。默认值依赖于平台。Windows下，`-XX:MetaspaceSize`是21M，`-XX:MaxMetaspaceSize`的值是-1代表没有限制。\n\n与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据区发生溢出，虚拟机一样会抛出异常`OutOfMemoryError:Metaspace`\n\n`-XX:MetaspaceSize：`设置初始的元空间大小。对于一个64位的服务器端JVM来说，其默认的`-XX:MetaspaceSize`值为21MB。这就是初始的高水位线，一旦触及这个水位线，Full GC将会被触发并卸载没用的类（即这些类对应的类加载器不再存活）然后这个高水位线将会重置。新的高水位线的值取决于GC后释放了多少元空间。如果释放的空间不足，那么在不超过`MaxMetaspaceSize`时，适当提高该值。如果释放空间过多，则适当降低该值。\n\n如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次。通过垃圾回收器的日志可以观察到Full GC多次调用。为了避免频繁地GC，建议将`-XX:MetaspaceSize`设置为一个**相对较高的值**。\n\n### 如何解决这些 OOM\n\n要解决OOM异常或Heap space的异常，一般的手段是首先通过**内存映像分析工具**（如Eclipse Memory Analyzer）对dump出来的堆转储快照进行分析，重点是确认内存中的对象是否是必要的，也就是要先分清楚到底是出现了**内存泄漏**（Memory Leak）还是**内存溢出**（Memory Overflow）\n\n> **内存泄漏**就是有大量的引用指向某些对象，但是这些对象以后不会使用了，但是因为它们还和GC ROOT有关联，所以导致以后这些对象也不会被回收，这就是内存泄漏的问题\n\n如果是内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。于是就能找到泄漏对象是通过怎样的路径与GCRoots相关联并导致垃圾收集器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GCRoots引用链的信息，就可以比较准确地定位出泄漏代码的位置。\n\n如果不存在内存泄漏，换句话说就是内存中的对象确实都还必须存活着，那就应当检查虚拟机的堆参数（-Xmx与-Xms），与机器物理内存对比看是否还可以调大，从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。\n\n\n\n## 为什么永久代要被元空间替代？\n\n是JRockit和HotSpot融合后的结果，因为JRockit没有永久代，所以他们不需要配置永久代\n\n随着Java8的到来，HotSpot VM中再也见不到永久代了。但是这并不意味着类的元数据信息也消失了。这些数据被移到了一个**与堆不相连的本地内存**区域，这个区域叫做**元空间**（Metaspace）。\n\n由于类的元数据分配在本地内存中，元空间的最大可分配空间就是系统可用内存空间，这项改动是很有必要的，原因有：\n\n- 为永久代设置空间**大小是很难确定的**\n- 对永久代进行**调优是很困难的**（主要是为了降低Full GC）\n\n### 永久代设置空间大小很难确定\n\n在某些场景下，如果动态加载类过多，容易产生永久代Perm区的OOM。比如某个实际Web工\n程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现致命错误：\n\n```\nException in thread‘dubbo client x.x connector'java.lang.OutOfMemoryError:PermGen space\n```\n\n而元空间和永久代之间最大的区别在于：**元空间并不在虚拟机中，而是使用本地内存**。因此，默认情况下，元空间的大小仅受本地内存限制。\n\n### 永久代调优比较困难\n\n有些人认为方法区（如HotSpot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java虚拟机规范》对方法区的约束是非常宽松的，**提到过可以不要求虚拟机在方法区中实现垃圾收集**。事实上也确实有未实现或未能完整实现方法区类型卸载的收集器存在（如JDK11时期的ZGC收集器就不支持类卸载）。\n\n一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，条件相当苛刻。但是这部分区域的回收有时又确实是必要的（GC较麻烦但也有必要）。以前sun公司的Bug列表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏。\n\n方法区的垃圾收集主要回收两部分内容：**常量池中废弃的常量和不再使用的类型**。但是类型的回收非常苛刻。\n\n## 方法区的垃圾回收\n\n> 面试题：方法区也有垃圾回收吗？有，分两种：**常量池中废弃的常量和不再使用的类**。类的回收条件非常苛刻，因为要等待其加载器也被回收等。\n\n有些人认为方法区（如Hotspot虚拟机中的元空间或者永久代）是没有垃圾收集行为的，其实不然。《Java虚拟机规范》对方法区的约束是非常宽松的，提到过可以不要求虚拟机在方法区中实现垃圾收集。事实上也确实有未实现或未能完整实现方法区**类型卸载**的收集器存在（如JDK 11时期的ZGC收集器就不支持类卸载）。\n\n一般来说这个区域的回收效果比较难令人满意，尤其是类型的卸载，**条件相当苛刻**。但是这部分区域的回收有时又确实是必要的。以前sun公司的Bug列表中，曾出现过的若干个严重的Bug就是由于低版本的HotSpot虚拟机对此区域未完全回收而导致内存泄漏。\n\n方法区的垃圾收集主要回收两部分内容：**常量池中废弃的常量和不再使用的类**。\n\n### 常量的回收\n\n先来说说方法区内常量池之中主要存放的两大类常量：**字面量**和**符号引用**。字面量比较接近Java语言层次的常量概念，如文本字符串、被声明为`final`的常量值等。而符号引用则属于编译原理方面的概念，包括下面三类常量：\n\n- 类和接口的全限定名\n- 字段的名称和描述符\n- 方法的名称和描述符\n\nHotSpot虚拟机对常量池的回收策略是**很明确的**，**只要常量池中的常量没有被任何地方引用，就可以被回收**。回收废弃常量与回收Java堆中的对象非常类似。\n\n### 类的回收\n\n关于常量的回收比较简单，重点是类的回收，也称作**类卸载**\n\n判定一个常量是否“废弃”还是相对简单，而要判定一个类型是否属于“不再被使用的类”的条件就**比较苛刻了**。需要同时满足下面三个条件：\n\n- **该类所有的实例都已经被回收**，也就是Java堆中不存在该类及其任何派生子类的实例。\n- 加载该类的**类加载器已经被回收**，这个条件除非是经过精心设计的可替换类加载器的场景，如OSGi、JSP的重加载等，否则**通常是很难达成的**。\n- 该类对应的`java.lang.Class`对象**没有在任何地方被引用**，无法在任何地方通过反射访问该类的方法。\n\n从而元空间中存储的类模板信息想要被回收必须要满足：该类的类加载器已经被回收（因为类加载器也会维护一个指针指向其加载的对象），但这显然是**非常难达到的**。\n\n类对象、类的Class对象、该类的加载器以及方法区中的类模板信息关系如图：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/images)\n\nJava虚拟机被允许对满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，没有引用了就必然会回收。关于是否要对类型进行回收，HotSpot虚拟机提供了`-Xnoclassgc`参数进行控制，还可以使用`-verbose:class` 以及 `-XX：+TraceClass-Loading`、`-XX：+TraceClassUnLoading`查看类加载和卸载信息\n\n在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及OSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。\n\n## 运行时数据区总结\n\n![image-20200708220303243](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200708220303243.png)\n\n### 常见面试题\n\n百度\n三面：说一下JVM内存模型吧，有哪些区？分别干什么的？\n\n蚂蚁金服：\nJava8的内存分代改进\nJVM内存分哪几个区，每个区的作用是什么？\n一面：JVM内存分布/内存结构？栈和堆的区别？堆的结构？为什么两个survivor区？\n二面：Eden和survior的比例分配\n\n小米：\njvm内存分区，为什么要有新生代和老年代\n\n字节跳动：\n二面：Java的内存分区\n二面：讲讲vm运行时数据库区\n什么时候对象会进入老年代？\n\n京东：\nJVM的内存结构，Eden和Survivor比例。\nJVM内存为什么要分成新生代，老年代，持久代。新生代中为什么要分为Eden和survivor。\n\n天猫：\n一面：Jvm内存模型以及分区，需要详细到每个区放什么。\n一面：JVM的内存模型，Java8做了什么改\n\n拼多多：\nJVM内存分哪几个区，每个区的作用是什么？\n\n美团：\njava内存分配\njvm的永久代中会发生垃圾回收吗？\n一面：jvm内存分区，为什么要有新生代和老年代？\n\n## 直接内存\n\n### 直接内存概述\n\n直接内存（Direct Memory）不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。直接内存是在Java**堆外**的、直接向系统申请的内存区间。\n\n> 元空间存储的类型信息、方法信息、域信息等都存储在直接内存中\n\n直接内存来源于NIO，通过存在堆中的`DirectByteBuffer`操作Native内存。\n\n通常，访问直接内存的速度会优于Java堆。即**读写性能高**。\n\n- 因此出于性能考虑，读写频繁的场合可能会考虑使用直接内存。\n- Java的NIO库允许Java程序使用直接内存，用于数据缓冲区\n\n使用下列代码，直接分配本地内存空间\n\n```java\nint BUFFER = 1024*1024*1024; // 1GB\nByteBuffer byteBuffer = ByteBuffer.allocateDirect(BUFFER);\n```\n\n### 非直接缓存区和缓存区\n\n原来采用BIO的架构，我们需要从用户态切换成内核态\n\n![image-20200709170907611](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200709170907611.png)\n\nNIO 使用了缓存区的概念，直接操作物理磁盘，省去了中间过程\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/0039.png)\n\n### 直接内存与 OOM\n\n直接内存也可能出下面`OutOfMemoryError`异常\n\n由于直接内存在Java堆外，因此它的大小不会直接受限于`-Xmx`指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。\n\n直接内存的缺点：\n\n- 分配回收成本较高\n- 不受JVM内存回收管理\n\n直接内存大小可以通过`MaxDirectMemorySize`设。如果不指定，默认与堆的最大值`-Xmx`参数值一致\n\n![image-20200709230647277](/images/%E3%80%90JVM%E3%80%91JVM%E6%96%B9%E6%B3%95%E5%8C%BA/image-20200709230647277.png)\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 堆","url":"/2021/09/25/【JVM】JVM堆/","content":"\n## 堆的核心概念\n\n### 堆与进程\n\n一个进程对应一个JVM实例，一个JVM实例有一个Runtime Data Area，其对应了一个`Runtime`类的单例对象。\n\n堆针对一个JVM进程来说是唯一的，也就是一个进程只有一个JVM，但是进程包含多个线程，他们是**共享同一堆空间的**。\n\n![image-20200706195127740](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706195127740.png)\n\n一个JVM实例**只存在一个堆内存**，堆也是Java内存管理的核心区域。Java堆区在JVM启动的时候即被创建，其空间大小也就确定了（**堆内存的大小是可以调节的**），是JVM管理的最大一块内存空间。\n\n《Java虚拟机规范》规定，堆可以处于物理上不连续的内存空间中，但在**逻辑上它应该被视为连续的**。所有的线程共享Java堆，在这里还可以划分线程私有的缓冲区（Thread Local Allocation Buffer，TLAB）。\n\n> - -Xms10m：最小堆内存\n> - -Xmx10m：最大堆内存\n\n<!-- More -->\n\n下图就是使用：Java VisualVM查看堆空间的内容，通过 jdk bin提供的插件：\n\n![image-20200706200739392](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706200739392.png)\n\n> 《Java虚拟机规范》中对Java堆的描述是：所有的对象实例以及数组都应当在运行时分配在堆上。（The heap is the run-time data area from which memory for all class instances and arrays is allocated）\n\n我要说的是：**“几乎”**所有的对象实例都在这里分配内存。—— 从**实际使用角度**看的。因为还有一些对象是在栈上分配的。数组和对象可能永远不会存储在栈上，因为栈帧中保存引用，这个引用指向对象或者数组在堆中的位置。\n\n在方法结束后，堆中的对象不会马上被移除，仅仅在垃圾收集的时候才会被移除。\n\n- 也就是触发了GC的时候，才会进行回收\n- 如果堆中对象马上被回收，那么用户线程就会收到影响，因为有stop the word\n\n堆，是GC（Garbage Collection，垃圾收集器）执行垃圾回收的重点区域。\n\n![image-20200706201904057](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706201904057.png)\n\n### 堆内存细分\n\nJava 7及之前堆内存逻辑上分为三部分：新生区+养老区+永久区\n\n- Young Generation Space 新生区（Young/New），又被划分为Eden区和Survivor区\n- Tenure generation space 养老区 （Old/Tenure）\n- Permanent Space 永久区 （Perm）\n\nJava 8及之后堆内存逻辑上分为三部分：新生区+养老区+**元空间**\n\n- Young Generation Space 新生区（Young/New），又被划分为Eden区和Survivor区\n- Tenure generation space 养老区 （Old/Tenure）\n- Meta Space  元空间 （Meta）\n\n约定：新生区 -> **新生代** -> 年轻代  、  养老区 -> 老年区 -> **老年代**、 永久区 -> 永久代\n\n> jdk 8 之后**内存空间**有哪些变化： **永久区改成了元空间**\n\n![image-20200706203419496](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706203419496.png)\n\n堆空间内部结构，JDK1.8之前从永久代  替换成 **元空间**\n\n![image-20200706203835403](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706203835403.png)\n\n\n\n## 设置堆内存大小与 OOM\n\nJava堆区用于存储Java对象实例，那么堆的大小在JVM启动时就已经设定好了，大家可以通过选项`\"-Xmx\"`和`\"-Xms\"`来进行设置。\n\n- `\"-Xms\"`：用于表示堆区的起始内存，等价于` -XX:InitialHeapSize`\n- `\"-Xmx\"`：用于表示堆区的最大内存，等价于 `-XX:MaxHeapSize`\n\n一旦堆区中的内存大小超过`\"-xmx\"`所指定的最大内存时，将会抛出`OutPfMemoryError`异常。\n\n通常会将`-Xms`和`-Xmx`两个参数配置相同的值，其目的是**为了能够在Java垃圾回收机制清理完堆区后不需要重新分隔计算堆区的大小，从而提高性能**。\n\n默认情况下：\n\n- 初始内存大小：物理电脑内存大小 / 64\n- 最大内存大小：物理电脑内存大小 / 4\n\n```java\n/**\n * 1. 设置堆空间大小的参数\n * -Xms 用来设置堆空间（年轻代+老年代）的初始内存大小\n *      -X 是jvm的运行参数\n *      ms 是memory start\n * -Xmx 用来设置堆空间（年轻代+老年代）的最大内存大小\n *\n * 2. 默认堆空间的大小\n *    初始内存大小：物理电脑内存大小 / 64\n *             最大内存大小：物理电脑内存大小 / 4\n * 3. 手动设置：-Xms600m -Xmx600m\n *     开发中建议将初始堆内存和最大的堆内存设置成相同的值。\n *\n * 4. 查看设置的参数：方式一： jps   /  jstat -gc 进程id\n *                  方式二：-XX:+PrintGCDetails\n */\npublic class HeapSpaceInitial {\n    public static void main(String[] args) {\n\n        //返回Java虚拟机中的堆内存总量\n        long initialMemory = Runtime.getRuntime().totalMemory() / 1024 / 1024;\n        //返回Java虚拟机试图使用的最大堆内存量\n        long maxMemory = Runtime.getRuntime().maxMemory() / 1024 / 1024;\n\n        System.out.println(\"-Xms : \" + initialMemory + \"M\");\n        System.out.println(\"-Xmx : \" + maxMemory + \"M\");\n\n        System.out.println(\"系统内存大小为：\" + initialMemory * 64.0 / 1024 + \"G\");\n        System.out.println(\"系统内存大小为：\" + maxMemory * 4.0 / 1024 + \"G\");\n\n        try {\n            Thread.sleep(1000000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n输出结果：\n\n```\n-Xms:245M\n-Xmx:3614M\n```\n\n如何查看堆内存的内存分配情况：\n\n```\njps  ->  jstat -gc 进程id\n```\n\n![image-20200706205756045](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706205756045.png)\n\n```\n-XX:+PrintGCDetails\n```\n\n![image-20200706205821919](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706205821919.png)\n\n### OutOfMemory 举例\n\n![image-20200706205947535](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706205947535.png)\n\n![image-20200706210000461](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706210000461.png)\n\n我们简单的写一个OOM例子\n\n```java\n/**\n * OOM测试\n */\npublic class OOMTest {\n    public static void main(String[] args) {\n        List<Integer> list = new ArrayList<>();\n        while(true) {\n            list.add(999999999);\n        }\n    }\n}\n\n```\n\n然后设置启动参数\n\n```\n-Xms10m -Xmx:10m\n```\n\n运行后，就出现OOM了，那么我们可以通过 VisualVM这个工具查看具体是什么参数造成的OOM\n\n![image-20200706211652779](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200706211652779.png)\n\n## 年轻代与老年代\n\n存储在JVM中的Java对象可以被划分为两类：\n\n- 一类是生命周期较短的瞬时对象，这类对象的创建和消亡都非常迅速\n  - 生命周期短的，及时回收即可\n- 另外一类对象的生命周期却非常长，在某些极端的情况下还能够与JVM的生命周期保持一致\n\nJava堆区进一步细分的话，可以划分为年轻代（YoungGen）和老年代（OldGen）\n\n其中年轻代又可以划分为**Eden空间**、**Survivor0空间**和**Survivor1空间**（有时也叫做from区、to区）\n\n![image-20200707075847954](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707075847954.png)\n\n下面这参数开发中一般不会调：\n\n![image-20200707080154039](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707080154039.png)\n\n- Eden：From：to  =  8:1:1\n- 新生代：老年代   =   1:2\n\n配置新生代与老年代在堆结构的占比。\n\n- 默认`-XX:NewRatio=2`，表示新生代占1，老年代占2，新生代占整个堆的1/3\n- 可以修改`-XX:NewRatio=4`，表示新生代占1，老年代占4，新生代占整个堆的1/5\n\n> 当发现在整个项目中，生命周期长的对象偏多，那么就可以通过调整 老年代的大小，来进行调优\n\n在HotSpot中，Eden空间和另外两个Survivor空间缺省所占的比例是8:1:1当然开发人员可以通过选项`\"-XX:SurvivorRatio\"`调整这个空间比例。比如`-XX:SurvivorRatio=8`\n\n几乎所有的Java对象都是在Eden区被new出来的。绝大部分的Java对象的销毁都在新生代进行了。（有些大的对象在Eden区无法存储时候，将直接进入老年代）\n\n>IBM公司的专门研究表明，新生代中80%的对象都是“朝生夕死”的。可以使用选项\"-Xmn\"设置新生代最大内存大小这个参数一般使用默认值就可以了。\n>\n\n![image-20200707084208115](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707084208115.png)\n\n``` java\n/**\n * -Xms600m -Xmx600m\n *\n * -XX:NewRatio ： 设置新生代与老年代的比例。默认值是2.\n * -XX:SurvivorRatio ：设置新生代中Eden区与Survivor区的比例。默认值是8\n * -XX:-UseAdaptiveSizePolicy ：关闭自适应的内存分配策略  （暂时用不到）\n * -Xmn:设置新生代的空间的大小。 （一般不设置）\n */\npublic class EdenSurvivorTest {\n    public static void main(String[] args) {\n        System.out.println(\"我只是来打个酱油~\");\n        try {\n            Thread.sleep(1000000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n\n\n## 图解对象分配过程\n\n### 概念\n\n为新对象分配内存是一件非常严谨和复杂的任务，JVM的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法与内存回收算法密切相关，所以还需要考虑GC执行完内存回收后是否会在内存空间中产生内存碎片。\n\n- new的对象先放伊甸园区。此区有大小限制。\n- 当伊甸园的空间填满时，程序又需要创建对象，JVM的垃圾回收器将对伊甸园区进行垃圾回收（MinorGC），将伊甸园区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到伊甸园区\n- 然后将伊甸园中的剩余对象移动到幸存者0区。\n- 如果再次触发垃圾回收，此时上次幸存下来的放到幸存者0区的，如果没有回收，就会放到幸存者1区。\n- 如果再次经历垃圾回收，此时会重新放回幸存者0区，接着再去幸存者1区。\n\n啥时候能去养老区呢？可以设置次数。默认是15次。\n\n- 在养老区，相对悠闲。当养老区内存不足时，再次触发GC：Major GC，进行养老区的内存清理\n- 若养老区执行了Major GC之后，发现依然无法进行对象的保存，就会产生OOM异常。\n\n可以设置参数：`-XX:MaxTenuringThreshold=N` 进行设置\n\n### 图解对象分配（一般情况）\n\n1、我们创建的对象，一般都是存放在Eden区的，**当我们Eden区满了后，就会触发GC操作**，一般被称为 YGC / Minor GC操作\n\n![image-20200707084714886](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707084714886.png)\n\n2、当我们进行一次垃圾收集后，红色的将会被回收，而绿色的还会被占用着，存放在S0（Survivor From）区。同时我们给每个对象设置了一个**年龄计数器**，一次Minor GC回收后年龄就是1。\n\n3、同时Eden区继续存放对象，当Eden区再次存满的时候，又会触发一个**Minor GC**操作，此时GC将会把Eden和Survivor From中的对象进行一次收集，把存活的对象放到S1（Survivor To）区，同时让年龄 + 1\n\n**注意**：Survivor From 和 Survivor To 是交替变换的，这次是From的下次就变成了To。每次Minor GC后都把依旧存活的从From区移动到To区，再把这个To区转换为From区（表明已经这里有数据了，下次数据就要从这里出去了），将刚才的From区转换为To区，等待下一次GC后存放数据。\n\n> 下一次再进行GC的时候：\n>\n> 1. 这一次的S0区为空，所以成为下一次GC的S1区\n> 2. 这一次的S1区则成为下一次GC的S0区\n> 3. 也就是说S0区和S1区在互相转换。\n\n![image-20200707085232646](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707085232646.png)\n\n4、我们继续不断地进行对象生成和垃圾回收，当Survivor中的对象的年龄达到15的时候，将会触发一次**Promotion晋升**的操作，也就是**将年轻代中的对象晋升到老年代中**。\n\n![image-20200707085737207](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707085737207.png)\n\n关于垃圾回收：频繁在新生区收集，很少在养老区收集，几乎不在永久区/元空间收集。\n\n### 思考：幸存者区满了以后如何操作？\n\n特别注意，**只有在Eden区满了的时候，才会触发Minor GC，而幸存者区满了后，不会主动触发Minor GC操作**，只能被动触发：Eden区满了，会连同幸存者区一起进行Minor GC。\n\n如果幸存者区在GC时发现还是满了， 那么数据会直接放到老年代。\n\n### 对象分配的特殊情况\n\n**情况一**：如果来了一个新对象，先看看 Eden 是否放的下？\n\n- 如果 Eden 放得下，则直接放到 Eden 区\n- 如果 Eden 放不下，则触发 YGC ，执行垃圾回收，看看还能不能放下？\n\n**情况二**：将对象放到老年区又有两种情况：\n\n- 如果 Eden 执行了 YGC 还是无法放不下该对象，那没得办法，只能说明是**超大对象**，**只能直接放到老年代**（即超大对象可能会直接放到老年代，其指的是在内存空间中是一个连续的大空间对象）\n- 那万一老年代都放不下，则**先触发Full GC **，再看看能不能放下，放得下最好，但如果还是放不下，那**只能报 OOM**\n\n**情况三**：如果 Eden 区满了，将对象往幸存区拷贝时，发现幸存区放不下了，那只能便宜了某些新对象，让他们直接晋升至老年区\n\n![image-20200707091058346](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707091058346.png)\n\n### 代码演示对象分配过程\n\n我们不断创建大对象\n\n```java\npublic class HeapInstanceTest {\n    byte [] buffer = new byte[new Random().nextInt(1024 * 200)];\n    public static void main(String[] args) throws InterruptedException {\n        ArrayList<HeapInstanceTest> list = new ArrayList<>();\n        while (true) {\n            list.add(new HeapInstanceTest());\n            Thread.sleep(10);\n        }\n    }\n}\n```\n\n然后设置JVM参数\n\n```bash\n-Xms600m -Xmx600m\n```\n\n然后cmd输入下面命令，打开VisualVM图形化界面\n\n```\njvisualvm\n```\n\n然后通过执行上面代码，通过VisualGC进行动态化查看\n\n![垃圾回收](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6.gif)\n\n最终，在老年代和新生代都满了，就出现OOM\n\n```\nException in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n\tat com.atguigu.java.chapter08.HeapInstanceTest.<init>(HeapInstanceTest.java:13)\n\tat com.atguigu.java.chapter08.HeapInstanceTest.main(HeapInstanceTest.java:17)\n```\n\n### 常用的调优工具\n\n- JDK 命令行\n- Eclipse：Memory Analyzer Tool\n- Jconsole\n- Visual VM（实时监控  推荐）\n- Jprofiler（推荐）\n- Java Flight Recorder（实时监控）\n- GCViewer\n- GCEasy\n\n### 总结\n\n- 针对幸存者S0，S1区的总结：复制之后有交换，谁空了谁是To\n- 关于垃圾回收：频繁在新生区收集，很少在老年代收集，几乎不再永久代和元空间进行收集\n- 新生代采用**复制算法**的目的：是为了减少内存碎片\n\n## Minor GC，MajorGC、Full GC\n\n- **Minor GC**：新生代的GC\n- **Major GC**：老年代的GC\n- **Full GC**：整堆收集，收集**整个Java堆和方法区**的垃圾收集\n\n注意Major GC和Full GC的区别：\n\n- Major GC只回收老年代的垃圾，而Full GC回收整个堆空间和方法区的垃圾（方法区后面变为元空间后不再受JVM控制，不会参与到Full GC）\n- 一般是先Minor GC，如果内存还不足，再Major GC，如果还不足，再Full GC\n- G1垃圾回收器就是尽可能避免Full GC\n- 打印出的GC日志里显示的是Full GC，包含元空间的信息\n\n\n\n>我们都知道，JVM的调优的一个环节，也就是垃圾收集，我们需要尽量的避免垃圾回收，因为在垃圾回收的过程中，容易出现STW的问题。而 Major GC 和 Full GC出现STW的时间，是Minor GC的**10倍以上**\n>\n\nJVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。针对Hotspot VM的实现，它里面的GC按照回收区域又分为两大种类型：一种是部分收集（Partial  GC），一种是整堆收集（Full GC）\n\n- **部分收集**：不是完整收集整个Java堆的垃圾收集。其中又分为：\n  - **新生代收集**（MinorGC / YoungGC）：只是新生代的垃圾收集\n  - **老年代收集**（MajorGC / OldGC）：只是老年代的圾收集。\n    - 目前，只有CMS会有单独收集老年代的行为。\n    - 注意，很多时候Major GC会和Full GC混淆使用，需要具体分辨是老年代回收还是整堆回收。\n  - **混合收集**（MixedGC）：收集整个新生代以及部分老年代的垃圾收集。\n    - 目前，只有G1 GC会有这种行为\n- **整堆收集**（Full GC）：收集整个java堆和方法区的垃圾收集。\n\n### Minor GC\n\n当年轻代空间不足时，就会触发MinorGC，这里的年轻代满指的是Eden区满，Survivor区满不会引发GC。（每次Minor GC会清理Eden区和Survivor区的内存。）\n\n因为Java对象大多都具备 **朝生夕灭** 的特性，所以Minor GC非常频繁，一般回收速度也比较快。这一定义既清晰又易于理解。\n\nMinor GC会引发STW，暂停其它用户的线程，等垃圾回收结束，用户线程才恢复运行\n\n> STW：stop the word\n\n![image-20200707095606813](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707095606813.png)\n\n### Major GC\n\n指发生在老年代的GC，对象从老年代消失时，我们说 “Major GC” 或 “Full GC” 发生了\n\n出现了Major GC，经常会伴随至少一次的Minor GC（但非绝对的，在Parallel Scavenge收集器的收集策略里就有直接进行Major GC的策略选择过程）。也就是在老年代空间不足时，会先尝试触发Minor GC。**如果之后空间还不足，再触发Major GC，否则就不再需要Major GC**。\n\nMajor GC的速度一般会比Minor GC慢10倍以上，STW的时间更长，如果Major GC后，内存还不足，就报OOM了。\n\n### Full GC\n\n触发Full GC执行的情况有如下五种：\n\n- 调用`System.gc()`时，系统建议执行Full GC，但是不必然执行\n- 老年代空间不足\n- 方法区空间不足（例如动态地加载了大量的类，在JDK 1.8后这些类信息进入元空间，不再受JVM控制，所以不再会Full GC了）\n- 通过Minor GC后进入老年代的平均大小大于老年代的可用内存\n- 由Eden区、Survivor space（From Space）区向Survivor space（To Space）区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小\n\n说明：Full GC 是开发或调优中尽量要避免的。这样暂时时间会短一些。\n\n### GC 举例\n\n我们编写一个OOM的异常，因为我们在不断的创建字符串，是存放在元空间的\n\n```java\npublic class GCTest {\n    public static void main(String[] args) {\n        int i = 0;\n        try {\n            List<String> list = new ArrayList<>();\n            String a = \"mogu blog\";\n            while(true) {\n                list.add(a);\n                a = a + a;\n                i++;\n            }\n        }catch (Exception e) {\n            e.getStackTrace();\n        }\n    }\n}\n```\n\n设置JVM启动参数\n\n```bash\n-Xms10m -Xmx10m -XX:+PrintGCDetails\n```\n\n打印出的日志\n\n```\n[GC (Allocation Failure) [PSYoungGen: 2038K->500K(2560K)] 2038K->797K(9728K), 0.3532002 secs] [Times: user=0.01 sys=0.00, real=0.36 secs] \n[GC (Allocation Failure) [PSYoungGen: 2108K->480K(2560K)] 2405K->1565K(9728K), 0.0014069 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] \n[Full GC (Ergonomics) [PSYoungGen: 2288K->0K(2560K)] [ParOldGen: 6845K->5281K(7168K)] 9133K->5281K(9728K), [Metaspace: 3482K->3482K(1056768K)], 0.0058675 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] \n[GC (Allocation Failure) [PSYoungGen: 0K->0K(2560K)] 5281K->5281K(9728K), 0.0002857 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] \n[Full GC (Allocation Failure) [PSYoungGen: 0K->0K(2560K)] [ParOldGen: 5281K->5263K(7168K)] 5281K->5263K(9728K), [Metaspace: 3482K->3482K(1056768K)], 0.0058564 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] \nHeap\n PSYoungGen      total 2560K, used 60K [0x00000000ffd00000, 0x0000000100000000, 0x0000000100000000)\n  eden space 2048K, 2% used [0x00000000ffd00000,0x00000000ffd0f138,0x00000000fff00000)\n  from space 512K, 0% used [0x00000000fff00000,0x00000000fff00000,0x00000000fff80000)\n  to   space 512K, 0% used [0x00000000fff80000,0x00000000fff80000,0x0000000100000000)\n ParOldGen       total 7168K, used 5263K [0x00000000ff600000, 0x00000000ffd00000, 0x00000000ffd00000)\n  object space 7168K, 73% used [0x00000000ff600000,0x00000000ffb23cf0,0x00000000ffd00000)\n Metaspace       used 3514K, capacity 4498K, committed 4864K, reserved 1056768K\n  class space    used 388K, capacity 390K, committed 512K, reserved 1048576K\n  \n  Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space\n\tat java.util.Arrays.copyOfRange(Arrays.java:3664)\n\tat java.lang.String.<init>(String.java:207)\n\tat java.lang.StringBuilder.toString(StringBuilder.java:407)\n\tat com.atguigu.java.chapter08.GCTest.main(GCTest.java:20)\n```\n\n触发OOM的时候，一定是进行了一次Full GC，因为只有在老年代空间不足时候，才会爆出OOM异常\n\n- [PSYoungGen: 2037K->504K(2560K)]：年轻代总空间为 2560K ，当前占用 2037K ，经过垃圾回收后剩余504K\n- 2037K->728K(9728K)：堆内存总空间为 9728K ，当前占用2037K ，经过垃圾回收后剩余728K\n\n## 堆空间分代思想\n\n 为什么要把Java堆分代？不分代就不能正常工作了吗？经研究，不同对象的生命周期不同。70%-99%的对象是临时对象。\n\n>新生代：有Eden、两块大小相同的survivor（又称为from/to，s0/s1）构成，to总为空。\n>老年代：存放新生代中经历多次GC仍然存活的对象。\n\n![image-20200707101511025](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707101511025.png)\n\n其实不分代完全可以，分代的唯一理由就是优化GC性能。如果没有分代，那所有的对象都在一块，就如同把一个学校的人都关在一个教室。GC的时候要找到哪些对象没用，这样就会对堆的所有区域进行扫描。而很多对象都是朝生夕死的，如果分代的话，把新创建的对象放到某一地方，当GC的时候先把这块存储“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。\n\n![image-20200707101543871](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707101543871.png)\n\n\n\n## 内存分配策略\n\n如果对象在Eden出生并经过第一次Minor GC后仍然存活，并且能被Survivor容纳的话，将被移动到Survivor空间中，并将对象年龄设为1。对象在Survivor区中每熬过一次Minor GC，年龄就增加1岁，当它的年龄增加到一定程度（默认为15岁，其实每个JVM、每个GC都有所不同）时，就会被晋升到老年代。\n\n对象晋升老年代的年龄阀值，可以通过选项`-XX:MaxTenuringThreshold`来设置。针对不同年龄段的对象分配原则如下所示：\n\n- **优先分配到Eden**\n  - 开发中比较长的字符串或者数组，会直接存在老年代，但是因为新创建的对象都是朝生夕死的，所以这个大对象可能也很快被回收，但是因为老年代触发Major GC的次数比 Minor GC要更少，因此可能回收起来就会比较慢\n- **大对象直接分配到老年代**\n  - 尽量避免程序中出现过多的大对象\n- **长期存活的对象分配到老年代**\n- **动态对象年龄判断** \n  - 如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。\n- **空间分配担保**：` -XX:HandlePromotionFailure`。\n\n\n### 空间分配担保策略\n\n在发生Minor GC**之前**，虚拟机会检查老年代**最大可用的连续空间**是否大于**新生代所有对象的总空间**：\n\n- 如果大于，则此次Minor GC是安全的，进行Minor GC（代表这次Minor GC后晋升到老年代的数据肯定不会超出老年代内存空间，肯定不需要Full GC）\n- 如果小于，则虚拟机会查看-`XX:HandlePromotionFailure` 设置值**是否允许担保失败**。\n  - 如果 `HandlePromotionFailure=true`，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小。\n    - 如果大于，则尝试进行一次Minor GC，但这次Minor GC依然是**有风险的**；\n    - 如果小于，则改为直接进行一次Full GC，不再Minor GC）。\n  - 如果`HandlePromotionFailure=false`，则改为直接进行一次Full GC（不再Minor GC）。\n\n简单理解，空间分配担保策略是指在Minor GC前判断**是否愿意承担一定的风险来节省一次Full GC**（风险是指进行了Minor GC还是有很多数据要存到老年代导致超出老年代空间，还得再Full GC，等于说白做了一次Minor GC，如果愿意承担这个风险，就能省一次Full GC）\n\n**历史版本**\n\n1. 在JDK 6 Update 24（JDK 7）之后，`HandlePromotionFailure`参数不会再影响到虚拟机的空间分配担保策略，观察openJDK中的源码变化，虽然源码中还定义了`HandlePromotionFailure`参数，但是在代码中已经不会再使用它。\n2. JDK 6 Update 24（JDK 7）之后设置 `HandlePromotionFailure=true`，**只要老年代的连续空间大于新生代对象总大小或者历次晋升的平均大小就会进行Minor GC**，否则将进行Full GC。\n\n## 为对象分配内存：TLAB\n\n---\n\n**问题：堆空间都是共享的么？**\n\n不一定，因为还有TLAB这个概念。在堆中划分出一块区域为每个线程所独占，其他线程无法并发在这块区域内**开辟内存空间**存放数据（**但是不影响其正常访问该区域内创建出的对象**）。\n\n---\n\n### 什么是 TLAB\n\n堆区是线程共享区域，任何线程都可以访问到堆区中的共享数据。但由于对象实例的创建在JVM中非常频繁，因此在并发环境下**从堆区中划分内存空间是线程不安全的**。\n\n> 说明：此处的线程不安全是指不同线程在创建对象时都将从堆区中开辟一段内存空间，这时如果多个线程并发开辟同一段内存空间就会线程不安全，为避免多个线程操作同一地址，需要使用**加锁**等机制，进而影响分配速度。TLAB就是为了解决该问题而被提出。\n\n**TLAB：Thread Local Allocation Buffer**，为每个线程单独分配一个缓冲区。\n\n从内存模型而不是垃圾收集的角度，对Eden区域继续进行划分，JVM为每个线程分配了一个私有缓存区域，**它包含在Eden空间内**。只有当前线程能够在该空间开辟内存空间存放数据，其他线程无法并发在这块区域内**开辟内存空间**存放数据（**但是不影响其正常访问该区域内创建出的对象**）。\n\n多线程**同时分配内存**时，使用TLAB可以避免一系列的非线程安全问题，同时还能够提升内存分配的吞吐量，因此我们可以将这种内存分配方式称之为**快速分配策略**。\n\n![image-20200707103547712](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707103547712.png)\n\n- 每个线程都有一个TLAB空间\n- 当一个线程的TLAB存满时，可以使用公共区域（蓝色）的\n\n所有OpenJDK衍生出来的JVM都提供了TLAB的设计。尽管不是所有的对象实例都能够在TLAB中成功分配内存，但JVM确实是将TLAB作为内存分配的首选。\n\n在程序中，开发人员可以通过选项`\"-XX:UseTLAB\"`设置是否开启TLAB空间。默认情况下，TLAB空间的内存非常小，仅占有整个Eden空间的1%，当然我们可以通过选项`\"-XX:TLABWasteTargetPercent\"`设置TLAB空间所占用Eden空间的百分比大小。\n\n一旦对象在TLAB空间分配内存失败时，JVM就会尝试着通过使用**加锁机制确保数据操作的原子性**，从而**直接在Eden空间中分配内存**（在其他Eden空间分配内存时若不加锁可能导致多线程并发在同一个区域分配内存）。\n\n> 哪个线程要分配内存，就在哪个线程的本地缓冲区中分配，只有本地缓冲区用完 了，**分配新的缓存区时才需要同步锁定** —-《深入理解JVM》\n\n### TLAB 分配过程\n\n对象首先是通过TLAB开辟空间，如果不能放入，那么需要通过加锁机制在Eden区进行分配：\n\n![image-20200707104253530](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707104253530.png)\n\n## 堆空间的参数设置\n\n> **官方文档**：https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html\n\n- `-XX：+PrintFlagsInitial`：查看所有的参数的默认初始值\n- `-XX:+PrintFlagsFinal`：查看所有的参数的最终值（可能会存在修改，不再是初始值）\n- `-Xms`：初始堆空间内存（默认为物理内存的1/64）\n- `-Xmx`：最大堆空间内存（默认为物理内存的1/4）\n- `-Xmn`：设置新生代的大小。（初始值及最大值）\n- `-XX:NewRatio`：配置新生代与老年代在堆结构的占比\n- `-XX:SurvivorRatio`：设置新生代中Eden和S0/S1空间的比例\n- `-XX:MaxTenuringThreshold`：设置新生代垃圾的最大年龄\n- `-XX:+PrintGCDetails`：输出详细的GC处理日志\n  - 打印gc简要信息：①`-XX:+PrintGC ` ② `-verbose:gc`\n- `-XX:HandlePromotionFalilure`：是否设置空间分配担保\n- `-server`：启动Server模式，因为在server模式下，才可以启用逃逸分析。\n- `-XX:+DoEscapeAnalysis`：启用逃逸分析\n- `-Xmx10m`：指定了堆空间最大为10MB\n- `-XX:+PrintGC`：将打印Gc日志\n- `-XX:+EliminateAllocations`：开启了标量替换（默认打开），允许将对象打散分配在栈上，比如对象拥有id和name两个字段，那么这两个字段将会被视为两个独立的局部变量进行分配\n\n## 堆是分配对象的唯一选择么？\n\n>  应该说，是的。\n\n**在《深入理解Java虚拟机》中关于Java堆内存有这样一段描述：**\n\n- 随着JIT编译期的发展与**逃逸分析技术**逐渐成熟，**栈上分配、标量替换**优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。\n- 在Java虚拟机中，对象是在Java堆中分配内存的，这是一个普遍的常识。但是，有一种特殊情况，那就是**如果经过逃逸分析（Escape Analysis）后发现，一个对象并没有逃逸出方法的话，那么就可能被优化成栈上分配**。这样就无需在堆上分配内存，也无须进行垃圾回收了。这也是最常见的堆外存储技术。\n- 此外，前面提到的基于OpenJDK深度定制的TaoBao VM，其中创新的GCIH（GC invisible heap）技术实现off-heap，将生命周期较长的Java对象从heap中移至heap外，并且GC不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升GC的回收效率的目的。\n\n### 逃逸分析\n\n如何将堆上的对象分配到栈，需要使用**逃逸分析手段**。\n\n这是一种可以有效减少Java程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，Java Hotspot编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。逃逸分析的基本行为就是分析对象动态作用域：\n\n- 当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。\n- 当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中。\n\n#### 逃逸分析举例\n\n没有发生逃逸的对象，则可以分配到栈上，随着方法执行的结束，栈空间就被移除，每个栈里面包含了很多栈帧，也就是发生逃逸分析\n\n```java\npublic void my_method() {\n    V v = new V();\n    // use v\n    // ....\n    v = null;\n}\n```\n\n针对下面的代码\n\n```java\npublic static StringBuffer createStringBuffer(String s1, String s2) {\n    StringBuffer sb = new StringBuffer();\n    sb.append(s1);\n    sb.append(s2);\n    return sb;\n}\n```\n\n如果想要`StringBuffer sb`不发生逃逸，可以这样写\n\n```java\npublic static String createStringBuffer(String s1, String s2) {\n    StringBuffer sb = new StringBuffer();\n    sb.append(s1);\n    sb.append(s2);\n    return sb.toString();\n}\n```\n\n完整的逃逸分析代码举例\n\n```java\n/**\n * 逃逸分析\n * 如何快速的判断是否发生了逃逸分析，就看new的对象是否在方法外被调用。\n */\npublic class EscapeAnalysis {\n\n    public EscapeAnalysis obj;\n\n    /**\n     * 方法返回EscapeAnalysis对象，发生逃逸\n     * @return\n     */\n    public EscapeAnalysis getInstance() {\n        return obj == null ? new EscapeAnalysis():obj;\n    }\n\n    /**\n     * 为成员属性赋值，发生逃逸\n     */\n    public void setObj() {\n        this.obj = new EscapeAnalysis();\n    }\n\n    /**\n     * 对象的作用于仅在当前方法中有效，没有发生逃逸\n     */\n    public void useEscapeAnalysis() {\n        EscapeAnalysis e = new EscapeAnalysis();\n    }\n\n    /**\n     * 引用成员变量的值，发生逃逸\n     */\n    public void useEscapeAnalysis2() {\n        EscapeAnalysis e = getInstance();\n        // getInstance().XXX  发生逃逸\n    }\n}\n```\n\n#### 参数设置\n\n在JDK 1.7 版本之后，HotSpot中**默认就已经开启了逃逸分析**\n\n如果使用的是较早的版本，开发人员则可以通过：\n\n- 选项`\"-XX:+DoEscapeAnalysis\"`显式开启逃逸分析\n- 通过选项`\"-XX:+PrintEscapeAnalysis\"`查看逃逸分析的筛选结果\n\n#### 结论\n\n开发中能使用局部变量的，就不要使用在方法外定义。\n\n使用逃逸分析，编译器可以对代码做如下优化：\n\n- **栈上分配**：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会发生逃逸，对象可能是栈上分配的候选，而不是堆上分配\n- **同步省略**：如果一个对象被发现只有一个线程被访问到，那么对于这个对象的操作可以不考虑同步。\n- **分离对象或标量替换**：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而是存储在CPU寄存器中。\n\n**Hotspot里没有实现栈上分配和同步省略。**\n\n### 栈上分配\n\nJIT编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无须进行垃圾回收了。\n\n**栈上分配本质使用的还是标量替换方式，将方法内的对象分解成标量数据后再存储在栈的局部变量表上，所以严格来说引用类型对象还是分配在堆空间上的，因为方法内不逃逸的对象会被分解成标量数据存储，就不再是引用类型对象了。**\n\n常见的栈上分配的场景\n\n> 在逃逸分析中，已经说明了。分别是给成员变量赋值、方法返回值、实例引用传递。\n\n#### 举例\n\n我们通过举例来说明开启逃逸分析和未开启逃逸分析时候的情况\n\n```java\n/**\n * 栈上分配\n * -Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails\n */\nclass User {\n    private String name;\n    private String age;\n    private String gender;\n    private String phone;\n}\n\npublic class StackAllocation {\n    public static void main(String[] args) throws InterruptedException {\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < 100000000; i++) {\n            alloc();\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(\"花费的时间为：\" + (end - start) + \" ms\");\n\n        // 为了方便查看堆内存中对象个数，线程sleep\n        Thread.sleep(10000000);\n    }\n\n    private static void alloc() {\n        // 未发生逃逸\n        User user = new User(); \n    }\n}\n```\n\n设置JVM参数，表示未开启逃逸分析\n\n```\n-Xmx1G -Xms1G -XX:-DoEscapeAnalysis -XX:+PrintGCDetails\n```\n\n运行结果，同时还触发了GC操作\n\n```\n花费的时间为：664 ms\n```\n\n然后查看内存的情况，发现有大量的User存储在堆中\n\n![image-20200707203038615](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707203038615.png)\n\n我们再开启逃逸分析\n\n```\n-Xmx1G -Xms1G -XX:+DoEscapeAnalysis -XX:+PrintGCDetails\n```\n\n然后查看运行时间，我们能够发现花费的时间快速减少，同时不会发生GC操作\n\n```\n花费的时间为：5 ms\n```\n\n在看内存情况，我们发现只有很少的User对象，说明User未发生逃逸，因为它存储在栈中，随着栈的销毁而消失\n\n![image-20200707203441718](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707203441718.png)\n\n### 同步省略（同步锁消除）\n\n线程同步的代价是相当高的，同步的后果是降低并发性和性能。\n\n在动态编译同步块的时候，JIT编译器可以**借助逃逸分析**来判断同步块所使用的**锁对象是否只能够被一个线程访问而没有被发布到其他线程**。如果没有，那么JIT编译器在编译这个同步块的时候就会**取消对这部分代码的同步**。这样就能大大提高并发性和性能。**这个取消同步的过程就叫同步省略，也叫锁消除。**\n\n例如下面的代码：\n\n```java\npublic void f() {\n    Object hellis = new Object();\n    synchronized(hellis) {\n        System.out.println(hellis);\n    }\n}\n```\n\n代码中对`hellis`这个对象加锁，但是hellis对象的生命周期只在`f()`方法中，并不会被其他线程所访问到，所以在JIT编译阶段就会被优化掉，优化成：\n\n```java\npublic void f() {\n    Object hellis = new Object();\n\tSystem.out.println(hellis);\n}\n```\n\n我们将其转换成字节码\n\n![image-20200707205634266](/images/%E3%80%90JVM%E3%80%91JVM%E5%A0%86/image-20200707205634266.png)\n\n注意：字节码文件中并没有进行优化，可以看到加锁和释放锁的操作依然存在，**同步省略操作是在解释运行时发生的**。\n\n### 分离对象和标量替换\n\n**标量（Scalar）是指一个无法再分解成更小的数据的数据**。Java中的**原始数据类型就是标量**。\n\n相对的，那些**还可以分解的数据叫做聚合量（Aggregate）**，Java中的**引用类型对象就是聚合量**，因为他**可以分解成其他聚合量和标量**。\n\n**在JIT阶段**，如果经过逃逸分析，发现一个对象不会被外界访问的话，**那么经过JIT优化，就会把这个对象拆解成若干个其中包含的若干个成员变量来代替。这个过程就是标量替换。**\n\n```java\npublic static void main(String args[]) {\n    alloc();\n}\nclass Point {\n    private int x;\n    private int y;\n}\nprivate static void alloc() {\n    Point point = new Point(1,2);\n    System.out.println(\"point.x\" + point.x + \";point.y\" + point.y);\n}\n```\n\n以上代码，经过标量替换后，就会变成\n\n```java\nprivate static void alloc() {\n    int x = 1;\n    int y = 2;\n    System.out.println(\"point.x = \" + x + \"; point.y=\" + y);\n}\n```\n\n可以看到，Point这个聚合量经过逃逸分析后，发现他并没有逃逸，就被替换成两个标量了。那么标量替换有什么好处呢？就是可以大大减少堆内存的占用。因为一旦不需要创建对象了，那么就不再需要分配堆内存了。\n\n**标量替换为栈上分配提供了很好的基础。**\n\n### 代码优化之标量替换\n\n上述代码在主函数中进行了1亿次alloc。调用进行对象创建，由于User对象实例需要占据约16字节的空间，因此累计分配空间达到将近1.5GB。如果堆空间小于这个值，就必然会发生GC。使用如下参数运行上述代码：\n\n```bash\n-server -Xmx100m -Xms100m -XX:+DoEscapeAnalysis -XX:+PrintGC -XX:+EliminateAllocations\n```\n\n这里设置参数如下：\n\n- 参数`-server`：启动Server模式，因为在server模式下，才可以启用逃逸分析。\n- 参数`-XX:+DoEscapeAnalysis`：启用逃逸分析\n- 参数`-Xmx10m`：指定了堆空间最大为10MB\n- 参数`-XX:+PrintGC`：将打印Gc日志\n- 参数`-XX:+EliminateAllocations`：开启了标量替换（默认打开），允许将对象打散分配在栈上，比如对象拥有id和name两个字段，那么这两个字段将会被视为两个独立的局部变量进行分配\n\n### 逃逸分析的不足\n\n关于逃逸分析的论文在1999年就已经发表了，但直到JDK1.6才有实现，而且这项技术到如今也并不是十分成熟。\n\n其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。\n一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。\n\n虽然这项技术并不十分成熟，但是它也是即时编译器优化技术中一个十分重要的手段。注意到有一些观点，认为通过逃逸分析，JVM会在栈上分配那些不会逃逸的对象，这在理论上是可行的，但是取决于JvM设计者的选择。据我所知，oracle Hotspot JVM中并未这么做，这一点在逃逸分析相关的文档里已经说明，所以可以明确所有的对象实例都是创建在堆上。\n\n目前很多书籍还是基于JDK7以前的版本，JDK已经发生了很大变化，intern字符串的缓存和静态变量曾经都被分配在永久代上，而永久代已经被元数据区取代。但是，intern字符串缓存和静态变量并不是被转移到元数据区，而是直接在堆上分配，所以这一点同样符合前面一点的结论：对象实例都是分配在堆上。\n\n## 小结\n\n年轻代是对象的诞生、成长、消亡的区域，一个对象在这里产生、应用，最后被垃圾回收器收集、结束生命。\n\n老年代放置长生命周期的对象，通常都是从Survivor区域筛选拷贝过来的Java对象。当然，也有特殊情况，我们知道普通的对象会被分配在TLAB上；如果对象较大，JVM会试图直接分配在Eden其他位置上；如果对象太大，完全无法在新生代找到足够长的连续空闲空间，JVM就会直接分配到老年代。当GC只发生在年轻代中，回收年轻代对象的行为被称为Minor GC。\n\n当GC发生在老年代时则被称为MajorGc或者FullGC。一般的，Minor GC的发生频率要比Major GC高很多，即老年代中垃圾回收发生的频率将大大低于年轻代。\n\nHotspot里没有实现栈上分配和同步省略。\n\n\n\n\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JUC】AQS 源码分析","url":"/2021/09/24/【JUC】AQS源码分析/","content":"\n## LockSupport\n\n### 线程等待和唤醒方式\n\n3种让线程等待和唤醒的方法：\n\n- 方式1：使用`Object`中的`wait()`方法让线程等待，使用`Object`中的`notify()`方法唤醒线程\n- 方式2：使用JUC包中`Condition`的`await()`方法让线程等待，使用`signal()`方法唤醒线程\n- 方式3：使用`LockSupport`类的`park()` 和 `unpark()` 阻塞当前线程以及唤醒指定被阻塞的线程\n\n传统的`synchronized`和`Lock`实现等待唤醒通知的约束：\n\n- 线程先要获得并持有锁，必须在锁块(`synchronized`或`lock`)中\n- 必须要先等待后唤醒，线程才能够被唤醒\n\n前两种方式存在的问题：\n\n- `Object`类中的`wait()`和`notify()`方法**必须要在同步块或者方法里面且成对出现使用**，否则会抛出`java.lang.IllegalMonitorStateException`。并且调用顺序必须是先`wait()`后`notify()`，否则线程无法被唤醒。\n- `Condition`类中的`await()`和`signal()`方法**必须要在同步块或者方法里面且成对出现使用**，否则会抛出`java.lang.IllegalMonitorStateException`。并且调用顺序必须是先`await()`后`signal()`，否则线程无法被唤醒。\n\n第三种使用`LockSupport`的方式则不会出现这些问题。\n\n### LockSupport 介绍\n\n> [LockSupport Java doc](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/locks/LockSupport.html)\n\n`LockSupport`（锁支持）是用来创建锁和其他同步类的**基本线程阻塞原语**。`LockSupport`中的 `park()` 和 `unpark(thread)` 的作用分别是**阻塞线程**和**解除阻塞线程**。其功能比`wait/notify`，`await/signal`更强。\n\n`LockSuport`是一个**线程阻塞工具类**，所有的方法都是**静态方法**，可以让线程在任意位置阻塞，阻寨之后也有对应的唤醒方法。归根结底，`LockSupport`调用的`Unsafe`中的`native`代码。\n\n<!-- More -->\n\n> Basic thread blocking primitives for creating locks and other synchronization classes.\n>\n> This class associates, with each thread that uses it, a permit (in the sense of the Semaphore class). A call to park will return immediately if the permit is available, consuming it in the process; otherwise it may block. A call to unpark makes the permit available, if it was not already available. (Unlike with Semaphores though, permits do not accumulate. There is at most one.) \n\n`LockSupport`类**通过`park()`和`unpark(thread)`方法来实现阻塞和唤醒线程的操作**。\n\n其使用了一种名为`Permit`（许可）的概念来做到阻塞和唤醒线程的功能，**每个线程都有一个许可（permit）**，**permit只有两个值1和零，默认是零**。可以把许可看成是一种信号量（Semaphore），但与Semaphore不同的是，**许可的累加上限是1**。\n\n---\n\n**面试题**：\n\n- 为什么`LockSupport`可以先唤醒线程后阻塞线程：因为`unpark(a)`让线程a先获得了一个凭证，之后a线程再调用`park()`方法时，就可以名正言顺的凭证消费，故不会阻塞。\n- 为什么`LockSupport`唤醒两次后阻塞两次，但最终结果还会阻塞线程：因为凭证的数量最多为1（不能累加），连续调用两次`unpark()`和调用一次效果一样，只会增加一个凭证；而调用两次`park()`却需要消费两个凭证，证不够，不能放行。\n\n---\n\n### LockSupport 源码\n\n- `park()` / `park(Object blocker)`：阻塞当前线程 / 阻塞传入的具体线程。其底层使用了`Unsafe`类的`native`本地方法：\n\n``` java\npublic class LockSupport {\n\n    //...\n\n    public static void park() {\n        UNSAFE.park(false, 0L);\n    }\n\n    public static void park(Object blocker) {\n        Thread t = Thread.currentThread();\n        setBlocker(t, blocker);\n        UNSAFE.park(false, 0L);\n        setBlocker(t, null);\n    }\n\n    //...   \n}\n```\n\n`permit`默认是0，所以一开始调用`park()`方法，当前线程就会阻塞，直到别的线程将当前线程的`permit`设置为1时，`park()`方法会被唤醒，然后会将`permit`再次设置为0并返回。（若其他线程事先调用了`unpark(a)`，则a线程的`permit`事先就变为了1，其后续再调用`park()`时就不会阻塞）\n\n- `unpark(Thread thread)` ：唤醒处于阻塞状态的指定线程\n\n``` java\npublic class LockSupport {\n\n    //...\n\n    public static void unpark(Thread thread) {\n        if (thread != null)\n            UNSAFE.unpark(thread);\n    }\n\n    //...\n\n}\n```\n\n调用`unpark(thread)`方法后，就会将`thread`线程的许可`permit`设置成1（注意多次调用`unpark()`方法，不会累加，`pemit`值还是1）。从而自动唤醒`thead`线程，即之前阻塞中的`LockSupport.park()`方法会立即返回。\n\n### LockSupport 案例解析\n\n``` java\npublic class LockSupportDemo {\n\n    public static void main(String[] args) {\n        Thread a = new Thread(()->{\n            //\ttry {\n            //\t\tTimeUnit.SECONDS.sleep(2);\n            //\t} catch (InterruptedException e) {\n            //\t\te.printStackTrace();\n            //  }\n            System.out.println(Thread.currentThread().getName() + \" come in. \" + System.currentTimeMillis());\n            LockSupport.park();\n            System.out.println(Thread.currentThread().getName() + \" 换醒. \" + System.currentTimeMillis());\n        }, \"Thread A\");\n        a.start();\n\n        Thread b = new Thread(()->{\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            LockSupport.unpark(a);\n            System.out.println(Thread.currentThread().getName()+\" 通知.\");\n        }, \"Thread B\");\n        b.start();\n    }\t\n}\n```\n\n输出结果：\n\n``` java\nThread A come in.\nThread B 通知.\nThread A 换醒.\n```\n\n正常 + 无锁块要求。先前错误的先唤醒后等待顺序，`LockSupport`可无视这顺序。\n\n### 总结\n\n`LockSuport`是一个**线程阻塞工具类**，所有的方法都是**静态方法**，可以让线程在任意位置阻塞，阻寨之后也有对应的唤醒方法。归根结底，`LockSupport`调用的`Unsafe`中的`native`代码。\n\n`LockSupport`提供`park()`和`unpark()`方法实现阻塞线程和解除线程阻塞的过程。`LockSupport`和每个使用它的线程都有一个许可(`permit`)关联。`permit`相当于1，0的开关，默认是0，调用一次`unpark()`就加1变成1，调用一次`park()`会消费`permit`，也就是将1变成0，同时`park()`立即返回。\n\n如再次调用`park()`会变成阻塞（因为`permit`为0了会阻塞在这里，一直到`permit`变为1），这时调用`unpark()`会把`permit`置为1。每个线程都有一个相关的`permit`，`permit`最多只有一个，**重复调用`unpark()`也不会积累凭证**。\n\n**形象的理解**\n\n线程阻塞需要消耗凭证(permit)，这个凭证最多只有1个。当调用`park()`方法时：\n\n- 如果有凭证，则会直接消耗掉这个凭证然后正常退出。\n- 如果无凭证，就必须阻塞等待凭证可用。\n\n而`unpark()`则相反，它会增加一个凭证，但凭证最多只能有1个，累加无效。\n\n---\n\n**面试题**：\n\n- 为什么`LockSupport`可以先唤醒线程后阻塞线程：因为`unpark(a)`让线程a先获得了一个凭证，之后a线程再调用`park()`方法时，就可以名正言顺的凭证消费，故不会阻塞。\n- 为什么`LockSupport`唤醒两次后阻塞两次，但最终结果还会阻塞线程：因为凭证的数量最多为1（不能累加），连续调用两次`unpark()`和调用一次效果一样，只会增加一个凭证；而调用两次`park()`却需要消费两个凭证，证不够，不能放行。\n\n---\n\n## AQS 理论\n\nAQS：`AbstractQueuedSynchronizer` **抽象的队列同步器**。\n\nAQS是用来构建锁或者其它同步器组件的**重量级基础框架**及**整个JUC体系的基石**， 通过内置的FIFO队列来完成资源获取线程的排队工作，并通过一个int类变量`state`表示持有锁的状态。\n\n**AQS 中大量应用了 CAS + Unsafe 保证自旋原子性地添加节点。**\n\n- 每次在抢占锁的时候都会CAS，因为可能其他非公平锁并发地抢占了锁，那么当前线程就需要再次自旋尝试获取锁。\n- 每次在修改时（例如添加修改节点时）都使用 `Unsafe` 类的 `native` 方法保证修改的原子性。\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/47fad3563d427ffe5058343de85e3e05.png)\n\nCLH：Craig、Landin and Hagersten队列（三位科学家的名字简写），是一个单向链表，AQS中的队列是CLH变体的**虚拟双向队列FIFO**。\n\n![image-20210926135141194](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926135141194.png)\n\nJUC的`locks`包下：\n\n- AbstractOwnableSynchronizer\n- AbstractQueuedLongSynchronizer\n- **AbstractQueuedSynchronizer**\n\nAQS是一个抽象的父类，可以将其理解为一个框架。基于AQS这个框架，我们可以实现多种同步器，比如下方图中的几个Java内置的同步器。同时我们也可以基于AQS框架实现我们自己的同步器以满足不同的业务场景需求。\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/7ecbe7fbeecd5d5e20b2d8de59e8a033.png)\n\nAQS中使用了**模板方法**的设计模式，AQS父类中的 `tryAcquire()` 方法和 `tryRelease()` 方法中只有 `throw new UnsupportedOperationException();`，说明如果子类不重写代码时被调用就会抛出异常：\n\n![image-20210927102559000](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927102559000.png)\n\n### AQS 能干嘛？\n\n加锁会导致阻塞：有阻塞就需要排队，实现排队必然需要有某种形式的队列来进行管理\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/47fad3563d427ffe5058343de85e3e05.png)\n\n1、抢到资源的线程直接使用办理业务，抢占不到资源的线程的必然涉及一种**排队等候机制**，抢占资源失败的线程继续去等待（类似办理窗口都满了，暂时没有受理窗口的顾客只能去候客区排队等候），仍然保留获取锁的可能且获取锁流程仍在继续（候客区的顾客也在等着叫号，轮到了再去受理窗口办理业务）。\n\n2、既然说到了**排队等候机制**，那么就一定会有某种队列形成，这样的队列是什么数据结构呢?\n\n3、如果共享资源被占用，就需要一定的**阻塞等待唤醒机制**来保证锁分配。这个机制主要用的是CLH队列的变体实现的，将暂时获取不到锁的线程加入到队列中，这个队列就是AQS的抽象表现。它将请求共享资源的线程封装成队列的结点(Node) ，通过CAS、自旋以及`LockSuport.park()`的方式，维护`state`变量的状态，使并发达到同步的效果。\n\n## AQS 结构\n\nAQS使用一个`volatile`的`int`类型的成员变量`state`来表示同步状态，通过内置的FIFO队列来完成资源获取的排队工作，将每条要去抢占资源的线程封装成一个`Node`，节点来实现锁的分配，通过CAS完成对`state`值的修改。\n\n``` java\npublic abstract class AbstractQueuedSynchronizer\n    extends AbstractOwnableSynchronizer\n    implements java.io.Serializable {\n\n    private static final long serialVersionUID = 7373984972572414691L;\n\n    // Creates a new {@code AbstractQueuedSynchronizer} instance\n    protected AbstractQueuedSynchronizer() { }\n\n    // Wait queue node class.\n    static final class Node {\n    }\n\n    // 头结点，你直接把它当做当前持有锁的线程 可能是最好理解的。实际上可能略有出入，往下看分析即可\n    private transient volatile Node head;\n\n    // 阻塞的尾节点，每个新的节点进来，都插入到最后，也就形成了一个链表\n    private transient volatile Node tail;\n\n    // 这个是最重要的，代表当前锁的状态，0代表没有被占用，大于 0 代表有线程持有当前锁\n    // 这个值可以大于 1，是因为锁可以重入，每次重入都加上 1\n    private volatile int state;\n\n    // 代表当前持有独占锁的线程，举个最重要的使用例子，因为锁可以重入\n    // reentrantLock.lock()可以嵌套调用多次，所以每次用这个来判断当前线程是否已经拥有了锁\n    // if (currentThread == getExclusiveOwnerThread()) {state++}\n    private transient Thread exclusiveOwnerThread; //继承自AbstractOwnableSynchronizer\n\n    // Returns the current value of synchronization state.\n    protected final int getState() {...}\n\n    // Sets the value of synchronization state.\n    protected final void setState(int newState) {...}\n\n    // Atomically sets synchronization state to the given updated\n    protected final boolean compareAndSetState(int expect, int update) {\n        ...\n    }         \n}\n```\n\n**四个比较重要的属性**：\n\n- `Node head`：指向哨兵节点\n- `Node tail`：指向尾结点，新来的线程将成为尾结点\n- `state`：代表当前锁的状态，0代表没有被占用，大于 0 代表有线程持有当前锁。这个值可以大于 1，是因为锁可以重入，每次重入都加上 1\n- `Thread exclusiveOwnerThread`：占有排它锁的线程，代表当前哪个线程正在占有着锁，后续抢占锁时将依据该值是否为 `null` 来判断锁是否已经被占用；释放锁时会将该值设置为 `null` \n\n### Node 类结构\n\nNode 的数据结构其实就是 `thread `+ `waitStatus `+ `pre `+ `next `四个属性而已。\n\n``` java\nstatic final class Node {\n    // 标识节点当前在共享模式下\n    static final Node SHARED = new Node();\n    // 标识节点当前在独占模式下\n    static final Node EXCLUSIVE = null;\n\n    // ======== 下面的几个int常量是给waitStatus用的 ===========\n    /** waitStatus value to indicate thread has cancelled */\n    // 代表此线程取消了争抢这个锁\n    static final int CANCELLED =  1;\n    /** waitStatus value to indicate successor's thread needs unparking */\n    // 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒\n    static final int SIGNAL    = -1;\n    /** waitStatus value to indicate thread is waiting on condition */\n    // 等待condition唤醒\n    static final int CONDITION = -2;\n    /**\n     * waitStatus value to indicate the next acquireShared should\n     * unconditionally propagate\n     */\n    // 共享模式同步状态获取讲会无条件的传播下去（共享模式下，该字段才会使用）\n    static final int PROPAGATE = -3;\n    // ===============-2和-3用的不多，暂时不分析======================================\n\n    // 取值为上面的1、-1、-2、-3，或者0(以后会讲到，waitStatus初始值为0)\n    // 这么理解，暂时只需要知道如果这个值 大于0 代表此线程取消了等待，\n    //    ps: 半天抢不到锁，不抢了，ReentrantLock是可以指定timeouot的\n    volatile int waitStatus;\n    // 前驱节点的引用\n    volatile Node prev;\n    // 后继节点的引用\n    volatile Node next;\n    // 这个就是线程本尊\n    volatile Thread thread;\n\n}\n```\n\n### AQS 队列基本结构\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/0efad5e335d52c8487af4e80680d251e.png)\n\n注意排队队列，不包括head（也就是后文要说的哨兵节点）。\n\n## AQS 整体工作流程\n\n本文将以 `ReentrantLock` 源码为例介绍AQS源码。\n\n`Lock`接口的实现类，基本都是通过**聚合**了一个**队列同步器**的子类完成线程访问控制的，即每个实现类内部都有一个AQS的子类 **Sync**：\n\n![image-20210926154035848](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926154035848.png)\n\n同时 **Sync** 类有两个子类：**FairSync**、**NonfairSync**。继承关系：\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/f991a259579532ca2528a66aa5c8ac60.png)\n\n**加锁阶段流程示意图：**\n\n![加锁阶段流程图](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/%E5%8A%A0%E9%94%81%E9%98%B6%E6%AE%B5%E6%B5%81%E7%A8%8B%E5%9B%BE.png)\n\n**解锁阶段流程示意图：**\n\n![解锁阶段流程图](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/%E8%A7%A3%E9%94%81%E9%98%B6%E6%AE%B5%E6%B5%81%E7%A8%8B%E5%9B%BE-1632731990653.png)\n\n## AQS 加锁过程源码分析\n\n### 1. 构造器中创建公平锁或非公平锁 sync\n\n`ReentrantLock` 的对象在实例化时将根据构造器中传入参数的不同创建公平锁或非公平锁对象`sync`：\n\n![image-20210926154334057](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926154334057.png)\n\n公平锁与非公平锁的区别在于：公平锁在获取同步状态时多了一个限制条件：`!hasQueuedPredecessors()`，其作用是**在加锁时判断等待队列中前面是否已经有正在排队的线程**。\n\n![image-20210926154908695](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926154908695.png)\n\n`hasQueuedPredecessors()`方法：\n\n![image-20210926155809751](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926155809751.png)\n\n> Predecessors：前辈\n\n`hasQueuedPredecessors()`中判断队列中是否前面还有正在排队的线程，导致公平锁和非公平锁的差异如下：\n\n- **公平锁**：公平锁讲究先来先到，线程在获取锁时，如果这个锁的等待队列中已经有线程在等待，那么当前线程就会进入等待队列中，不会直接去抢占;\n- **非公平锁**：不管等待队列中是否有其他线程正在等待，直接尝试占有锁。\n\n**非公平锁的非公平体现在**：其 `lock()` 方法一开始会先CAS尝试抢锁，若失败则进入队列中等待，这之后就和公平锁一样要按照顺序排队了。\n\n![image-20210927160002837](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927160002837.png)\n\n\n\n### 2. sync.lock()：外部程序尝试加锁\n\n![image-20210927101855258](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927101855258.png)\n\n在主程序调用 `ReentrantLock` 的 `lock()` 方法尝试加锁后，`ReentrantLock`对象将调用内聚的公平锁或非公平锁`sync`对象的`lock()`方法（公平锁和非公平锁的`lock()`方法有所区别，体现在非公平锁会先尝试抢占一次锁）：\n\n![image-20210927160006504](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927160006504.png)\n\n​\t此处以**非公平锁** `NonfairSync` 为例分析 `lock()` 方法的细节：\n\n首先，试图将状态量`state`设置为1，此时是使用的CAS机制，底层调用`Unsafe`类的 `native` 方法进行原子操作。\n\n- 若设置成功，说明没有线程占有锁，则将当前线程设置为占有锁的线程。\n- 若设置失败，说明已经有线程正在占有锁，则调用 `acquire(1)` 尝试再次抢占锁（因为可能有重入锁的情况发生，即当前线程再次重入该锁，自然是需要放行的），若还是抢占失败，则进入队列排队等待。\n\n![image-20210926163751633](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926163751633.png)\n\n其中，`compareAndSetState(0,1)` 方法底层调用`Unsafe`类的 `native` 方法进行原子操作：\n\n![image-20210926162216445](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926162216445.png)\n\n\n\n### 3. acquire() \n\n> 该方法为 AQS 父类中的方法，为公平锁和非公平锁公用\n\n若设置失败，说明已经有线程正在占有锁，则调用 `acquire(1)` 尝试再次抢占锁。`acquire()` 方法内：\n\n- 首先调用子类重写的`tryAcquire(arg)`方法尝试占有锁。若占有成功，则直接返回，无需执行后续操作\n- 若占有失败，则调用 `addWaiter()` 方法将当前线程封装成`Node`类型的节点，添加到等待队列（双向链表）的尾部\n- 调用 `acquireQueued()` 方法将当前节点的前一个节点的`waitStatus`设置为-1，并调用`LockSupport.park()` 方法阻塞当前线程\n\n![image-20210926202310361](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926202310361.png)\n\n下面逐一分析上述三个方法的细节。\n\n### 4. tryAcquire()：尝试占有锁\n\n首先以非公平锁为例，执行`tryAcquire(arg)`方法时将调用非公平锁重写的 `nonfairTryAcquire()` 方法：\n\n1. **再次CAS，试图抢占锁**。大多数情况还会抢占失败，但也可能在此时占有锁的线程恰好释放锁，那么当前线程就可以顺利抢占到锁，并将当前线程设置为占有锁的线程，并返回 true 代表尝试获取锁成功。这也是一种**双重检验**的思想（外面抢占一次失败，进来再抢占一次）。\n2. 如果当前是**重入锁**的情况（即当前线程和占有锁的线程是同一个线程，也代表了当前锁被同一个线程重入了），那么将状态量`state`大小增加，并返回 true 代表尝试获取锁成功。\n3. 若1、2两次判断都不成立，则返回 false 代表尝试获取锁失败。\n\n![image-20210926175021909](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926175021909.png)\n\n若返回false，代表抢占锁失败，则进行下一步：`addWaiter()` 加入到等待队列（双向链表）中。\n\n---\n\n公平锁与非公平锁在 `tryAcquire()` 方法中的区别在于：公平锁在获取同步状态时多了一个限制条件：`!hasQueuedPredecessors()`，其作用是**在加锁时判断等待队列中前面是否已经有正在排队的线程**。\n\n![image-20210926154908695](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926154908695.png)\n\n因此公平锁的线程在抢占锁前会判断当前队列中是否已经有正在排队的线程，如果有就不会尝试抢占锁，直接进入队列排队等待。\n\n---\n\n\n\n### 5.  addWaiter()：添加到等待队列中\n\n在`addWaiter()`方法中，将当前线程封装成一个`Node`节点，并添加到等待队列（双向链表）的队尾。将tail指向当前节点。\n\n![image-20210926212716145](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926212716145.png)\n\n- 橙黄色区域的代码在`tail != null`时才会触发，代表当前队列中已经有了尾结点，说明当前线程不是第一个来排队的线程，无需再创建哨兵节点（head指向的头节点）\n- 粉色区域的代码在`tail = null`时触发，代表当前队列中还没有尾结点，说明当前线程是第一个来排队的线程，需要创建哨兵节点（head指向的头节点）\n\n> 哨兵节点：又称为虚节点，傀儡节点。其内不存储任何信息，只是占位。真正有数据的节点是从第二个开始的。\n\n粉色区域的 `enq(node)` 方法只会执行一次，用于创建哨兵节点（head指向的头节点）：\n\n![image-20210926220033922](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210926220033922.png)\n\n其中，再次`if == null`判断的目的是**双重检验**，防止刚进来时尾结点就恰好被其他线程设置了。else内的代码是为了在这种情况下将当前节点作为那个恰好加塞的节点的后驱节点。**同时该过程采用CAS思想，一直自旋直到某一次成功将当前节点原子性地加入到队列中**。\n\n> `compareAndSetXxx()`：都是调用底层 Unsafe 类的 native 方法，保证修改的原子性。\n\n该过程示意图：\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/e1bf33ccbf81dacd7601677bda136f02.png)\n\n> 订正：队列中B的`waitStatus`应该等于-1，因为在线程C排队时会将其前一个节点B的 `waitStatus` 设置为 -1（`waitStatus`的值将在下一步 `acquireQueued()` 被设置）\n\n### 6. acquireQueued()：阻塞当前线程\n\n当执行完 `addWaiter()` 后，当前节点就被加入到了队列中排队等待。\n\n此时再调用 `acquireQueued()`方法阻塞当前线程：\n\n- 在 for 循环中每次都取出当前节点的前一个节点 `p`\n- 判断 `p` 是否是哨兵节点，如果是，说明当前节点排在队首，那么尝试抢占一次锁。若抢占成功，**取消当前的哨兵节点的引用**（未来将被GC），把当前节点设为新的哨兵节点，并开始占有锁。退出 for 循环\n- 若 `p` 不是哨兵节点或当前节点抢占失败，则调用 `shouldParkAfterFailedAcquire()` 方法将前一个节点的 `waitStatus` 设置为 -1，并在 `parkAndCheckInterrupt()` 方法中调用 `LockSupport.park(this)` **阻塞当前线程**，直到其前面的线程都出队并且自己被 `unpark()` 唤醒，才会取消阻塞再次进入 for 循环**自旋尝试获取锁**（因为可能其他非公平锁会在此时抢占锁，那么当前线程又要阻塞）。\n\n![image-20210927154405966](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927154405966.png)\n\n上述过程将一直在 for 循环中**自旋**，直到当前节点前面所有的节点都出队，并且锁被释放掉，`parkAndCheckInterrupt()` 方法才会从阻塞状态被唤醒，从而执行**橙黄色框**内的方法：取消当前的哨兵节点的引用（未来将被GC），把当前节点设为新的哨兵节点，并开始占有锁（该方法在后文解锁时才会执行，具体分析见下文）。\n\n---\n\n`shouldParkAfterFailedAcquire()` 方法：\n\n![image-20210927115459331](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927115459331.png)\n\n当经过 `shouldParkAfterFailedAcquire()` 方法将前一个节点的 `waitStatus` 设置为 `Node.SIGNAL=-1` （代表等待锁释放的状态）后，再执行 `parkAndCheckInterrupt()` 方法阻塞当前线程，本质是使用 `LockSupport.park()` 方法：\n\n![image-20210927101303519](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927101303519.png)\n\n调用该方法后，当前线程将阻塞在此，等待前面所有线程执行完毕后被 `LockSupport.unpark()` 方法唤醒。\n\n---\n\n==**经过上面的分析，每个后来的线程都会在队列中排队并阻塞等待锁的释放。下面开始介绍解锁时的流程：**==\n\n## AQS 解锁过程源码分析\n\n### 1. sync.release(1)：外部程序尝试解锁\n\n![image-20210927102025829](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927102025829.png)\n\n在主程序调用 `ReentrantLock` 的 `unlock()` 方法释放锁后，`ReentrantLock`对象将调用内聚的公平锁或非公平锁`sync`对象的`release()`方法，该方法在AQS父类中：\n\n> 该方法为 AQS 父类中的方法，为公平锁和非公平锁公用\n\n![image-20210927150103000](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927150103000.png)\n\n- 首先调用 `tryRelease()` 方法尝试释放锁，其先将AQS中的state减一（代表释放一个锁），再将AQS中的占有线程设置为 `null`\n- 接着获取哨兵节点，若其不为空且 `waitStatus != 0`，说明其后已经有了在排队的线程，该线程将`waitStatus`设置为-1，见上文 【[6. acquireQueued()：阻塞当前线程](#6-acquirequeued阻塞当前线程)】分析 \n- 满足 if 判断后调用 `unparkSuccessor(h)` 方法，该方法内将调用 `LockSupport.unpark(s.thread)` 方法将排在队首的线程唤醒。\n\n接下来将介绍这两个方法的内容：\n\n### 2. tryRelease()：尝试释放锁\n\n `tryRelease()` 方法内定义在AQS父类中，使用了**模板方法**的设计模式， `tryRelease()` 方法中只有 `throw new UnsupportedOperationException();`，说明如果子类不重写代码时被调用就会抛出异常：\n\n![image-20210927150608798](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927150608798.png)\n\n公平锁和非公平锁重写了该方法，并且内容一致（不同于`tryAcquire`方法子类重写的不同）：\n\n![image-20210927103216804](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927103216804.png)\n\n- 首先将AQS中的 `state` 值减一\n- 然后判断当前线程和**拥有锁的线程**是否是同一个线程，若不是，则抛出异常`IllegalMonitorStateException`\n- 若是同一个线程，则判断减一后的`state`是否为0，若是，则代表目前没有线程正占有着锁。则将**占有锁的线程**设置为 `null`\n\n该方法执行完毕后，状态量 `state` 减少了一，并且**占有锁的线程**被设置为了 `null`\n\n### 3. unparkSuccessor(h)：唤醒队首线程\n\n接着将哨兵节点 `h` 传入 `unparkSuccessor(h)` 方法：\n\n![image-20210927152330860](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927152330860.png)\n\n该方法将调用   `LockSupport.unpark(s.thread)` 方法将排在队首的线程唤醒，此时将分析上文中阻塞等待的方法【[6. acquireQueued()：阻塞当前线程](#6-acquirequeued阻塞当前线程)】：\n\n![image-20210927154354074](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927154354074.png)\n\n根据上文分析，此时队首的线程阻塞在绿色框内的 `shouldParkAfterFailedAcquire()` 方法：\n\n![image-20210927101303519](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210927101303519.png)\n\n那么在唤醒了该线程后，程序继续向下执行，程序没有被中断过，所以 `return Thread.interrupted()` 将返回 false。\n\n接着再次自旋后执行橙黄色框的 if 判断，此时 `p == head` 条件满足，则执行 `tryAcquire(arg)` 尝试抢占锁。因为此时的锁已经被解开了，当前队首线程就能够抢占成功，则进入橙黄色框内的代码：\n\n该代码块的作用是：取消当前的哨兵节点的引用，从队列中移除（未来将被GC），并把当前节点设为新的哨兵节点，并开始占有锁。\n\n该过程示意图：\n\n![img](/images/%E3%80%90JUC%E3%80%91AQS%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/aa60bf0eb603162facee9e8503f59c9a.png)\n\n\n\n\n\n\n\n","tags":["JUC","源码分析"],"categories":["JUC","源码分析"]},{"title":"【JUC】CAS 原理","url":"/2021/09/24/【JUC】CAS原理/","content":"\n## CAS\n\nCAS是指**Compare And Swap**，**比较并交换**，它是一条CPU**并发原语**，是一种很重要的同步思想。如果**主内存**的值跟期望值一样，那么就进行修改，否则一直重试，直到一致为止。\n\nCAS并发原语体现在JAVA语言中就是`sun.misc.Unsafe`类中的各个方法。调用`UnSafe`类中的CAS方法，JVM会帮我们实现出CAS汇编指令。这是一种完全依赖于硬件的功能，通过它实现了原子操作。再次强调，由于CAS是一种系统原语，原语属于操作系统用语范畴，是由若干条指令组成的，用于完成某个功能的一个过程，并且原语的执行必须是连续的，在执行过程中不允许被中断，也就是说CAS是一条CPU的原子指令，不会造成所谓的数据不一致问题。\n\nCAS的好处是其能在保证数据一致性的同时，也保证并发性。\n\nJava中CAS操作的执行依赖于`Unsafe`类的 `native `本地方法（其调用操作系统底层原语，能保证原子性）。\n\n<!-- More -->\n\n### AtomicInteger\n\n原子整型类`AtomicInteger`类的方法底层即使用了CAS思想：\n\n``` java\npublic class CASDemo {\n    public static void main(String[] args) {\n        AtomicInteger atomicInteger = new AtomicInteger(5);\n        System.out.println(atomicInteger.compareAndSet(5, 2019)+\"\\t current data : \"+ atomicInteger.get());\n        //修改失败\n        System.out.println(atomicInteger.compareAndSet(5, 1024)+\"\\t current data : \"+ atomicInteger.get());\n    }\n}\n```\n\n第一次修改，期望值为5，主内存也为5，修改成功，为2019。第二次修改，期望值为5，主内存为2019，修改失败。\n\n`AtomicInteger `类：\n\n``` java\npublic class AtomicInteger extends Number implements java.io.Serializable {\n    private static final long serialVersionUID = 6214790243416807050L;\n\n    // setup to use Unsafe.compareAndSwapInt for updates\n    private static final Unsafe unsafe = Unsafe.getUnsafe();\n    private static final long valueOffset;\n\n    static {\n        try {\n            valueOffset = unsafe.objectFieldOffset\n                (AtomicInteger.class.getDeclaredField(\"value\"));\n        } catch (Exception ex) { throw new Error(ex); }\n    }\n\n    private volatile int value;\n    \n    /**\n     * Creates a new AtomicInteger with the given initial value.\n     *\n     * @param initialValue the initial value\n     */\n    public AtomicInteger(int initialValue) {\n        value = initialValue;\n    }\n\n    /**\n     * Creates a new AtomicInteger with initial value {@code 0}.\n     */\n    public AtomicInteger() {\n    }\n    \n    ...\n            \n    /**\n     * Atomically increments by one the current value.\n     *\n     * @return the previous value\n     */\n    public final int getAndIncrement() {\n        return unsafe.getAndAddInt(this, valueOffset, 1);\n    }\n    \n    ...\n}\n```\n\n其内还有许多采用了CAS思想的方法，例如`AtomicInteger.getAndIncrement()`方法，发现其没有加`synchronized`**也实现了同步**。这是为什么？\n\n``` java\npublic final int getAndIncrement() {\n    return unsafe.getAndAddInt(this, valueOffset, 1);\n}\n```\n\n## CAS 底层原理\n\n`AtomicInteger`内部维护了三个比较重要的参数：\n\n``` java\nprivate static final Unsafe unsafe = Unsafe.getUnsafe();\nprivate static final long valueOffset;\nprivate volatile int value;\n\nstatic {\n    try {\n        valueOffset = unsafe.objectFieldOffset\n            (AtomicInteger.class.getDeclaredField(\"value\"));\n    } catch (Exception ex) { throw new Error(ex); }\n}\n```\n\n- `unsafe`：`AtomicInteger`类通过调用 `Unsafe `类的 `native ` 本地方法保证修改操作的**原子性**\n- `valueOffset`：表示该变量值在内存中的**偏移地址**，因为`Unsafe`就是根据内存偏移地址获取数据的\n- `value`：用`volatile`修饰，保证了多线程之间的**内存可见性**。\n\n### Unsafe 类\n\nJava中CAS操作的执行依赖于`Unsafe`类的 `native `本地方法。\n\n`Unsafe `是CAS的核心类，由于Java方法无法直接访问底层系统，需要通过本地（`native`）方法来访问，`Unsafe`相当于一个后门，基于该类可以直接操作特定内存的数据。`Unsafe`类存在于`sun.misc`包中，其内部方法操作可以像C的指针一样直接操作内存。\n\n**注意Unsafe类中的大多方法都是native修饰的，也就是说Unsafe类中的方法可以直接调用操作系统底层资源执行相应任务**。\n\n`AtomicInteger.getAndIncrement()`调用了`Unsafe.getAndAddInt()`方法：\n\n``` java\npublic final int getAndIncrement(){\n    return unsafe.getAndAddInt(this,valueOffset,1);\n}\n```\n\n`Unsafe`类的 `getAnddAddInt()` 方法：\n\n``` java\npublic final int getAnddAddInt(Object var1,long var2,int var4){\n    int var5;\n    do{\n        var5 = this.getIntVolatile(var1, var2);\n    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n    return var5;\n}\n\npublic native int getIntVolatile(Object var1, long var2);\npublic final native boolean compareAndSwapInt(Object var1, long var2, int var4, int var5);\n```\n\n其中，`getIntVolatile()` 方法和 `compareAndSwapInt()` 方法都是 `native` 本地方法，其由底层操作系统执行，**能保证操作的原子性**。\n\n`UnSafe.getAndAddInt()`源码解释：\n\n- `var1`：`AtomicInteger`对象本身。\n- `var2`：该对象值得引用地址。\n- `var4`：需要变动的数量。\n- `var5`：是用`var1`，`var2`找出的主内存中真实的值。\n- 用该对象当前的值与`var5`比较：\n  - 如果相同，更新`var5+var4`并且返回`true`,\n  - 如果不同，继续取值然后再比较，直到更新完成。\n\n这个方法的var1和var2，就是根据**对象**和**偏移量**得到在**主内存的快照值**var5。然后`compareAndSwapInt`方法通过var1和var2得到当前**主内存的实际值**。如果这个**实际值**跟**快照值**相等，那么就更新主内存的值为var5+var4。如果不等，那么就一直循环，一直获取快照，一直对比，直到实际值和快照值相等为止。\n\n比如有A、B两个线程，一开始都从主内存中拷贝了原值为3，A线程执行到`var5=this.getIntVolatile`，即var5=3。此时A线程挂起，B修改原值为4，B线程执行完毕，由于加了volatile，所以这个修改是立即可见的。A线程被唤醒，执行`this.compareAndSwapInt()`方法，发现这个时候主内存的值不等于快照值3，所以继续循环，**重新**从主内存获取。\n\n### 底层汇编\n\n`Unsafe`类中的`compareAndSwapInt()`是一个本地方法，该方法的实现位于`unsafe.cpp`中：\n\n``` cpp\nUNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)\nUnsafeWrapper(\"Unsafe_CompareAndSwaplnt\");\noop p = JNlHandles::resolve(obj);\njint* addr = (jint *)index_oop_from_field_offset_long(p, offset);\nreturn (jint)(Atomic::cmpxchg(x, addr, e))== e;\nUNSAFE_END\n//先想办法拿到变量value在内存中的地址。\n//通过Atomic::cmpxchg实现比较替换，其中参数x是即将更新的值，参数e是原内存的值。\n```\n\n## CAS 缺点\n\nCAS实际上是一种**自旋锁**，其缺点是\n\n1. 一直循环，开销比较大。\n2. 只能保证一个变量的原子操作，多个变量依然要加锁。\n3. 引出了**ABA问题**。\n\n## ABA 问题\n\n所谓ABA问题，就是比较并交换的循环，存在一个**时间差**，而这个时间差可能带来意想不到的问题。比如线程T1将值从A改为B，然后又从B改为A。线程T2看到的就是A，但是**却不知道这个A发生了更改**。尽管线程T2 CAS操作成功，但不代表就没有问题。\n\n有的需求，比如CAS，**只注重头和尾**，只要首尾一致就接受。但是有的需求，还看重过程，中间不能发生任何修改，这就引出了`AtomicReference`原子引用。\n\n## AtomicReference\n\n`AtomicInteger`对整数进行原子操作，如果是一个POJO呢？可以用`AtomicReference`来包装这个POJO，使其操作原子化。\n\n``` java\nclass User {\n    String name;\n    int age;\n    User(String name, int age) {\n        this.name = name;\n        this.age = age;\n    }\n}\n\npublic class AtomReferenceDemo {\n    public static void main(String[] args) {\n        User user1 = new User(\"Jack\", 25);\n        User user2 = new User(\"Lucy\", 21);\n        AtomicReference<User> atomicReference = new AtomicReference<>();\n        atomicReference.set(user1);\n        System.out.println(atomicReference.compareAndSet(user1, user2)); // true\n        // 此时atomicReference变为user2，不再是user1，故原值不匹配，return false\n        System.out.println(atomicReference.compareAndSet(user1, user2)); // false\n    }\n}\n```\n\n## ABA 问题的解决\n\n使用`AtomicStampedReference`类可以解决ABA问题。这个类维护了一个“**版本号**”Stamp，在进行CAS操作的时候，不仅要比较当前值，还要比较**版本号**。只有两者都相等，才执行更新操作。即乐观锁思想。\n\n``` java\npublic class ABAProblem {\n    static AtomicReference<Integer> atomicReference = new AtomicReference<>(100);\n    static AtomicStampedReference<Integer> atomicStampedReference = new AtomicStampedReference<>(100, 1);\n\n    public static void main(String[] args) {\n        System.out.println(\"======ABA问题的产生======\");\n\n        new Thread(() -> {\n            atomicReference.compareAndSet(100, 101);\n            atomicReference.compareAndSet(101, 100);\n        }, \"t1\").start();\n\n        new Thread(() -> {\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n\n            }\n            System.out.println(atomicReference.compareAndSet(100, 2019) + \"\\t\" + atomicReference.get().toString());\n        }, \"t2\").start();\n\n        try {\n            TimeUnit.SECONDS.sleep(2);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        System.out.println(\"======ABA问题的解决======\");\n        new Thread(() -> {\n            int stamp = atomicStampedReference.getStamp();\n            System.out.println(Thread.currentThread().getName() + \"\\t第一次版本号： \" + stamp);\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            atomicStampedReference.compareAndSet(100, 101, atomicStampedReference.getStamp(),\n                                                 atomicStampedReference.getStamp() + 1);\n            System.out.println(Thread.currentThread().getName() + \"\\t第二次版本号： \" + atomicStampedReference.getStamp());\n            atomicStampedReference.compareAndSet(101, 100, atomicStampedReference.getStamp(),\n                                                 atomicStampedReference.getStamp() + 1);\n            System.out.println(Thread.currentThread().getName() + \"\\t第三次版本号： \" + atomicStampedReference.getStamp());\n        }, \"t3\").start();\n\n        new Thread(() -> {\n            int stamp = atomicStampedReference.getStamp();\n            System.out.println(Thread.currentThread().getName() + \"\\t第一次版本号： \" + stamp);\n            try {\n                TimeUnit.SECONDS.sleep(3);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            boolean result = atomicStampedReference.compareAndSet(100, 2019, stamp, stamp + 1);\n            System.out.println(Thread.currentThread().getName() + \"\\t修改成功与否：\" + result + \"  当前最新版本号\"\n                               + atomicStampedReference.getStamp());\n            System.out.println(Thread.currentThread().getName() + \"\\t当前实际值：\" + atomicStampedReference.getReference());\n        }, \"t4\").start();\n    }\n}\n```\n\n输出结果：\n\n``` \n============以下是ABA问题的产生==========\ntrue\t2019\n============以下是ABA问题的解决==========\nt3\t 第一次版本号1\nt4\t 第一次版本号1\nt3\t 第二次版本号2\nt3\t 第三次版本号3\nt4\t 修改成功否：false\t 当前最新实际版本号：3\nt4\t 当前实际最新值100\n```\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["JUC"],"categories":["JUC"]},{"title":"【JVM】JVM 虚拟机栈","url":"/2021/09/23/【JVM】JVM虚拟机栈/","content":"\n## 虚拟机栈概述\n\n由于跨平台性的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。\n\n基于栈的架构优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令。\n\n### 内存中的栈与堆\n\n栈是**运行时**的单位，而堆是**存储**的单位\n\n- 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。\n- 堆解决的是数据存储的问题，即数据怎么放，放哪里\n\n![image-20200705163928652](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705163928652.png)\n\n<!-- More -->\n\n### Java 虚拟机栈是什么\n\nJava虚拟机栈（Java Virtual Machine Stack），早期也叫Java栈。每个线程在创建时都会创建一个虚拟机栈，其内部保存一个个的栈帧（Stack Frame），对应着一次次的Java方法调用。\n\n>虚拟机栈是线程私有的\n\n![image-20200705164722033](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705164722033.png)\n\n虚拟机栈生命周期和线程一致，也就是线程结束了，该虚拟机栈也销毁了\n\n### 虚拟机栈的作用\n\n主管Java程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。\n\n- 局部变量，它是相比于成员变量来说的（或属性）\n- 基本数据类型变量 VS  引用类型变量（类、数组、接口）\n\n### 栈的特点\n\n栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器。JVM直接对Java虚拟机栈的操作只有两个：\n\n- 每个方法执行，伴随着进栈（入栈、压栈）\n- 执行结束后的出栈工作\n\n对于栈来说不存在垃圾回收问题（但是栈存在溢出的情况）\n\n![image-20200705165025382](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705165025382.png)\n\n### 栈中可能出现的异常\n\nJava 虚拟机规范允许Java栈的大小是动态的或者是固定不变的。\n\n- 如果采用固定大小的Java虚拟机栈，那每一个线程的Java虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过Java虚拟机栈允许的最大容量，Java虚拟机将会抛出一个`StackOverflowError `异常。\n- 如果Java虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那Java虚拟机将会抛出一个 `OutOfMemoryError `异常。\n\n```java\npublic class StackErrorTest {\n    private static int count = 1;\n    public static void main(String[] args) {\n        System.out.println(count++);\n        main(args);\n    }\n}\n```\n\n当栈深度达到9803的时候，就出现栈内存空间不足\n\n### 设置栈内存大小\n\n\n> Sets the thread stack size (in bytes). Append the letter `k` or `K` to indicate KB, `m` or `M` to indicate MB, and `g` or `G` to indicate GB. The default value depends on the platform:\n>\n> - Linux/x64 (64-bit): 1024 KB\n> - macOS (64-bit): 1024 KB\n> - Oracle Solaris/x64 (64-bit): 1024 KB\n> - Windows: The default value depends on virtual memory\n\n我们可以使用参数 -Xss选项来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度：\n\n\n```java\n-Xss1m\n-Xss1k\n```\n\n## 栈的存储单位\n\n每个线程都有自己的栈，栈中的数据都是以**栈帧**（Stack Frame）的格式存在。在这个线程上正在执行的每个方法都**各自对应一个栈帧**（Stack Frame）。\n\n栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息。\n\n### 栈中存储什么？\n\nJVM直接对Java栈的操作只有两个，就是对栈帧的**压栈**和**出栈**，遵循“先进后出”/“后进先出”原则。\n\n在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为**当前栈帧**（Current Frame），与当前栈帧相对应的方法就是**当前方法**（Current Method），定义这个方法的类就是**当前类**（Current Class）。\n\n执行引擎运行的所有字节码指令**只针对当前栈帧**进行操作。如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，成为新的当前帧。\n\n![image-20200705203142545](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705203142545.png)\n\n下面写一个简单的代码\n\n```java\npublic class StackFrameTest {\n    public static void main(String[] args) {\n        method01();\n    }\n\n    private static int method01() {\n        System.out.println(\"方法1的开始\");\n        int i = method02();\n        System.out.println(\"方法1的结束\");\n        return i;\n    }\n\n    private static int method02() {\n        System.out.println(\"方法2的开始\");\n        int i = method03();;\n        System.out.println(\"方法2的结束\");\n        return i;\n    }\n    private static int method03() {\n        System.out.println(\"方法3的开始\");\n        int i = 30;\n        System.out.println(\"方法3的结束\");\n        return i;\n    }\n}\n```\n\n输出结果为\n\n```bash\n方法1的开始\n方法2的开始\n方法3的开始\n方法3的结束\n方法2的结束\n方法1的结束\n```\n\n满足栈先进后出的概念，通过Idea的 DEBUG，能够看到栈信息\n\n![image-20200705203916023](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705203916023.png)\n\n### 栈运行原理\n\n不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧之中引用另外一个线程的栈帧。\n\n如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧。\n\nJava方法有两种返回函数的方式，一种是正常的函数返回，使用`return`指令；另外一种是抛出异常。不管使用哪种方式，都会导致栈帧被弹出。\n\n### 栈帧的内部结构\n\n每个栈帧中存储着：\n\n- **局部变量表**（Local Variables）\n- **操作数栈**（operand Stack）（或表达式栈）\n- **动态链接**（DynamicLinking）（或指向运行时常量池的方法引用）\n- **方法返回地址**（Return Address）（或方法正常退出或者异常退出的定义）\n- 一些附加信息\n\n![image-20200705204836977](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705204836977.png)\n\n每个线程下的栈都是私有的，因此每个线程都有自己各自的栈，并且每个栈里面都有很多栈帧，栈帧的大小主要由**局部变量表**和**操作数栈**决定的。\n\n![image-20200705205443993](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705205443993.png)\n\n## 局部变量表\n\n**局部变量表**：Local Variables，被称之为**局部变量数组**或**本地变量表**。由于局部变量表是建立在线程的栈上，是线程的私有数据，因此**不存在数据安全问题**。\n\n局部变量表定义为一个**数字数组**，主要用于存储**方法参数**和定义在方法体内的**局部变量**，这些数据类型包括`this`对象、各类基本数据类型、对象引用（reference），以及`returnAddress`类型。\n\n> 在方法内的基本数据类型的局部变量，其值直接保存在局部变量表里（例如 int a = 1，1这个值直接保存在局部变量表里）。而类对象内的基本数据类型成员变量的值是保存在堆中该对象所在的内存区域内。\n\n局部变量表所需的容量大小是**在编译期确定下来**的，并保存在方法的`Code`属性的`maximum local variables`数据项中。在方法运行期间是不会改变局部变量表的大小的。\n\n方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。\n\n局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。\n\n### 局部变量表分析示例\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0008.png)\n\n看完字节码后，可得结论：**局部变量表所需的容量大小是在编译期确定下来的。**\n\n下面详细里面的细节：\n\n1. Misc（杂项）\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0011.png)\n\n2. 行号表：Java代码的行号和字节码指令行号的对应关系\n\n> 注意：生效行数和剩余有效行数都是针对于字节码文件的行数\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0012.png)\n\n3. 局部变量表\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0013.png)\n\n图中圈的东西表示该局部变量的作用域\n\n- `Start PC = 11` 表示在字节码的11行开始生效，也就是Java代码对应的第15行。而声明`int num`在java代码的是第14行，说明是从声明的下一行开始生效\n- `Length = 5` 表示局部变量剩余有效行数，main方法字节码指令总共有16行，从11行开始生效，那么剩下就是`16-11 = 5`\n\n`Ljava/lang/String` 前面的L表示引用类型\n\n### 关于 Slot 的理解\n\n参数值的存放总是在局部变量数组的 `index 0` 开始，到 `数组长度-1` 的索引结束。\n\n局部变量表，**最基本的存储单元是Slot**（变量槽）。局部变量表中存放编译期可知的各种基本数据类型（8种），引用类型（reference），`returnAddress`类型的变量。\n\n在局部变量表里，32位以内的类型只占用一个Slot（包括`returnAddress`类型），64位的类型（long和double）占用两个slot。\n\n>byte、short、char 在存储前被转换为int，boolean也被转换为int，0表示false，非0表示true。\n>long和double则占据两个slot。\n\nJVM会为局部变量表中的每一个Slot都分配一个**访问索引**，通过这个索引即可成功访问到局部变量表中指定的局部变量值。当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个slot上\n\n如果需要访问局部变量表中一个64bit的局部变量值时，只需要使用前一个索引即可。（比如：访问long或double类型变量）\n\n如果当前帧是由构造方法或者实例方法创建的，那么该对象引用`this`将会存放在index为0的slot处，其余的参数按照参数表顺序继续排列。\n\n![image-20200705212454445](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705212454445.png)\n\n### Slot 代码示例\n\n**this 存放在 index = 0 的位置：**\n\n``` java\npublic void test3() {\n    this.count++;\n}\n```\n\n局部变量表：this 存放在 index = 0 的位置\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0015.png)\n\n**64位的类型（long和double）占用两个slot：**\n\n``` java\npublic String test2(Date dateP, String name2) {\n    dateP = null;\n    name2 = \"songhongkang\";\n    double weight = 130.5;//占据两个slot\n    char gender = '男';\n    return dateP + name2;\n}\n```\n\nweight 为 double 类型，index 直接从 3 蹦到了 5\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0016.png)\n\n**static 无法调用 this**\n\nthis 不存在与 static 方法的局部变量表中，所以无法调用\n\n```java\npublic static void testStatic(){\n    LocalVariablesTest test = new LocalVariablesTest();\n    Date date = new Date();\n    int count = 10;\n    System.out.println(count);\n    // 因为this变量不存在于当前方法的局部变量表中！！\n    // System.out.println(this.count);\n}\n```\n\n### Slot 的重复利用\n\n栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。\n\n![image-20200705213106749](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200705213106749.png)\n\n### 静态变量与局部变量的对比\n\n变量的分类：\n\n- 按数据类型分：基本数据类型、引用数据类型\n- 按类中声明的位置分：成员变量（类变量，实例变量）、局部变量\n  - 类变量：linking的prepare阶段，给类变量默认赋值，init阶段给类变量显示赋值即静态代码块\n  - 实例变量：随着对象创建，会在堆空间中分配实例变量空间，并进行默认赋值\n  - 局部变量：在使用前必须进行显式赋值，不然编译不通过。\n\n参数表分配完毕之后，再根据方法体内定义的变量的顺序和作用域分配。\n\n我们知道类变量表有两次初始化的机会，第一次是在“准备阶段”，执行系统初始化，对类变量设置零值，另一次则是在“初始化”阶段，赋予程序员在代码中定义的初始值。和类变量初始化不同的是，局部变量表不存在系统初始化的过程，这意味着一旦定义了局部变量则必须人为的初始化，否则无法使用。\n\n在栈帧中，**与性能调优关系最为密切的部分就是局部变量表**。在方法执行时，虚拟机使用局部变量表完成方法的传递。局部变量表中的变量也是重要的**垃圾回收根节点**，只要被局部变量表中直接或间接引用的对象都不会被回收。\n\n## 操作数栈\n\n### 概念\n\n每一个独立的栈帧除了包含局部变量表以外，还包含一个后进先出（Last - In - First -Out）的 **操作数栈**，也可以称之为 **表达式栈**（Expression Stack）\n\n> 操作数栈是一个长度固定的数组，其在编译阶段就确定了长度（同局部变量表一样）\n\n操作数栈，在方法执行过程中，根据字节码指令，往栈中写入数据或提取数据，即入栈（push）和 出栈（pop）\n\n- 某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈\n- 比如：执行复制、交换、求和等操作\n\n![image-20200706090618332](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706090618332.png)\n\n代码举例\n\n![image-20200706090833697](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706090833697.png)\n\n### 操作数栈的作用\n\n操作数栈，主要用于**保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间**。\n\n操作数栈就是JVM执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，这个方法的操作数栈是空的。\n\n> 这个时候数组是有长度的，因为数组一旦创建，那么就是不可变的\n\n每一个操作数栈都会拥有一个**明确的栈深度**用于存储数值，其所需的最大深度在**编译期就定义好了**，保存在方法的`Code`属性中，为`maxstack`的值。\n\n栈中的任何一个元素都是可以任意的Java数据类型\n\n- 32bit的类型占用一个栈单位深度\n- 64bit的类型占用两个栈单位深度\n\n操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问\n\n如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新PC寄存器中下一条需要执行的字节码指令。\n\n操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译器期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证。|\n\n另外，我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈。\n\n### 代码追踪\n\n我们给定代码\n\n```java\npublic void testAddOperation() {\n    byte i = 15;\n    int j = 8;\n    int k = i + j;\n}\n```\n\n使用 `javap` 命令反编译 `.class` 文件： `javap -v 类名.class`\n\n``` \n0 bipush 15\n2 istore_1\n3 bipush 8\n5 istore_2\n6 iload_1\n7 iload_2\n8 iadd\n9 istore_3\n10 return\n```\n\n> byte、short、char、boolean 内部都是使用int型来进行保存的\n>\n> 从上面的代码我们可以知道，我们都是通过bipush对操作数 15 和  8进行入栈操作。同时使用的是 iadd方法进行相加操作，i -> 代表的就是 int，也就是int类型的加法操作\n>\n\n执行流程如下所示：\n\n首先执行第一条语句，PC寄存器指向的是0，也就是指令地址为0，然后使用bipush让操作数15入栈。\n\n![image-20200706093131621](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706093131621.png)\n\n执行完后，让 PC + 1，指向下一行代码，下一行代码就是将操作数栈的元素存储到局部变量表1的位置，我们可以看到局部变量表的已经增加了一个元素\n\n![image-20200706093251302](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706093251302.png)\n\n> 为什么局部变量表不是从0开始的呢？\n>\n> 其实局部变量表也是从0开始的，但是因为0号位置存储的是this指针，所以就直接省略了\n\n然后 PC+1，指向的是下一行。让操作数8也入栈，同时执行store操作，存入局部变量表中\n\n![image-20200706093646406](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706093646406.png)\n\n![image-20200706093751711](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706093751711.png)\n\n然后从局部变量表中，依次将数据放在操作数栈中\n\n![image-20200706093859191](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706093859191.png)\n\n![image-20200706093921573](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706093921573.png)\n\n然后将操作数栈中的两个元素执行相加操作，并存储在局部变量表3的位置\n\n![image-20200706094046782](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706094046782.png)\n\n![image-20200706094109629](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706094109629.png)\n\n最后PC寄存器的位置指向10，也就是return方法，则直接退出方法\n\n**如果被调用的方法带有返回值，返回值入操作数栈**\n\n``` java\npublic int getSum(){\n    int m = 10;\n    int n = 20;\n    int k = m + n;\n    return k;\n}\n\npublic void testGetSum(){\n    // 获取上一个栈桢返回的结果，并保存在操作数栈中\n    int i = getSum();\n    int j = 10;\n}\n```\n\n`getSum()` 方法字节码指令：最后带着个 `ireturn`\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0029.png)\n\n`testGetSum()` 方法字节码指令：一上来就加载 `getSum()` 方法的返回值\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0030.png)\n\n## 栈顶缓存技术\n\n**栈顶缓存技术：Top Of Stack Cashing**\n\n前面提过，基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读/写次数。\n\n由于操作数是存储在内存中的，因此频繁地执行内存读/写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM的设计者们提出了栈顶缓存（Tos，Top-of-Stack Cashing）技术，将栈顶元素全部**缓存在物理CPU的寄存器**中，以此**降低对内存的读/写次数，提升执行引擎的执行效率**。\n\n> 寄存器：指令更少，执行速度快\n\n## 动态链接\n\n**动态链接（或指向运行时常量池的方法引用）**：Dynamic Linking\n\n![image-20200706100311886](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706100311886.png)\n\n> 动态链接、方法返回地址、附加信息 ： 有些地方被统称为帧数据区\n\n每一个栈帧内部都包含一个**指向运行时常量池中该栈帧所属方法的引用**。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接（Dynamic Linking）。比如：invokedynamic指令\n\n在Java源文件被编译到字节码文件中时，所有的变量和方法引用都作为**符号引用**（symbolic Reference）保存在class文件的**常量池**里。\n\n比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用。\n\n![image-20200706101251847](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706101251847.png)\n\n> 为什么需要运行时常量池？\n>\n> 因为在不同的方法，都可能调用常量或者方法，所以只需要存储一份即可，节省了空间。常量池的作用：就是为了提供一些符号和常量，便于指令的识别\n>\n\n### 示例\n\n``` java\npublic class DynamicLinkingTest {\n    int num = 10;\n\n    public void methodA(){\n        System.out.println(\"methodA()....\");\n    }\n\n    public void methodB(){\n        System.out.println(\"methodB()....\");\n        methodA();\n        num++;\n    }\n}\n```\n\n对应字节码：\n\n``` \nClassfile /F:/IDEAWorkSpaceSourceCode/JVMDemo/out/production/chapter05/com/atguigu/java1/DynamicLinkingTest.class\n  Last modified 2020-11-10; size 712 bytes\n  MD5 checksum e56913c945f897c7ee6c0a608629bca8\n  Compiled from \"DynamicLinkingTest.java\"\npublic class com.atguigu.java1.DynamicLinkingTest\n  minor version: 0\n  major version: 52\n  flags: ACC_PUBLIC, ACC_SUPER\nConstant pool:\n   #1 = Methodref          #9.#23         // java/lang/Object.\"<init>\":()V\n   #2 = Fieldref           #8.#24         // com/atguigu/java1/DynamicLinkingTest.num:I\n   #3 = Fieldref           #25.#26        // java/lang/System.out:Ljava/io/PrintStream;\n   #4 = String             #27            // methodA()....\n   #5 = Methodref          #28.#29        // java/io/PrintStream.println:(Ljava/lang/String;)V\n   #6 = String             #30            // methodB()....\n   #7 = Methodref          #8.#31         // com/atguigu/java1/DynamicLinkingTest.methodA:()V\n   #8 = Class              #32            // com/atguigu/java1/DynamicLinkingTest\n   #9 = Class              #33            // java/lang/Object\n  #10 = Utf8               num\n  #11 = Utf8               I\n  #12 = Utf8               <init>\n  #13 = Utf8               ()V\n  #14 = Utf8               Code\n  #15 = Utf8               LineNumberTable\n  #16 = Utf8               LocalVariableTable\n  #17 = Utf8               this\n  #18 = Utf8               Lcom/atguigu/java1/DynamicLinkingTest;\n  #19 = Utf8               methodA\n  #20 = Utf8               methodB\n  #21 = Utf8               SourceFile\n  #22 = Utf8               DynamicLinkingTest.java\n  #23 = NameAndType        #12:#13        // \"<init>\":()V\n  #24 = NameAndType        #10:#11        // num:I\n  #25 = Class              #34            // java/lang/System\n  #26 = NameAndType        #35:#36        // out:Ljava/io/PrintStream;\n  #27 = Utf8               methodA()....\n  #28 = Class              #37            // java/io/PrintStream\n  #29 = NameAndType        #38:#39        // println:(Ljava/lang/String;)V\n  #30 = Utf8               methodB()....\n  #31 = NameAndType        #19:#13        // methodA:()V\n  #32 = Utf8               com/atguigu/java1/DynamicLinkingTest\n  #33 = Utf8               java/lang/Object\n  #34 = Utf8               java/lang/System\n  #35 = Utf8               out\n  #36 = Utf8               Ljava/io/PrintStream;\n  #37 = Utf8               java/io/PrintStream\n  #38 = Utf8               println\n  #39 = Utf8               (Ljava/lang/String;)V\n{\n  int num;\n    descriptor: I\n    flags:\n\n  public com.atguigu.java1.DynamicLinkingTest();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n         4: aload_0\n         5: bipush        10\n         7: putfield      #2                  // Field num:I\n        10: return\n      LineNumberTable:\n        line 7: 0\n        line 9: 4\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      11     0  this   Lcom/atguigu/java1/DynamicLinkingTest;\n\n  public void methodA();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=2, locals=1, args_size=1\n         0: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #4                  // String methodA()....\n         5: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: return\n      LineNumberTable:\n        line 12: 0\n        line 13: 8\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  this   Lcom/atguigu/java1/DynamicLinkingTest;\n\n  public void methodB();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=3, locals=1, args_size=1\n         0: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n         3: ldc           #6                  // String methodB()....\n         5: invokevirtual #5                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V\n         8: aload_0\n         9: invokevirtual #7                  // Method methodA:()V\n        12: aload_0\n        13: dup\n        14: getfield      #2                  // Field num:I\n        17: iconst_1\n        18: iadd\n        19: putfield      #2                  // Field num:I\n        22: return\n      LineNumberTable:\n        line 16: 0\n        line 18: 8\n        line 20: 12\n        line 21: 22\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      23     0  this   Lcom/atguigu/java1/DynamicLinkingTest;\n}\nSourceFile: \"DynamicLinkingTest.java\"\n```\n\n在字节码指令中，`methodB()` 方法中通过 `invokevirtual #7` 指令调用了方法 A ，那么 #7 是个啥呢？\n\n往上面翻，找到常量池的定义：`#7 = Methodref #8.#31`\n\n- 先找 `#8` ：\n  - `#8 = Class #32` ：去找 `#32`\n  - `#32 = Utf8 com/atguigu/java1/DynamicLinkingTest`\n  - 结论：通过 `#8` 我们找到了 `DynamicLinkingTest` 这个类\n- 再来找 `#31`：\n  - `#31 = NameAndType #19:#13` ：去找 `#19` 和 `#13`\n  - `#19 = Utf8 methodA` ：方法名为 `methodA`\n  - `#13 = Utf8 ()V` ：方法没有形参，返回值为 `void`\n\n结论：通过 `#7` 我们就能找到需要调用的 `methodA()` 方法，并进行调用。在上面，其实还有很多符号引用，比如 `Object`、`System`、`PrintStream `等等\n\n\n\n## 方法调用\n\n在JVM中，将符号引用转换为调用方法的直接引用与方法的绑定机制相关\n\n### 链接\n\n#### 静态链接\n\n当一个字节码文件被装载进JVM内部时，如果被调用的目标方法在**编译期**确定，且运行期保持不变时，这种情况下将调用**方法**的符号引用转换为直接引用的过程称之为静态链接\n\n#### 动态链接\n\n如果被调用的方法在编译期无法被确定下来，也就是说，**只能够在程序运行期**将调用的方法的符号转换为直接引用，由于这种引用转换过程具备动态性，因此也被称之为动态链接。\n\n### 早晚期绑定的发展历史\n\n随着高级语言的横空出世，类似于Java一样的基于面向对象的编程语言如今越来越多，尽管这类编程语言在语法风格上存在一定的差别，但是它们彼此之间始终保持着一个共性，那就是都支持封装、继承和多态等面向对象特性，既然这一类的编程语言具备多态特性，那么自然也就具备早期绑定和晚期绑定两种绑定方式。\n\nJava中任何一个普通的方法其实都具备虚函数的特征，它们相当于C\\+\\+语言中的虚函数（C\\+\\+中则需要使用关键字`virtual`来显式定义）。如果在Java程序中不希望某个方法拥有虚函数的特征时，则可以使用关键字`final`来标记这个方法。\n\n### 绑定机制\n\n>  静态链接与动态链接针对的是**方法**。早期绑定和晚期绑定范围更广。早期绑定涵盖了静态链接，晚期绑定涵盖了动态链接。\n\n对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。**绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程**，这仅仅发生一次。\n\n#### 早期绑定\n\n早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就**可以使用静态链接的方式将符号引用转换为直接引用**。\n\n#### 晚期绑定\n\n如果被调用的方法在编译期无法被确定下来，**只能够在程序运行期根据实际的类型绑定相关的方法**，这种绑定方式也就被称之为晚期绑定。\n\n示例代码：\n\n``` java\nclass Animal {\n\n    public void eat() {\n        System.out.println(\"动物进食\");\n    }\n}\n\ninterface Huntable {\n    void hunt();\n}\n\nclass Dog extends Animal implements Huntable {\n    @Override\n    public void eat() {\n        System.out.println(\"狗吃骨头\");\n    }\n\n    @Override\n    public void hunt() {\n        System.out.println(\"捕食耗子，多管闲事\");\n    }\n}\n\nclass Cat extends Animal implements Huntable {\n\n    public Cat() {\n        super();//表现为：早期绑定\n    }\n\n    public Cat(String name) {\n        this();//表现为：早期绑定\n    }\n\n    @Override\n    public void eat() {\n        super.eat();//表现为：早期绑定\n        System.out.println(\"猫吃鱼\");\n    }\n\n    @Override\n    public void hunt() {\n        System.out.println(\"捕食耗子，天经地义\");\n    }\n}\n\npublic class AnimalTest {\n    public void showAnimal(Animal animal) {\n        animal.eat();//表现为：晚期绑定\n    }\n\n    public void showHunt(Huntable h) {\n        h.hunt();//表现为：晚期绑定\n    }\n}\n```\n\n部分字节码：\n\n``` \n{\n  public com.atguigu.java2.AnimalTest();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=1, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n         4: return\n      LineNumberTable:\n        line 54: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       5     0  this   Lcom/atguigu/java2/AnimalTest;\n\n  public void showAnimal(com.atguigu.java2.Animal);\n    descriptor: (Lcom/atguigu/java2/Animal;)V\n    flags: ACC_PUBLIC\n    Code:\n      stack=1, locals=2, args_size=2\n         0: aload_1\n         1: invokevirtual #2                  // Method com/atguigu/java2/Animal.eat:()V\n         4: return\n      LineNumberTable:\n        line 56: 0\n        line 57: 4\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       5     0  this   Lcom/atguigu/java2/AnimalTest;\n            0       5     1 animal   Lcom/atguigu/java2/Animal;\n\n  public void showHunt(com.atguigu.java2.Huntable);\n    descriptor: (Lcom/atguigu/java2/Huntable;)V\n    flags: ACC_PUBLIC\n    Code:\n      stack=1, locals=2, args_size=2\n         0: aload_1\n         1: invokeinterface #3,  1            // InterfaceMethod com/atguigu/java2/Huntable.hunt:()V\n         6: return\n      LineNumberTable:\n        line 60: 0\n        line 61: 6\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       7     0  this   Lcom/atguigu/java2/AnimalTest;\n            0       7     1     h   Lcom/atguigu/java2/Huntable;\n}\nSourceFile: \"AnimalTest.java\"\n```\n\n- `invokevirtual `体现为晚期绑定\n- `invokeinterface `也体现为晚期绑定\n- `invokespecial `体现为早期绑定\n- `invokestatic `也体现为早期绑定\n\n一些可以明确知道是非虚方法（例如static方法，private方法等）会以`invokestatic `/`invokespecial `的方式引用。其他不能确定的虚方法（因为没写`@Override`，所以编译阶段编译器也不知道这个方法是不是重写或实现的方法）就会以`invokevirtual `方式引用。\n\n### 虚方法和非虚方法\n\n- 如果方法在编译期就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法。\n- 静态方法、私有方法、final方法、实例构造器、父类方法都是非虚方法。\n- 其他方法称为虚方法。\n\n虚拟机中提供了以下几条方法调用指令：\n\n#### 普通调用指令\n\n- `invokestatic`：调用静态方法，解析阶段确定唯一方法版本，早期绑定\n- `invokespecial`：调用`<init>`方法、私有及父类方法，解析阶段确定唯一方法版本，早期绑定\n- `invokevirtual`：调用所有虚方法，晚期绑定\n- `invokeinterface`：调用接口方法，晚期绑定\n\n#### 动态调用指令\n\n- `invokedynamic`：动态解析出需要调用的方法，然后执行\n\n前四条指令固化在虚拟机内部，方法的调用执行不可人为干预，而`invokedynamic`指令则支持由用户确定方法版本。其中`invokestatic`指令和`invokespecial`指令调用的方法称为非虚方法，其余的（final修饰的除外）称为虚方法。\n\n#### 区别\n\n一些可以明确知道的非虚方法（例如`static`方法，`private`方法等）会以`invokestatic `/`invokespecial `的方式引用。\n\n其他不能确定的虚方法（因为没写`@Override`，所以编译阶段编译器也不知道这个方法是不是重写或实现的方法）就会以`invokevirtual `方式引用。这些虚方法在运行阶段被第一次调用时会向上找当前方法引用是属于哪个类的，然后将其添加到虚函数表中。后续再调用直接去虚函数表中查找即可。\n\n示例\n\n``` java\nclass Father {\n    public Father() {\n        System.out.println(\"father的构造器\");\n    }\n\n    public static void showStatic(String str) {\n        System.out.println(\"father \" + str);\n    }\n\n    public final void showFinal() {\n        System.out.println(\"father show final\");\n    }\n\n    public void showCommon() {\n        System.out.println(\"father 普通方法\");\n    }\n}\n\npublic class Son extends Father {\n    public Son() {\n        //invokespecial\n        super();\n    }\n\n    public Son(int age) {\n        //invokespecial\n        this();\n    }\n\n    //不是重写的父类的静态方法，因为静态方法不能被重写！\n    public static void showStatic(String str) {\n        System.out.println(\"son \" + str);\n    }\n\n    private void showPrivate(String str) {\n        System.out.println(\"son private\" + str);\n    }\n\n    public void show() {\n        //invokestatic\n        showStatic(\"atguigu.com\");\n        //invokestatic\n        super.showStatic(\"good!\");\n        //invokespecial\n        showPrivate(\"hello!\");\n        //invokespecial\n        super.showCommon();\n\n        //invokevirtual\n        showFinal();//因为此方法声明有final，不能被子类重写，所以也认为此方法是非虚方法。\n       \n        //虚方法如下：\n        /*\n        invokevirtual  你没有显示的加super.，编译器认为你可能调用子类的showCommon(即使son子类没有重写，也\t\t  会认为)，所以编译期间确定不下来，就是虚方法。\n        */\n        showCommon();\n        info();\n\n        MethodInterface in = null;\n        //invokeinterface\n        in.methodA();\n    }\n\n    public void info() {\n\n    }\n\n    public void display(Father f) {\n        f.showCommon();\n    }\n\n    public static void main(String[] args) {\n        Son so = new Son();\n        so.show();\n    }\n}\n\ninterface MethodInterface {\n    void methodA();\n}\n```\n\n`Son `类中` show()` 方法的字节码指令如下：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0032.png)\n\n### invokedynamic 指令\n\nJVM字节码指令集一直比较稳定，一直到Java7中才增加了一个`invokedynamic`指令，这是Java为了实现动态类型语言支持而做的一种改进。\n\n但是在Java7中并没有提供直接生成`invokedynamic`指令的方法，需要借助ASM这种底层字节码工具来产生`invokedynamic`指令。直到Java8的`Lambda`表达式的出现，`invokedynamic`指令的生成，在Java中才有了直接的生成方式。\n\nJava7中增加的动态语言类型支持的本质是对Java虚拟机规范的修改，而不是对Java语言规则的修改，这一块相对来讲比较复杂，增加了虚拟机中的方法调用，最直接的受益者就是运行在Java平台的动态语言的编译器。\n\n``` java\n@FunctionalInterface\ninterface Func {\n    public boolean func(String str);\n}\n\npublic class Lambda {\n    public void lambda(Func func) {\n        return;\n    }\n\n    public static void main(String[] args) {\n        Lambda lambda = new Lambda();\n\n        Func func = s -> {\n            return true;\n        };\n\n        lambda.lambda(func);\n\n        lambda.lambda(s -> {\n            return true;\n        });\n    }\n}\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0033.png)\n\n### 动态类型语言和静态类型语言\n\n动态类型语言和静态类型语言两者的区别就在于对类型的检查是在编译期还是在运行期，满足前者就是静态类型语言，反之是动态类型语言。\n\n说的再直白一点就是，静态类型语言是判断变量自身的类型信息；动态类型语言是判断变量值的类型信息，变量没有类型信息，变量值才有类型信息，这是动态语言的一个重要特征。\n\n> Java：String info = \"mogu blog\";     (Java是静态类型语言的，会先编译就进行类型检查)\n>\n> JS：var name = \"shkstart\";    var name = 10;    （运行时才进行检查）\n\n### 方法重写的本质\n\n#### Java 语言中方法重写的本质\n\n- 找到操作数栈顶的第一个元素所执行的对象的实际类型，记作C。\n- 如果在类型C中找到与常量中的描述符合简单名称都相符的方法，则进行访问权限校验，\n  - 如果通过则返回这个方法的直接引用，查找过程结束；\n  - 如果不通过，则返回`java.lang.IIlegalAccessError` 异常。\n- 否则说明该方法没有被当前类型C所重写，按照继承关系从下往上依次对C的各个父类进行第2步的搜索和验证过程。\n- 如果始终没有找到合适的方法，则抛出`java.lang.AbstractMethodsrror`异常。\n\n> 上面这个过程称为**动态分派**\n\n#### IllegalAccessError介绍\n\n程序试图访问或修改一个属性或调用一个方法，这个属性或方法，你没有权限访问。一般的，这个会引起编译器异常。这个错误如果发生在运行时，就说明一个类发生了不兼容的改变。\n\n比如，你把应该有的jar包放从工程中拿走了，或者Maven中存在jar包冲突\n\n### 虚方法表\n\n在面向对象的编程中，会很频繁的使用到动态分派，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，JVM采用在类的方法区建立一个**虚方法表**（virtual method table）（非虚方法不会出现在表中）来实现。使用索引表来代替查找。每个类中都有一个虚方法表，表中存放着各个方法的实际入口。\n\n#### 虚方法表是什么时候被创建的呢？\n\n虚方法表会在**类加载的链接阶段**被创建并开始初始化，类的变量初始值准备完成之后，JVM会把该类的方法表也初始化完毕。\n\n![image-20200706144954070](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706144954070.png)\n\n如上图所示：如果类中重写了方法，那么调用的时候，就会直接在虚方法表中查找，否则将会直接连接到Object的方法中。\n\n比如说`Son`在调用`toString()`的时候，`Son`没有重写过，`Son`的父类`Father`也没有重写过，那就直接调用`Object`类的`toString`。那么就直接在虚方法表里指明`toString()`直接指向`Object`类。\n\n下次`Son`对象再调用`toString()`时就直接去找`Object`，不用先找`Son`–>再找`Father`–>最后才到`Object`的这样的一个过程。\n\n## 方法返回地址\n\n存放调用该方法的pc寄存器的值。一个方法的结束，有两种方式：\n\n- 正常执行完成\n- 出现未处理的异常，非正常退出\n\n无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的pc计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定，栈帧中一般不会保存这部分信息。\n\n当一个方法开始执行后，只有两种方式可以退出这个方法：\n\n### 正常退出\n\n执行引擎遇到任意一个方法返回的字节码指令（`return`），会有返回值传递给上层的方法调用者，简称正常完成出口；\n\n- 一个方法在正常调用完成之后，究竟需要使用哪一个返回指令，还需要根据方法返回值的实际数据类型而定。\n- 在字节码指令中，返回指令包含`ireturn`（当返回值是`boolean`，`byte`，`char`，`short`和`int`类型时使用），`lreturn`（`Long`类型），`freturn`（`Float`类型），`dreturn`（`Double`类型），`areturn`。另外还有一个`return`指令声明为`void`的方法，实例初始化方法，类和接口的初始化方法使用。\n\n### 异常退出\n\n在方法执行过程中遇到异常（`Exception`），并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，简称**异常完成出口**。\n\n方法执行过程中，抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码\n\n![image-20200706154554604](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/image-20200706154554604.png)\n\n本质上，方法的退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。\n\n正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值。\n\n### 异常处理表\n\n- 反编译字节码文件，可得到 Exception table\n- `from `：字节码指令起始地址\n- `to `：字节码指令结束地址\n- `target `：出现异常跳转至地址为 11 的指令执行\n- `type `：捕获异常的类型\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A0%88/0041.png)\n\n## 一些附加信息\n\n栈帧中还允许携带与Java虚拟机实现相关的一些附加信息。例如：对程序调试提供支持的信息。\n\n## 栈的相关面试题\n\n**1. 举例栈溢出的情况**\n\nSOF（StackOverflowError），栈大小分为固定的，和动态变化。如果是**固定**的就可能出现`StackOverflowError`。如果是**动态变化的，内存不足时就可能出现 OOM**。可以通过 `-Xss` 设置栈的大小。\n\n> 动态变化的举例：通过 -Xms 和 -Xmx 可以实现堆空间的动态变化，但是 Hotspot 中并没有栈相关的动态变化参数，只有 -Xss 设置固定的大小，默认为 1M\n\n**2. 调整栈大小，就能保证不出现溢出么？**\n\n不能，对于无限递归的情况下，增大栈大小只能推迟溢出发生的时间，不能阻止溢出\n\n**3. 分配的栈内存越大越好么？**\n\n不是，一定时间内降低了OOM和SOF的概率，但是会挤占其它的线程空间，因为整个空间是有限的。栈变大后线程数就会变小（因为计算机的内存总量是有限的，栈内存大了，线程数也少了）\n\n**4. 垃圾回收是否涉及到虚拟机栈？**\n\n不会。栈里可能出现Error，但是不涉及GC。弹栈的过程有点类似GC但不是。\n\n**5. 运行时数据区，是否存在Error和GC？**\n\n| 运行时数据区 | 是否存在Error | 是否存在GC |\n| ------------ | ------------- | ---------- |\n| 程序计数器   | 否            | 否         |\n| 虚拟机栈     | 是            | 否         |\n| 本地方法栈   | 是            | 否         |\n| 方法区       | 是（OOM）     | 是         |\n| 堆           | 是            | 是         |\n\n**6. 方法中定义的局部变量是否线程安全？**\n\n具体问题具体分析。在方法内定义的局部变量，其在该方法的**生命周期内**是线程安全的，一旦出了生命周期就不一定了。总结一句话就是：如果对象是在内部产生，并在内部消亡，没有返回到外部，那么它就是线程安全的，反之则是线程不安全的。\n\n```java\n/**\n * 面试题\n * 方法中定义局部变量是否线程安全？具体情况具体分析\n * 何为线程安全？\n *    如果只有一个线程才可以操作此数据，则必是线程安全的\n *    如果有多个线程操作，则此数据是共享数据，如果不考虑共享机制，则为线程不安全\n */\npublic class StringBuilderTest {\n\n    // s1的声明方式是线程安全的\n    public static void method01() {\n        // 线程内部创建的，属于局部变量\n        StringBuilder s1 = new StringBuilder();\n        s1.append(\"a\");\n        s1.append(\"b\");\n    }\n\n    // 这个也是线程不安全的，因为有返回值，有可能被其它的程序所调用\n    public static StringBuilder method04() {\n        StringBuilder stringBuilder = new StringBuilder();\n        stringBuilder.append(\"a\");\n        stringBuilder.append(\"b\");\n        return stringBuilder;\n    }\n\n    // stringBuilder 是线程不安全的，操作的是共享数据\n    public static void method02(StringBuilder stringBuilder) {\n        stringBuilder.append(\"a\");\n        stringBuilder.append(\"b\");\n    }\n\n\n    /**\n     * 同时并发的执行，会出现线程不安全的问题\n     */\n    public static void method03() {\n        StringBuilder stringBuilder = new StringBuilder();\n        new Thread(() -> {\n            stringBuilder.append(\"a\");\n            stringBuilder.append(\"b\");\n        }, \"t1\").start();\n\n        method02(stringBuilder);\n    }\n\n    // StringBuilder是线程安全的，但是String也可能线程不安全的\n    public static String method05() {\n        StringBuilder stringBuilder = new StringBuilder();\n        stringBuilder.append(\"a\");\n        stringBuilder.append(\"b\");\n        return stringBuilder.toString();\n    }\n}\n```\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JUC】volatile","url":"/2021/09/23/【JUC】volatile/","content":"\n## JMM\n\nJMM（Java内存模型：Java Memory Model，简称JMM）本身是一种抽象的概念并不真实存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。JMM不是Java**内存布局**，不是所谓的栈、堆、方法区。\n\nJMM关于同步的规定：\n\n1. 线程解锁前，必须把共享变量的值刷新回主内存\n2. 线程加锁前，必须读取主内存的最新值到自己的工作内存\n3. 加锁解锁是同一把锁\n\n由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方称为栈空间），工作内存是每个线程的私有数据区域，而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，**但线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝的自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存**，不能直接操作主内存中的变量，各个线程中的工作内存中存储着主内存中的**变量副本拷贝**，因此不同的线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成，其简要访问过程如下图：\n\n![img](/images/%E3%80%90JUC%E3%80%91volatile/086f17f778d19c9be53c65117aaacd87.png)\n\n每个Java线程都有自己的**工作内存**。操作数据，首先从主内存中读，得到一份拷贝，操作完毕后再写回到主内存。\n\nJMM可能带来**可见性**、**原子性**和**有序性**问题。所谓可见性，就是某个线程对主内存内容的更改，应该**立刻通知到其它线程**。原子性是指一个操作是不可分割的，不能执行到一半，就不执行了。所谓有序性，就是**指令是有序的，不会被重排**。\n\n## volatile\n\nvolatile是JVM提供的**轻量级的同步机制**（`synchronized`锁是**重量级的同步机制**）。\n\n其特点：\n\n- 保证可见性\n- 不保证原子性\n- 禁止指令重排（保证有序性）\n\n<!-- More -->\n\n### 可见性\n\n各个线程对主内存中共享变量的操作都是各个线程各自拷贝到自己的工作内存进行操作后再写回到主内存中的。\n\n这就可能存在一个线程AAA修改了共享变量X的值但还未写回主内存时，另外一个线程BBB又对主内存中同一个共享变量X进行操作，但此时A线程工作内存中共享变量X对线程B来说并不可见，这种工作内存与主内存同步延迟现象就造成了可见性问题。\n\n示例代码：\n\n``` java\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 假设是主物理内存\n */\nclass MyData {\n\n    //volatile int number = 0;\n    int number = 0;\n\n    public void addTo60() {\n        this.number = 60;\n    }\n}\n\n/**\n * 验证volatile的可见性\n * 1. 假设int number = 0， number变量之前没有添加volatile关键字修饰\n */\npublic class VolatileDemo {\n\n    public static void main(String args []) {\n\n        // 资源类\n        MyData myData = new MyData();\n\n        // AAA线程 实现了Runnable接口的，lambda表达式\n        new Thread(() -> {\n\n            System.out.println(Thread.currentThread().getName() + \"\\t come in\");\n\n            // 线程睡眠3秒，假设在进行运算\n            try {\n                TimeUnit.SECONDS.sleep(3);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            // 修改number的值\n            myData.addTo60();\n\n            // 输出修改后的值\n            System.out.println(Thread.currentThread().getName() + \"\\t update number value:\" + myData.number);\n\n        }, \"AAA\").start();\n\n        // main线程就一直在这里等待循环，直到number的值不等于零\n        while(myData.number == 0) {}\n\n        // 按道理这个值是不可能打印出来的，因为主线程运行的时候，number的值为0，所以一直在循环\n        // 如果能输出这句话，说明AAA线程在睡眠3秒后，更新的number的值，重新写入到主内存，并被main线程感知到了\n        System.out.println(Thread.currentThread().getName() + \"\\t mission is over\");\n\n    }\n}\n```\n\n由于没有`volatile`修饰`MyData`类的成员变量`number`，`main`线程将会卡在`while(myData.number == 0) {}`，不能正常结束。\n\n若想正确结束，需要使用`volatile`修饰`MyData`类的成员变量`number`。\n\n``` java\nvolatile int number = 0;\n```\n\n### 原子性\n\n**`volatile`不保证原子性。**若想保证操作原子性，需要使用原子类`AtomicXxx`。\n\n原子性：不可分割，完整性，也即某个线程正在做某个具体业务时，中间不可以被加塞或者被分割。需要整体完整要么同时成功，要么同时失败。\n\nvolatile不保证原子性案例演示：\n\n``` java\nclass MyData2 {\n    /**\n     * volatile 修饰的关键字，是为了增加主线程和线程之间的可见性，只要有一个线程修改了内存中的值，其它线程也能马上感知\n     */\n    volatile int number = 0;\n    public void addPlusPlus() {\n        number++;\n    }\n}\n\npublic class VolatileAtomicityDemo {\n\n    public static void main(String[] args) {\n        MyData2 myData = new MyData2();\n\n        // 创建10个线程，线程里面进行1000次循环\n        for (int i = 0; i < 20; i++) {\n            new Thread(() -> {\n                // 里面\n                for (int j = 0; j < 1000; j++) {\n                    myData.addPlusPlus();\n                }\n            }, String.valueOf(i)).start();\n        }\n\n        // 需要等待上面20个线程都计算完成后，在用main线程取得最终的结果值\n        // 这里判断线程数是否大于2，为什么是2？因为默认是有两个线程的，一个main线程，一个gc线程\n        while(Thread.activeCount() > 2) {\n            // yield表示不执行\n            Thread.yield();\n        }\n\n        // 查看最终的值\n        // 假设volatile保证原子性，那么输出的值应该为：  20 * 1000 = 20000\n        System.out.println(Thread.currentThread().getName() + \"\\t finally number value: \" + myData.number);\n    }\n}\n```\n\n最后的结果总是小于20000。\n\n#### 原因分析\n\n`number++`在多线程下是非线程安全的。`number++`的操作，会形成3条指令：\n\n``` \ngetfield    //读\niconst_1\t//++常量1\niadd\t\t//加操作\nputfield\t//写操作\n```\n\n假设有3个线程，分别执行`number++`，都先从主内存中拿到最开始的值，`number=0`，然后三个线程分别进行操作。假设线程0执行完毕，`number=1`，也立刻通知到了其它线程，但是此时线程1、2已经拿到了`number=0`，切换回1、2线程后不会再去从主内存中获取一次`number`的值了，所以结果是线程1、2将`number`变成1覆盖了线程3的赋值。\n\n解决的方式就是：\n\n1. 对`addPlusPlus()`方法加`synchronized`锁，但它是**重量级的同步机制**，并发效率较低。\n2. 使用`java.util.concurrent.AtomicInteger`类，其可以保证原子性。\n\n``` java\nprivate static void atomicDemo() {\n    System.out.println(\"原子性测试\");\n    MyData myData=new MyData();\n    for (int i = 1; i <= 20; i++) {\n        new Thread(()->{\n            for (int j = 0; j <1000 ; j++) {\n                myData.addPlusPlus();\n                myData.addAtomic();\n            }\n        },String.valueOf(i)).start();\n    }\n    while (Thread.activeCount()>2){\n        Thread.yield();\n    }\n    System.out.println(Thread.currentThread().getName()+\"\\t int type finally number value: \"+myData.number);\n    System.out.println(Thread.currentThread().getName()+\"\\t AtomicInteger type finally number value: \"+myData.atomicInteger);\n}\n```\n\n结果：\n\n``` \n原子性测试\nmain\t int type finally number value: 17542\nmain\t AtomicInteger type finally number value: 20000\n```\n\n### 有序性\n\nvolatile可以保证**有序性**，也就是防止**指令重排序**。\n\n``` java\npublic class ResortSeqDemo {\n\n    int a=0;\n    boolean flag=false;\n    /*\n    多线程下flag=true可能先执行，还没走到a=1就被挂起。\n    其它线程进入method02的判断，修改a的值=5，而不是6。\n     */\n    public void method01(){\n        a=1;\n        flag=true;\n    }\n    public void method02(){\n        if (flag){\n            a+=5;\n            System.out.println(\"*****retValue: \"+a);\n        }\n    }\n}\n```\n\nvolatile可以保证**有序性**，也就是防止**指令重排序**。所谓指令重排序，就是出于**优化考虑**，CPU执行指令的顺序跟程序员自己编写的顺序不一致。就好比一份试卷，题号是老师规定的，是程序员规定的，但是考生（CPU）可以先做选择，也可以先做填空。\n\n``` \nint x = 11; //语句1\nint y = 12; //语句2\nx = x + 5;  //语句3\ny = x * x;  //语句4\n```\n\n以上例子，可能出现的执行顺序有1234、2134、1342，这三个都没有问题，最终结果都是x = 16，y=256。但是如果是4开头，就有问题了，y=0。这个时候就**不需要**指令重排序。\n\nvolatile底层是用CPU的**内存屏障**（Memory Barrier）指令来实现的，有两个作用，一个是保证特定操作的顺序性，二是保证变量的可见性。在指令之间插入一条Memory Barrier指令，告诉编译器和CPU，在Memory Barrier指令之间的指令不能被重排序。\n\n## volatile 指令重排序\n\n计算机在执行程序时，**为了提高性能**，编译器和处理器的常常会对指令做重排，一般分以下3种：\n\n![img](/images/%E3%80%90JUC%E3%80%91volatile/bd9649a5795e503000a1fe89e57665a7.png)\n\n- 单线程环境里面能够确保程序最终执行结果和代码顺序执行的结果一致（因为即使重排序也不会影响执行逻辑）。处理器在进行重排序时必须要考虑指令之间的**数据依赖性**\n- 但多线程环境中线程交替执行，由于编译器优化重排的存在，两个线程中使用的变量能否保证一致性是无法确定的，结果无法预测。例如两条指令顺序颠倒后被不同线程并发访问就可能出现问题。\n\n### 理论\n\n内存屏障(Memory Barrier）又称内存栅栏，是一个CPU指令，它的作用有两个:\n\n1. 保证特定操作的执行顺序，\n2. 保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）。\n\n由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过**插入内存屏障禁止在内存屏障前后的指令执行重排序优化**。内存屏障另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。\n\n对volatile变量进行写操作时，会在写操作后加入一条store屏障指令，将工作内存中的共享变量值刷新回到主内存。\n\n![img](/images/%E3%80%90JUC%E3%80%91volatile/d7626eb368ec93d80ed98478dd579401.png)\n\n对volatile变量进行读操作时，会在读操作前加入一条load屏障指令，从主内存中读取共享变量。\n\n![img](/images/%E3%80%90JUC%E3%80%91volatile/c351d47587cbdf0ba57028ec8b894114.png)\n\n**线性安全性获得保证**\n\n- 工作内存与主内存同步延迟现象导致的**可见性**问题 - 可以使用synchronized或volatile关键字解决，它们都可以使一个线程修改后的变量立即对其他线程可见。\n- 对于指令重排导致的**可见性**问题和**有序性**问题 - 可以利用volatile关键字解决，因为volatile的另外一个作用就是禁止重排序优化。\n\n\n\n\n\n\n\n## 单例模式使用 volatile\n\n不使用 volatile 时的懒汉式单例模式：\n\n```java\nclass Bank{\n    private Bank(){}\n    private static Bank instance = null;\n\n    public static Bank getInstance(){\n        //方式一：效率稍差\n        /*\n        synchronized (Bank.class) {\n            if(instance == null){\n                instance = new Bank();\n            }\n            return instance;\n        }*/\n        \n        //方式二：效率更高，如果实例对象已经非空，说明已经造好了对象，不需要再进入同步代码块内\n        //DCL（Double Check Lock 双端检锁机制）\n        if(instance == null){\n            synchronized (Bank.class) {\n                if(instance == null){\n                    instance = new Bank();\n                }\n            }\n        }\n        return instance;\n    }\n}\n```\n\n### 可能存在的问题\n\n注意，双端检锁机制不一定线程安全，原因是指令重排序的存在，加入`volatile`可以禁止指令重排序。指令重排序只会保证串行语义的执行的一致性（单线程），并不会关心多线程间的语义一致性。\n\n代码中 `instance = new Bank()` 语句实际的执行顺序为：\n\n1. `memory = allocate()`：为对象开辟一块内存空间\n2. `instance(memory)`：初始化该对象，为其成员属性赋值\n3. `instance = memory`：设置`instance`指向刚才分配的内存地址，此时 `instance != null`\n\n正常顺序是1 -> 3 -> 2。但由于指令重排序，可能某个线程在new对象的时候，重新排序后是1 -> 3 -> 2。即先给该对象引用赋了地址，但还未为该变量进行初始化（还未实例化对象）。\n\n这就导致了可能该对象还未初始化时，另一个线程就抢到CPU执行权并判断 ` if(instance == null)`，此时发现`instance`的值已经不为空了（因为已经开辟并分配了地址），其将被直接返回，那么获取到的对象就是`null`值了。\n\n> 该情况不会导致重复new对象，只是有可能返回null值。\n\n解决方案：\n\n1. 采用方式一，在整个方法上加锁。缺点是并发效率低\n2. 为`instance`对象添加`volatile`关键字，禁止指令重排序。\n\n``` java\nclass Bank{\n    private Bank(){}\n    private volatile static Bank instance = null;\n\n    public static Bank getInstance(){\n        // DCL（Double Check Lock 双端检锁机制）\n        if(instance == null){\n            synchronized (Bank.class) {\n                if(instance == null){\n                    instance = new Bank();\n                }\n            }\n        }\n        return instance;\n    }\n}\n```\n\n\n\n","tags":["JUC"],"categories":["JUC"]},{"title":"【JVM】JVM 运行时数据区","url":"/2021/09/22/【JVM】JVM运行时数据区/","content":"\n## 运行时数据区概述\n\n![image-20200705111640511](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705111640511.png)\n\n当我们通过前面的：**类的加载 -> 验证 -> 准备 -> 解析 -> 初始化** 这几个阶段完成后，就会用到执行引擎对我们的类进行使用，同时执行引擎将会使用到我们运行时数据区\n\n![image-20200705111843003](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705111843003.png)\n\n<!-- More -->\n\n好比大厨做饭，我们把大厨后面的东西（切好的菜，刀，调料），比作是运行时数据区。而厨师可以类比于执行引擎，将通过准备的东西进行制作成精美的菜品\n\n![image-20200705112036630](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705112036630.png)\n\n### 运行时数据区结构\n\n内存是非常重要的系统资源，是硬盘和CPU的中间仓库及桥梁，承载着操作系统和应用程序的实时运行JVM内存布局规定了Java在运行过程中内存申请、分配、管理的策略，保证了JVM的高效稳定运行。**不同的JVM对于内存的划分方式和管理机制存在着部分差异**。结合JVM虚拟机规范，来探讨一下经典的JVM内存布局。\n\n我们通过磁盘或者网络IO得到的数据，都需要先加载到内存中，然后CPU从内存中获取数据进行读取，也就是说内存充当了CPU和磁盘之间的桥梁\n\n> 运行时数据区的完整图：来自阿里巴巴手册JDK8\n\n![image-20200705112416101](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705112416101.png)\n\n### 线程的内存空间\n\nJava虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线程对应的数据区域会随着线程开始和结束而创建和销毁。\n\n下图中灰色的为单独线程私有的，红色的为多个线程共享的。即：\n\n- **每个线程独立拥有**：程序计数器、栈、本地栈。\n- **线程间共享**：堆、堆外内存（永久代或元空间、代码缓存）\n\n![image-20200705112601211](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705112601211.png)\n\n### Runtime 类\n\n**每个JVM只有一个Runtime实例**。即为运行时环境，相当于内存结构的中间的那个框框：运行时环境。\n\n![img](https://cdn.jsdelivr.net/gh/youthlql/lqlp@v1.0.0/JVM/chapter_003/0006.png)\n\n## 线程\n\n### JVM 线程\n\n线程是一个程序里的运行单元。JVM允许一个应用有多个线程并行的执行。**在Hotspot JVM里，每个线程都与操作系统的本地线程直接映射。**\n\n当一个Java线程准备好执行以后，此时一个操作系统的本地线程也同时创建。Java线程执行终止后，本地线程也会回收。\n\n操作系统负责所有线程的安排调度到任何一个可用的CPU上。一旦本地线程初始化成功，它就会调用Java线程中的`run()`方法。\n\n### JVM 系统线程\n\n如果你使用jconsole或者是任何一个调试工具，都能看到在后台有许多线程在运行。这些主要的后台系统线程在Hotspot JVM里主要是以下几个：\n\n- **虚拟机线程**：这种线程的操作是需要JVM达到安全点才会出现。这些操作必须在不同的线程中发生的原因是他们都需要JVM达到安全点，这样堆才不会变化。这种线程的执行类型包括\"stop-the-world\"的垃圾收集，线程栈收集，线程挂起以及偏向锁撤销。\n- **周期任务线程**：这种线程是时间周期事件的体现（比如中断），他们一般用于周期性操作的调度执行。\n- **GC线程**：这种线程对在JVM里不同种类的垃圾收集行为提供了支持。\n- **编译线程**：这种线程在运行时会将字节码编译成到本地代码。\n- **信号调度线程**：这种线程接收信号并发送给JVM，在它内部通过调用适当的方法进行处理。\n\n## 程序计数器（PC 寄存器）\n\n### PC 寄存器介绍\n\n> 官方文档网址：https://docs.oracle.com/javase/specs/jvms/se8/html/index.html\n\nJVM程序计数寄存器（Program Counter Register）中，Register的命名源于CPU的寄存器，**寄存器存储指令相关的现场信息**。CPU只有把数据装载到寄存器才能够运行。这里，并非是广义上所指的物理寄存器，或许将其翻译为PC计数器（或指令计数器）会更加贴切（也称为程序钩子），并且也不容易引起一些不必要的误会。\n\n![image-20200705155551919](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705155551919.png)\n\n**JVM中的PC寄存器是对物理PC寄存器的一种抽象模拟**。它是一块很小的内存空间，几乎可以忽略不记。也是**运行速度最快**的存储区域。\n\n在JVM规范中，每个线程都有它自己的程序计数器，是**线程私有的**，生命周期与线程的生命周期保持一致。任何时间一个线程都只有一个方法在执行，也就是所谓的**当前方法**。\n\n- 程序计数器会存储**当前线程正在执行的Java方法的JVM指令地址**；或者，如果是在执行`native`方法，则是未指定值（undefned）。\n- 它是**程序控制流**的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。字节码解释器工作时就是通过改变这个计数器的值来选取**下一条需要执行的字节码指令**。\n- 它是**唯一一个**在Java虚拟机规范中没有规定任何`OutofMemoryError`情况的区域。\n\n### PC 寄存器的作用\n\nPC寄存器用来存储**指向下一条指令的地址**（？），也即将要执行的指令代码。**由执行引擎读取下一条指令，并执行该指令**。\n\n![image-20200705155728557](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705155728557.png)\n\n### 补充\n\n深入理解 Java 虚拟机中是这样说的：如果线程正在执行的是一个Java方法，这个计数器记录的是**正在执行**的虚拟机字节指令的地址\n\nJVM 8规范里：如果执行的不是本地方法，PC 寄存器中存的是当前执行指令的地址。\n\nCPU 里的PC寄存器确实是指向下一条，但是JVM规范里明确说了，程序计数器指向的是**当前指令**的地址。\n\n### 举例\n\n```java\npublic class PCRegisterTest {\n    public static void main(String[] args) {\n        int i = 10;\n        int j = 20;\n        int k = i + j;\n    }\n}\n```\n\n查看字节码\n\n```\nClassfile /F:/IDEAWorkSpaceSourceCode/JVMDemo/out/production/chapter04/com/atguigu/java/PCRegisterTest.class\n  Last modified 2020-11-2; size 675 bytes\n  MD5 checksum 53b3ef104479ec9e9b7ce5319e5881d3\n  Compiled from \"PCRegisterTest.java\"\npublic class com.atguigu.java.PCRegisterTest\n  minor version: 0\n  major version: 52\n  flags: ACC_PUBLIC, ACC_SUPER\nConstant pool:\n   #1 = Methodref          #6.#26         // java/lang/Object.\"<init>\":()V\n   #2 = String             #27            // abc\n   #3 = Fieldref           #28.#29        // java/lang/System.out:Ljava/io/PrintStream;\n   #4 = Methodref          #30.#31        // java/io/PrintStream.println:(I)V\n   #5 = Class              #32            // com/atguigu/java/PCRegisterTest\n   #6 = Class              #33            // java/lang/Object\n   #7 = Utf8               <init>\n   #8 = Utf8               ()V\n   #9 = Utf8               Code\n  #10 = Utf8               LineNumberTable\n  #11 = Utf8               LocalVariableTable\n  #12 = Utf8               this\n  #13 = Utf8               Lcom/atguigu/java/PCRegisterTest;\n  #14 = Utf8               main\n  #15 = Utf8               ([Ljava/lang/String;)V\n  #16 = Utf8               args\n  #17 = Utf8               [Ljava/lang/String;\n  #18 = Utf8               i\n  #19 = Utf8               I\n  #20 = Utf8               j\n  #21 = Utf8               k\n  #22 = Utf8               s\n  #23 = Utf8               Ljava/lang/String;\n  #24 = Utf8               SourceFile\n  #25 = Utf8               PCRegisterTest.java\n  #26 = NameAndType        #7:#8          // \"<init>\":()V\n  #27 = Utf8               abc\n  #28 = Class              #34            // java/lang/System\n  #29 = NameAndType        #35:#36        // out:Ljava/io/PrintStream;\n  #30 = Class              #37            // java/io/PrintStream\n  #31 = NameAndType        #38:#39        // println:(I)V\n  #32 = Utf8               com/atguigu/java/PCRegisterTest\n  #33 = Utf8               java/lang/Object\n  #34 = Utf8               java/lang/System\n  #35 = Utf8               out\n  #36 = Utf8               Ljava/io/PrintStream;\n  #37 = Utf8               java/io/PrintStream\n  #38 = Utf8               println\n  #39 = Utf8               (I)V\n{\n  public com.zhao.java.PCRegisterTest();\n    descriptor: ()V\n    flags: ACC_PUBLIC\n    Code:\n      stack=1, locals=1, args_size=1\n         0: aload_0\n         1: invokespecial #1                  // Method java/lang/Object.\"<init>\":()V\n         4: return\n      LineNumberTable:\n        line 7: 0\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       5     0  this   Lcom/atguigu/java/PCRegisterTest;\n\n  public static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n      stack=2, locals=5, args_size=1\n         0: bipush        10\n         2: istore_1\n         3: bipush        20\n         5: istore_2\n         6: iload_1\n         7: iload_2\n         8: iadd\n         9: istore_3\n        10: ldc           #2                  // String abc\n        12: astore        4\n        14: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n        17: iload_1\n        18: invokevirtual #4                  // Method java/io/PrintStream.println:(I)V\n        21: getstatic     #3                  // Field java/lang/System.out:Ljava/io/PrintStream;\n        24: iload_3\n        25: invokevirtual #4                  // Method java/io/PrintStream.println:(I)V\n        28: return\n      LineNumberTable:\n        line 10: 0\n        line 11: 3\n        line 12: 6\n        line 14: 10\n        line 15: 14\n        line 16: 21\n        line 18: 28\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0      29     0  args   [Ljava/lang/String;\n            3      26     1     i   I\n            6      23     2     j   I\n           10      19     3     k   I\n           14      15     4     s   Ljava/lang/String;\n}\nSourceFile: \"PCRegisterTest.java\"\n```\n\n其中， `main()` 方法的`Code`内：\n\n```bash\n0: bipush        10\n2: istore_1\n3: bipush        20\n5: istore_2\n6: iload_1\n7: iload_2\n8: iadd\n9: istore_3\n10: return\n```\n\n左边的数字代表**指令地址（指令偏移）**，即 PC 寄存器中可能存储的值，然后执行引擎读取 PC 寄存器中的值，并执行该指令。\n\n![image-20200705161007423](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705161007423-1632311587698.png)\n\n\n\n### 两个面试题\n\n**1. 使用PC寄存器存储字节码指令地址有什么用呢？**或者问**为什么使用 PC 寄存器来记录当前线程的执行地址呢？**\n\n- 因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行\n- JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令\n\n![image-20200705161409533](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200705161409533.png)\n\n\n\n**2. PC 寄存器为什么被设定为私有的？**\n\n我们都知道所谓的多线程在一个特定的时间段内只会执行其中某一个线程的方法，CPU会不停地做任务切换，这样必然导致经常中断或恢复，如何保证分毫无差呢？**为了能够准确地记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程都分配一个PC寄存器**，这样一来各个线程之间便可以进行独立计算，从而不会出现相互干扰的情况。\n\n由于CPU时间片轮限制，众多线程在并发执行过程中，任何一个确定的时刻，一个处理器或者多核处理器中的一个内核，只会执行某个线程中的一条指令。这样必然导致经常中断或恢复，如何保证分毫无差呢？每个线程在创建后，都会产生自己的程序计数器和栈帧，程序计数器在各个线程之间互不影响。\n\n### CPU 时间片\n\nCPU时间片即CPU分配给各个程序的时间，每个线程被分配一个时间段，称作它的时间片。\n\n- 在宏观上：我们可以同时打开多个应用程序，每个程序并行不悖，同时运行。\n- 在微观上：由于只有一个CPU，一次只能处理程序要求的一部分，如何处理公平，一种方法就是引入时间片，**每个程序轮流执行**。\n\n[![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/0011.png)](https://cdn.jsdelivr.net/gh/youthlql/lqlp@v1.0.0/JVM/chapter_003/0011.png)\n\n## 本地方法接口\n\n### 本地方法\n\n简单地讲，**一个Native Method是一个Java调用非Java代码的接囗**。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/0012.png)\n\n一个Native Method是这样一个Java方法：该方法的实现由非Java语言实现，比如C。这个特征并非Java所特有，很多其它的编程语言都有这一机制，比如在C++中，你可以用extern 告知C++编译器去调用一个C的函数。\n\n> “A native method is a Java method whose implementation is provided by non-java code.”（本地方法是一个非Java的方法，它的具体实现是非Java代码的实现）\n\n在定义一个native method时，并不提供实现体（有些像定义一个Java interface），因为其实现体是由非java语言在外面实现的。本地接口的作用是融合不同的编程语言为Java所用，**它的初衷是融合C/C++程序。**\n\n### 举例\n\n需要注意的是：标识符`native`可以与其它java标识符连用，但是**`abstract`除外**\n\n```java\npublic class IHaveNatives {\n    public native void Native1(int x);\n\n    public native static long Native2();\n\n    private native synchronized float Native3(Object o);\n\n    native void Native4(int[] ary) throws Exception;\n}\n```\n\n### 为什么要使用 Native Method？\n\nJava使用起来非常方便，然而有些层次的任务用Java实现起来不容易，或者我们对程序的效率很在意时，问题就来了。\n\n**1. 与 Java 环境外交互**\n\n有时Java应用需要与Java外面的**硬件环境**交互，这是本地方法存在的主要原因。你可以想想Java需要与一些**底层系统**，如**操作系统或某些硬件交换信息时的情况**。本地方法正是这样一种交流机制：它为我们提供了一个非常简洁的接口，而且我们无需去了解Java应用之外的繁琐的细节。\n\n**2. 与操作系统的交互**\n\nJVM支持着Java语言本身和运行时库，它是Java程序赖以生存的平台，它由一个解释器（解释字节码）和一些连接到本地代码的库组成。然而不管怎样，它毕竟不是一个完整的系统，它经常依赖于一些底层系统的支持。这些底层系统常常是强大的操作系统。\n\n**通过使用本地方法，我们得以用Java实现了jre的与底层系统的交互，甚至JVM的一些部分就是用C写的**。\n\n还有，如果我们要使用一些Java语言本身没有提供封装的操作系统的特性时，我们也需要使用本地方法。\n\n**3. Sun Java**\n\nSun的解释器是用C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分是用Java实现的，它也通过一些本地方法与外界交互。\n\n例如：类`java.lang.Thread`的`setPriority()`方法是用Java实现的，但是它实现调用的是该类里的本地方法`setPriority0()`。这个本地方法是用C实现的，并被植入JVM内部在Windows 95的平台上，这个本地方法最终将调用Win32 `setpriority()` API。这是一个本地方法的具体实现由JVM直接提供，更多的情况是本地方法由外部的动态链接库（external dynamic link library, \\*.dll）提供，然后被JVM调用。\n\n### 本地方法的现状\n\n目前该方法使用的越来越少了，除非是与**硬件**有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间的通信很发达，比如可以使用Socket通信，也可以使用Web Service等等，不多做介绍。\n\n## 本地方法栈\n\n**Java虚拟机栈于管理Java方法的调用，而本地方法栈用于管理本地方法的调用**。\n\n本地方法栈，也是**线程私有的**。其允许被实现成固定或者是可动态扩展的内存大小（在内存溢出方面和虚拟机栈相同）\n\n- 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java虚拟机将会抛出一个`StackOverflowError `异常。\n- 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么Java虚拟机将会抛出一个`OutOfMemoryError`异常。\n\n本地方法一般是使用C语言或C++语言实现的。它的具体做法是在Native Method Stack中登记native方法，在执行引擎 Execution Engine 执行时加载本地方法库。\n\n![image-20200706174708418](/images/%E3%80%90JVM%E3%80%91JVM%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA/image-20200706174708418.png)\n\n**注意事项**\n\n- 当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。\n  - 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区\n  - 它甚至可以直接使用本地处理器中的寄存器\n  - 直接从本地内存的堆中分配任意数量的内存\n- 并不是所有的JVM都支持本地方法。因为Java虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果JVM产品不打算支持native方法，也可以无需实现本地方法栈。\n- 在Hotspot JVM中，**直接将本地方法栈和虚拟机栈合二为一**。\n\n\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 类加载机制","url":"/2021/09/22/【JVM】JVM类加载机制/","content":"\n## 类加载器子系统概述\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/05e32da21f7e001e26951a21a6393db5.png)\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/94f3ef5322aa4dd32f2478f49c98a7af.png)\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/68747470733a2f2f63646e2e6a7364656c6976722e6e65742f67682f796f7574686c716c2f6c716c704076312e302e302f4a564d2f636861707465725f3030322f303030332e6a7067)\n\n如果自己想手写一个Java虚拟机的话，主要考虑哪些结构呢？\n\n- 类加载器\n- 执行引擎\n\n<!-- More -->\n\n## 类加载器子系统作用\n\n类加载器子系统负责从文件系统或者网络中加载Class文件，.`class`文件在文件开头有特定的文件标识：**魔数** `CA FE BA BE`。类加载器`ClassLoader`只负责`.class`文件的加载，至于它是否可以运行，则由执行引擎E`xecution Engine`决定。\n\n加载的类信息存放于一块称为**方法区（Java 8.0称为元空间）**的内存空间。除了类的信息外，方法区中还会存放**运行时常量池**信息，可能还包括**字符串字面量**和**数字常量**（这部分常量信息是Class文件中常量池部分的内存映射） \n\n![image-20200705081813409](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705081813409-1632296385072.png)\n\n- `.class` 文件存在于本地硬盘上，可以理解为设计师画在纸上的模板，而最终这个模板在执行的时候是要加载到JVM的方法区（JDK 8 的元空间）当中来根据这个文件实例化出n个一模一样的实例。\n- `.class` 文件加载到JVM的方法区（JDK 8 的元空间）中，被称为DNA**元数据模板**。\n- 在`.class`文件 -> JVM -> 最终成为**元数据模板**，此过程就要一个运输工具（类装载器Class Loader），扮演一个快递员的角色。\n\n![image-20200705081913538](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705081913538-1632294600690.png)\n\n![image-20211014204209807](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211014204209807.png)\n\n\n\n## 类的加载过程\n\n在Java中数据类型分为基本数据类型和引用数据类型。**基本数据类型由虚拟机预先定义**，引用数据类型则需要进行类的加载。即基本数据类型不需要类加载器来加载，在JVM启动时就已经预定义，下面讨论的加载过程都是针对引用类型对象而言。\n\n例如下面的一段简单的代码：\n\n```java\npublic class HelloLoader {\n    public static void main(String[] args) {\n        System.out.println(\"我已经被加载啦\");\n    }\n}\n```\n\n它的加载过程是怎么样的呢?\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201118115656.jpg)\n\n完整的流程图如下所示：加载 --> 链接（验证 --> 准备 --> 解析） --> 初始化\n\n![image-20200705082601441](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705082601441-1632294600690.png)\n\n下面按顺序分析该类的加载过程：\n\n- **加载阶段 - Loading**：将 `.class` 文件从硬盘/网络中读取加载到内存中\n- **链接阶段 - Linking**\n  - **验证 - Verify**：校验文件是否合法\n  - **准备 - Prepare**：为类的静态成员变量初始化，赋零值\n  - **解析 - Resolve**：将常量池内的符号引用转换为直接引用\n- **初始化阶段 - Initialization**：为类的静态成员变量赋值。合并类的静态成员变量赋值语句和静态代码块中的语句组成 `<clinit>()` 方法，并按顺序执行为这些静态成员变量赋值。\n\n![image-20200705081813409](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705081813409-1632296385072.png)\n\n按照Java虚拟机规范，从class文件到加载到内存中的类，到类卸载出内存为止，它的整个生命周期包括如下7个阶段：\n\n![image-20211014204138998](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211014204138998.png)\n\n## 加载阶段 - Loading \n\n所谓加载，就是将Java类的字节码文件加载到机器内存中，并在方法区中构建出Java类的原型——**类模板信息**\n\n> 所谓类模板对象，其实就是Java类在JVM内存中的一个快照，JVM将从字节码文件中解析出的常量池、类字段、类方法等信息存储到类模板中，这样JVM在运行期便能通过类模板而获取Java类中的任意信息，能够对Java类的成员变量进行遍历，也能进行Java方法的调用，见下图中方法区里的二进制数据表结构。反射的机制即基于这一基础。如果JVM没有将Java类的声明信息存储起来，则JVM在运行期也无法反射。\n\n作用：加载阶段负责将`.class`文件从硬盘/网络中读取二进制字节流到内存中，交给链接阶段进行验证/准备/解析。\n\n流程：\n\n1. 通过一个类的全限定名获取定义此类的**二进制字节流**\n2. 将这个二进制字节流所代表的静态存储结构转化为**方法区内的运行时数据结构——类模板信息**\n3. 在内存中生成一个代表这个类的`java.lang.Class`对象，作为方法区这个类的各种数据的访问入口（下图中代表Sample类的Class对象）\n\n\n\n![image-20211014204209807](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211014204209807.png)\n\n### 加载 .class 文件的方式\n\n- 从本地系统中直接加载 `.class` 文件（最常见）\n- 通过网络获取，典型场景：Web Applet\n- 从zip压缩包中读取，成为日后jar、war格式的基础\n- 运行时计算生成，使用最多的是：动态代理技术\n- 由其他文件生成，典型场景：JSP应用从专有数据库中提取`.class`文件，比较少见\n- 从**加密文件**中获取，典型的防Class文件被反编译的保护措施\n\n### 类模型与 Class 实例的位置\n\n代表该类的类模板信息存储在方法区（JDK 8 以后的元空间）中，其对应的 Class 对象存储在堆区，并能访问到方法区中的类信息。\n\n![image-20211014204942607](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211014204942607.png)\n\n### 数组类的加载\n\n创建数组类的情况稍微有些特殊，**因为数组类本身并不是由类加载器负责创建**，而是由JVM在运行时根据需要而直接创建的，但数组的元素类型仍然需要依靠类加载器去创建。创建数组类（下述简称A）的过程：\n\n- 如果数组的元素类型是引用类型，那么就遵循定义的加载过程递归加载和创建数组A的元素类型\n- JVM使用指定的元素类型和数组维度来创建新的数组类。\n\n如果数组的元素类型是引用类型，数组类的可访问性就由元素类型的可访问性决定。否则数组类的可访问性将被缺省定义为public。\n\n\n\n## 链接阶段 - Linking\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201118121444924.png)\n\n### 验证 - Verify\n\n**目的在于确保Class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全**。如果出现不合法的字节码文件，那么将会验证不通过。\n\n主要包括四种验证，文件格式验证，元数据验证，字节码验证，符号引用验证。\n\n![image-20211014205546184](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211014205546184.png)\n\n说明：\n\n- 格式验证其实适合加载阶段一起进行的，只是为了分类才将其归纳到链接阶段。验证通过后，类加载器才会将类的二进制数据信息加载到方法区中。\n- 格式验证之外的其他验证操作将会在方法区中进行。\n- 链接阶段的验证虽然拖慢了加载速度，但是它避免了在字节码运行时还需要进行各种检查。\n\n\n\n> 工具：Binary Viewer查看\n\n![image-20200705084038680](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705084038680-1632294600690.png)\n\n同时我们可以通过安装IDEA的插件，来查看我们的Class文件\n\n![image-20200705090237078](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705090237078-1632294600690.png)\n\n安装完成后，我们编译完一个class文件后，点击view即可显示我们安装的插件来查看字节码方法了\n\n![image-20200705090328171](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705090328171-1632294600690.png)\n\n### 准备 - Prepare\n\n作用：为**类的静态成员变量**分配内存并且设置该类变量的**默认零初始值**，基本数据类型为零值，引用数据类型为`null`。\n\n> 准备阶段不会为 static 方法块中定义的静态成员进行初始化，其由初始化阶段完成\n\n```java\npublic class HelloApp {\n    private static int a = 1;  // 准备阶段为0，在下个阶段，也就是初始化的时候才是1\n    public static void main(String[] args) {\n        System.out.println(a);\n    }\n}\n```\n\n上面的变量a在**准备阶段**会赋默认零初始值，**但不是1，而是0**。在这个阶段并不会像初始化阶段中那样会有初始化或者代码被执行。\n\n**注意**：\n\n- 这里不包含用`final`修饰的`static`，因为 **`final`在编译的时候就会分配了**，可以在字节码文件中该Field的属性中查看到其值为1，说明在程序运行前就已经确定了该值，因此准备阶段时其值就已经是1了\n- 这里**不会为实例变量分配初始化**，**类的静态成员变量会分配在方法区中（JDK 8 中存储在堆中），而实例变量是会随着对象一起分配到堆中。**\n\n下面代码中，`num`在`static`方法块中先赋值再声明，看似顺序不合理，但是在准备阶段已经先声明了静态成员变量`num`并为赋值为0。在后续的初始化阶段，才会执行`static`代码块中赋值操作，此时已经声明了`num`变量。\n\n``` java\nstatic {\n    num = 1;\n}\n\nprivate static int num;\n```\n\n---\n\n注意：\n\n```java\n// 一般情况：static final修饰的基本数据类型、字符串类型字面量会在准备阶段赋值\nprivate static final String str = \"Hello world\";\n// 特殊情况：static final修饰的引用类型不会在准备阶段赋值，而是在初始化阶段赋值\nprivate static final String str = new String(\"Hello world\");\n```\n\n结论：使用 `static + final` 修饰，且显式赋值中不涉及到方法或构造器调用的基本数据类型或String类型的显式赋值，是在链接阶段的准备环节进行，否则就是在初始化阶段进行。\n\n```java\npublic static final int INT_CONSTANT = 10;                                // 在链接阶段的准备环节赋值\npublic static final int NUM1 = new Random().nextInt(10);                  // 在初始化阶段clinit>()中赋值\npublic static int a = 1;                                                  // 在初始化阶段<clinit>()中赋值\n\npublic static final Integer INTEGER_CONSTANT1 = Integer.valueOf(100);     // 在初始化阶段<clinit>()中赋值\npublic static Integer INTEGER_CONSTANT2 = Integer.valueOf(100);           // 在初始化阶段<clinit>()中概值\n\npublic static final String s0 = \"helloworld0\";                            // 在链接阶段的准备环节赋值\npublic static final String s1 = new String(\"helloworld1\");                // 在初始化阶段<clinit>()中赋值\npublic static String s2 = \"hellowrold2\";                                  // 在初始化阶段<clinit>()中赋值\n```\n\n\n\n### 解析 - Resolve\n\n作用：将常量池内的类、接口、字段和方法等**符号引用转换为直接引用**。\n\n> `.class `文件中只会保存常量池中信息（例如类信息、方法信息等）的**符号引用**，不需要直接引用这些信息，这样文件体积就会比较小，也能节省栈的空间，即栈帧里的动态链接部分只需要保存符号引用，而不需要保存直接引用，该转换由解析阶段完成。\n\n符号引用就是一些字面量的引用，和虚拟机的内部数据结构和和内存布局无关。比较容易理解的就是在Class类文件中，通过常量池进行了大量的符号引用。但是在程序实际运行时，只有符号引用是不够的，比如当 `println()` 方法被调用时，系统需要明确知道该方法的位置，因此需要在调用该方法前找到其真实地址。\n\n使用 `javap` 命令解析 `.class` 文件后可以查看符号引用：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/df32a22e07108b9318c3a020d304c783.png)\n\n以方法为例，Java虚拟机为每个类都准备了一张方法表，将其所有的方法都列在表中，当需要调用一个类的方法的时候，只要知道这个方法在方法表中的偏移量就可以直接调用该方法。通过解析阶段，符号引用就可以转变为目标方法在类中方发表中的位置，从而使得方法被成功调用。\n\n事实上，**解析操作往往会伴随着JVM在执行完初始化之后再执行**，只是将其分类到链接阶段而已。\n\n符号引用就是一组符号来描述所引用的目标。符号引用的字面量形式明确定义在《java虚拟机规范》的`class`文件格式中。**直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。**\n\n解析动作主要针对类或接口、字段、类方法、接口方法、方法类型等。对应常量池中的`CONSTANT Class info`、`CONSTANT Fieldref info`、`CONSTANT Methodref info`等。\n\n## 初始化阶段 - Initialization \n\n作用：初始化阶段就是执行**类的静态属性初始化方法**`<clinit>()`的过程（class init）。\n\n`<clinit>()`方法不需显式定义，是javac编译器自动收集类中的**所有类静态成员变量的赋值动作和静态代码块中的语句合并而来**。也就是说，当我们代码中包含`static`变量的时候，就会自动生成`clinit()`方法。静态属性构造器方法中指令按语句在源文件中出现的顺序执行。\n\n`<clinit>()`不同于类的构造器。（关联：构造器是虚拟机视角下的`<init>()`）若该类具有父类，JVM会保证子类的`<clinit>()`执行前，父类的`<clinit>()`已经执行完毕。\n\n只有当我们代码中包含`static`成员变量或`static`代码块的时候，才会有`<clinit>()`方法。\n\n``` java\npublic class ClassInitTest {\n    private static int num = 1;\n\n    static {\n        num = 3;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(ClassInitTest.num);\n    }\n}\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201120091316.png)\n\n### `<clinit>() `方法初始化顺序\n\n`<clinit>()`方法中的指令按语句在源文件中出现的顺序执行。\n\n```java\npublic class ClassInitTest {\n    private static int num = 1;\n    static {\n        num = 2;\n        number = 20;\n        System.out.println(num);\n        System.out.println(number);  // 报错，非法的前向引用，但是不调用的话是不会有错的\n    }\n\n    private static int number = 10;\n\n    public static void main(String[] args) {\n        System.out.println(ClassInitTest.num); // 2\n        System.out.println(ClassInitTest.number); // 10\n    }\n}\n```\n\n静态变量 number 的值变化过程如下\n\n- 准备阶段时：默认初始化 0\n- 执行静态代码块：20\n- 执行静态变量初始化：10\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201120100027.png)\n\n若该类具有父类，JVM会保证子类的`<clinit>()`执行前，父类的`<clinit>()`已经执行完毕\n\n### `<init>()` 方法初始化顺序\n\n类的构造器方法是虚拟机视角下的`<init>()`\n\n``` java\npublic class ClinitTest {\n    // 任何一个类声明以后，内部至少存在一个类的构造器\n    private int a = 1;\n    private static int c = 3;\n\n    public static void main(String[] args) {\n        int b = 2;\n    }\n\n    public ClinitTest(){\n        a = 10;\n        int d = 20;\n    }\n}\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/b7186181da1af4d40001c3ca25f8fefb.png)\n\n在构造器中：\n\n- 先将类变量 a 赋值为 10\n- 再将局部变量赋值为 20\n\n\n\n关于涉及到父类时候的变量赋值过程\n\n```java\npublic class ClinitTest1 {\n    static class Father {\n        public static int A = 1;\n        static {\n            A = 2;\n        }\n    }\n\n    static class Son extends Father {\n        public static int b = A;\n    }\n\n    public static void main(String[] args) {\n        System.out.println(Son.b);\n    }\n}\n```\n\n上述代码，加载流程如下：\n\n- 首先，执行 `main()` 方法需要加载 `ClinitTest1 `类\n- 获取 `Son.b` 静态变量，需要加载 `Son` 类\n- `Son `类的父类是 `Father `类，所以需要先执行 `Father `类的加载，再执行 `Son `类的加载\n\n输出结果为 2，也就是说首先加载`ClinitTest1`的时候，会找到`main()`方法，然后执行`Son`的初始化，但是`Son`继承了`Father`，因此还需要执行`Father`的初始化，同时将`A`赋值为2。我们通过反编译得到`Father`的加载过程，首先我们看到原来的值被赋值成1，然后又被复制成2，最后返回\n\n```bash\niconst_1\nputstatic #2 <com/zhao/java/chapter02/ClinitTest1$Father.A>\niconst_2\nputstatic #2 <com/zhao/java/chapter02/ClinitTest1$Father.A>\nreturn\n```\n\n### `<clinit>()` 的线程安全性\n\n对于`<clinit>()`方法的调用，也就是类的初始化，虚拟机会在内部确保其**多线程环境中的安全性**。\n\n虚拟机会保证一个类的`<clinit>()`方法在多线程环境中被正确地加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的`<clinit>()`方法，其他线程都需要阻塞等待，直到活动线程执行`<clinit>()`方法完毕。\n\n因此，如果在一个类的`<clinit>()`方法中有耗时很长的操作，就可能造成多个线程阻塞，引发死锁。并且这种死锁是很难发现的，因为看起来它们并没有可用的锁信息。\n\n如果之前的线程成功加载了类，则等在队列中的线程就没有机会再执行`<clinit>()`方法了。那么，当需要使用这个类时，虚拟机会直接返回给它已经准备好的信息。\n\n代码演示死锁情况：\n\n```java\npublic class DeadThreadTest {\n    public static void main(String[] args) {\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName() + \"\\t 线程t1开始\");\n            new DeadThread();\n        }, \"t1\").start();\n\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName() + \"\\t 线程t2开始\");\n            new DeadThread();\n        }, \"t2\").start();\n    }\n}\n\nclass DeadThread {\n    static {\n        if (true) {\n            System.out.println(Thread.currentThread().getName() + \"\\t 初始化当前类\");\n            while(true) {\n\n            }\n        }\n    }\n}\n```\n\n上面的代码，输出结果为\n\n```\n线程t1开始\n线程t2开始\n线程t2 初始化当前类\n```\n\n程序卡死，分析原因：\n\n- 两个线程同时去加载 `DeadThread `类，而 `DeadThread `类中静态代码块中有一处死循环\n- 先加载 `DeadThread `类的线程抢到了同步锁，然后在类的静态代码块中执行死循环，而另一个线程在等待同步锁的释放\n- 所以无论哪个线程先执行 `DeadThread` 类的加载，另外一个类也不会继续执行\n\n从上面可以看出初始化后，只能够执行一次初始化，这也就是**同步加锁**的过程\n\n### 类的主动使用和被动使用\n\nJava程序对类的使用方式分为：主动使用和被动使用。\n\n#### 主动使用\n\nClass **只有在必须要首次使用的时候才会被加载**，Java虚拟机不会无条件地加载Class类型。即程序启动时并不会立即加载所有Class，而是会等待程序运行到需要使用该类时才会加载该类，但也不是都会执行初始化阶段，而是按需执行：需要用到时再初始化（即主动使用情况），不需要时不初始化。\n\n并且每个类只会被加载一次，第二次使用该类时，不再需要加载初始化，可以直接从方法区中获取该类信息。\n\nJava虚拟机规定，一个类或接口在初次使用前，必须要进行初始化。这里指的“使用”，是指主动使用，即：如果出现如下的情况，则会对类进行初始化操作。而初始化操作之前的加载、验证、准备已经完成。\n\n主动使用有下列七种情况：\n\n- 创建类的实例\n- 访问某个类或接口的静态变量，或者对该静态变量赋值\n- 调用类的静态方法\n- 反射（比如：`Class.forName(\"com.zhao.Test\")`）\n- 初始化一个类的子类\n- Java虚拟机启动时被标明为启动类的类（`main()` 方法所在类）\n- JDK 7开始提供的动态语言支持：\n- `java.lang.invoke.MethodHandle`实例的解析结果REF getStatic、REF putStatic、REF invokeStatic句柄对应的类没有初始化，则初始化\n\n下面逐个举例：\n\n1.  创建类的实例：当创建一个类的实例时，比如使用new关键字，或者通过反射、克隆、反序列化。\n\n\n```java\n/**\n * 反序列化\n */\nClass Order implements Serializable {\n    static {\n        System.out.println(\"Order类的初始化\");\n    }\n}\n\npublic void test() {\n    ObjectOutputStream oos = null;\n    ObjectInputStream ois = null;\n    try {\n        // 序列化\n        oos = new ObjectOutputStream(new FileOutputStream(\"order.dat\"));\n        oos.writeObject(new Order());\n        // 反序列化\n        ois = new ObjectInputStream(new FileOutputStream(\"order.dat\"));\n        Order order = ois.readObject();\n    }\n    catch (IOException e){\n        e.printStackTrace();\n    }\n    catch (ClassNotFoundException e){\n        e.printStackTrace();\n    }\n    finally {\n        try {\n            if (oos != null) {\n                oos.close();\n            }\n            if (ois != null) {\n                ois.close();\n            }\n        }\n        catch (IOException e){\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n2. 静态方法：当调用类的静态方法时，即当使用了字节码 `invokestatic` 指令。 \n3. 静态字段：当使用类、接口的静态字段时（final修饰特殊考虑），比如，使用`getstatic`或者putstatic指令。（对应访问变量、赋值变量操作）  \n\n```java\npublic class ActiveUse {\n    @Test\n    public void test() {\n        System.out.println(User.num);\n    }\n}\n\nclass User {\n    static {\n        System.out.println(\"User类的初始化\");\n    }\n    public static final int num = 1;\n}\n```\n\n4. 反射：当使用`java.lang.reflect`包中的方法反射类的方法时。比如：`Class.forName(\"com.zhao.java.Test\")` \n5. 继承：当初始化子类时，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。  \n\n> 当Java虚拟机初始化一个类时，要求它的所有父类都已经被初始化，但是该规则并不适用于接口\n> - 在初始化一个类时，并不会先初始化它所实现的接口\n> - 在初始化一个接口时，并不会先初始化它的父接口\n> - 因此，一个父接口并不会因为它的子接口或者实现类的初始化而初始化。只有当程序首次使用特定接口的静态字段时，才会导致该接口的初始化。\n\n6. default方法：如果一个接口定义了default方法，那么直接实现或者间接实现该接口的类的初始化，该接口要在其之前被初始化。  \n\n```java\ninterface Compare {\n\tpublic static final Thread t = new Thread() {\n        {\n            System.out.println(\"Compare接口的初始化\");\n        }\n    }   \n}\n```\n\n7. `main()` 方法：当虚拟机启动时，用户需要指定一个要执行的主类（包含`main()`方法的那个类），虚拟机会先初始化这个主类。  \n\n>  JVM启动的时候通过引导类加载器加载一个初始类。这个类在调用`public static void main(String[])` 方法之前被链接和初始化。这个方法的执行将依次导致所需的类的加载，链接和初始化。\n\n8. `MethodHandle`：当初次调用`MethodHandle`实例时，初始化该`MethodHandle`指向的方法所在的类。（涉及解析REF getStatic、REF_putStatic、REF invokeStatic方法句柄对应的类）\n\n#### 被动使用\n\n除了以上几种情况，**其他使用Java类的方式都被看作是对类的被动使用，都不会导致类的 `<clinit>()` 初始化**。**被动使用时，类会被加载，但是不会进行初始化。**\n\n被动使用的举例：\n\n1.  静态字段：当通过子类引用父类的静态变量，不会导致子类初始化，只有真正声明这个字段的类才会被初始化。  \n\n```java\npublic class PassiveUse {\n \t@Test\n    public void test() {\n        System.out.println(Child.num);\n    }\n}\n\nclass Child extends Parent {\n    static {\n        System.out.println(\"Child类的初始化\");\n    }\n}\n\nclass Parent {\n    static {\n        System.out.println(\"Parent类的初始化\");\n    }\n    \n    public static int num = 1;\n}\n```\n\n2. 数组定义：通过数组定义类引用，不会触发此类的初始化  \n\n```java\nParent[] parents= new Parent[10];\nSystem.out.println(parents.getClass()); \n// new的话才会初始化\nparents[0] = new Parent();\n```\n\n3. 引用常量：引用常量不会触发此类或接口的初始化。因为常量在链接阶段就已经被显式赋值了。  \n\n```java\npublic class PassiveUse {\n    public static void main(String[] args) {\n        System.out.println(Serival.num);\n        // 但引用其他类的话还是会初始化\n        System.out.println(Serival.num2);\n    }\n}\n\ninterface Serival {\n    public static final Thread t = new Thread() {\n        {\n            System.out.println(\"Serival初始化\");\n        }\n    };\n\n    public static int num = 10; \n    public static final int num2 = new Random().nextInt(10);\n}\n```\n\n4. 调用`loadClass()` 方法：调用`ClassLoader`某个子类的`loadClass()`方法加载一个类，并不是对类的主动使用，不会导致类的初始化（只会加载，连解析都不一定会执行，除非传入参数要求解析）。  \n\n```java\nClass clazz = ClassLoader.getSystemClassLoader().loadClass(\"com.test.java.Person\");\n```\n\n**扩展**\n\n```\n-XX:+TraceClassLoading：追踪打印类的加载信息\n```\n\n## 卸载阶段\n\n### 类、类的加载器、类的实例之间的引用关系\n\n在类加载器的内部实现中，用一个Java集合来存放所加载类的引用。另一方面，一个Class对象总是会引用它的类加载器，调用Class对象的`getClassLoader()`方法，就能获得它的类加载器。由此可见，代表某个类的Class实例与其类的加载器之间为双向关联关系。\n\n一个类的实例总是引用代表这个类的Class对象。在Object类中定义了`getClass()`方法，这个方法返回代表对象所属类的Class对象的引用。此外，所有的java类都有一个静态属性class，它引用代表这个类的Class对象。\n\n### 类的生命周期\n\n当Sample类被加载、链接和初始化后，它的生命周期就开始了。当代表Sample类的Class对象不再被引用，即不可触及时，Class对象就会结束生命周期，Sample类在方法区内的数据也会被卸载，从而结束Sample类的生命周期。\n\n**一个类何时结束生命周期，取决于代表它的Class对象何时结束生命周期**。\n\n![image-20211014213433097](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211014213433097.png)\n\nloader1变量和obj变量间接应用代表Sample类的Class对象，而objClass变量则直接引用它。\n\n如果程序运行过程中，将上图左侧三个引用变量都置为null，此时Sample对象结束生命周期，MyClassLoader对象结束生命周期，代表Sample类的Class对象也结束生命周期，Sample类在方法区内的二进制数据被卸载。\n\n当再次有需要时，会检查Sample类的Class对象是否存在，如果存在会直接使用，不再重新加载；如果不存在Sample类会被重新加载，在Java虚拟机的堆区会生成一个新的代表Sample类的Class实例（可以通过哈希码查看是否是同一个实例）\n\n### 类的卸载\n\n- 启动类加载器加载的类型在整个运行期间是不可能被卸载的（jvm和jls规范）\n- 被系统类加载器和扩展类加载器加载的类型在运行期间不太可能被卸载，因为系统类加载器实例或者扩展类的实例基本上在整个运行期间总能直接或者间接的访问的到，其达到unreachable的可能性极小。\n- 被开发者自定义的类加载器实例加载的类型只有在很简单的上下文环境中才能被卸载，而且一般还要借助于强制调用虚拟机的垃圾收集功能才可以做到。可以预想，稍微复杂点的应用场景中（比如：很多时候用户在开发自定义类加载器实例的时候采用缓存的策略以提高系统性能），被加载的类型在运行期间也是几乎不太可能被卸载的（至少卸载的时间是不确定的）。\n\n综合以上三点，一个已经加载的类型被卸载的几率很小至少被卸载的时间是不确定的。同时我们可以看的出来，开发者在开发代码时候，不应该对虚拟机的类型卸载做任何假设的前提下，来实现系统中的特定功能。\n\n\n\n## 类加载器\n\n### 类加载的方式\n\n类加载的方式：**显式加载**与**隐式加载**\n\n`.class`文件的显式加载与隐式加载的方式是指**JVM加载`.class`文件到内存的方式**。\n\n- 显式加载指的是在代码中通过调用ClassLoader加载class对象，如直接使用`Class.forName(name)`或`this.getClass().getClassLoader().loadClass()`加载Class对象。\n- 隐式加载则是不直接在代码中调用ClassLoader的方法加载class对象，而是通过虚拟机自动加载到内存中，如在加载某个类的`.class`文件时，该类的`.class`文件中引用了另外一个类的对象，此时额外引用的类将通过JVM自动加载到内存中。\n\n在日常开发以上两种方式一般会混合使用。\n\n```java\n//隐式加载\nUser user=new User();\n\n//显式加载，并初始化\nClass clazz = Class.forName(\"com.test.java.User\");\n//显式加载，但不初始化\nClassLoader.getSystemClassLoader().loadClass(\"com.test.java.Parent\");\n```\n\n`Class.forName(name)`与`this.getClass().getClassLoader().loadClass()`加载Class对象的区别：\n\n- `Class.forName()`：是一个**静态方法**，最常用的是`Class.forName(String className);` 。其根据传入的类的全限定名返回一个Class对象。该方法在将Class文件加载到内存的同时，**会执行类的初始化**。\n-  `ClassLoader.loadClass()`：这是一个**实例方法**，需要一个ClassLoader对象来调用该方法。  该方法将Class文件加载到内存时，**并不会执行类的初始化（默认情况下解析阶段也不会执行）**，**直到这个类第一次使用时才进行初始化**（见后文源码分析，`loadClass()` 方法并没有初始化阶段的代码）。该方法因为需要得到一个ClassLoader对象，所以**可以根据需要指定使用哪个类加载器**。 \n\n\n\n### 类加载器的必要性\n\n一般情况下，Java开发人员并不需要在程序中显式地使用类加载器，但是了解类加载器的加载机制却显得至关重要。从以下几个方面说：\n\n- 避免在开发中遇到`java.lang.ClassNotFoundException`异常或`java.lang.NoClassDefFoundError`异常时，手足无措。只有了解类加载器的加载机制才能够在出现异常的时候快速地根据错误异常日志定位问题和解决问题\n- 需要支持类的动态加载或需要对编译后的字节码文件进行加解密操作时，就需要与类加载器打交道了。\n- 开发人员可以在程序中编写自定义类加载器来重新定义类的加载规则，以便实现一些自定义的处理逻辑。\n\n### 命名空间\n\n**何为类的唯一性？**\n\n对于任意一个类，都需要由加载它的类加载器和这个类本身一同确认其在Java虚拟机中的唯一性。**每一个类加载器都拥有一个独立的类名称空间**。不同类加载器间的命名空间不同，相互不干扰。\n\n**比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义**。否则，即使这两个类源自同一个Class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那这两个类就必定不相等。\n\n**命名空间**\n\n-  每个类加载器都有自己的命名空间，命名空间由该加载器及所有的父加载器所加载的类组成 \n-  在同一命名空间中，不会出现类的完整名字（包括类的包名）相同的两个类 \n-  在不同的命名空间中，有可能会出现类的完整名字（包括类的包名）相同的两个类 \n\n在大型应用中，我们往往借助这一特性，来运行**同一个类的不同版本**。\n\n\n\n### 类加载器的分类\n\nJVM支持两种类型的类加载器 。分别为**引导类加载器**（Bootstrap ClassLoader）和**自定义类加载器**（User-Defined ClassLoader）。\n\n从概念上来讲，自定义类加载器一般指的是程序中由开发人员自定义的一类类加载器，但是Java虚拟机规范却没有这么定义，而是将**所有派生于抽象类ClassLoader的类加载器都划分为自定义类加载器**。除了**引导类加载器**，其他类加载器都集成自抽象类`ClassLoader`，因此都属于自定义类加载器。\n\n> 启动类加载器通过C/C++语言编写，而自定义类加载器都是由Java语言编写的，虽然扩展类加载器和应用程序类加载器是被JDK开发人员使用java语言来编写的，但是也是由java语言编写的，所以也被称为自定义类加载器。**自定义类型加载器是由引导类加载器所加载的**，在JVM启动时，引导类加载器加载并调用Launcher类，创建出自定义类型加载器，**并创建一个单独的Launcher线程**。\n\n无论类加载器的类型如何划分，在程序中我们最常见的类加载器始终只有3个，如下所示：\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/9d1ee398a719d8c95024a6311be0d4d6.png)\n\n这里的四者之间是**包含关系**，不是上层和下层，也不是子系统的继承关系。正是由于子类加载器中包含着父类加载器的引用，所以可以通过子类加载器的方法获取对应的父类加载器，这也是双亲委派机制实现的基础。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201120104448.png)\n\n我们通过一个类，获取它不同的加载器：\n\n```java\npublic class ClassLoaderTest {\n    public static void main(String[] args) {\n        // 获取系统类加载器\n        ClassLoader systemClassLoader = ClassLoader.getSystemClassLoader();\n        System.out.println(systemClassLoader);\n\n        // 获取其上层的：扩展类加载器\n        ClassLoader extClassLoader = systemClassLoader.getParent();\n        System.out.println(extClassLoader);\n\n        // 试图获取 根加载器\n        ClassLoader bootstrapClassLoader = extClassLoader.getParent();\n        System.out.println(bootstrapClassLoader);\n\n        // 获取自定义加载器\n        ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();\n        System.out.println(classLoader);\n\n        // 获取String类型的加载器\n        ClassLoader classLoader1 = String.class.getClassLoader();\n        System.out.println(classLoader1);\n    }\n}\n```\n\n得到的结果，从结果可以看出**根加载器无法直接通过代码获取**，同时目前用户代码所使用的加载器为**系统类加载器**。同时我们通过获取`String`类型的加载器，发现是`null`，那么说明`String`类型是通过根加载器进行加载的，也就是说Java的核心类库都是使用根加载器进行加载的。\n\n```\nsun.misc.Launcher$AppClassLoader@18b4aac2\nsun.misc.Launcher$ExtClassLoader@1540e19d\nnull\nsun.misc.Launcher$AppClassLoader@18b4aac2\nnull \n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/d47503a1999253a84256a94887e5cb79.png)\n\n**说明：**\n\n- 站在程序的角度看，引导类加载器与另外两种类加载器（系统类加载器和扩展类加载器）并不是同一个层次意义上的加载器，引导类加载器是使用C++语言编写而成的，而另外两种类加载器则是使用Java语言编写而成的。由于引导类加载器压根儿就不是一个Java类，因此在Java程序中只能打印出空值。\n- 数组类的Class对象，不是由类加载器去创建的，而是在Java运行期JVM根据需要自动创建的。对于数组类的类加载器来说，是通过`Class.getClassLoader()`返回的，与数组当中元素类型的类加载器是一样的；如果数组当中的元素类型是基本数据类型，数组类是没有类加载器的。\n\n### 启动类加载器（引导类加载器，Bootstrap ClassLoader）\n\n- 这个类加载使用**C/C++语言实现**的，嵌套在JVM内部。\n- 它用来加载Java的核心库（`JAVAHOME/jre/1ib/rt.jar`、`resources.jar`或`sun.boot.class.path`路径下的内容），用于提供JVM自身需要的类\n- 并不继承自`java.lang.ClassLoader`，没有父加载器。\n- 加载扩展类和应用程序类加载器，并指定为他们的父类加载器。\n- 出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类\n\n### 扩展类加载器（Extension ClassLoader）\n\n- **Java语言编写**，由`sun.misc.Launcher$ExtClassLoader`实现，是Launcher类的**内部类**。\n- 派生于`ClassLoader`类\n- 用于加载Java后期版本不断扩展出的类\n- 父类加载器为启动类加载器\n- 从`java.ext.dirs`系统属性所指定的目录中加载类库，或从JDK的安装目录的`jre/lib/ext`子目录（扩展目录）下加载类库。如果用户创建的JAR放在此目录下，也会自动由扩展类加载器加载。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/aHR0cDovL2hleWdvLm9zcy1jbi1zaGFuZ2hhaS5hbGl5dW5jcy5jb20vaW1hZ2VzL2ltYWdlLTIwMjAwNzI3MTcwODM3NTM4LnBuZw)\n\n### 应用程序类加载器（系统类加载器，AppClassLoader）\n\n- **Java语言**编写，由`sun.misc.Launchers$AppClassLoader`实现，是Launcher类的内部类\n- 派生于`ClassLoader`类\n- 父类加载器为扩展类加载器\n- 它负责加载环境变量`classpath`或系统属性`java.class.path`指定路径下的类库（用户自定义的类都由该加载器加载）\n- 该类加载是程序中**默认的类加载器**，一般来说，Java应用的类都是由它来完成加载\n- 通过`classLoader#getSystemclassLoader()`方法可以获取到该类加载器\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/aHR0cDovL2hleWdvLm9zcy1jbi1zaGFuZ2hhaS5hbGl5dW5jcy5jb20vaW1hZ2VzL2ltYWdlLTIwMjAwNzI3MTcwOTE4MDM3LnBuZw)\n\n### 用户自定义类加载器\n\n**用户自定义的类加载器的父类加载器`parent`是 AppClassLoader**，见下图：\n\n![image-20211015211158127](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211015211158127.png)\n\n在Java的日常应用程序开发中，类的加载几乎是由上述3种类加载器相互配合执行的，在必要时，我们还可以自定义类加载器，来定制类的加载方式。\n\n为什么要自定义类加载器？\n\n- 隔离加载类\n- 修改类加载的方式\n- 扩展加载源\n- 防止源码泄漏\n\n体现Java语言强大生命力和巨大魅力的关键因素之一便是，Java开发者可以自定义类加载器来实现类库的动态加载，加载源可以是本地的JAR包，也可以是网络上的远程资源。\n\n通过类加载器可以实现非常绝妙的**插件机制**，这方面的实际应用案例举不胜举。例如，著名的OSGI组件框架，再如Eclipse的插件机制。类加载器为应用程序提供了一种**动态增加新功能的机制**，这种机制无须重新打包发布应用程序就能实现。\n\n同时，自定义加载器能够实现**应用隔离**。例如Tomcat，Spring等中间件和组件框架都在内部实现了自定义的加载器，并通过自定义加载器隔离不同的组件模块。这种机制比C/C\\+\\+程序要好太多，想不修改C/C\\+\\+程序就能为其新增功能，几乎是不可能的，仅仅一个兼容性便能阻挡住所有美好的设想。\n\n自定义类加载器通常需要继承于`ClassLoader`。用户自定义类加载器实现步骤：\n\n- 开发人员可以通过继承抽象类`java.lang.ClassLoader`类的方式，实现自己的类加载器，以满足一些特殊的需求\n- 在JDK1.2之前，在自定义类加载器时，总会去继承`ClassLoader`类并重写`loadClass()`方法，从而实现自定义的类加载类，但是在JDK1.2之后已不再建议用户去覆盖`loadClass()`方法，而是建议把自定义的类加载逻辑写在`findClass()`方法中，这样就不会破坏默认`loadClass()`方法里的双亲委派机制逻辑。\n- 在编写自定义类加载器时，如果没有太过于复杂的需求，**可以直接继承`URIClassLoader`类**，这样就可以避免自己去编写`findClass()`方法及其获取字节码流的方式，使自定义类加载器编写更加简洁。\n\n``` java\npublic class CustomClassLoader extends ClassLoader {\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n\n        try {\n            byte[] result = getClassFromCustomPath(name);\n            if (result == null) {\n                throw new FileNotFoundException();\n            } else {\n                //defineClass和findClass搭配使用\n                return defineClass(name, result, 0, result.length);\n            }\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        }\n\n        throw new ClassNotFoundException(name);\n    }\n    \n    //自定义流的获取方式\n    private byte[] getClassFromCustomPath(String name) {\n        //从自定义路径中加载指定类:细节略\n        //如果指定路径的字节码文件进行了加密，则需要在此方法中进行解密操作。\n        return null;\n    }\n\n    public static void main(String[] args) {\n        CustomClassLoader customClassLoader = new CustomClassLoader();\n        try {\n            Class<?> clazz = Class.forName(\"One\", true, customClassLoader);\n            Object obj = clazz.newInstance();\n            System.out.println(obj.getClass().getClassLoader());\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n\n\n### 查看根加载器所能加载的目录\n\n根加载器只能够加载 `java/lib`目录下的class，我们通过下面代码验证一下\n\n```java\npublic class ClassLoaderTest1 {\n    public static void main(String[] args) {\n        System.out.println(\"*********启动类加载器************\");\n        // 获取BootstrapClassLoader 能够加载的API的路径\n        URL[] urls = sun.misc.Launcher.getBootstrapClassPath().getURLs();\n        for (URL url : urls) {\n            System.out.println(url.toExternalForm());\n        }\n\n        // 从上面路径中，随意选择一个类，来看看他的类加载器是什么：得到的是null，说明是  根加载器\n        ClassLoader classLoader = Provider.class.getClassLoader();\n    }\n}\n```\n\n得到的结果\n\n```\n*********启动类加载器************\nfile:/E:/Software/JDK1.8/Java/jre/lib/resources.jar\nfile:/E:/Software/JDK1.8/Java/jre/lib/rt.jar\nfile:/E:/Software/JDK1.8/Java/jre/lib/sunrsasign.jar\nfile:/E:/Software/JDK1.8/Java/jre/lib/jsse.jar\nfile:/E:/Software/JDK1.8/Java/jre/lib/jce.jar\nfile:/E:/Software/JDK1.8/Java/jre/lib/charsets.jar\nfile:/E:/Software/JDK1.8/Java/jre/lib/jfr.jar\nfile:/E:/Software/JDK1.8/Java/jre/classes\nnull\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/d47503a1999253a84256a94887e5cb79.png)\n\n## ClassLoader 源码解析\n\n### 关于 ClassLoader\n\n`ClassLoader`类，它是一个**抽象类**，其后所有的类加载器都继承自`ClassLoader`（不包括启动类加载器）\n\n![image-20200705103516138](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705103516138-1632294600690.png)\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201120104448.png)\n\n其中，`ExtClassLoader` 和 `AppClassLoader` 都是`sun.misc.Launcher` 类的**内部类**。\n\n### Launcher\n\n`sun.misc.Launcher` 是Java虚拟机的入口应用（启动器），由该类负责设置当前程序的系统类加载器：\n\n![image-20211015145906637](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211015145906637.png)\n\n其中，创建扩展类加载器的细节：\n\n![image-20211015145400761](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211015145400761.png)\n\n获取`ClassLoader`的途径：\n\n- 获取当前`ClassLoader`：`clazz.getClassLoader()`（每个Class对象都保存有加载其的类加载器对象）\n- 获取当前线程上下文的`ClassLoader`：`Thread.currentThread().getContextClassLoader()`\n- 获取系统的`ClassLoader`：`ClassLoader.getSystemClassLoader()`\n- 获取调用者的`ClassLoader`：`DriverManager.getCallerClassLoader()`\n\n除了以上虚拟机自带的加载器外，用户还可以定制自己的类加载器。Java提供了抽象类`java.lang.ClassLoader`，所有用户自定义的类加载器都应该继承`ClassLoader`类。\n\n### loadClass() 源码\n\n当调用类加载器主动加载类时：`this.getClass().getClassLoader().loadClass()`，将经过以下过程：\n\n- `findLoadedClass(name)`：先在当前加载器的缓存中查找有无目标类，如果有，直接返回。\n- `loadClass(name)`：首先基于双亲委派机制，不断向上找父类加载器看是否能加载该类，一直找到引导类加载器；\n- 如果父类不能加载，则尝试调用当前类加载器的 `findClass(name)` 方法进行加载\n-  `findClass(name)` 方法内将调用 `defineClass(name, res)` 方法（底层调用 native 本地方法），根据传入的类名称 `name` 和二进制流 `res` 将目标类进行加载，为其创建一个 Class 类型对象\n- 此时才完成了类的加载阶段，但是注意还没有进行链接阶段和初始化阶段\n- 如果 `loadClass(name, resolve)` 方法传入了参数 `resolve == true`，则将进行链接阶段：`resolveClass(c)`\n- `loadClass()` 方法并没有初始化阶段的代码，说明用这种方式加载类是不会初始化的，只有等到该类第一次被调用时才会执行`<clinit>()`初始化（区别于 `Class.forName(name)` 方式，该方式是会初始化的）。\n\n![image-20211015152354574](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211015152354574.png)\n\n `findClass(name)` 类由 `URLClassLoader`重写，在其内调用 `defineClass(name, res)` 真正进行加载Class。该方法由 `protected` 修饰，说明是被保护的，只能由其子类调用，外部程序无法访问该方法，这是JVM的一种类加载**保护机制**。\n\n![image-20211015152829587](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211015152829587.png)\n\n在 `defineClass(name, res)` 方法内，将根据传入的类名称 `name` 和二进制流 `res` 将目标类进行加载，为其创建一个 Class 类型对象，至此才即完成了类的加载，但是还没解析和初始化。\n\n开发人员可以自定义类加载器继承`URIClassLoader`类，重写 `findClass()` 方法，在内编写自定义的加载流程，例如加密解密，但是必须最后在其内调用 `defineClass()` 方法加载类。\n\n**注意不要重写 `loadClass()` 方法，因为开发人员自定义的 `loadClass()` 方法可能会破坏双亲委派机制**。\n\n\n\n## 双亲委派模型\n\nJava虚拟机对`.class`文件采用的是按需加载的方式，也就是说当需要使用该类时才会将它的`.class`文件加载到内存生成`Class`对象。而且加载某个类的`.class`文件时，Java虚拟机采用的是双亲委派模式，即把请求交由父类处理，它是一种任务委派模式。\n\n但不是所有类加载都遵守这个模型，有的时候，启动类加载器所加载的类型，是可能要加载用户代码的，比如JDK内部的ServiceProvider/ServiceLoader机制，用户可以在标准API框架上，提供自己的实现，JDK也需要提供些默认的参考实现。例如，Java中JNDI、JDBC、文件系统、Cipher等很多方面，都是利用的这种机制，这种情况就不会用双亲委派模型去加载，而是利用所谓的上下文加载器。\n\n- **可见性**，子类加载器可以访问父加载器加载的类型，但是反过来是不允许的。不然，因为缺少必要的隔离，我们就没有办法利用类加载器去实现容器的逻辑。\n- **单一性**，由于父加载器的类型对于子加载器是可见的，所以父加载器中加载过的类型，就不会在子加载器中重复加载。但是注意，类加载器“邻居”间，同一类型仍然可以被加载多次，因为互相并不可见。\n\n### 工作原理\n\n- 如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行；\n- 如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器；\n- 如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。\n\n![image-20200705105151258](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705105151258-1632294600690.png)\n\n### 源码支持\n\n![image-20211015152354574](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211015152354574.png)\n\n双亲委派机制在`java.lang.ClassLoader.loadClass(String, boolean)`接口中体现。该接口的逻辑如下：\n\n- 先在当前加载器的缓存中查找有无目标类，如果有，直接返回。\n- 判断当前加载器的父加载器是否为空，如果不为空，则调用`parent.loadClass(name, false)`接口进行加载。\n- 反之，如果当前加载器的父类加载器为空，则调用`findBootstrapClassorNull(name)`接口，让引导类加载器进行加载。\n- 如果通过以上3条路径都没能成功加载，则调用`findClass(name)`接口进行加载。该接口最终会调用`java.lang.ClassLoader`接口的`defineClass()`系列的native接口加载目标Java类。\n\n双亲委派的模型就隐藏在这第2和第3步中。\n\n**举例**\n\n假设当前加载的是`java.lang.Object`这个类，很显然，该类属于JDK中核心得不能再核心的一个类，因此一定只能由引导类加载器进行加载。当]VM准备加载`java.lang.Object`时，JVM默认会使用系统类加载器去加载，按照上面4步加载的逻辑，在第1步从系统类的缓存中肯定查找不到该类，于是进入第2步。由于从系统类加载器的父加载器是扩展类加载器，于是扩展类加载器继续从第1步开始重复。由于扩展类加载器的缓存中也一定查找不到该类，因此进入第2步。扩展类的父加载器是null，因此系统调用`findClass(String)`，最终通过引导类加载器进行加载。\n\n---\n\n如果在自定义的类加载器中重写`java.lang.ClassLoader.loadClass(String)`或`java.lang.ClassLoader.loadclass(String, boolean)`方法，抹去其中的双亲委派机制，仅保留上面这4步中的第l步与第4步，那么是不是就能够加载核心类库了呢？\n\n这也不行！因为JDK还为核心类库提供了一层**保护机制**。不管是自定义的类加载器，还是系统类加载器亦或扩展类加载器，最终都必须调用 `java.lang.ClassLoader.defineclass(String, byte[], int, int, ProtectionDomain)`方法，而该方法会执行`preDefineClass()`接口，该接口中**提供了对JDK核心类库的保护**。\n\n---\n\n### 双亲委派模型的优势\n\n双亲机制可以：\n\n- 避免类的重复加载\n- 保护程序安全，防止核心API被随意篡改\n  - 自定义类：`java.lang.String`\n  - 自定义类：`java.lang.ShkStart`（报错：阻止创建 `java.lang` 开头的类）\n\n### 双亲委派模型的弊端\n\n检查类是否加载的委托过程是单向的，这个方式虽然从结构上说比较清晰，使各个ClassLoader的职责非常明确，但是同时会带来一个问题，即**顶层的ClassLoader无法访问底层的ClassLoader所加载的类**。\n\n通常情况下，引导类加载器加载的类为系统核心类，包括一些重要的系统接口，而系统类加载器加载的为应用类。按照这种模式，应用类访问系统类自然是没有问题，但是**系统类访问应用类就会出现问题**。比如在系统类中提供了一个接口，**该接口需要在应用类中得以实现，该接口还绑定一个工厂方法，用于创建该接口的实例，而接口和工厂方法都在启动类加载器中**（例如JDBC）。这时，就会出现该工厂方法无法创建由应用类加载器加载的应用实例的问题。（引导类加载器向加载该类时，发现接口实现方法和工厂方法都在必须由系统类加载器加载，自己无法加载）\n\n> 总结上面的情况：引导类加载器负责加载比较基础的类，但如果有时这些比较基础的类又要回调回其子类实现的方法（用户的代码），则由于双亲委派模型的限制，无法处理这种情况\n\n一个典型的例子便是[JNDI服务](https://www.cnblogs.com/study-everyday/p/6723313.html)（Java Naming and Directory Interface，**命名与目录接口**），JNDI现在已经是Java的标准服务，它的代码由启动类加载器来完成加载（在JDK 1.3时加入到`rt.jar`的），肯定属于Java中很基础的类型了。\n\n> https://jiges.github.io/2017/12/08/JNDI%E6%98%AF%E4%BB%80%E4%B9%88/ ，https://blog.csdn.net/wanxiaoderen/article/details/106638603\n\n但**JNDI存在的目的就是对资源进行查找和集中管理**，它需要调用由其他厂商实现并部署在应用程序的`ClassPath`下的JNDI**服务提供者接口**（Service Provider Interface，SPI）的代码。现在问题来了，启动类加载器是绝不可能认识、加载这些代码的（SPI：在Java平台中，通常把核心类`rt.jar`中提供外部服务、可由应用层自行实现的接口称为SPI，例如JDBC）。\n\n解决方案：使用**上下文类加载管理器。JNDI服务使用这个线程上下文类加载器去加载所需的SPI服务代码**\n\n![image-20211018103731245](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018103731245.png)\n\n> 上图中rt.jar中有要实现的SPI核心类的基础接口，在加载它的接口时需要调用实现类中的方法，但引导类加载器无法加载其实现类，只能交给线程上下文类加载器。\n\n**结论**\n\n**Java虚拟机规范并没有明确要求类加载器的加载机制一定要使用双亲委派模型，只是建议采用这种方式而已**。比如在Tomcat中，类加载器所采用的加载机制就和传统的双亲委派模型有一定区别，当缺省的类加载器接收到一个类的加载任务时，首先会由它自行加载，当它加载失败时，才会将类的加载任务委派给它的超类加载器去执行，这同时也是Servlet规范推荐的一种做法。\n\n### 破坏双亲委派机制\n\n双亲委派模型并不是一个具有强制性约束的模型，而是Java设计者推荐给开发者们的类加载器实现方式。\n\n在Java的世界中大部分的类加载器都遵循这个模型，但也有例外的情况，直到**Java模块化**出现为止，双亲委派模型主要出现过3次较大规模“被破坏”的情况。\n\n#### 第一次破坏双亲委派机制：重写 loadClass() 方法\n\n双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前一——即JDK1.2面世以前的“远古”时代。\n\n由于双亲委派模型在JDK 1.2之后才被引入，但是类加载器的概念和抽象类`java.lang.ClassLoader`则在Java的第一个版本中就已经存在，面对经存在的用户自定义类加载器的代码，Java设计者们引入双亲委派模型时不得不做出一些妥协，**为了兼容这些已有代码，无法再以技术手段避免loadClass()被子类覆盖的可能性**，只能在JDK1.2之后的`java.lang.ClassLoader`中添加一个新的protected方法`findClass()`，并引导用户编写的类加载逻辑时尽可能去重写这个方法，而不是在`loadClass()`中编写代码。\n\n上文我们已经分析过`loadClass()`方法，双亲委派的具体逻辑就实现在这里面，按照`loadClass()`方法的逻辑，如果父类加载失败，会自动调用自己的`findClass()`方法来完成加载，这样既不影响用户按照自己的意愿去加载类，又可以保证新写出来的类加载器是符合双亲委派规则的。\n\n#### 第二次破坏双亲委派机制：线程上下文类加载器\n\n双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷导致的，双亲委派很好地解决了各个类加载器协作时基础类型的一致性问题（越基础的类由越上层的类加载器加载），基础类型之所以被称为“基础”，是因为它们总是作为被用户代码继承、调用的API存在，但程序设计往往没有绝对不变的完美规则，如果有基础的类又要回调回其子类实现的方法（用户的代码），该怎么办呢？\n\n一个典型的例子便是[JNDI服务](https://www.cnblogs.com/study-everyday/p/6723313.html)（Java Naming and Directory Interface，**命名与目录接口**），JNDI现在已经是Java的标准服务，它的代码由启动类加载器来完成加载（在JDK 1.3时加入到`rt.jar`的），肯定属于Java中很基础的类型了。但**JNDI存在的目的就是对资源进行查找和集中管理**，它需要调用由其他厂商实现并部署在应用程序的`ClassPath`下的JNDI**服务提供者接口**（Service Provider Interface，SPI）的代码。现在问题来了，启动类加载器是绝不可能认识、加载这些代码的（SPI：在Java平台中，通常把核心类`rt.jar`中提供外部服务、可由应用层自行实现的接口称为SPI，例如JDBC）。\n\n为了解决这个困境，Java的设计团队只好引入了一个不太优雅的设计：线程上下文类加载器（`ThreadContextClassLoader`）。这个类加载器可以通过`java.lang.Thread`类的`setContextClassLoader()`方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器**默认就是应用程序类加载器**。\n\n有了线程上下文类加载器，程序就可以做一些“舞弊”的事情了。**JNDI服务使用这个线程上下文类加载器去加载所需的SPI服务代码**，**这是一种父类加载器去请求子类加载器完成类加载的行为，这种行为实际上是打通了双亲委派模型的层次结构来逆向使用类加载器，已经违背了双亲委派模型的一般性原则**。但这也是无可奈何的事情。 例如JNDI、JDBC、JCE、JAXB和JBI等。不过，当SPI的服务提供者多于一个的时候，代码就只能根据具体提供者的类型来硬编码判断，为了消除这种极不优雅的实现方式，在JDK6时，JDK提供了`java.util.ServiceLoader`类，以`META-INF/services`中的配置信息，辅以**责任链模式**（类似于Spring Boot里的自动配置原理），这才算是给SPI的加载提供了一种相对合理的解决方案。\n\n![image-20211018103725540](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018103725540.png)\n\n默认上下文加载器就是应用类加载器，这样以上下文加载器为中介，使得启动类加载器中的代码也可以访问应用类加载器中的类。\n\n#### 第三次破坏双亲委派机制：代码热替换\n\n双亲委派模型的第三次“被破坏”是由于用户对**程序动态性**的追求而导致的。如：**代码热替换(Hot Swap)、模块热部署(Hot Deployment)**等（即修改了本地`.class`文件后，程序可以热修改，无需重新启动加载）\n\nIBM公司主导的JSR-291（即OSGiR4.2）实现模块化热部署的关键是**它自定义的类加载器机制的实现**，**每一个程序模块（OSGi中称为Bundle）都有一个自己的类加载器，当需要更换一个Bundle时，就把Bundle连同类加载器一起换掉以实现代码的热替换**。**在OSGi环境下，类加载器不再双亲委派模型推荐的树状结构，而是进一步发展为更加复杂的网状结构**。\n\n当收到类加载请求时，OSGi将按照下面的顺序进行类搜索：\n\n- **将以 `java.*` 开头的类委派给父类加载器加载**\n- **否则，将委派列表名单内的类给父类加载器加载**\n- 否则，将Import列表中的类，委派给Export这个类的Bundle的类加载器加载\n- 否则，查找当前Bundle的ClassPath，使用自己的类加载器加载。\n- 否则，查找类是否在自己的Fragment Bundle中，如果在，则委派给Fragment Bundle的类加载器加载\n- 否则，查找Dynamic Import列表的Bundle，委派给对应Bund1e的类加载器加载。\n- 否则，类查找失败。\n\n说明：只有开头两点仍然符合双亲委派模型的原则，**其余的类查找都是在平级的类加载器中进行的**\n\n**小结**：这里，我们使用了“被破坏”这个词来形容上述不符合双亲委派模型原则的行为，但这里“被破坏”并不一定是带有贬义的。只要有明确的目的和充分的理由，突破旧有原则无疑是一种创新。\n\n正如：OSGi中的类加载器的设计不符合传统的双亲委派的类加载器架构，且业界对其为了实现热部署而带来的额外的高复杂度还存在不少争议，但对这方面有了解的技术人员基本还是能达成一个共识，认为**OSGi中对类加载器的运用是值得学习的，完全弄懂了OSGi的实现，就算是掌握了类加载器的精粹。**\n\n### 热替换的实现\n\n热替换是指在程序的运行过程中，不停止服务，只通过替换程序文件来修改程序的行为。**热替换的关键需求在于服务不能中断，修改必须立即表现在正在运行的系统之中**。基本上大部分**脚本语言**都是天生支持热替换的，比如：PHP，只要替换了PHP源文件，这种改动就会立即生效，而无需重启Web服务器。\n\n但对Java来说，热替换并非天生就支持，如果一个类已经加载到系统中，通过修改类文件，并无法让系统再来加载并重定义这个类。因此，在Java中实现这一功能的一个可行的方法就是灵活运用ClassLoader。\n\n注意：由不同ClassLoader加载的同名类属于不同的类型，不能相互转换和兼容。即两个不同的ClassLoader加载同一个类，在虚拟机内部，会认为这2个类是完全不同的。根据这个特点，可以用来模拟热替换的实现，基本思路如下图所示：\n\n![image-20211018103711336](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018103711336.png)\n\n因为每次热替换时都创建了新的自定义 ClassLoader 实例，所以其加载的类都是不同的，就可以实现热替换的效果。\n\n\n\n### 双亲委派机制举例\n\n示例一：我们自己定义一个`java.lang`包，在其下面定义一个`String`类，里面声明了静态代码块\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/20201120145148.png)\n\n``` java\npackage java.lang;\n\npublic class String {\n\n    static {\n        System.out.println(\"我是自定义的String类的静态代码块\");\n    }\n}\n```\n\n在一个测试类中加载String类，看看加载的String类是JDK自带的，还是我们自己编写的\n\n``` java\npublic class StringTest {\n    public static void main(String[] args) {\n        String str = new java.lang.String();\n        System.out.println(\"你好，世界\");\n    }\n}\n```\n\n结果：程序并没有输出我们静态代码块中的内容，可见仍然加载的是 JDK 自带的 `String `类\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/34e48ebaa5bd451522c8039215636172.png)\n\n示例二：在我们自己定义的 String 类中整个 `main()` 方法\n\n``` java\npublic class String {\n\n    static {\n        System.out.println(\"我是自定义的String类的静态代码块\");\n    }\n\n    //错误: 在类 java.lang.String 中找不到 main 方法\n    public static void main(String[] args) {\n        System.out.println(\"hello,String\");\n    }\n}\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/4afef5f16208076b038a6194447dcadb.png)\n\n原因：由于双亲委派机制，我们的`String`类是由引导类加载器加载的，而引导类加载器并没有`main()`方法，所以会报错。\n\n示例三：当我们加载 `jdbc.jar` 用于实现数据库连接的时候，首先我们需要知道的是 `jdbc.jar` 是基于SPI接口进行实现的，所以在加载的时候，**会进行双亲委派，最终从根加载器中加载SPI核心类，然后在加载SPI接口类，接着在进行反向委派，通过线程上下文类加载器进行实现类 `jdbc.jar` 的加载**。\n\n![image-20200705105810107](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20200705105810107-1632294600691.png)\n\n示例四：在`java.lang`包下自定义类，发现出于保护机制，不允许我们自定义类。\n\n``` java\npackage java.lang;\n\npublic class ShkStart {\n    public static void main(String[] args) {\n        System.out.println(\"hello!\");\n    }\n}\n```\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/61a081a966f66450d67c9615f11671a3.png)\n\n\n\n\n\n## 沙箱安全机制\n\n自定义`String`类，但是在加载自定义`String`类的时候会率先使用引导类加载器加载，而引导类加载器在加载的过程中会先加载jdk自带的文件（`rt.jar`包中`java\\lang\\String.class`），报错信息说没有`main()`方法，就是因为加载的是`rt.jar`包中的`String`类。\n\n这样**可以保证对java核心源代码的保护**，这就是沙箱安全机制。\n\n沙箱安全机制：\n\n- **保证程序安全**\n- **保护Java原生的JDK代码**\n\n**Java安全模型的核心就是Java沙箱**（sandbox）。什么是沙箱？**沙箱是一个限制程序运行的环境**。\n\n沙箱机制就是**将Java代码限定在虚拟机特定的运行范围内，并且严格限制代码对本地系统资源访问**。通过这样的措施来保证对代码的有限隔离，防止对本地系统造成破坏。\n\n沙箱主要限制系统资源访问，那系统资源包括什么？CPU、内存、文件系统、网络。不同级别的沙箱对这些资源访问的限制也可以不一样。所有的Java程序运行都可以指定沙箱，可以定制安全策略。\n\n###  JDK 1.0 时期\n\n在Java中将执行程序分成本地代码和远程代码两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码，可以访问一切本地资源。而对于非授信的远程代码在早期的Java实现中，安全依赖于**沙箱（Sandbox）机制**。如下图所示JDK 1.0安全模型：\n\n![image-20211018104311131](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018104311131.png)\n\n### JDK 1.1 时期\n\nJDK 1.0中如此严格的安全机制也给程序的功能扩展带来障碍，比如当用户希望远程代码访问本地系统的文件时候，就无法实现。\n\n因此在后续的JDK 1.1版本中，针对安全机制做了改进，增加了**安全策略**。允许用户指定代码对本地资源的访问权限。如下图所示JDK1.1安全模型\n\n![image-20211018104404224](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018104404224.png)\n\n### JDK 1.2 时期\n\n在JDK 1.2版本中，再次改进了安全机制，增加了**代码签名**。**不论本地代码或是远程代码，都会按照用户的安全策略设定**，由类加载器加载到虚拟机中权限不同的运行空间，来实现差异化的代码执行权限控制。如下图所示JDK1.2安全模型：\n\n![image-20211018104435405](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018104435405.png)\n\n### JDK 1.6 时期\n\n当前最新的安全机制实现，则引入了**域（Domain）**的概念。\n\n虚拟机会把所有代码加载到不同的系统域和应用域。**系统域部分专门负责与关键资源进行交互**，而各个应用域部分则通过系统域的部分代理来对各种需要的资源进行访问。虚拟机中不同的受保护域（Protected Domain），对应不一样的权限（Permission）。\n\n> 思想类似于操作系统里的核心态和用户态，用户态想访问系统资源时必须转为核心态\n\n存在于不同域中的类文件就具有了当前域的全部权限，如下图所示，最新的安全模型：\n\n![image-20211018104641337](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018104641337.png)\n\n## 自定义类的加载器\n\n### 为什么要自定义类加载器？\n\n- **隔离加载类**：在某些框架内进行中间件与应用的模块隔离，把类加载到不同的环境。比如：阿里内某容器框架通过自定义类加载器确保应用中依赖的jar包不会影响到中间件运行时使用的jar包。再比如：**Tomcat这类Web应用服务器，内部自定义了好几种类加载器，用于隔离同一个Web应用服务器上的不同应用程序**。 \n- **修改类加载方式**：类的加载模型并非强制，除Bootstrap外，其他的加载并非一定要引入，或者根据实际情况在某个时间点进行按需进行动态加载 \n- **扩展加载源**：比如从数据库、网络、甚至是电视机机顶盒进行加载 \n- **防止源码泄漏**：Java代码容易被编译和篡改，可以进行**编译加密**。那么类加载也需要自定义，**还原加密的字节码**。 \n\n**常见的场景**\n\n- 实现类似进程内隔离，类加载器实际上用作不同的命名空间，以提供类似容器、模块化的效果。例如，两个模块依赖于某个类库的不同版本，如果分别被不同的容器加载，就可以互不干扰。这个方面的集大成者是JavaEE和OSGI、JPMS等框架。\n- 应用需要从不同的数据源获取类定义信息，例如网络数据源，而不是本地文件系统。或者是需要自己操纵字节码，动态修改或者生成类型。\n\n**注意**\n\n在一般情况下，使用不同的类加载器去加载不同的功能模块，会提高应用程序的安全性。但是，如果涉及Java类型转换，则加载器反而容易产生不美好的事情。**在做Java类型转换时，只有两个类型都是由同一个加载器所加载，才能进行类型转换，否则转换时会发生异常**。\n\n### 实现方式\n\nJava提供了抽象类`java.lang.ClassLoader`，所有用户自定义的类加载器都应该继承`ClassLoader`类。\n\n在自定义`ClassLoader`的子类时候，我们常见的会有两种做法:\n\n- 方式一：重写`loadClass()`方法\n- 方式二：重写`findclass()`方法\n\n**对比**\n\n- 这两种方法本质上差不多，毕竟`loadClass()`也会调用`findClass()`，但是从逻辑上讲我们最好不要直接修改`loadClass()`的内部逻辑。建议的做法是只在`findClass()`里重写自定义类的加载方法，根据参数指定类的名字，返回对应的Class对象的引用。\n- `loadClass()`这个方法是实现双亲委派模型逻辑的地方，擅自修改这个方法会导致模型被破坏，容易造成问题。\n- 同时，也避免了自己重写`loadClass()`方法的过程中必须写双亲委托的重复代码，从代码的复用性来看，不直接修改这个方法始终是比较好的选择。\n- 当编写好自定义类加载器后，便可以在程序中调用`loadClass()`方法来实现类加载操作。\n\n**说明**\n\n- 其父类加载器是**系统类加载器**\n- JVM中的所有类加载都会使用`java.lang.ClassLoader.loadClass(String)`接口(自定义类加载器并重写`java.lang.ClassLoader.loadClass(String)`接口的除外)，连JDK的核心类库也不能例外。\n\n```java\npublic class CustomClassLoader extends ClassLoader {\n    @Override\n    protected Class<?> findClass(String name) throws ClassNotFoundException {\n\n        try {\n            byte[] result = getClassFromCustomPath(name);\n            if (result == null) {\n                throw new FileNotFoundException();\n            } else {\n                //defineClass和findClass搭配使用\n                return defineClass(name, result, 0, result.length);\n            }\n        } catch (FileNotFoundException e) {\n            e.printStackTrace();\n        }\n\n        throw new ClassNotFoundException(name);\n    }\n    \n    //自定义流的获取方式\n    private byte[] getClassFromCustomPath(String name) {\n        //从自定义路径中加载指定类:细节略\n        //如果指定路径的字节码文件进行了加密，则需要在此方法中进行解密操作。\n        return null;\n    }\n\n    public static void main(String[] args) {\n        CustomClassLoader customClassLoader = new CustomClassLoader();\n        try {\n            Class<?> clazz = Class.forName(\"One\", true, customClassLoader);\n            Object obj = clazz.newInstance();\n            System.out.println(obj.getClass().getClassLoader());\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n## Java 9 新特性\n\n> https://www.yuque.com/u21195183/jvm/mrgsug#9eca4c5f\n\n为了保证兼容性，JDK9没有从根本上改变三层类加载器架构和双亲委派模型，但为了模块化系统的顺利运行，仍然发生了一些值得被注意的变动。\n\n-  扩展机制被移除，扩展类加载器由于向后兼容性的原因被保留，不过被重命名为平台类加载器(platform class loader)。可以通过classLoader的新方法`getPlatformClassLoader()`来获取。\n  JDK9时基于模块化进行构建（原来的rt.jar和tools.jar被拆分成数十个JMOD文件），其中的Java类库就已天然地满足了可扩展的需求，那自然无须再保留`<JAVA_HOME>\\lib\\ext`目录，此前使用这个目录或者java.ext.dirs系统变量来扩展JDK功能的机制已经没有继续存在的价值了。 \n- 平台类加载器和应用程序类加载器都不再继承自`java.net.URLClassLoader`。现在启动类加载器、平台类加载器、应用程序类加载器全都继承于`jdk.internal.loader.BuiltinClassLoader`。 \n\n![image-20211018105345375](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018105345375.png)\n\n如果有程序直接依赖了这种继承关系，或者依赖了`URLClassLoader`类的特定方法，那代码很可能会在JDK9及更高版本的JDK中崩溃。\n\n- 在Java9中，类加载器有了名称。该名称在构造方法中指定，可以通过`getName()`方法来获取。平台类加载器的名称是platform，应用类加载器的名称是app。类加载器的名称在调试与类加载器相关的问题时会非常有用。\n- 启动类加载器现在是在jvm内部和java类库共同协作实现的类加载器（以前是C++实现），但为了与之前代码兼容，在获取启动类加载器的场景中仍然会返回null，而不会得到`BootClassLoader`实例。\n- 类加载的委派关系也发生了变动。当平台及应用程序类加载器收到类加载请求，在委派给父加载器加载前，要先判断该类是否能够归属到某一个系统模块中，如果可以找到这样的归属关系，就要优先委派给负责那个模块的加载器完成加载。\n\n![image-20211018105552699](/images/%E3%80%90JVM%E3%80%91JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/image-20211018105552699.png)\n\n```java\npublic class ClassLoaderTest {\n    public static void main(String[] args) {\n        System.out.println(ClassLoaderTest.class.getClassLoader());\n        System.out.println(ClassLoaderTest.class.getClassLoader().getParent());\n        System.out.println(ClassLoaderTest.class.getClassLoader().getParent().getParent());\n\n        //获取系统类加载器\n        System.out.println(ClassLoader.getSystemClassLoader());\n        //获取平台类加载器\n        System.out.println(ClassLoader.getPlatformClassLoader());\n        //获取类的加载器的名称\n        System.out.println(ClassLoaderTest.class.getClassLoader().getName());\n    }\n}\n```\n\n\n\n## 其它\n\n###  如何判断两个 class 对象是否相同\n\n在JVM中表示两个class对象是否为同一个类存在两个必要条件：\n\n- 类的完整类名必须一致，包括包名。\n- **加载这个类的`ClassLoader`（指ClassLoader实例对象）必须相同**。\n\n换句话说，在JVM中，即使这两个类对象（class对象）来源同一个Class文件，被同一个虚拟机所加载，但只要加载它们的`ClassLoader`实例对象不同，那么这两个类对象也是不相等的。\n\nJVM必须知道一个类型是由启动加载器加载的还是由用户类加载器加载的。如果一个类型是由用户类加载器加载的，那么JVM会将这个类加载器的一个引用作为类型信息的一部分保存在方法区中。当解析一个类型到另一个类型的引用的时候，JVM需要保证这两个类型的类加载器是相同的。\n\n## 相关面试题\n\n蚂蚁金服：\n\n- 描述一下JVM加载Class文件的原理机制？\n- 一面：类加载过程\n\n百度：\n\n- 类加载的时机\n- java类加载过程？\n- 简述java类加载机制？\n\n腾讯：\n\n- JVM中类加载机制，类加载过程？\n\n滴滴：\n\n- JVM类加载机制\n\n美团：\n\n- Java类加载过程\n- 描述一下jvm加载class文件的原理机制\n\n京东：\n\n- 什么是类的加载？\n- 哪些情况会触发类的加载？\n- 讲一下JVM加载一个类的过程JVM的类加载机制是什么？\n\n\n\n蚂蚁金服：\n\n- 深入分析ClassLoader，双亲委派机制\n- 类加载器的双亲委派模型是什么？一面：双亲委派机制及使用原因\n\n 百度：\n\n- 都有哪些类加载器，这些类加载器都加载哪些文件？\n- 手写一个类加载器Demo\n- `Class.forName(“java.lang.String”)`和`Class.getClassLoader().loadClass(“java.lang.String)`有什么区别？\n\n 腾讯：\n\n- 什么是双亲委派模型？\n- 类加载器有哪些？ \n\n小米：\n\n- 双亲委派模型介绍一下\n\n滴滴：\n\n- 简单说说你了解的类加载器\n- 一面：讲一下双亲委派模型，以及其优点\n\n 字节跳动：\n\n- 什么是类加载器，类加载器有哪些？\n\n 京东：\n\n- 类加载器的双亲委派模型是什么？\n- 双亲委派机制可以打破吗？为什么\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【JVM】JVM 字节码指令集","url":"/2021/09/20/【JVM】JVM字节码指令集/","content":"\n## 前言\n\n曾经：源代码 -> 经过编译 -> 本地机器码\n\nJava：源代码 -> 经过编译 -> **字节码** -> **解释器** -> 本地机器码\n\n![image-20210508090007130](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210508090007130.png)\n\n**字节码：与操作系统和机器指令集无关的，平台中立的程序编译后的存储格式**\n\n> 字节码是无关性的基石\n\n**平台无关性**的基石：\n\n- 所有平台都统一支持字节码\n- 不同的Java虚拟机都可以执行平台无关的字节码\n\n因此实现了**一次编译，到处运行**\n\n**语言无关性**的基石：\n\n- Java虚拟机\n- 字节码\n\nJava虚拟机不是只可以执行Java源代码编译而成的字节码，只要符合要求（安全...）的字节码，它都可以执行。因此Kotlin等语言也可以运行在Java虚拟机上。\n\n## Class 字节码文件结构\n\n> 文件格式存取数据的类型\n\n- 无符号数 : u1，u2，u4，u8代表1，2，4，8个字节的无符号数(可以表示数字，UTF-8的字符串，索引引用....)\n- 表: 由n个无符号数或n个表组成(命名以`_info`结尾)\n\n### 初识 Class 文件格式\n\n```java\npublic class Test {\n    private int m;\n    private final int CONSTANT=111;\n\n    public int inc() throws Exception {\n        int x;\n        try {\n            x = 1;\n            return x;\n        }catch (Exception e){\n            x = 2;\n            return  x;\n        }finally{\n            x = 3;\n        }\n    }\n}\n```\n\n使用可视化工具classpy查看反编译的结果\n\n![image-20201107172118033](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107172118033.png)\n\n每个集合前都有一个计数器来统计集合中元素的数量\n\n<!-- More -->\n\n>  Class文件格式的描述\n\n| 数据类型       | 名称                | 数量                    | 对应图中名字     | 作用                                            |\n| -------------- | ------------------- | ----------------------- | ---------------- | ----------------------------------------------- |\n| u4             | magic               | 1                       | 魔数             | 确定这个文件是否是一个能被虚拟机接受的Class文件 |\n| u2             | minor_version       | 1                       | 次版本号         | 虚拟机必须拒绝执行超过其版本号的Class文件       |\n| u2             | major_version       | 1                       | 主版本号         | 虚拟机必须拒绝执行超过其版本号的Class文件       |\n| u2             | constant_pool_count | 1                       | 常量池容量计数器 | 统计常量数量                                    |\n| cp_info        | constant_pool       | constant_pool_count - 1 | 常量池           | 存放常量                                        |\n| u2             | access_flags        | 1                       | 访问标志         | 识别类(类，接口)的访问信息                      |\n| u2             | this_class          | 1                       | 类索引           | 确定类的全限定名                                |\n| u2             | super_class         | 1                       | 父类索引         | 确定父类的全限定名                              |\n| u2             | interfaces_count    | 1                       | 接口计数器       | 统计该类实现接口数量                            |\n| u2             | interfaces          | interfaces_count        | 接口索引集合     | 描述该类实现了的接口                            |\n| u2             | fields_count        | 1                       | 字段表集合计数器 | 统计类的字段数量                                |\n| field_info     | fields              | fields_count            | 字段表集合       | 描述类声明的字段(类变量，实例变量)              |\n| u2             | methods_count       | 1                       | 方法表集合计数器 | 统计类的方法数量                                |\n| method_info    | methods             | methods_count           | 方法表集合       | 描述类声明的方法                                |\n| u2             | attribute_count     | 1                       | 属性表集合计数器 | 统计属性数量                                    |\n| attribute_info | attributes          | attributes_count        | 属性表集合       | 描述属性                                        |\n\n### 魔数与主次版本号\n\n- **魔数**：确定这个文件是否为一个能被虚拟机接受的有效Class文件\n- **主次版本号**：虚拟机拒绝执行超过其版本号的Class文件\n  - 不同版本的Java前端编译器编译生成对应的Class文件主次版本号不同\n  - 支持高版本JVM执行低版本前端编译器生成的Class文件(向下兼容)\n  - 拒绝低版本JVM执行高版本前端编译器生成的Clsss文件\n\n### 常量池\n\n常量池包含两大常量： **字面量和符号引用**\n\n> 符号引用与直接引用\n\n- **符号引用**\n  - 使用一组符号描述引用（为了定位到目标引用）\n  - 与虚拟机内存布局无关\n  - 还是符号引用时目标引用不一定被加载到内存\n- **直接引用**\n  - 直接执行目标的指针，相对偏移量或间接定位目标引用的句柄\n  - 与虚拟机内存布局相关\n  - 解析直接引用时目标引用已经被加载到内存中\n\n> 字面量与符号引用\n\n- **字面量**\n  - 文本字符串\n  - 被final声明的常量\n- **符号引用**\n  - 全限定名\n  - 方法或字段的简单名称和描述符\n\n![image-20210512225657765](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210512225657765.png)\n\n图中的常量有我们代码中熟悉的常量也有很多没有显示出现在代码中的常量\n\n### 访问标志\n\n访问标志：**用于识别类或接口的访问信息**\n\n- 是否是一个接口，枚举，模块，注解...\n- 是否被final(public，abstract...)修饰\n\n![image-20201107175942225](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107175942225.png)\n\n- `ACC_PUBLIC`：被public修饰\n- `ACC_SUPER`： 允许使用`invokespecial`字节码指令\n\n### 类索引，父类索引与接口索引集合\n\n> 类索引\n\n**用于确定本类的全限定名**\n\n![image-20201107180153111](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107180153111.png)\n\n类索引指向常量池中表示该类的符号引用\n\n> 父类索引\n\n**用于确定父类的全限定名**\n\n![image-20201107180509860](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107180509860.png)\n\n父类索引指向常量池中表示该类父类的符号引用。除了Object外，所有类的父类索引都不为0\n\n> 接口索引集合\n\n**描述这个类实现了哪些接口**\n\n我们的例子中没有实现接口，就没有（接口索引集合计数器为0）\n\n> 总结\n\n**Class 文件由“类索引，父类索引，接口索引集合”来确定该类的继承关系**\n\n### 字段表集合\n\n**描述类声明的字段**，字段包括类变量和成员变量（实例变量），不包括局部变量\n\n![image-20201107181355881](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107181355881.png)\n\n> 简单名称和描述符\n\n- **简单名称**\n  - 字段： 没有描述字段类型的名称\n  - 方法： 没有描述参数列表和返回类型的名称\n- **描述符**\n  - 字段： 描述字段的类型\n  - 方法： 描述参数列表和返回值\n  - 描述符字符含义(long，boolean，对象类型是J，Z，L 其他都是首字母大写)\n\n\n| 标识字符 | 含义                          |\n| -------- | ----------------------------- |\n| B        | byte                          |\n| C        | char                          |\n| D        | double                        |\n| F        | float                         |\n| I        | int                           |\n| J        | long                          |\n| S        | short                         |\n| Z        | boolean                       |\n| V        | void                          |\n| L        | 对象类型，如Ljava/lang/Object |\n\n  - 描述符描述n维数组\n    - 在前面先写n个`[` 再写标识字符\n      比如 `java.lang.Integer[ ]` => `[Ljava.lang.Integer`\n  - 描述符描述方法\n    - 参数列表按照从左到右的顺序写在`()`中\n    - 返回类型写到最后。比如`String method(long[], int, String[])` => `([JIL[java.lang.String)Ljava.lang.String`\n\n\n因此Class文件中字段描述符指向常量池中的#07 I 符号引用(的索引)\n\n> 注意\n\n1. **字段表集合不会列出父类或父接口中声明的字段**\n2. **只用 简单名称 来确定字段，所以不能有重名字段**\n3. **用 简单名称 和 描述符 确定方法，所以方法可以重名（重载）**\n   - 字节码文件 规定 简单名称+描述符相同才是同一个方法\n   - 但是 Java语法 规定 重载 = 简单名称相同 + 描述符的参数列表不同 + 描述符的返回类型不能不同\n\n### 方法表集合\n\n**描述类声明的方法**，与字段表集合类似\n\n![image-20201107182407009](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107182407009.png)\n\n> 注意\n\n**方法表集合中不会列出父类方法信息（不重写的情况）**\n\n### 属性表集合\n\n属性比较多，这里只说明我们例子中出现的，其他的会总结。**用于描述某些场景专有信息**刚刚在字段，方法表集合中都可以看到属性表集合，说明属性表集合是可以被携带的。\n\n> 怎么没看到Java源代码中的代码呢?\n\n实际上它属于属性表集合中的Code属性\n\n#### Code 属性\n\nJava源代码中方法体中的代码经过编译后编程字节码指令存储在Code属性内\n\n![image-20201107184345952](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107184345952.png)\n\n其中的异常表集合代表 **编译器为这段代码生成的多条异常记录，对应着可能出现的代码执行路径**（程序在try中不抛出异常会怎么执行，抛出异常又会怎么执行....）\n\n![image-20201107184823648](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107184823648.png)\n\n#### Exceptions 属性\n\n列举出方法中可能抛出的检查异常（Checked Exception），也就是方法声明`throws`关键字后面的列举异常\n\n![image-20201107185136111](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107185136111.png)\n\n#### LineNumberTable 属性\n\n描述Java源码行号与字节码指令行号(字节码偏移量)对应关系\n\n#### SourceFile 属性\n\n记录生成此Class文件的源码名称\n\n#### StackMapTable属性\n\n虚拟机类加载验证阶段的字节码验证时，不需要再检验了，只需要查看StackMapTable属性中的记录是否合法\n\n**编译阶段将一系列的验证类型结果记录在StackMapTable属性中**\n\n![image-20201107185712220](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107185712220.png)\n\n#### ConstantValue\n\n在类加载的准备阶段，为静态变量（常量）赋值。只有类变量才有这个属性。\n\n- 实例变量的赋值： 在实例构造器\n- 类变量的赋值： 在类构造器或带有ConstantValue属性在类加载的准备阶段\n\n**如果类变量被final修饰（此时该变量是一个常量），且该变量数据类型是基本类型或字符串，就会生成ConstantValue属性**，该属性指向常量池中要赋值的常量，在类加载的准备阶段，直接把在常量池中ConstantValue指向的常量赋值给该变量\n\n![image-20201107191419341](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20201107191419341.png)\n\n#### 总结所有属性\n\n| 属性名                 | 作用                                                         |\n| ---------------------- | ------------------------------------------------------------ |\n| Code                   | 方法体内的代码经过编译后变为字节码指令存储在Code属性中       |\n| Exceptions             | 列举出方法可能抛出的检查异常(Checked Exception)              |\n| LineNumberTable        | Java源码行号与字节码偏移量(字节码行号)对应关系               |\n| LocalVariableTable     | Java源码定义的局部变量与栈帧中局部变量表中的变量对应关系(==局部变量名称，描述符，局部变量槽位置，局部变量作用范围等==) |\n| LocalVariableTypeTable | 与`LocalVariableTable`相似，只是把`LocalVariableTable`的描述符换成了字段的特征签名(完成对泛型的描述) |\n| SourceFile             | 记录生成这个Class文件的源码文件名称                          |\n| SourceDebugExtension   | 用于存储额外的代码调式信息                                   |\n| ConstantValue          | 在类加载的准备阶段，为静态变量(常量)赋值                     |\n| InnerClasses           | 记录内部类与宿主类之间的关系                                 |\n| Deprecated             | 用于表示某个字段，方法或类已弃用 (可以用注解@deprecated表示) |\n| Synthetic              | 用于表示某字段或方法不是由Java源代码生成的，而是由编译器自行添加的 |\n| StackMapTable          | 虚拟机类加载验证阶段的字节码验证时，不需要再检验了，只需要查看StackMapTable属性中的记录是否合法 |\n| Signature              | 记录泛型签名信息                                             |\n| BootstrapMethods       | 保存动态调用(invokeeddynamic)指令引用的引导方法限定符        |\n| MethodParameters       | 记录方法的各个形参名称与信息                                 |\n\n\n\n### javap 解析 Class 文件\n\n#### 关于 javac\n\n- `javac xx.java` 编译Java源文件，不会生成对应的局部变量表\n- `javac -g xx.java` 编译Java源文件，生成对应的局部变量表\n\nIDEA中编译Java源文件使用的是`javac -g`\n\n#### 关于 javap\n\n![image-20210513195725462](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210513195725462.png)\n\n> 常用\n\n`javap -v` 基本上可以反编译出Class文件中的很多信息（常量池，字段集合，方法集合...）\n\n但是它不会显示私有字段或方法的信息，所以可以使用`javap -v -p`\n\n> 详解 javap -v -p\n\n```\npublic class JavapTest {\n    private int a = 1;\n    float b = 2.1F;\n    protected double c = 3.5;\n    public  int d = 10;\n\n    private void test(int i){\n        i+=1;\n        System.out.println(i);\n    }\n\n    public void test1(){\n        String s = \"test1\";\n        System.out.println(s);\n    }\n}\n```\n\n![image-20210513200417243](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210513200417243.png)\n\n![image-20210513200532661](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210513200532661.png)\n\n![image-20210513200946912](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210513200946912.png)\n\n\n\n## 字节码指令集\n\n> https://www.yuque.com/u21195183/jvm/bg6q2k\n\n### 字节码与数据类型\n\n在Java虚拟机的指令集中，大多数的指令都包含了其操作所对应的数据类型信息。例如，iload指令用于从局部变量表中加载int型的数据到操作数栈中，而fload指令加载的则是float类型的数据。\n\n对于大部分与数据类型相关的字节码指令，它们的操作码助记符中都有特殊的字符来表明专门为哪种数据类型服务：\n\n- i代表对int类型的数据操作\n- l代表long\n- s代表short\n- b代表byte\n- c代表char\n- f代表float\n- d代表double\n\n也有一些指令的助记符中没有明确地指明操作类型的字母，如arraylength指令，它没有代表数据类型的特殊字符，但操作数永远只能是一个数组类型的对象。还有另外一些指令，如无条件跳转指令goto则是与数据类型无关的。\n\n大部分的指令都没有支持整数类型byte、char和short，甚至没有任何指令支持boolean类型。编译器会在编译期或运行期将byte和short类型的数据带符号扩展（Sign-Extend）为相应的int类型数据，将boolean和char类型数据零位扩展（Zero-Extend）为相应的int类型数据。与之类似，在处理boolean、byte、short和char类型的数组时，也会转换为使用对应的int类型的字节码指令来处理。因此，大多数对于boolean、byte、short和char类型数据的操作，实际上都是使用相应的int类型作为运算类型。\n\n### 指令分析\n\n大部分指令先以i(int)，l(long)，f(float)，d(double)，a(引用)开头。**其中byte，char，short，boolean在hotspot中都是转成int去执行（使用int类型的字节码指令）**。\n\n字节码指令大致分为:\n\n1. 加载与存储指令\n2. 算术指令\n3. 类型转换指令\n4. 对象创建与访问指令\n5. 方法调用与返回指令\n6. 操作数栈管理指令\n7. 控制转义指令\n8. 异常处理指令\n9. 同步控制指令\n\n在hotspot中每个方法对应的一组**字节码指令实际上就是在该方法所对应的栈帧中的局部变量表和操作数栈上进行操作**。\n\n**字节码指令包含字节码操作指令和操作数** （操作数可能是在局部变量表上，也可能在常量池中，还可能就是常数）\n\n（说在前面）在做值相关操作时：\n\n- 一个指令，可以从局部变量表、常量池、堆中对象、方法调用、系统调用中等取得数据，这些数据（可能是值，可能是对象的引用）被压入操作数栈。\n- 一个指令，也可以从操作数栈中取出一到多个值（pop多次），完成赋值、加减乘除、方法传参、系统调用等等操作。\n\n### 加载与存储指令\n\n> 加载\n\n加载和存储指令用于将数据从栈帧的局部变量表和操作数栈之间来回传递。（可以从局部变量表，常量池中加载到操作数栈）\n\n加载与存储相关指令（**重要**）：\n\n- **局部变量压栈指令**：将一个局部变量加载到操作数栈：`xload、xload_<n>`（其中x为i、l、f、d、a，n为0到3）\n- **常量入栈指令**：将一个常量加载到操作数栈：`bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_m1、iconst_<i>、lconst_<l>）、fconst_<f>、dconst_<d>`\n- **栈中元素装入局部变量表指令**：将一个数值从操作数栈存储到局部变量表：`xstore、xstore_<n>`（其中x为i、l、f、d、a，n为0到3）；`xastore`（其中x为i、l、f、d、a、b、c、s）\n- 扩充局部变量表的访问索引的指令：`wide`。\n\n上面所列举的指令助记符中，有一部分是以尖括号结尾的（例如`iload_<n>`）。这些指令助记符实际上代表了一组指令（例如`iload_<n>`代表了`iload_0、iload_1、iload_2`和`iload_3`这几个指令）。这几组指令都是某个带有一个操作数的通用指令（例如iload）的特殊形式，对于这若干组特殊指令来说，它们表面上没有操作数，不需要进行取操作数的动作，但操作数都隐含在指令中。\n\n除此之外，它们的语义与原生的通用指令完全一致（例如`iload_0`的语义与操作数为0时的iload指令语义完全一致）。在尖括号之间的字母指定了指令隐含操作数的数据类型，`<n>`代表非负的整数，`<i>`代表是int类型数据，`<l>`代表long类型，`<f>`代表float类型，`<d>`代表double类型。\n\n**操作byte、char、short和boolean类型数据时，用int类型的指令来表示**。\n\n---\n\n字节码指令操作byte、char、short和boolean类型数据时，都会将其转换为int类型，因为局部变量表里一个槽占用4个字节，所以1或2字节的数据放进去就会自动变成四个字节。\n\n但是在从局部变量表读取该数据到操作数栈前，会使用相应的**窄化类型转换**指令（例如i2b，int -> byte）将局部变量表里int类型的数据转换为其原本字节大小，然后再在操作数栈中进行运算。\n\n![img](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20200705212454445.png)\n\n---\n\n![image-20210514163308948](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210514163308948.png)\n\n注意：编译时就知道了局部变量表应该有多少槽的位置和操作数栈的最大深度（为节省空间，局部变量槽还会复用）\n\n**局部变量压栈常用指令集**\n\n| xload_n     | xload_0 | xload_1 | xload_2 | xload_3 |\n| ----------- | ------- | ------- | ------- | ------- |\n| **iload_n** | iload_0 | iload_1 | iload_2 | iload_3 |\n| **lload_n** | lload_0 | lload_1 | lload_2 | lload_3 |\n| **fload_n** | fload_0 | fload_1 | fload_2 | fload_3 |\n| **dload_n** | dload_0 | dload_1 | dload_2 | dload_3 |\n| **aload_n** | aload_0 | aload_1 | aload_2 | aload_3 |\n\n**局部变量压栈指令剖析**\n\n局部变量压栈指令将给定的局部变量表中的数据压入操作数栈。这类指令大体可以分为：\n\n- `xload_<n>`（x为i、l、f、d、a，n为0到3）\n- `xload`（x为i、l、f、d、a）\n\n说明：在这里，x的取值表示数据类型。\n\n指令`xload_n`表示将第n个局部变量压入操作数栈，比如`iload_1`、`fload_0`、`aload_0`等指令。其中`aload_n`表示将一个对象引用压栈。\n\n指令`xload`通过指定参数的形式，把局部变量压入操作数栈，当使用这个命令时，表示局部变量的数量可能超过了4个，比如指令`iload`、`fload`等。\n\n举例：\n\n```java\npublic void load(int num, Object obj, long count, boolean flag, short[] arr) {\n    System.out.println(num);\n    System.out.println(obj);\n    System.out.println(count);\n    System.out.println(flag);\n    System.out.println(arr);\n}\n```\n\n字节码执行过程：\n\n![image-20211020211048622](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211020211048622.png)\n\n\n\n\n\n### 算术指令\n\n**算术指令将操作数栈中的两个栈顶元素出栈作运算再将运算结果入栈**\n\n使用的是后缀表达式（逆波兰表达式），比如 3 4 + => 3 + 4\n\n#### 分类\n\n大体上算术指令可以分为两种：对整型数据进行运算的指令与对浮点类型数据进行运算的指令。\n\n在每一大类中，都有针对Java虚拟机具体数据类型的专用算术指令。**但没有直接支持byte、short、char和boolean类型的算术指令，对于这些数据的运算，都使用int类型的指令来处理**。此外，在处理boolean、byte、short和char类型的数组时，也会转换为使用对应的int类型的字节码指令来处理。\n\n![image-20211021094724555](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021094724555.png)\n\n\n\n####  运算时的溢出\n\n数据运算可能会导致溢出，例如两个很大的正整数相加，结果可能是一个负数。其实Java虚拟机规范并无明确规定过整型数据溢出的具体结果，仅规定了在处理整型数据时，只有除法指令以及求余指令中当出现除数为0时会导致虚拟机抛出异常`ArithmeticException`。\n\n#### 运算模式\n\n- **向最接近数舍入模式**：JVM要求在进行浮点数计算时，所有的运算结果都必须舍入到适当的精度，非精确结果必须舍入为可被表示的最接近的精确值，如果有两种可表示的形式与该值一样接近，将优先选择最低有效位为零的；\n- **向零舍入模式**：将浮点数转换为整数时，采用该模式，该模式将在目标数值类型中选择一个最接近但是不大于原值的数字作为最精确的舍入结果；\n\n#### NaN 值使用\n\n当一个操作产生溢出时，将会使用有符号的无穷大表示，如果某个操作结果没有明确的数学定义的话，将会使用NaN值来表示。而且所有使用NaN值作为操作数的算术操作，结果都会返回NaN；\n\n![image-20211021094942783](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021094942783.png)\n\n\n\n> 注意\n\n1. 当除数是0时会抛出`ArithmeticException`异常（如果是0.0，结果是Infinity）\n2. 浮点数转整数向0取整\n3. 浮点数计算精度丢失\n4. Infinity 计算结果无穷大\n5. NAN 计算结果不确定计算值\n\n```java\npublic void test1() {\n    double d1 = 10 / 0.0;\n    //Infinity\n    System.out.println(d1);\n\n    double d2 = 0.0 / 0.0;\n    //NaN\n    System.out.println(d2);\n\n    //向0取整模式:浮点数转整数\n    //5\n    System.out.println((int) 5.9);\n    //-5\n    System.out.println((int) -5.9);\n\n\n    //向最接近数舍入模式:浮点数运算\n    //0.060000000000000005\n    System.out.println(0.05+0.01);\n\n    //抛出ArithmeticException: / by zero异常\n    System.out.println(1/0);\n}\n```\n\n\n\n#### 算术指令集\n\n| 算数指令     | int(boolean,byte,char,short) | long | float         | double        |      |\n| ------------ | ---------------------------- | ---- | ------------- | ------------- | ---- |\n| 加法指令     | iadd                         | ladd | fadd          | dadd          |      |\n| 减法指令     | isub                         | lsub | fsub          | dsub          |      |\n| 乘法指令     | imul                         | lmul | fmul          | dmul          |      |\n| 除法指令     | idiv                         | ldiv | fdiv          | ddiv          |      |\n| 求余指令     | irem                         | lrem | frem          | drem          |      |\n| 取反指令     | ineg                         | lneg | fneg          | dneg          |      |\n| 自增指令     | iinc                         |      |               |               |      |\n| 按位或指令   | ior                          | lor  |               |               |      |\n| 按位与指令   | iand                         | land |               |               |      |\n| 按位异或指令 | ixor                         | lxor |               |               |      |\n| 比较指令     |                              | lcmp | fcmpg / fcmpl | dcmpg / dcmpl |      |\n\n![image-20210514173650867](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210514173650867.png)\n\n\n\n#### 算术指令举例\n\n举例1\n\n```java\npublic static int bar(int i) {\n\treturn ((i + 1) - 2) * 3 / 4;\n}\n```\n\n![image-20211021095249945](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021095249945.png)\n\n举例2\n\n``` java\npublic void add() {\n\tbyte i = 15;\n\tint j = 8;\n\tint k = i + j;\n}\n```\n\n![image-20211021095347090](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021095347090.png)\n\n![image-20211021095357407](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021095357407.png)\n\n![image-20211021095407259](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021095407259.png)\n\n![ef9ac1fd-3b93-4167-8d55-14e13c287d54](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/ef9ac1fd-3b93-4167-8d55-14e13c287d54.gif)\n\n举例3\n\n```java\npublic static void main(String[] args) {\n\tint x = 500;\n\tint y = 100;\n\tint a = x / y;\n\tint b = 50;\n\tSystem.out.println(a + b);\n}\n```\n\n![image-20211021095659729](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021095659729.png)\n\n![image-20211021095708757](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021095708757.png)\n\n\n\n#### 自增指令\n\n1、`i++`：\n\n``` java\npublic static void main(String[] args) {\n    int i = 0;\n    int a = i++;\n}\n```\n\n上述代码的字节码解析：\n\n- `iconst_0`：将数字 0 入操作数栈\n- `istore_1`：弹出操作数栈顶元素 0 并存储到局部变量表索引位置为1的变量（此时操作数栈为空）\n- `iload_1`：从局部变量表中加载索引位置1的元素（0）到操作数栈（目的是备份一下i  自增前的值，待自增结束后再赋值给 a）\n- `iinc 1 by 1`：首先读取局部变量表中 i 的值，再进行加一操作，最后存储加一后的值1到索引位置 1，重新赋给了 i（该指令没有原子性）\n- `istore_2`：将操作数栈顶的元素 0（第三步存储的）赋值给局部变量表中的 a\n\n所以最终结果就是，a 的值等于 0。而到这这一结果的根本原因是因为：在给 a 赋值前先从局部变量表中 `load `了 i 加一前的值，并在最后将该值又赋给了 a，所以造成了 `i++` 后 a 的值等于 i 加一前的值。\n\n![image-20211021142230633](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021142230633.png)\n\n注意：`iinc 1 by 1`这条指令虽然在JVM层面只是一条命令，但是其在最底层的CPU层面却是包含了三个步骤：\n\n1. 读取：从局部变量表中读取 i 的值\n2. 累加：将该值进行加一\n3. 保存：将加一后的值保存回局部变量表中\n\n其中的一条指令可以保证是原子操作，但是3条指令合在一起却不是，这就导致了`i++`语句不是原子操作。\n\n如果在读取操作进行后，当前线程失去了执行权，那么在该线程再一次获取到执行权后，就不会再做一次读取操作，而是直接使用线程切换前读取到的值进行加一，这就导致了高并发下 `i++` 操作的结果异常\n\n---\n\n情景：两个线程同时对 `static int i = 0` 进行各自连续100次的 `i++` 操作，理想情况下结果为 200，但最极端的情况下，结果为 2。该过程图解：\n\n![幻灯片1](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/%E5%B9%BB%E7%81%AF%E7%89%871.PNG)\n\n---\n\n\n\n2、`i--`：\n\n``` java\npublic static void main(String[] args) {\n    int i = 0;\n    int a = ++i;\n}\n```\n\n![image-20211021163147335](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021163147335.png)\n\n对比 `++i` 和 `i++`，可以看到二者的区别是：\n\n- `++i` 是先执行 `iinc 1 by 1`，将 i 的值增加，然后再 `iload_1` 读取了加一后的 i 值，将该值赋给 a\n- `i++` 则是在 `iinc 1 by 1` 执行前就先把 i 原本的值**备份**了一份，然后 i 自增后，再将之前备份的值赋给 a\n\n\n\n>  补充：只有局部变量才使用 iinc 指令，如果是调用的成员变量属性++，则不会使用 iinc 指令，其指令更加复杂。先从局部变量表里 load 该值，然后再加一，最后存回局部变量表里去。\n\n\n\n### 类型转换指令\n\n类型转换指令可以分为**宽化类型转换**和**窄化类型转换**（对应基本类型的**非强制转换**和**强制转换**）\n\n#### 类型转换指令集\n\n|            | **byte** | **char** | **short** | **int** | **long** | **float** | **double** |\n| ---------- | -------- | -------- | --------- | ------- | -------- | --------- | ---------- |\n| **int**    | i2b      | i2c      | i2s       | ○       | i2l      | i2f       | i2d        |\n| **long**   | l2i i2b  | l2i i2c  | l2i i2s   | l2i     | ○        | l2f       | l2d        |\n| **float**  | f2i i2b  | f2i i2c  | f2i i2s   | f2i     | f2l      | ○         | f2d        |\n| **double** | d2i i2b  | d2i i2c  | d2i i2s   | d2i     | d2l      | d2f       | ○          |\n\n####  宽化类型转换指令\n\n1. 转换规则\n\nJava虚拟机直接支持以下数值的宽化类型转换（ widening numeric conversion,小范围类型向大范围类型的安全转换）。也就是说，并不需要指令执行，包括\n\n- 从int类型到long、float或者 double类型。对应的指令为：`i21`、`i2f`、`i2d `\n- 从long类型到float、 double类型。对应的指令为：`i2f`、`i2d `\n- 从float类型到double类型。对应的指令为：`f2d `\n\n简化为：int -> long -> float -> double\n\n2. 精度损失问题\n\n-  宽化类型转换是不会因为超过目标类型最大值而丢失信息的，例如，从int转换到long，或者从int转换到double，都不会丢失任何信息，转换前后的值是精确相等的。 \n- 从int、long类型数值转换到float，或者long类型数值转换到double时，将可能发生精度丢失一一可能丢失掉几个最低有效位上的值，转换后的浮点数值是根据IEEE754最接近含入模式所得到的正确整数值。 \n\n尽管宽化类型转换实际上是可能发生精度丢失的，但是这种转换永远不会导致Java虚拟机抛出运行时异常\n\n补充说明：\n\n从byte、char和 short类型到int类型的宽化类型转换实际上是不存在的。对于byte类型转为int,拟机并没有做实质性的转化处理，只是简单地通过操作数栈交換了两个数据。而将byte转为long时，使用的是i2l，可以看到在内部，byte在这里已经等同于int类型处理，类似的还有 short类型，这种处理方式有两个特点：\n\n一方面可以减少实际的数据类型，如果为 short和byte都准备一套指令，那么指令的数量就会大増，而虚拟机目前的设计上，只愿意使用一个字节表示指令，因此指令总数不能超过256个，为了节省指令资源，将 short和byte当做int处理也在情理之中。\n\n另一方面，由于局部变量表中的槽位固定为32位，无论是byte或者short存入局部变量表，都会占用32位空间。从这个角度说，也没有必要特意区分这几种数据类型。\n\n#### 窄化类型转换指令\n\n1. 转换规则\n\nJava虚拟机也直接支持以下窄化类型转换：\n\n-  从主int类型至byte、 short或者char类型。对应的指令有：`i2b`、`i2c`、`i2s` \n- 从long类型到int类型。对应的指令有：`l2i `\n- 从float类型到int或者long类型。对应的指令有：`f2i`、`f2l `\n- 从double类型到int、long或者float类型。对应的指令有：`d2i`、`d2l`、`d2f `\n\n2. 精度损失问题\n\n窄化类型转换可能会导致转换结果具备不同的正负号、不同的数量级，因此，转换过程很可能会导致数值丢失精度。\n\n尽管数据类型窄化转换可能会发生上限溢出、下限溢出和精度丢失等情况，但是Java虚拟机规范中明确规定数值类型的窄化转换指令永远不可能导致虚拟机抛出运行时异常\n\n补充说明：\n\n当将一个浮点值窄化转换为整数类型T(T限于int或long类型之一)的时候，将遵循以下转换规则：\n\n-  如果浮点值是NaN，那转换结果就是int或long类型的0.\n- 如果浮点值不是无穷大的话，浮点值使用IEEE754的向零含入模式取整，获得整数值v。如果v在目标类型T(int或long)的表示范围之内，那转换结果就是v。否则，将根据v的符号，转换为T所能表示的最大或者最小正数 \n\n当将一个double类型窄化转换为float类型时，将遵循以下转换规则，通过向最接近数舍入模式舍入一个可以使用float类型表示的数字。最后结果根据下面这3条规则判断：\n\n-  如果转换结果的绝对值太小而无法使用float来表示，将返回float类型的正负零 \n- 如果转换结果的绝对值太大而无法使用float来表示，将返回float类型的正负无穷大。 \n- 对于double类型的NaN值将按规定转换为float类型的NaN值。 \n\n\n\n**注意: long转换为float或double时可能发生精度丢失**\n\n```java\npublic void test2(){\n    long l1 =  123412345L;\n    long l2 =  1234567891234567899L;\n\n    float f1 = l1;\n    //结果: 1.23412344E8 => 123412344\n    //                l1 =  123412345L\n    System.out.println(f1);\n\n    double d1 = l2;\n    //结果: 1.23456789123456794E18 => 1234567891234567940\n    //                          l2 =  1234567891234567899L\n    System.out.println(d1);\n}\n```\n\nNaN和Infinity的特殊情况：\n\n- **NaN转为整型会变成0**\n- **正无穷或负无穷转为整型会变成那个类型的最大值或最小值**\n\n```java\npublic void test3(){\n    double d1 = Double.NaN;\n    double d2 = Double.POSITIVE_INFINITY;\n\n    int i1 = (int) d1;\n    int i2 = (int) d2;\n    //0\n    System.out.println(i1);\n    //true\n    System.out.println(i2==Integer.MAX_VALUE);\n\n    long l1 = (long) d1;\n    long l2 = (long) d2;\n    //0\n    System.out.println(l1);\n    //true\n    System.out.println(l2==Long.MAX_VALUE);\n\n    float f1 = (float) d1;\n    float f2 = (float) d2;\n    //NaN\n    System.out.println(f1);\n    //Infinity\n    System.out.println(f2);\n}\n```\n\n\n\n### 对象创建与访问指令\n\n> https://www.yuque.com/u21195183/jvm/bg6q2k#153d0652\n\n对象创建与访问指令: **创建指令，字段访问指令，数组操作指令，类型检查指令**\n\n#### 创建指令\n\n- `new`: 创建实例\n- `newarray`: 创建一维基本类型数组\n- `anewarray`: 创建一维引用类型数组\n- `multianewarray`: 创建多维数组\n\n**注意：这里的创建可以理解为分配内存，当多维数组只分配了一维数组时使用的是`anewarray`**\n\n![image-20210514230240390](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210514230240390.png)\n\n#### 字段访问指令\n\n- `getstatic`: 对静态字段进行读操作\n- `putstatic`: 对静态字段进行写操作\n- `getfield`: 对实例字段进行读操作\n- `putfield`: 对实例字段进行写操作\n\n**读操作：把要进行读操作的字段入栈**\n\n**写操作：把要写操作的值出栈再写到对应的字段**\n\n![image-20210515093103500](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515093103500.png)\n\n举例：以`getstatic`指令为例，它含有一个操作数，为指向常量池的Fieldref索引，它的作用就是获取Fieldref指定的对象或者值，并将其压入操作数栈。\n\n```java\npublic void sayHello() {\n    System.out.println(\"hel1o\"); \n}\n```\n\n对应的字节码指令：\n\n```shell\n0 getstatic #8 <java/lang/System.out>\n3 ldc #9 <hello>\n5 invokevirtual #10 <java/io/PrintStream.println>\n8 return\n```\n\n图示：\n\n![image-20211021141445947](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021141445947.png)\n\n\n\n#### 数组操作指令\n\n- `b/c/s/i/l/f/d/a aload`：**表示将数组中某索引元素入栈** (读)\n  - 需要的参数从栈顶依次向下：**索引位置,数组引用**\n- `b/c/s/i/l/f/d/a astore`：**表示将某值出栈并写入数组某索引元素** (写)\n  - 需要的参数从栈顶依次向下：**要写入的值,索引位置,数组引用**\n\n![image-20210515094055002](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515094055002.png)\n\n注意：b开头的指令对byte和boolean通用\n\n- `arraylength`：**先将数组引用出栈再将获得的数组长度入栈**\n\n![image-20210515095603614](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515095603614.png)\n\n#### 类型检查指令\n\n- `instanceof`: 判断某对象是否为某类的实例\n- `checkcast`: 检查引用类型是否可以强制转换\n\n![image-20210515095311597](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515095311597.png)\n\n### 方法调用与返回指令\n\n#### 方法调用指令\n\n**非虚方法：静态方法、私有方法、父类中的方法、被final修饰的方法、实例构造器**\n\n与之对应不是非虚方法的就是虚方法了。\n\n\n- 普通调用指令\n  - `invokestatic`：调用静态方法\n  - `invokespecial`：调用私有方法、父类中的方法、实例构造器方法、final方法\n  - `invokeinterface`：调用接口方法\n  - `invokevirtual`：调用虚方法\n  - **使用`invokestatic`和`invokespecial`指令的一定是非虚方法**\n  - 使用`invokeinterface`指令一定是虚方法(因为接口方法需要具体的实现类去实现)\n  - 使用`invokevirtual`指令可能是虚方法\n- 动态调用指令\n  - **`invokedynamic`: 动态解析出需要调用的方法再执行**\n\n\n  jdk 7 出现`invokedynamic`，支持动态语言。\n\n\n> 测试虚方法代码\n\n父类\n\n```java\npublic class Father {\n    public static void staticMethod(){\n        System.out.println(\"father static method\");\n    }\n\n    public final void finalMethod(){\n        System.out.println(\"father final method\");\n    }\n\n    public Father() {\n        System.out.println(\"father init method\");\n    }\n\n    public void overrideMethod(){\n        System.out.println(\"father override method\");\n    }\n}\n```\n\n接口\n\n```java\npublic interface TestInterfaceMethod {\n    void testInterfaceMethod();\n}\n```\n\n子类\n\n```java\npublic class Son extends Father{\n\n    public Son() {\n        //invokespecial 调用父类init 非虚方法\n        super();\n        //invokestatic 调用父类静态方法 非虚方法\n        staticMethod();\n        //invokespecial 调用子类私有方法 特殊的非虚方法\n        privateMethod();\n        //invokevirtual 调用子类的重写方法 虚方法\n        overrideMethod();\n        //invokespecial 调用父类方法 非虚方法\n        super.overrideMethod();\n        //invokespecial 调用父类final方法 非虚方法\n        super.finalMethod();\n        //invokedynamic 动态生成接口的实现类 动态调用\n        TestInterfaceMethod test = ()->{\n            System.out.println(\"testInterfaceMethod\");\n        };\n        //invokeinterface 调用接口方法 虚方法\n        test.testInterfaceMethod();\n    }\n\n    @Override\n    public void overrideMethod(){\n        System.out.println(\"son override method\");\n    }\n\n    private void privateMethod(){\n        System.out.println(\"son private method\");\n    }\n\n    public static void main(String[] args) {\n        new Son();\n    }\n}\n```\n\n![image-20210426234249850](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210426234249850.png)\n\n#### 方法返回指令\n\n**方法返回指令: 方法结束前，将栈顶元素（最后一个元素）出栈，返回给调用者**\n\n根据方法的返回类型划分多种指令：\n\n![image-20210515103425506](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515103425506.png)\n\n方法调用结束前，需要进行返回。方法返回指令是根据返回值的类型区分的。\n\n- 包括`ireturn`（当返回值是boolean、byte、char、short和int 类型时使用）、`lreturn`、`freturn`、`dreturn`和`areturn`\n- 另外还有一条`return `指令供声明为void的方法、实例初始化方法以及类和接口的类初始化方法使用。\n\n通过`ireturn`指令，将当前函数操作数栈的顶层元素弹出，并将这个元素压入调用者函数的操作数栈中（因为调用者非常关心函数的返回值），所有在当前函数操作数栈中的其他元素都会被丢弃。如果当前返回的是synchronized方法，那么还会执行一个隐含的`monitorexit`指令，退出临界区。\n\n最后，会丢弃当前方法的整个帧，恢复调用者的帧，并将控制权转交给调用者。\n\n举例：\n\n```java\npublic int methodReturn() {\n    int i = 500;\n    int j = 200;\n    int k = 50;\n    \n    return (i + j) / k;\n}\n```\n\n图示：\n\n![image-20211021141618931](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20211021141618931.png)\n\n### 操作数栈管理指令\n\n**通用型指令，不区分类型**\n\n- 出栈\n  - `pop/pop2`出栈1个/2个栈顶元素\n- 入栈\n  - `dup/dup2` 复制栈顶1个/2个slot并重新入栈\n  - `dup_x1` 复制栈顶1个slot并插入到栈顶开始的第2个slot下\n  - `dup_x2 `复制栈顶1个slot并插入到栈顶开始的第3个slot下\n  - `dup2_x1`复制栈顶2个slot并插入到栈顶开始的第3个slot下\n  - `dup2_x2`复制栈顶2个slot并插入到栈顶开始的第4个slot下\n    - 插入到具体的slot计算：dup的系数 + `_x`的系数\n\n### 控制转义指令\n\n#### 条件跳转指令\n\n**通常先进行比较指令，再进行条件跳转指令**\n\n比较指令比较结果-1,0,1再进行判断是否要跳转\n\n**条件跳转指令: 出栈栈顶元素，判断它是否满足条件，若满足条件则跳转到指定位置**\n\n![image-20210515164609270](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515164609270.png)\n\n![image-20210515165351883](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515165351883.png)\n\n注意: 这种跳转指令一般都\"取反\",比如代码中第一个条件语句是d>100,它第一个条件跳转指令就是`ifle`小于等于0,满足则跳转,不满足则按照顺序往下走\n\n#### 比较条件跳转指令\n\n**比较条件跳转指令 类似 比较指令和条件跳转指令 的结合体**\n\n![image-20210515180004587](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515180004587.png)\n\n![image-20210515181000595](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515181000595.png)\n\n#### 多条件分支跳转指令\n\n**多条件分支跳转指令是为了switch-case提出的**\n\n- `tableswitch`用于case值连续的switch多条件分支跳转指令，效率好\n- `lookupswitch`用于case值不连续的switch多条件分支跳转指令(虽然case值不连续,但最后会对case值进行排序)\n\n> tableswitch\n\n![image-20210515182307183](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515182307183.png)\n\n> lookupswitch\n\n![image-20210515183527055](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515183527055.png)\n\n对于String类型是先找到对应的哈希值再equals比较确定走哪个case的\n\n#### 无条件跳转指令\n\n**无条件跳转指令就是跳转到某个字节码指令处**\n\n- `goto`经常使用\n- `jsr,jsr_w,ret`不怎么使用了\n\n![image-20210515183640270](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515183640270.png)\n\n### 异常处理指令\n\nthrow抛出异常对应`athrow`：**清除该操作数栈上所有内容,将异常实例压入调用者操作数栈上**\n\n使用`try-catch/try-final/throws`时会产生异常表：**异常表保存了异常处理信息** (起始，结束位置，字节码指令偏移地址，异常类在常量池中的索引等信息)\n\n> athrow\n\n![image-20210515192750444](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515192750444.png)\n\n> 异常表\n\n![image-20210515193437666](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515193437666.png)\n\n异常还会被压入栈或者保存到局部变量表中\n\n### 同步控制指令\n\nsynchronized作用于方法时，方法的访问标识会有**ACC_SYNCHRONIZED表示该方法需要加锁**。synchronized作用于某个对象时，对应着 **`monitorentry`加锁字节码指令和 `monitorexit`解锁字节码指令**。\n\n**Java中的synchronized默认是可重入锁**。\n\n当线程要访问需要加锁的对象时 （执行`monitorentry`）：\n\n1. 先查看对象头中加锁次数，如果为0说明未加锁，获取后，加锁次数自增\n2. 如果不为0，再查看获取锁的线程是不是自己，如果是自己就可以访问，加锁次数自增\n3. 如果不为0且获取锁线程不是自己，就阻塞\n\n当线程释放锁时 （执行`monitorexit`）会让加锁次数自减：\n\n![image-20210515195912727](/images/%E3%80%90JVM%E3%80%91JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%8C%87%E4%BB%A4%E9%9B%86/image-20210515195912727.png)\n\n为什么会有2个`monitorexit `?\n\n程序正常执行应该是一个`monitorentry`对应一个`monitorexit`的。但如果程序在加锁的代码中抛出了异常，没有释放锁，那不就会造成其他阻塞的线程永远也拿不到锁了吗？所以在程序抛出异常时（跳转PC偏移量为15的指令）继续往下执行，**抛出异常前要释放锁**。\n\n\n\n\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【数据结构】栈与队列","url":"/2021/09/20/【数据结构】栈与队列/","content":"\n## 栈的常见题目\n\n\n\n\n\n<!-- More -->\n\n\n\n### 栈内元素的排序\n\n请编写一个程序，对一个栈里的整型数据，按升序进行排序（即排序前，栈里的数据是无序的，排序后最大元素位于栈顶），要求最多只能使用一个额外的栈存放临时数据，但不得将元素复制到别的数据结构中。\n\n思路：创建一个辅助栈，按照底大顶小的顺序保存原栈中的数据。\n\n- 从原栈中弹出元素：\n  - 如果辅助栈为空或辅助栈栈顶元素大于当前元素，则该元素进辅助栈\n  - 否则该元素暂时不进，而是不断弹出辅助栈的栈顶元素到原栈中，直到辅助栈为空或辅助栈栈顶元素大于当前元素，将该元素进辅助栈\n- 重复该过程，直到原栈弹空，此时辅助栈中保存了所有元素，并且是按照降序排序的\n- 依次弹出辅助栈中的元素到原栈中，即完成了升序排序\n\n代码：\n\n```java\npublic class StackSort {\n    public static void stackSort(Stack<Integer> stack) {\n        int tmp = 0;\n        Stack<Integer> stackHelper = new Stack<>();\n        stack.isEmpty();\n        // 遍历原始栈，将每个元素压入到辅助栈中\n        while (!stack.isEmpty()) {\n            tmp = stack.pop();\n            // 如果tmp大于辅助栈的栈顶, 则辅助栈一直弹栈直到tmp能进去\n            while (!stackHelper.isEmpty() && tmp > stackHelper.peek()) {\n                stack.push(stackHelper.pop());\n            }\n            // 辅助栈弹够了以后, 就可以把tmp放进去了, 此时能保证辅助栈里的顺序是上面小下面大\n            stackHelper.push(tmp);\n        }\n\n        // 最后再将辅助栈里的元素一一弹出压入原栈中\n        while (!stackHelper.isEmpty()) {\n            stack.push(stackHelper.pop());\n        }\n    }\n}\n```\n\n\n\n## 单调栈\n\n遍历整个数组，使用一个栈记录数组中的元素**索引**。\n\n### 所有元素不重复的情况\n\n- 当寻找某个元素左右距离他最近的比他小的元素时，栈底元素的值小于栈顶元素的值。例如栈中：`[2 -> 3 -> 4(栈顶)`。新来一个元素1，其值小于4，则找到了当前栈顶4左右侧距离他最近的比他小的元素3和1。将4弹出，记录其左右侧的3和1，然后继续。\n- 当寻找某个元素左右距离他最近的比他大的元素时，栈底元素大于栈顶元素。例如栈中：`[4 -> 3 -> 2(栈顶)`。新来一个元素5，其值大于2，则找到了当前栈顶2左右侧距离他最近的比他大的元素3和5。\n\n规律：\n\n- 整体是满足**单调性**的。当发现新来的元素破坏了栈中的单调性时，**将栈顶元素弹出**（其余元素不弹出，新来的元素也不在此时入栈，而是进行下一轮判断是否可以入栈），记录此时新的栈顶元素作为其左侧最近元素，记录新来的元素为其右侧最近元素。\n- **栈中保存的元素始终是按照升序或降序排列的**，肯定满足单调性。这是因为中途破坏单调性的元素都被弹出并记录了，还在栈中的都是单调排序的。\n- 找某个元素左右比他小的，栈中是升序排列；找某个元素左右比他大的，栈中是降序排列。\n\n### 有元素重复的情况\n\n当有元素重复时，栈中不能单单只存储一个 Integer 类型变量，而应该存储一个 ArrayList，将相同值的元素存储到同一个 List 中。\n\n算法整体顺序一致，区别在于弹栈时弹出的是一个 List，需要将这个 List 中的所有元素都遍历一次，加入到 `res[][]` 中；另外，在获取左侧的元素索引值时，需要获取到栈顶第二个 List 里的**最后一个元素**（这个元素是最靠近当前弹出栈的元素的，因为整体是单调的，越靠后的，越在 List 的后面）。\n\n代码：\n\n```java\npublic class MonotonousStack {\n\n   public static int[][] getNearLessNoRepeat(int[] nums) {\n      if (nums == null || nums.length < 1) {\n         return null;\n      }\n\n      Stack<Integer> stack = new Stack<>();\n      int[][] res = new int[nums.length][2];\n\n      for (int i = 0; i < nums.length; i++) {\n         // 如果遇到栈顶元素大于当前元素，说明栈顶元素找到了其左侧小于它的第一个元素（栈顶下的第二个的元素）\n         // 如果新来的元素仍是按照升序或降序排列，则都不会弹栈，因为仍然是符合单调性的，只有在破坏单调性时才弹栈记录\n         while (!stack.isEmpty() && nums[stack.peek()] > nums[i]) {\n            int popIndex = stack.pop();\n            // 弹出的栈顶元素左侧的最小值就是新的栈顶元素（或不存在，对应栈空）\n            int leftLessIndex = stack.isEmpty() ? -1 : stack.peek();\n            // 存储这个栈顶元素的左侧小于它的第一个元素索引 leftLessIndex 和其右边小于它的第一个元素索引 i\n            res[popIndex][0] = leftLessIndex;\n            res[popIndex][1] = i;\n         }\n         // 跳出while循环时，i位置的元素已经能插入到栈中并满足栈中的单调性了，此时将i压入栈中\n         stack.push(i);\n      }\n\n      // 遍历完数组后，栈中可能还存在一些元素，这些元素的最近元素还没保存到res里\n      // 将栈中元素依次弹出，其左侧最近值就是下一个栈中元素，右侧最近值不存在，保存-1\n      while (!stack.isEmpty()) {\n         int popIndex = stack.pop();\n         int leftLessIndex = stack.isEmpty() ? -1 : stack.peek();\n         res[popIndex][0] = leftLessIndex;\n         res[popIndex][1] = -1;\n      }\n      return res;\n   }\n\n\n   public static int[][] getNearLess(int[] nums) {\n      if (nums == null || nums.length < 1) {\n         return null;\n      }\n\n      Stack<List<Integer>> stack = new Stack<>();\n      int[][] res = new int[nums.length][2];\n      for (int i = 0; i < nums.length; i++) {\n         while (!stack.isEmpty() && nums[stack.peek().get(0)] > nums[i]) {\n            // 获取到list集合，里面可能存着多个相同值的元素\n            List<Integer> popList = stack.pop();\n            // 左边最小的元素为新的栈顶集合里的最后一个元素，因为最后一个元素是最靠近当前元素的（因为栈结构的单调性）\n            int leftLessIndex = stack.isEmpty() ? -1 :stack.peek().get(stack.peek().size() - 1);\n            // 遍历当前list里的元素（值相同），为其赋上左边最小元素索引（是相同的）以及右侧元素（i）\n            for (Integer popIndex : popList) {\n               res[popIndex][0] = leftLessIndex;\n               res[popIndex][1] = i;\n            }\n         }\n         // 将i加入到栈中，注意分两种情况：\n         //   1. i的值和当前栈顶元素的值不相同，则新建一个list，将该list入栈\n         //   2. i的值和当前栈顶元素的值相同，则将i加入到栈顶元素的list里的最后一个位置\n         // 注意要带上 !stack.isEmpty() && ，必须要有元素才行\n         if (!stack.isEmpty() && nums[stack.peek().get(0)] == nums[i]) {\n            // 相同时，直接加入到栈顶的list中\n            stack.peek().add(i);\n         } else {\n            // 不同时，新建一个list，入栈\n            List<Integer> list = new ArrayList<>();\n            list.add(i);\n            stack.push(list);\n         }\n      }\n\n      // 全部遍历完毕后，依次弹栈，记录栈中元素的左侧最小信息到res中\n      while (!stack.isEmpty()) {\n         List<Integer> popList = stack.pop();\n         for (Integer popIndex : popList) {\n            int leftLessIndex = stack.isEmpty() ? -1 : stack.peek().get(stack.peek().size() - 1);\n            res[popIndex][0] = leftLessIndex;\n            res[popIndex][1] = -1;\n         }\n      }\n\n      return res;\n   }\n\n   // for test\n   public static int[] getRandomArrayNoRepeat(int size) {\n      int[] arr = new int[(int) (Math.random() * size) + 1];\n      for (int i = 0; i < arr.length; i++) {\n         arr[i] = i;\n      }\n      for (int i = 0; i < arr.length; i++) {\n         int swapIndex = (int) (Math.random() * arr.length);\n         int tmp = arr[swapIndex];\n         arr[swapIndex] = arr[i];\n         arr[i] = tmp;\n      }\n      return arr;\n   }\n\n   // for test\n   public static int[] getRandomArray(int size, int max) {\n      int[] arr = new int[(int) (Math.random() * size) + 1];\n      for (int i = 0; i < arr.length; i++) {\n         arr[i] = (int) (Math.random() * max) - (int) (Math.random() * max);\n      }\n      return arr;\n   }\n\n   // for test\n   public static int[][] rightWay(int[] arr) {\n      int[][] res = new int[arr.length][2];\n      for (int i = 0; i < arr.length; i++) {\n         int leftLessIndex = -1;\n         int rightLessIndex = -1;\n         int cur = i - 1;\n         while (cur >= 0) {\n            if (arr[cur] < arr[i]) {\n               leftLessIndex = cur;\n               break;\n            }\n            cur--;\n         }\n         cur = i + 1;\n         while (cur < arr.length) {\n            if (arr[cur] < arr[i]) {\n               rightLessIndex = cur;\n               break;\n            }\n            cur++;\n         }\n         res[i][0] = leftLessIndex;\n         res[i][1] = rightLessIndex;\n      }\n      return res;\n   }\n\n   // for test\n   public static boolean isEqual(int[][] res1, int[][] res2) {\n      if (res1.length != res2.length) {\n         return false;\n      }\n      for (int i = 0; i < res1.length; i++) {\n         if (res1[i][0] != res2[i][0] || res1[i][1] != res2[i][1]) {\n            return false;\n         }\n      }\n\n      return true;\n   }\n\n   // for test\n   public static void printArray(int[] arr) {\n      for (int i = 0; i < arr.length; i++) {\n         System.out.print(arr[i] + \" \");\n      }\n      System.out.println();\n   }\n\n   public static void main(String[] args) {\n      int size = 10;\n      int max = 20;\n      int testTimes = 2000000;\n      for (int i = 0; i < testTimes; i++) {\n         int[] arr1 = getRandomArrayNoRepeat(size);\n         int[] arr2 = getRandomArray(size, max);\n         if (!isEqual(getNearLessNoRepeat(arr1), rightWay(arr1))) {\n            System.out.println(\"Oops!\");\n            printArray(arr1);\n            break;\n         }\n         if (!isEqual(getNearLess(arr2), rightWay(arr2))) {\n            System.out.println(\"Oops!\");\n            printArray(arr2);\n            break;\n         }\n      }\n   }\n}\n```\n\n## 单调栈的相关题目\n\n### 数组中累积和与最小值的乘积\n\n定义指标A：正数数组中累积和与最小值的乘积。给定一个数组，请返回子数组中，指标A最大的值。\n\n该问题可以使用单调栈结构进行求解。思路：\n\n- 遍历每一个元素，以该元素作为当前子区间内的最小值元素（其子区间内的元素都比当前元素大）；\n- 尽可能的扩大该子区间的范围，使得当前元素为最小值的子区间范围尽可能的大，这样其数组中的累加和就会尽可能的大；\n- 找到当前元素左右侧区间边界的方法为：使用单调栈找出当前元素左侧和右侧距离他最近的比他小的元素\n- 对数组中每个元素都进行该操作，直到找出最大的指标A\n- 可以在单调栈的建立过程中更新最大的指标A，无需创建索引后再单独计算\n\n代码：\n\n``` java\npublic class MonotonousStack {\n    public static int solution(int[] nums) {\n        if (nums == null || nums.length < 1) {\n            return -1;\n        }\n\n        // 数组的前缀累加和\n        int[] sums = new int[nums.length];\n        // 初始化第一个元素\n        sums[0] = nums[0];\n        // 遍历每一个元素,计算前缀累加和\n        for (int i = 1; i < nums.length; i++) {\n            sums[i] = sums[i - 1] + nums[i];\n        }\n\n        Stack<Integer> stack = new Stack<>();\n        // 记录答案\n        int max = Integer.MIN_VALUE;\n        for (int i = 0; i < nums.length; i++) {\n            // 注意单调栈里保存的是索引值\n            // 如果当前栈顶元素大于新来的元素,则找到了当前栈顶元素左右离他最近的元素,将其弹出\n            // 注意是 while 循环，不断判断当前元素 nums[i] 与新的栈顶的大小，可能会一直弹出\n            while (!stack.isEmpty() && nums[stack.peek()] >= nums[i]) {\n                // 弹出栈顶元素，更新指标A的最大值\n                // 注意这两个边界值的元素值都比当前元素小\n                int j = stack.pop();\n                // 1. 如果栈空，则不存在比他小的左边界，可以一直取到nums[0]，则当前子区间的累加和等于sums[i-1]（不能包含i值，因为其小于nums[j]）\n                // 2. 如果栈不为空，则存在比他小的左边界且该边界值取不到，则当前子区间的累加和等于sums[i - 1] - sums[stack.peek()]\n                max = Math.max(max, (stack.isEmpty() ? sums[i - 1] : (sums[i - 1] - sums[stack.peek()])) * nums[j]);\n            } \n            // 新来的元素入栈\n            stack.push(i);\n        }\n        // 最后将栈里剩余元素进行设置\n        while (!stack.isEmpty()) {\n            int j = stack.pop();\n            // 当前栈中元素都不存在比他小的右边界，所以右边界从sums[size - 1]开始取\n            max = Math.max(max, (stack.isEmpty() ? sums[size - 1] : (sums[size - 1] - sums[stack.peek()])) * arr[j]);\n        }\n        return max;\n    }\n}\n```\n\n\n\n### 柱状图中最大的矩形\n\n[柱状图中最大的矩形](https://leetcode-cn.com/problems/largest-rectangle-in-histogram/)：给定 *n* 个非负整数，用来表示柱状图中各个柱子的高度。每个柱子彼此相邻，且宽度为 1 。求在该柱状图中，能够勾勒出来的矩形的最大面积。\n\n<img src=\"/images/%E3%80%90%E7%AE%97%E6%B3%95%E3%80%91%E5%8D%95%E8%B0%83%E6%A0%88/image-20211215154559108.png\" alt=\"image-20211215154559108\" style=\"zoom:50%;\" />\n\n该问题即为上一题的具体形式，同样可以使用单调栈进行求解。\n\n\n\n\n\n\n\n","tags":["算法","数据结构"],"categories":["算法","数据结构"]},{"title":"【Redis】Redis 分布式锁","url":"/2021/09/15/【Redis】Redis分布式锁/","content":"\n![image-20210913131720145](/images/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/image-20210913131720145.png)\n\n## 分布式锁简介\n\n随着业务发展的需要，原单体单机部署的系统被演化成分布式集群系统后，由于分布式系统多线程、多进程并且分布在不同机器上，这将使原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题。\n\n分布式锁主流的实现方案：\n\n-  基于数据库实现分布式锁\n- 基于缓存（Redis等，将key存储在缓存中）\n- 基于 ZooKeeper（将key存储在ZooKeeper中）\n\n每一种分布式锁解决方案都有各自的优缺点：\n\n- 高性能：Redis（AP），但其无法保证主从机器上的缓存数据是一致的，可能主机刚保存了某个锁，还未同步给从机，自己就宕机了。在哨兵机制选举出了另一台主机后，其内并不存在该锁，故此前加的分布式锁失效，但其能保证高性能，而不像ZooKeeper一样主从同步时服务无法访问。\n- 可靠性：ZooKeeper（CP），能够保证数据的一致性，主机收到的加锁消息会在同步给所有从机后再一起添加到缓存中，此时即可以保证分布式锁数据高度一致，但是缺点是同步期间服务无法访问，性能降低。\n\n本文将介绍基于Redis的分布式锁实现方式。\n\n<!-- More -->\n\n## 阶段一：未加锁时\n\n在未加锁时，不论是单机应用还是分布式应用，都会出现超卖问题，原因：\n\n- 某个线程先进行get判断，发现库存有剩余，就准备执行减库存操作。\n- 而在其减库存操作完成之前，另一个线程进行了get判断，也发现库存有剩余，此时该线程也会执行减库存操作，从而造成同一个商品被消费两次。\n\n``` java\n@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n\n@GetMapping(\"/buy_goods\")\npublic String buy_Goods(){\n    String result = stringRedisTemplate.opsForValue().get(\"goods:001\");// get key ==== 看看库存的数量够不够\n\n    int goodsNumber = result == null ? 0 : Integer.parseInt(result);\n    if(goodsNumber > 0){\n        int realNumber = goodsNumber - 1;\n\n        stringRedisTemplate.opsForValue().set(\"goods:001\", String.valueOf(realNumber));\n        System.out.println(\"成功买到商品，库存还剩下: \"+ realNumber + \" 件\" + \"\\t服务提供端口\" + serverPort);\n\n        return \"成功买到商品，库存还剩下:\" + realNumber + \" 件\" + \"\\t服务提供端口\" + serverPort;\n    }else{\n        System.out.println(\"商品已经售完/活动结束/调用超时,欢迎下次光临\" + \"\\t服务提供端口\" + serverPort);\n    }\n\n    return \"商品已经售完/活动结束/调用超时,欢迎下次光临\" + \"\\t服务提供端口\" + serverPort;\n}\n```\n\n## 版本二：单机版锁\n\n使用 `synchronized` 关键字或 JUC 的 `ReentraLock` 类可实现单机版锁：\n\n``` java\nclass X {\n    private final ReentrantLock lock = new ReentrantLock();\n    // ...\n\n    public void m() {\n        lock.lock();  // block until condition holds // 不见不散\n        try {\n            // ... method body\n        } finally {\n            lock.unlock()\n        }\n    }\n\n    public void m2() {\n\n        if(lock.tryLock(timeout, unit)){ // 过时不候\n            try {\n                // ... method body\n            } finally {\n                lock.unlock()\n            }   \n        }else{\n            // perform alternative actions\n        }\n    }\n}\n```\n\n但其对分布式应用的超卖问题仍无法解决。\n\n## 版本三： 分布式锁 SETNX\n\n使用 Redis 提供的 SET 命令添加分布式锁：\n\n``` bash\nSET sku:1:info “OK” NX PX 10000\n```\n\n参数解读：\n\n- `EX second` ：设置键的过期时间为 second 秒。 `SET key value EX second` 效果等同于 `SETEX key second value` \n- `PX millisecond` ：设置键的过期时间为 millisecond 毫秒。 `SET key value PX millisecond` 效果等同于 `PSETEX key millisecond value` \n- `NX` ：只在键不存在时，才对键进行设置操作。 `SET key value NX` 效果等同于 `SETNX key value` \n- `XX` ：只在键已经存在时，才对键进行设置操作\n\n![image-20210915191119081](/images/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/image-20210915191119081.png)\n\nJava 代码：\n\n``` java\npublic static final String REDIS_LOCK = \"redis_lock\";\n\n@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n\npublic void m(){\n    String value = UUID.randomUUID().toString() + Thread.currentThread().getName();\n\n    Boolean flag = stringRedisTemplate.opsForValue()\n        .setIfAbsent(REDIS_LOCK, value);\n    if(!flag) {\n        return \"抢锁失败\";\n    }\n    // 业务逻辑...\n    stringRedisTemplate.delete(REDIS_LOCK);\n}\n```\n\n其仍然存在的问题：\n\n- 出现异常时，可能无法释放锁，必须要在代码层面 **finally** 释放锁。\n- 部署了微服务jar包的机器挂了，代码层面根本没有走到finally这块，没办法保证解锁，这个key没有被删除，需要加入一个**过期时间**限定key。\n\n## 版本四：设置超时时间\n\n使用 SET 命令时指定过期时间，同时**保证加锁和设置超时时间是原子性的**：\n\n``` java\npublic static final String REDIS_LOCK = \"redis_lock\";\n\n@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n\npublic void m(){\n    String value = UUID.randomUUID().toString() + Thread.currentThread().getName();\n\n    try {\n        // 原子性操作，保证加锁和设置超时时间是原子性的\n        Boolean flag = stringRedisTemplate.opsForValue()\n            .setIfAbsent(REDIS_LOCK, value, 10L, TimeUnit.SECONDS);\n        if(!flag) {\n            return \"抢锁失败\";\n        }\n        //业务逻辑...\n    } finally{\n        stringRedisTemplate.delete(REDIS_LOCK);   \n    }\n}\n```\n\n**另一个新问题**：误删别人的锁。\n\n可能第一个线程执行时间过长，在其删除自己上的锁之前，锁就已经过期了。此时再来一个线程上了锁，而第一个线程执行完业务后会删掉第二个线程上的锁：\n\n![img](/images/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/8491f7f7a87dcc888d60141f6d662e1b.png)\n\n解决方法：给锁添加UUID，保证每个线程只能删除自己创建的锁。\n\n## 版本五：添加 UUID 防止误删除\n\n给每个线程创建独一无二的UUID，将其作为锁的value，防止误删。\n\n![image-20210915192157172](/images/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/image-20210915192157172.png)\n\n``` java\npublic static final String REDIS_LOCK = \"redis_lock\";\n\n@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n\npublic void m(){\n    // 每个线程创建独一无二的UUID，防止误删\n    String value = UUID.randomUUID().toString() + Thread.currentThread().getName();\n\n    try{\n        Boolean flag = stringRedisTemplate.opsForValue()\n            .setIfAbsent(REDIS_LOCK, value, 10L, TimeUnit.SECONDS);\n        if(!flag) {\n            return \"抢锁失败\";\n        }\n        // 业务逻辑...       \n    } finally {\n        // 判断UUID和自己相等才能删（仍存在问题：判断和删除的操作不是原子性的）\n        if(stringRedisTemplate.opsForValue().get(REDIS_LOCK).equals(value)) {\n            stringRedisTemplate.delete(REDIS_LOCK);\n        }\n    }\n}\n```\n\n新的问题：finally 块里判断UUID是否和自己相等的代码和删除锁的代码不是原子性的，可能出现情况：\n\n- 第一个线程在其加的锁即将结束前，查询到了该锁的value，并返回与自己本地存的UUID判断是否相等（对应上述 if 判断里的代码）\n- 而第一个线程刚查询完，还没返回和自己本地存的UUID判断前，该锁过期了；\n- 此时第二个线程创建了他自己的锁，其UUID显然与第一个线程本地存的UUID不同；\n- 第一个线程此时再删除锁时，就会把第二个线程创建的锁删掉，仍然没解决误删除的问题\n\n解决此问题的方法为：\n\n- **使用LUA脚本将判断与删除的操作变成原子性的。**\n- 使用 Redis 的事务机制，监视加的锁。\n\n### 版本六：LUA 脚本保证删除原子性\n\n ``` java\nimport redis.clients.jedis.JedisPool;\nimport redis.clients.jedis.JedisPoolConfig;\n\npublic class RedisUtils {\n\tprivate static JedisPool jedisPool;\n\t\n\tstatic {\n\t\tJedisPoolConfig jpc = new JedisPoolConfig();\n\t\tjpc.setMaxTotal(20);\n\t\tjpc.setMaxIdle(10);\n\t\tjedisPool = new JedisPool(jpc);\n\t}\n\t\n\tpublic static JedisPool getJedis() throws Exception{\n\t\tif(jedisPool == null)\n\t\t\tthrow new NullPointerException(\"JedisPool is not OK.\");\n\t\treturn jedisPool;\n\t}\t\n}\n ```\n\n``` java\npublic static final String REDIS_LOCK = \"redis_lock\";\n\n@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n\npublic void m(){\n    String value = UUID.randomUUID().toString() + Thread.currentThread().getName();\n\n    try{\n        Boolean flag = stringRedisTemplate.opsForValue()\n            .setIfAbsent(REDIS_LOCK, value, 10L, TimeUnit.SECONDS);\n\n        if(!flag) {\n            return \"抢锁失败\";\n        }\n        // 业务逻辑...       \n    } finally {\n        Jedis jedis = RedisUtils.getJedis();\n\n        String script = \"if redis.call('get', KEYS[1]) == ARGV[1] \"\n            + \"then \"\n            + \"    return redis.call('del', KEYS[1]) \"\n            + \"else \"\n            + \"    return 0 \"\n            + \"end\";\n\n        try {\n            Object o = jedis.eval(script, Collections.singletonList(REDIS_LOCK),// \n                                  Collections.singletonList(value));\n\n            if(\"1\".equals(o.toString())) {\n                System.out.println(\"---del redis lock ok.\");\n            }else {\n                System.out.println(\"---del redis lock error.\");\n            }\n\n        } finally {\n            if(jedis != null) \n                jedis.close();\n        }\n    }\n}\n```\n\n同时使用事务解决原子性的方式：\n\n``` java\npublic static final String REDIS_LOCK = \"redis_lock\";\n\n@Autowired\nprivate StringRedisTemplate stringRedisTemplate;\n\npublic void m(){\n    String value = UUID.randomUUID().toString() + Thread.currentThread().getName();\n\n    try{\n        Boolean flag = stringRedisTemplate.opsForValue()\n            .setIfAbsent(REDIS_LOCK, value, 10L, TimeUnit.SECONDS);\n        if(!flag) {\n            return \"抢锁失败\";\n        }\n        // 业务逻辑...\n    } finally {\n        while(true) {\n            stringRedisTemplate.watch(REDIS_LOCK);\n            if(stringRedisTemplate.opsForValue().get(REDIS_LOCK).equalsIgnoreCase(value)){\n                stringRedisTemplate.setEnableTransactionSupport(true);\n                stringRedisTemplate.multi();\n                stringRedisTemplate.delete(REDIS_LOCK);\n                List<Object> list = stringRedisTemplate.exec();\n                if (list == null) {\n                    continue;\n                }\n            }\n            stringRedisTemplate.unwatch();\n            break;\n        } \n    }\n}\n```\n\n仍然存在的问题：我们自己设置的过期时间可能会在业务代码执行完毕前到期，不能做到自动续期，解决方法：使用 **Redisson** 中的 **Reentrant Lock**，利用其看门狗机制实现过期时间自动续期。\n\n## Redisson\n\n> 官方文档：https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95\n\nRedisson是一个在 Redis 的基础上实现的 Java 驻内存数据网格（In-Memory Data Grid），提供了分布式和可扩展的 Java 数据结构。其特点：\n\n- 基于 Netty 实现，采用非阻塞 IO，性能高\n- 支持异步请求\n- 支持连接池、pipeline、LUA Scripting、Redis Sentinel、Redis Cluster 不支持事务，官方建议以 LUA Scripting 代替事务\n- 主从、哨兵、集群都支持。Spring 也可以配置和注入 RedissonClient。\n- 实现分布式锁：在 Redisson 里面提供了更加简单的分布式锁的实现。\n\n### 导入依赖\n\n``` xml\n<!-- redisson -->\n<dependency>\n    <groupId>org.redisson</groupId>\n    <artifactId>redisson</artifactId>\n    <version>3.12.0</version>\n</dependency>\n\n<!-- 与 spring boot 整合 -->\n<!-- redisson-spring-boot-starter -->\n<dependency>\n    <groupId>org.redisson</groupId>\n    <artifactId>redisson-spring-boot-starter</artifactId>\n    <version>3.12.0</version>\n</dependency>\n```\n\n### 程序化配置\n\nRedisson程序化的配置方法是通过构建`Config`对象实例来实现的，使用`Config`对象创建出**RedissonClient**对象，后续所有对Redisson的使用都借助于**RedissonClient**对象。\n\n``` java\n@Configuration\npublic static class Application {\n    // 集群模式\n    @Bean(destroyMethod=\"shutdown\")\n    public RedissonClient redisson() throws IOException {\n        Config config = new Config();\n        config.useClusterServers()\n            .addNodeAddress(\"redis://127.0.0.1:7004\", \"redis://127.0.0.1:7001\"); // 可以用\"rediss://\"来启用SSL连接\n        return Redisson.create(config);\n    }\n\n    // 单节点模式\n    @Bean(destroyMethod=\"shutdown\")\n    public RedissonClient redisson() throws IOException {\n        Config config = new Config();\n        config.useSingleServer().setAddress(\"redis://myredisserver:6379\");\n        return Redisson.create(config);\n    }\n}\n```\n\n后续将使用**RedissonClient**进行各种操作。\n\n### 可重入锁 Reentrant Lock\n\n基于Redis的Redisson分布式可重入锁[`RLock`](http://static.javadoc.io/org.redisson/redisson/3.10.0/org/redisson/api/RLock.html) 。其实现了`java.util.concurrent.locks.Lock`接口。同时还提供了[异步（Async）](http://static.javadoc.io/org.redisson/redisson/3.10.0/org/redisson/api/RLockAsync.html)、[反射式（Reactive）](http://static.javadoc.io/org.redisson/redisson/3.10.0/org/redisson/api/RLockReactive.html)和[RxJava2标准](http://static.javadoc.io/org.redisson/redisson/3.10.0/org/redisson/api/RLockRx.html)的接口。\n\n该类可实现分布式锁的效果，原理为：在Redis缓存创建了一把锁，其他线程再想获取锁时就得阻塞等待该锁从Redis缓存中删除（底层有一个`while(true)`循环不断尝试获取锁）。\n\n方式一：不手动指定过期时间，使用**看门狗默认的过期时间+自动续期策略**：\n\n``` java\n// redisson 是上文中注入到容器中的 RedissonClient 对象\nRLock lock = redisson.getLock(\"myLock\");  // 设置锁名\n\n// 加锁，若其他线程发现该锁已经被锁上，则阻塞式等待其他线程解锁后才继续运行\nlock.lock();\n\ntry {\n    // 业务...\n} finally {\n    // 解锁\n    lock.unlock();\n\n    // 严谨的写法：\n    if (lock.isLocked() && lock.isHeldByCurrentThread()) {\n        lock.unlock();\n    }\n}\n\n\n```\n\n流程：\n\n- 当前线程在执行 `lock()` 后，将在Redis缓存中创建一个锁（**Hash**结构），其key值为`\"myLock\"`，其内存储了`key = uuid:线程号, value = 1`，代表当前线程对象拥有了该锁；\n- 此时其他线程再调用`lock()` 时将发现Redis缓存中已经存在了`\"myLock\"`锁，因此会**阻塞等待**（`while(true)`循环判断锁是否还在）；\n- 等待当前线程调用 `unlock()` 后，该`\"myLock\"`锁将从Redis缓存中移除，此时其他线程才可以结束阻塞，创建另一把锁，即再在Redis缓存中创建一个`\"myLock\"` 。\n\n上述方式的细节：\n\n- 锁的**自动续期**：如果业务超长，运行期间自动会给锁续期到30s，不用担心业务时间长，锁自动过期被删掉。\n- 加锁的业务只要**运行完成**，就不会给当前锁续期，即使不手动解锁，锁也默认也会在30s后自动删除。\n\n方式二：**手动**设置超时时间：\n\n``` java\nlock.lock(10, TimeUnit.SECONDS);\n```\n\n上述代码设置10s后自动解锁（不会自动续期），这个时间一定要大于业务的执行时间，否则锁过期后再`unlock()`，解锁的就是别的线程加的锁，此时就会报错uuid不匹配。\n\n**自动续期原理**：\n\n- 如果我们给锁指定了超时时间，就给Redis发送LUA脚本进行占锁且设置超时时间的操作（保证z占锁和设置超时时间的原子性）\n- 如果我们未指定锁的超时时间，就设置超时时间为**LockWatchdogTimeout**（看门狗）的默认时间30s。如果占锁成功，就会返回一个 `RFuture<Long>` 对象，异步监听一个**定时任务**（用于给锁重新设置超时时间，新的超时时间就是看门狗的默认时间30s），之后每隔10s（三分之一的看门狗默认时间）就会将超时时间续期到30s\n\n**最佳实战**：使用 `lock.lock(30, TimeUnit.SECONDS);` 方式，将超时时间设置的大一些，手动解锁。这样的好处是省掉了频繁续期的操作。\n\n方式三：**尝试加锁**，等待一定时间还未拿到锁就放弃加锁。\n\n`lock()` 方法会阻塞等待直到获取到锁。若不想阻塞等待，可以使用` tryLock()` 方法，其会阻塞等待一定时间后停止等待，即放弃尝试加锁：\n\n``` java\n// 尝试加锁，最多等待100秒，上锁以后10秒自动解锁\nboolean res = lock.tryLock(100, 10, TimeUnit.SECONDS);\nif (res) {\n   try {\n     ...\n   } finally {\n       lock.unlock();\n   }\n}\n```\n\n### 读写锁 RReadWriteLock\n\n读写锁 **RReadWriteLock** 用于保证一定能读取到最新数据，用法是：在**改数据时加写锁**，在**读数据时加读锁**。修改数据期间：\n\n- 写锁是一个**排他锁**（互斥锁/独占锁）\n- 读锁是一个**共享锁**。\n\n写锁如果没有释放，读锁就得一直阻塞等待。\n\n``` java\nRReadWriteLock lock = redisson.getReadWriteLock(\"rw-lock\");\n```\n\n改数据时加写锁：\n\n``` java\nRLock wlock = lock.writeLock();\nwLock.lock();\n\n// ...\n\nwlock.unlock();\n```\n\n读数据时加读锁：\n\n``` java\nRLock rlock = lock.readLock();\nrLock.lock();\n\n// ...\n\nrlock.unlock();\n```\n\n某个线程开启写锁时，其他线程的读锁就会阻塞等待，写锁当然也会阻塞等待。\n\n四种不同情况下的锁：\n\n- **读 + 读**：相当于无锁，并发读。只会分别在Redis中记录当前的读锁，会同时添加锁成功，不会阻塞\n- **写 + 读**：读锁阻塞等待写锁释放才能读\n- **写 + 写**：后来的写锁阻塞等待前一个写锁释放才能写\n- **读 + 写**：后来的写锁阻塞等待其他读锁释放才能写（防止前一个线程还没读到数据就被后来的线程修改了）\n\n**总结：只要有写锁的存在，无论是先写还是后写，都必须阻塞等待。**\n\n### 信号量 RSemaphore\n\n信号量机制可以用来做分布式**限流**。\n\n情景：先在Redis中创建一个`key: \"park\", value=3`，代表当前共有三个车位（三个信号）。之后客户端多次获取信号，直到Redis中`\"park\"`的信号量为0，代表没有多余的信号给客户端了。此后再想来获取信号的客户端就会阻塞等待其他客户端释放信号，才能继续获取到信号。\n\n获取一个信号：获取一个值，占一个车位\n\n``` java\nRSemaphore park = redisson.getSemaphore(\"park\");\npark.acquire();\n\n// 不阻塞等待，没有信号就放弃获取信号\nboolean b = park.tryAcquire();\nif (b) {\n    // 执行业务\n} else {\n    return \"error\";\n}\n```\n\n释放一个信号：释放一个车位\n\n``` java\nRSemaphore park = redisson.getSemaphore(\"park\");\npark.release();\n```\n\n### 闭锁 RCountDownLatch\n\n基于Redisson的分布式闭锁（[CountDownLatch](http://static.javadoc.io/org.redisson/redisson/3.10.0/org/redisson/api/RCountDownLatch.html)）。Java对象`RCountDownLatch`采用了与`java.util.concurrent.CountDownLatch`相似的接口和用法。\n\n``` java\nRCountDownLatch latch = redisson.getCountDownLatch(\"anyCountDownLatch\");\nlatch.trySetCount(5); \nlatch.await(); // 阻塞等待5个数都减掉\n\n// 在其他线程或其他JVM里\nRCountDownLatch latch = redisson.getCountDownLatch(\"anyCountDownLatch\");\nlatch.countDown(); // 计数减一\n\n```\n\n\n\n","tags":["Redis","分布式"],"categories":["Redis","分布式"]},{"title":"【JUC】JUC 各种锁","url":"/2021/09/14/【JUC】JUC锁/","content":"\n## JUC 简介\n\nJUC 就是 `java.util .concurrent` 工具包的简称。这是一个处理线程的工具包，JDK 1.5开始出现的。\n\n更多笔记：https://github.com/Seazean/JavaNotes/blob/main/Prog.md\n\n<!-- More -->\n\n## Synchronized 和 Lock 的区别\n\n`synchronized`关键字和`java.util.concurrent.locks.Lock`都能加锁，两者有什么区别呢？\n\n- **原始构成**：`sync`是JVM层面的，底层通过`monitorenter`和`monitorexit`来实现的。`Lock`是JDK API层面的。（`sync`一个`enter`会有两个`exit`，一个是正常退出，一个是异常退出）\n- **使用方法**：`sync`不需要手动释放锁（若发生异常也会自动释放），而`Lock`需要手动释放`unlock()`（通常写在finally代码块中防止发生异常无法释放同步监视器）\n- **是否可中断**：`sync`不可中断，除非抛出异常或者正常运行完成。`Lock`是可中断的，通过调用`interrupt()`方法。\n- **是否为公平锁**：`sync`只能是非公平锁，而`Lock`既能是公平锁，又能是非公平锁。\n- **绑定多个条件**：`sync`不能，只能随机唤醒。而`Lock`可以通过`Condition`来绑定多个条件，精确唤醒。\n\n在高并发场景下，`Lock` 的性能远优于 `synchronized`。\n\n优先使用顺序：`Lock `——> 同步代码块（已经进入了方法体，分配了相应资源）——> 同步方法（在方法体之外）\n\n## 死锁\n\n两个或者两个以上线程在执行过程中，因为争夺资源而造成一种互相等待的现象。如果没有外力干涉，他们无法在执行下去。\n\n产生死锁的原因：\n\n- 系统资源不足\n- 进程运行推进顺序不合适\n- 资源分配不当\n\n发生死锁的四个条件：\n\n1. 互斥条件，线程使用的资源至少有一个不能共享的。\n2. 至少有一个线程必须持有一个资源**且**正在等待获取一个当前被别的线程持有的资源。\n3. 资源不能被抢占。\n4. 循环等待。\n\n![img](/images/%E3%80%90JUC%E3%80%91JUC%E9%94%81/5d9a16c9c88e8676d9c8df8ecf9a4d4f.png)\n\n死锁案例：\n\n``` java\npublic class DeadLock {\n\n    //创建两个对象\n    static Object a = new Object();\n    static Object b = new Object();\n\n    public static void main(String[] args) {\n        new Thread(()->{\n            synchronized (a) {\n                System.out.println(Thread.currentThread().getName()+\" 持有锁a，试图获取锁b\");\n                try {\n                    TimeUnit.SECONDS.sleep(1);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                synchronized (b) {\n                    System.out.println(Thread.currentThread().getName()+\" 获取锁b\");\n                }\n            }\n        },\"A\").start();\n\n        new Thread(()->{\n            synchronized (b) {\n                System.out.println(Thread.currentThread().getName()+\" 持有锁b，试图获取锁a\");\n                try {\n                    TimeUnit.SECONDS.sleep(1);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                synchronized (a) {\n                    System.out.println(Thread.currentThread().getName()+\" 获取锁a\");\n                }\n            }\n        },\"B\").start();\n    }\n}\n```\n\n\n\n**验证是否是死锁**\n\n1.  jps 类似于linux中的`ps -ef`查看进程号\n2.  jstack 自带的堆栈跟踪工具\n\n通过用idea自带的命令行输入 `jps -l`，查看其编译代码的进程号后使用 `jstack 进程号`查看进程堆栈信息。死锁验证截图：\n\n![img](/images/%E3%80%90JUC%E3%80%91JUC/9bd90c95c5da45fe8fe49852733c1370.png)\n\n## 公平锁与非公平锁\n\n**概念**：所谓**公平锁**，就是多个线程按照**申请锁的顺序**来获取锁，类似排队，先到先得。而**非公平锁**，则是多个线程抢夺锁，会导致**优先级反转**或**饥饿现象**。\n\n**区别**：公平锁在获取锁时先查看此锁维护的**等待队列**，**为空**或者当前线程是等待队列的**队首**，则直接占有锁，否则插入到等待队列，FIFO原则。非公平锁比较粗鲁，上来直接**先尝试占有锁**，失败则采用公平锁方式。非公平锁的优点是**吞吐量**比公平锁更大。\n\n- 公平锁：效率相对低，线程不会饿死\n- 非公平锁：效率高，但线程可能饿死\n\n 非公平锁可能造成其他线程饿死的情况，即某一个线程拿着锁一直工作，其他线程一直拿不到锁。\n\n`synchronized`和`ReentrantLock`默认都是**非公平锁**。`ReentrantLock`在构造的时候传入`true`则是**公平锁**：\n\n``` java\nReentrantLock lock = new ReentrantLock(true);\n```\n\n不传参时，使用的是非公平锁；传入true时使用的是公平锁：\n\n![image-20210917094529785](/images/%E3%80%90JUC%E3%80%91JUC/image-20210917094529785.png)\n\n`FairSync` 内：\n\n![image-20210917094646045](/images/%E3%80%90JUC%E3%80%91JUC/image-20210917094646045.png)\n\n\n\n## 可重入锁\n\n`synchronized `和 `Lock `（`ReentrantLock`）都是可重入锁（又称为递归锁）。`synchronized `是隐式锁，不用手工上锁与解锁，而 `Lock ` （`ReentrantLock`）为显式锁，需要手工上锁与解锁。\n\n**可重入锁作用：避免某一对象递归调用同一方法时产生死锁**，一个线程拿到了外层的锁就可以无视内部的锁。**前提：必须是同一把锁**\n\n有了可重入锁之后，破解第一把锁之后就可以一直进入到内层结构，直接无视内部的其他锁。也就是说，线程可以进入任何一个它已经拥有的锁所同步着的代码块（只能进入同一把锁的同步代码块）。\n\n比如`get`方法里面有`set`方法，两个方法都有同一把锁，得到了`get`的锁，就自动得到了`set`的锁。就像有了家门的锁，厕所、书房、厨房就为你敞开了一样。\n\n```java\npackage concurrent.reentrantlock;\n\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\n\npublic class ReentrantLockDemo {\n    public static void main(String[] args) {\n        Phone phone=new Phone();\n        syncTest(phone);\n        System.out.println();\n\n        Thread t3=new Thread(phone);\n        Thread t4=new Thread(phone);\n        t3.start();\n        t4.start();\n\n    }\n\n    private static void syncTest(Phone phone) {\n\n        new Thread(()->{\n            try{\n                phone.sendSMS();\n            }catch (Exception e){\n                e.printStackTrace();\n            }\n        },\"t1\").start();\n\n        new Thread(()->{\n            try{\n                phone.sendSMS();\n            }catch (Exception e){\n                e.printStackTrace();\n            }\n        },\"t2\").start();\n    }\n}\n\nclass Phone implements Runnable {\n    //Synchronized TEST\n\n    public synchronized void sendSMS(){\n        System.out.println(Thread.currentThread().getId()+\"\\t\"+\"sendSMS()\");\n        sendEmail();\n    }\n    public synchronized void sendEmail(){\n        System.out.println(Thread.currentThread().getId()+\"\\t\"+\"sendEmail()\");\n    }\n\n    //Reentrant TEST\n    Lock lock = new ReentrantLock();\n    @Override\n    public void run() {\n        get();\n    }\n    public void get(){\n        lock.lock();\n        try{\n            System.out.println(Thread.currentThread().getId()+\"\\t\"+\"get()\");\n            set();\n        }finally {\n            lock.unlock();\n        }\n    }\n    public void set(){\n        lock.lock();\n        try{\n            System.out.println(Thread.currentThread().getId()+\"\\t\"+\"set()\");\n        }finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n\n\n### 案例\n\n下面分别为`synchronized `和 `Lock `锁的演示。注意：他们加的是同一把锁。若锁不同，还是无法进入。\n\n``` java\nObject o = new Object();\nnew Thread(()->{\n    synchronized(o) {\n        System.out.println(Thread.currentThread().getName() + \" 外层\");\n\n        synchronized (o) {\n            System.out.println(Thread.currentThread().getName() + \" 中层\");\n\n            synchronized (o) {\n                System.out.println(Thread.currentThread().getName() + \" 内层\");\n            }\n        }\n    }\n\n},\"t1\").start();\n```\n\n``` java\npublic class SyncLockDemo {\n\n    public synchronized void add() {\n        add();\n    }\n\n    public static void main(String[] args) {\n        // Lock演示可重入锁\n        Lock lock = new ReentrantLock();\n        // 创建线程\n        new Thread(()->{\n            try {\n                // 上锁\n                lock.lock();\n                System.out.println(Thread.currentThread().getName()+\" 外层\");\n\n                try {\n                    // 上锁\n                    lock.lock();\n                    System.out.println(Thread.currentThread().getName()+\" 内层\");\n                }finally {\n                    // 释放锁\n                    lock.unlock();\n                }\n            }finally {\n                // 释放锁\n                lock.unlock();\n            }\n        },\"t1\").start();\n\n        // 创建新线程\n        new Thread(()->{\n            lock.lock();\n            System.out.println(\"aaaa\");\n            lock.unlock();\n        },\"aa\").start();\n    }\n}\n\n```\n\n### 锁的配对\n\n锁之间要配对，加了几把锁，最后就得解开几把锁，下面的代码编译和运行都没有任何问题。但锁的数量不匹配会导致死循环。\n\n```java\nlock.lock();\nlock.lock();\n\ntry{\n    someAction();\n}finally{\n    lock.unlock();\n}\n```\n\n## 自旋锁\n\n**SpinLock**：所谓自旋锁，就是尝试获取锁的线程不会**立即阻塞**，而是采用**循环的方式去尝试获取**。自己在那儿一直循环获取，就像“**自旋**”一样。这样的好处是减少**线程切换的上下文开销**，缺点是会**消耗CPU**。CAS底层的`getAndAddInt`就是**自旋锁**思想。\n\n> 提到了互斥同步对性能最大的影响阻塞的实现，挂起线程和恢复线程的操作都需要转入内核态完成，这些操作给系统的并发性能带来了很大的压力。同时，虚拟机的开发团队也注意到在许多应用上，**共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和恢复线程并不值得**。如果物理机器有一个以上的处理器，能让两个或以上的线程同时并行执行，我们就可以让后面请求锁的那个线程 “稍等一下”，但不放弃处理器的执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需让线程执行一个忙循环（自旋），这项技术就是所谓的自旋锁。\n>\n> 《深入理解JVM.2nd》Page 398\n\n``` java\n// 跟CAS类似，一直循环比较。\nwhile (!atomicReference.compareAndSet(null, thread)) { }\n```\n\n基于原子引用手写一个自旋锁 `AtomicReference<Thread>` ：\n\n```java\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicReference;\n\npublic class SpinLockDemo {\n    // 现在的泛型装的是Thread，原子引用线程\n    AtomicReference<Thread>  atomicReference = new AtomicReference<>();\n\n    public void myLock() {\n        // 获取当前进来的线程\n        Thread thread = Thread.currentThread();\n        System.out.println(Thread.currentThread().getName() + \"\\t come in \");\n\n        // 开始自旋，期望值是null，更新值是当前线程，如果是null，则更新为当前线程，否者自旋\n        while(!atomicReference.compareAndSet(null, thread)) {\n            //摸鱼\n        }\n    }\n\n    public void myUnLock() {\n        // 获取当前进来的线程\n        Thread thread = Thread.currentThread();\n\n        // 自己用完了后，把atomicReference变成null\n        atomicReference.compareAndSet(thread, null);\n\n        System.out.println(Thread.currentThread().getName() + \"\\t invoked myUnlock()\");\n    }\n\n    public static void main(String[] args) {\n        SpinLockDemo spinLockDemo = new SpinLockDemo();\n\n        // 启动t1线程，开始操作\n        new Thread(() -> {\n\n            // 开始占有锁\n            spinLockDemo.myLock();\n\n            try {\n                TimeUnit.SECONDS.sleep(5);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n            // 开始释放锁\n            spinLockDemo.myUnLock();\n\n        }, \"t1\").start();\n\n\n        // 让main线程暂停1秒，使得t1线程，先执行\n        try {\n            TimeUnit.SECONDS.sleep(1);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n        // 1秒后，启动t2线程，开始占用这个锁\n        new Thread(() -> {\n\n            // 开始占有锁\n            spinLockDemo.myLock();\n            // 开始释放锁\n            spinLockDemo.myUnLock();\n\n        }, \"t2\").start();\n    }\n}\n```\n\n## 读写锁\n\n> 读写锁设计主要解决什么问题？用于**读多写少**情况下读操作**不会阻塞等待**，**提高并发性**\n\n**读锁**是**共享的**，**写锁**是**独占的**。`ReentrantLock`和`synchronized`都是**独占锁**，独占锁就是**一个锁**只能被**一个线程**所持有。有的时候，需要**读写分离**，那么就要引入读写锁，即`ReentrantReadWriteLock`。\n\n读写锁 **ReentrantReadWriteLock**：一个资源可以被多个读线程同时访问，也可以单独被一个写线程访问，但不能同时存在读写线程，读写互斥，读读共享。\n\n读写锁用于保证所有线程一定能读取到最新数据，用法是：在**改数据时加写锁**，在**读数据时加读锁**。修改数据期间：\n\n- 写锁是一个**独占锁**（互斥锁/排他锁）\n- 读锁是一个**共享锁**。\n\n写锁如果没有释放，读锁就得一直阻塞等待。\n\n- 创建读锁：`ReentrantReadWriteLock.readLock()`\n- 创建写锁：`ReentrantReadWriteLock.writeLock()`\n\n读写锁有以下三个重要的特性：\n\n- **公平选择性**：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平优于公平。\n- **重进入**：读锁和写锁都支持线程重进入。\n- **锁降级**：遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为读锁。\n\n具体案例：模拟多线程在 `Map` 中取数据和读数据\n\n``` java\n// 资源类\nclass MyCache {\n    // 创建map集合\n    private volatile Map<String,Object> map = new HashMap<>();\n\n    // 创建读写锁对象\n    private ReadWriteLock rwLock = new ReentrantReadWriteLock();\n\n    // 放数据\n    public void put(String key,Object value) {\n        // 添加写锁\n        rwLock.writeLock().lock();\n\n        try {\n            System.out.println(Thread.currentThread().getName()+\" 正在写操作\"+key);\n            // 暂停一会\n            TimeUnit.MICROSECONDS.sleep(300);\n            // 放数据\n            map.put(key,value);\n            System.out.println(Thread.currentThread().getName()+\" 写完了\"+key);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            // 释放写锁\n            rwLock.writeLock().unlock();\n        }\n    }\n\n    // 取数据\n    public Object get(String key) {\n        // 添加读锁\n        rwLock.readLock().lock();\n        Object result = null;\n        try {\n            System.out.println(Thread.currentThread().getName()+\" 正在读取操作\"+key);\n            // 暂停一会\n            TimeUnit.MICROSECONDS.sleep(300);\n            result = map.get(key);\n            System.out.println(Thread.currentThread().getName()+\" 取完了\"+key);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } finally {\n            // 释放读锁\n            rwLock.readLock().unlock();\n        }\n        return result;\n    }\n}\n\npublic class ReadWriteLockDemo {\n    public static void main(String[] args) throws InterruptedException {\n        MyCache myCache = new MyCache();\n        // 创建线程放数据\n        for (int i = 1; i <=5; i++) {\n            final int num = i;\n            new Thread(()->{\n                myCache.put(num+\"\",num+\"\");\n            }, String.valueOf(i)).start();\n        }\n\n        TimeUnit.MICROSECONDS.sleep(300);\n\n        // 创建线程取数据\n        for (int i = 1; i <=5; i++) {\n            final int num = i;\n            new Thread(()->{\n                myCache.get(num+\"\");\n            }, String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n四种不同情况下的锁（两个线程并发情况下）：\n\n- **读 + 读**：相当于无锁，并发读。\n- **写 + 读**：读锁阻塞等待写锁释放才能读\n- **写 + 写**：后来的写锁阻塞等待前一个写锁释放才能写\n- **读 + 写**：后来的写锁阻塞等待其他读锁释放才能写（防止前一个线程还没读到数据就被后来的线程修改了）\n\n**只要有写锁的存在，其他线程无论是先写还是后写，都必须阻塞等待。**\n\n读写锁的缺点：\n\n- 可能造成锁饥饿：大量的读操作会让写操作一直阻塞等待\n- **锁降级**：某个线程先上写锁，再上读锁，执行完业务后先释放写锁，再释放读锁。这样外部看来就是写锁降级退化成了读锁。反过来却不行，先加读锁后不能再加写锁。\n\n### 总结\n\n- 在线程持有读锁的情况下，该线程和其他线程均不能取得写锁（因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有）\n- 在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败），但其他线程获取读锁\n\n原因：当线程获取读锁的时候，可能有其他线程同时也在持有读锁，因此不能把获取读锁的线程“升级”为写锁；而对于获得写锁的线程，它一定独占了读写锁，因此可以继续让它获取读锁，当它同时获取了写锁和读锁后，还可以先释放写锁继续持有读锁，这样一个写锁就“降级”为了读锁。\n\n\n\n## 闭锁 CountDownLatch\n\n`CountDownLatch `类可以设置一个**计数器**，然后通过 `countDown()` 方法来进行减 1 的操作，使用 `await()` 方法等待计数器不大于 0，然后继续执行 `await()` 方法之后的语句。具体步骤可以演化为定义一个类，减1操作，并等待到0，为0执行结果。\n\n该类的构造方法为：`CountDownLatch(int count)`\n\n两个常用的主要方法：\n\n- `await()`：使当前线程在锁存器倒计数至零之前一直在等待，除非线程被中断\n- `countDown()`：递减锁存器的计数，如果计数达到零，将释放所有等待的线程\n\n具体案例：6个同学陆续离开教室之后，班长才能锁门。如果不加 `CountDownLatch` 类，会出现线程混乱执行，同学还未离开教室班长就已经锁门了。\n\n``` java\npublic class CountDownLatchDemo {\n    //6 个同学陆续离开教室之后，班长锁门\n    public static void main(String[] args) throws InterruptedException {\n        // 创建CountDownLatch对象，设置初始值\n        CountDownLatch countDownLatch = new CountDownLatch(6);\n\n        // 6个同学陆续离开教室之后\n        for (int i = 1; i <=6; i++) {\n            new Thread(()->{\n                System.out.println(Thread.currentThread().getName()+\" 号同学离开了教室\");\n                // 计数-1\n                countDownLatch.countDown();\n            }, String.valueOf(i)).start();\n        }\n\n        // 阻塞等待直到计数器中的数为0\n        countDownLatch.await();\n        System.out.println(Thread.currentThread().getName()+\" 班长锁门走人了\");\n    }\n}\n```\n\n## 循环栅栏 CyclicBarrier \n\n`CyclicBarrier` 类是一个**同步辅助类**，允许一组线程互相等待，直至到达某个**公共屏障点**，在设计一组固定大小的线程的程序中，这些线程必须互相等待直至达到公共屏障点。这个类很有用，因为barrier在释放等待线程后可以重用，所以称为循环barrier。`CountDownLatch`是减，而`CyclicBarrier`是加。\n\n创建一个新的CyclicBarrier，它将在给定数量的参与者（线程）处于等待状态时启动，并在启动barrier时执行给定的屏障操作，该操作由最后一个进入barrier的线程操作。\n\n常用的构造方法：`CyclicBarrier(int parties，Runnable barrierAction) `\n\n常用的方法有：`await()`： 在所有的线程都已经在此barrier上调用 `await()` 方法之前一直等待\n\n### 案例\n\n案例一：集齐7颗龙珠就可以召唤神龙\n\n``` java\n// 集齐7颗龙珠就可以召唤神龙\npublic class CyclicBarrierDemo {\n    // 创建固定值\n    private static final int NUMBER = 7;\n\n    public static void main(String[] args) {\n        // 创建CyclicBarrier，只有在7个线程都调用了await()方法才会执行其事先设置好的代码\n        CyclicBarrier cyclicBarrier =\n            new CyclicBarrier(NUMBER, ()->{\n                System.out.println(\"***** 集齐7颗龙珠了！召唤神龙！ *****\");\n            });\n\n        // 集齐七颗龙珠过程\n        for (int i = 1; i <=7; i++) {\n            new Thread(()->{\n                try {\n                    System.out.println(Thread.currentThread().getName()+\" 星龙被收集到了\");\n                    // 等待\n                    cyclicBarrier.await();\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }, String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n上述代码中，只有在7个线程都调用了 `await()` 方法才会执行 `CyclicBarrier `对象事先设置好的代码“召唤神龙”。\n\n案例二：来自《Java编程思想》的例子，展现CyclicBarrier的可循环性：\n\n``` java\nimport java.util.concurrent.*;\nimport java.util.*;\n\nclass Horse implements Runnable {\n    private static int counter = 0;\n    private final int id = counter++;\n    private int strides = 0;\n    private static Random rand = new Random(47);\n    private static CyclicBarrier barrier;\n\n    public Horse(CyclicBarrier b) {\n        barrier = b;\n    }\n\n    public synchronized int getStrides() {\n        return strides;\n    }\n\n    public void run() {\n        try {\n            while (!Thread.interrupted()) {//没有中断，就不断循环\n                synchronized (this) {\n                    //模拟马单位时间的移动距离\n                    strides += rand.nextInt(3); // Produces 0, 1 or 2\n                }\n                barrier.await();//<---等待其他马到齐到循环屏障\n            }\n        } catch (InterruptedException e) {\n            // A legitimate way to exit\n        } catch (BrokenBarrierException e) {\n            // This one we want to know about\n            throw new RuntimeException(e);\n        }\n    }\n\n    public String toString() {\n        return \"Horse \" + id + \" \";\n    }\n\n    public String tracks() {\n        StringBuilder s = new StringBuilder();\n        for (int i = 0; i < getStrides(); i++)\n            s.append(\"*\");\n        s.append(id);\n        return s.toString();\n    }\n}\n\npublic class HorseRace {\n    static final int FINISH_LINE = 75;\n    private List<Horse> horses = new ArrayList<Horse>();\n    private ExecutorService exec = Executors.newCachedThreadPool();\n    private CyclicBarrier barrier;\n\n    public HorseRace(int nHorses, final int pause) {\n        //初始化循环屏障\n        barrier = new CyclicBarrier(nHorses, new Runnable() {\n            // 循环多次执行的任务\n            public void run() {\n\n                // The fence on the racetrack\n                StringBuilder s = new StringBuilder();\n                for (int i = 0; i < FINISH_LINE; i++)\n                    s.append(\"=\"); \n                System.out.println(s);\n\n                //打印马移动距离\n                for (Horse horse : horses)\n                    System.out.println(horse.tracks());\n\n                //判断有没有马到终点了\n                for (Horse horse : horses)\n                    if (horse.getStrides() >= FINISH_LINE) {\n                        System.out.println(horse + \"won!\");\n                        exec.shutdownNow();// 有只马跑赢了，所有任务都结束了\n                        return;\n                    }\n\n                try {\n                    TimeUnit.MILLISECONDS.sleep(pause);\n                } catch (InterruptedException e) {\n                    System.out.println(\"barrier-action sleep interrupted\");\n                }\n            }\n        });\n        // 开跑！\n        for (int i = 0; i < nHorses; i++) {\n            Horse horse = new Horse(barrier);\n            horses.add(horse);\n            exec.execute(horse);\n        }\n    }\n\n    public static void main(String[] args) {\n        int nHorses = 7;\n        int pause = 200;\n        new HorseRace(nHorses, pause);\n    }\n}\n```\n\n\n\n\n\n\n\n**总结：** `CyclicBarrier `的构造方法第一个参数是**目标障碍数**，每执行一次 `await()` 方法障碍数会加一，如果达到了目标障碍数，才会执行事先设置好的代码“召唤神龙”。\n\n## 信号量 Semaphore \n\n信号量主要用于两个目的，一个是用于**多个共享资源的互斥使用**，另一个用于**并发线程数的控制**。正常的锁在任何时刻都**只允许一个任务访问一项资源**，而 `Semaphore` 允许**n个任务**同时访问这个资源。\n\n从概念上讲，信号量维护了一个**许可集**（车位集），如有必要，在许可可用前会阻塞每一个`acquire()`（没车位了就阻塞等待别人释放车位），然后再获取该许可。每个 `release()` 添加一个许可（释放一个车位），从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，`Semaphore` 只对可用许可的号码进行计数，并采取相应的行动。\n\n具体常用的构造方法：`new Semaphore(3)` 设置许可数量为3（3个车位）\n\n具体常用的方法有：\n\n- `acquire()`：从此信号量获取一个许可，在提供一个许可前一直将线程阻塞，除非线程被中断\n- `release()`：释放一个许可，将其返回给信号量\n\n一般 `acquire()` 都会抛出异常，`release() `在 finally 代码块中执行。\n\n`CountDownLatch`的问题是**不能复用**。比如`count=3`，那么加到3，就不能继续操作了。而`Semaphore`可以解决这个问题，比如6辆车3个停车位，对于`CountDownLatch`**只能停3辆车**，而`Semaphore`可以停6辆车，车位空出来后，其它车可以占有：\n\n``` java\n// 6辆汽车，停3个车位\npublic class SemaphoreDemo {\n    public static void main(String[] args) {\n        // 创建Semaphore，设置许可数量3（3个车位）\n        Semaphore semaphore = new Semaphore(3);\n\n        // 模拟6辆汽车\n        for (int i = 1; i <=6; i++) {\n            new Thread(()->{\n                try {\n                    // 抢占一个许可（车位）\n                    semaphore.acquire();\n                    \n                    System.out.println(Thread.currentThread().getName()+\" 抢到了车位\");\n                    // 设置随机停车时间\n                    TimeUnit.SECONDS.sleep(new Random().nextInt(5));\n                    System.out.println(Thread.currentThread().getName()+\" ------离开了车位\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                } finally {\n                    // 释放这个许可（车位）\n                    semaphore.release();\n                }\n            }, String.valueOf(i)).start();\n        }\n    }\n}\n```\n\n当前共有三个车位（三个许可）。之后三个线程先后获取许可0，许可量为0，代表没有多余的许可给其他线程了。此后再想来获取许可的线程会阻塞等待其他线程释放许可，才能继续获取到许可。\n\n\n\n## 阻塞队列\n\n### BlockingQueue 简介\n\n> JUC 线程池的底层应用了阻塞队列存储排队的线程\n\nJUC 包中，`BlockingQueue` 很好地解决了多线程中如何高效安全“传输”数据的问题。通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。\n\n阻塞队列是共享队列（多线程操作），一端输入，一端输出。不能无限放队列，满了之后就会进入阻塞，取出也同理\n\n![image-20210917175644768](/images/%E3%80%90JUC%E3%80%91JUC/image-20210917175644768.png)\n\n- 当队列是空的，从队列中获取元素的操作将会被阻塞\n- 当队列是满的，从队列中添加元素的操作将会被阻塞\n- 试图从空的队列中获取元素的线程将会被阻塞，直到其他线程往空的队列插入新的元素\n- 试图向已满的队列中添加新元素的线程将会被阻塞，直到其他线程从队列中移除一个或多个元素或者完全清空，使队列变得空闲起来并后续新增\n\n在多线程领域：所谓阻塞，在某些情况下会**挂起**线程（即阻塞），一旦条件满足，被挂起的线程又会自动被唤起。\n\n多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和“消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的数据处理完毕，反之亦然。\n\n- 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放入队列\n- 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有空的位置，线程被自动唤醒\n\n### 为什么需要 BlockingQueue? \n\n在JUC包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。使用后我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切 `BlockingQueue` 都给你一手包办了。\n\n**体系**：`Collection` → `Queue` → `BlockingQueue` → 七个阻塞队列实现类。\n\n### 种类\n\n| 类名                    | 作用                             |\n| ----------------------- | -------------------------------- |\n| **ArrayBlockingQueue**  | 由**数组**构成的**有界**阻塞队列 |\n| **LinkedBlockingQueue** | 由**链表**构成的**有界**阻塞队列 |\n| PriorityBlockingQueue   | 支持优先级排序的无界阻塞队列     |\n| DelayQueue              | 支持优先级的延迟无界阻塞队列     |\n| **SynchronousQueue**    | **单个元素**的阻塞队列           |\n| LinkedTransferQueue     | 由链表构成的无界阻塞队列         |\n| LinkedBlockingDeque     | 由链表构成的双向阻塞队列         |\n\n粗体标记的三个用得比较多，**许多消息中间件底层就是用它们实现的**。\n\n需要注意的是`LinkedBlockingQueue`虽然是有界的，但有个巨坑，其默认大小是`Integer.MAX_VALUE`，高达21亿，一般情况下内存早爆了（在线程池的`ThreadPoolExecutor`有体现）。\n\n**1. ArrayBlockingQueue**\n\n由**数组**结构组成的**有界**阻塞队列。`ArrayBlockingQueue`  在生产者放入数据和消费者获取数据，都是共用同一个锁对象，无法并行。\n\n**2. LinkedBlockingQueue**\n\n由**链表**结构组成的**有界**阻塞队列（但大小默认值为`integer.MAX_VALUE`）。\n\n之所以能够高效地处理并发数据，是因为其对于生产者端和消费者端分别采用了**独立的锁**来控制数据同步，这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。\n\n**3. DelayQueue**\n\n使用**优先级队列**实现的**延迟无界**阻塞队列。\n\n`DelayQueue` 中的元素只有当其指定的延迟时间到了，才能够从队列中获取到该元素。`DelayQueue` 是一个**没有大小限制**的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞\n\n**4. PriorityBlockingQueue**\n\n支持**优先级排序**的**无界**阻塞队列。不会阻塞数据生产者，而只会在没有可消费的数据时，阻塞数据的消费者。\n\n**5. SynchronousQueue**\n\n不存储元素的阻塞队列，也即**单个元素**的队列。一种**无缓冲**的等待队列。相对于有缓冲的 `BlockingQueue` 来说，少了一个中间经销商的环节（缓冲区）。\n\n声明一个 `SynchronousQueue` 有两种不同的方式，它们之间有着不太一样的行为。\n\n公平模式和非公平模式的区别：\n\n- 公平模式：`SynchronousQueue `会采用公平锁，并配合一个 FIFO 队列来阻塞\n  多余的生产者和消费者，从而体系整体的公平策略；\n- 非公平模式（默认）：`SynchronousQueue `采用非公平锁，同时配合一个 LIFO 队列来管理多余的生产者和消费者\n\n后一种模式，如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有某些生产者或者是消费者的数据永远都得不到处理\n\n**6. LinkedTransferQueue**\n\n由**链表**结构组成的**无界**阻塞队列。\n\n预占模式：意思就是消费者线程取元素时，如果队列不为空，则直接取走数据，若队列为空，生成一个节点（节点元素为 null）入队，消费者线程被等待在这个节点上，生产者线程入队时发现有一个元素为 null 的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的方法返回。\n\n**7. LinkedBlockingDeque**\n\n由**链表**结构组成的**双向**阻塞队列。阻塞有两种情况：\n\n- 插入元素时：如果当前队列已满将会进入阻塞状态，一直等到队列有空的位置时再该元素插入，该操作可以通过设置超时参数，超时后返回 false 表示操作失败，也可以不设置超时参数一直阻塞，中断后抛出 `InterruptedException` 异常\n- 读取元素时：如果当前队列为空会阻塞住直到队列不为空然后返回元素，同样可以通过设置超时参数\n\n### 常用方法\n\n![img](/images/%E3%80%90JUC%E3%80%91JUC/23c582a533ca4b80b4c2ca7b9db3de92.png)\n\n创建阻塞队列 `BlockingQueue<String> blockingQueue = new ArrayBlockingQueue<>(3);`\n\n### 抛出异常类型\n\n执行该类型方法时，若阻塞队列已满/空，再向队列中插入/移除时将**抛出异常**\n\n- 加入元素：`blockingQueue.add(\"a\")`\n- 检查元素：`blockingQueue.element()`\n- 取出元素：`blockingQueue.remove()`\n\n### 特殊值类型\n\n执行该类型方法时，若阻塞队列已满/空，再向队列中插入/移除时，成功返回`true`，失败返回`false`\n\n- 加入元素：`blockingQueue.offer(\"a\")`\n- 检查元素：`blockingQueue.peek()`\n- 取出元素：`blockingQueue.poll()`\n\n### 阻塞类型\n\n执行该类型方法时，若阻塞队列已满/空，再向队列中插入/移除时，线程进入**阻塞状态**\n\n- 加入元素：`blockingQueue.put(\"a\");`\n- 取出元素：`blockingQueue.take()`\n\n### 超时类型\n\n执行该类方法时，若阻塞队列已满/空，再向队列中插入/移除时，线程进入阻塞状态，但等待一段时间后还无法插入/移除数据时，线程将退出\n\n- 加入元素：`blockingQueue.offer(\"w\", 3L, TimeUnit.SECONDS)`\n- 取出元素：`blockingQueue.poll( 3L, TimeUnit.SECONDS)`\n\n### SynchronousQueue\n\n队列**只有一个元素**，如果想插入多个，必须等队列元素取出后，才能插入，只能有一个“坑位”，用一个插一个：\n\n``` java\npackage concurrent.blockingqueue;\n\nimport java.util.concurrent.BlockingQueue;\nimport java.util.concurrent.SynchronousQueue;\nimport java.util.concurrent.TimeUnit;\n\npublic class SynchronousQueueDemo {\n    public static void main(String[] args) {\n        BlockingQueue<String> blockingQueue = new SynchronousQueue<String>();\n        new Thread(() -> {\n            try {\n                System.out.println(Thread.currentThread().getName() + \"\\t put 1\");\n                blockingQueue.put(\"1\");\n                System.out.println(Thread.currentThread().getName() + \"\\t put 2\");\n                blockingQueue.put(\"2\");\n                System.out.println(Thread.currentThread().getName() + \"\\t put 3\");\n                blockingQueue.put(\"3\");\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }, \"AAA\").start();\n        new Thread(() -> {\n            try {\n                try {\n                    TimeUnit.SECONDS.sleep(5);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \"\\t take \" + blockingQueue.take());\n                try {\n                    TimeUnit.SECONDS.sleep(5);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \"\\t take \" + blockingQueue.take());\n                try {\n                    TimeUnit.SECONDS.sleep(5);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \"\\t take\" + blockingQueue.take());\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }, \"BBB\").start();\n    }\n}\n```\n\n### 阻塞队列的应用——生产者消费者\n\n#### 传统模式\n\n传统模式使用`Lock`来进行操作，需要手动加锁、解锁。\n\n``` java\npackage concurrent.blockingqueue;\n\nimport java.util.concurrent.locks.Condition;\nimport java.util.concurrent.locks.Lock;\nimport java.util.concurrent.locks.ReentrantLock;\npublic class ProdConsTradiDemo {\n    public static void main(String[] args) {\n        ShareData shareData = new ShareData();\n        new Thread(() -> {\n            for (int i = 0; i < 5; i++) {\n                try {\n                    shareData.increment();\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"Producer\").start();\n        new Thread(() -> {\n            for (int i = 0; i < 5; i++) {\n                try {\n                    shareData.decrement();\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }\n        }, \"Consumer\").start();\n    }\n}\nclass ShareData {\n    private int number = 0;\n    private Lock lock = new ReentrantLock();\n    private Condition condition = lock.newCondition();\n\n    public void increment() throws InterruptedException {\n        lock.lock();\n        try {\n            //1 判断\n            while (number != 0) {\n                //等待，不能生产\n                condition.await();\n            }\n            //2 干活\n            number++;\n            System.out.println(Thread.currentThread().getName() + \"\\t\" + number);\n            //3 通知唤醒\n            condition.signalAll();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n    public void decrement() throws InterruptedException {\n        lock.lock();\n        try {\n            //1 判断\n            while (number == 0) {\n                //等待，不能生产\n                condition.await();\n            }\n            //2 干活\n            number--;\n            System.out.println(Thread.currentThread().getName() + \"\\t\" + number);\n            //3 通知唤醒\n            condition.signalAll();\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            lock.unlock();\n        }\n    }\n}\n```\n\n#### 阻塞队列模式\n\n使用阻塞队列就不需要手动加锁了\n\n``` java\npackage concurrent.blockingqueue;\n\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.BlockingQueue;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nclass MyResource {\n    // 默认开启，进行生产消费\n    // 这里用到了volatile是为了保持数据的可见性，也就是当TLAG修改时，要马上通知其它线程进行修改\n    private volatile boolean FLAG = true;\n\n    // 使用原子包装类，而不用number++\n    private AtomicInteger atomicInteger = new AtomicInteger();\n\n    // 这里不能为了满足条件，而实例化一个具体的SynchronousBlockingQueue\n    BlockingQueue<String> blockingQueue = null;\n\n    // 而应该采用依赖注入里面的，构造注入方法传入\n    public MyResource(BlockingQueue<String> blockingQueue) {\n        this.blockingQueue = blockingQueue;\n        // 查询出传入的class是什么\n        System.out.println(blockingQueue.getClass().getName());\n    }\n\n    /**\n     * 生产\n     * @throws Exception\n     */\n    public void myProd() throws Exception{\n        String data = null;\n        boolean retValue;\n        // 多线程环境的判断，一定要使用while进行，防止出现虚假唤醒\n        // 当FLAG为true的时候，开始生产\n        while(FLAG) {\n            data = atomicInteger.incrementAndGet() + \"\";\n\n            // 2秒存入1个data\n            retValue = blockingQueue.offer(data, 2L, TimeUnit.SECONDS);\n            if(retValue) {\n                System.out.println(Thread.currentThread().getName() + \"\\t 插入队列:\" + data  + \"成功\" );\n            } else {\n                System.out.println(Thread.currentThread().getName() + \"\\t 插入队列:\" + data  + \"失败\" );\n            }\n\n            try {\n                TimeUnit.SECONDS.sleep(1);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n\n        System.out.println(Thread.currentThread().getName() + \"\\t 停止生产，表示FLAG=false，生产介绍\");\n    }\n\n    /**\n     * 消费\n     * @throws Exception\n     */\n    public void myConsumer() throws Exception{\n        String retValue;\n        // 多线程环境的判断，一定要使用while进行，防止出现虚假唤醒\n        // 当FLAG为true的时候，开始生产\n        while(FLAG) {\n            // 2秒消耗1个data\n            retValue = blockingQueue.poll(2L, TimeUnit.SECONDS);\n            if(retValue != null && retValue != \"\") {\n                System.out.println(Thread.currentThread().getName() + \"\\t 消费队列:\" + retValue  + \"成功\" );\n            } else {\n                FLAG = false;\n                System.out.println(Thread.currentThread().getName() + \"\\t 消费失败，队列中已为空，退出\" );\n\n                // 退出消费队列\n                return;\n            }\n        }\n    }\n\n    /**\n     * 停止生产的判断\n     */\n    public void stop() {\n        this.FLAG = false;\n    }\n\n}\npublic class ProdConsumerBlockingQueueDemo {\n\n    public static void main(String[] args) {\n        // 传入具体的实现类， ArrayBlockingQueue\n        MyResource myResource = new MyResource(new ArrayBlockingQueue<String>(10));\n\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName() + \"\\t 生产线程启动\");\n            System.out.println(\"\");\n            System.out.println(\"\");\n            try {\n                myResource.myProd();\n                System.out.println(\"\");\n                System.out.println(\"\");\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }, \"prod\").start();\n\n\n        new Thread(() -> {\n            System.out.println(Thread.currentThread().getName() + \"\\t 消费线程启动\");\n\n            try {\n                myResource.myConsumer();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }, \"consumer\").start();\n\n        // 5秒后，停止生产和消费\n        try {\n            TimeUnit.SECONDS.sleep(5);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        System.out.println(\"5秒中后，生产和消费线程停止，线程结束\");\n        myResource.stop();\n    }\n}\n```\n\n输出结果：\n\n``` \njava.util.concurrent.ArrayBlockingQueue\nproducer\t 生产线程启动\n\n\nconsumer\t 消费线程启动\nproducer\t 插入队列:1成功\nconsumer\t 消费队列:1成功\nproducer\t 插入队列:2成功\nconsumer\t 消费队列:2成功\nproducer\t 插入队列:3成功\nconsumer\t 消费队列:3成功\nproducer\t 插入队列:4成功\nconsumer\t 消费队列:4成功\nproducer\t 插入队列:5成功\nconsumer\t 消费队列:5成功\n\n5秒后，生产和消费线程停止，线程结束\nproducer\t 停止生产，表示FLAG=false，生产结束\n\nconsumer\t 消费失败，队列中已为空，退出\n```\n\n\n\n\n\n\n\n## 线程池\n\n> 连接池是创建和管理一个连接的缓冲池的技术，这些连接准备好被任何需要它们的线程使用\n\n**线程池（ThreadPool）**：一种线程使用模式。线程过多会带来调度开销，进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代价。其特点：\n\n- 线程复用\n- 管理线程\n- 控制最大并发数\n\n线程池不仅能够保证内核的充分利用，还能防止过分调度。优势：\n\n- **降低资源消耗**：通过重复利用已创建的线程降低线程创建和销毁造成的销耗。\n- **提高响应速度**：当任务到达时，任务可以不需要等待线程创建就能立即执行。\n- **提高线程的可管理性**：线程是稀缺资源，如果无限制的创建，不仅会销耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。\n\nJava 中的线程池是通过 `Executor `框架实现的，该框架中用到了 `Executor`，`Executors`，`ExecutorService`，`ThreadPoolExecutor `这几个类（\t`Executors`为工具类）：\n\n![img](/images/%E3%80%90JUC%E3%80%91JUC/cc01ccd591ac421eb6d150728bb1584a.png)\n\n### 线程池种类\n\n- `Executors.newFixedThreadPool(int)`：一池N线程\n- `Executors.newSingleThreadExecutor()`：一池一线程\n- `Executors.newCachedThreadPool()`：一池可扩容根据需求创建线程\n\n案例代码：\n\n``` java\n// 演示线程池三种常用分类\npublic class ThreadPoolDemo1 {\n    public static void main(String[] args) {\n        // 一池五线程\n        ExecutorService threadPool1 = Executors.newFixedThreadPool(5); // 5个窗口\n        // 一池一线程\n        ExecutorService threadPool2 = Executors.newSingleThreadExecutor(); // 一个窗口\n        // 一池可扩容线程\n        ExecutorService threadPool3 = Executors.newCachedThreadPool();\n        \n        // 10个顾客请求\n        try {\n            for (int i = 1; i <=10; i++) {\n                //执行\n                threadPool3.execute(()->{\n                    System.out.println(Thread.currentThread().getName()+\" 办理业务\");\n                });\n            }\n        }catch (Exception e) {\n            e.printStackTrace();\n        }finally {\n            // 关闭线程池\n            threadPool3.shutdown();\n        }\n    }\n}\n```\n\n### 底层原理\n\n`ThreadPoolExecutor `的构造方法需要传入7个参数：\n\n``` java\npublic ThreadPoolExecutor(int corePoolSize,\n                         int maximumPoolSize,\n                         long keepAliveTime,\n                         TimeUnit unit,\n                         BlockingQueue<Runnable> workQueue,\n                         ThreadFactory threadFactory,\n                         RejectedExecutionHandler handler) {\n    if (corePoolSize < 0 ||\n      maximumPoolSize <= 0 ||\n      maximumPoolSize < corePoolSize ||\n     keepAliveTime < 0)\n      throw new IllegalArgumentException();\n      if (workQueue == null || threadFactory == null || handler == null)\n         throw new NullPointerException();\n       this.corePoolSize = corePoolSize;\n       this.maximumPoolSize = maximumPoolSize;\n       this.workQueue = workQueue;\n       this.keepAliveTime = unit.toNanos(keepAliveTime);\n       this.threadFactory = threadFactory;\n       this.handler = handler;\n}\n```\n\n7个参数解读：\n\n- `int corePoolSize`：常驻线程数量（核心）\n- `int maximumPoolSize`：线程池中能够容纳同时执行的最大线程数量\n- `long keepAliveTime,TimeUnit unit`：多余的空闲线程的存活时间。当前线程池中线程数量超过 `corePoolSize `时，且空闲时间达到 `keepAliveTime` 的扩容线程会被销毁\n- `BlockingQueue<Runnable> workQueue`：阻塞队列（已提交但是尚未执行的线程将放入其中）\n- `ThreadFactory threadFactory`：线程工厂，用于创建线程，一般用默认工厂即可\n- `RejectedExecutionHandler handler`：拒绝策略（线程与阻塞队列都满了会执行拒绝策略）\n\n线程池具体工作流程：\n\n1. 在创建了线程池后，线程池中的线程数为零\n2. 当调用 `execute()` 方法添加一个请求任务时，线程池会做出如下判断： \n   1. 如果正在运行的线程数量小于`corePoolSize`，那么马上创建线程运行这个任务； \n   2. 如果正在运行的线程数量大于或等于`corePoolSize`，那么将这个任务放入队列等待空余线程； \n   3. 如果这个时候队列满了且正在运行的线程数量还小于`maximumPoolSize`，那么还是要创建非核心线程（扩容线程）立刻运行这个任务； \n   4. 如果队列满了且正在运行的线程数量大于或等于`maximumPoolSize`，那么线程池会启动饱和拒绝策略来执行。\n3. 当一个线程完成任务时，它会从队列中取下一个任务来执行\n4. 当一个线程无事可做超过一定的时间（`keepAliveTime`）时（即过期时），线程池会判断：\n   1. 如果当前运行的线程数大于`corePoolSize`，那么这个线程就被停掉。 \n   2. 所以线程池的所有任务完成后，它最终会收缩到`corePoolSize`的大小。\n\n![img](/images/%E3%80%90JUC%E3%80%91JUC/ff005c5fbd7246669fff31c97ce9525d.png)\n\n**拒绝策略：**\n\n- `CallerRunsPolicy`：回退，线程请求从哪个线程来的回哪个线程去执行。当触发拒绝策略，只要线程池没有关闭的话，则使用调用线程直接运行任务。一般并发比较小，性能要求不高，不允许失败。但是，由于调用者自己运行任务，如果任务提交速度过快，可能导致程序阻塞，性能效率上必然的损失较大\n- `AbortPolicy`：（默认配置）丢弃任务，并抛出拒绝执行 `RejectedExecutionException `异常信息。线程池默认的拒绝策略。必须处理好抛出的异常，否则会打断当前的执行流程，影响后续的任务执行。\n- `DiscardPolicy`：直接丢弃，不抛异常\n- `DiscardOldestPolicy`：当触发拒绝策略，只要线程池没有关闭的话，丢弃阻塞队列 `workQueue `中最老的一个任务，并将新任务加入\n\n![img](/images/%E3%80%90JUC%E3%80%91JUC/07a1429981584ef986c0852071d3bd78.png)\n\n### 自定义线程池\n\n实际在开发中不允许使用`Executors`创建，而是通过`ThreadPoolExecutor`的方式自定义线程数参数，规避资源耗尽风险。原因是 `Executors` 创建的线程池允许的请求队列长度为 `Integer.MAX_VALUE`，这可能会堆积大量的请求，从而导致OOM：\n\n![在这里插入图片描述](/images/%E3%80%90JUC%E3%80%91JUC/5f5fba97080a4ffb8d853a70872bff6a.png)\n\n自定义线程池：\n\n``` java\nExecutorService threadPool = new ThreadPoolExecutor(\n        2,\n        5,\n        2L,\n        TimeUnit.SECONDS,\n        new ArrayBlockingQueue<>(3),\n        Executors.defaultThreadFactory(),\n        new ThreadPoolExecutor.AbortPolicy()\n);\n```\n\n通常将 `maximPoolSize `设置为自己电脑 cpu 核数 + 1\n\n### 谈一谈对线程池的理解\n\nJUC 中的线程池主要有三种：\n\n- `Executors.newFixedThreadPool(int)`：一池N线程\n- `Executors.newSingleThreadExecutor()`：一池一线程\n- `Executors.newCachedThreadPool()`：一池可扩容根据需求创建线程\n\n但三者底层都是 new 的 `ThreadPoolExecutor`，只不过传入的参数不同而已：\n\n![image-20210918192102967](/images/%E3%80%90JUC%E3%80%91JUC/image-20210918192102967.png)\n\n![image-20210918192119156](/images/%E3%80%90JUC%E3%80%91JUC/image-20210918192119156.png)\n\n![image-20210918192130791](/images/%E3%80%90JUC%E3%80%91JUC/image-20210918192130791.png)\n\n\n\n\n\n### 线程池配置合理线程数\n\n合理配置线程池你是如何考虑的？\n\n#### CPU 密集型\n\nCPU密集的意思是该任务**需要大量的运算**，而**没有阻塞**，CPU一直全速运行。\n\nCPU密集任务只有在真正的多核CPU上才可能得到加速(通过多线程)，而在单核CPU上，无论你开几个模拟的多线程该任务都不可能得到加速，因为CPU总的运算能力就那些。\n\nCPU密集型任务配置**尽可能少的线程数量**，一般公式：**（CPU核数+1）个线程的线程池**\n\n#### lO 密集型\n\nIO密集型，即该任务需要大量的IO，即**大量的阻塞**。\n\n在单线程上运行IO密集型的任务会导致浪费大量的CPU运算能力浪费在等待。所以在IO密集型任务中使用多线程可以大大加速程序运行，即使在单核CPU上，这种加速主要就是利用了被浪费掉的阻塞时间。\n\nIO密集型时，大部分线程都阻塞，故需要多配置线程数，参考公式：**CPU核数/ (1-阻塞系数)**。阻塞系数在0.8~0.9之间比如8核CPU：`8/(1-0.9)=80`个线程数\n\n\n\n\n\n## Fork 与 Join 分支\n\nFork/Join 可以将一个大的任务拆分成多个子任务进行并行处理，最后将子任务结果合并成最后的计算结果，并进行输出。Fork/Join 框架要完成两件事情：\n\n- **任务分割**：首先Fork/Join框架需要把大的任务分割成足够小的子任务，如果子任务比较大的话还要对子任务进行继续分割\n- 执行任务并**合并结果**：分割的子任务分别放到**双端队列**里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都放在另外一个队列里，启动一个线程从队列里取数据，然后合并这些数据。\n\n在Java的 Fork/Join 框架中，使用两个类完成上述操作\n\n- `ForkJoinTask`：我们要使用 Fork/Join 框架，首先需要创建一个 ForkJoin 任务。该类提供了在任务中执行 fork 和 join 的机制。通常情况下我们不需要直接集成 `ForkJoinTask` 类，只需要继承它的子类，Fork/Join 框架提供了两个子类：\n  - `RecursiveAction`：用于没有返回结果的任务\n  - `RecursiveTask`：用于有返回结果的任务\n- `ForkJoinPool`：实现了 `Executor `接口。`ForkJoinTask` 需要通过 `ForkJoinPool `来执行\n- `RecursiveTask`：继承后可以实现递归调用的任务\n\n示例：\n\n``` java\nclass Fibonacci extends RecursiveTask<Integer> {\n    final int n;\n    Fibonacci(int n) { this.n = n; }\n    Integer compute() {\n        if (n <= 1)\n            return n;\n        Fibonacci f1 = new Fibonacci(n - 1);\n        f1.fork();\n        Fibonacci f2 = new Fibonacci(n - 2);\n        return f2.compute() + f1.join();\n    }\n}\n```\n\n### Fork/Join 框架的实现原理\n\n`ForkJoinPool `由 `ForkJoinTask `数组和 `ForkJoinWorkerThread `数组组成，`ForkJoinTask`数组负责存放以及将程序提交给 `ForkJoinPool`，而 `ForkJoinWorkerThread` 负责执行这些任务。\n\n![image-20210917181012212](/images/%E3%80%90JUC%E3%80%91JUC/image-20210917181012212.png)\n\n![image-20210917181020781](/images/%E3%80%90JUC%E3%80%91JUC/image-20210917181020781.png)\n\nFork/Join 框架的实现原理见文档 [JUC并发编程](https://yuyun-zhao.github.io/documents/JUC2021.pdf)。\n\n### 使用案例\n\n具体案例：1加到100，相加两个数值不能大于10\n\n``` java\nclass MyTask extends RecursiveTask<Integer> {\n\n    // 拆分差值不能超过10，计算10以内运算\n    private static final Integer VALUE = 10;\n    private int begin ;// 拆分开始值\n    private int end;// 拆分结束值\n    private int result ; // 返回结果\n\n    // 创建有参数构造\n    public MyTask(int begin,int end) {\n        this.begin = begin;\n        this.end = end;\n    }\n\n    // 拆分和合并过程\n    @Override\n    protected Integer compute() {\n        // 判断相加两个数值是否大于10\n        if((end-begin)<=VALUE) {\n            // 相加操作\n            for (int i = begin; i <=end; i++) {\n                result = result+i;\n            }\n        } else {// 进一步拆分\n            // 获取中间值\n            int middle = (begin+end)/2;\n            // 拆分左边\n            MyTask task01 = new MyTask(begin,middle);\n            // 拆分右边\n            MyTask task02 = new MyTask(middle+1,end);\n            // 调用方法拆分\n            task01.fork();\n            task02.fork();\n            //合并结果\n            result = task01.join()+task02.join();\n        }\n        return result;\n    }\n}\n\npublic class ForkJoinDemo {\n    public static void main(String[] args) throws ExecutionException, InterruptedException {\n        // 创建MyTask对象\n        MyTask myTask = new MyTask(0,100);\n        // 创建分支合并池对象\n        ForkJoinPool forkJoinPool = new ForkJoinPool();\n        ForkJoinTask<Integer> forkJoinTask = forkJoinPool.submit(myTask);\n        // 获取最终合并之后结果\n        Integer result = forkJoinTask.get();\n        System.out.println(result);\n        // 关闭池对象\n        forkJoinPool.shutdown();\n    }\n}\n```\n\n## 异步回调 CompletableFuture\n\n`CompletableFuture` 在 Java 里面被用于**异步**编程，异步通常意味着非阻塞，可以使得我们的任务单独运行在与主线程分离的其他线程中，并且通过**回调**的方式在主线程中得到异步任务的执行状态，是否完成，和是否异常等信息。\n\n- `Future` 接口不是通过回调的方式，而是使用 `get()` 方法阻塞判断业务是否执行完毕，所以本质还是同步\n- `CompletableFuture `接口通过回调的方式，并不会阻塞等待业务执行完毕，而是在业务执行完毕后回调通知主线程运行结果，这才是真正的异步。\n\n![image-20210917164341898](/images/%E3%80%90JUC%E3%80%91JUC/image-20210917164341898.png)\n\n`CompletableFuture `实现了 `Future`, `CompletionStage `接口，实现了 `Future `接口就可以兼容现在有线程池框架，而 `CompletionStage `接口才是异步编程的接口抽象，里面定义多种异步方法，通过这两者集合，从而打造出了强大的`CompletableFuture `类\n\n- `runAsync()`：调用**没有返回值**方法，主线程调用 `get() `方法时会阻塞（这种方式和 `Future `相似，本质还是同步）\n- `supplyAsync()`：调用**有返回值**方法（**回调**的方式得到运行结果，程序不会阻塞，真正的异步）\n\n具体案例：\n\n``` java\n// 异步调用和同步调用\npublic class CompletableFutureDemo {\n    public static void main(String[] args) throws Exception {\n        // 本质上是同步调用\n        CompletableFuture<Void> completableFuture1 = CompletableFuture.runAsync(()->{\n            System.out.println(Thread.currentThread().getName()+\" : CompletableFuture1\");\n        });\n        // 尽管会创建另一个线程执行任务，但是主线程仍然会阻塞在get()方法处直到任务完成\n        completableFuture1.get();\n\n        // 消息队列\n        // 异步调用\n        CompletableFuture<Integer> completableFuture2 = CompletableFuture.supplyAsync(()->{\n            System.out.println(Thread.currentThread().getName()+\" : CompletableFuture2\");\n            // 模拟异常\n            int i = 10/0;\n            return 1024;\n        });\n        \n        // 回调的方式异步执行\n        completableFuture2.whenComplete((t,u)->{\n            System.out.println(\"------t=\"+t);\n            System.out.println(\"------u=\"+u);\n        }).exceptionally(f ->\n                         { System.out.println(\"------exception=\"+f.getMessage);\n                         return 4444;})\n                         .get();\n    }\n}\n```\n\n`whenComplete()`方法的源码为：\n\n``` java\npublic CompletableFuture<T> whenComplete(\n    BiConsumer<? super T, ? super Throwable> action) {\n    return uniWhenCompleteStage(null, action);\n}\n```\n\n其中，`t`为返回结果，`u`为异常信息（没有异常时为null）\n\n### Future 与 CompletableFuture\n\n对比这两种方法，一个为同步一个为异步。\n\n`Futrue `在 Java 里面，通常用来表示一个异步任务的引用，比如我们将任务提交到线程池里面，然后我们会得到一个 `Futrue`，在 `Future `里面有 `isDone()` 方法来判断任务是否处理结束，还有 `get()` 方法可以一直阻塞直到任务结束然后获取结果，**但整体来说这种方式，还是同步的，因为需要客户端不断阻塞等待或者不断轮询才能知道任务是否完成**。\n\n与 `CompletableFuture `相比， `Future `的缺点：\n\n**（1）不支持手动完成**\n\n我提交了一个任务，但是执行太慢了，我通过其他路径已经获取到了任务结果，现在没法把这个任务结果通知到正在执行的线程，所以必须主动取消或者一直等待它执行完成\n\n**（2）不支持进一步的非阻塞调用**\n\n通过 `Future `的 `get()` 方法会一直阻塞到任务完成，但是想在获取任务之后执行额外的任务，因为 `Future `不支持回调函数，所以无法实现这个功能\n\n**（3）不支持链式调用**\n\n对于 `Future `的执行结果，我们想继续传到下一个 Future 处理使用，从而形成一个链式的 `pipline `调用，这在 `Future `中是没法实现的。\n\n**（4）不支持多个 Future 合并**\n\n比如我们有 10 个 `Future `并行执行，我们想在所有的 `Future `运行完毕之后，执行某些函数，是没法通过 `Future `实现的。\n\n**（5）不支持异常处理**\n\n`Future `的 API 没有任何的异常处理的 api，所以在异步运行时，如果出了问题是不好定位的\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["JUC"],"categories":["JUC"]},{"title":"【JVM】JVM 概述","url":"/2021/09/14/【JVM】JVM概述/","content":"\n## JVM 与 Java 体系结构\n\n### 前言\n\n![image-20200704111417472](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704111417472.png)\n\n计算机系统体系对我们来说越来越远，在不了解底层实现方式的前提下，通过高级语言很容易编写程序代码。但事实上计算机并不认识高级语言。\n\n![image-20200704112119729](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704112119729.png)\n\n<!-- More -->\n\n### Java vs C++\n\n垃圾收集机制为我们打理了很多繁琐的工作，大大提高了开发的效率，但是，垃圾收集也不是万能的，懂得JVM内部的内存结构、工作机制，是设计高扩展性应用和诊断运行时问题的基础，也是Java工程师进阶的必备能力。\n\n![image-20200704112700211](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704112700211.png)\n\nC语言需要自己来分配内存和回收内存，Java全部交给JVM进行分配和回收。\n\n### Java 生态圈\n\nJava是目前应用最为广泛的软件开发平台之一。随着Java以及Java社区的不断壮大Java 也早已不再是简简单单的一门计算机语言了，它更是一个平台、一种文化、一个社区。\n\n- 作为一个平台，Java虚拟机扮演着举足轻重的作用\n  - Groovy、Scala、JRuby、Kotlin等都是Java平台的一部分\n- 作为灯种文化，Java几乎成为了“开源”的代名词。\n  - 第三方开源软件和框架。如Tomcat、Struts，MyBatis，Spring等。\n  - 就连JDK和JVM自身也有不少开源的实现，如openJDK、Harmony。\n- 作为一个社区，Java拥有全世界最多的技术拥护者和开源社区支持，有数不清的论坛和资料。从桌面应用软件、嵌入式开发到企业级应用、后台服务器、中间件，都可以看到Java的身影。其应用形式之复杂、参与人数之众多也令人咋舌。\n\n![image-20200704151731216](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704151731216.png)\n\n每个语言都需要转换成字节码文件，最后转换的字节码文件都能通过Java虚拟机进行运行和处理\n\n![image-20200704152052489](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704152052489.png)\n\n随着Java7的正式发布，Java虚拟机的设计者们通过JSR-292规范基本实现在Java虚拟机平台上运行非Java语言编写的程序。\n\nJava虚拟机根本不关心运行在其内部的程序到底是使用何种编程语言编写的，它只关心“字节码”文件。也就是说Java虚拟机拥有语言无关性，并不会单纯地与Java语言“终身绑定”，只要其他编程语言的编译结果满足并包含Java虚拟机的内部指令集、符号表以及其他的辅助信息，它就是一个有效的字节码文件，就能够被虚拟机所识别并装载运行。\n\n### 字节码\n\n我们平时说的java字节码，指的是用java语言编译成的字节码。准确的说任何能在jvm平台上执行的字节码格式都是一样的。所以应该统称为：jvm字节码。\n\n不同的编译器，可以编译出相同的字节码文件，字节码文件也可以在不同的JVM上运行。\n\nJava虚拟机与Java语言并没有必然的联系，它只与特定的二进制文件格式—Class文件格式所关联，Class文件中包含了Java虚拟机指令集（或者称为字节码、Bytecodes）和符号表，还有一些其他辅助信息。\n\n### 多语言混合编程\n\nJava平台上的多语言混合编程正成为主流，通过特定领域的语言去解决特定领域的问题是当前软件开发应对日趋复杂的项目需求的一个方向。\n\n试想一下，在一个项目之中，并行处理用clojure语言编写，展示层使用JRuby/Rails，中间层则是Java，每个应用层都将使用不同的编程语言来完成，而且，接口对每一层的开发者都是透明的，各种语言之间的交互不存在任何困难，就像使用自己语言的原生API一样方便，因为它们最终都运行在一个虚拟机之上。\n\n对这些运行于Java虚拟机之上、Java之外的语言，来自系统级的、底层的支持正在迅速增强，以JSR-292为核心的一系列项目和功能改进（如Da Vinci Machine项目、Nashorn引擎、InvokeDynamic指令、java.lang.invoke包等），推动Java虚拟机从“Java语言的虚拟机”向 “多语言虚拟机”的方向发展。\n\n### Java 发展的重大事件\n\n- 1990年，在Sun计算机公司中，由Patrick Naughton、MikeSheridan及James Gosling领导的小组Green Team，开发出的新的程序语言，命名为oak，后期命名为Java\n- 1995年，Sun正式发布Java和HotJava产品，Java首次公开亮相。\n- 1996年1月23日sun Microsystems发布了JDK 1.0。\n- 1998年，JDK1.2版本发布。同时，sun发布了JSP/Servlet、EJB规范，以及将Java分成了J2EE、J2SE和J2ME。这表明了Java开始向企业、桌面应用和移动设备应用3大领域挺进。\n- 2000年，JDK1.3发布，Java HotSpot Virtual Machine正式发布，成为Java的默认虚拟机。\n- 2002年，JDK1.4发布，古老的Classic虚拟机退出历史舞台。\n- 2003年年底，Java平台的scala正式发布，同年Groovy也加入了Java阵营。\n- 2004年，JDK1.5发布。同时JDK1.5改名为JavaSE5.0。\n- 2006年，JDK6发布。同年，Java开源并建立了openJDK。顺理成章，Hotspot虚拟机也成为了openJDK中的默认虚拟机。\n- 2007年，Java平台迎来了新伙伴Clojure。\n- 2008年，oracle收购了BEA，得到了JRockit虚拟机。\n- 2009年，Twitter宣布把后台大部分程序从Ruby迁移到scala，这是Java平台的又一次大规模应用。\n- 2010年，oracle收购了sun，获得Java商标和最真价值的HotSpot虚拟机。此时，oracle拥有市场占用率最高的两款虚拟机HotSpot和JRockit，并计划在未来对它们进行整合：HotRockit\n- 2011年，JDK7发布。在JDK1.7u4中，正式启用了新的垃圾回收器G1。\n- 2017年，JDK9发布。将G1设置为默认Gc，替代CMS\n- 同年，IBM的J9开源，形成了现在的open J9社区\n- 2018年，Android的Java侵权案判决，Google赔偿oracle计88亿美元\n- 同年，oracle宣告JavagE成为历史名词JDBC、JMS、Servlet赠予Eclipse基金会\n- 同年，JDK11发布，LTS版本的JDK，发布革命性的zGc，调整JDK授权许可\n- 2019年，JDK12发布，加入RedHat领导开发的shenandoah GC\n\n![image-20200704182035810](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704182035810.png)\n\n在JDK11之前，oracleJDK中还会存在一些openJDK中没有的、闭源的功能。但在JDK11中，我们可以认为openJDK和oracleJDK代码实质上已经完全一致的程度。\n\n### 虚拟机与 Java 虚拟机\n\n#### 虚拟机\n\n所谓虚拟机（Virtual Machine），就是一台虚拟的计算机。它是一款软件，用来执行一系列虚拟计算机指令。大体上，虚拟机可以分为系统虚拟机和程序虚拟机。\n\n- 大名鼎鼎的Visual Box，Mware就属于系统虚拟机，它们完全是对物理计算机的仿真，提供了一个可运行完整操作系统的软件平台。\n- 程序虚拟机的典型代表就是Java虚拟机，它专门为执行单个计算机程序而设计，在Java虚拟机中执行的指令我们称为Java字节码指令。\n\n无论是系统虚拟机还是程序虚拟机，在上面运行的软件都被限制于虚拟机提供的资源中。\n\n#### Java 虚拟机\n\nJava虚拟机是一台执行Java字节码的虚拟计算机，它拥有独立的运行机制，其运行的Java字节码也未必由Java语言编译而成。\n\nJVM平台的各种语言可以共享Java虚拟机带来的跨平台性、优秀的垃圾回器，以及可靠的即时编译器。\n\nJava技术的核心就是Java虚拟机（JVM，Java Virtual Machine），因为所有的Java程序都运行在Java虚拟机内部。\n\nJava虚拟机就是二进制字节码的运行环境，负责装载字节码到其内部，解释/编译为对应平台上的机器指令执行。每一条Java指令，Java虚拟机规范中都有详细定义，如怎么取操作数，怎么处理操作数，处理结果放在哪里。\n\n特点：\n\n- 一次编译，到处运行\n- 自动内存管理\n- 自动垃圾回收功能\n\n### JVM 的位置\n\nJVM是运行在操作系统之上的，它与硬件没有直接的交互\n\n![image-20200704183048061](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704183048061.png)\n\nJava的体系结构\n\n![image-20200704183236169](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704183236169.png)\n\n### JVM 整体结构\n\n- HotSpot VM是目前市面上高性能虚拟机的代表作之一。\n- 它采用解释器与即时编译器并存的架构。\n- 在今天，Java程序的运行性能早已脱胎换骨，已经达到了可以和C/C++程序一较高下的地步。\n\n![image-20200704183436495](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704183436495.png)\n\n执行引擎包含三部分：解释器，及时编译器，垃圾回收器\n\n### Java 代码执行流程\n\n![image-20200704210429535](/images/%E3%80%90JVM%E3%80%91JVM%E6%A6%82%E8%BF%B0/image-20200704210429535.png)\n\n只是能生成被Java虚拟机所能解释的字节码文件，那么理论上就可以自己设计一套代码了\n\n## JVM 的架构模型\n\nJava编译器输入的指令流基本上是一种**基于栈的指令集架构**，另外一种指令集架构则是**基于寄存器的指令集架构**。具体来说：这两种架构之间的区别：\n\n**基于栈式架构的特点**\n\n- 设计和实现更简单，适用于资源受限的系统；\n- 避开了寄存器的分配难题：使用零地址指令方式分配。\n- 指令流中的指令大部分是零地址指令，其执行过程依赖于操作栈。指令集更小，编译器容易实现。\n- 不需要硬件支持，可移植性更好，更好实现跨平台\n\n**基于寄存器架构的特点**\n\n- 典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。\n- 指令集架构则完全依赖硬件，可移植性差\n- 性能优秀和执行更高效\n- 花费更少的指令去完成一项操作。\n- 在大部分情况下，基于寄存器架构的指令集往往都以一地址指令、二地址指令和三地址指令为主，而基于栈式架构的指令集却是以零地址指令为主方水洋\n\n### 举例\n\n同样执行2+3这种逻辑操作，其指令分别如下：\n\n基于栈的计算流程（以Java虚拟机为例）：\n\n```bash\niconst_2 //常量2入栈\nistore_1\niconst_3 // 常量3入栈\nistore_2\niload_1\niload_2\niadd //常量2/3出栈，执行相加\nistore_0 // 结果5入栈\n```\n\n而基于寄存器的计算流程\n\n```bash\nmov eax,2 //将eax寄存器的值设为1\nadd eax,3 //使eax寄存器的值加3\n```\n\n### 字节码反编译\n\n我们编写一个简单的代码，然后查看一下字节码的反编译后的结果\n\n```java\npublic class StackStruTest {\n    public static void main(String[] args) {\n        int i = 2 + 3;\n    }\n}\n```\n\n然后我们找到编译后的 `.class`文件，使用下列命令进行反编译\n\n```bash\njavap -v StackStruTest.class\n```\n\n得到的文件为:\n\n```\n  public static void main(java.lang.String[]);\n    descriptor: ([Ljava/lang/String;)V\n    flags: ACC_PUBLIC, ACC_STATIC\n    Code:\n      stack=2, locals=4, args_size=1\n         0: iconst_2\n         1: istore_1\n         2: iconst_3\n         3: istore_2\n         4: iload_1\n         5: iload_2\n         6: iadd\n         7: istore_3\n         8: return\n      LineNumberTable:\n        line 9: 0\n        line 10: 2\n        line 11: 4\n        line 12: 8\n      LocalVariableTable:\n        Start  Length  Slot  Name   Signature\n            0       9     0  args   [Ljava/lang/String;\n            2       7     1     i   I\n            4       5     2     j   I\n            8       1     3     k   I\n```\n\n### 总结\n\n由于**跨平台性**的设计，Java的指令都是根据栈来设计的。不同平台CPU架构不同，所以不能设计为基于寄存器的。**优点是跨平台，指令集小，编译器容易实现，缺点是性能下降，实现同样的功能需要更多的指令**。\n\n时至今日，尽管嵌入式平台已经不是Java程序的主流运行平台了（准确来说应该是HotSpotVM的宿主环境已经不局限于嵌入式平台了），那么为什么不将架构更换为基于寄存器的架构呢？\n\n#### 基于栈的指令集架构特点\n\n- 跨平台性\n- 指令集小\n- 指令多\n- 执行性能比寄存器差\n\n## JVM 生命周期\n\n### 虚拟机的启动\n\nJava虚拟机的启动是通过引导类加载器（bootstrap class loader）创建一个初始类（initial class）来完成的，这个类是由虚拟机的具体实现指定的。\n\n### 虚拟机的执行\n\n- 一个运行中的Java虚拟机有着一个清晰的任务：执行Java程序。\n- 程序开始执行时他才运行，程序结束时他就停止。\n- 执行一个所谓的Java程序的时候，真真正正在执行的是一个叫做**Java虚拟机的进程**。\n\n### 虚拟机的退出\n\n有如下的几种情况：\n\n- 程序正常执行结束\n- 程序在执行过程中遇到了异常或错误而异常终止\n- 由于操作系统用现错误而导致Java虚拟机进程终止\n- 某线程调用Runtime类或system类的exit方法，或Runtime类的halt方法，并且Java安全管理器也允许这次exit或halt操作。\n- 除此之外，JNI（Java Native Interface）规范描述了用JNI Invocation API来加载或卸载 Java虚拟机时，Java虚拟机的退出情况。\n\n## JVM 发展历程\n\n### Sun Classic VM\n\n- 早在1996年Java1.0版本的时候，Sun公司发布了一款名为sun classic VM的Java虚拟机，它同时也是世界上第一款商用Java虚拟机，JDK1.4时完全被淘汰。\n- 这款虚拟机内部只提供解释器。现在还有及时编译器，因此效率比较低，而及时编译器会把热点代码缓存起来，那么以后使用热点代码的时候，效率就比较高。\n- 如果使用JIT编译器，就需要进行外挂。但是一旦使用了JIT编译器，JIT就会接管虚拟机的执行系统。解释器就不再工作。解释器和编译器不能配合工作。\n- 现在hotspot内置了此虚拟机。\n\n### Exact VM\n\n为了解决上一个虚拟机问题，jdk1.2时，sun提供了此虚拟机。\n\nExact Memory Management：准确式内存管理\n\n- 也可以叫Non-Conservative/Accurate Memory Management\n- 虚拟机可以知道内存中某个位置的数据具体是什么类型。|\n\n具备现代高性能虚拟机的维形\n\n- 热点探测（寻找出热点代码进行缓存）\n- 编译器与解释器混合工作模式\n\n只在solaris平台短暂使用，其他平台上还是classic vm，英雄气短，终被Hotspot虚拟机替换\n\n### HotSpot VM\n\nHotSpot历史\n\n- 最初由一家名为“Longview Technologies”的小公司设计\n- 1997年，此公司被sun收购；2009年，Sun公司被甲骨文收购。\n- JDK1.3时，HotSpot VM成为默认虚拟机\n\n目前Hotspot占有绝对的市场地位，称霸武林。\n\n- 不管是现在仍在广泛使用的JDK6，还是使用比例较多的JDK8中，默认的虚拟机都是HotSpot\n- Sun/oracle JDK和openJDK的默认虚拟机\n- 因此本课程中默认介绍的虚拟机都是HotSpot，相关机制也主要是指HotSpot的Gc机制。（比如其他两个商用虚机都没有方法区的概念）\n\n从服务器、桌面到移动端、嵌入式都有应用。\n\n名称中的HotSpot指的就是它的热点代码探测技术。\n\n- 通过计数器找到最具编译价值代码，触发即时编译或栈上替换\n- 通过编译器与解释器协同工作，在最优化的程序响应时间与最佳执行性能中取得平衡\n\n### JRockit\n\n专注于服务器端应用\n\n- 它可以不太关注程序启动速度，因此JRockit内部不包含解析器实现，全部代码都靠即时编译器编译后执行。\n\n大量的行业基准测试显示，JRockit JVM是世界上最快的JVM。\n\n- 使用JRockit产品，客户已经体验到了显著的性能提高（一些超过了70%）和硬件成本的减少（达50%）。\n\n优势：全面的Java运行时解决方案组合\n\n- JRockit面向延迟敏感型应用的解决方案JRockit Real Time提供以毫秒或微秒级的JVM响应时间，适合财务、军事指挥、电信网络的需要\n- MissionControl服务套件，它是一组以极低的开销来监控、管理和分析生产环境中的应用程序的工具。\n\n2008年，JRockit被oracle收购。\n\noracle表达了整合两大优秀虚拟机的工作，大致在JDK8中完成。整合的方式是在HotSpot的基础上，移植JRockit的优秀特性。\n\n高斯林：目前就职于谷歌，研究人工智能和水下机器人\n\n### IBM的J9\n\n全称：IBM Technology for Java Virtual Machine，简称IT4J，内部代号：J9\n\n市场定位与HotSpot接近，服务器端、桌面应用、嵌入式等多用途VM广泛用于IBM的各种Java产品。\n\n目前，有影响力的三大商用虚拟机之一，也号称是世界上最快的Java虚拟机。\n\n2017年左右，IBM发布了开源J9VM，命名为openJ9，交给EClipse基金会管理，也称为Eclipse OpenJ9\n\nOpenJDK   -> 是JDK开源了，包括了虚拟机\n\n### KVM和CDC / CLDC  Hotspot\n\noracle在Java ME产品线上的两款虚拟机为：CDC/CLDC HotSpot Implementation VM KVM（Kilobyte）是CLDC-HI早期产品目前移动领域地位尴尬，智能机被Angroid和ioS二分天下。\n\nKVM简单、轻量、高度可移植，面向更低端的设备上还维持自己的一片市场\n\n- 智能控制器、传感器\n- 老人手机、经济欠发达地区的功能手机\n\n所有的虚拟机的原则：一次编译，到处运行。\n\n### Azul VM\n\n前面三大“高性能Java虚拟机”使用在通用硬件平台上这里Azu1VW和BEALiquid VM是与特定硬件平台绑定、软硬件配合的专有虚拟机I\n\n- 高性能Java虚拟机中的战斗机。\n\nAzul VM是Azu1Systems公司在HotSpot基础上进行大量改进，运行于Azul Systems公司的专有硬件Vega系统上的ava虚拟机。\n\n每个Azu1VM实例都可以管理至少数十个CPU和数百GB内存的硬件资源，并提供在巨大内存范围内实现可控的GC时间的垃圾收集器、专有硬件优化的线程调度等优秀特性。\n\n2010年，AzulSystems公司开始从硬件转向软件，发布了自己的zing JVM，可以在通用x86平台上提供接近于Vega系统的特性。\n\n### Liquid VM\n\n高性能Java虚拟机中的战斗机。\n\nBEA公司开发的，直接运行在自家Hypervisor系统上Liquid VM即是现在的JRockit VE（Virtual Edition），\n\nLiquid VM不需要操作系统的支持，或者说它自己本身实现了一个专用操作系统的必要功能，如线程调度、文件系统、网络支持等。\n\n随着JRockit虚拟机终止开发，Liquid vM项目也停止了。\n\n### Apache Marmony\n\nApache也曾经推出过与JDK1.5和JDK1.6兼容的Java运行平台Apache Harmony。\n\n它是IElf和Inte1联合开发的开源JVM，受到同样开源的openJDK的压制，Sun坚决不让Harmony获得JCP认证，最终于2011年退役，IBM转而参与OpenJDK\n\n虽然目前并没有Apache Harmony被大规模商用的案例，但是它的Java类库代码吸纳进了Android SDK。\n\n### Micorsoft JVM\n\n微软为了在IE3浏览器中支持Java Applets，开发了Microsoft JVM。\n\n只能在window平台下运行。但确是当时Windows下性能最好的Java VM。\n\n1997年，sun以侵犯商标、不正当竞争罪名指控微软成功，赔了sun很多钱。微软windowsXPSP3中抹掉了其VM。现在windows上安装的jdk都是HotSpot。\n\n### Taobao JVM\n\n由AliJVM团队发布。阿里，国内使用Java最强大的公司，覆盖云计算、金融、物流、电商等众多领域，需要解决高并发、高可用、分布式的复合问题。有大量的开源产品。\n\n基于openJDK开发了自己的定制版本AlibabaJDK，简称AJDK。是整个阿里Java体系的基石。\n\n基于openJDK Hotspot VM发布的国内第一个优化、深度定制且开源的高性能服务器版Java虚拟机。\n\n- 创新的GCIH（GCinvisible heap）技术实现了off-heap，即将生命周期较长的Java对象从heap中移到heap之外，并且Gc不能管理GCIH内部的Java对象，以此达到降低GC的回收频率和提升Gc的回收效率的目的。\n- GCIH中的对象还能够在多个Java虚拟机进程中实现共享\n- 使用crc32指令实现JvM intrinsic降低JNI的调用开销\n- PMU hardware的Java profiling tool和诊断协助功能\n- 针对大数据场景的ZenGc \n\ntaobao vm应用在阿里产品上性能高，硬件严重依赖inte1的cpu，损失了兼容性，但提高了性能\n\n目前已经在淘宝、天猫上线，把oracle官方JvM版本全部替换了。\n\n### Dalvik VM\n\n谷歌开发的，应用于Android系统，并在Android2.2中提供了JIT，发展迅猛。\n\nDalvik y只能称作虚拟机，而不能称作“Java虚拟机”，它没有遵循 Java虚拟机规范\n\n不能直接执行Java的Class文件\n\n基于寄存器架构，不是jvm的栈架构。\n\n执行的是编译以后的dex（Dalvik Executable）文件。执行效率比较高。\n\n- 它执行的dex（Dalvik Executable）文件可以通过class文件转化而来，使用Java语法编写应用程序，可以直接使用大部分的Java API等。\n\nAndroid 5.0使用支持提前编译（Ahead of Time Compilation，AoT）的ART VM替换Dalvik VM。\n\n### Graal VM\n\n2018年4月，oracle Labs公开了GraalvM，号称 \"Run Programs Faster Anywhere\"，勃勃野心。与1995年java的”write once，run anywhere\"遥相呼应。\n\nGraalVM在HotSpot VM基础上增强而成的跨语言全栈虚拟机，可以作为“任何语言”\n的运行平台使用。语言包括：Java、Scala、Groovy、Kotlin；C、C++、Javascript、Ruby、Python、R等\n\n支持不同语言中混用对方的接口和对象，支持这些语言使用已经编写好的本地库文件\n\n工作原理是将这些语言的源代码或源代码编译后的中间格式，通过解释器转换为能被Graal VM接受的中间表示。Graal VM提供Truffle工具集快速构建面向一种新语言的解释器。在运行时还能进行即时编译优化，获得比原生编译器更优秀的执行效率。\n\n如果说HotSpot有一天真的被取代，Graalvm希望最大。但是Java的软件生态没有丝毫变化。\n\n### 总结\n\n具体JVM的内存结构，其实取决于其实现，不同厂商的JVM，或者同一厂商发布的不同版本，都有可能存在一定差异。主要以oracle HotSpot VM为默认虚拟机。\n\n","tags":["JVM"],"categories":["JVM"]},{"title":"【MyBatis】Spring Boot 整合 MyBatis","url":"/2021/09/14/【MyBatis】SpringBoot整合MyBatis/","content":"\n![img](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/kuangstudyb0b1cef3-3796-4822-bfe8-52a894961853.png)\n\n## 整合 Druid 数据源\n\n### 导入 JDBC 场景\n\n在Maven中导入JDBC场景`spring-boot-starter-data-jdbc`：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-jdbc</artifactId>\n</dependency>\n\n```\n\n导入该场景后，将出现数据源Hikari、JDBC和事务等依赖：\n\n![image-20210804152401123](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210804152401123.png)\n\n<!-- More -->\n\n导入数据库MySQL驱动的依赖：\n\n```xml\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n</dependency>\n```\n\nSpring Boot提供的MySQL驱动的默认版本：`<mysql.version>8.0.22</mysql.version>`\n\n若想要修改版本，可以：\n\n1. 直接依赖引入具体版本（maven的就近依赖原则）\n2. 重新声明版本（maven的属性的就近优先原则）\n\n```xml\n<properties>\n    <java.version>1.8</java.version>\n    <mysql.version>5.1.49</mysql.version>\n</properties>\n\n<!-- 或者：-->\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.49 </version>\n</dependency>\n```\n\n### 数据源自动配置原理\n\n**DataSourceAutoConfiguration**： 数据源的自动配置类\n\n- 修改**数据源**相关的配置前缀：`\"spring.datasource\"`\n- **数据库连接池**的配置，是容器中**没有自定义的DataSource时**才自动配置的\n- 底层自动配置的数据源是：**HikariDataSource**\n\n![image-20210804153524354](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210804153524354.png)\n\n修改**数据源**的配置项：\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/school?useUnicode=true&characterEncoding=utf8&useSSL=true\n    username: root\n    password: zhaoyuyun\n    driver-class-name: com.mysql.jdbc.Driver\n```\n\n其他数据库相关的自动配置类：\n\n- **DataSourceTransactionManagerAutoConfiguration**： 事务管理器的自动配置\n- **JdbcTemplateAutoConfiguration**： JdbcTemplate的自动配置，可以来对数据库进行crud。容器中有**JdbcTemplate**这个组件，可以修改配置前缀  `\"spring.jdbc\"` 来修改JdbcTemplate的配置。\n- **JndiDataSourceAutoConfiguration**： jndi的自动配置\n- **XADataSourceAutoConfiguration**： 分布式事务相关的\n\n### Druid 数据源\n\nDruid官方github地址：https://github.com/alibaba/druid\n\n引入Druid官方提供的`starter`场景依赖：\n\n```xml\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>druid-spring-boot-starter</artifactId>\n    <version>1.1.17</version>\n</dependency>\n```\n\n其向容器中添加了一个Druid数据源自动配置类**DruidDataSourceAutoConfigure**：\n\n![image-20210804202513107](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210804202513107.png)\n\n- 该配置器在Spring Boot自带的数据源自动配置器**DataSourceAutoConfiguration**之前配置，因此不再注册Spring Boot默认的数据源**HikariDataSource**。\n- 该配置器绑定了**DataSourceProperties**和**DruidStatProperties**资源配置类，分别对应资源路径`\"spring.datasource\"`和`\"spring.datasource.druid\"`\n- 该配置器导入了其他相关的配置类，用于开启配置页、防火墙、Web监控等功能\n\n导入的其他相关配置类如下：\n\n- **DruidSpringAopConfiguration.class**（`spring.datasource.druid.aop-patterns`）：监控Spring Bean\n- **DruidStatViewServletConfiguration.class**（`spring.datasource.druid.stat-view-servlet`）：配置监控页：\n- **DruidWebStatFilterConfiguration.class**（`spring.datasource.druid.web-stat-filter`）：Web监控配置\n- **DruidFilterConfiguration.class**：配置Druid的所有Filters：\n\n```java\nprivate static final String FILTER_STAT_PREFIX = \"spring.datasource.druid.filter.stat\";\nprivate static final String FILTER_CONFIG_PREFIX = \"spring.datasource.druid.filter.config\";\nprivate static final String FILTER_ENCODING_PREFIX = \"spring.datasource.druid.filter.encoding\";\nprivate static final String FILTER_SLF4J_PREFIX = \"spring.datasource.druid.filter.slf4j\";\nprivate static final String FILTER_LOG4J_PREFIX = \"spring.datasource.druid.filter.log4j\";\nprivate static final String FILTER_LOG4J2_PREFIX = \"spring.datasource.druid.filter.log4j2\";\nprivate static final String FILTER_COMMONS_LOG_PREFIX = \"spring.datasource.druid.filter.commons-log\";\nprivate static final String FILTER_WALL_PREFIX = \"spring.datasource.druid.filter.wall\";\n```\n\n配置示例：\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/db_account\n    username: root\n    password: 123456\n    driver-class-name: com.mysql.jdbc.Driver\n\n    druid:\n      aop-patterns: com.zhao.admin.*  # 监控SpringBean\n      filters: stat,wall     # 底层开启功能，stat（sql监控），wall（防火墙）\n\n      stat-view-servlet:   # 配置监控页功能\n        enabled: true\n        login-username: admin\n        login-password: admin\n        resetEnable: false\n\n      web-stat-filter:  # 监控web\n        enabled: true\n        urlPattern: /*\n        exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*'\n\n      filter:\n        stat:    # 对上面filters里面的stat的详细配置\n          slow-sql-millis: 1000\n          logSlowSql: true\n          enabled: true\n        wall:\n          enabled: true\n          config:\n            drop-table-allow: false\n```\n\nSpringBoot配置示例：https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter\n\n配置项列表：[https://github.com/alibaba/druid/wiki/DruidDataSource%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E5%88%97%E8%A1%A8](https://github.com/alibaba/druid/wiki/DruidDataSource配置属性列表)\n\n## 整合 MyBatis\n\nMyBatis官方链接：https://github.com/mybatis\n\n导入MyBatis的`starter`场景依赖：\n\n```XML\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.4</version>\n</dependency>\n```\n\n其导入了如下包：\n\n![image-20210805142616006](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805142616006.png)\n\n其中，MyBatis的自动配置器**MybatisAutoConfiguration**会在Spring Boot启动时注册到容器中：\n\n![image-20210805143359047](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805143359047.png)\n\n该类绑定了**MybatisProperties**，对应Spring Boot的配置文件中以`\"mybatis\"`为前缀的属性：\n\n![image-20210805144216362](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805144216362.png)\n\n1. **MybatisAutoConfiguration**向容器中注册了**sqlSessionFactory**，其使用容器中存在的数据源，并且从配置资源类**MybatisProperties**中获取MyBatis的配置属性值：\n\n![image-20210805143832167](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805143832167.png)\n\n2. **MybatisAutoConfiguration**向容器中注册了**SqlSessionTemplate**，其可以执行批量的**SqlSession**：\n\n![image-20210805144629709](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805144629709.png)\n\n![image-20210805144721508](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805144721508.png)\n\n3. **MybatisAutoConfiguration**向容器中注册了**AutoConfiguredMapperScannerRegistrar**，其用于扫描容器中带有 **@Mapper** 注解的组件：\n\n![image-20210805151107546](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805151107546.png)\n\n### 使用 MyBatis\n\n开启MyBatis流程：\n\n- 导入MyBatis官方starter场景： `mybatis-spring-boot-starter`\n- 编写`xxxMapper`接口，并在其上使用 **@Mapper** 注解（也可以使用 **@MapperScan()**  简化）\n- 编写sql映射文件`xxxMapper.xml`（放置在`classpath:mapper/*.xml`下）并绑定`xxxMapper`接口\n- 在`application.yaml`中指定mapper配置文件的位置`mapper-locations`，以及指定全局配置文件的信息\n\n具体步骤如下：\n\n1. 导入MyBatis的starter场景： `mybatis-spring-boot-starter`\n\n```XML\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.4</version>\n</dependency>\n```\n\n2. 编写`UserMapper`接口，并在其上使用 **@Mapper** 注解（也可以使用 **@MapperScan(\"com.zhao.mapper\")**  简化）\n\n```java\n@Mapper\npublic interface UserMapper {\n\n    // 可以使用注解代替xml里的sql语句\n    @Select(\"select * from user where id = #{id}\")\n    User selectUser(Long id);\n\n    void deleteUser(Long id);\n}\n```\n\n3. 编写sql映射文件`userMapper.xml`（放置在`classpath:mapper/*.xml`下）\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.zhao.admin.mapper.UserMapper\">\n    <select id=\"selectUser\" resultType=\"com.zhao.admin.bean.User\">\n        select * from user where id = #{id}\n    </select>\n\n    <delete id=\"deleteUser\" parameterType=\"long\">\n        delete from user where id = #{id}\n    </delete>\n</mapper>\n```\n\n4. 在`application.yaml`中配置MyBatis：\n\n```yaml\nmybatis:\n  #  config-location: classpath:mybatis/mybatis-config.xml\n  mapper-locations: classpath:mapper/*.xml\n  \n  # 可以不写mybatis-config.xml，所有全局配置文件的配置都放在configuration配置项中即可\n  configuration:\n    map-underscore-to-camel-case: true  \n```\n\n项目结构：\n\n![image-20210805212017625](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805212017625.png)\n\n### 整合 MyBatis Plus\n\n导入MyBatis-Plus的`starter`场景：`mybatis-plus-boot-starter`\n\n```xml\n<dependency>\n    <groupId>com.baomidou</groupId>\n    <artifactId>mybatis-plus-boot-starter</artifactId>\n    <version>3.4.1</version>\n</dependency>\n```\n\n其会向容器中导入**MybatisPlusAutoConfiguration**：\n\n![image-20210805194210051](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805194210051.png)\n\n其对应的配置前缀为`\"mybatis-plus\"`，其会默认扫描`\"classpath*:/mapper/**/*.xml\"`，即类路径下mapper目录下的所有`.xml`文件都会被作为MyBatis的xml进行扫描（开发人员将sql映射文件放置在该目录下即可）：\n\n![image-20210805193856503](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805193856503.png)\n\n使用时，自定义的Mapper接口继承 `BaseMapper<User>` 接口即可自动实现简单功能的CRUD:\n\n```java\n@Mapper\npublic interface UserMapper extends BaseMapper<User> {\n\n}\n```\n\n `BaseMapper<User>` 接口中默认实现了简单CRUD的方法：\n\n![image-20210805213009214](/images/%E3%80%90MyBatis%E3%80%91SpringBoot%E6%95%B4%E5%90%88MyBatis/image-20210805213009214.png)\n\n使用MyBatis Plus提供的`IService`，`ServiceImpl`，减轻Service层开发工作。\n\n``` java\nimport com.zhao.hellomybatisplus.model.User;\nimport com.baomidou.mybatisplus.extension.service.IService;\n\nimport java.util.List;\n\n/**\n *  Service 的CRUD也不用写了\n */\npublic interface UserService extends IService<User> {\n\t//此处故意为空\n}\n```\n\n``` java\nimport com.zhao.hellomybatisplus.model.User;\nimport com.zhao.hellomybatisplus.mapper.UserMapper;\nimport com.zhao.hellomybatisplus.service.UserService;\nimport com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport java.util.List;\n\n@Service\npublic class UserServiceImpl extends ServiceImpl<UserMapper,User> implements UserService {\n\t//此处故意为空\n}\n```\n\n## \n\n\n\n","tags":["MyBatis"],"categories":["MyBatis"]},{"title":"【Redis】Spring Boot 整合 Redis","url":"/2021/09/13/【Redis】SpringBoot整合Redis/","content":"\n![image-20210913131720145](/images/%E3%80%90Redis%E3%80%91SpringBoot%E6%95%B4%E5%90%88Redis/image-20210913131720145.png)\n\n### 导入依赖\n\n导入Redis的`starter`场景依赖：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n\n<!-- spring2.X 集成redis所需common-pool2-->\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-pool2</artifactId>\n</dependency>\n\n<!--导入jedis-->\n<dependency>\n    <groupId>redis.clients</groupId>\n    <artifactId>jedis</artifactId>\n</dependency>\n```\n\nRedis相关的组件都由 **RedisAutoConfiguration** 完成配置和注入：\n\n![image-20210914141335348](/images/%E3%80%90Redis%E3%80%91SpringBoot%E6%95%B4%E5%90%88Redis/image-20210914141335348.png)\n\n其绑定了 `spring.redis` 属性，并且向容器中注入了：\n\n- `RedisTemplate<Object, Object>`\n- `StringRedisTemplate`，其 key-value 都是String类型\n\n提供了两种 Redis 客户端：\n\n- **Lettuce**：默认，基于Netty框架的客户端，线程安全，性能较好。\n- **Jedis**\n\n<!-- More -->\n\n### 配置文件\n\n``` yaml\nspring:\n  redis:\n    host: 192.168.1.203\n    port: 6379\n    password:  \n    database: 0             # Redis 数据库索引（默认为0）\n    client-type: lettuce    # Redis 客户端类型\n    timeout: 1800000        # 连接超时时间（毫秒）\n    lettuce:\n       pool:\n         max-active: 10     # 连接池最大连接数（使用负值表示没有限制）\n         max-wait: -1       # 最大阻塞等待时间（负数表示没限制）\n         min-idle: 5        # 连接池中的最大空闲连接\n         min-idle: 0        # 连接池中的最小空闲连接\n\n    # 也可以配置客户端为 jedis      \n    # jedis:\n      # pool:\n        # max-active: 10\n```\n\n### Redis 配置类\n\n``` java\n@EnableCaching\n@Configuration\npublic class RedisConfig extends CachingConfigurerSupport {\n\n    @Bean\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        RedisSerializer<String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        template.setConnectionFactory(factory);\n        // key序列化方式\n        template.setKeySerializer(redisSerializer);\n        // value序列化\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n        // value hashmap序列化\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        return template;\n    }\n\n    @Bean\n    public CacheManager cacheManager(RedisConnectionFactory factory) {\n        RedisSerializer<String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        // 解决查询缓存转换异常的问题\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        // 配置序列化（解决乱码的问题）, 过期时间600秒\n        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()\n            .entryTtl(Duration.ofSeconds(600))\n            .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))\n            .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))\n            .disableCachingNullValues();\n        RedisCacheManager cacheManager = RedisCacheManager.builder(factory)\n            .cacheDefaults(config)\n            .build();\n        return cacheManager;\n    }\n}\n```\n\n### 业务类测试\n\n``` java\n@RestController\n@RequestMapping(\"/redisTest\")\npublic class RedisTestController {\n    @Autowired\n    private RedisTemplate redisTemplate;\n    \n    @Autowired\n    private StringRedisTemplate redisTemplate;\n    \n    @Autowired\n    private RedisConnectionFactory redisConnectionFactory;\n\n    @GetMapping\n    public String testRedis01() {\n        // 设置值到redis\n        redisTemplate.opsForValue().set(\"name\",\"lucy\");\n\n        // 从redis获取值\n        String name = (String)redisTemplate.opsForValue().get(\"name\");\n        return name;\n    }\n    \n    @GetMapping\n    void testRedis02(){\n        ValueOperations<String, String> operations = redisTemplate.opsForValue();\n        operations.set(\"hello\",\"world\");\n        String hello = operations.get(\"hello\");\n        \n        System.out.println(hello);\n        System.out.println(redisConnectionFactory.getClass());\n    }\n}\n```\n\n### 统计 URL 访问次数\n\n自定义拦截器统计URL的访问次数\n\n``` java\n@Component\npublic class RedisUrlCountInterceptor implements HandlerInterceptor {\n    @Autowired\n    StringRedisTemplate redisTemplate;\n\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n        String uri = request.getRequestURI();\n        // 默认每次访问当前uri就会计数+1\n        redisTemplate.opsForValue().increment(uri);\n        return true;\n    }\n}\n```\n\n注册URL统计拦截器：\n\n``` java\n@Configuration\npublic class AdminWebConfig implements WebMvcConfigurer{\n    @Autowired\n    RedisUrlCountInterceptor redisUrlCountInterceptor;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(redisUrlCountInterceptor)\n            .addPathPatterns(\"/**\")\n            .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/fonts/**\",\"/images/**\",\n                                 \"/js/**\",\"/aa/**\");\n    }\n}\n```\n\n调用Redis内的统计数据：\n\n``` java\n@Slf4j\n@Controller\npublic class IndexController {\n\n\t@Autowired\n    StringRedisTemplate redisTemplate;\n    \n\t@GetMapping(\"/main.html\")\n    public String mainPage(HttpSession session,Model model){\n        log.info(\"当前方法是：{}\",\"mainPage\");\n\n        ValueOperations<String, String> opsForValue =\n                redisTemplate.opsForValue();\n\n        String s = opsForValue.get(\"/main.html\");\n        String s1 = opsForValue.get(\"/sql\");\n\n        model.addAttribute(\"mainCount\",s);\n        model.addAttribute(\"sqlCount\",s1);\n\n        return \"main\";\n    }\n}\n```\n\n\n\n\n\n","tags":["Redis"],"categories":["Redis"]},{"title":"【Docker】Docker 基础","url":"/2021/09/13/【Docker】Docker/","content":"\n## Docker 简介\n\n### Docker 理念\n\nDocker 是基于Go语言实现的云开源项目。Docker 的主要目标是“**Build, Ship[ and Run Any App,Anywhere**\"，也就是通过对应用组件的封装、分发、部署、运行等生命期的管理，使用户的APP （可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“**一次封装，到处运行**”。\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-02_18-14-27.png)\n\n Linux容器技术的出现就解决了这样一一个问题，而Docker就是在它的基础上发展过来的。将应用运行在Docker容器上面，而Docker容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。**只需要一次配置好环境，换到别的机器上就可以一键部署好，大大简化了操作**。\n\n一句话：Docker 是解决了运行环境和配置问题的**软件容器**，方便做持续集成并有助于整体发布的**容器虚拟化技术**\n\n### 之前的虚拟机技术\n\n虚拟机（virtual machine）就是带环境安装的一种解决方案。\n\n它可以在一种操作系统里面运行另一种作系统，比如在**Windows系统里面运行Linux系统**。应用程序对此毫无感知，因为虚拟机看上去跟真实系统一模一样，而对于底层系统来说，虚拟机就是一个普通文件，不需要了就删掉，对其他部分毫无影响。这类虚拟机完美的运行了另一套系统，能够使应用程序，操作系统和硬件三者之间的逻辑不变。\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-02_18-18-07.png)\n\n虚拟机的缺点：\n\n- 资源占用多\n- 冗余步骤多\n- 启动慢\n\n### 容器虚拟化技术\n\n由于前面虛拟机存在这些缺点，Linux 发展出了另一种虚拟化技术: **Linux 容器**（Linux Containers，缩为LXC）。\n\n**Linux 容器不是模拟一个完整的操作系统**，而是对进程进行**隔离**。有了容器，就可以将软件运行所的所有资源打包到一个**隔离的容器**中。容器与虚拟机不同，不需要捆绑一整套操作系统，只需要软件工作所需的库资源和设置。系统因此而变得高效轻量并保证部署在任何环境中的软件都能始终如一地运行。\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-02_18-22-04.png)\n\n比较Docker和传统虚拟化方式的不同之处：\n\n- 传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程。\n- 而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，**而且也没有进行硬件虚拟**。因此容器要比传统虚拟机为轻便。\n- **每个容器之间互相隔离**，每个容器有自己的文件系统，容器之间进程不会相互影响，能区分计算资源。\n\n<!-- More -->\n\n### 开发/运维（DevOps）\n\n一次构建、随处运行。\n\n#### 更快速的应用交付和部署\n\n​\t传统的应用开发完成后，需要提供一堆安装程序和配置说明文档，安装部署后需根据配置文档进行繁杂的配置才能正常运行。Docker化之后只需要交付少量容器镜像文件，在正式生产环境加载镜像并运行即可，应用安装配置在镜像里已经内置好，大大节省部署配置和测试验证时间。\n\n#### 更便捷的升级和扩缩容\n\n随着微服务架构和Docker的发展，大量的应用会通过微服务方式架构，应用的开发构建将变成搭乐高积木一样，每个Docker容器将变成一块“积木”，应用的升级将变得非常容易。当现有的容器不足以支撑业务处理时，可通过镜像运行新的容器进行快速扩容，使应用系统的扩容从原先的天级变成分钟级甚至秒级。\n\n#### 更简单的系统运维\n\n应用容器化运行后，生产环境运行的应用可与开发、测试环境的应用高度--致，容器会将应用程序相关的环境和状态完全封装起来，不会因为底层基础架构和操作系统的不一致性给应用带来影响，产生新的BUG。当出现程序异常时，也可以通过测试环境的相同容器进行快速定位和修复。\n\n#### 更高效的计算资源利用\n\n​\t**Docker是内核级虚拟化**，其不像传统的虚拟化技术一样 需要额外的Hypervisor支持，所以在一台物理机上可以运行很多个容器实例，可大大提升物理服务器的CPU和内存的利用率。\n\n\n\n### Docker 的基本组成\n\nDocker架构图：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/architecture.svg)\n\n#### 镜像（image）\n\nDocker镜像（lmage）就是一个**只读**的模板。**镜像可以用来创建Docker容器，一个镜像可以创建很多容器**。\n\n通过 `docker run imageName/imageID` 命令可以创建并运行某一个镜像的容器实例（可以创建多个容器实例）。\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-02_19-39-12.png)\n\n#### 容器（container）\n\nDocker利用容器（Container）独立运行的一个或一组应用。**容器是用镜像创建的运行实例**。它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台。\n\n**可以把容器看做是一个简易版的Linux环境**（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。容器的定义和镜像几乎一模一样，也是一堆层的统一视角， 唯一区别在于容器的最上面那一层是可读可写的。\n\n通过 `docker commit containerID imageName:tag` 命令可以创建出某个容器实例对应的镜像文件，从而将自己自定义的环境进行打包发布。\n\n#### 仓库（repository）\n\n仓库（**Repository**）是**集中存放镜像**文件的场所。仓库（Repository）和仓库注册服务器（Registry） 是有区别的。仓库注册服务器上往往存放着多个仓库，每个仓库中又包含了多镜像，每个镜像有不同的标签（tag） 。\n\n仓库分为公开仓库（**Public**) 和私有仓库（**Private**) 两种形式。**最大的公开仓库是Docker Hub（ttps://hub. docker.com/)**。存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云、网易云等\n\n#### 总结\n\n需要正确的理解仓储/镜像/容器这几个概念:\n\nDocker本身是一个容器运行载体或称之为管理引擎。**我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就似乎image镜像文件**。只有通过这个镜像文件才能生成Docker容器。image文件可以看作是容器的模板。Docker根据image文件生成容器的实例。同一个image文件，可以生成多个同时运行的容器实例。\n\n一个容器运行一种服务，当我们需要的时候，就可以通过Docker客户端创建一个对应的运行实例，也就是我们的容器。至于仓储，就是放了一堆镜像的地方，我们可以把镜像发布到仓储中，需要的时候从仓储中拉下来就可以了。\n\n\n\n### Docker 底层原理\n\n#### Docker 是怎样工作的\n\nDocker是一个Client-Server结构的系统，Docker守护进程运行在主机上，然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。**容器，是一个运行时环境，就是我们前面说到的集装箱。**\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_10-58-47.png)\n\n#### 为什么 Docker 比 VM 快\n\n**Docker有着比虚拟机更少的抽象层**。由于Docker不需要**Hypervisor**实现硬件资源虚拟化，运行在Docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上Docker将会在效率上有明显优势。\n\n**Docker利用的是宿主机的内核*，而不需要Guest OS**。因此，当新建一个容器时，Docker不需要和虚拟机一样重新加载一个操作系统内核仍而避免引导、加载操作系统内核返个比较费时费资源的过程，当新建一个虚拟机时，虚拟机软件需要加载GuestOS，返个新建过程是分钟级别的。而Docker由于直接利用宿主机的操作系统，则省略了返个过程,因此新建一个Docker容器只需要几秒钟。\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_11-00-34.png)\n\n![img](/images/%E3%80%90Docker%E3%80%91Docker/20210717130758965.png)\n\n\n\n## Docker 安装\n\n>  Docker官网： https://www.docker.com/； Docker中文网站: https://www.docker-cn.com/； Docker Hub官网：https://hub.docker.com/\n\n1. CentOS 7 安装 Docker：\n\n``` bash\nyum install -y docker\n```\n\n2. 开启 Docker 服务：\n\n``` bash\nsystemctl start docker.service\n```\n\n3. 查看安装结果：\n\n``` bash\ndocker version\n```\n\n4. 设置开机启动：\n\n``` bash\nsystemctl enable docker.service\n```\n\n5. 配置 docker 镜像下载加速。编辑配置⽂件：\n\n``` bash\nvim /etc/docker/daemon.json\n```\n\n在其中加入加速镜像源地址即可（https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors）：\n\n``` bash\n{\n  \"registry-mirrors\": [\"https://gc2odbl5.mirror.aliyuncs.com\"]\n}\n```\n\n加完加速地址后，重新加载配置⽂件，重启docker 服务即可：\n\n``` bash\nsystemctl daemon-reload\nsystemctl restart docker.service\n```\n\n\n\n## Docker 常用命令\n\n### 基础命令\n\n``` bash\ndocker version           # 查看docker的版本信息\ndocker info              # 查看docker的系统信息,包括镜像和容器的数量\ndocker xxx --help        # 帮助命令(可查看可选的参数)\ndocker COMMAND --help\n```\n\n命令的帮助文档地址：https://docs.docker.com/engine/reference/commandline/docker/\n\n### 镜像命令\n\n1. `docker images` 查看本地主机的所有镜像：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker images\nREPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nhello-world   latest    bf756fb1ae65   11 months ago   13.3kB\n\n# 解释:\n1.REPOSITORY  镜像的仓库源\n2.TAG  镜像的标签\n3.IMAGE ID 镜像的id\n4.CREATED 镜像的创建时间\n5.SIZE 镜像的大小\n\n# 可选参数\n-a/--all 列出所有镜像\n-q/--quiet 只显示镜像的id\n```\n\n2. `docker search` 搜索DockerHub仓库中的镜像：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker search mysql\nNAME                              DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nmysql                             MySQL is a widely used, open-source relation…   10308     [OK]\nmariadb                           MariaDB is a community-developed fork of MyS…   3819      [OK]\nmysql/mysql-server                Optimized MySQL Server Docker images. Create…   754                  [OK]\npercona                           Percona Server is a fork of the MySQL relati…   517       [OK]\ncentos/mysql-57-centos7           MySQL 5.7 SQL database server                   86\nmysql/mysql-cluster               Experimental MySQL Cluster Docker images. Cr…   79\ncenturylink/mysql                 Image containing mysql. Optimized to be link…   60                   [OK]\n\n# 可选参数\nSearch the Docker Hub for images\n\nOptions:\n  -f, --filter filter   Filter output based on conditions provided\n      --format string   Pretty-print search using a Go template\n      --limit int       Max number of search results (default 25)\n      --no-trunc        Do not truncate output\n      \n# 搜索收藏数大于3000的镜像\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker search mysql --filter=STARS=3000\nNAME      DESCRIPTION                                     STARS     OFFICIAL   AUTOMATED\nmysql     MySQL is a widely used, open-source relation…   10308     [OK]\nmariadb   MariaDB is a community-developed fordockerk of MyS…   3819      [OK]\n```\n\n3. `docker pull 镜像名[:tag]` 下载镜像：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker pull mysql\nUsing default tag: latest            # 如果不写tag默认就是latest\nlatest: Pulling from library/mysql\n6ec7b7d162b2: Pull complete          # 分层下载,docker image的核心-联合文件系统\nfedd960d3481: Pull complete\n7ab947313861: Pull complete\n64f92f19e638: Pull complete\n3e80b17bff96: Pull complete\n014e976799f9: Pull complete\n59ae84fee1b3: Pull complete\nffe10de703ea: Pull complete\n657af6d90c83: Pull complete\n98bfb480322c: Pull complete\n6aa3859c4789: Pull complete\n1ed875d851ef: Pull complete\nDigest: sha256:78800e6d3f1b230e35275145e657b82c3fb02a27b2d8e76aac2f5e90c1c30873 #签名\nStatus: Downloaded newer image for mysql:latest\ndocker.io/library/mysql:latest  # 下载来源的真实地址  \n\n# docker pull mysql 等价于 docker pull docker.io/library/mysql:latest\n```\n\n指定版本下载：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker pull mysql:5.7\n5.7: Pulling from library/mysql\n6ec7b7d162b2: Already exists\nfedd960d3481: Already exists\n7ab947313861: Already exists\n64f92f19e638: Already exists\n3e80b17bff96: Already exists\n014e976799f9: Already exists\n59ae84fee1b3: Already exists\n7d1da2a18e2e: Pull complete\n301a28b700b9: Pull complete\n529dc8dbeaf3: Pull complete\nbc9d021dc13f: Pull complete\nDigest: sha256:c3a567d3e3ad8b05dfce401ed08f0f6bf3f3b64cc17694979d5f2e5d78e10173\nStatus: Downloaded newer image for mysql:5.7\ndocker.io/library/mysql:5.7\n```\n\n4. `docker rmi` 删除镜像：\n\n``` bash\n# 1.删除指定的镜像id\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker rmi -f  镜像id\n# 2.删除多个镜像id\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker rmi -f  镜像id 镜像id 镜像id\n# 3.删除全部的镜像id\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker rmi -f  $(docker images -aq)\n```\n\n5. `docker commit` 提交容器副本使之称为一个新的镜像：\n\n``` bash\n$ docker commit -m=\"提交的描述信息\" -a=\"作者\" 容器ID 要创建的目标镜像名:[标签名]\n```\n\n\n\n### 容器命令\n\n1. `docker run` 运行容器：\n\n``` bash\n$ docker run [可选参数] image\n\n# 参数说明\n--name=\"名字\"           指定容器名字\n-d                     后台方式运行\n-it                    使用交互方式运行,进入容器查看内容\n-p                     指定容器的端口\n(\n-p ip:主机端口:容器端口  配置主机端口映射到容器端口\n-p 主机端口:容器端口\n-p 容器端口\n)\n-P                     随机指定端口(大写的P)\n```\n\n以前台方式进入容器，并进行交互：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker run -it centos /bin/bash\n[root@bd1b8900c547 /]$ ls      \nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n```\n\n2. 退出容器：\n\n``` bash\n# exit 停止并退出容器（后台方式运行则仅退出）\n# Ctrl+P+Q  不停止容器退出\n[root@bd1b8900c547 /]$ exit\nexit\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$\n```\n\n3. `docker ps` 列出运行过的容器：\n\n``` bash\n$ docker ps  # 列出当前正在运行的容器\n        -a   # 列出所有容器的运行记录\n        -n=? # 显示最近创建的n个容器\n        -q   # 只显示容器的编号\n\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker ps\nCONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker ps -a\nCONTAINER ID   IMAGE          COMMAND       CREATED         STATUS                     PORTS     NAMES\nbca129320bb5   centos         \"/bin/bash\"   4 minutes ago   Exited (0) 3 minutes ago             optimistic_shtern\nbd1b8900c547   centos         \"/bin/bash\"   6 minutes ago   Exited (0) 5 minutes ago             cool_tesla\ncf6adbf1b506   bf756fb1ae65   \"/hello\"      5 hours ago     Exited (0) 5 hours ago               optimistic_darwin\n```\n\n4. `docker rm` 删除容器：\n\n``` bash\n$ docker rm 容器id                 # 删除指定的容器,不能删除正在运行的容器,强制删除使用 rm -f\n$ docker rm -f $(docker ps -aq)   # 删除所有的容器\n$ docker ps -a -q|xargs docker rm # 删除所有的容器\n```\n\n5. 启动和停止容器：\n\n``` bash\n$ docker start 容器id          # 启动容器\n$ docker restart 容器id        # 重启容器\n$ docker stop 容器id           # 停止当前运行的容器\n$ docker kill 容器id           # 强制停止当前容器\n```\n\n6. `docker run -d xxx` 启动守护式容器（在后台运行）\n\n\n\n### 其他常用命令\n\n1. 日志的查看\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker logs --help\n\nUsage:  docker logs [OPTIONS] CONTAINER\nFetch the logs of a container\n\nOptions:\n      --details        Show extra details provided to logs\n  -f, --follow         Follow log output\n      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)\n  -n, --tail string    Number of lines to show from the end of the logs (default \"all\")\n  -t, --timestamps     Show timestamps\n      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37Z) or relative (e.g. 42m for 42 minutes)\n\n# 常用：\ndocker logs -tf 容器id\ndocker logs --tail number 容器id #num为要显示的日志条数\n\n# docker容器后台运行，必须要有一个前台的进程，否则会自动停止\n# 编写shell脚本循环执行，使得centos容器保持运行状态\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker run -d centos /bin/sh -c \"while true;do echo hi;sleep 5;done\"\nc703b5b1911ff84d584390263a35707b6024816e1f46542b61918a6327a570dc\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES\nc703b5b1911f   centos    \"/bin/sh -c 'while t…\"   13 seconds ago   Up 10 seconds             pedantic_banach\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker logs -tf --tail 10 c703b5b1911f\n2020-12-27T03:34:07.255599560Z hi\n2020-12-27T03:34:12.257641517Z hi\n2020-12-27T03:34:17.259706294Z hi\n2020-12-27T03:34:22.261693707Z hi\n2020-12-27T03:34:27.262609289Z hi\n2020-12-27T03:34:32.267862677Z hi\n2020-12-27T03:34:37.270382873Z hi\n2020-12-27T03:34:42.272414182Z hi\n2020-12-27T03:34:47.274823243Z hi\n2020-12-27T03:34:52.277419274Z hi\n```\n\n2. 查看容器中进程信息：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker top c703b5b1911f\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\nroot                11156               11135               0                   11:31               ?                   00:00:00            /bin/sh -c while true;do echo hi;sleep 5;done\nroot                11886               11156               0                   11:43               ?                   00:00:00            /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 5\n```\n\n3. `docker inspect` 查看容器的元数据（查看容器内部细节）：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker inspect 容器id\n```\n\n4. 进入当前正在运行的容器：\n\n因为通常我们的容器都是使用后台方式来运行的，有时需要进入容器修改配置。\n\n方式一：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker exec -it c703b5b1911f /bin/bash\n[root@c703b5b1911f /]$ ls\nbin  dev  etc  home  lib  lib64  lost+found  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n[root@c703b5b1911f /]$ ps -ef      \nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 03:31 ?        00:00:00 /bin/sh -c while true;do echo hi;sleep 5;done\nroot       279     0  0 03:54 pts/0    00:00:00 /bin/bash\nroot       315     1  0 03:56 ?        00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 5\nroot       316   279  0 03:56 pts/0    00:00:00 ps -ef\n```\n\n方式二：\n\n``` bash\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker attach c703b5b1911f\n```\n\n区别：\n\n- `docker exec` 进入容器后开启一个新的终端，可以在里面操作\n- `docker attach` 进入容器正在执行的终端，不会启动新的进程\n\n> docker exec 详细参数介绍：https://www.runoob.com/docker/docker-exec-command.html\n\n5. `docker cp` 拷贝容器的文件到主机中：\n\n``` bash\n# docker cp 容器id:容器内路径 目的主机路径\n\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker exec -it c703b5b1911f /bin/bash\n[root@c703b5b1911f /]$ cd home\n[root@c703b5b1911f home]$ ls\n[root@c703b5b1911f home]$ touch test.java\n[root@c703b5b1911f home]$ ls\ntest.java\n[root@c703b5b1911f home]$ exit\nexit\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES\nc703b5b1911f   centos    \"/bin/sh -c 'while t…\"   35 minutes ago   Up 35 minutes             pedantic_banach\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker cp c703b5b1911f:/home/test.java /home\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ ls /home\nhai  pan  test.java\n```\n\n\n\n完整命令示意图：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_13-30-12.png)\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/20201003133051.png)\n\n\n\n## Docker 镜像\n\nDocker 镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的有内容，包括代码、运行时、库、环境变量和配置文件。\n\n### UnionFS（联合文件系统）\n\nUnionFS (联合文件系统) : Union文件系统（UnionFS）是一一种分层、轻量级并且高性能的文件系统，它支持对文件系统的修作为一 次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下(unite several directories into a singlevirtualfilesystem)。Union文件系统是Docker镜像的基础。镜像可以通过分层来进行继承，基于基础镜像(没有父镜像)可以制作各种具.体的应用镜像。\n\n特性：一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录\n\n### Docker 镜像加载原理\n\nDocker 的镜像实际上**由一层一层的文件系统组成**，这种层级的文件系统是 UnionFS 联合文件系统。\n\n**botfs（boot file system）**主要包含**bootloader**和**kernel**，**bootloader**主要是引导加载**kernel**，**Linux**刚启动时会加载bootfs文件系统，在**Docker**镜像的最底层是**bootfs**。这一层与我们典型的**Linux/Unix**系统是一样的，包含boot加载器和内核。当boot加载完成之后整个内核就都在内存中了，此时内存的使用权己由bootfs转交给内核，此时系统也会卸载bootfs。\n\n**rootfs (root file system)，**在**bootfs**之上。 包含的就是典型Linux系统中的 **/dev, /proc, /bin, /etc** 等标准目录和文件。**rootfs**就是各种不同的操作系统发行版，比如**Ubuntu**，**Centos**等等。\n\n![image-20211109145554754](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109145554754.png)\n\n平时我们安装的虚拟机的Centos都是好几个G ，为什么Docker这里才要200M？\n\n对于一个精简的**OS，rootfs**可 以很小，只需要包括最基本的命令、工具和程序库就可以了，因为底层直接用**Host**的**kernel**，自只需要提供rootfs就行了。由此可见对于不同的**linux**发行版，**bootfs**基本是一致的，**rootfs**会有差别，因此不同的发行版可以公用**bootfs**。\n\n\n\n### 分层的镜像\n\n下载一个镜像时，可以看到是分层下载的：\n\n![image-20211109143422083](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109143422083.png)\n\n\n\n### 为什么 Docker 镜像要采用这种分层结构\n\n最大的一个好处就是**共享资源**。比如：**有多个镜像都从相同的base镜像构建而来**，那么宿主机只需在磁盘上保存一份**base**镜像，同时内存中也只需加载一份**base**镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。\n\n特点：Docker镜像都是**只读的**，当容器启动时，**一个新的可写层被加载到镜像的顶部**，这一层通常被称为**容器层**，容器层之下都叫**镜像层**。\n\n![image-20211109144853656](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109144853656.png)\n\n![image-20211109144905762](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109144905762.png)\n\n![image-20211109144953165](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109144953165.png)\n\n\n\n### Docker 镜像 Commit 操作\n\n`docker commit` 提交容器副本使之称为一个新的镜像：\n\n``` bash\n$ docker commit -m=\"提交的描述信息\" -a=\"作者\" 容器ID 要创建的目标镜像名:[标签名]\n```\n\n---\n\n**案例：提交 Tomcat 镜像**\n\n由于默认的Tomcat镜像的webapps文件夹中没有任何内容，需要从webapps.dist中拷贝文件到webapps文件夹。下面自行制作镜像：就是从webapps.dist中拷贝文件到webapps文件夹下，并提交该镜像作为一个新的镜像。使得该镜像默认的webapps文件夹下就有文件。具体命令如下：\n\n``` bash\n# 1.复制文件夹\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker run -it tomcat /bin/bash\nroot@2a3bf3eaa2e4:/usr/local/tomcat $ cd webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps $ ls\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps $ cd ../\nroot@2a3bf3eaa2e4:/usr/local/tomcat $ cp -r webapps.dist/* webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat $ cd webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps $ ls\nROOT  docs  examples  host-manager  manager\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker ps\nCONTAINER ID   IMAGE                 COMMAND        CREATED         STATUS         PORTS                    NAMES\n2a3bf3eaa2e4   tomcat                \"/bin/bash\"    4 minutes ago   Up 4 minutes   8080/tcp                 competent_torvalds\n7789d4505a00   portainer/portainer   \"/portainer\"   24 hours ago    Up 24 hours    0.0.0.0:8088->9000/tcp   quirky_sinoussi\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker exec -it 2a3bf3eaa2e4 /bin/bash\nroot@2a3bf3eaa2e4:/usr/local/tomcat $ cd webapps\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps $ ls\nROOT  docs  examples  host-manager  manager\nroot@2a3bf3eaa2e4:/usr/local/tomcat/webapps $ cd ../\nroot@2a3bf3eaa2e4:/usr/local/tomcat $ read escape sequence\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker ps\nCONTAINER ID   IMAGE                 COMMAND        CREATED         STATUS         PORTS                    NAMES\n2a3bf3eaa2e4   tomcat                \"/bin/bash\"    8 minutes ago   Up 8 minutes   8080/tcp                 competent_torvalds\n7789d4505a00   portainer/portainer   \"/portainer\"   24 hours ago    Up 24 hours    0.0.0.0:8088->9000/tcp   quirky_sinoussi\n\n# 2.提交镜像作为一个新的镜像\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker commit -m=\"add webapps\" -a=\"Ethan\" 2a3bf3eaa2e4 mytomcat:1.0\nsha256:f189aac861de51087af5bc88a5f1de02d9574e7ee2d163c647dd7503a2d3982b\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker images\nREPOSITORY            TAG       IMAGE ID       CREATED         SIZE\nmytomcat              1.0       f189aac861de   7 seconds ago   653MB\nmysql                 5.7       f07dfa83b528   6 days ago      448MB\ntomcat                latest    feba8d001e3f   10 days ago     649MB\nnginx                 latest    ae2feff98a0c   12 days ago     133MB\ncentos                latest    300e315adb2f   2 weeks ago     209MB\nportainer/portainer   latest    62771b0b9b09   5 months ago    79.1MB\nelasticsearch         7.6.2     f29a1ee41030   9 months ago    791MB\n\n# 3.运行容器\n[root@iZwz99sm8v95sckz8bd2c4Z ~]$ docker run -it mytomcat:1.0 /bin/bash\nroot@1645774d4605:/usr/local/tomcat $ cd webapps\nroot@1645774d4605:/usr/local/tomcat/webapps $ ls\nROOT  docs  examples  host-manager  manager\nwz99sm8v95sckz8bd2c4Z ~]$ docker images\nREPOSITORY            TAG       IMAGE ID       CREATED         SIZE\nmytomcat              1.0       f189aac861de   7 seconds ago   653MB\nmysql                 5.7       f07dfa83b528   6 days ago      448MB\ntomcat                latest    feba8d001e3f   10 days ago     649MB\nnginx                 latest    ae2feff98a0c   12 days ago     133MB\ncentos                latest    300e315adb2f   2 weeks ago     209MB\nportainer/portainer   latest    62771b0b9b09   5 months ago    79.1MB\nelasticsearch         7.6.2     f29a1ee41030   9 months ago    791MB\n```\n\n---\n\n\n\n## Docker 容器数据卷\n\nDocker的理念：将运用与运行的环境打包形成容器运行。运行可以伴随着容器，但是我们对数据的要求希望是持久化的，容器之间希望有可能共享数据。\n\nDocker容器产生的数据，如果不通过`docker commit`生成新的镜像，使得数据做为镜像的一部分保存下来，那么当容器删除后，数据自然也就没有了。为了能保存数据在docker中我们使用卷。\n\n> 有点类似我们Redis里面的rdb和aof文件\n\n卷就是目录或文件，存在于一个或多个容器中，由Docker挂载到容器，但不属于联合文件系统，因此能够绕过Union FileSystem提供一些用于持续存储或共享数据的特性：\n\n**卷的设计目的就是数据的持久化，完全独立于容器的生存周期，因此Docker不会在容器被删除时删除其挂载的数据卷**。特点：\n\n- 数据卷可在容器之间共享或重用数据\n- 卷中的更改可以直接生效\n- 数据卷中的更改不会包含在镜像的更新中\n- 数据卷的生命周期一直持续到没有容器使用它为止\n\n容器的持久化：**容器间继承 + 共享数据**\n\n### 添加数据卷方式一：命令行\n\n``` bash\n$ docker run -it -v /宿主机绝对路径目录:/容器内目录 镜像名\n\n# 设置数据卷权限为只读\n$ docker run -it -v /宿主机绝对路径目录:/容器内目录:ro 镜像名\n```\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_15-30-44.png)\n\n查看数据卷是否挂载成功：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_15-31-52.png)\n\n使用数据卷即可实现容器和宿主机之间数据共享。\n\n### 添加数据卷方式二：DockerFile 添加\n\n在 Dockerfile 文件中使用`VOLUME`指令来给镜像添加一个或多个数据卷：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_15-35-17.png)\n\n> 注意，该文件中写的路径是在容器中的路径，宿主机上关联的对应路径是随机生成的名称，不包含在该文件中（出于可移植和共享的考虑）。\n\n`docker build` 后生成镜像：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_15-36-01.png)\n\n对应的宿主机中关联的目录需要使用 `docker inspect 镜像id` 进行查看：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_15-37-05.png)\n\n> Docker挂载主机目录Docker访问如果出现cannot open directory . Permission denied。解决办法：在挂载目录后多加一个`--privileged=true`参数即可\n\n### 数据卷容器\n\n某个容器挂载数据卷，其它容器通过挂载这个（父容器）实现数据共享，挂载数据卷的这个容器，称之为数据卷容器。\n\n即某个容器挂在了数据卷，其他容器使用 `--volumes-from` 参数继承自该容器，则这些容器都可以共享同一份数据，称这个父容器为数据卷容器。之后即使删除了父容器，之前“继承”出的子容器也仍然能共享那些数据。\n\n结论：容器之间配置信息的传递，数据卷的生命周期一直持续到没有容器使用它为止\n\n\n\n## DockerFile 解析\n\nDockerfile 是用来构建Docker镜像的**构建文件**，由一系列命令和参数构成的脚本。\n\n从应用软件的角度来看，Dockerfile、 Docker镜像与Docker容器分别代表软件的三个不同阶段：\n\n- Dockerfile是软件的原材料\n- Docker镜像是软件的交付品\n- Docker容器则可以认为是软件的运行态\n\nDockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_17-35-08.png)\n\n- Dockerfile，需要定义一个Dockerfile，Dockerfile定义了进程需要的一切东西。Dockerfile涉及的内容包括执行代码或者是文件、环境变量、依赖包、运行时环境、动态链接库、操作系统的发行版、服务进程和内核进程（当应用进程需要和系统服务和内核进程打交道，这时需要考虑如何设计namespace的权限控制）等等\n- Docker镜像，在用Dockerfile定义文件之后，`docker build`时会产生一个Docker镜像，当运行Docker镜像时，会真正开始提供服务\n- Docker容器，容器是直接提供服务的\n\n\n\n### Docker 执行 Dockerfile 的大致流程\n\n- docker 从**基础镜像**运行一个容器\n- 执行一条指令并对容器作出修改\n- 执行类似`docker commit`的操作提交一个新的镜像层\n- docker再基于刚提交的镜像运行一个新容器\n- 执行dockerfile中的下一条指令直到所有指令都执行完成\n\n\n\n### DockerFile 体系结构（保留字指令）\n\n![image-20211109185453109](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109185453109.png)\n\n![image-20211109185510613](/images/%E3%80%90Docker%E3%80%91Docker/image-20211109185510613.png)\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_17-48-16.png)\n\n### 案例\n\n#### Base 镜像（scratch）\n\nDocker Hub中 99%的镜像都是通过在base镜像中安装和配置需要的软件构建出来的\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_17-52-43.png)\n\n#### 自定义镜像 mycentos\n\n1. 编写Dockerfile文件：\n\n```dockerfile\nFROM centos\nMAINTAINER ZZYY<zzyy167@126.com>\n\nENV MYPATH /usr/local\nWORKDIR $MYPATH\n\nRUN yum -y install vim\nRUN yum -y install net-tools\n\nEXPOSE 80\n\nCMD echo $MYPATH\nCMD echo \"success--------------ok\"\nCMD /bin/bash\n```\n\n2. 构建镜像文件：`docker build -t 新镜像名字:TAG .` \n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_17-56-15.png)\n\n3. 运行：`docker run -it 新镜像名字:TAG `\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-03_17-57-09.png)\n\n4. 列出镜像的变更历史：`docker history 镜像名`\n\n\n\n## Docker 镜像推送到阿里云\n\n本地镜像发布到阿里云流程：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-49-17.png)\n\n### 生成镜像\n\n从配置好环境的容器中打包创建一个新的镜像：\n\n```bash\ndocker commit [OPTIONS] 容器ID [REPOSITORY[:TAG]]\n```\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-50-48.png)\n\n### 将本地镜像推送到阿里云\n\n1. 登录阿里云开发者平台：https://promotion.aliyun.com/ntms/act/kubernetes.html\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-53-02.png)\n\n2. 创建阿里云镜像仓库：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-54-07.png)\n\n3. 将镜像推送到 registry：\n\n```bash\n$ sudo docker login --username=white3e registry.cn-shenzhen.aliyuncs.com\n\n$ sudo docker tag [ImageId] registry.cn-shenzhen.aliyuncs.com/ggccqq/mycentos:[镜像版本号]\n\n$ sudo docker push registry.cn-shenzhen.aliyuncs.com/ggccqq/mycentos:[镜像版本号]\n其中[ImageId][镜像版本]自己填写\n```\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-56-10.png)\n\n4. 公有云查询信息：\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-56-53.png)\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-57-23.png)\n\n\n\n### 将阿里云上的镜像下载到本地\n\n![](/images/%E3%80%90Docker%E3%80%91Docker/Snipaste_2020-10-04_12-59-00.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Docker","Linux"],"categories":["Docker","Linux"]},{"title":"【Redis】Redis 常见问题","url":"/2021/09/13/【Redis】Redis-常见问题/","content":"\n![image-20210913131720145](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210913131720145.png)\n\n## Redis 介绍\n\n### 说说什么是 Redis?\n\n> Redis 是一个开源（BSD 许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，HyperLogLogs 等数据类型。内置复制、Lua 脚本、LRU 收回、事务，以及不同级别磁盘持久化功能，同时通过 Redis Sentinel 提供高可用，通过 Redis Cluster 提供自动分区。根据月度排行网站 DB-Engines 的数据，Redis 是最流行的键值对存储数据库。\n>\n\nRedis 全称为：Remote Dictionary Server（远程数据服务），是一个基于内存且支持持久化的高性能 key-value 数据库。具备以下三个基本特征：\n\n- 多数据类型\n- 持久化机制\n- 主从同步\n\n### Redis 有什么优点和缺点？\n\n#### Redis 优点\n\n- 读写性能优异， Redis 能读的速度是 110000 次 /s，写的速度是 81000 次 /s。\n- **支持数据持久化**，支持 AOF 和 RDB 两种持久化方式。\n- **支持事务**，Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作合并后的原子性执行。\n- **数据结构丰富**，除了支持 string 类型的 value 外还支持 hash、set、zset、list 等数据结构。\n- **支持主从复制**，主机会自动将数据同步到从机，可以进行读写分离。\n\n#### Redis 缺点\n\n- 数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此 Redis 适合的场景主要局限在较小数据量的高性能操作和运算上。\n- Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的 IP 才能恢复。\n- 主机宕机，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低了系统的可用性。\n- Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。\n\n<!-- More -->\n\n\n\n### Redis 和 Memcached 的区别有哪些？\n\n- Redis 和 Memcache 都是将数据存放在内存中，都是内存数据库。不过 Memcache 还可用于缓存其他东西，例如图片、视频等等。\n- Memcache 仅支持 key-value 结构的数据类型，Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，hash 等数据结构的存储。\n- 虚拟内存– Redis 当物理内存用完时，可以将一些很久没用到的 value 交换到磁盘；分布式–设定 Memcache 集群，利用 magent 做一主多从；Redis 可以做一主多从。都可以一主一从。\n- 存储数据安全– Memcache 挂掉后，数据没了；Redis 可以定期保存到磁盘（持久化）\n- Memcache 的单个 value 最大 1m ， Redis 的单个 value 最大 512m 。\n- 灾难恢复– Memcache 挂掉后，数据不可恢复；Redis 数据丢失后可以通过 aof 恢复\n- Redis 原生就支持集群模式， Redis3.0 版本中，官方便能支持 Cluster 模式了， Memcached 没有原生的集群模式，需要依赖客户端来实现，然后往集群中分片写入数据。\n- Memcached 网络 IO 模型是多线程，非阻塞 IO 复用的网络模型，原型上接近于 nignx 。而 Redis 使用单线程的 IO 复用模型，自己封装了一个简单的 AeEvent 事件处理框架，主要实现类 epoll，kqueue 和 select ，更接近于 Apache 早期的模式。\n\n对比：\n\n- Redis 支持**更丰富的数据类型**（支持更复杂的应用场景）。Redis 不仅仅支持简单的 k/v 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储。Memcached 只支持最简单的 k/v 数据类型。\n- Redis 支持数据的**持久化**，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memecache 把数据全部存在内存之中。\n- Redis 有灾难恢复机制。 因为可以把缓存中的数据持久化到磁盘上。\n- Redis 在服务器内存使用完之后，可以将不用的数据放到磁盘上。但是，Memcached 在服务器内存使用完之后，就会直接报异常。\n- Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；但是 Redis 目前是原生支持 cluster 模式的.\n- Memcached 是多线程，非阻塞 IO 复用的网络模型；Redis 使用单线程的多路 IO 复用模型。 （Redis 6.0 引入了多线程 IO ）\n- Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持。并且，Redis 支持更多的编程语言。\n- Memcached 过期数据的删除策略只用了惰性删除，而 Redis 同时使用了惰性删除与定期删除。\n\n\n总结：Redis 性能更好，功能更多，支持的数据格式更多，支持的高可用解决方案更多。\n\n## Redis 数据结构\n\n### Redis 的数据类型有哪些？分别在哪些场景下使用比较合适？\n\nRedis 主要有以下几种数据类型：\n\n- String：这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。，一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。\n- Hash：这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在 Redis 里，然后每次读写缓存的时候，可以就操作 hash 里的某个字段。\n- List：List 是有序列表，这个可以玩儿出很多花样。比如可以通过 list 存储一些列表型的数据结构，类似**粉丝列表**、**文章的评论列表**之类的东西。\n- Set：是无序集合，自动去重。直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器上呢？得基于 Redis 进行**全局的 set 去重**。可以基于 set 进行交集、并集、差集的操作，比如交集可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁\n- Zset：排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。可以用来做**排行榜**功能。\n\n> 一般文章都是以 Redis 只有 5 种数据类型，还有 Bitmaps、HyperLogLogs、Streams 等。\n>\n\n\n\n### Redis 有哪些使用场景？\n\n#### 缓存数据\n\nRedis 提供了键过期功能，也提供了灵活的键淘汰策略，所以，现在 Redis 用在缓存的场合非常多。\n\n#### 排行榜\n\n很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜等。Redis 提供的有序集合Zset数据结构能实现各种复杂的排行榜应用。\n\n#### 计数器 \n\n如电商网站商品的浏览量、视频网站视频的播放数等。为了保证数据实时效，每次浏览都得给 + 1，并发量高时如果每次都请求数据库操作无疑是种挑战和压力。\n\n#### 分布式会话\n\n分布式系统中存储 Session，使得多台Web服务器都能共享 Session。\n\n集群模式下，在应用不多的情况下一般使用容器自带的 session 复制功能就能满足，当应用增多相对复杂的系统中，一般都会搭建以 Redis 等内存数据库为中心的 session 服务，session 不再由容器管理，而是由 session 服务及内存数据库管理。\n\n#### 分布式锁\n\n分布式锁实现方案，常见有三种：数据库，Redis、ZooKeepr。Redis 就是其中之一。\n\n如全局 ID、减库存、秒杀等场景，并发量不大的场景可以使用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用 Redis 的 setnx 功能来编写分布式的锁，如果设置返回 1 说明获取锁成功，否则获取锁失败，实际应用中要考虑的细节要更多。\n\n#### 社交网络\n\n点赞、踩、关注 / 被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis 提供的哈希Hash、Set集合等数据结构能很方便地实现这些功能。\n\n#### 最新列表\n\nRedis 列表结构，LPUSH 可以在列表头部插入一个内容 ID 作为关键字，LTRIM 可用来限制列表的数量，这样列表永远为 N 个 ID，无需查询最新的列表，直接根据 ID 去到对应的内容页即可。\n\n#### 消息系统\n\n消息队列主要用于业务解耦、流量削峰及异步处理实时性低的业务。Redis 提供了发布 / 订阅及阻塞队列功能，能实现一个简单的消息队列系统 。但 Redis 不是一个专业的消息队列。建议使用其他消息队列：Kafka、RocketMQ、RabbitMQ 等。\n\n\n\n\n\n## Redis 线程模型\n\n### Redis 是单线程的吗？\n\n这里的单线程指的是 **Redis 网络请求模块使用了一个线程**（所以不需考虑并发安全性），即一个线程处理所有网络请求，**其他模块仍用了多个线程**。\n\n### 为什么 Redis 单线程模型也能效率这么高？\n\n可以从下面 5 个方面来回答：\n\n- **C 语言**实现，效率高\n- **纯内存**操作，不涉及IO操作，十分节省时间\n- 基于**非阻塞的 IO 复用模型**机制\n- 单线程的话就能**避免多线程的频繁上下文切换**问题\n- 丰富的数据结构（全称采用 Hash 结构，读取速度非常快，对数据存储进行了一些优化，比如亚索表，跳表等）\n\n### Redis 为什么设计成单线程的？\n\n- 绝大部分请求是**纯粹的内存操作**（非常快速）\n- 采用单线程，**避免了不必要的上下文切换和竞争条件**\n- 非阻塞 IO，内部采用 epoll，epoll 中的读、写、关闭、连接都转化成了事件，然后利用 epoll 的多路复用特性，避免 IO 代价。\n\n### 请说说 Redis 的线程模型？\n\nRedis 内部使用文件事件处理器 `file event handler` ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket ，根据 socket 上的事件来选择对应的事件处理器进行处理。\n\n文件事件处理器的结构包含 4 个部分：\n\n- 多个 socket \n- IO 多路复用程序\n- 文件事件分派器\n- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）\n\n多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。\n\n来看客户端与 Redis 的一次通信过程：\n\n![image-20210917191843979](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210917191843979.png)\n\n- 首先，Redis 服务端进程初始化的时候，会将 server socket 的 `AE_READABLE` 事件与连接应答处理器关联。\n- 客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 `AE_READABLE` 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 `AE_READABLE` 事件与命令请求处理器关联。\n- 假设此时客户端发送了一个 `set key value` 请求，此时 Redis 中的 socket01 会产生 `AE_READABLE` 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 `AE_READABLE` 事件，由于前面 socket01 的 `AE_READABLE` 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 `key value` 并在自己内存中完成 `key value` 的设置。操作完成后，它会将 socket01 的 `AE_WRITABLE` 事件与命令回复处理器关联。\n- 如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 `AE_WRITABLE` 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 `AE_WRITABLE` 事件与命令回复处理器的关联。\n- 这样便完成了一次通信。\n\n### Redis 是单线程的，如何提高多核 CPU 的利用率？\n\nCPU 不太可能是 Redis 的瓶颈，一般内存和网络才有可能是。例如使用 Redis 的管道（pipelining）在 liunx 系统上运行可以达到 500K 的 RPS (requests per second) ，因此，如果您的应用程序主要使用 O (N) 或者 O (log (N)) 的 命令，他们几乎不需要使用什么 CPU。\n\n然而，为了最大限度的使用 CPU，可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的，所以，如果你想使用多个 CPU，你可以考虑一下分片（shard） 。\n\n在 Redis 的客户端类库里面，比如 RB（Ruby 的客户端）和 PRedis（最常用的 PHP 客户端之一），能够使用一致性哈希（consistent hashing）来处理多个 Redis 实例。\n\n### Redis 没有使用多线程？为什么不使用多线程？Redis6.0 之后为何引入了多线程？\n虽然说 Redis 是单线程模型，但是， 实际上，Redis 在 4.0 之后的版本中就已经加入了对多线程的支持。不过，Redis 4.0 增加的多线程主要是针对一些**大键值对的删除操作**的命令，使用这些命令就会使用主处理之外的其他线程来 “异步处理”。\n\nRedis 6 终于支持多线程了，告别单线程了吗？\n\nRedis 6 新增的IO多线程其实指**客户端交互部分**的**网络IO**交互处理模块**多线程**，而非**执行命令多线程**。Redis6执行命令依然是单线程。\n\n大体上来说，**Redis 6.0 之前主要还是单线程处理**。\n\nRedis 6 加入多线程，但跟 Memcached 这种从 IO处理到数据访问多线程的实现模式有些差异。Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。之所以这么设计是不想因为多线程而变得复杂，需要去控制 key、lua、事务，LPUSH/LPOP 等等的并发问题。整体的设计大体如下:\n\n![image-20210918165204453](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210918165204453.png)\n\n\n\n\n\n### Redis6.0 之前为什么不使用多线程？\n\n我觉得主要原因有下面 3 个：\n\n- 单线程编程容易并且更容易维护；\n- Redis 的性能瓶颈不在 CPU ，主要在内存和网络；\n- 多线程就会存在死锁、线程上下文切换等问题，甚至会影响性能。\n\n### Redis6.0 之后为何引入了多线程？\n\nRedis6.0 引入多线程主要是为了提高**网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（**Redis 的瓶颈主要受限于内存和网络**）。虽然，Redis6.0 引入了多线程，**但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了， 执行命令仍然是单线程顺序执行**。因此，你也不需要担心线程安全问题。\n\nRedis6.0 的多线程默认是禁用的，只使用主线程。如需开启需要修改 Redis 配置文件 `redis.conf `：\n\n``` conf\nio-threads-do-reads yes\n```\n\n开启多线程后，还需要设置线程数，否则是不生效的。同样需要修改 Redis 配置文件 `redis.conf `:\n\n``` \nio-threads 4  # 官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程\n```\n\n\n\n\n\n### 什么是 Redis Pipelining ？\n\nRedis 有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis 的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。\n\nRedis 运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是， 相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样 Redis 可以做很多内部复杂性很强的事情。\n\n同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。\n\n## Redis 持久化\n\n### Redis 有几种持久化方式？\n\nRedis 提供了两种方式，实现数据的持久化到硬盘。\n\n- **【全量】RDB 持久化**，是指在指定的时间间隔内将内存中的数据集快照写入磁盘。实际操作过程是，**fork 一个子进程**，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。\n- **【增量】AOF 持久化**，以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以**文本的方式记录**，可以打开文件看到详细的操作记录。\n\n### 说说 RDB 的优缺点\n\n#### 优点\n\n- **灵活设置备份频率和周期**。你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。\n- **非常适合冷备份**，对于灾难恢复而言，RDB 是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。推荐，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 OSS 分布式存储上。\n- **性能最大化**。对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。\n- **恢复更快**。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。\n\n#### 缺点\n\n- 如果想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。所以，RDB 实际场景下，需要和 AOF 一起使用。\n- 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。所以，**RDB 建议在业务低估，例如在半夜执行。**\n\n\n### 说说 AOF 的优缺点\n\n#### 优点\n\n- 该机制可以带来更高的数据安全性，即数据持久性。Redis 中提供了 3 种同步策略，即每秒同步、每修改 (执行一个命令) 同步和不同步。事实上，每秒同步也是**异步完成的**，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。\n- 由于该机制对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。因为以 append-only 模式写入，所以**没有任何磁盘寻址的开销，写入性能非常高**。另外，如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，不用担心，在 Redis 下一次启动之前，我们**可以通过 Redis-check-aof 工具来帮助我们解决数据一致性的问题。**\n- 如果 AOF 日志过大，Redis 可以自动启用 **rewrite** 机制。即使出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。\n- AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该文件完成数据的重建。\n\n\n#### 缺点\n\n- 对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。\n- 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。总之，每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。\n- 以前 AOF 发生过 bug ，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 /merge/ 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，**因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。**\n\n### 两种持久化方式该如何选择？\n\nRDB 的 bgsave 做**镜像全量**持久化，AOF 做**增量**持久化。因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使用。在 Redis 实例重启时，会使用 bgsave 持久化文件重新构建内存，再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。\n\n一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用 RDB 持久化。\n\n有很多用户都只使用 AOF 持久化，但并不推荐这种方式：因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， **并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快**，除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的问题。\n\n### 那如果突然机器掉电会怎样？\n\n取决于 AOF 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数据。但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。实际上，极端情况下最多丢失 2 秒的数据。因为 AOF 线程负责每秒执行一次 fsync 操作，操作完成后，记录最后同步时间。主线程负责对比上次同步时间，如果超过 2 秒，阻塞等待成功。\n\n###  bgsave 的原理是什么？\n\nfork 和 cow 。fork 是指 Redis 通过创建子进程来进行 `bgsave `操作。cow 指的是 `copy on write `，子进程创建后，**父子进程共享数据段**，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。这里 `bgsave `操作后，会产生 RDB 快照文件。\n\nRedis 会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个**临时文件**中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，**主进程是不进行任何IO操作的**，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。\n\n![image-20210912103134052](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210912103134052.png)\n\n`bgsave`：Redis会在后台（Background）**异步**进行快照操作， 快照同时还可以响应客户端请求。可以通过 `lastsave` 命令获取最后一次成功执行快照的时间\n\n## Redis 内存\n\n### Redis 内存调整与查看方式？\n\n#### 查看 Redis 最大占用内存\n\n配置文件 `redis.conf` 的 `maxmemory` 参数，`maxmemory`是`bytes`字节类型，注意转换。\n\n#### Redis 默认内存多少可以用？\n\n如果不设置最大内存大小或者设置最大内存大小为0，**在64位操作系统下不限制内存大小**，在32位操作系统下最多使用3GB内存。\n\n#### 一般生产上你如何配置？\n\n一般推荐Redis设置内存为**最大物理内存的四分之三**。\n\n#### 如何修改 Redis 内存设置\n\n- 修改配置文件 `redis.conf` 的 `maxmemory` 参数，如：`maxmemory 104857600` （代表100MB）\n- 通过命令修改\n  - `config set maxmemory 1024`：设置最大内存\n  - `config get maxmemory`：查看当前配置中的最大内存\n\n#### 什么命令查看 Redis 内存使用情况?\n\n`info memory`\n\n### Redis 打满内存 OOM\n\n``` bash\n127.0.0.1:6379> config get maxmemory\n1) \"maxmemory\"\n2) \"0\"\n127.0.0.1:6379> config set maxmemory 1\nOK\n127.0.0.1:6379> set a 123\n(error) OOM command not allowed when used memory > 'maxmemory'.\n```\n\n没有加上过期时间就会导致数据写满`maxmemory`，报OOM错误。为了避免类似情况，引出后文的内存淘汰策略\n\n### Redis 数据过期判断原理？\n\nRedis 通过一个叫做**过期字典**（可以看作是 hash 表）来保存数据过期的时间。过期字典的键指向 Redis 数据库中的某个 key (键)，过期字典的值是一个 long long 类型的整数，这个整数保存了 key 所指向的数据库键的过期时间（毫秒精度的 UNIX 时间戳）。\n\n### Redis 有几种数据 “过期删除” 策略？\n\n**Redis 过期策略是：定期删除 + 惰性删除。**\n\nRedis 的过期删除策略，就是指当 Redis 中缓存的 key 过期了，Redis 如何处理。Redis 提供了 3 种数据过期策略：\n\n- **立即删除**：key一旦过期立刻被删除，能节省内存空间。缺点是**对CPU不友好**，用处理器性能换取存储空间。\n- **惰性删除（被动删除）**：当数据过期时不立即删除，而是等到有客户端请求访问该key时再删除，并通知客户端该key不存在。缺点是**对内存不友好**，大量不常用的key过期后无法回收内存，会占用大量内存资源。\n- **定期删除（主动删除）**：是上述两种策略的折中。由于惰性删除策略无法保证冷数据被及时删除，所以 Redis 会**定期每隔一段时间主动淘汰**一批已过期的 key，并通过限制删除操作执行的**时**长和**频率**来减少删除操作对CPU时间的影响。其周期性轮询Redis库中的时效性数据，利用**随机抽取**的策略，利用**过期数据占比**的方式控制删除频度\n\n> https://zhuanlan.zhihu.com/p/105587132\n\n#### 定期删除策略\n\nRedis 会将每个设置了过期时间的 key 放入到一个**独立的字典**中，以后会**定期遍历**这个字典来删除到期的 key。Redis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的**贪心策略**：\n\n1. 从过期字典中随机 20 个 key；\n2. 删除这 20 个 key 中已经过期的 key；\n3. 如果过期的 key 比率超过 1/4，那就重复步骤 1；\n\nRedis默认是每隔 100ms 就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除。注意这里是随机抽取的。为什么要随机呢？假如 Redis 存了几十万个 key ，每隔100ms就遍历所有的设置过期时间的 key 的话，就会给 CPU 带来很大的负载。\n\n#### 惰性删除策略\n\n所谓惰性策略就是在客户端访问这个key的时候，Redis对key的过期时间进行检查，如果过期了就立即删除，不会给你返回任何东西。\n\n定期删除可能会导致很多过期key到了时间并没有被删除掉。所以就有了惰性删除。假如你的过期 key，靠定期删除没有被删除掉，还停留在内存里，除非你的系统去查一下那个 key，才会被Redis给删除掉。这就是所谓的惰性删除，即当你主动去查过期的key时，如果发现key过期了就立即进行删除，不返回任何东西。\n\n**总结：定期删除是集中处理，惰性删除是零散处理。**\n\n Redis 中，**同时使用了定期删除和惰性删除策略**，定期删除没有随机抽到的过期key将在客户端访问时惰性删除。但该方案仍然会有一些不常被访问的key残留在内存中，解决方案是使用**数据淘汰策略**。\n\n### Redis 有哪几种数据 “淘汰” 策略？\n\n**当内存即将达到限制，才会执行数据淘汰策略**，算是对上述删除策略的兜底。Redis 一共8种数据淘汰策略（达到某种条件后回收key）：\n\n- `noeviction`：不会驱逐任何key。当内存限制达到时仍想增加数据时返回错误\n- `allkeys-lru`：加入键的时候，如果过限，首先通过LRU算法驱逐**所有键**中**最久没有使用**的键（LRU）\n- `volatile-lru`：加入键的时候如果过限，首先从**设置了过期时间的键集合**中驱逐**最久没有使用**的键（LRU）\n- `allkeys-lfu`：加入键的时候如果过限，从**所有键**中驱逐**使用频率最少**的键（LFU）\n- `volatile-lfu`：加入键的时候如果过限，从**所有配置了过期时间的键**中驱逐**使用频率最少**的键（LFU）\n- `allkeys-random`：加入键的时候如果过限，从**所有key随机删除**。\n- `volatile-random`：加入键的时候如果过限，从**过期键**的集合中**随机删除**\n- `volatile-ttl`：加入键的时候如果过限，从**过期键**的集合优先回收**存活时间（TTL）较短**的键，使得新添加的数据有空间存放。\n\nRedis 默认配置的是`noeviction`策略。**开发常用的策略是 `allkeys-lru`。**\n\n上述几种策略可分为以下两个维度：\n\n- 对所有键都驱逐\n- 只对设置了过期时间的键驱逐\n\n四个方面：\n\n- 随机删除\n- LRU\n- LFU\n- TTL\n\n#### 如何配置淘汰策略\n\n- 命令\n  - `config set maxmemory-policy noeviction`\n  - `config get maxmemory`\n- 配置文件 - 配置文件`Redis.conf`的`maxmemory-policy`参数\n\n### Redis 大 Key 问题\n\n> https://www.cnblogs.com/cxy2020/p/13810963.html\n\n### Redis 一个字符串类型的值能存储最大容量是多少？\n\n512M\n\n### 缓存命中率表示什么？\n\n通常来说，缓存命中率越高，缓存的收益越高，应用的性能也就越好。\n\n- **缓存命中**： 可以从缓存中获取到需要的数据\n- **缓存不命中**：缓存中无法获取所需数据，需要再次查询数据库或者其他数据存储载体。\n\n> 缓存命中率 = 缓存中获取数据次数 / 获取数据总次数\n\n### 如何提高 Redis 命中率？\n\n提供缓存命中率，通常有如下方式：\n\n- 缓存**预加载**\n- 增加缓存**存储量**\n- 调整缓存存储数据类型\n- 提升缓存**更新频次**\n\n### 怎么优化 Redis 的内存占用？\n\n- redisObject 对象\n- 缩减键值对象\n- 共享对象池\n- 字符串优化\n- 编码优化\n- 控制 key 的数量\n\n### 对 Redis 进行性能优化，有些什么建议？\n\n- **Master 最好不要做任何持久化工作**，如 RDB 内存快照和 AOF 日志文件。\n- Master 调用 `BGREWRITEAOF` 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，导致服务 load 过高，出现短暂服务暂停现象。\n- 尽量避免在压力很大的主库上增加过多的从库。\n- 主从复制不要用图状结构，用**单向链表结构**更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3... 。\n- Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。\n\n### 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？\n\n使用 `keys` 指令可以扫出指定模式的 key 列表。\n\n追问：如果这个 Redis 正在给线上的业务提供服务，那使用 `keys` 指令会有什么问题？\n\n回答 Redis 关键的一个特性：**Redis 的单线程的**。**keys 指令会导致线程阻塞一段时间**，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 `scan` 指令，**`scan` 指令可以无阻塞的提取出指定模式的 key 列表**，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。\n\n\n\n\n\n## Redis 事务\n\n### 什么是 Redis 事务？\n\n可以一次性执行多条命令，本质上是一组命令的集合。一个事务中的所有命令都会序列化，然后按顺序地串行化执行，而不会被插入其他命令 。\n\nRedis 的事务相关命令有：\n\n- **DISCARD**：取消事务，放弃执行事务块中的所有命令\n- **EXEC**：执行事务块中的命令\n- **MULTI**：标记一个事务的开始\n- **UNWATCH**：取消 WATCH 命令对所有 key 的监视\n- **WATCH key [key…]**：监视一个（或多个）key，如果在事务之前执行这个（或者这些）key 被其他命令所改动，那么事务将会被打断。\n\n### Redis 事务的注意点有哪些？\n\n- 不支持回滚，如果事务中有错误的操作，无法回滚到处理前的状态，需要开发者处理。\n- 在执行完当前事务内所有指令前，不会同时执行其他客户端的请求。\n\n### 为什么 Redis 事务不支持回滚？\n\nRedis 事务不支持回滚，如果遇到问题，会继续执行余下的命令。这一点和关系型数据库不太一致。这样处理的原因有：\n\n- 只有语法错误，Redis 才会执行失败，例如错误类型的赋值， 这就是说从程序层面完全可以捕获以及解决这些问题\n- 支持回滚需要增加很多工作，不支持的情况下，Redis 可以**保持简单、速度快的特性**\n\nRedis 是不支持 roll back 的，因而不满足原子性的（而且不满足持久性）。\n\nRedis 官网也解释了自己为啥不支持回滚。简单来说就是 Redis 开发者们觉得没必要支持回滚，这样更简单便捷并且性能更好。Redis 开发者觉得即使命令执行错误也应该在开发过程中就被发现而不是生产过程中。\n\n### 如何使用 Redis 实现分布式锁？\n\n关于Redis分布式锁的详细介绍见[【Redis】Redis 分布式锁](https://yuyun-zhao.github.io/2021/09/15/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/)。\n\n使用 Redis 实现分布式锁的思路：\n\n1、`setnx(String key,String value)`\n\n- 若返回 1，说明设置成功，获取到锁；\n- 若返回 0，说明设置失败，已经有了这个 key，说明其它线程持有锁，重试。\n\n2、`expire(String key, int seconds)`\n\n获取到锁（返回 1）后，还需要用设置生存期，如果在多少秒内没有完成，比如发生机器故障、网络故障等，键值对过期，释放锁，实现高可用。\n\n3、`del(String key)`\n\n完成业务后需要释放锁。释放锁有 2 种方式：del 删除 key，或者 expire 将有效期设置为 0（马上过期）。在执行业务过程中，如果发生异常，不能继续往下执行，也应该马上释放锁。\n\n如果项目中 Redis 是多机部署的，那么可以尝试使用 Redisson 实现**分布式锁**，这是 Redis 官方提供的 Java 组件。\n\n## Redis 分布式锁\n\n### 分布式锁的实现条件？\n\n- 互斥性，和单体应用一样，要保证任意时刻，只能有一个客户端持有锁\n- 可靠性，要保证系统的稳定性，不能产生死锁\n- 一致性，要保证锁只能由加锁人解锁，不能产生 A 的加锁被 B 用户解锁的情况\n\n### Redis 和 ZooKeeper 实现的分布式锁有什么区别？\n\n- **高性能**：Redis（AP），但其无法保证主从机器上的缓存数据是一致的，可能主机刚保存了某个锁，还未同步给从机，自己就宕机了。在哨兵机制选举出了另一台主机后，其内并不存在该锁，故此前加的分布式锁失效，但其能保证高性能，而不像ZooKeeper一样主从同步时服务无法访问。\n- **可靠性**：ZooKeeper（CP），能够保证数据的一致性，主机收到的加锁消息会在同步给所有从机后再一起添加到缓存中，此时即可以保证分布式锁数据高度一致，但是缺点是同步期间服务无法访问，性能降低。\n\n二者区别：\n\n- 实现方式的不同，Redis 实现方式为插入一条占位数据key，而 ZK 为注册一个**临时节点**。\n- 遇到宕机情况时，Redis 需要等到过期时间到了后自动释放锁，而 ZK 因为是临时节点，在宕机时候已经是删除了节点去释放锁。\n- Redis 在没抢占到锁的情况下一般会去**自旋获取锁**（阻塞等待锁释放），比较浪费性能，而 ZK 是通过**注册监听器**的方式获取锁，性能而言优于 Redis。\n- 对于性能要求很高的建议使用 Redis 来实现，否则，建议使用 ZooKeeper 来实现。\n\n### 如何使用 Redis 实现分布式限流？\n\n限流的目的是通过对并发访问 / 请求进行限速或者一个时间窗口内的的请求进行限速来保护系统，一旦达到限制速率则可以拒绝服务。Redis 限流的实现方式有 3 种，分别是：\n\n- 基于 Redis 的 `setnx` 的操作，给指定的 key 设置**过期时间**；\n- 基于 Redis 的数据结构 `Zset`，将请求打造成一个 `Zset` 数组；\n- 基于 Redis 的令牌桶算法，输出速率大于输入速率，就要限流。\n- 基于 Redis 的**信号量机制**，当信号量值为0，则拒绝其他的请求，进行限量。详细介绍见[【Redis】Redis 分布式锁](https://yuyun-zhao.github.io/2021/09/15/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/)。\n\n### 如何使用 Redis 实现消息队列？\n\nRedis 的 `List` 数据结构常用来作为异步消息队列使用，使用 `rpush/lpush` 操作入队列，使用 `lpop` 和 `rpop` 来出队列。`rpush` 和 `lpop` 结合 或者 `lpush` 和 `rpop` 结合。\n\n![image-20210916142243407](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210916142243407.png)\n\n客户端是通过队列的 pop 操作来获取消息，然后进行处理。处理完了再接着获取消息，再进行处理。如此循环往复，这便是作为队列消费者的客户端的生命周期。\n\n## Redis 高可用：主从复制、哨兵机制、集群\n\n### Redis 高可用方案有哪些？\n\n**主从复制、哨兵机制、集群**\n\n#### Redis 单副本\n\nRedis 单副本，采用单个 Redis 节点部署架构，没有备用节点实时同步数据，不提供数据持久化和备份策略，适用于数据可靠性要求不高的纯缓存业务场景。\n\n#### Redis 多副本（主从）\n\nRedis 多副本，采用主从（replication）部署结构，相较于单副本而言最大的特点就是主从实例间数据实时同步，并且提供数据持久化和备份策略。主从实例部署在不同的物理服务器上，根据公司的基础环境配置，可以实现同时对外提供服务和读写分离策略。\n\n#### Redis Sentinel（哨兵）\n\nRedis Sentinel 是社区版本推出的原生高可用解决方案，其部署架构主要包括两部分：Redis Sentinel 集群和 Redis 数据集群。\n\n其中 Redis Sentinel 集群是由若干 Sentinel 节点组成的分布式集群，可以实现故障发现、故障自动转移、配置中心和客户端通知。Redis Sentinel 的节点数量要满足 2n+1（n>=1）的奇数个。\n\n#### Redis Cluster\n\nRedis Cluster 是社区版推出的 Redis 分布式集群解决方案，主要解决 Redis 分布式方面的需求，比如，当遇到单机内存，并发和流量等瓶颈的时候，Redis Cluster 能起到很好的负载均衡的目的。\n\nRedis Cluster 集群节点**最小配置 6 个节点以上（3 主 3 从）**，其中**主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。**\n\nRedis Cluster 采用虚拟槽分区，所有的键根据哈希函数映射到 0～16383 个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。\n\n#### Redis 自研\n\nRedis 自研的高可用解决方案，主要体现在配置中心、故障探测和 failover 的处理机制上，通常需要根据企业业务的实际线上环境来定制化。\n\n### Redis 的同步机制是什么？\n\nRedis 可以使用主从同步，从从同步。第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 rdb 文件全量同步到复制节点，复制节点接受完成后将 rdb 镜像加载到内存。\n\n加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。\n\n### 主从复制原理\n\nslave启动成功连接到master后会发送一个`sync`命令。master接到命令启动后台的**存盘进程**，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个**RDB数据文件**到slave，以完成一次完全同步。\n\n- **全量复制**：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中\n- **增量复制**：master继续将**新的**所有收集到的修改命令依次传给slave（只传送新增的修改命令），完成同步\n\n在Redis2.8版本后，主从断线后恢复的情况下实现增量复制。\n\n![image-20210912205253939](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210912205253939.png)\n\n### 说说 Redis Cluster 哈希槽的概念？\n\nRedis Cluster **没有使用一致性 hash **，而是引入了**哈希槽**的概念。\n\nRedis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。因为最大是 16384 个哈希槽，所以考虑 Redis 集群中的每个节点都能分配到一个哈希槽，所以最多支持 16384 个 Redis 节点。\n\n为什么是 16384 呢？主要考虑集群内的网络带宽，而 16384 刚好是 2K 字节大小。\n\n### Redis 的哨兵有什么功能？\n\n哨兵是 Redis 集群架构中非常重要的一个组件，主要功能如下：\n\n- **集群监控**，负责监控 Redis Master 和 Slave 进程是否正常工作；\n- **消息通知**，如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员；\n- **故障转移**，如果 Master node 挂掉了，会自动转移到 Slave node 上；\n- **配置中心**，如果故障转移发生了，通知 Client 客户端新的 Master 地址。\n\n### Redis 哨兵和集群的区别是什么？\n\nRedis 的哨兵作用是管理多个 Redis 服务器，提供了监控、提醒以及自动的故障转移的功能。哨兵可以保证当主服务器挂了后，可以从从服务器选择一台当主服务器，把别的从服务器转移到读新的主机。Redis 哨兵的主要功能有：\n\nRedis 的集群的功能是为了解决单机 Redis 容量有限的问题，将数据按一定的规则分配到多台机器，对内存的每秒访问不受限于单台服务器，可受益于分布式集群高扩展性。\n\n### Redis Cluster 的主从复制模型是怎样的？\n\n为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型，每个节点都会有 N-1 个复制节点。所以，**Redis Cluster 可以说是 Redis Sentinel 带分片的加强版**。也可以说：\n\n- **Redis Sentinel 着眼于高可用**，在 master 宕机时会自动将 slave 提升为 master ，继续提供服务。\n- **Redis Cluster 着眼于扩展性**，在单个 Redis 内存不足时，使用 Cluster 进行分片存储。\n\n### Redis 集群模式的工作原理能说一下么？\n\n- 自动将数据进行分片，每个 master 上放一部分数据\n- 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的\n\n在 Redis cluster 架构下，每个 Redis 要放开两个端口号，比如一个是 6379，另外一个就是 加 1w 的端口号，比如 16379。16379 端口号是用来进行**节点间通信**的，也就是 Cluster Bus 的东西，Cluster Bus 的通信，用来进行故障检测、配置更新、故障转移授权。Cluster Bus 用了另外一种二进制的协议，Gossip 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。\n\n#### 节点间的内部通信机制\n\n集群元数据的维护有两种方式：集中式、Gossip 协议。Redis Cluster 节点间采用 Gossip 协议进行通信。\n\n**集中式**是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于ZooKeeper（分布式协调的中间件）对所有元数据进行存储维护。\n\n![image-20210918163208507](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210918163208507.png)\n\nRedis 维护集群元数据采用另一个方式， **Gossip 协议**，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。\n\n![image-20210918163238692](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210918163238692.png)\n\n- 集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。\n- Gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。\n  - 10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号 + 10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong。\n  - 交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。\n\n### Gossip 协议\n\nGossip 协议包含多种消息，包含 ping,pong,meet,fail 等等。\n\n- `meet`：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。\n\n  ``` bash\n  redis-trib.rb add-node\n  ```\n\n  其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。\n\n- ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。\n- pong：返回 ping 和 meet，包含自己的状态和其它信息，也用于信息广播和更新。\n- fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。\n\n#### ping 消息深入\n\nping 时要携带一些元数据，如果很频繁，可能会加重网络负担。\n\n每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 `cluster_node_timeout / 2`，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 `cluster_node_timeou`t 可以调节，如果调得比较大，那么会降低 ping 的频率。\n\n每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 3 个其它节点的信息，最多包含 总节点数减 2 个其它节点的信息。\n\n### 在集群模式下，Redis 的 key 是如何寻址的？\n\n使用 Hash Slot 算法，算出来当前 key 的 Hash Slot 值，找到对应的服务器存储\n\n### 分布式寻址都有哪些算法？\n\n分布式寻址算法：\n\n- hash 算法（大量缓存重建）\n- 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）\n- Redis cluster 的 Hash Slot 算法\n\n\n\n### 了解一致性 hash 算法吗？\n\n**hash 算法**：来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。\n\n![image-20210918163839867](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210918163839867.png)\n\n**一致性 hash 算法**： \n\n一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。\n\n来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环顺时针 “行走”，遇到的第一个 master 节点就是 key 所在位置。\n\n在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。\n\n然而，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点，这样就实现了数据的均匀分布，负载均衡。\n\n![image-20210918164000686](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210918164000686.png)\n\n### Redis Cluster 的 hash slot 算法，如何动态增加和删除一个节点？\n\nRedis Cluster 有固定的 **16384 **个 hash slot，对每个 key 计算 CRC16 值，然后对 16384 取模，可以获取 key 对应的 hash slot。\n\nRedis Cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有 5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 hash tag 来实现。\n\n任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。\n\n![image-20210918164110174](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210918164110174.png)\n\n### Redis Cluster 的高可用与主备切换原理\n\nRedis Cluster 的高可用的原理，几乎跟哨兵是类似的。\n\n#### 判断节点宕机\n\n如果一个节点认为另外一个节点宕机，那么就是 pfail，主观宕机。如果多个节点都认为另外一个节点宕机了，那么就是 fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。在 `cluster-node-timeout` 内，某个节点一直没有返回 pong，那么就被认为 pfail。\n\n如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中，ping 给其他节点，如果超过半数的节点都认为 pfail 了，那么就会变成 fail。\n\n#### 从节点过滤\n\n对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。\n\n检查每个 slave node 与 master node 断开连接的时间，如果超过了 `cluster-node-timeout * cluster-slave-validity-factor`，那么就没有资格切换成 master。\n\n#### 从节点选举\n\n每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。\n\n所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node（N/2 + 1）都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。\n\n从节点执行主备切换，从节点切换为主节点。\n\n#### 与哨兵比较\n\n整个流程跟哨兵相比，非常类似，所以说，Redis Cluster 功能强大，直接集成了 Replication 和 Sentinel 的功能。\n\n集群模式是否默认含有哨兵？以后详细复习\n\n\n\n### 请说说你们生产环境中的 Redis 是怎么部署的？\n\n- Redis Cluster ，10 台机器，5 台机器部署了 Redis 主实例，另外 5 台机器部署了 Redis 的从实例，每个主实例挂了一个从实例，5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5 万，5 台机器最多是 25 万读写请求每秒。\n- 机器是什么配置？32G 内存 + 8 核 CPU + 1T 磁盘，但是分配给 Redis 进程的是 10G 内存，一般线上生产环境，Redis 的内存尽量不要超过 10G，超过 10G 可能会有问题。那么，5 台机器对外提供读写，一共有 50G 内存。\n- 因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，Redis 从实例会自动变成主实例继续提供读写服务。\n- 你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10kb 。100 条数据是 1mb ，10 万条数据是 1G 。常驻内存的是 200 万条商品数据，占用内存是 20G ，仅仅不到总内存的 50% 。目前高峰期每秒就是 3500 左右的请求量。\n- 其实大型的公司，会有基础架构的 Team 负责缓存集群的运维。\n\n### 了解什么是 Redis 的雪崩、穿透和击穿？Redis 崩溃之后会怎么样？系统该如何应对这种情况？如何处理 Redis 的穿透？\n\n### 缓存雪崩\n\n> 视频介绍：https://www.bilibili.com/video/BV1Y7411G7Pf?spm_id_from=333.999.0.0\n\n对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了，这就是缓存雪崩（还有key集中过期导致请求全都访问数据库导致雪崩，解决方案是设置过期时间时加上随机值）。\n\n![image-20210917195322315](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210917195322315.png)\n\n缓存雪崩的事前事中事后的解决方案如下：\n\n- 事前：Redis 高可用，主从 + 哨兵，Redis cluster，避免全盘崩溃。\n- 事中：本地 ehcache 缓存 + hystrix 限流 & 降级，避免 MySQL 被打死。\n- 事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。\n\n![image-20210917195130352](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210917195130352.png)\n\n用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis，如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。\n\n限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？走降级！可以返回一些默认的值，或者友情提示，或者空白的值。\n\n#### 针对 Redis 服务不可用的情况：\n\n- 采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。\n- 限流，避免同时处理大量的请求。\n\n#### 针对热点缓存失效的情况：\n\n- 设置不同的失效时间比如随机设置缓存的失效时间。\n- 设置缓存永不失效。\n\n### 缓存穿透\n\n对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。\n\n举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都 “视缓存于无物”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。\n\n![image-20210917195334229](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210917195334229.png)\n\n#### 有哪些解决办法？\n\n最基本的就是首先做好参数校验，一些不合法的参数请求直接抛出异常信息返回给客户端。比如查询的数据库 id 不能小于 0、传入的邮箱格式不对的时候直接返回错误消息给客户端等等。\n\n#### 缓存无效 key\n\n如果缓存和数据库都查不到某个 key 的数据就写一个到 Redis 中去并设置过期时间，具体命令如下：` SET key value EX 10086` 。这种方式可以解决请求的 key 变化不频繁的情况，如果黑客恶意攻击，每次构建不同的请求 key，会导致 Redis 中缓存大量无效的 key 。很明显，这种方案并不能从根本上解决此问题。如果非要用这种方式来解决穿透问题的话，尽量将无效的 key 的过期时间设置短一点比如 1 分钟。\n\n#### 布隆过滤器\n\n布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地判断一个给定数据是否存在于海量数据中。我们需要的就是判断 key 是否合法，有没有感觉布隆过滤器就是我们想要找的那个 “人”。\n\n具体是这样做的：把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。\n\n加入布隆过滤器之后的缓存处理流程图如下：\n\n![image-20210917195443933](/images/%E3%80%90Redis%E3%80%91Redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/image-20210917195443933.png)\n\n但是，需要注意的是布隆过滤器可能会存在误判的情况。总结来说就是： 布隆过滤器说某个元素存在，小概率会误判。布隆过滤器说某个元素不在，那么这个元素一定不在。\n\n为什么会出现误判的情况呢？我们还要从布隆过滤器的原理来说：\n\n我们先来看一下，当一个元素加入布隆过滤器中的时候，会进行哪些操作：\n\n- 使用布隆过滤器中的哈希函数对元素值进行计算，得到哈希值（有几个哈希函数得到几个哈希值）。\n- 根据得到的哈希值，在位数组中把对应下标的值置为 1。\n\n我们再来看一下，当我们需要判断一个元素是否存在于布隆过滤器的时候，会进行哪些操作：\n\n- 对给定元素再次进行相同的哈希计算；\n- 得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。\n\n然后，一定会出现这样一种情况：不同的字符串可能哈希出来的位置相同。 （可以适当增加位数组大小或者调整我们的哈希函数来降低概率）\n\n### 缓存击穿\n\n缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。\n\n解决方式：\n\n- 可以将热点数据设置为永远不过期；\n- 或者基于 Redis or Zookeeper 实现分布式互斥锁，等待第一个请求构建完缓存之后，再释放锁，进而其它请求才能通过该 key 访问数据。\n\n### 如何保证缓存与数据库的双写一致性？\n\n- **缓存失效时间变短（不推荐，治标不治本）** ：我们让缓存数据的过期时间变短，这样的话缓存就会从数据库中加载数据。另外，这种解决办法对于先操作缓存后操作数据库的场景不适用。\n- **增加 cache 更新重试机制（常用）**： 如果 cache 服务当前不可用导致缓存删除失败的话，我们就隔一段时间进行重试，重试次数可以自己定。如果多次重试还是失败的话，我们可以把当前更新失败的 key 存入队列中，等缓存服务可用之后，再将 缓存中对应的 key 删除即可。\n\n### Redis 的并发竞争问题是什么？如何解决这个问题？了解 Redis 事务的 CAS 方案吗？\n\n多客户端同时并发写一个 key，可能本来应该先到的数据后到了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。 Redis 自己就有天然解决这个问题的 CAS 类的**乐观锁**方案（WATCH）。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 杂项\n\n### 熟悉 Redis 的哪些客户端？\n\n#### Jedis\n\n是我们最熟悉和最常用的客户端。轻量，简洁，便于集成和改造。\n\n**Jedis 多个线程使用一个连接的时候线程不安全**。可以使用连接池，为每个请求创建不同的连接，基于 Apache common pool 实现。跟数据库一样，可以设置最大连接数等参数。Jedis 中有多种连接池的子类\n\nJedis 有 4 种工作模式：单节点、分片、哨兵、集群。3 种请求模式：Client、Pipeline、事务。\n\n- Client 模式就是客户端**发送一个命令**，**阻塞等待**服务端执行，然后读取返回结果。\n- Pipeline 模式是**一次性发送多个命令**，最后一次取回所有的返回结果，这种模式通过减少网络的往返时间和 io 读写次数，大幅度提高通信性能。\n- 事务模式（Transaction 模式），即开启 Redis 的事务管理，事务模式开启后，所有的命令（除了 exec，discard，multi 和 watch）到达服务端以后不会立即执行，会进入一个等待队列。\n\n#### Lettuce\n\n与 Jedis 相比，Lettuce 则完全**克服了其线程不安全的缺点**：Lettuce 是一个可伸缩的线程安全的 Redis 客户端，支持同步、异步和响应式模式（Reactive）。**多个线程可以共享一个连接实例，而不必担心多线程并发问题。**\n\n**Lettuce 是 Spring Boot 2.x 默认的客户端**，替换了 Jedis。集成之后我们不需要单独使用它，直接调用 Spring 的 RedisTemplate 操作，连接和创建和关闭也不需要我们操心。\n\n**异步调用基于 Netty 框架构建**，支持 Redis 的高级功能，如 Pipeline、发布订阅，事务、Sentinel，集群，支持连接池。异步的结果使用 **RedisFuture** 包装，提供了大量回调的方法。\n\n#### Redisson\n\n是一个在 Redis 的基础上实现的 Java 驻内存数据网格（In-Memory Data Grid），提供了分布式和可扩展的 Java 数据结构。\n\n特点：\n\n- 基于 Netty 实现，采用非阻塞 IO，性能高\n- 支持异步请求\n- 支持连接池、pipeline、LUA Scripting、Redis Sentinel、Redis Cluster 不支持事务，官方建议以 LUA Scripting 代替事务\n- 主从、哨兵、集群都支持。Spring 也可以配置和注入 RedissonClient。\n\n实现分布式锁：在 Redisson 里面提供了更加简单的**分布式锁**的实现。\n\n\n\n### 你知道有哪些 Redis 分区实现方案？\n\nRedis 分区方案，主要分成两种类型：\n\n- **客户端分区**，就是在客户端就已经决定数据会被存储到哪个 Redis 节点或者从哪个 Redis 节点读取。大多数客户端已经实现了客户端分区。案例：Redis Cluster 和客户端分区。\n- **代理分区**，意味着客户端将请求发送给代理，然后代理决定去哪个节点写数据或者读数据。代理根据分区规则决定请求哪些 Redis 实例，然后根据 Redis 的响应结果返回给客户端。案例：Twemproxy 和 Codis 。\n\n查询路由 (Query routing) 的意思，是客户端随机地请求任意一个 Redis 实例，然后由 Redis 将请求转发给正确的 Redis 节点。Redis Cluster 实现了一种混合形式的查询路由，但并不是直接将请求从一个 Redis 节点转发到另一个 Redis 节点，而是在客户端的帮助下直接 Redirect 到正确的 Redis 节点。\n\n\n\n\n\n\n\n### Redis 分布式锁相关问题\n\n\n\n1. Redis除了拿来做缓存，你还见过基于Redis的什么用法？\n\n答：可以做简易的购物车，交友关系，微信朋友圈点赞，微信公众号订阅。还能做发布订阅，消息中间件，数据库\n\n\n\n2. Redis做分布式锁的时候有需要注意的问题？\n\n\n\n3. 如果是Redis是单点部署的，会带来什么问题？那你准备怎么解决单点问题呢？\n\n\n\n4. 集群模式下，比如主从模式，有没有什么问题呢？\n\n\n\n5. 那你简单的介绍一下Redlock吧？你简历上写Redisson，你谈谈。\n\n\n\n6. Redis分布式锁如何续期？看门狗知道吗？\n\n\n\n\n\n","tags":["Redis"],"categories":["Redis"]},{"title":"【操作系统】进程管理","url":"/2021/09/10/【操作系统】进程管理/","content":"\n\n\n\n\n","tags":["操作系统"],"categories":["操作系统"]},{"title":"【Redis】Redis 基础","url":"/2021/09/09/【Redis】Redis/","content":"\n![image-20210913131720145](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913131720145.png)\n\n## Redis 简介\n\n> [Redis官网](https://redis.io/) 、[Redis中文网](http://www.redis.cn/)\n\n**Redis：REmote DIctionary Server（远程字典服务器）** 是完全开源免费的，用C语言编写的，遵守BSD协议，是一个高性能的（key/value）分布式内存数据库，基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一，也被人们称为数据结构服务器。\n\n### Redis 单线程模型\n\nRedis 采用**单线程模型**来处理客户端的请求。对读写等事件的响应是通过对`epoll`函数的包装来做到的。Redis的实际处理速度完全依靠主进程的执行效率。\n\n> Epoll是Linux内核为处理大批量文件描述符而作了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本， 它能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。\n\nRedis是**单线程 + 多路IO复用技术**\n\n多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）\n\n**串行  vs  多线程+锁（memcached） vs  单线程 + 多路IO复用（Redis）**\n\n（与Memcache三点不同：支持多数据类型，支持持久化，单线程+多路IO复用）\n\n### Redis 特点\n\nRedis 与其他 key - value 缓存软件有以下三个特点：\n\n- Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用\n- Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储\n- Redis支持数据的备份，即master-slave模式的数据备份\n\nRedis 能够用来：\n\n- 内存存储和持久化：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务\n- 取最新N个数据的操作，如：可以将最新的10条评论的ID放在Redis的List集合里面\n- 模拟类似于HttpSession这种需要设定过期时间的功能\n- 发布、订阅消息系统\n- 定时器、计数器\n\nRedis 安装见 [Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\n<!-- More -->\n\n## Redis 五大数据类型\n\n> https://blog.csdn.net/u011863024/article/details/107476187\n\n- **String**（字符串）\n  - String是Redis最基本的类型，可以理解成与Memcached一模一样的类型，一个key对应一个value。\n  - String类型是**二进制安全的**。意思是Redis的String可以包含任何数据。比如jpg图片或者序列化的对象。\n  - String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是512M\n- **Hash**（哈希，类似java里的Map）\n  - Redis Hash 是一个键值对集合。\n  - Redis Hash是一个String类型的field和value的映射表，Hash特别适合用于存储对象。\n    类似Java里面的`Map<String,Object>`\n- **List**（列表）\n  - Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素导列表的头部（左边）或者尾部（右边）。\n  - 它的底层实际是个链表\n- **Set**（集合）\n  - Redis的Set是String类型的无序集合。它是通过`HashTable`实现实现的\n- **Zset**（sorted set：有序集合）\n  - Redis Zset 和 Set 一样也是String类型元素的集合，且不允许重复的成员。\n  - 不同的是每个元素都会关联一个double类型的分数。\n  - Redis正是通过分数来为集合中的成员进行从小到大的排序。Zset的成员是唯一的，但分数（score）却可以重复。\n\nRedis 常见数据类型操作命令：\n\n- [Redis 命令参考](http://redisdoc.com/)\n- [Redis 官网命令参考](https://redis.io/commands)\n\n### String\n\nString的数据结构为简单动态字符串（Simple Dynamic String,缩写SDS）。是可以修改的字符串，内部结构实现上类似于Java的`ArrayList`，采用预分配冗余空间的方式来减少内存的频繁分配.\n\n![image-20210912213742688](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912213742688.png)\n\n如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M。\n\n### List\n\nRedis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）。它的底层实际是个**双向链表**，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差。\n\n![image-20210912213906532](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912213906532.png)\n\nList的数据结构为**快速链表quickList**。\n\n首先在列表元素较少的情况下会使用一块**连续的内存**存储，这个结构是**ziplist**，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。\n\n当数据量比较多的时候才会改成**quicklist**。因为普通的链表需要的附加指针空间太大，会比较浪费空间。比如这个列表里存的只是int类型的数据，结构上还需要两个额外的指针prev和next。\n\n![image-20210912214047542](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912214047542.png)\n\nRedis将链表和**ziplist**结合起来组成了**quicklist**。也就是将多个ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。\n\n### Set\n\nSet对外提供的功能与List类似是一个列表的功能，特殊之处在于Set是可以**自动排重**的，当你需要存储一个列表数据，又不希望出现重复数据时，Set是一个很好的选择，并且Set提供了判断某个成员是否在一个Set集合内的重要接口，这个也是List所不能提供的。\n\nRedis的Set是String类型的**无序集合**。它底层其实是一个value为null的**Hash**表，所以添加/删除/查找的**复杂度都是O(1)**。一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变。\n\nSet数据结构是Dict字典，字典是用哈希表实现的。Java中`HashSet`的内部实现使用的是`HashMap`，只不过所有的value都指向同一个对象。**Redis的Set结构也是一样，它的内部也使用Hash结构，所有的value都指向同一个内部值。**\n\n### Hash\n\nHash 是一个键值对集合。它是一个String类型的field和value的映射表，Hash特别适合用于存储对象。它类似Java里面的`Map<String,Map<K,V>>`，存储方式：\n\n![image-20210912214645546](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912214645546.png)\n\n通过 key(用户ID) + field(属性标签) 就可以操作对应属性数据了，既不需要重复存储数据，也不会带来序列化和并发修改控制的问题。\n\nHash类型对应的数据结构是两种：ziplist（压缩列表），hashtable（哈希表）。当field-value长度较短且个数较少时，使用ziplist，否则使用hashtable。\n\n### Zset\n\nRedis有序集合Zset与普通集合Set非常相似，是一个没有重复元素的字符串集合。不同之处是有序集合的每个成员都关联了一个**评分（score）**，这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 。\n\n因为元素是有序的，所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素。访问有序集合的中间元素也是非常快的，因此你能够使用有序集合作为一个没有重复成员的智能列表。\n\n一方面它等价于Java的数据结构`Map<String, Double>`，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表。\n\nZset底层使用了两个数据结构\n\n- Hash，Hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值。\n- 跳跃表，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表。\n\n跳跃表示例：\n\n![image-20210912215152100](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912215152100.png)\n\n### 实际应用场景\n\n#### String\n\n- 商品编号、订单号采用INCR命令生成\n- 是否喜欢的文章\n\n#### Hash\n\n- 新增商品 `hset shopcar:uid1024 334488 1`\n- 新增商品 `hset shopcar:uid1024 334477 1`\n- 增加商品数量 `hincrby shopcar:uid1024 334477 1`\n- 商品总数 `hlen shopcar:uid1024`\n- 全部选择 `hgetall shopcar:uid1024`\n\n#### List\n\nA和B发布了文章分别是11和22。\n\n- 我关注了A和B，只要他们发布了新文章，就会安装进我的List：`lpush likearticle:myid1122`\n- 查看我自己的号订阅的全部文章，类似分页，下面0~10就是一次显示10条：`lrange likearticle:myid 0 10`\n\n#### Set\n\n- 微信抽奖小程序\n  - 用户ID，立即参与按钮\n    - `SADD key 用户ID`\n  - 显示已经有多少人参与了、上图23208人参加\n    - `SCARD key`\n  - 抽奖(从set中任意选取N个中奖人)\n    - `SRANDMEMBER key 2`（随机抽奖2个人，元素不删除）\n    - `SPOP key 3`（随机抽奖3个人，元素会删除）\n- 微信朋友圈点赞\n  - 新增点赞\n    - `sadd pub:msglD 点赞用户ID1 点赞用户ID2`\n  - 取消点赞\n    - `srem pub:msglD 点赞用户ID`\n  - 展现所有点赞过的用户\n    - `SMEMBERS pub:msglD`\n  - 点赞用户数统计，就是常见的点赞红色数字\n    - `scard pub:msgID`\n  - 判断某个朋友是否对楼主点赞过\n    - `SISMEMBER pub:msglD用户ID`\n- 微博好友关注社交关系\n  - 共同关注：我去到局座张召忠的微博，马上获得我和局座共同关注的人\n    - `sadd s1 1 2 3 4 5`\n    - `sadd s2 3 4 5 6 7`\n    - `SINTER s1 s2`\n  - 我关注的人也关注他(大家爱好相同)\n- QQ内推可能认识的人\n  - `sadd s1 1 2 3 4 5`\n  - `sadd s2 3 4 5 6 7`\n  - `SINTER s1 s2`\n  - `SDIFF s1 s2`\n  - `SDIFF s2 s1`\n\n#### Zset\n\n- 根据商品销售对商品进行排序显示\n  - 定义商品销售排行榜（sorted set集合），key为goods:sellsort，分数为商品销售数量。\n  - 商品编号1001的销量是9，商品编号1002的销量是15 `- zadd goods:sellsort 9 1001 15 1002`\n  - 有一个客户又买了2件商品1001，商品编号1001销量加2 - `zincrby goods:sellsort 2 1001`\n  - 求商品销量前10名 - `ZRANGE goods:sellsort 0 10 withscores`\n- 抖音热搜\n  - 点击视频\n    - `ZINCRBY hotvcr:20200919 1 八佰`\n    - `ZINCRBY hotvcr:20200919 15 八佰 2 花木兰`\n  - 展示当日排行前10条\n    - `ZREVRANGE hotvcr:20200919 0 9 withscores`\n\n\n\n## Redis 新数据类型\n\n### Bitmaps\n\n现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“abc”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “abc”分别对应的ASCII码分别是97、 98、 99， 对应的二进制分别是01100001、 01100010和01100011，如下图\n\n![image-20210913122404598](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913122404598.png)\n\n合理地使用操作位能够有效地提高内存使用率和开发效率。\n\nRedis提供了Bitmaps这个“数据类型”可以实现对位的操作：\n\n- Bitmaps本身不是一种数据类型， 实际上它就是字符串（key-value） ， 但是它可以对字符串的位进行操作。\n- Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。 可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量。\n\n![image-20210913122513817](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913122513817.png)\n\nBitmaps可用于统计网站的活跃用户数量，占用内存远小于Set。\n\nBitmaps常用命令见 [Redis6 文档](https://yuyun-zhao.github.io/documents/Redis6.pdf)。\n\n### HyperLogLog\n\n在工作当中，我们经常会遇到与统计相关的功能需求，比如统计网站PV（PageView页面访问量）,可以使用Redis的incr、incrby轻松实现。但像UV（UniqueVisitor，独立访客）、独立IP数、搜索记录数等需要去重和计数的问题如何解决？这种求集合中不重复元素个数的问题称为**基数问题**。解决基数问题有很多种方案：\n\n- 数据存储在MySQL表中，使用distinct count计算不重复个数\n- 使用Redis提供的hash、set、bitmaps等数据结构来处理\n\n以上的方案结果精确，但随着数据不断增加，导致占用空间越来越大，对于非常大的数据集是不切实际的。能否能够降低一定的精度来平衡存储空间？Redis推出了**HyperLogLog**\n\nRedis HyperLogLog 是用来做**基数统计**的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。\n\n在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。\n\n什么是基数？比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。\n\nHyperLogLog常用命令见 [Redis6 文档](https://yuyun-zhao.github.io/documents/Redis6.pdf)。\n\n### Geospatial\n\nRedis 3.2 中增加了对GEO类型的支持。GEO，Geographic，地理信息的缩写。该类型，就是元素的2维坐标，在地图上就是经纬度。Redis基于该类型，提供了经纬度设置，查询，范围查询，距离查询，经纬度Hash等常见操作。\n\nGeospatial常用命令见 [Redis6 文档](https://yuyun-zhao.github.io/documents/Redis6.pdf)。\n\n\n\n## Redis 常用命令\n\n### Key 关键字\n\n![image-20210911230855564](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911230855564.png)\n\n### String\n\n![image-20210911230754903](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911230754903.png)\n\n常用命令：\n\n- `SET key value`\n- `GET key`\n- `MSET key value [key value…]`  同时设置多个键值\n- `MGET key [key…]` 同时获取多个键值\n- `INCR key` 递增数字 （可以不用预先设置key的数值。如果预先设置key但值不是数字，则会报错)\n- `INCRBY key increment` 增加指定的整数 \n- `DECR key` 递减数值 \n- `DECRBY key decrement` 减少指定的整数\n- `STRLEN key`  获取字符串长度\n- `SETNX key value`  分布式锁\n\n### List\n\n![image-20210911231436324](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911231436324.png)\n\n常用命令：\n\n- `LPUSH key value [value …]`  向列表左边添加元素 \n- `RPUSH key value [value …]`  向列表右边添加元素 \n- `LRANGE key start stop`  查看列表 \n- `LLEN key`  获取列表中元素的个数\n\n性能总结：\n\n- 它是一个字符串链表，left、right都可以插入添加；\n- 如果键不存在，创建新的链表；\n- 如果键已存在，新增内容；\n- 如果值全移除，对应的键也就消失了。\n- 链表的操作无论是头和尾效率都极高，但假如是对中间元素进行操作，效率就很惨淡了。\n\n### Set\n\n![image-20210911231420212](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911231420212.png)\n\n常用命令：\n\n- `SADD key member [member …]`  添加元素 \n- `SREM key member [member …]`  删除元素 \n- `SMEMBERS key`  获取集合中的所有元素 \n- `SISMEMBER key member`  判断元素是否在集合中 \n- `SCARD key`  获取集合中的元素个数 \n-  `SRANDMEMBER key [数字]`  从集合中随机弹出一个元素，元素不删除\n- `SPOP key[数字]`  从集合中随机弹出一个元素，出一个删一个 \n\n集合运算：\n\n- 集合的差集运算A - B\n  - 属于A但不属于B的元素构成的集合\n  - `SDIFF key [key …]`\n- 集合的交集运算A ∩ B\n  - 属于A同时也属于B的共同拥有的元素构成的集合\n  - `SINTER key [key …]`\n- 集合的并集运算A U B\n  - 属于A或者属于B的元素合并后的集合\n  - `SUNION key [key …]`\n\n\n\n### Hash\n\n![image-20210911231758180](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911231758180.png)\n\n常用命令：\n\n- `HSET key field value`  一次设置一个字段值 \n- `HGET key field`  一次获取一个字段值\n- `HMSET key field value [field value …]`  一次设置多个字段值 \n- `HMGET key field [field …]`  一次获取多个字段值 \n- `HGETALL key`  获取所有字段值 \n- `HLEN key`  获取某个key内的全部数量 \n- `HDEL key`  删除一个key \n\n### ZSet\n\n![image-20210911231825494](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911231825494.png)\n\n常用命令：\n\n- `ZADD key score member [score member …]`  添加元素 \n- `ZRANGE key start stop [WITHSCORES]`  按照元素分数从小到大的顺序返回索引从start到stop之间的所有元素 \n- `ZSCORE key member` 获取元素的分数 \n- `ZREM key member [member …]`  删除元素 \n- `ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] ` 获取指定分数范围的元素 \n- `ZINCRBY key increment member`  增加某个元素的分数\n- ` ZCARD key`  获取集合中元素的数量\n- `ZCOUNT key min max`  获得指定分数范围内的元素个数 \n- ` ZREMRANGEBYRANK key start stop ` 按照排名范围删除元素\n- 获取元素的排名\n  - `ZRANK key member`  从小到大 \n  - `ZREVRANK key member`  从大到小 \n\n## Redis 配置文件介绍\n\nRedis 的配置文件位于 Redis 安装目录下，文件名为 `redis.conf`可以通过 CONFIG 命令查看或设置配置项。\n\n`Redis CONFIG` 命令格式如下：\n\n``` bash\nredis 127.0.0.1:6379> CONFIG GET CONFIG_SETTING_NAME\n```\n\n**实例**\n\n``` bash\nredis 127.0.0.1:6379> CONFIG GET loglevel\n\n1) \"loglevel\"\n2) \"notice\"\n```\n\n### 参数说明\n\n`redis.conf` 配置项说明如下：\n\n![image-20210911232231984](/images/%E3%80%90Redis%E3%80%91Redis/image-20210911232231984.png)\n\n## Redis 持久化\n\nRedis 的两种持久化方式：\n\n- **RDB（Redis DataBase）**：备份数据集\n- **AOF（Append Only File）**：仅备份指令\n\n### RDB\n\nRDB（Redis DataBase）是指在指定的时间间隔内将内存中的**数据集快照**写入磁盘，也就是行话讲的`Snapshot`快照，它恢复时是将快照文件直接读到内存里。\n\nRedis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个**临时文件**中，待持久化过程都结束了，再用这个临时文件替换上次持久化好的文件。 整个过程中，**主进程是不进行任何IO操作的**，这就确保了极高的性能。如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那RDB方式要比AOF方式更加的高效。RDB的缺点是最后一次持久化后的数据可能丢失。\n\n>Fork的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等） 数值都和原进程一致，但是是一个全新的进程，并**作为原进程的子进程**\n>\n>在Linux程序中，fork() 会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，Linux中引入了“**写时复制技术**”\n>\n>**一般情况父进程和子进程会共用同一段物理内存**，只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。\n\n写时复制技术：\n\n其他线程在读取数据时，当有写操作时，先将数据复制一份出来，写操作的线程将向其内写数据。写完后将数据与原先数据进行合并。之后再来读操作时读取的就是新的内容。（将原数据的引用指向复制后的数据上）\n\nRDB持久化过程：\n\n![image-20210912103134052](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912103134052.png)\n\nRDB 默认保存的备份文件为 `dump.rdb` 文件（可以在配置文件中修改名称）。相关配置在 `redis.conf` 的 `### SNAPSHOTTING ###` 部分。`dump.rdb`文件的保存路径在配置文件的 `dir ./` 位置配置。\n\n**如何触发RDB快照**：\n\n- 配置文件中默认的快照配置 `dbfilename dump.rdb`\n- 命令 `save` 或者是 `bgsave`\n  - `save`：同步保存，阻塞其他所有操作\t\n  - `bgsave`：Redis会在后台（Background）**异步**进行快照操作， 快照同时还可以响应客户端请求。可以通过 `lastsave` 命令获取最后一次成功执行快照的时间\n- 执行 `flushall` 命令，也会产生 `dump.rdb` 文件，但里面是空的，无意义\n\n**如何恢复**：\n\n- 将备份文件`dump.rdb`移动到 Redis 安装目录并启动服务即可\n- `CONFIG GET dir`获取备份文件保存的目录\n\n**如何停止**：\n\n动态停止RDB保存规则的方法：`redis-cli config set save \"\"`\n\n### RDB 常见配置\n\n`dump.rdb`文件的保存路径：\n\n![image-20210912111523166](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912111523166.png)\n\n**保存时机策略**：\n\n![image-20210912104201388](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912104201388.png)\n\n默认保存时机策略是：1分钟内改了1万次，或5分钟内改了10次，或15分钟内改了1次。若想禁用保存，则可以不设置`save`指令或给`save`传入空字符串。\n\n**stop-writes-on-bgsave-error**：\n\n![image-20210912111553281](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912111553281.png)\n\n当Redis无法写入磁盘的话，直接关掉Redis的写操作。推荐yes。\n\n**rdbcompression 压缩文件**：\n\n![image-20210912111619198](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912111619198.png)\n\n对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能。推荐yes。\n\n**rdbchecksum 检查完整性**：\n\n![image-20210912111730249](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912111730249.png)\n\n在存储快照后，还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。推荐yes。\n\n\n\n### RDB 优势与劣势\n\n**优势**\n\n- 适合大规模的数据恢复\n- 对数据完整性和一致性要求不高\n\n**劣势**\n\n- 在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会**丢失最后一次快照后的所有修改**\n- Fork的时候，内存中的数据被克隆了一份，**大致2倍的膨胀性**需要考虑\n- 虽然Redis在fork时使用了**写时拷贝技术**，但是如果数据庞大时还是比较消耗性能。\n\n### RDB 小结\n\n![img](/images/%E3%80%90Redis%E3%80%91Redis/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzIxLnBuZw)\n\n- RDB是一个非常紧凑的文件。\n- RDB在保存RDB文件时**父进程唯一需要做的就是fork出一个子进程，接下来的工作全部由子进程来做，父进程不需要再做其他IO操作，所以RDB持久化方式可以最大化redis的性能**。\n- 与AOF相比，在恢复大的数据集的时候，RDB方式会更快一一些。\n- 数据丢失风险大。\n- RDB需要经常fork子进程来保存数据集到硬盘上，当数据集比较大的时候fork的过程是非常耗时的吗，可能会导致Redis在一些毫秒级不能回应客户端请求。\n\n### AOF\n\nAOF（Append Only File）以**日志的形式来记录每个写操作**（增量保存），将Redis执行过的所有**写指令记录下来（读操作不记录）**， **只许追加（append）文件但不可以改写文件**，redis启动之初会读取该文件重新构建数据，换言之，redis 重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。AOF的同步是**异步完成的**。\n\n**AOF和RDB同时开启时，系统默认读取AOF的数据（数据不会存在丢失）**\n\n### AOF 持久化流程\n\n- 客户端的请求写命令会被append追加到AOF缓冲区内；\n- AOF缓冲区根据AOF **持久化策略[always,everysec,no]** 将操作sync同步到磁盘的AOF文件中；\n- AOF文件大小超过重写策略或手动重写时，会对AOF文件**rewrite**重写，压缩AOF文件容量；\n- Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的；\n\n![image-20210912112446186](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912112446186.png)\n\nRDB 默认保存的备份文件为 `appendonly.aof` 文件（可以在配置文件中修改名称）。相关配置在 `redis.conf` 的 `### APPEND ONLY MODE ###` 部分。AOF文件的保存路径，同RDB的路径一致。\n\n**AOF和RDB同时开启时，系统默认读取AOF的数据（数据不会存在丢失）**\n\n若 `appendonly.aof` 文件出现损坏，可以使用`Redis-check-aof --fix`命令进行修复。\n\n### AOF 同步频率设置\n\n- **appendfsync always**：始终同步，每次Redis的写入都会立刻记入日志；性能较差但数据完整性比较好\n- **appendfsync everysec**：**每秒同步**，每秒记入日志一次，**如果宕机，本秒的数据可能丢失**（RDB方式损失的时间可能更长）。\n- **appendfsync no**：Redis不主动进行同步，把同步时机交给操作系统。\n\n### Rewrite 重写压缩\n\nAOF采用**文件追加方式，文件会越来越大**。为避免出现此种情况，新增了**重写机制Rewrite**：当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩， 只保留可以恢复数据的**最小指令集**。可以使用命令 `bgrewriteaof`：在一个子进程中进行aof的重写，从而不阻塞主进程对其余命令的处理，同时解决了aof文件过大问题。\n\n#### Rewrite 原理\n\nAOF文件持续增长而过大时，**会fork出一条新进程来将文件重写（也是先写临时文件最后再rename）**，**redis4.0版本后的重写，实质上就是把 rdb 的快照，以二级制的形式附在新的aof头部，作为已有的历史数据，替换掉原来的流水账操作**。\n\n每次 rewrite 并不是基于旧的指令日志进行 merge 的（因为可能某次宕机导致日志中存储错误的指令），而是**基于当时内存中的数据**进行指令的重新构建，这样健壮性会好很多。\n\n#### Rewrite 相关配置\n\n**`no-appendfsync-on-rewrite`**\n\n> https://blog.csdn.net/jingkyks/article/details/46956905\n\n同时在执行`bgrewriteaof`操作和主进程写aof文件的操作，两者都会操作磁盘，而`bgrewriteaof`往往会涉及大量磁盘操作，这样就会造成主进程在写aof文件的时候出现阻塞的情形，现在`no-appendfsync-on-rewrite`参数出场了。\n\n>  如果该参数设置为no，是最安全的方式，不会丢失数据，但是要忍受阻塞的问题。如果设置为yes呢？这就相当于将appendfsync设置为no，这说明并没有执行磁盘操作，只是写入了缓冲区，因此这样并不会造成阻塞（因为没有竞争磁盘），但是如果这个时候redis挂掉，就会丢失数据。丢失多少数据呢？在linux的操作系统的默认设置下，最多会丢失30s的数据。\n\n- 如果 `no-appendfsync-on-rewrite=yes` ：正在重写时新增命令不再写入aof文件，而是写入缓存，等重写结束再同步到aof文件。这种模式下用户请求不会阻塞，但是在这段时间如果宕机会丢失这段时间的缓存数据。（降低数据安全性，提高性能）\n-  如果 `no-appendfsync-on-rewrite=no`：正在重写时新增命令会阻塞等待重写操作完成再同步到磁盘中，缺点是会发生阻塞。（数据安全，但是性能降低）\n\n**重写触发机制**：\n\n重写虽然可以节约大量磁盘空间，减少恢复时间。但是每次重写还是有一定的负担的，因此设定Redis要满足一定条件才会进行重写。 \n\nRedis会记录上次重写时的AOF大小，默认配置是当AOF文件大小是上次rewrite后大小的**两倍**且文件大于**64M**时触发。修改以下配置即可更改重写触发时机：\n\n- `auto-aof-rewrite-percentage`：设置重写的基准值，文件达到100%时开始重写（文件是原来重写后文件的2倍时触发）例如：文件达到70MB开始重写，降到50MB，下次什么时候开始重写？100MB\n- `auto-aof-rewrite-min-size`：设置重写的基准值，最小文件64MB。达到这个值开始重写，一般该值设置大一些 3~5GB。\n\n### Rewrite 流程\n\n- `bgrewriteaof`触发重写，判断是否当前有`bgsave`（RDB进程）或`bgrewriteaof`在运行，如果有，则等待该命令结束后再继续执行。\n- **主进程fork出子进程执行重写操作，保证主进程不会阻塞**。\n- 子进程遍历Redis内存中数据到**临时文件**，**客户端的写请求同时写入aof_buf缓冲区和aof_rewrite_buf重写缓冲区保证原AOF文件完整以及新AOF文件生成期间的新的数据修改动作不会丢失。**\n- 子进程写完新的AOF文件后，**向主进程发信号，父进程更新统计信息**。\n- 主进程把`aof_rewrite_buf`中的数据写入到新的AOF文件。\n- 使用新的AOF文件覆盖旧的AOF文件，完成AOF重写。\n\n![image-20210912114736426](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912114736426.png)\n\n### AOF 优势与劣势\n\n**优势**\n\n- 备份机制更稳健，**丢失数据概率更低**。\n- 可读的日志文本，通过操作AOF稳健，可以处理误操作。\n\n**劣势**\n\n- 相同数据集的数据而言aof文件占用磁盘空间要远大于rdb文件，恢复速度慢于rdb\n- 每次读写都同步的话，有一定的性能压力。\n- AOF运行效率要慢于RDB，每秒同步策略效率较好，不同步效率和RDB相同\n\n### AOF 小结\n\n![img](/images/%E3%80%90Redis%E3%80%91Redis/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzIyLnBuZw)\n\n- AOF文件时一个只进行**追加的日志文件**\n- Redis可以在AOF文件体积变得过大时，**自动地在后台对AOF进行重写**\n- AOF文件有序地保存了对数据库执行的所有写入操作，这些写入操作以Redis协议的格式保存，因此AOF文件的内容非常容易被人读懂，对文件进行分析也很轻松\n- 对于相同的数据集来说，**AOF文件的体积通常要大于RDB文件的体积**\n- 根据所使用的 fsync 策略，**AOF的速度可能会慢于RDB**\n\n### 总结\n\n官方推荐两个都启用。\n\n- 如果对数据不敏感，可以选单独用RDB。\n- 不建议单独用 AOF，因为可能会出现Bug。\n- 如果只是做纯内存缓存，可以都不用。\n\n**官方建议**：\n\n- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储\n- AOF持久化方式记录每次对服务器写的操作，当服务器重启的时候会重新执行这些命令来恢复原始的数据，AOF命令以redis协议追加保存每次写的操作到文件末尾\n- Redis还能对AOF文件进行后台重写，使得AOF文件的体积不至于过大\n- 只做缓存：如果你只希望你的数据在服务器运行的时候存在，你也可以不使用任何持久化方式\n\n同时开启两种持久化方式：\n\n- 在这种情况下，当redis重启的时候会**优先载入AOF文件来恢复原始的数据，因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整。**\n- RDB的数据不实时，同时使用两者时服务器重启也只会找AOF文件。那要不要只使用AOF呢？ 建议不要，因为RDB更适合用于备份数据库（AOF在不断变化不好备份）， 快速重启，而且不会有AOF可能潜在的bug，留着作为一个万一的手段。\n\n性能建议：\n\n- 因为RDB文件只用作后备用途，建议只在 Slave上持久化RDB文件，而且只要15分钟备份一次就够了，只保留save 900 1这条规则。\n- 如果使用AOF，好处是在最恶劣情况下也只会丢失不超过两秒数据，启动脚本较简单只load自己的AOF文件就可以了。代价：一是带来了持续的IO，二是AOF Rewrite的最后将Rewrite过程中产生的新数据写到新文件造成的阻塞几乎是不可避免的。\n- 只要硬盘许可，应该尽量减少AOF Rewrite的频率，AOF重写的基础大小默认值64M太小了，可以设到5G以上。\n- 默认超过原大小100%大小时重写可以改到适当的数值。\n\n## Redis 发布和订阅\n\nRedis 发布订阅 (pub/sub) 是一种消息通信模式：发送者 (pub) 发送消息，订阅者 (sub) 接收消息。Redis 客户端可以订阅任意数量的频道。\n\n![image-20210913183818788](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913183818788.png)\n\n当给这个频道发布消息后，消息就会发送给订阅的客户端\n\n![image-20210913183826952](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913183826952.png)\n\nRedis Sentinel 间通讯时使用了发布订阅功能。\n\n## Redis 事务\n\n> [Redis 事务官方文档](http://www.redis.cn/topics/transactions.html)\n\nRedis事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。\n\nRedis事务的主要作用就是**串联多个命令防止别的命令插队**。\n\n### 事务常用命令\n\n![image-20210912202032972](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912202032972.png)\n\n**Multi、Exec、Discard**\n\n从输入`Multi`命令开始（**组队阶段**），输入的命令都会依次进入**命令队列**中，**但不会执行**，直到输入`Exec`命令后进入**执行阶段**，Redis会将之前命令队列中的命令依次执行。组队的过程中可以通过`Discard`命令来放弃组队。 \n\n![image-20210912202226170](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912202226170.png)\n\n1. 当**组队阶段**中某个命令出现了报告错误，执行时整个的所有队列都会被取消。\n\n![image-20210912202406006](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912202406006.png)\n\n2. 当**执行阶段**某个命令报出了错误，则**只有报错的命令不会被执行，而其他的命令都会执行**，不会回滚。\n\n![image-20210912202423699](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912202423699.png)\n\n### 事务三阶段\n\n- 开启：以`MULTI`开始一个事务\n- 入队：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面\n- 执行：由`EXEC`命令触发事务\n\n### WATCH\n\n`WATCH`指令，类似乐观锁，事务提交时，如果Key的值已被别的客户端改变， 比如某个list已被别的客户端`push/pop`过了，整个事务队列都不会被执行。\n\n通过`WATCH`命令在事务执行之前监控了多个Keys，倘若在`WATCH`之后有任何Key的值发生了变化， `EXEC`命令执行的事务都将被放弃，同时返回`Nullmulti-bulk`应答以通知调用者事务执行失败\n\n### 悲观锁\n\n![image-20210912202607757](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912202607757.png)\n\n**悲观锁（Pessimistic Lock）**，顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。**传统的关系型数据库里边就用到了很多这种锁机制**，比如**行锁**，**表锁**等，**读锁**，**写锁**等，都是在做操作之前先上锁。\n\n### 乐观锁\n\n![image-20210912202630691](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912202630691.png)\n\n**乐观锁（Optimistic Lock）**，顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用**版本号**等机制。**乐观锁适用于多读的应用类型，这样可以提高吞吐量**。Redis就是利用这种check-and-set机制实现事务的。\n\n何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。\n\n此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，**如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据**。\n\n使用 **WATCH 乐观锁 + LUA脚本** 可以解决**超卖**问题和**库存遗留**问题。详细代码见见 [Redis6 文档](https://yuyun-zhao.github.io/documents/Redis6.pdf)。\n\n\n\n### Redis 事务三特性\n\n- **单独的隔离操作**：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断\n- **没有隔离级别的概念**：队列中的命令没有提交之前都不会实际的被执行，因为事务提交前任何指令都不会被实际执行， 也就不存在“事务内的查询要看到事务里的更新，在事务外查询不能看到”这个让人万分头痛的问题\n- **不保证原子性**：Redis同一个事务中如果有一条命令执行失败，其后的命令仍然会被执行，没有回滚\n\n## Redis 主从复制\n\n主机数据更新后根据配置和策略， 自动同步到备机的master/slaver机制，**Master以写为主，Slave以读为主**。主从复制能够用来：\n\n- 读写分离，性能扩展\n- 容灾快速恢复\n\n![image-20210912204058177](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912204058177.png)\n\n每次与Master断开连接之后，都需要重新连接，除非配置进`redis.conf`文件（具体位置：`redis.conf`搜寻`#### REPLICATION ####`）。常用命令：\n\n- 从库配置命令：`slaveof 主库IP 主库端口`。\n- 查看当前主从配置：`info replication`\n\n> replication\n> 英 [ˌreplɪ’keɪʃ(ə)n] 美 [ˌreplɪ’keɪʃ(ə)n]\n> n.\n> (绘画等的)复制;拷贝;重复(实验);(尤指对答辩的)回答\n\n### 常见问题\n\n- 切入点问题？slave1、slave2是从头开始复制还是从切入点开始复制？比如从k4进来，那之前的123是否也可以复制？答：从头开始复制；123也可以复制\n- 从机是否可以写？set可否？答：从机不可写，不可set，主机可写\n- 主机shutdown后情况如何？从机是上位还是原地待命答：从机还是原地待命\n- 主机又回来了后，主机新增记录，从机还能否顺利复制？答：能\n- 其中一台从机down后情况如何？依照原有它能跟上大部队吗？答：不能跟上，每次与master断开之后，都需要重新连接，除非你配置进`redis.conf`文件（具体位置：`redis.conf`搜寻`#### REPLICATION ####`）\n\n### 薪火相传\n\n上一个slave可以是下一个slave的Master，slave同样可以接收其他 slaves的连接和同步请求，那么该slave作为了链条中下一个的master，可以有效减轻master的写压力，去中心化降低风险。风险是一旦某个slave宕机，后面的slave都没法备份。主机挂了，从机还是从机，无法写数据了。中途变更转向：会清除之前的数据，重新建立拷贝最新的。\n\n![image-20210912204652370](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912204652370.png)\n\n### 反客为主\n\n当一个master宕机后，后面的slave可以立刻升为master，使当前数据库停止与其他数据库的同步，转成主数据库。其后面的slave不用做任何修改。\n\n使用命令：`SLAVEOF no one`\n\n### 主从复制原理\n\nslave启动成功连接到master后会发送一个`sync`命令。master接到命令启动后台的**存盘进程**，同时收集所有接收到的用于修改数据集命令，在后台进程执行完毕之后，master将传送整个**RDB数据文件**到slave，以完成一次完全同步。\n\n- **全量复制**：而slave服务在接收到数据库文件数据后，将其存盘并加载到内存中\n- **增量复制**：master继续将**新的**所有收集到的修改命令依次传给slave（只传送新增的修改命令），完成同步\n\n在Redis2.8版本后，主从断线后恢复的情况下实现增量复制。\n\n![image-20210912205253939](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912205253939.png)\n\n## Redis 哨兵模式（sentinel）\n\n> 更多细节见博客 https://www.huaweicloud.com/articles/f2e85fe106cd4b353928348513fecdab.html、https://www.cnblogs.com/kevingrace/p/9004460.html\n\n哨兵模式是**反客为主的自动版**，能够在后台监控主机是否故障，如果故障了根据**投票数**自动将从库转换为主库。通常哨兵也配置多个，互相监控。一组sentinel能同时监控多个master，原master重启后会变为从机。哨兵与服务器间通过发布订阅获得消息。\n\nRedis 的 Sentinel 系统用于管理多个 Redis 服务器(instance) 该系统执行以下三个任务:\n\n- **监控(Monitoring)**：Sentinel 会不断地定期检查你的主服务器和从服务器是否运作正常。\n- **提醒(Notification)**：当被监控的某个 Redis 服务器出现问题时，Sentinel 可以通过 API 向管理员或者其他应用程序发送通知（例如发邮件）。\n- **自动故障迁移(Automaticfailover)**：当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作， 它会将失效主服务器的其中一个从服务器升级为新的主服务器， 并让失效主服务器的其他从服务器改为复制新的主服务器；通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel ， 其他 Sentinel 对它们自己的配置进行更新。**当客户端试图连接失效的主服务器时， 集群也会向客户端返回新主服务器的地址**，使得集群可以使用新主服务器代替失效服务器。\n\nRedis Sentinel 是一个分布式系统， 你可以在一个架构中运行多个 Sentinel 进程（progress）， 这些进程使用流言协议（gossip protocols) 来接收关于主服务器是否下线的信息， 并使用投票协议（agreement protocols）来决定是否执行自动故障迁移， 以及选择哪个从服务器作为新的主服务器。\n\n哨兵是 Redis 集群架构中非常重要的一个组件，主要功能如下：\n\n- **集群监控**，负责监控 Redis Master 和 Slave 进程是否正常工作；\n- **消息通知**，如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员；\n- **故障转移**，如果 Master node 挂掉了，会自动转移到 Slave node 上；\n- **配置中心**，如果故障转移发生了，通知 Client 客户端新的 Master 地址。\n\n![image-20210913165922239](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913165922239.png)\n\n![image-20210913164351029](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913164351029.png)\n\n假设主服务器宕机，哨兵1先监测到这个结果，系统并不会立刻进行 **failover（故障转移）** 过程，仅仅是哨兵1主观地认为其不可用，此现象称为**主观下线**。当其后的哨兵也检测到主服务器不可用，并且数量达到一定值时（该数量在配置文件中配置，见下文），那么哨兵之间将进行一次投票，选出某一个哨兵发出 failover 指令，根据优先级/偏移量选出新的主机，所有从机都设置该服务器为主服务器，这个过程被称为**客观下线**。\n\n**主观下线**：所谓主观下线，就是**单个**sentinel认为某个服务下线（有可能是接收不到订阅，之间的网络不通等等原因）。\n\nsentinel会以每秒一次的频率向所有与其建立了命令连接的实例（master，从服务，其他sentinel）发ping命令，通过判断ping回复是有效回复，还是无效回复来判断实例时候在线（对该sentinel来说是“主观在线”）。\n\nsentinel配置文件中的`down-after-milliseconds`设置了判断主观下线的时间长度，如果实例在`down-after-milliseconds`毫秒内，返回的都是无效回复，那么sentinel会认为该实例已（主观）下线，修改其flags状态为`SRI_S_DOWN`。如果多个sentinel监视一个服务，有可能存在多个sentinel的`down-after-milliseconds`配置不同，这个在实际生产中要注意。\n\n**客观下线**：当主观下线的节点是主节点时，此时该哨兵3节点会通过指令`sentinel is-masterdown-by-addr`寻求其它哨兵节点对主节点的判断，如果其他的哨兵也认为主节点主观线下了，则当认为主观下线的票数超过了`quorum`（选举）个数，此时哨兵节点则认为该主节点确实有问题，这样就客观下线了，大部分哨兵节点都同意下线操作，也就说是客观下线。\n\n![image-20210913174004677](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913174004677.png)\n\n哨兵至少需要3个实例，来保证自己的健壮性。哨兵+redis主从的部署架构，是不会保证数据零丢失的，只能保证redis集群的高可用性。对于哨兵+redis主从这种复杂的部署架构，尽量在测试环境和生产环境，都进行充分的测试和演练。\n\n### 自动故障转移机制\n\n哪个从机会被选举为主机呢？首先判断每个slave与master断开连接的次数：如果一个slave与master失去联系超过10次，并且每次都超过了配置的最大失联时间(`down-after-milliseconds`)，如果sentinel在进行failover时发现slave失联，那么这个slave就会被sentinel认为不适合用来做新master的。\n\n符合上述条件的slave才会被列入master候选人列表，并根据以下顺序来进行排序：\n\n![image-20210912211245500](/images/%E3%80%90Redis%E3%80%91Redis/image-20210912211245500.png)\n\n- 根据优先级别：`slave-priority` （在配置文件中配置`slave-priority`设置）。优先级默认：`slave-priority 100`，值越小优先级越高（如果一个redis的slave优先级配置为0，那么它将永远不会被选为master。但是它依然会从master哪里复制数据。）\n- 偏移量是指与原主机数据相比相差最少的，即同步率最高的（根据复制的下标数比较谁的次数多）\n- 每个Redis实例启动后都会随机生成一个40位的`runid`\n\n### 配置方法\n\n1. 新建`sentinel.conf`文件\n2. 配置监控的master地址：`sentinel monitor mymaster 127.0.0.1 6379 1`\n\n其中`mymaster`为监控对象起的服务器名称， 1 为至少有多少个哨兵同意迁移的数量（可以同时配置多个哨兵一起监控，此处配置的1代表至少1个哨兵觉得主服务器宕机才可以进行重新选举）。 \n\n3. 启动哨兵：`redis-sentinel  ./sentinel.conf`\n\n### 复制延时\n\n由于所有的写操作都是先在master上操作，然后同步更新到slave上，所以从master同步到slave机器有一定的延迟，当系统很繁忙的时候，延迟问题会更加严重，slave机器数量的增加也会使这个问题更加严重。\n\n### 哨兵 leader 选举算法\n\n如果主节点被判定为**客观下线**之后，就要选取一个哨兵节点来完成后面的故障转移工作，选举出一个leader的流程如下：\n\n- 每个在线的哨兵节点都可以成为领导者，当它确认（比如哨兵3）主节点下线时，会向其它哨兵发`is-master-down-by-addr`命令，征求判断并要求将自己设置为领导者，由领导者处理故障转移；\n- 当其它哨兵收到此命令时，可以同意或者拒绝它成为领导者；\n- 如果哨兵3发现自己在选举的票数大于等于`num(sentinels)/2+1`时，将成为领导者，如果没有超过，继续选举...\n\n![image-20210913173713479](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913173713479.png)\n\n### Redis 哨兵主备切换的数据丢失问题\n\n共有两种数据丢失场景：\n\n#### 1. 异步复制时间过长\n\n因为master->slave的复制是**异步的**，所以可能有部分数据还没复制到slave，master就宕机了（此时异步复制时间过长），这些数据就丢失了。\n\n#### 2. 脑裂\n\n脑裂，也就是说，某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着，这个时候，**集群中就会出现两个master**。\n\n此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master数据可能就会丢失。因此master在恢复的时候，会被作为一个slave挂到新的master上，自己的数据会被清空，从新的master复制数据，导致刚才客户端传来的数据丢失。\n\n#### 解决异步复制和脑裂导致的数据丢失\n\n设置数据复制和同步的延迟时间，**当slave与master间的数据复制同步时间超过了延迟时间，就拒绝客户端的写请求**：\n\n``` \nmin-slaves-to-write 1   # 最少一个slave和master进行数据复制同步时超过延迟时间 \nmin-slaves-max-lag 10   # 延迟时间10s\n```\n\n> lag：落后，即延迟了10s\n\n该配置要求至少有1个slave进行数据复制和同步的延迟不能超过10秒。如果一旦某个slave和master进行数据复制和同步的**延迟超过了10秒钟**，那么这个时候，master就**不会再接收任何请求了**（即，若slave和master数据同步时间太长，master就别再写数据了，让客户端等待稍后再写）。\n\n#### 1. 减少异步复制的数据丢失\n有了`min-slaves-max-lag`这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就**拒绝写请求**（让客户端稍后再写），这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低的可控范围内。\n\n#### 2. 减少脑裂的数据丢失\n如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定数量的slave发送数据，而且slave超过10秒没有给自己ack消息，那么就直接拒绝客户端的写请求（让客户端稍后再写）。\n\n这样脑裂后的**旧master就不会接受client的新数据**，也就避免了数据丢失。上面的配置就确保了，如果跟任何一个slave丢了连接，在10秒后发现没有slave给自己ack，那么就拒绝新的写请求。因此在脑裂场景下，最多就丢失10秒的数据。\n\n### 总结\n\n哨兵架构，几乎可以做到了我们的要实现的**高可用**，但是哨兵的选举还是**需要时间的**，而且**中间会阻塞客户端的请求**，假如我们的选举消耗了1秒（实际可能几秒，高则几十秒），就在这1秒的时候来了客户端的请求，那个请求也是不可用的，并且我们的读写的节点实际还是单节点的，怎么办? 使用 Redis集群架构：\n\n![image-20210913175731575](/images/%E3%80%90Redis%E3%80%91Redis/image-20210913175731575.png)\n\nRedis的集群其实就是一个个小的主从结合在一起（官方建议小于1000个小主从），变成了我们的Redis集群，每个小主从也就是我们的Redis数据分片。\n\n## Redis Cluster 集群\n\n### 问题引出\n\n- 容量不够，redis如何进行扩容？\n- 并发写操作， redis如何分摊？\n\n另外，主从模式，薪火相传模式，主机宕机，导致ip地址发生变化，应用程序中配置需要修改对应的主机地址、端口等信息。\n\n之前通过代理主机来解决，但是 Redis 3.0 中提供了解决方案。就是**无中心化集群配置**。\n\n### 什么是集群\n\nRedis 集群实现了对Redis的**水平扩容**，即启动N个Redis节点，将整个数据库分布存储在这N个节点中，**每个节点存储总数据的 1/N**。Redis 的集群的功能就是为了解决**单机 Redis 容量有限的问题**。\n\nRedis 集群通过分区（partition）来提供一定程度的可用性（availability）： 即使集群中有一部分节点失效或者无法进行通讯， 集群也可以继续处理命令请求。\n\nRedis Cluster 集群节点**最小配置 6 个节点以上（3 主 3 从）**，其中**主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。**\n\nRedis Cluster 采用**虚拟槽分区**，所有的键根据哈希函数映射到 0～16383 个整数槽内，每个节点负责维护一部分槽以及槽所印映射的键值数据。\n\n**Redis Cluster 可以说是 Redis Sentinel 带分片的加强版**。也可以说：\n\n- **Redis Sentinel 着眼于高可用**，在 master 宕机时会自动将 slave 提升为 master ，继续提供服务。\n- **Redis Cluster 着眼于扩展性**，在单个 Redis 内存不足时，使用 Cluster 进行分片存储。\n\nRedis 集群配置方法见 [Redis6 文档](https://yuyun-zhao.github.io/documents/Redis6.pdf)。\n\n### slots 哈希槽\n\n一个 Redis 集群包含 16384 个哈希槽（hash slot）， 数据库中的每个键都属于这 16384 个哈希槽的其中一个， 集群使用公式 `CRC16(key) % 16384` 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。\n\n为什么是 16384 呢？主要考虑集群内的网络带宽，而 16384 刚好是 2K 字节大小。\n\n集群中的每个节点负责处理一部分插槽。 举个例子， 如果一个集群可以有主节点， 其中：\n\n- 节点 A 负责处理 0 号至 5460 号插槽。\n- 节点 B 负责处理 5461 号至 10922 号插槽。\n- 节点 C 负责处理 10923 号至 16383 号插槽。\n\n在`redis-cli`每次录入、查询键值，Redis都会计算出该key应该送往的插槽，如果不是该客户端对应服务器的插槽，Redis会报错，并告知应前往的Redis实例地址和端口。\n\n`redis-cli`客户端提供了 `–c ` 参数实现自动重定向：如 `redis-cli -c –p 6379` 登入后，再录入、查询键值对可以自动重定向。\n\n不在一个 slot 下的键值，是不能使用 `mget`, `mset` 等多键操作。\n\n![image-20210915195625155](/images/%E3%80%90Redis%E3%80%91Redis/image-20210915195625155.png)\n\n可以通过 `{}` 来定义组的概念，从而使key中 `{}` 内相同内容的键值对放到一个slot中去。\n\n![image-20210915195120417](/images/%E3%80%90Redis%E3%80%91Redis/image-20210915195120417.png)\n\n### 查询集群中的值\n\n`CLUSTER GETKEYSINSLOT <slot><count>` 返回 `count` 个 `slot` 槽中的键。\n\n### 故障恢复\n\n如果主节点下线？从节点能否自动升为主节点？注意：**15秒超时**\n\n![image-20210915195317930](/images/%E3%80%90Redis%E3%80%91Redis/image-20210915195317930.png)\n\n主节点恢复后，主从关系会如何？**主节点回来变成从机。**\n\n![image-20210915195323682](/images/%E3%80%90Redis%E3%80%91Redis/image-20210915195323682.png)\n\n如果某一段插槽的所有主从节点都宕掉，Redis服务是否还能继续?\n\n- 如果某一段插槽的所有主从都挂掉，而 `cluster-require-full-coverage` 为 yes ，那么 ，**整个集群都挂掉**\n- 如果某一段插槽的所有主从都挂掉，而 `cluster-require-full-coverage` 为 no ，那么，**该插槽**数据全都不能使用，也无法存储，但其他插槽仍然可以使用。\n\n 其中 `cluster-require-full-coverage` 为 `redis.conf `中的参数。\n\n### 集群优点\n\n- 无中心架构：访问任何一台服务器的主机都能路由到指定的服务器上，无需单独配置一台服务器进行路由；\n- 数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布；\n- 可扩展性：可线性扩展到 1000 多个节点，节点可动态添加或删除；\n- 高可用性：部分节点不可用时，集群仍可用。通过增加 Slave 做 standby 数据副本，能够实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave 到 Master 的角色提升；\n- 降低运维成本，提高系统的扩展性和可用性。\n\n### 集群缺点\n\n- Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅 JedisCluster 相对成熟，异常处理部分还不完善，比如常见的 “max redirect exception”。\n- 节点会因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断下线，这种 failover 是没有必要的。\n- 数据通过异步复制，不保证数据的强一致性。\n- 多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。\n- Slave 在集群中充当 “冷备”，不能缓解读压力，当然可以通过 SDK 的合理设计来提高 Slave 资源的利用率。\n\n\n\n## Redis 应用问题解决\n\n### 缓存穿透\n\n大量的请求瞬时涌入系统，而这个数据在 Redis 中**不存在**，**所有的请求都落到了数据库上**，从而可能压垮数据源。例如反复用一个不存在的用户id进行访问，会对数据库进行大量查询。造成这种情况的原因有系统设计不合理、缓存数据更新不及时，或爬虫等恶意攻击。\n\n![image-20210914170043586](/images/%E3%80%90Redis%E3%80%91Redis/image-20210914170043586.png)\n\n解决办法：\n\n**1. 使用布隆过滤器**\n\n布隆过滤器是一种比较巧妙的**概率型数据结构**，它实际上是一个很长的二进制向量 bitmaps 和一系列随机映射函数（哈希函数）。\n\n> 详细介绍见博客：https://zhuanlan.zhihu.com/p/43263751\n>\n> 本质上布隆过滤器是一种数据结构，比较巧妙的概率型数据结构（probabilistic data structure），特点是高效地插入和查询，可以用来告诉你 **“某样东西一定不存在或者可能存在”**。\n>\n> 相比于传统的 List、Set、Map 等数据结构，它更高效、占用空间更少，但是缺点是其返回的结果**是概率性的，而不是确切的**。\n\n其思想是：将查询的参数都存储到一个 bitmaps 中，在查询缓存前，再找个新的 bitmap，在里面对参数进行验证。如果验证的 bitmaps 中存在，则进行底层缓存的数据查询，如果 bitmap 中不存在查询参数，则进行拦截，不再进行缓存的数据查询。\n\n布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。)\n\n将所有可能存在的数据哈希到一个足够大的bitmaps中，一个一定不存在的数据会被这个bitmaps拦截掉，从而避免了对底层存储系统的查询压力。\n\n**2. 缓存空对象**\n\n如果从数据库查询的结果为空，**依然把这个结果进行缓存**，那么当用 key 获取数据时，即使数据不存在，Redis 也可以直接返回结果，避免多次访问数据库。但是缓存空值的缺点是：\n\n- 如果存在黑客恶意的随机访问，造成**缓存过多的空值**，那么可能造成很多**内存空间的浪费**。但是也可以对这些数据设置很短的过期时间来控制；\n- 如果查询的 key 对应的 Redis 缓存空值没有过期，数据库这时有了新数据，那么会出现**数据库和缓存数据不一致**的问题。但是可以保证当数据库有数据后更新缓存进行解决。\n\n**3. 设置可访问的名单（白名单）**\n\n使用 bitmaps 类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmap里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问。\n\n**4. 进行实时监控**\n\n当发现Redis的命中率开始急速降低，需要排查访问对象和访问的数据，和运维人员配合，可以设置黑名单限制服务。\n\n### 缓存击穿\n\n缓存击穿是指一个key非常热点（其内容存在于数据库中，不像缓存穿透里key的内容不存在），但某个时刻，其在Redis中过期，这时大量且持久的并发集中对数据库中的这个key进行访问，就会瞬间压垮数据库，就像在屏幕上凿开一个洞，击穿了数据库。常见场景：微博突发热点，大量高并发请求瞬间访问该热点key，但该key在某个时刻过期，其过期瞬间这些高并发请求就会一起访问数据库，导致其被击穿。\n\n![image-20210914174222618](/images/%E3%80%90Redis%E3%80%91Redis/image-20210914174222618.png)\n\n解决方法：\n\n**1. 预先设置热门数据**\n\n在Redis高峰访问之前，把一些热门数据提前存入到redis里面，加大这些热门数据key的时长\n\n**2. 实时调整**\n\n现场监控哪些数据热门，实时调整key的过期时长\n\n**3. 使用分布式锁**\n\n使用分布式锁，保证对于每个key同时只有一个线程去查询后端服务，其他线程没有获得分布式锁的权限，因此只需要等待即可，不会再访问数据库。这种方式将高并发的压力转移到了分布式锁，因此对分布式锁的考验很大。Redis 分布式锁使用方法见文章[【Redis】Redis 分布式锁](https://yuyun-zhao.github.io/2021/09/15/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/)\n\n在缓存失效的时候（判断拿出来的值为空），不是立即去访问数据库，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX）去set一个mutex key。\n\n- 当操作返回成功时，再进行访问数据库的操作，并回设缓存，最后删除mutex key；\n- 当操作返回失败，证明有线程正在访问数据库，当前线程睡眠一段时间再重试整个get缓存的方法。\n\n![image-20210914175544276](/images/%E3%80%90Redis%E3%80%91Redis/image-20210914175544276.png)\n\n### 缓存雪崩\n\n缓存雪崩是指当大量缓存几乎同一时间失效或Redis宕机时，大量的请求访问直接请求数据库，导致数据库服务器无法抗住请求或挂掉的情况。这时网站常常会出现 502 错误，导致网站不可用问题。\n\n缓存雪崩与缓存击穿的区别在于这里针对**很多key几乎同时过期**，前者则是**某一个key**。\n\n缓存失效时的雪崩效应对底层系统的冲击非常可怕，在预防缓存雪崩时，有以下方案：\n\n**1. 构建多级缓存架构**\n\nNginx缓存 + Redis缓存 + 其他缓存（ehcache等）\n\n**2. 使用锁或队列**\n\n用加锁或者队列的方式来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。不适用高并发情况。\n\n**3. 设置过期标志更新缓存**\n\n记录缓存数据是否过期（设置提前量），如果过期会触发通知另外的线程在后台去更新实际key的缓存。\n\n**4. 将缓存失效时间分散开**\n\n比如我们可以在原有的失效时间基础上增加一个**随机值**，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。\n\n**5. 服务降级**\n\n对数据库进行过载保护或应用层限流，这种情况下一般是在网站处于大流量、高并发时，服务器整体不能承受时，可以采用的一种限流保护措施；\n\n### 分布式锁\n\nRedis 分布式锁使用方法见文章[【Redis】Redis 分布式锁](https://yuyun-zhao.github.io/2021/09/15/%E3%80%90Redis%E3%80%91Redis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/)\n\n## Jedis 使用\n\n导入 Maven 依赖：\n\n``` xml\n<dependency>\n    <groupId>redis.clients</groupId>\n    <artifactId>jedis</artifactId>\n    <version>3.2.0</version>\n</dependency>\n```\n\n### Jedis 常用 API\n\n``` java\nimport java.util.HashMap;\nimport java.util.Iterator;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\n\nimport redis.clients.jedis.Jedis;\n\npublic class TestAPI {\n    public static void main(String[] args) {\n\n        Jedis jedis = new Jedis(\"127.0.0.1\", 6379);\n\n        // key\n        Set<String> keys = jedis.keys(\"*\");\n        for (Iterator iterator = keys.iterator(); iterator.hasNext();) {\n            String key = (String) iterator.next();\n            System.out.println(key);\n        }\n        System.out.println(\"jedis.exists====>\" + jedis.exists(\"k2\"));\n        System.out.println(jedis.ttl(\"k1\"));\n\n        // String\n        // jedis.append(\"k1\",\"myreids\");\n        System.out.println(jedis.get(\"k1\"));\n        jedis.set(\"k4\", \"k4_redis\");\n        System.out.println(\"----------------------------------------\");\n        jedis.mset(\"str1\", \"v1\", \"str2\", \"v2\", \"str3\", \"v3\");\n        System.out.println(jedis.mget(\"str1\", \"str2\", \"str3\"));\n\n        // list\n        System.out.println(\"----------------------------------------\");\n        // jedis.lpush(\"mylist\",\"v1\",\"v2\",\"v3\",\"v4\",\"v5\");\n        List<String> list = jedis.lrange(\"mylist\", 0, -1);\n        for (String element : list) {\n            System.out.println(element);\n        }\n\n        // set\n        jedis.sadd(\"orders\", \"jd001\");\n        jedis.sadd(\"orders\", \"jd002\");\n        jedis.sadd(\"orders\", \"jd003\");\n        Set<String> set1 = jedis.smembers(\"orders\");\n        for (Iterator iterator = set1.iterator(); iterator.hasNext();) {\n            String string = (String) iterator.next();\n            System.out.println(string);\n        }\n        jedis.srem(\"orders\", \"jd002\");\n        System.out.println(jedis.smembers(\"orders\").size());\n\n        // hash\n        jedis.hset(\"hash1\", \"userName\", \"lisi\");\n        System.out.println(jedis.hget(\"hash1\", \"userName\"));\n        Map<String, String> map = new HashMap<String, String>();\n        map.put(\"telphone\", \"13811814763\");\n        map.put(\"address\", \"atguigu\");\n        map.put(\"email\", \"abc@163.com\");\n        jedis.hmset(\"hash2\", map);\n        List<String> result = jedis.hmget(\"hash2\", \"telphone\", \"email\");\n        for (String element : result) {\n            System.out.println(element);\n        }\n\n        // zset\n        jedis.zadd(\"zset01\", 60d, \"v1\");\n        jedis.zadd(\"zset01\", 70d, \"v2\");\n        jedis.zadd(\"zset01\", 80d, \"v3\");\n        jedis.zadd(\"zset01\", 90d, \"v4\");\n\n        Set<String> s1 = jedis.zrange(\"zset01\", 0, -1);\n        for (Iterator iterator = s1.iterator(); iterator.hasNext();) {\n            String string = (String) iterator.next();\n            System.out.println(string);\n        }\n    }\n}\n```\n\n### Jedis 事务\n\n未加锁事务：\n\n``` java\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.Response;\nimport redis.clients.jedis.Transaction;\n\npublic class Test03 {\n    public static void main(String[] args) {\n        Jedis jedis = new Jedis(\"127.0.0.1\", 6379);\n\n        // 监控key，如果该动了事务就被放弃\n        /*\n\t\t * 3 jedis.watch(\"serialNum\"); jedis.set(\"serialNum\",\"s#####################\");\n\t\t * jedis.unwatch();\n\t\t */\n        Transaction transaction = jedis.multi();// 被当作一个命令进行执行\n        Response<String> response = transaction.get(\"serialNum\");\n        transaction.set(\"serialNum\", \"s002\");\n        response = transaction.get(\"serialNum\");\n        transaction.lpush(\"list3\", \"a\");\n        transaction.lpush(\"list3\", \"b\");\n        transaction.lpush(\"list3\", \"c\");\n\n        transaction.exec();\n        // 2 transaction.discard();\n        System.out.println(\"serialNum***********\" + response.get());\n\n    }\n}\n```\n\n加锁时事务（`jedis.watch(\"xxx\")`）：\n\n``` java\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.Transaction;\n\npublic class TestTX {\n    public boolean transMethod() throws InterruptedException {\n        Jedis jedis = new Jedis(\"127.0.0.1\", 6379);\n        int balance; // 可用余额\n        int debt; // 欠额\n        int amtToSubtract = 10; // 实刷额度\n\n        jedis.watch(\"balance\");\n        // jedis.set(\"balance\",\"5\");//此句不该出现，模拟其他程序已经修改了该条目\n        Thread.sleep(7000);\n        balance = Integer.parseInt(jedis.get(\"balance\"));\n        if (balance < amtToSubtract) {\n            jedis.unwatch();\n            System.out.println(\"modify\");\n            return false;\n        } else {\n            System.out.println(\"***********transaction\");\n            Transaction transaction = jedis.multi();\n            transaction.decrBy(\"balance\", amtToSubtract);\n            transaction.incrBy(\"debt\", amtToSubtract);\n            transaction.exec();\n            balance = Integer.parseInt(jedis.get(\"balance\"));\n            debt = Integer.parseInt(jedis.get(\"debt\"));\n\n            System.out.println(\"*******\" + balance);\n            System.out.println(\"*******\" + debt);\n            return true;\n        }\n    }\n\n    /**\n\t * 通俗点讲，watch命令就是标记一个键，如果标记了一个键，在提交事务前如果该键被别人修改过，那事务就会失败，这种情况通常可以在程序中重新再尝试一次。\n\t * 首先标记了键balance，然后检查余额是否足够，不足就取消标记，并不做扣减；足够的话，就启动事务进行更新操作，\n\t * 如果在此期间键balance被其它人修改，那在提交事务（执行exec）时就会报错，程序中通常可以捕获这类错误再重新执行一次，直到成功。\n\t * \n\t * @throws InterruptedException\n\t */\n    public static void main(String[] args) throws InterruptedException {\n        TestTX test = new TestTX();\n        boolean retValue = test.transMethod();\n        System.out.println(\"main retValue-------: \" + retValue);\n    }\n}\n```\n\n### Jedis 主从复制\n\n``` java\nimport redis.clients.jedis.Jedis;\n\npublic class TestMS {\n    public static void main(String[] args) {\n        Jedis jedis_M = new Jedis(\"127.0.0.1\", 6379);\n        Jedis jedis_S = new Jedis(\"127.0.0.1\", 6380);\n\n        jedis_S.slaveof(\"127.0.0.1\", 6379);\n        jedis_M.set(\"class\", \"1122V2\");\n\n        String result = jedis_S.get(\"class\");//可能有延迟，需再次启动才能使用\n        System.out.println(result);\n    }\n}\n```\n\n### JedisPool\n\n1. 获取Jedis实例需要从JedisPool中获取\n2. 用完Jedis实例需要返还给JedisPool\n3. 如果Jedis在使用过程中出错，则也需要还给JedisPool\n\n饿汉模式下的JedisPool单例创建：\n\n``` java\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.JedisPool;\nimport redis.clients.jedis.JedisPoolConfig;\n\npublic class JedisPoolUtil {\n    private static volatile JedisPool jedisPool = null;\n\n    private JedisPoolUtil() {\n    }\n\n    public static JedisPool getJedisPoolInstance() {\n        if (null == jedisPool) {\n            synchronized (JedisPoolUtil.class) {\n                if (null == jedisPool) {\n                    JedisPoolConfig poolConfig = new JedisPoolConfig();\n                    poolConfig.setMaxActive(1000);\n                    poolConfig.setMaxIdle(32);\n                    poolConfig.setMaxWait(100 * 1000);\n                    poolConfig.setTestOnBorrow(true);\n\n                    jedisPool = new JedisPool(poolConfig, \"127.0.0.1\", 6379);\n                }\n            }\n        }\n        return jedisPool;\n    }\n\n    public static void release(JedisPool jedisPool, Jedis jedis) {\n        if (null != jedis) {\n            jedisPool.returnResourceObject(jedis);\n        }\n    }\n}\n```\n\n测试：\n\n``` java\nimport redis.clients.jedis.Jedis;\nimport redis.clients.jedis.JedisPool;\n\npublic class TestPool {\n\n    public static void main(String[] args) {\n        JedisPool jedisPool = JedisPoolUtil.getJedisPoolInstance();\n        JedisPool jedisPool2 = JedisPoolUtil.getJedisPoolInstance();\n\n        System.out.println(jedisPool == jedisPool2);\n\n        Jedis jedis = null;\n        try {\n            jedis = jedisPool.getResource();\n            jedis.set(\"aa\", \"bb\");\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            JedisPoolUtil.release(jedisPool, jedis);\n        }\n    }\n}\n```\n\n### JedisPool 配置总结\n\nJedisPool的配置参数大部分是由**JedisPoolConfig**的对应项来赋值的。\n\n- **maxActive**：控制一个pool可分配多少个jedis实例，通过pool.getResource()来获取；如果赋值为-1，则表示不限制；如果pool已经分配了maxActive个jedis实例，则此时pool的状态为exhausted。\n- **maxIdle**：控制一个pool最多有多少个状态为idle(空闲)的jedis实例；\n- **whenExhaustedAction**：表示当pool中的jedis实例都被allocated完时，pool要采取的操作；默认有三种。\n  - `WHEN_EXHAUSTED_FAIL` --> 表示无jedis实例时，直接抛出NoSuchElementException；\n  - `WHEN_EXHAUSTED_BLOCK` --> 则表示阻塞住，或者达到maxWait时抛出JedisConnectionException；\n  - `WHEN_EXHAUSTED_GROW` --> 则表示新建一个jedis实例，也就说设置的maxActive无用；\n- **maxWait**：表示当borrow一个jedis实例时，最大的等待时间，如果超过等待时间，则直接抛JedisConnectionException；\n- **testOnBorrow**：获得一个jedis实例的时候是否检查连接可用性（ping()）；如果为true，则得到的jedis实例均是可用的；\n- **testOnReturn**：return 一个jedis实例给pool时，是否检查连接可用性（ping()）；\n- **testWhileIdle**：如果为true，表示有一个idle object evitor线程对idle object进行扫描，如果validate失败，此object会被从pool中drop掉；这一项只有在timeBetweenEvictionRunsMillis大于0时才有意义；\n- **timeBetweenEvictionRunsMillis**：表示idle object evitor两次扫描之间要sleep的毫秒数；\n- **numTestsPerEvictionRun**：表示idle object evitor每次扫描的最多的对象数；\n- **minEvictableIdleTimeMillis**：表示一个对象至少停留在idle状态的最短时间，然后才能被idle object evitor扫描并驱逐；这一项只有在timeBetweenEvictionRunsMillis大于0时才有意义；\n- **softMinEvictableIdleTimeMillis**：在minEvictableIdleTimeMillis基础上，加入了至少minIdle个对象已经在pool里面了。如果为-1，evicted不会根据idle time驱逐任何对象。如果minEvictableIdleTimeMillis>0，则此项设置无意义，且只有在timeBetweenEvictionRunsMillis大于0时才有意义；\n- **lifo**：borrowObject返回对象时，是采用DEFAULT_LIFO（last in first out，即类似cache的最频繁使用队列），如果为False，则表示FIFO队列；\n\n其中JedisPoolConfig对一些参数的默认设置如下：\n\n- testWhileIdle=true\n- minEvictableIdleTimeMills=60000\n- timeBetweenEvictionRunsMillis=30000\n- numTestsPerEvictionRun=-1\n  \n\n## Redis 6.0 新功能\n\n\n\n\n\n","tags":["Redis","中间件"],"categories":["Redis","中间件"]},{"title":"【Redis】NoSQL 介绍","url":"/2021/09/08/【Redis】NoSQL介绍/","content":"\n## 数据库发展历史\n\n### 单机 MySQL 时代\n\n> https://blog.csdn.net/u011863024/article/details/107476187\n\n在90年代，一个网站的访问量一般都不大，用单个数据库完全可以轻松应付。在那个时候，更多的都是静态网页，动态交互类型的网站不多。\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzAxLnBuZw)\n\n> DAL dal是数据访问层的英文缩写，即为数据访问层（Data Access Layer）\n\n上述架构中数据存储的瓶颈是什么?\n\n1. 数据量的总大小一个机器放不下时\n2. 数据的索引（B+ Tree）一个机器的内存放不下时\n3. 访问量（读写混合）一个实例不能承受\n\n### Memcached(缓存) + MySQL + 垂直拆分\n\n后来，随着访问量的上升，几乎大部分使用MySQL架构的网站在数据库上都开始出现了性能问题，web程序不再仅仅专注在功能上，同时也在追求性能。程序员们开始大量的使用缓存技术来缓解数据库的压力，优化数据库的结构和索引。开始比较流行的是通过文件缓存来缓解数据库压力，但是当访问量继续增大的时候，多台web机器通过文件缓存不能共享，大量的小文件缓存也带了比较高的IO压力。在这个时候，Memcached就自然的成为一个非常时尚的技术产品。\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzAyLnBuZw)\n\n### MySQL 主从读写分离\n\n由于数据库的写入压力增加，Memcached 只能缓解数据库的**读取**压力。读写集中在一个数据库上让数据库不堪重负，大部分网站开始使用主从复制技术来达到读写分离，以提高读写性能和读库的可扩展性。Mysql的master-slave模式成为这个时候的网站标配了。\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzAzLnBuZw)\n\n<!-- More -->\n\n### 分表分库 + 水平拆分 + MySQL 集群\n\n在Memcached的高速缓存，MySQL的主从复制， 读写分离的基础之上，这时MySQL主库的写压力开始出现瓶颈，而数据量的持续猛增，由于MyISAM使用表锁，在高并发下会出现严重的锁问题，大量的高并发MySQL应用开始使用**InnoDB**引擎代替MyISAM。\n\n同时，开始流行使用分表分库来缓解写压力和数据增长的扩展问题。这个时候，分表分库成了一个热门技术，是面试的热门问题也是业界讨论的热门技术问题。也就在这个时候，MySQL推出了还不太稳定的表分区，这也给技术实力一般的公司带来了希望。虽然MySQL推出了MySQL Cluster集群，但性能也不能很好满足互联网的要求，只是在高可靠性上提供了非常大的保证。\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzA0LnBuZw)\n\n### MySQL 的扩展性瓶颈\n\nMySQL数据库也经常存储一些大文本字段，导致数据库表非常的大，在做数据库恢复的时候就导致非常的慢，不容易快速恢复数据库。比如1000万4KB大小的文本就接近40GB的大小， 如果能把这些数据从MySQL省去，MySQL将变得非常的小。关系数据库很强大，但是它并不能很好的应付所有的应用场景。MySQL的扩展性差（需要复杂的技术来实现），大数据下IO压力大，表结构更改困难，正是当前使用MySQL的开发人员面临的问题。\n\n### 如今的分布式\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzA1LnBuZw)\n\n### 为什么用 NoSQL\n\n今天我们可以通过第三方平台（如: Google，Facebook等） 可以很容易地访问和抓取数据。用户的个人信息，社交网络，地理位置，用户生成的数据和用户操作日志已经成倍的增加。我们如果要对这些用户数据进行挖掘，那SQL数据库已经不适合这些应用了，NoSQL数据库的发展也却能很好的处理这些大的数据。\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzA3LnBuZw)\n\n### Web1.0 时代\n\nWeb1.0的时代，数据访问量很有限，用一夫当关的高性能的单点服务器可以解决大部分问题。\n\n![image-20210913125502050](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/image-20210913125502050.png)\n\n### Web2.0 时代\n\n随着Web2.0的时代的到来，用户访问量大幅度提升，同时产生了大量的用户数据。加上后来的智能移动设备的普及，所有的互联网平台都面临了巨大的性能挑战。\n\n![image-20210913125531993](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/image-20210913125531993.png)\n\n### 解决 CPU 及内存压力\n\n问题：Session 存在哪？\n\n![image-20210913125549134](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/image-20210913125549134.png)\n\n最佳方案：存在缓存数据库中\n\n### 解决 IO 压力\n\n![image-20210913125706449](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/image-20210913125706449.png)\n\n## NoSQL 概述\n\n> https://blog.csdn.net/u011863024/article/details/107476187\n\nNoSQL（NoSQL = Not Only SQL），意即“不仅仅是SQL”，**泛指非关系型的数据库**。\n\n随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL 数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题，包括超大规模数据的存储。（例如谷歌或Facebook每天为他们的用户收集万亿比特的数据）。这些类型的数据存储不需要固定的模式，**无需多余操作就可以横向扩展**。\n\nNoSQL 不依赖业务逻辑方式存储，而以简单的 key-value 模式存储。因此大大地增加了数据库的扩展能力。其特点：\n\n- 不遵循SQL标准\n- 不支持ACID\n- 远超于SQL的性能\n\n### NoSQL 适用场景\n\n- 对数据高并发的读写\n- 海量数据的读写\n- 对数据高可扩展性的\n\n### NoSQL 不适用场景\n\n- 需要事务支持\n- 基于sql的结构化查询存储，处理复杂的关系，需要即席查询。\n\n\n\n### 易扩展\n\nNoSQL数据库种类繁多，但是一个共同的特点都是去掉关系数据库的关系型特性。数据之间无关系，这样就非常容易扩展。也无形之间，在架构的层面上带来了可扩展的能力。\n\n### 大数据量高性能\n\nNoSQL数据库都具有非常高的读写性能，尤其在大数据量下，同样表现优秀。这得益于它的无关系性，数据库的结构简单。\n\n一般MySQL使用Query Cache，每次表的更新Cache就失效，是一种大粒度的Cache，在针对web2.0的交互频繁的应用，Cache性能不高。而NoSQL的Cache是记录级的，是一种细粒度的Cache，所以NoSQL在这个层面上来说就要性能高很多了。\n\n### 多样灵活的数据模型\n\nNoSQL无需事先为要存储的数据建立字段，随时可以存储自定义的数据格式。\n\n而在关系数据库里，增删字段是一件非常麻烦的事情。如果是非常大数据量的表，增加字段简直就是一个噩梦。\n\n### 传统 RDBMS VS NOSQL\n\n**RDBMS**\n\n- 高度组织化结构化数据\n- 结构化查询语言(SQL)\n- 数据和关系都存储在单独的表中\n- 数据操纵语言，数据定义语言\n- 严格的一致性\n- 基础事务\n\n**NoSQL**\n\n- 代表着不仅仅是SQL\n- 没有声明性查询语言\n- 没有预定义的模式\n- 键-值对存储，列存储，文档存储，图形数据库\n- 最终一致性，而非ACID属性\n- 非结构化和不可预知的数据\n- CAP定理\n- 高性能，高可用性和可伸缩性\n\n### 有哪些 NoSQL\n\n- Memcached：\n  - **很早**出现的NoSql数据库\n  - 数据都在内存中，一般**不持久化**\n  - 支持简单的key-value模式，支持**类型单一**\n  - 一般是作为缓存数据库辅助持久化的数据库\n- Redis\n  - 几乎覆盖了Memcached的绝大部分功能\n  - 数据都在内存中，**支持持久化**，主要用作备份恢复\n  - 除了支持简单的key-value模式，还**支持多种数据结构**的存储，比如 list、set、hash、zset等。\n  - 一般是作为缓存数据库辅助持久化的数据库\n- MongDB\n  - 高性能、开源、模式自由(schema free)的**文档型数据库**\n  - 数据都在内存中， 如果内存不足，把不常用的数据保存到硬盘\n  - 虽然是key-value模式，但是对value（尤其是**json**）提供了丰富的查询功能\n  - 支持二进制数据及大型对象\n  - 可以根据数据的特点**替代RDBMS** ，成为独立的数据库。或者配合RDBMS，存储特定的数据。\n\n\n\n大数据时代的3V：\n\n1. 海量Volume\n2. 多样Variety\n3. 实时Velocity\n\n互联网需求的3高：\n\n1. 高并发\n2. 高可括\n3. 高性能\n\n\n\n\n\n## NoSQL 数据模型简介\n\n以一个电商客户、订单、订购、地址模型来对比关系型数据库和非关系型数据库：\n\n传统关系型数据库如何设计\n- ER图（1：1、1：N、N：1）主外键等\n- NOSQL如何设计\n  - BSON ()是一种类json的一种二进制形式的存储格式，简称Binary JSON，它和JSON一样，支持内嵌的文档对象和数组对象\n- 两者对比，问题和难点\n  - 为什么用聚合模型来处理\n    - 高并发的操作是不太建议用关联查询的，互联网公司用冗余数据来避免关联查询\n    - 分布式事务是支持不了太多的并发的\n\n聚合模型\n- KV\n- BSON\n- 列族\n  - 顾名思义，是按列存储数据的。最大的特点是方便存储结构化和半结构化数据，方便做数据压缩，对针对某一 列或者某几列的查询有非常大的IO优势。\n  ![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzE4LnBuZw)\n- 图形\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzE3LnBuZw)\n\n\n\n## NoSQL 数据库的四大分类\n\n- KV\n  - 新浪：BerkeleyDB + Redis\n  - 美团：Redis + tair\n  - 阿里、百度：memcache + Redis\n- 文档型数据库（bson格式比较多）\n  - CouchDB\n  - MongoDB\n    - MongoDB是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。\n    - MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。\n- 列存储数据库\n  - Cassandra、HBase\n  - 分布式文件系统\n- 图关系数据库\n  - 它不是放图形的、放的是关系比如：朋友圈社交网络、广告推荐系统\n  - 社交网络、推荐系统。专注于构建关系图谱\n  - Neo4j、InfoGrid\n- 四者对比：\n\n![img](/images/%E3%80%90Redis%E3%80%91NoSQL%E4%BB%8B%E7%BB%8D/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzE5LnBuZw)\n\n## 分布式与集群\n\n分布式系统（distributed system）：由多台计算机和通信的软件组件通过计算机网络连接（本地网络或广域网）组成。分布式系统是建立在网络之上的软件系统。正是因为软件的特性，所以分布式系统具有高度的内聚性和透明性。因此，网络和分布式系统之间的区别更多的在于高层软件（特别是操作系统），而不是硬件。分布式系统可以应用在在不同的平台上如：PC、工作站、局域网和广域网上等。\n\n简单来讲：\n\n- **分布式**：不同的多台服务器上面部署不同的服务模块（工程），他们之间通过Rpc/Rmi之间通信和调用，对外提供服务和组内协作。\n- **集群**：不同的多台服务器上面部署相同的服务模块，通过分布式调度软件进行统一的调度，对外提供服务和访问。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Redis"],"categories":["Redis"]},{"title":"【Spring Cloud】Spring Cloud Alibaba Seata","url":"/2021/09/08/【SpringCloud】Seata/","content":"\n## Seata 简介\n\n> Seata：[https://](https://github.com/seata/seata)[github.com/seata/seata](https://github.com/seata/seata)\n\nSeata（Simple Extensible Autonomous Transaction Architecture，简单可扩展自治事务框架）是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。Seata 开源半年左右，目前已经有接近一万 star，社区非常活跃。\n\n![Seata](/images/%E3%80%90SpringCloud%E3%80%91Seata/1561960344792-8810110b-1eda-4417-944e-7051ca52f90d.png)\n\nSeata 会有 4 种分布式事务解决方案，分别是 AT 模式、TCC 模式、Saga 模式和 XA 模式：\n\n![image-20200305230513415](/images/%E3%80%90SpringCloud%E3%80%91Seata/image-20200305230513415.png)\n\nSeata中比较常用的是**AT模式**。下面将介绍其工作原理。\n\n### Seata 产品模块\n\n如下图所示，Seata 中有三大模块，分别是 **TM**、**RM** 和 **TC**。 **其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起（集成在业务代码中）**，**TC 作为 Seata 的服务端独立部署，并被注册到注册中心和配置中心**。\n\n![image-20200305225811888](/images/%E3%80%90SpringCloud%E3%80%91Seata/image-20200305225811888-1631068234111.png)\n\n<!-- More -->\n\n### Seata 详细架构和流程\n\nSeata 中的几个基本概念：\n\n- **TC（Transaction Coordinator）** ：事务协调者，维护全局和分支事务的状态，驱动全局事务提交或回滚（TM之间的协调者），**TC作为Seata的服务端 Seata-Serve，下载后直接使用jar包运行，其将被注册到注册中心和配置中心从而被各个微服务订阅**。\n- **TM（Transaction Manager）** ：事务管理器，定义全局事务的范围：开始全局事务、提交或回滚全局事务。TM对应的方法使用 **@GlobalTransactional** 注解标注，其内的业务代码处于同一个全局事务下。\n- **RM（Resource Manager）** ：资源管理器，管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n\n![image-20200305225811888](/images/%E3%80%90SpringCloud%E3%80%91Seata/image-20200305225811888.png)\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Seata/302377d33ddcd708e20b996bd9f2c7b8.png)\n\n**三者工作分工**：\n\n- TM：业务模块中全局事务的开启者\n  - 向TC开启一个全局事务（标注 **@GlobalTransactionnal** 注解代表开启一个全局事务）\n  - 全局事务创建成功并生成一个全局唯一的`XID`，`XID`在微服务调用链路的上下文中传播；\n  - 调用其它微服务（例如订单模块作为TM调用了库存模块和支付模块）\n  - TM向TC发起针对`XID`的**全局提交或回滚决议**\n- RM：业务模块执行者中包含RM部分，负责**向TC汇报事务执行状态**\n  - 负责与数据库交互，执行本地事务\n  - **向TC注册分支事务**，并提交本地事务执行结果\n  - 将其纳入XID对应全局事务的管辖\n- TM：结束对微服务的调用，**通知TC全局事务执行完毕，事务一阶段结束**\n- TC：**汇总各个分支事务执行结果，决定分布式事务是提交还是回滚**，通知所有 RM提交/回滚资源，事务二阶段结束。\n\n**三者的关系**：\n\n- TM用于开启全局事务生成`XID`，调用其他微服务，并在全局事务的方法执行完毕后通知TC全局事务执行完毕（即一阶段结束），此时TC即可统计各个分支事务的执行结果判断二阶段应该是提交还是回滚；\n- 每个RM与本地数据库交互，执行本地事务并立即提交（不阻塞），之后向TC注册当前分支事务的信息，最后将本地事务提交的结果上报给 TC；\n- TC调度`XID`下管辖的全部分支事务完成提交或回滚请求。其先保存每个RM注册的分支事务信息，当收到TM的一阶段结束通知后，根据接收汇总到的各个分支事务的执行结果判断二阶段应该是提交还是回滚：若都成功，则通知每个RM二阶段提交；若有失败，则通知每个RM二阶段回滚\n\n### Seata 两个阶段具体工作流程\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Seata/302377d33ddcd708e20b996bd9f2c7b8.png)\n\n**一阶段**：\n\n- TM开启全局事务，并向TC声明全局事务，包括全局事务`XID`信息\n- TM所在服务调用其它微服务\n- 微服务主要由RM来执行\n  - 查询`before_image`\n  - 执行本地事务\n  - 查询`after_image`\n  - 生成`undo_log`并写入数据库\n  - 向TC注册分支事务，告知事务执行结果\n  - 获取全局锁（阻止其它全局事务并发修改当前数据）\n  - 释放本地锁（不影响其它业务对数据的操作）\n- 待所有业务执行完毕，事务发起者（TM）会尝试向TC提交全局事务\n\n**二阶段**：\n\n- TC统计分支事务执行情况，根据结果判断下一步行为：\n  - 分支都成功：通知分支事务，提交事务\n  - 有分支执行失败：通知执行成功的分支事务，回滚数据\n- 分支事务的RM收到TC传来的消息：\n  - 提交事务：直接清空`before_image`和`after_image`信息，释放全局锁\n  - 回滚事务：\n    - 校验`after_image`，判断是否有脏写\n    - 如果没有脏写，回滚数据到`before_image`，清除`before_image`和`after_image`\n    - 如果有脏写，请求人工介入\n\n### Seata 工作流程示例\n\n详见Seata的官方文档：https://seata.io/zh-cn/docs/overview/what-is-seata.html\n\n> #### 场景\n\n以一个示例来说明 AT 分支的整个工作过程。\n\n业务表：`product`\n\n| Field | Type         | Key  |\n| ----- | ------------ | ---- |\n| id    | bigint(20)   | PRI  |\n| name  | varchar(100) |      |\n| since | varchar(100) |      |\n\nAT 分支事务的业务逻辑：\n\n```sql\nupdate product set name = 'GTS' where name = 'TXC';\n```\n\n> #### 一阶段\n\n过程：\n\n1. **解析 SQL**：得到 SQL 的类型（UPDATE），表（product），条件（where name = 'TXC'）等相关的信息。\n2. **查询 before image（前镜像）**：根据解析得到的条件信息，生成查询语句，定位数据（即修改前先查询出来当前这，保存到undo log）。\n\n```sql\nselect id, name, since from product where name = 'TXC';\n```\n\n得到前镜像：\n\n| id   | name | since |\n| ---- | ---- | ----- |\n| 1    | TXC  | 2014  |\n\n3. **执行业务 SQL**：更新这条记录的 name 为 'GTS'。\n4. **查询 after image（后镜像）**：根据前镜像的结果，通过 **主键（id）** 定位数据。\n\n```sql\nselect id, name, since from product where id = `1`;\n```\n\n得到后镜像：\n\n| id   | name | since |\n| ---- | ---- | ----- |\n| 1    | GTS  | 2014  |\n\n5. **插入回滚日志**：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 `UNDO_LOG` 表中：\n\n```json\n{\n    \"branchId\": 641789253,\n    \"undoItems\": [{\n        \"afterImage\": {\n            \"rows\": [{\n                \"fields\": [{\n                    \"name\": \"id\",\n                    \"type\": 4,\n                    \"value\": 1\n                }, {\n                    \"name\": \"name\",\n                    \"type\": 12,\n                    \"value\": \"GTS\"\n                }, {\n                    \"name\": \"since\",\n                    \"type\": 12,\n                    \"value\": \"2014\"\n                }]\n            }],\n            \"tableName\": \"product\"\n        },\n        \"beforeImage\": {\n            \"rows\": [{\n                \"fields\": [{\n                    \"name\": \"id\",\n                    \"type\": 4,\n                    \"value\": 1\n                }, {\n                    \"name\": \"name\",\n                    \"type\": 12,\n                    \"value\": \"TXC\"\n                }, {\n                    \"name\": \"since\",\n                    \"type\": 12,\n                    \"value\": \"2014\"\n                }]\n            }],\n            \"tableName\": \"product\"\n        },\n        \"sqlType\": \"UPDATE\"\n    }],\n    \"xid\": \"xid:xxx\"\n}\n```\n\n6. **提交前，向 TC 注册分支**：申请 `product` 表中，主键值等于 1 的记录的 **全局锁** 。\n7. **本地事务提交**：业务数据的更新和前面步骤中生成的 `UNDO LOG` 一并提交。\n8. **将本地事务提交的结果上报给 TC**。\n\n> #### 二阶段-回滚\n\n若收到 TC 的**分支回滚**请求，开启一个本地事务，执行如下操作：\n\n1. 通过 `XID` 和 `Branch ID` 查找到相应的 `UNDO LOG` 记录（同一个微服务可能同时参与多个不同的事务组，有多个 `XID`）。\n2. **数据校验**：拿 `UNDO LOG` 中的后镜像与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理。\n3. 根据 `UNDO LOG` 中的**前镜像**和**业务 SQL 的相关信息**生成并执行回滚的语句：\n\n```sql\nupdate product set name = 'TXC' where id = 1;\n```\n\n4. **提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC**。\n\n> #### 二阶段-提交\n\n1. 收到 TC 的**分支提交**请求，把请求放入一个**异步任务的队列**中，**马上返回提交成功**的结果给 TC。\n2. 异步任务阶段的分支提交请求将**异步和批量地删除相应 `UNDO LOG` 记录**。\n\n\n\n## Seata AT 模式实战\n\n假定一个用户购买商品的业务逻辑。整个业务逻辑由3个微服务提供支持：\n\n- **仓储服务**：对给定的商品扣除仓储数量。\n- **订单服务**：根据采购需求创建订单。\n- **帐户服务**：从用户帐户中扣除余额。\n\n流程图：\n\n![image-20200306164728739](/images/%E3%80%90SpringCloud%E3%80%91Seata/image-20200306164728739.png)\n\n订单服务在下单时，同时调用库存服务和用户服务，此时就会发生跨服务和跨数据源的分布式事务问题。\n\n## 安装 TC：Seata-Server\n\n> https://blog.csdn.net/u011863024/article/details/114298288\n\nSeata 模型中的TC即为其官方提供的`Seata-Server`，[下载地址](https://github.com/seata/seata/releases)。\n\n将`seata-server-0.9.0.zip`解压到指定目录。其核心配置文件主要有两个（`${seata_home}/conf/`目录）：\n\n- `registry.conf`：配置注册中心信息\n- `file.conf`：配置事务信息以及数据库信息\n\n### registry.conf\n\n`registry.conf`配置文件需要指定使用的注册中心和配置中心信息（本案例使用Nacos）， TC 将被注册到注册中心和配置中心，其他的微服务模块都去注册中心订阅TC的地址：\n\n```json\nregistry {\n  # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa\n  # 注册中心改用为nacos\n  type = \"nacos\"\n\n  nacos {\n  \t## 加端口号\n    serverAddr = \"localhost:8848\"\n    namespace = \"\"\n    cluster = \"default\"\n  }\n  ...\n}\n\nconfig {\n  # file、nacos 、apollo、zk、consul、etcd3\n  type = \"nacos\"\n\n  nacos {\n    serverAddr = \"localhost:8848\"\n    namespace = \"\"\n  }\n  ...\n}\n```\n\n### file.conf\n\n`file.conf`配置文件需要修改的内容：\n\n- 事务组名称：`my_tx_group`（同一个事务组里的业务模块应配置相同的组名）\n- 事务日志存储模式： `\"db\"`\n- 数据库信息\n\n```json\nservice {\n    ## my_tx_group 是自定义的事务组名\n    vgroup_mapping.my.test.tx_group=\"my_tx_group\" \n    default.grouplist = \"127.0.0.1:8091\"\n    enableDegrade = false\n    disable = false\n    max.commitretry.timeout= \"-1\"\n    max.ollbackretry.timeout= \"-1\"\n}\n\n## transaction log store\nstore {\n\t## store mode: file, db\n\t## 事务日志的存储模式改成db\n\tmode = \"db\"\n\t\n\t## file store\n\tfile {\n            dir = \"sessionStore\"\n\n            # branch session size, if exceeded first try compress lockkey, still exceeded throws exceptions\n            max-branch-session-size = 16384\n            # globe session size, if exceeded throws exceptions\n            max-global-session-size = 512\n            # file buffer size, if exceeded allocate new buffer\n            file-write-buffer-cache-size = 16384\n            # when recover batch read size\n            session.reload.read_size= 100\n            # async, sync\n            flush-disk-mode = async\n\t}\n\n\t# database store\n\tdb {\n            ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc.\n            datasource = \"dbcp\"\n            ## mysql/oracle/h2/oceanbase etc.\n            ## 配置数据源\n            db-type = \"mysql\"\n            driver-class-name = \"com.mysql.jdbc.Driver\"\n            url = \"jdbc:mysql://127.0.0.1:3306/seata\"\n            user = \"root\"\n            password = \"你自己密码\"\n            min-conn= 1\n            max-conn = 3\n            global.table = \"global_table\"\n            branch.table = \"branch_table\"\n            lock-table = \"lock_table\"\n            query-limit = 100\n\t}\n}\n```\n\n关键配置：\n\n`store`：TC的服务端数据存储配置\n\n- `mode`：数据存储方式，支持两种：file和db\n  - `file`：将数据存储在本地文件中，性能比较好，但不支持水平扩展\n  - `db`：将数据保存在指定的数据库中，需要指定数据库连接信息\n\n如果用文件作为存储介质，不需要其它配置了，直接运行即可。但是如果使用db作为存储介质，还需要在数据库中创建3张表：`\"global_table\"`、`\"branch_table\"`、`\"lock_table\"`，用于存储全局XID信息，分支信息和锁信息。在 Mysql 5.7 数据库新建库`seata`，在`seata`库里创建这三张表。建表`db_store.sql`在`\\seata-server-0.9.0\\seata\\conf`目录里面：\n\n```sql\n-- the table to store GlobalSession data\ndrop table if exists `global_table`;\ncreate table `global_table` (\n  `xid` varchar(128)  not null,\n  `transaction_id` bigint,\n  `status` tinyint not null,\n  `application_id` varchar(32),\n  `transaction_service_group` varchar(32),\n  `transaction_name` varchar(128),\n  `timeout` int,\n  `begin_time` bigint,\n  `application_data` varchar(2000),\n  `gmt_create` datetime,\n  `gmt_modified` datetime,\n  primary key (`xid`),\n  key `idx_gmt_modified_status` (`gmt_modified`, `status`),\n  key `idx_transaction_id` (`transaction_id`)\n);\n\n-- the table to store BranchSession data\ndrop table if exists `branch_table`;\ncreate table `branch_table` (\n  `branch_id` bigint not null,\n  `xid` varchar(128) not null,\n  `transaction_id` bigint ,\n  `resource_group_id` varchar(32),\n  `resource_id` varchar(256) ,\n  `lock_key` varchar(128) ,\n  `branch_type` varchar(8) ,\n  `status` tinyint,\n  `client_id` varchar(64),\n  `application_data` varchar(2000),\n  `gmt_create` datetime,\n  `gmt_modified` datetime,\n  primary key (`branch_id`),\n  key `idx_xid` (`xid`)\n);\n\n-- the table to store lock data\ndrop table if exists `lock_table`;\ncreate table `lock_table` (\n  `row_key` varchar(128) not null,\n  `xid` varchar(96),\n  `transaction_id` long ,\n  `branch_id` long,\n  `resource_id` varchar(256) ,\n  `table_name` varchar(32) ,\n  `pk` varchar(36) ,\n  `gmt_create` datetime ,\n  `gmt_modified` datetime,\n  primary key(`row_key`)\n);\n```\n\n以上步骤即完成了Seata-Server的配置工作，接下来先启动Nacos服务中心，再启动`seata-server - seata-server-0.9.0\\seata\\bin\\seata-server.bat`。此时的 Seata-Server 即注册到了Nacos服务中心，后续的微服务即可订阅到其信息。\n\n## Seata 业务数据库准备\n\n创建三个业务数据库：\n\n- `seata_ order`：订单信息数据库\n- `seata_ storage`：库存信息数据库\n- `seata_ account`：账户信息数据库\n\n1. 在 `seata_order` 库下建 `t_order` 表：\n\n```sql\nCREATE TABLE t_order (\n    `id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY,\n    `user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id',\n    `product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id',\n    `count` INT(11) DEFAULT NULL COMMENT '数量',\n    `money` DECIMAL(11,0) DEFAULT NULL COMMENT'金额',\n    `status` INT(1) DEFAULT NULL COMMENT '订单状态: 0:创建中; 1:已完结',\n) ENGINE=INNODB AUTO_INCREMENT=` DEFAULT CHARSET=utf8;\n\nSELECT * FROM t_order;\n```\n\n2. 在 `seata_storage` 库下建 `t_storage` 表：\n\n```sql\nCREATE TABLE t_storage (\n`id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY,\n`product_id` BIGINT(11) DEFAULT NULL COMMENT '产品id',\n`total` INT(11) DEFAULT NULL COMMENT '总库存'，\n`used` INT(11) DEFAULT NULL COMMENT '已用库存'，\n`residue` INT(11) DEFAULT NULL COMMENT '剩余库存'\n) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;\n\nINSERT INTO seata_storage.t_storage(`id`, `product_id`, `total`, `used`, `residue`)\nVALUES ('1', '1', '100', '0','100');\n\nSELECT * FROM t_storage;\n```\n\n3. 在 `seata_account `库下建 `t_account` 表：\n\n```sql\nCREATE TABLE t_account(\n\t`id` BIGINT(11) NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'id',\n\t`user_id` BIGINT(11) DEFAULT NULL COMMENT '用户id',\n\t`total` DECIMAL(10,0) DEFAULT NULL COMMENT '总额度',\n\t`used` DECIMAL(10,0) DEFAULT NULL COMMENT '已用余额', I\n\t`residue` DECIMAL(10,0) DEFAULT '0' COMMENT '剩余可用额度'\n) ENGINE=INNODB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;\n\nINSERT INTO seata_account.t_account(`id`, `user_id`, `total`, `used`, `residue`)\nVALUES ('1', '1', '1000', '0', '1000');\n\nSELECT * FROM t_account;\n```\n\n4. 按照上述三个库分别建对应的回滚日志表 `undo log`\n\n- 订单-库存-账户3个库下**都需要建各自的回滚日志表**\n- 建表语句见 `\\seata-server-0.9.0\\seata\\conf` 目录下的 `db_ undo_ log.sql`\n\n```sql\n-- the table to store seata xid data\n-- 0.7.0+ add context\n-- you must to init this sql for you business databese. the seata server not need it.\n-- 此脚本必须初始化在你当前的业务数据库中，用于AT 模式XID记录。与server端无关（注：业务数据库）\n-- 注意此处0.3.0+ 增加唯一索引 ux_undo_log\ndrop table `undo_log`;\nCREATE TABLE `undo_log` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT,\n  `branch_id` bigint(20) NOT NULL,\n  `xid` varchar(100) NOT NULL,\n  `context` varchar(128) NOT NULL,\n  `rollback_info` longblob NOT NULL,\n  `log_status` int(11) NOT NULL,\n  `log_created` datetime NOT NULL,\n  `log_modified` datetime NOT NULL,\n  `ext` varchar(100) DEFAULT NULL,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\n```\n\n## Order-Module 搭建\n\n创建订单模块 `seata-order-service2001`\n\n### 导入 Maven 依赖\n\n注意，排除了`spring-cloud-starter-alibaba-seata`中的seata版本，而使用自定义的seata版本包：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2020</artifactId>\n        <groupId>com.atguigu.springcloud</groupId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>seata-order-service2001</artifactId>\n\n    <dependencies>\n        <!--nacos-->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!--seata-->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-seata</artifactId>\n            <exclusions>\n                <exclusion>\n                    <artifactId>seata-all</artifactId>\n                    <groupId>io.seata</groupId>\n                </exclusion>\n            </exclusions>\n        </dependency>\n        <dependency>\n            <groupId>io.seata</groupId>\n            <artifactId>seata-all</artifactId>\n            <version>0.9.0</version>\n        </dependency>\n        <!--feign-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\n        </dependency>\n        <!--web-actuator-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--mysql-druid-->\n        <dependency>\n            <groupId>mysql</groupId>\n            <artifactId>mysql-connector-java</artifactId>\n            <version>5.1.37</version>\n        </dependency>\n        <dependency>\n            <groupId>com.alibaba</groupId>\n            <artifactId>druid-spring-boot-starter</artifactId>\n            <version>1.1.10</version>\n        </dependency>\n        <dependency>\n            <groupId>org.mybatis.spring.boot</groupId>\n            <artifactId>mybatis-spring-boot-starter</artifactId>\n            <version>2.0.0</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n### 配置文件 application.yaml\n\n``` yaml\nserver:\n  port: 2001\n\nspring:\n  application:\n    name: seata-order-service\n  cloud:\n    alibaba:\n      seata:\n        # 自定义事务组名称需要与seata-server中的对应，三个模块的组名应该相同\n        tx-service-group: my_tx_group\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n  datasource:\n    driver-class-name: com.mysql.jdbc.Driver\n    url: jdbc:mysql://localhost:3306/seata_order\n    username: root\n    password: 123456\n\nfeign:\n  hystrix:\n    enabled: false\n\nlogging:\n  level:\n    io:\n      seata: info\n\nmybatis:\n  mapperLocations: classpath:mapper/*.xml\n```\n\n### file.conf\n\n在 `resouces` 目录下创建 `file.conf` 配置事务组名和数据等信息（另外两个模块同样需要创建该文件）\n\n``` json\ntransport {\n  # tcp udt unix-domain-socket\n  type = \"TCP\"\n  #NIO NATIVE\n  server = \"NIO\"\n  #enable heartbeat\n  heartbeat = true\n  #thread factory for netty\n  thread-factory {\n    boss-thread-prefix = \"NettyBoss\"\n    worker-thread-prefix = \"NettyServerNIOWorker\"\n    server-executor-thread-prefix = \"NettyServerBizHandler\"\n    share-boss-worker = false\n    client-selector-thread-prefix = \"NettyClientSelector\"\n    client-selector-thread-size = 1\n    client-worker-thread-prefix = \"NettyClientWorkerThread\"\n    # netty boss thread size,will not be used for UDT\n    boss-thread-size = 1\n    #auto default pin or 8\n    worker-thread-size = 8\n  }\n  shutdown {\n    # when destroy server, wait seconds\n    wait = 3\n  }\n  serialization = \"seata\"\n  compressor = \"none\"\n}\n\nservice {\n  vgroup_mapping.my_tx_group = \"my_tx_group\"  # 修改自定义事务组名称\n  default.grouplist = \"127.0.0.1:8091\"\n  enableDegrade = false\n  disable = false\n  max.commit.retry.timeout = \"-1\"\n  max.rollback.retry.timeout = \"-1\"\n  disableGlobalTransaction = false\n}\n\n\nclient {\n  async.commit.buffer.limit = 10000\n  lock {\n    retry.internal = 10\n    retry.times = 30\n  }\n  report.retry.count = 5\n  tm.commit.retry.count = 1\n  tm.rollback.retry.count = 1\n}\n\n## transaction log store\nstore {\n  ## store mode: file、db\n  mode = \"db\"\n\n  ## file store\n  file {\n    dir = \"sessionStore\"\n\n    # branch session size , if exceeded first try compress lockkey, still exceeded throws exceptions\n    max-branch-session-size = 16384\n    # globe session size , if exceeded throws exceptions\n    max-global-session-size = 512\n    # file buffer size , if exceeded allocate new buffer\n    file-write-buffer-cache-size = 16384\n    # when recover batch read size\n    session.reload.read_size = 100\n    # async, sync\n    flush-disk-mode = async\n  }\n\n  ## database store\n  db {\n    ## the implement of javax.sql.DataSource, such as DruidDataSource(druid)/BasicDataSource(dbcp) etc.\n    datasource = \"dbcp\"\n    ## mysql/oracle/h2/oceanbase etc.\n    db-type = \"mysql\"\n    driver-class-name = \"com.mysql.jdbc.Driver\"\n    url = \"jdbc:mysql://127.0.0.1:3306/seata\"\n    user = \"root\"\n    password = \"123456\"\n    min-conn = 1\n    max-conn = 3\n    global.table = \"global_table\"\n    branch.table = \"branch_table\"\n    lock-table = \"lock_table\"\n    query-limit = 100\n  }\n}\nlock {\n  ## the lock store mode: local、remote\n  mode = \"remote\"\n\n  local {\n    ## store locks in user's database\n  }\n\n  remote {\n    ## store locks in the seata's server\n  }\n}\nrecovery {\n  #schedule committing retry period in milliseconds\n  committing-retry-period = 1000\n  #schedule asyn committing retry period in milliseconds\n  asyn-committing-retry-period = 1000\n  #schedule rollbacking retry period in milliseconds\n  rollbacking-retry-period = 1000\n  #schedule timeout retry period in milliseconds\n  timeout-retry-period = 1000\n}\n\ntransaction {\n  undo.data.validation = true\n  undo.log.serialization = \"jackson\"\n  undo.log.save.days = 7\n  #schedule delete expired undo_log in milliseconds\n  undo.log.delete.period = 86400000\n  undo.log.table = \"undo_log\"\n}\n\n## metrics settings\nmetrics {\n  enabled = false\n  registry-type = \"compact\"\n  # multi exporters use comma divided\n  exporter-list = \"prometheus\"\n  exporter-prometheus-port = 9898\n}\n\nsupport {\n  ## spring\n  spring {\n    # auto proxy the DataSource bean\n    datasource.autoproxy = false\n  }\n}\n```\n\n配置解读：\n\n- `transport`：与TC交互的一些配置\n  - `heartbeat`：client和server通信心跳检测开关\n  - `enableClientBatchSendRequest`：客户端事务消息请求是否批量合并发送\n- `service`：TC的地址配置，用于获取TC的地址\n  - `vgroup_mapping.test_tx_group = \"my_tx_group\"`：\n    - `test_tx_group`：是事务组名称，要与`application.yml`中配置一致，\n    - `seata_tc_server`：是TC服务端在注册中心的id，将来通过注册中心获取TC地址\n    - `enableDegrade`：服务降级开关，默认关闭。如果开启，当业务重试多次失败后会放弃全局事务\n    - `disableGlobalTransaction`：全局事务开关，默认false。false为开启，true为关闭\n  - `default.grouplist`：这个当注册中心为file的时候，才用到\n- `client`：客户端配置\n  - `rm`：资源管理器配\n    - `asynCommitBufferLimit`：二阶段提交默认是异步执行，这里指定异步队列的大小\n    - `lock`：全局锁配置\n      - `retryInterval`：校验或占用全局锁重试间隔，默认10，单位毫秒\n      - `retryTimes`：校验或占用全局锁重试次数，默认30次\n      - `retryPolicyBranchRollbackOnConflict`：分支事务与其它全局回滚事务冲突时锁策略，默认true，优先释放本地锁让回滚成功\n    - `reportRetryCount`：一阶段结果上报TC失败后重试次数，默认5次\n  - `tm`：事务管理器配置\n    - `commitRetryCount`：一阶段全局提交结果上报TC重试次数，默认1\n    - `rollbackRetryCount`：一阶段全局回滚结果上报TC重试次数，默认1\n  - `undo`：undo_log的配置\n    - `dataValidation`：是否开启二阶段回滚镜像校验，默认true\n    - `logSerialization`：undo序列化方式，默认Jackson\n    - `logTable`：自定义undo表名，默认是`undo_log`\n  - `log`：日志配置\n    - `exceptionRate`：出现回滚异常时的日志记录频率，默认100，百分之一概率。回滚失败基本是脏数据，无需输出堆栈占用硬盘空间\n\n### registry.conf\n\n在 `resouces` 目录下创建 `registry.conf` 配置注册中心和配置中心信息（另外两个模块同样需要创建该文件）\n\n``` json\nregistry {\n  # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa\n  type = \"nacos\"\n\n  nacos {\n    serverAddr = \"localhost:8848\"\n    namespace = \"\"\n    cluster = \"default\"\n  }\n  eureka {\n    serviceUrl = \"http://localhost:8761/eureka\"\n    application = \"default\"\n    weight = \"1\"\n  }\n  redis {\n    serverAddr = \"localhost:6379\"\n    db = \"0\"\n  }\n  zk {\n    cluster = \"default\"\n    serverAddr = \"127.0.0.1:2181\"\n    session.timeout = 6000\n    connect.timeout = 2000\n  }\n  consul {\n    cluster = \"default\"\n    serverAddr = \"127.0.0.1:8500\"\n  }\n  etcd3 {\n    cluster = \"default\"\n    serverAddr = \"http://localhost:2379\"\n  }\n  sofa {\n    serverAddr = \"127.0.0.1:9603\"\n    application = \"default\"\n    region = \"DEFAULT_ZONE\"\n    datacenter = \"DefaultDataCenter\"\n    cluster = \"default\"\n    group = \"SEATA_GROUP\"\n    addressWaitTime = \"3000\"\n  }\n  file {\n    name = \"file.conf\"\n  }\n}\n\nconfig {\n  # file、nacos 、apollo、zk、consul、etcd3\n  type = \"nacos\"\n\n  nacos {\n    serverAddr = \"localhost:8848\"\n    namespace = \"\"\n  }\n  consul {\n    serverAddr = \"127.0.0.1:8500\"\n  }\n  apollo {\n    app.id = \"seata-server\"\n    apollo.meta = \"http://192.168.1.204:8801\"\n  }\n  zk {\n    serverAddr = \"127.0.0.1:2181\"\n    session.timeout = 6000\n    connect.timeout = 2000\n  }\n  etcd3 {\n    serverAddr = \"http://localhost:2379\"\n  }\n  file {\n    name = \"file.conf\"\n  }\n}\n```\n\n### 业务代码\n\ndomain：\n\n``` java\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class CommonResult<T> {\n    private Integer code;\n    private String  message;\n    private T       data;\n\n    public CommonResult(Integer code, String message) {\n        this(code,message,null);\n    }\n}\n```\n\n``` java\npackage com.atguigu.springcloud.alibaba.domain;\n\nimport lombok.AllArgsConstructor;\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\nimport java.math.BigDecimal;\n\n@Data\n@AllArgsConstructor\n@NoArgsConstructor\npublic class Order {\n    private Long id;\n\n    private Long userId;\n\n    private Long productId;\n\n    private Integer count;\n\n    private BigDecimal money;\n\n    private Integer status; //订单状态：0：创建中；1：已完结\n}\n```\n\nDao接口及实现：\n\n``` java\nimport com.atguigu.springcloud.alibaba.domain.Order;\nimport org.apache.ibatis.annotations.Mapper;\nimport org.apache.ibatis.annotations.Param;\n\n@Mapper\npublic interface OrderDao {\n    //1 新建订单\n    void create(Order order);\n\n    //2 修改订单状态，从零改为1\n    void update(@Param(\"userId\") Long userId,@Param(\"status\") Integer status);\n}\n```\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" >\n\n<mapper namespace=\"com.atguigu.springcloud.alibaba.dao.OrderDao\">\n\n    <resultMap id=\"BaseResultMap\" type=\"com.atguigu.springcloud.alibaba.domain.Order\">\n        <id column=\"id\" property=\"id\" jdbcType=\"BIGINT\"/>\n        <result column=\"user_id\" property=\"userId\" jdbcType=\"BIGINT\"/>\n        <result column=\"product_id\" property=\"productId\" jdbcType=\"BIGINT\"/>\n        <result column=\"count\" property=\"count\" jdbcType=\"INTEGER\"/>\n        <result column=\"money\" property=\"money\" jdbcType=\"DECIMAL\"/>\n        <result column=\"status\" property=\"status\" jdbcType=\"INTEGER\"/>\n    </resultMap>\n\n    <insert id=\"create\">\n        insert into t_order (id,user_id,product_id,count,money,status)\n        values (null,#{userId},#{productId},#{count},#{money},0);\n    </insert>\n    \n    <update id=\"update\">\n        update t_order set status = 1\n        where user_id=#{userId} and status = #{status};\n    </update>\n\n</mapper>\n```\n\nService接口及实现：\n\n- OrderService\n  - OrderServiceImpl\n- StorageService\n- AccountService\n\n``` java\nimport com.atguigu.springcloud.alibaba.domain.Order;\n\npublic interface OrderService {\n    void create(Order order);\n}\n```\n\nStorageService 接口和 AccountService 接口标注 `@FeignClient` 注解，开启远程调用与负载均衡\n\n\n``` java\nimport com.atguigu.springcloud.alibaba.domain.CommonResult;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\n\nimport java.math.BigDecimal;\n\n@FeignClient(value = \"seata-storage-service\")\npublic interface StorageService {\n    @PostMapping(value = \"/storage/decrease\")\n    CommonResult decrease(@RequestParam(\"productId\") Long productId, @RequestParam(\"count\") Integer count);\n}\n```\n\n``` java\nimport com.atguigu.springcloud.alibaba.domain.CommonResult;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.PostMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\n\nimport java.math.BigDecimal;\n\n@FeignClient(value = \"seata-account-service\")\npublic interface AccountService {\n    @PostMapping(value = \"/account/decrease\")\n    CommonResult decrease(@RequestParam(\"userId\") Long userId, @RequestParam(\"money\") BigDecimal money);\n}\n```\n\n### @GlobalTransactional 注解\n\n订单微服务的 `OrderServiceImpl` 调用其他微服务，使用 **@GlobalTransactional** 注解开启 Seata 全局事务，表示当前方法内的业务全部处于同一个 Seata 全局事务中\n\n``` java\nimport com.atguigu.springcloud.alibaba.dao.OrderDao;\nimport com.atguigu.springcloud.alibaba.domain.Order;\nimport com.atguigu.springcloud.alibaba.service.AccountService;\nimport com.atguigu.springcloud.alibaba.service.OrderService;\nimport com.atguigu.springcloud.alibaba.service.StorageService;\nimport io.seata.spring.annotation.GlobalTransactional;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.stereotype.Service;\n\nimport javax.annotation.Resource;\n\n@Service\n@Slf4j\npublic class OrderServiceImpl implements OrderService\n{\n    @Resource\n    private OrderDao orderDao;\n    @Resource\n    private StorageService storageService;\n    @Resource\n    private AccountService accountService;\n\n    /**\n     * 创建订单->调用库存服务扣减库存->调用账户服务扣减账户余额->修改订单状态\n     * 简单说：下订单->扣库存->减余额->改状态\n     */\n    @Override\n    @GlobalTransactional(name = \"my-create-order\", rollbackFor = Exception.class)\n    public void create(Order order)\n    {\n        log.info(\"----->开始新建订单\");\n        //1 新建订单\n        orderDao.create(order);\n\n        //2 扣减库存\n        log.info(\"----->订单微服务开始调用库存，做扣减Count\");\n        storageService.decrease(order.getProductId(),order.getCount());\n        log.info(\"----->订单微服务开始调用库存，做扣减end\");\n\n        //3 扣减账户\n        log.info(\"----->订单微服务开始调用账户，做扣减Money\");\n        accountService.decrease(order.getUserId(),order.getMoney());\n        log.info(\"----->订单微服务开始调用账户，做扣减end\");\n\n        //4 修改订单状态，从零到1,1代表已经完成\n        log.info(\"----->修改订单状态开始\");\n        orderDao.update(order.getUserId(),0);\n        log.info(\"----->修改订单状态结束\");\n\n        log.info(\"----->下订单结束了，O(∩_∩)O哈哈~\");\n    }\n}\n```\n\n### 代理 DataSource\n\nSeata 的二阶段执行是通过拦截sql语句，分析语义来指定回滚策略，因此需要对`DataSource`做代理。在项目中添加一个配置类：\n\n```java\npackage com.zhao.order.config;\n\nimport com.baomidou.mybatisplus.extension.spring.MybatisSqlSessionFactoryBean;\nimport io.seata.rm.datasource.DataSourceProxy;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\nimport javax.sql.DataSource;\n\n/**\n * 使用Seata对数据源进行代理\n */\n@Configuration\npublic class DataSourceProxyConfig {\n\n    @Value(\"${mybatis.mapperLocations}\")\n    private String mapperLocations;\n\n    @Bean\n    @ConfigurationProperties(prefix = \"spring.datasource\")\n    public DataSource druidDataSource() {\n        return new DruidDataSource();\n    }\n\n    @Bean\n    public DataSourceProxy dataSourceProxy(DataSource dataSource) {\n        return new DataSourceProxy(dataSource);\n    }\n\n    @Bean\n    public SqlSessionFactory sqlSessionFactoryBean(DataSource dataSource) throws Exception {\n        // 订单服务中引入了mybatis-plus，所以要使用特殊的SqlSessionFactoryBean\n        SqlSessionFactoryBean sqlSessionFactoryBean = new SqlSessionFactoryBean();\n        // 代理数据源\n        sqlSessionFactoryBean.setDataSource(new DataSourceProxy(dataSource));\n\n        // sqlSessionFactoryBean.setMapperLocations(new PathMatchingResourcePatternResolver().getResources(mapperLocations));\n        // sqlSessionFactoryBean.setTransactionFactory(new SpringManagedTransactionFactory());\n\n        // 生成SqlSessionFactory\n        return sqlSessionFactoryBean.getObject();\n    }\n}\n```\n\n这里的 `DataSourceProxy` 是 Seata 提供的代理类，用于代理原始数据源，进行拦截解析SQL语句等操作。\n\n### 主启动类\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\n\n@EnableDiscoveryClient\n@EnableFeignClients\n// 取消数据源的自动创建，而是使用自己定义的数据源配置 DataSourceProxyConfig\n@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)\npublic class SeataOrderMainApp2001 {\n\n    public static void main(String[] args) {\n        SpringApplication.run(SeataOrderMainApp2001.class, args);\n    }\n}\n```\n\n## 其他微服务模块\n\n另外两个微服务模块与订单模块配置相同，本文不再赘述。区别在于其他业务模块的事务注解可以使用`@Transactionnal`，而不是`@GlobalTransactional`，只有事务发起者TM才需要添加`@GlobalTransactional`。\n\n\n\n\n\n## 雪花算法\n\n未完待续....","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【分布式】分布式事务理论","url":"/2021/09/07/【分布式】分布式事务/","content":"\n## 分布式事务\n\n分布式事务，就是指不是在单个服务或单个数据库架构下，产生的事务：\n\n- 跨数据源的分布式事务\n- 跨服务的分布式事务\n- 综合情况\n\n### 1）跨数据源\n\n随着业务数据规模的快速发展，数据量越来越大，单库单表逐渐成为瓶颈。所以我们对数据库进行了水平拆分，将原单库单表拆分成数据库分片，于是就产生了跨数据库事务问题。\n\n![image-20200304201018438](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304201018438-1631008633494.png)\n\n### 2）跨服务\n\n在业务发展初期，“一块大饼”的单业务系统架构，能满足基本的业务需求。但是随着业务的快速发展，系统的访问量和业务复杂程度都在快速增长，单系统架构逐渐成为业务发展瓶颈，解决业务系统的高耦合、可伸缩问题的需求越来越强烈。\n\n如下图所示，按照面向服务（SOA）的架构的设计原则，将单业务系统拆分成多个业务系统，降低了各系统之间的耦合度，使不同的业务系统专注于自身业务，更有利于业务的发展和系统容量的伸缩。\n\n![image-20200304202639509](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304202639509-1631008633494.png)\n\n<!-- More -->\n\n### 3）分布式系统的数据一致性问题\n\n在数据库水平拆分、服务垂直拆分之后，一个业务操作通常要跨多个数据库、服务才能完成。在分布式网络环境下，我们无法保障所有服务、数据库都百分百可用，一定会出现部分服务、数据库执行成功，另一部分执行失败的问题。\n\n当出现部分业务操作成功、部分业务操作失败时，业务数据就会出现不一致。例如电商行业中比较常见的下单付款案例，包括下面几个行为：\n\n- 创建新订单\n- 扣减商品库存\n- 从用户账户余额扣除金额\n\n完成上面的操作需要访问三个不同的微服务和三个不同的数据库。\n\n![image-20200304204442839](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304204442839-1631008633494.png)\n\n在分布式环境下，肯定会出现部分操作成功、部分操作失败的问题，比如：订单生成了，库存也扣减了，但是用户账户的余额不足，这就造成数据不一致。订单的创建、库存的扣减、账户扣款在每一个服务和数据库内是一个本地事务，可以保证ACID原则。\n\n但是当我们把三件事情看做一个事情事，要满足保证“业务”的原子性，要么所有操作全部成功，要么全部失败，不允许出现部分成功部分失败的现象，这就是分布式系统下的事务了。\n\n此时ACID难以满足，这是分布式事务要解决的问题。为什么分布式系统下，事务的ACID原则难以满足？这得从**CAP定理**和**BASE理论**说起。\n\n## CAP 定理\n\n> 本小节内容摘自：[CAP 定理的含义](https://www.ruanyifeng.com/blog/2018/07/cap.html)\n\n什么是CAP定理呢？\n\n![image-20200304205842784](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304205842784-1631008633494.png) \n\n1998年，加州大学的计算机科学家 Eric Brewer 提出，分布式系统有三个指标。\n\n- **Consistency（一致性）**\n- **Availability（可用性）**\n- **Partition tolerance （分区容错性）**\n\n它们的第一个字母分别是 C、A、P。Eric Brewer 说，这三个指标**不可能同时做到**。这个结论就叫做 CAP 定理。\n\n由于当前的网络硬件肯定会出现延迟丢包等问题，所以**分区容忍性**是我们必须需要实现的。所以我们只能在**一致性**和**可用性**之间进行权衡，**没有**NoSQL系统能同时保证这三点。\n\n- CA：传统Oracle数据库\n- AP：大多数网站架构的选择\n- CP：Redis、Mongodb\n\n![img](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/aHR0cHM6Ly9naXRlZS5jb20vamFsbGVua3dvbmcvTGVhcm5SZWRpcy9yYXcvbWFzdGVyL2ltYWdlLzIwLnBuZw)\n\n### Partition tolerance \n\n先看 Partition tolerance，中文叫做\"分区容错\"。\n\n大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区（partition）。分**区容错的意思是，区间通信可能失败**。比如，一台服务器放在上海，另一台服务器放在北京，这就是两个区，它们之间可能因网络问题无法通信。如图：\n\n![image-20200304210120471](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304210120471-1631008633494.png) \n\n上图中，G1 和 G2 是两台跨区的服务器。G1 向 G2 发送一条消息，G2 可能无法收到。系统设计的时候，必须考虑到这种情况。\n\n一般来说，分布式系统，分区容错无法避免，因此可以认为 CAP 的 P 总是成立。根据CAP 定理，剩下的 C 和 A 无法同时做到。\n\n### Consistency\n\nConsistency 中文叫做\"一致性\"。意思是，**写操作之后的读操作，必须返回该值**。举例来说，某条记录是 v0，用户向 G1 发起一个写操作，将其改为 v1。\n\n![image-20200304210414309](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304210414309-1631008633494.png) \n\n接下来，用户的读操作就会得到 v1。这就叫一致性。\n\n![image-20200304210506575](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304210506575-1631008633494.png) \n\n问题是，用户有可能向 G2 发起读操作，由于 G2 的值没有发生变化，因此返回的是 v0。G1 和 G2 读操作的结果不一致，这就不满足一致性了。\n\n![image-20200304210521364](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304210521364-1631008633494.png)\n\n为了让 G2 也能变为 v1，就要在 G1 写操作的时候，让 G1 向 G2 发送一条消息，要求 G2 也改成 v1。\n\n![image-20200304210540168](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304210540168-1631008633494.png) \n\n这样的话，用户向 G2 发起读操作，也能得到 v1。\n\n![image-20200304210557117](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200304210557117-1631008633494.png) \n\n### Availability \n\n Availability 中文叫做\"可用性\"，意思是**只要收到用户的请求，服务器就必须给出回应（对和错不论）**。\n\n用户可以选择向 G1 或 G2 发起读操作。不管是哪台服务器，只要收到请求，就必须告诉用户，到底是 v0 还是 v1，否则就不满足可用性。\n\n### Consistency 和 Availability 的矛盾\n\n一致性和可用性，为什么不可能同时成立？答案很简单，因为可能通信失败（即出现分区容错）。\n\n- 如果保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，没有可用性不。\n- 如果保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。\n\n综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标。如果追求一致性，那么无法保证所有节点的可用性；如果追求所有节点的可用性，那就没法做到一致性。\n\n### 几点疑问\n\n- 怎样才能同时满足CA？除非是单点架构。\n- 何时要满足CP？对一致性要求高的场景。例如我们的Zookeeper就是这样的，在服务节点间数据同步时，服务对外不可用。\n- 何时满足AP？对可用性要求较高的场景。例如Eureka，必须保证注册中心随时可用，不然拉取不到服务就可能出问题。\n\n## BASE 理论\n\nBASE就是为了解决关系数据库强一致性而引起的可用性降低问题而提出的解决方案。它的思想是通过**让系统放松对某一时刻数据一致性的要求来换取系统整体伸缩性和性能上改观**。\n\nBASE是三个单词的缩写：\n\n- **Basically Available**（基本可用）：服务在等待同步的一小段时间内是不可用的，所以只是基本可用\n- **Soft state**（软状态）\n- **Eventually consistent**（最终一致性）：不是数据立刻一致，而是等一段时间后一致，最终结果是一致的即可\n\n我们解决分布式事务就是根据上述理论来实现。还以上面的下单减库存和扣款为例：\n\n订单服务、库存服务、用户服务及他们对应的数据库就是分布式应用中的三个部分。\n\n- **CP方式**：现在如果要满足事务的强一致性，就必须在订单服务数据库锁定的同时，对库存服务、用户服务数据资源同时锁定。等待三个服务业务全部处理完成，才可以释放资源。此时如果有其他请求想要操作被锁定的资源就会被阻塞，这样就是满足了CP。这就是强一致，弱可用\n- **AP方式**：三个服务的对应数据库各自独立执行自己的业务，执行本地事务，不要求互相锁定资源。但是这个中间状态下，我们去访问数据库，可能遇到数据不一致的情况，不过我们需要做一些后补措施，保证在经过一段时间后，数据最终满足一致性，例如高峰期视频的点击量等数据不需要强一致性，但要保证高可用。这就是高可用，但弱一致（最终一致）。\n\n由上面的两种思想，延伸出了很多的分布式事务解决方案：\n\n- **XA**\n- **TCC**\n- **可靠消息最终一致**\n- **AT**\n\n下文将逐一介绍这些解决方案。\n\n## XA\n\n分布式事务的解决手段之一，就是**二阶段提交协议**（2PC：Two-Phase Commit）\n\n1994 年，X/Open 组织（即现在的 Open Group ）定义了分布式事务处理的 DTP 模型。该模型包括这样几个角色：\n\n- **应用程序（ AP ）**：我们的微服务\n- **事务管理器（ TM ）**：全局事务管理者\n- **资源管理器（ RM ）**：一般是数据库\n- **通信资源管理器（ CRM ）**：是TM和RM间的**通信中间件**\n\n在该模型中，一个分布式事务（全局事务）可以被拆分成许多个本地事务，运行在不同的AP和RM上。每个本地事务的ACID很好实现，但是全局事务必须保证其中包含的每一个本地事务都能同时成功，若有一个本地事务失败，则所有其它事务都必须回滚。但问题是，本地事务处理过程中，并不知道其它事务的运行状态。因此，就需要通过CRM来通知各个本地事务，同步事务执行的状态。\n\n因此，各个本地事务的通信必须有统一的标准，否则不同数据库间就无法通信。**XA** 就是 X/Open DTP中通信中间件与TM间联系的**接口规范**，定义了用于通知事务开始、提交、终止、回滚等接口，各个数据库厂商都必须实现这些接口。\n\n## 二阶段提交\n\n> 参考：[漫话分布式系统共识协议: 2PC/3PC篇](https://zhuanlan.zhihu.com/p/35298019)\n\n**二阶提交协议**就是根据XA这一思想衍生出来的，将全局事务拆分为两个阶段来执行：\n\n- 阶段一：准备阶段，各个本地事务完成本地事务的准备工作。\n- 阶段二：执行阶段，各个本地事务根据上一阶段执行结果，进行提交或回滚。\n\n这个过程中需要一个协调者（coordinator），还有事务的参与者（voter）。\n\n### 正常情况\n\n![image-20200305141029973](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305141029973.png) \n\n- **投票阶段**：协调组询问各个事务参与者，是否可以执行事务。每个事务参与者执行事务，写入redo和undo日志，然后反馈事务执行成功的信息（`agree`）\n- **提交阶段**：协调组发现每个参与者都可以执行事务（`agree`），于是向各个事务参与者发出`commit`指令，各个事务参与者提交事务。\n\n### 异常情况\n\n当然，也有异常的时候：\n\n![image-20200305141318326](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305141318326.png) \n\n- **投票阶段**：协调组询问各个事务参与者，是否可以执行事务。每个事务参与者执行事务，写入redo和undo日志，然后反馈事务执行结果，但只要有一个参与者返回的是`Disagree`，则说明执行失败。\n- **提交阶段**：协调组发现有一个或多个参与者返回的是`Disagree`，认为执行失败。于是向各个事务参与者发出`abort`指令，各个事务参与者回滚事务。\n\n### 缺陷\n\n二阶段提交的问题：\n\n**1. 单点故障问题**\n\n2PC的缺点在于不能处理`fail-stop`形式的节点failure，即coordinator在提交阶段宕机时，voters不能得知其他事务到底是执行成功还是失败。比如下图这种情况：\n\n![image-20200305142812815](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305142812815.png) \n\n假设coordinator和voter3都在Commit这个阶段crash了, 而voter1和voter2没有收到commit消息. 这时候voter1和voter2就陷入了一个困境. 因为他们并不能判断现在是两个场景中的哪一种：\n\n- 上轮全票通过然后voter3第一个收到了commit的消息并在commit操作之后crash了\n- 上轮voter3反对所以干脆没有通过。\n\n**2. 阻塞问题**\n\n在准备阶段、提交阶段，每个事务参与者都会**锁定本地资源**，**并等待其它事务的执行结果**，阻塞时间较长，资源锁定时间太久，因此执行的效率就比较低了。\n\n面对二阶段提交的上述缺点，后来又演变出了三阶段提交，但是依然没有完全解决阻塞和资源锁定的问题，而且引入了一些新的问题，因此实际使用的场景较少。\n\n### 使用场景\n\n**对事务有强一致性要求**，对事务执行效率不敏感，并且不希望有太多代码侵入。\n\n## TCC\n\n> http://www.zhdba.com/mysqlops/2012/04/06/innodb-log1/\n\nTCC模式可以解决2PC中的资源锁定和阻塞问题，减少资源锁定时间。\n\n### 基本原理\n\n它本质是一种**补偿**的思路。事务运行过程包括三个方法：\n\n- **Try**：资源的检测和预留；\n- **Confirm**：执行的业务操作提交；要求 Try 成功 Confirm 一定要能成功；\n- **Cancel**：预留资源释放。\n\n执行分两个阶段：\n\n- **准备阶段（try）**：资源的检测和预留；\n- **执行阶段（confirm/cancel）**：根据上一步结果，判断下面的执行方法。如果上一步中所有事务参与者都成功，则这里执行confirm。反之，执行cancel\n\n![image-20200305155521612](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305155521612.png) \n\n粗看似乎与两阶段提交没什么区别，但其实差别很大：\n\n- try、confirm、cancel都是**独立的事务**，不受其它参与者的影响，**不会阻塞等待**\n- try、confirm、cancel由程序员在业务层编写，锁粒度有代码控制\n\n### 实例\n\n我们以之前的下单业务中的扣减余额为例来看下三个不同的方法要怎么编写，假设账户A原来余额是100，需要余额扣减30元。如图：\n\n![image-20200305155830732](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305155830732.png)\n\n一阶段（Try）：余额检查，并冻结用户部分金额，此阶段执行完毕，**事务已经提交**\n\n- 检查用户余额是否充足，如果充足，冻结部分余额\n- **在账户表中添加冻结金额字段**，值为30，余额不变\n\n二阶段：提交或补偿\n\n- **提交（Confirm）**：真正的扣款，把冻结金额从余额中扣除，冻结金额清空\n  - 修改冻结金额为0，修改余额为100-30 = 70元\n- **补偿（Cancel）**：释放之前冻结的金额，**并非回滚**\n  - 余额不变，修改账户冻结金额为0\n\n总结：一阶段不修改真实的字段，只修改添加的冻结金额字段；二阶段若提交则修改真实字段，清除冻结金额字段，若失败则只需清除冻结金额字段\n\n### 优点\n\nTCC执行的每一个阶段都会提交本地事务并释放锁，并**不需要等待其它事务的执行结果**。而如果其它事务执行失败，**最后不是回滚，而是执行补偿操作**。这样就**避免了资源的长期锁定和阻塞等待**，**执行效率比较高**，属于**性能比较好**的分布式事务方式。\n\n### 缺点\n\n- 代码侵入：需要**人为编写**代码实现try、confirm、cancel，代码侵入较多\n- 开发成本高：一个业务需要拆分成3个步骤，分别编写业务实现，业务编写比较复杂\n- 安全性考虑：cancel动作如果执行失败，资源就无法释放，需要引入重试机制，而重试可能导致重复执行，还要考虑重试时的幂等问题\n\n### 总结\n\n每个单独的事务是强一致，但**整体不是强一致**（因为一阶段中每个事务都会立即提交，不会等待其他的事务一起提交，这样如果其他的事务失败了就不是整体强一致，还需要再在二阶段**手动写补偿**的代码把一阶段提交的额外字段数据给补偿掉）\n\n### 使用场景\n\n- 对事务有一定的一致性要求（最终一致）\n- 对性能要求较高\n- 开发人员具备较高的编码能力和幂等处理经验\n\n## 可靠消息服务\n\n这种实现方式的思路，其实是源于ebay，其基本的设计思想是将远程分布式事务拆分成一系列的本地事务。\n\n### 基本原理\n\n一般分为事务的发起者A和事务的其它参与者B：\n\n- 事务发起者A执行本地事务\n- 事务发起者A通过**消息队列MQ**将需要执行的事务信息发送给事务参与者B\n- 事务参与者B接收到消息后执行本地事务，若失败则一直重试执行事务\n\n如图：\n\n![image-20200305181454125](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305181454125.png)\n\n这个过程有点像你去学校食堂吃饭：\n\n- 拿着钱去收银处，点一份红烧牛肉面，付钱\n- 收银处给你发一个小票，还有一个号牌，你别把票弄丢！\n- 你凭小票和号牌一定能领到一份红烧牛肉面，不管需要多久\n\n几个注意事项：\n\n- 事务发起者A必须确保本地事务成功后，消息一定发送成功\n- MQ必须保证消息正确投递和持久化保存\n- 事务参与者B必须确保消息**最终一定能消费**，**如果失败需要多次重试**，时效性可能比较差\n- 事务B执行失败，会一直重试，但**不会导致事务A回滚**\n\n那么问题来了，我们如何保证消息发送一定成功？如何保证消费者一定能收到消息？\n\n### 本地消息表\n\n为了避免消息发送失败或丢失，我们可以把消息持久化到数据库中。实现时有简化版本和解耦合版本两种方式。\n\n#### 简化版本\n\n原理图：\n\n![image-20200305183431211](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305183431211.png) \n\n- 事务发起者：\n  - 开启本地事务\n  - 执行事务相关业务\n  - 发送消息到MQ\n  - 把消息持久化到数据库，标记为已发送\n  - 提交本地事务\n\n- 事务接收者：\n  - 接收消息\n  - 开启本地事务\n  - 处理事务相关业务\n  - 修改数据库消息状态为已消费\n  - 提交本地事务\n\n- 额外的定时任务\n  - 定时扫描表中超时未消费消息，重新发送\n\n**优点**：与tcc相比，实现方式较为简单，开发成本低。\n\n**缺点：**\n\n- 数据一致性完全依赖于消息服务，因此消息服务必须是可靠的。\n- 需要处理被动业务方的幂等问题\n- 被动业务失败不会导致主动业务的回滚，而是重试被动的业务\n- **事务业务与消息发送业务耦合**、业务数据与消息表要在一起\n\n#### 独立消息服务\n\n为了解决上述问题，我们会引入一个独立的消息服务，来完成对消息的持久化、发送、确认、失败重试等一系列行为，大概的模型如下：\n\n![image-20200305200131083](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305200131083.png)\n\n一次消息发送的时序图：\n\n![image-20200305205430863](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305205430863.png)\n\n事务发起者A的基本执行步骤：\n\n- 开启本地事务\n- 通知消息服务，准备发送消息（消息服务将消息持久化，标记为准备发送）\n- 执行本地业务，\n  - 执行失败则终止，通知消息服务，取消发送（消息服务修改订单状态）\n  - 执行成功则继续，通知消息服务，确认发送（消息服务发送消息、修改订单状态）\n- 提交本地事务\n\n消息服务本身提供下面的接口：\n\n- 准备发送：把消息持久化到数据库，并标记状态为准备发送\n- 取消发送：把数据库消息状态修改为取消\n- 确认发送：把数据库消息状态修改为确认发送。尝试发送消息，成功后修改状态为已发送\n- 确认消费：消费者已经接收并处理消息，把数据库消息状态修改为已消费\n- 定时任务：定时扫描数据库中状态为确认发送的消息，然后询问对应的事务发起者，事务业务执行是否成功，结果：\n  - 业务执行成功：尝试发送消息，成功后修改状态为已发送\n  - 业务执行失败：把数据库消息状态修改为取消\n\n事务参与者B的基本步骤：\n\n- 接收消息\n- 开启本地事务\n- 执行业务\n- 通知消息服务，消息已经接收和处理\n- 提交事务\n\n**优点：** 解除了事务业务与消息相关业务的耦合\n\n**缺点：** 实现起来比较复杂\n\n### RocketMQ 事务消息\n\nRocketMQ本身自带了事务消息，可以保证消息的可靠性，原理其实就是**自带了本地消息表**，与上面的思路类似。\n\n\n### RabbitMQ 的消息确认\n\nRabbitMQ 确保消息不丢失的思路比较奇特，并没有使用传统的本地表，而是利用了消息的确认机制：\n\n- 生产者确认机制：确保消息从生产者到达MQ不会有问题\n  - 消息生产者发送消息到RabbitMQ时，可以设置一个异步的监听器，监听来自MQ的ACK\n  - MQ接收到消息后，会返回一个回执给生产者：\n    - 消息到达交换机后路由失败，会返回失败ACK\n    - 消息路由成功，持久化失败，会返回失败ACK\n    - 消息路由成功，持久化成功，会返回成功ACK\n  - 生产者提前编写好不同回执的处理方式\n    - **失败回执：等待一定时间后重新发送**\n    - 成功回执：记录日志等行为\n- 消费者确认机制：确保消息能够被消费者正确消费\n  - 消费者需要在监听队列的时候指定**手动ACK模式**\n  - RabbitMQ把消息投递给消费者后，会等待消费者ACK，**接收到ACK后才删除消息**，如果没有接收到ACK消息会一直保留在服务端，如果消费者断开连接或异常后，消息会投递给其它消费者。\n  - 消费者处理完消息，提交事务后，手动ACK。如果执行过程中抛出异常，则不会ACK，业务处理失败，等待下一条消息\n\n经过上面的两种确认机制，可以确保从消息生产者到消费者的消息安全，再结合生产者和消费者两端的本地事务，即可保证一个分布式事务的最终一致性。\n\n### 消息事务的优缺点\n\n总结上面的几种模型，消息事务的优缺点如下：\n\n- 优点：\n  - 业务相对简单，不需要编写三个阶段业务\n  - 是多个本地事务的结合，因此资源锁定周期短，性能好\n- 缺点：\n  - 代码侵入\n  - 依赖于MQ的可靠性\n  - 消息发起者可以回滚，但是消息参与者无法引起事务回滚\n  - 事务时效性差，取决于MQ消息发送是否及时，还有消息参与者的执行情况\n\n## AT 模式\n\n> Seata [官方文档](https://seata.io/zh-cn/docs/dev/mode/at-mode.html)。\n\n2019年 1 月份，Seata 开源了 AT 模式。AT 模式是一种**无侵入**的分布式事务解决方案。可以看做是**对TCC或者二阶段提交模型的一种优化**，解决了TCC模式中的代码侵入、编码复杂等问题。\n\n在 AT 模式下，用户只需关注自己的“业务 SQL”，用户的 “业务 SQL” 作为一阶段，Seata 框架**会自动生成事务的二阶段提交和回滚操作**。\n\n### 基本原理\n\n流程图：\n\n![image-20200305212340203](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305212340203.png)\n\n有没有感觉跟TCC的执行很像，都是分两个阶段：\n\n- 一阶段：执行本地事务，并返回执行结果\n- 二阶段：根据一阶段的结果，判断二阶段做法是提交还是回滚\n\n但AT模式底层做的事情可完全不同，而且第二阶段**根本不需要我们编写，全部有Seata自己实现了**。也就是说：我们写的**代码与本地事务时代码一样**，无需手动处理分布式事务。\n\n那么，AT模式如何实现无代码侵入，如何帮我们自动实现二阶段代码的呢？\n\n### 一阶段\n\n在一阶段，Seata 会**拦截“业务 SQL”**：\n\n- 首先解析 SQL 语义，根据SQL语义找到“业务 SQL”要更新的业务数据，在业务数据被更新前，将这些要更新的数据保存成“**before image**”（前镜像，undo log，用于二阶段回滚时恢复原数据）\n- 然后执行“业务 SQL”更新业务数据，在业务数据更新之后，再将这些更新后的数据保存成“**after image**”（后镜像，redo log，其用于二阶段回滚前对比当前数据有无被脏写）\n- 将**前后镜像**数据以及**业务 SQL 相关的信息**组成一条回滚日志记录，插入到 `UNDO_LOG` 表中（数据库中除了业务表还需要准备一张 `UNDO_LOG` 表存放这些回滚日志，用于回滚时利用记录的SQL语句与前镜像进行回滚补偿）。\n- 最后获取全局行锁，**立即提交事务（不阻塞）**。\n\n以上操作全部**在一个数据库事务内完成**，这样保证了一阶段操作的**原子性**。这里的`before image`和`after image`类似于数据库的**undo**和**redo**日志，但其实**是用数据库模拟的**，即将undo和redo日志保存到日志Log表里。\n\n![image-20200305213652558](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305213652558.png)\n\n### 二阶段 提交\n\n二阶段如果是提交的话，因为“业务 SQL”在一阶段已经提交至数据库， 所以 Seata 框架只需将一阶段**保存的快照数据和行锁删掉，完成数据清理即可**。\n\n### 二阶段 回滚\n\n二阶段如果是回滚的话，Seata 就需要回滚一阶段已经执行的“业务 SQL”，还原业务数据。回滚方式便是用“**before image**”还原业务数据。\n\n但在还原前要首先要校验脏写，对比“数据库当前业务数据”和 “**after image**”，**如果两份数据完全一致就说明没有脏写**，可以还原业务数据，如果不一致就说明有**脏写**，出现脏写就需要转人工处理。不过因为有**全局锁**机制，所以可以降低出现**脏写**的概率。\n\n![image-20200305214649845](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305214649845.png)\n\nAT 模式的一阶段、二阶段提交和回滚**均由 Seata 框架自动生成**，用户只需编写“业务 SQL”，便能轻松接入分布式事务，AT 模式是一种对业务**无任何侵入**的分布式事务解决方案。AT 模式的补偿等操作是框架**自动实现**，TCC 则需要**手动添加补偿代码**。\n\nAT 模式的详细工作机制见 [Seata 工作机制](#Seata-两个阶段具体工作流程)。\n\n### 优缺点\n\n优点：\n\n- 与2PC相比：每个分支事务都是独立提交，不互相等待，**减少了资源锁定和阻塞时间**\n- 与TCC相比：二阶段的执行操作全部**自动化生成**，**无代码侵入**，开发成本低\n\n缺点：\n\n- 与TCC相比，需要动态生成二阶段的反向补偿操作，**执行性能略低于TCC**\n\n### 几种模式对比\n\n- XA 二阶段：一阶段会有阻塞问题，必须等到所有事务都提交才能一起提交，每个事务都会阻塞等待其他事务\n- TCC：一阶段不阻塞，二阶段需要手动添加补偿代码，较繁琐\n- AT：一阶段不阻塞，每个事务执行完立即提交；二阶段框架自动实现补偿，性能略低于TCC\n\n## Saga 模式\n\nSaga 模式是 Seata 即将开源的长事务解决方案，将由蚂蚁金服主要贡献。其理论基础是Hector & Kenneth  在1987年发表的论文[Sagas](https://microservices.io/patterns/data/saga.html)。\n\nSeata 官网对于Saga的指南：https://seata.io/zh-cn/docs/user/saga.html\n\n### 基本模型\n\n在 Saga 模式下，分布式事务内有多个参与者，每一个参与者都是一个冲正补偿服务，需要用户根据业务场景实现其正向操作和逆向回滚操作。\n\n分布式事务执行过程中，依次执行各参与者的正向操作，如果所有正向操作均执行成功，那么分布式事务提交。如果任何一个正向操作执行失败，那么分布式事务会去退回去执行前面各参与者的逆向回滚操作，回滚已提交的参与者，使分布式事务回到初始状态。\n\n![Saga 模式](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/1561965208439-606129fe-6761-4177-8887-1fda9306f104.png) \n\nSaga 模式下分布式事务通常是由事件驱动的，各个参与者之间是异步执行的，Saga 模式是一种长事务解决方案。\n\n### 适用场景：\n\n- 业务流程长、业务流程多\n- 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口\n\n### 优点\n\n- 一阶段提交本地事务，无锁，高性能\n- 事件驱动架构，参与者可异步执行，高吞吐\n- 补偿服务易于实现\n\n### 缺点\n\n不保证隔离性（应对方案见[用户文档](https://seata.io/zh-cn/docs/user/saga.html)）\n\n## Seata\n\n### 介绍\n\n> Seata：[https://](https://github.com/seata/seata)[github.com/seata/seata](https://github.com/seata/seata)\n\nSeata（Simple Extensible Autonomous Transaction Architecture，简单可扩展自治事务框架）是 2019 年 1 月份蚂蚁金服和阿里巴巴共同开源的分布式事务解决方案。Seata 开源半年左右，目前已经有接近一万 star，社区非常活跃。\n\n![Seata](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/1561960344792-8810110b-1eda-4417-944e-7051ca52f90d.png)\n\nSeata 会有 4 种分布式事务解决方案，分别是 AT 模式、TCC 模式、Saga 模式和 XA 模式：\n\n![image-20200305230513415](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305230513415.png)\n\nSeata中比较常用的是**AT模式**。下面将介绍其工作原理。\n\n### Seata 产品模块\n\n如下图所示，Seata 中有三大模块，分别是 **TM**、**RM** 和 **TC**。 **其中 TM 和 RM 是作为 Seata 的客户端与业务系统集成在一起（集成在业务代码中）**，**TC 作为 Seata 的服务端独立部署，并被注册到注册中心和配置中心**。\n\n![image-20200305225811888](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305225811888-1631068234111.png)\n\n### Seata 详细架构和流程\n\nSeata 中的几个基本概念：\n\n- **TC（Transaction Coordinator）** ：事务协调者，维护全局和分支事务的状态，驱动全局事务提交或回滚（TM之间的协调者），**TC作为Seata的服务端 Seata-Serve，下载后直接使用jar包运行，其将被注册到注册中心和配置中心从而被各个微服务订阅**。\n- **TM（Transaction Manager）** ：事务管理器，定义全局事务的范围：开始全局事务、提交或回滚全局事务。TM对应的方法使用 **@GlobalTransactional** 注解标注，其内的业务代码处于同一个全局事务下。\n- **RM（Resource Manager）** ：资源管理器，管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。\n\n![image-20200305225811888](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/image-20200305225811888.png)\n\n![img](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/302377d33ddcd708e20b996bd9f2c7b8.png)\n\n**三者工作分工**：\n\n- TM：业务模块中全局事务的开启者\n  - 向TC开启一个全局事务（标注 **@GlobalTransactionnal** 注解代表开启一个全局事务）\n  - 全局事务创建成功并生成一个全局唯一的`XID`，`XID`在微服务调用链路的上下文中传播；\n  - 调用其它微服务（例如订单模块作为TM调用了库存模块和支付模块）\n  - TM向TC发起针对`XID`的**全局提交或回滚决议**\n- RM：业务模块执行者中包含RM部分，负责**向TC汇报事务执行状态**\n  - 负责与数据库交互，执行本地事务\n  - **向TC注册分支事务**，并提交本地事务执行结果\n  - 将其纳入XID对应全局事务的管辖\n- TM：结束对微服务的调用，**通知TC全局事务执行完毕，事务一阶段结束**\n- TC：**汇总各个分支事务执行结果，决定分布式事务是提交还是回滚**，通知所有 RM提交/回滚资源，事务二阶段结束。\n\n**三者的关系**：\n\n- TM用于开启全局事务生成`XID`，调用其他微服务，并在全局事务的方法执行完毕后通知TC全局事务执行完毕（即一阶段结束），此时TC即可统计各个分支事务的执行结果判断二阶段应该是提交还是回滚；\n- 每个RM与本地数据库交互，执行本地事务并立即提交（不阻塞），之后向TC注册当前分支事务的信息，最后将本地事务提交的结果上报给 TC；\n- TC调度`XID`下管辖的全部分支事务完成提交或回滚请求。其先保存每个RM注册的分支事务信息，当收到TM的一阶段结束通知后，根据接收汇总到的各个分支事务的执行结果判断二阶段应该是提交还是回滚：若都成功，则通知每个RM二阶段提交；若有失败，则通知每个RM二阶段回滚\n\n### Seata 两个阶段具体工作流程\n\n![img](/images/%E3%80%90%E5%88%86%E5%B8%83%E5%BC%8F%E3%80%91%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/302377d33ddcd708e20b996bd9f2c7b8.png)\n\n**一阶段**：\n\n- TM开启全局事务，并向TC声明全局事务，包括全局事务`XID`信息\n- TM所在服务调用其它微服务\n- 微服务主要由RM来执行\n  - 查询`before_image`\n  - 执行本地事务\n  - 查询`after_image`\n  - 生成`undo_log`并写入数据库\n  - 向TC注册分支事务，告知事务执行结果\n  - 获取全局锁（阻止其它全局事务并发修改当前数据）\n  - 释放本地锁（不影响其它业务对数据的操作）\n- 待所有业务执行完毕，事务发起者（TM）会尝试向TC提交全局事务\n\n**二阶段**：\n\n- TC统计分支事务执行情况，根据结果判断下一步行为：\n  - 分支都成功：通知分支事务，提交事务\n  - 有分支执行失败：通知执行成功的分支事务，回滚数据\n- 分支事务的RM收到TC传来的消息：\n  - 提交事务：直接清空`before_image`和`after_image`信息，释放全局锁\n  - 回滚事务：\n    - 校验`after_image`，判断是否有脏写\n    - 如果没有脏写，回滚数据到`before_image`，清除`before_image`和`after_image`\n    - 如果有脏写，请求人工介入\n\n### Seata 工作流程示例\n\n详见Seata的官方文档：https://seata.io/zh-cn/docs/overview/what-is-seata.html\n\n> #### 场景\n\n以一个示例来说明 AT 分支的整个工作过程。\n\n业务表：`product`\n\n| Field | Type         | Key  |\n| ----- | ------------ | ---- |\n| id    | bigint(20)   | PRI  |\n| name  | varchar(100) |      |\n| since | varchar(100) |      |\n\nAT 分支事务的业务逻辑：\n\n```sql\nupdate product set name = 'GTS' where name = 'TXC';\n```\n\n> #### 一阶段\n\n过程：\n\n1. **解析 SQL**：得到 SQL 的类型（UPDATE），表（product），条件（where name = 'TXC'）等相关的信息。\n2. **查询 before image（前镜像）**：根据解析得到的条件信息，生成查询语句，定位数据（即修改前先查询出来当前这，保存到undo log）。\n\n```sql\nselect id, name, since from product where name = 'TXC';\n```\n\n得到前镜像：\n\n| id   | name | since |\n| ---- | ---- | ----- |\n| 1    | TXC  | 2014  |\n\n3. **执行业务 SQL**：更新这条记录的 name 为 'GTS'。\n4. **查询 after image（后镜像）**：根据前镜像的结果，通过 **主键（id）** 定位数据。\n\n```sql\nselect id, name, since from product where id = `1`;\n```\n\n得到后镜像：\n\n| id   | name | since |\n| ---- | ---- | ----- |\n| 1    | GTS  | 2014  |\n\n5. **插入回滚日志**：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 `UNDO_LOG` 表中：\n\n```json\n{\n    \"branchId\": 641789253,\n    \"undoItems\": [{\n        \"afterImage\": {\n            \"rows\": [{\n                \"fields\": [{\n                    \"name\": \"id\",\n                    \"type\": 4,\n                    \"value\": 1\n                }, {\n                    \"name\": \"name\",\n                    \"type\": 12,\n                    \"value\": \"GTS\"\n                }, {\n                    \"name\": \"since\",\n                    \"type\": 12,\n                    \"value\": \"2014\"\n                }]\n            }],\n            \"tableName\": \"product\"\n        },\n        \"beforeImage\": {\n            \"rows\": [{\n                \"fields\": [{\n                    \"name\": \"id\",\n                    \"type\": 4,\n                    \"value\": 1\n                }, {\n                    \"name\": \"name\",\n                    \"type\": 12,\n                    \"value\": \"TXC\"\n                }, {\n                    \"name\": \"since\",\n                    \"type\": 12,\n                    \"value\": \"2014\"\n                }]\n            }],\n            \"tableName\": \"product\"\n        },\n        \"sqlType\": \"UPDATE\"\n    }],\n    \"xid\": \"xid:xxx\"\n}\n```\n\n6. **提交前，向 TC 注册分支**：申请 `product` 表中，主键值等于 1 的记录的 **全局锁** 。\n7. **本地事务提交**：业务数据的更新和前面步骤中生成的 `UNDO LOG` 一并提交。\n8. **将本地事务提交的结果上报给 TC**。\n\n> #### 二阶段-回滚\n\n若收到 TC 的**分支回滚**请求，开启一个本地事务，执行如下操作：\n\n1. 通过 `XID` 和 `Branch ID` 查找到相应的 `UNDO LOG` 记录（同一个微服务可能同时参与多个不同的事务组，有多个 `XID`）。\n2. **数据校验**：拿 `UNDO LOG` 中的后镜像与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理。\n3. 根据 `UNDO LOG` 中的**前镜像**和**业务 SQL 的相关信息**生成并执行回滚的语句：\n\n```sql\nupdate product set name = 'TXC' where id = 1;\n```\n\n4. **提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC**。\n\n> #### 二阶段-提交\n\n1. 收到 TC 的**分支提交**请求，把请求放入一个**异步任务的队列**中，**马上返回提交成功**的结果给 TC。\n2. 异步任务阶段的分支提交请求将**异步和批量地删除相应 `UNDO LOG` 记录**。\n\n以上即为 Seata 框架的工作原理，关于 Seata 框架的使用见文章 [【Spring Cloud】Spring Cloud Alibaba Nacos](https://yuyun-zhao.github.io/2021/09/08/%E3%80%90SpringCloud%E3%80%91Seata/) \n\n","tags":["分布式"],"categories":["分布式"]},{"title":"【Spring Cloud】Spring Cloud Alibaba Sentinel","url":"/2021/09/06/【SpringCloud】Sentinel/","content":"\n## Sentinel 简介\n\n> [官方Github](https://github.com/alibaba/Sentinel)、[官方文档](https://sentinelguard.io/zh-cn/docs/introduction.html)\n\n随着微服务的流行，服务和服务之间的稳定性变得越来越重要。Sentinel 以流量为切入点，从**流量控制**、**熔断降级**、**系统负载保护**等多个维度保护服务的稳定性。Sentinel 具有以下特征：\n\n- **丰富的应用场景**：Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、集群流量控制、实时熔断下游不可用应用等。\n- **完备的实时监控**：Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。\n- **广泛的开源生态**：Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。\n- **完善的 SPI 扩展点**：Sentinel 提供简单易用、完善的 SPI 扩展接口。您可以通过实现扩展接口来快速地定制逻辑。例如定制规则管理、适配动态数据源等。\n\nSentinel 的主要特性：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/e4efa9c3547366ae4f747ad4007f6447.png)\n\n<!-- More -->\n\nHystrix 与 Sentinel 比较：\n\n- Hystrix（[【Spring Cloud】Hystrix](https://yuyun-zhao.github.io/2021/08/30/%E3%80%90SpringCloud%E3%80%91Hystrix/)）\n  1. 需要我们程序员自己手工搭建监控平台\n  2. 没有一套web界面可以给我们进行更加细粒度化得配置流控、速率控制、服务熔断、服务降级\n- Sentinel\n  1. 单独一个组件，可以独立出来。\n  2. 直接界面化的细粒度统一配置。\n\n> sentinel\n> 英 [ˈsentɪnl] 美 [ˈsentɪnl]\n> n. 哨兵\n\n服务使用中的各种问题：\n\n- 服务雪崩\n- 服务降级\n- 服务熔断\n- 服务限流\n\nSentinel 分为两个部分：\n\n- 核心库（Java 客户端）不依赖任何框架/库，能够运行于所有 Java 运行时环境，同时对 Dubbo / Spring Cloud 等框架也有较好的支持。\n- 控制台（Dashboard）基于 Spring Boot 开发，打包后可以直接运行，不需要额外的 Tomcat 等应用容器。\n\n## 服务熔断框架对比\n\n![image-20210907152331967](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907152331967.png)\n\n## Sentinel 下载安装运行\n\n> [官方文档](https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_spring_cloud_alibaba_sentinel)\n\n下载地址：https://github.com/alibaba/Sentinel/release\n\n安装步骤：\n\n- 下载到本地 `sentinel-dashboard-1.7.0.jar`\n- 运行命令 `java -jar sentinel-dashboard-1.7.0.jar`\n\n前提：\n\n- Java 8 环境\n- 8080端口不能被占用\n\n进入Sentinel管理界面方式：访问 http://localhost:8080，登录账号密码均为sentinel\n\n![image-20210907110649244](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907110649244.png)\n\n## Sentinel 实时监控\n\n1. 启动Nacos服务中心（见文章[【Spring Cloud】Spring Cloud Alibaba Nacos](https://yuyun-zhao.github.io/2021/09/05/%E3%80%90SpringCloud%E3%80%91Nacos/#spring-cloud-alibaba-%E7%AE%80%E4%BB%8B)）\n2. 新建Module：`cloudalibaba-sentinel-service8401`\n3. 导入Maven依赖：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloudalibaba-sentinel-service8401</artifactId>\n\n    <dependencies>\n        <dependency><!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n            <groupId>com.zhao.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n        <!--SpringCloud ailibaba nacos -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到-->\n        <dependency>\n            <groupId>com.alibaba.csp</groupId>\n            <artifactId>sentinel-datasource-nacos</artifactId>\n        </dependency>\n        <!--SpringCloud ailibaba sentinel -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-sentinel</artifactId>\n        </dependency>\n        <!--openfeign-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\n        </dependency>\n        <!-- SpringBoot整合Web组件+actuator -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--日常通用jar包配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>cn.hutool</groupId>\n            <artifactId>hutool-all</artifactId>\n            <version>4.6.3</version>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n4. 配置文件：\n\n``` yaml\nserver:\n  port: 8401\n\nspring:\n  application:\n    name: cloudalibaba-sentinel-service\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 # Nacos服务注册中心地址\n    sentinel:\n      transport:\n        dashboard: localhost:8080  # 配置Sentinel dashboard地址\n        port: 8719  # sentinel 会启动一个 httpServer 与 dashboard 通讯，其端口号为8719\n\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: '*'\n\nfeign:\n  sentinel:\n    enabled: true  # 激活Sentinel对Feign的支持\n```\n\n5. 主启动类：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@EnableDiscoveryClient\n@SpringBootApplication\npublic class MainApp8401 {\n    public static void main(String[] args) {\n        SpringApplication.run(MainApp8401.class, args);\n    }\n}\n```\n\n6. 业务类 FlowLimitController：\n\n``` java\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RequestParam;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport java.util.concurrent.TimeUnit;\n\n@RestController\n@Slf4j\npublic class FlowLimitController {\n    @GetMapping(\"/testA\")\n    public String testA() {\n        return \"------testA\";\n    }\n\n    @GetMapping(\"/testB\")\n    public String testB() {\n        log.info(Thread.currentThread().getName()+\"\\t\"+\"...testB\");\n        return \"------testB\";\n    }\n}\n```\n\n7. 启动Sentinel Dashboard：`java -jar sentinel-dashboard-1.7.0.jar`\n8. 测试：发出请求 http://localhost:8401/testA 后，可在Sentinel Dashboard看到监控中的微服务8401\n\n## Sentinel 流控规则\n\n### 流控规则\n\n![image-20210907110723331](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907110723331.png)\n\n**Sentinel 流控：控制流量访问的规则，超出限制的流量禁止访问，从而达到限流的目的。**\n\n进一步解释说明：\n\n- 资源名：唯一名称，默认请求路径。\n- 针对来源：Sentinel可以针对调用者进行限流，填写微服务名，默认default（不区分来源）。\n- 阈值类型/单机阈值：\n  - QPS（每秒钟的请求数量）︰当调用该API的QPS达到阈值的时候，进行限流。\n  - 线程数：当调用该API的线程数达到阈值的时候，进行限流。\n- 是否集群：不需要集群。\n- 流控模式：\n  - **直接**：API达到限流条件时，直接限流。\n  - **关联**：当关联的资源达到阈值时，就限流自己。\n  - **链路**：只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流)【API级别的针对来源】。\n- 流控效果：\n  - **快速失败**：直接失败，抛异常。\n  - **Warm up**：根据Code Factor（冷加载因子，默认3）的值，从阈值/codeFactor，经过预热时长，才达到设置的QPS阈值。\n  - **排队等待**：匀速排队，让请求以匀速的速度通过，阈值类型必须设置为QPS，否则无效。\n\n### QPS 直接失败\n\nQPS（每秒钟的请求数量），系统默认为**直接 -> 快速失败**：\n\n![image-20210907114315762](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114315762.png)\n\n上图配置表示1秒钟内查询1次就是OK，若超过次数1，就直接->快速失败，报默认错误 `Blocked by Sentinel (flow limiting)`。\n\n### 线程数直接失败\n\n线程数：当调用该请求的线程数达到阈值的时候，进行限流。\n\n![image-20210907114210623](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114210623.png)\n\n### 关联\n\n关联模式下，当自己关联的资源达到阈值时，就限流自己。例如当与A关联的资源B达到阀值后，就限流A自己（B惹事，A挂了）\n\n### 链路\n\n只记录指定链路上的流量（指定资源从入口资源进来的流量，如果达到阈值，就进行限流）【API级别的针对来源】\n\n### 预热 Warm Up\n\nWarm Up（`RuleConstant.CONTROL_BEHAVIOR_WARM_UP`）方式，即预热/冷启动方式。当系统长期处于低水位的情况下，当流量突然增加时，直接把系统拉升到高水位可能瞬间把系统压垮。通过\"冷启动\"，让通过的流量缓慢增加，在一定时间内逐渐增加到阈值上限，给冷系统一个预热的时间，避免冷系统被压垮。详细文档可以参考[流量控制 - Warm Up 文档](https://github.com/alibaba/Sentinel/wiki/限流---冷启动)，具体的例子可以参见 WarmUpFlowDemo。\n\n通常冷启动的过程系统允许通过的 QPS 曲线如下图所示：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/ede9b7e029c54840e3b40b69c4f371b5.png)\n\n默认`coldFactor`为3，即请求QPS 从 `threshold / 3`开始，经预热时长逐渐升至设定的QPS阈值。\n\nWarmUp配置案例，阀值为10 + 预热时长设置5秒：\n\n系统初始化的阀值为 `10 / 3` 约等于3，即阀值刚开始为3。然后过了5秒后阀值才慢慢升高恢复到10：\n\n![image-20210907114251384](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114251384.png)\n\n**应用场景**\n\n如：秒杀系统在开启的瞬间，会有很多流量上来，很有可能把系统打死，预热方式就是把为了保护系统，可慢慢的把流量放进来,慢慢的把阀值增长到设置的阀值。\n\n### 排队等待\n\n匀速排队，让请求以均匀的速度通过，阀值类型必须设成QPS，否则无效。\n\n设置：`/testA`每秒1次请求，超过的话就**排队等待**，等待的超时时间为20000毫秒：\n\n![image-20210907114341372](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114341372.png)\n\n**匀速排队**\n\n匀速排队（RuleConstant.CONTROL_BEHAVIOR_RATE_LIMITER）方式会严格控制请求通过的间隔时间，也即是让请求以均匀的速度通过，对应的是漏桶算法。详细文档可以参考 [流量控制 - 匀速器模式](https://github.com/alibaba/Sentinel/wiki/流量控制-匀速排队模式)，具体的例子可以参见 PaceFlowDemo。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/79f93ab9f5dc11b05bbed9b793ef7c20.png)\n\n这种方式主要用于处理**间隔性突发**的流量，例如**消息队列**。想象一下这样的场景，在某一秒有大量的请求到来，而接下来的几秒则处于空闲状态，**我们希望系统能够在接下来的空闲期间逐渐处理这些请求，而不是在第一秒直接拒绝多余的请求。**\n\n**测试**：添加日志记录代码到`FlowLimitController`的`testA`方法\n\n``` java\n@RestController\n@Slf4j\npublic class FlowLimitController {\n    @GetMapping(\"/testA\")\n    public String testA() {\n        log.info(Thread.currentThread().getName()+\"\\t\"+\"...testA\");//<----\n        return \"------testA\";\n    }\n}\n```\n\nPostman模拟并发密集访问 `/testA`。后台显示：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/c89a2124391676992c8fabffdaf1a07c.png)\n\n###  @SentinelResource 服务限流配置\n\n**方式1：指定资源名**：\n\n在 Controller 上使用 **@SentinelResource** 注解修饰目标方法，并设置**资源名**：`value = \"byResource\"`，同时设置满足限流条件时的回调方法`blockHandler = \"handleException\"`：\n\n```java\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport com.zhao.springcloud.alibaba.myhandler.CustomerBlockHandler;\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class RateLimitController {\n    \n    @GetMapping(\"/byResource\")\n    @SentinelResource(value = \"byResource\", blockHandler = \"handleException\")\n    public CommonResult byResource() {\n        return new CommonResult(200,\"按资源名称限流测试OK\",new Payment(2020L,\"serial001\"));\n    }\n    \n    public CommonResult handleException(BlockException exception) {\n        return new CommonResult(444,exception.getClass().getCanonicalName()+\"\\t 服务不可用\");\n    }\n}\n```\n\n在控制台为该资源 `\"byResource\"` 设置流控规则，表示1秒钟内查询次数大于1，就跳转到`blockHandler`指定的`handleException()`方法：\n\n![image-20210907140018504](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907140018504.png)\n\n**方式2：指定URL**：\n\n```java\n@RestController\npublic class RateLimitController {\n    @GetMapping(\"/rateLimit/byUrl\")\n    @SentinelResource(value = \"byUrl\")\n    public CommonResult byUrl() {\n        return new CommonResult(200,\"按url限流测试OK\",new Payment(2020L,\"serial002\"));\n    }\n}\n```\n\n可以在流控规则中指定URL，这样符合该URL的请求在满足条件时都会调用自定义的方法：\n\n![image-20210907140935899](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907140935899.png)\n\n注意：`blockHandler` 只能处理限流和降级相关的异常 `BlockException`，若是业务本身出现异常则不会响应 `blockHandler`  指定的方法，此情况需要使用 `fallback` 属性。\n\n## Sentinel 服务降级规则\n\n### 熔断降级概述\n\n> [【Spring Cloud】Hystrix](https://yuyun-zhao.github.io/2021/08/30/%E3%80%90SpringCloud%E3%80%91Hystrix/)\n\n除了流量控制以外，对调用链路中不稳定的资源进行熔断降级也是保障高可用的重要措施之一。一个服务常常会调用别的模块，可能是另外的一个远程服务、数据库，或者第三方 API 等。例如，支付的时候，可能需要远程调用银联提供的 API；查询某个商品的价格，可能需要进行数据库查询。然而，这个被依赖服务的稳定性是不能保证的。如果依赖的服务出现了不稳定的情况，请求的响应时间变长，那么调用服务的方法的响应时间也会变长，线程会产生堆积，最终可能耗尽业务自身的线程池，服务本身也变得不可用。\n\n现代微服务架构都是分布式的，由非常多的服务组成。不同服务之间相互调用，组成复杂的调用链路。以上的问题在链路调用中会产生放大的效果。复杂链路上的某一环不稳定，就可能会层层级联，最终导致整个链路都不可用。因此我们需要对不稳定的弱依赖服务调用进行熔断降级，暂时切断不稳定调用，避免局部不稳定因素导致整体的雪崩。**熔断降级作为保护自身的手段，通常在客户端（调用端）进行配置。**\n\n**服务熔断和服务降级的区别：**\n\n- 服务降级是在服务执行的时候，出现超时或异常等情况中断执行，转去执行fallback里的代码\n- 服务熔断是在开启熔断机制后，服务不再尝试执行，而是直接进入fallback里的代码\n\n### Sentinel 服务降级规则\n\n![image-20210907114410767](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114410767.png)\n\n- **RT（平均响应时间，毫秒级）**\n  - 平均响应时间超出阈值且`QPS >= 5`（在1s时间窗口内通过的请求>=5），两个条件同时满足后触发降级\n  - 窗口期过后关闭断路器\n  - RT最大4900（更大的需要通过`-Dcsp.sentinel.statistic.max.rt=XXXX`才能生效）\n- **异常比列（秒级）**：`QPS >= 5`且异常比例（秒级统计）超过阈值时触发降级；时间窗口结束后，关闭降级 \n- **异常数（分钟级）**：异常数（分钟统计）超过阈值时，触发降级；时间窗口结束后，关闭降级\n\nSentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高)，对这个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。\n\n当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出 `DegradeException`）。\n\n1.7.0版本的 Sentinel 的断路器是没有类似Hystrix半开状态的(Sentinei 1.8.0 已有半开状态)。半开的状态系统自动去检测是否请求有异常，没有异常就关闭断路器恢复使用，有异常则继续打开断路器不可用。断路器的介绍见[【Spring Cloud】Hystrix](https://yuyun-zhao.github.io/2021/08/30/%E3%80%90SpringCloud%E3%80%91Hystrix/)。\n\n### Sentinel 降级策略 - RT\n\nSentinel 1.7.0 版本的**平均响应时间**（`DEGRADE_GRADE_RT`）：\n\nRT 平均响应时间（`DEGRADE_GRADE_RT`）：当1s内持续进入5个请求，对应时刻的平均响应时间均超过阈值（ count，以ms为单位），那么在接下的时间窗口（`DegradeRule`中的`timeWindow`，以s为单位）之内，对这个方法的调用都会自动地熔断（抛出`DegradeException`）。注意 Sentinel 默认统计的RT上限是4900 ms，超出此阈值的都会算作4900ms，若需要变更此上限可以通过启动配置项`-Dcsp.sentinel.statistic.max.rt=xxx`来配置。窗口期时间到了，自动结束熔断。\n\nSentinel 1.8.0 没有平均响应时间，取而代之的是**慢调用比例** (`SLOW_REQUEST_RATIO`)：\n\n慢调用比例 （`SLOW_REQUEST_RATIO`）：选择以慢调用比例作为阈值，需要设置允许的慢调用 RT（即最大的响应时间），请求的响应时间大于该值则统计为慢调用。当单位统计时长（`statIntervalMs`）内请求数目大于设置的最小请求数目，并且慢调用的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入**探测恢复状态**（`HALF-OPEN` 状态），**若接下来的一个请求响应时间小于设置的慢调用 RT 则结束熔断，若大于设置的慢调用 RT 则会再次被熔断**\n\nSentinel 1.7.0 版本平均响应时间示意图：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/dcf85d4362c017e543173c76b7dcc2a8.png)\n\n![image-20210907114444429](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114444429.png)\n\n如上配置时，若1s内请求数>=5，并且平均响应时间>200ms，则触发熔断，在1s的时间窗后结束熔断。\n\n### Sentinel 降级策略 - 异常比例\n\nSentinel 1.7.0 版本的异常比例：\n\n异常比例（`DEGRADE_GRADE_EXCEPTION_RATIO`）：当资源的每秒请求量 >= 5，并且每秒异常总数占通过量的比值超过阈值（ `DegradeRule`中的 `count`）之后，资源进入降级状态，即在接下的时间窗口( `DegradeRule`中的`timeWindow`，以s为单位）之内，对这个方法的调用都会自动地返回。异常比率的阈值范围是[0.0, 1.0]，代表0% -100%。\n\nSentinel 1.8.0 版本的异常比例：\n\n异常比例 （`ERROR_RATIO`）：当单位统计时长（`statIntervalMs`）内请求数目大于设置的最小请求数目，并且异常的比例大于阈值，则接下来的熔断时长内请求会自动被熔断。经过熔断时长后熔断器会进入**探测恢复状态**（`HALF-OPEN` 状态），**若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断**。异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。\n\nSentinel 1.7.0 版本异常比例示意图：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/b8f35b00fffd79ef68e8f744403b92f3.png)\n\n![image-20210907114507169](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114507169.png)\n\n如上配置时，若1s内请求数>=5且出现异常的请求数占比大于0.2时触发熔断，在1s的时间窗后结束熔断。\n\n### Sentinel 降级策略 - 异常数\n\nSentinel 1.7.0 版本的异常数：\n\n异常数（`DEGRADE_GRADF_EXCEPTION_COUNT` ）：当资源近1分钟的异常数目超过阈值之后会进行熔断。注意由于统计时间窗口是分钟级别的，若`timeWindow`小于60s，则结束熔断状态后码可能再进入熔断状态。**异常数是按照分钟统计的，时间窗口一定要大于等于60秒**。\n\nSentinel 1.8.0 版本的异常数：\n\n异常数（`ERROR_COUNT`）：当单位统计时长内的异常数目超过阈值之后会自动进行熔断。经过熔断时长后熔断器会进入探测恢复状态（`HALF-OPEN` 状态），若接下来的一个请求成功完成（没有错误）则结束熔断，否则会再次被熔断。\n\nSentinel 1.8.0 版本异常比例示意图：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/d92c6a9ae5ed514b52ddf43fdf0d5f0e.png)\n\n![image-20210907114521979](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114521979.png)\n\n如上配置时，若1s内请求数>=5且出现异常的请求数大于5时触发熔断，在61s的时间窗后结束熔断。（**异常数是按照分钟统计的，时间窗口一定要大于等于60秒**）\n\n###  @SentinelResource 服务降级配置\n\n**方式1：指定资源名**：\n\n在 Controller 上使用 **@SentinelResource** 注解修饰目标方法，并设置**资源名**：`value = \"byResource\"`，同时设置满足降级条件时的回调方法`blockHandler = \"handleException\"`：\n\n```java\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport com.zhao.springcloud.alibaba.myhandler.CustomerBlockHandler;\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class RateLimitController {\n    \n    @GetMapping(\"/byResource\")\n    @SentinelResource(value = \"byResource\", blockHandler = \"handleException\")\n    public CommonResult byResource() {\n        return new CommonResult(200,\"按资源名称降级测试OK\",new Payment(2020L,\"serial001\"));\n    }\n    \n    public CommonResult handleException(BlockException exception) {\n        return new CommonResult(444,exception.getClass().getCanonicalName()+\"\\t 服务不可用\");\n    }\n}\n```\n\n在控制台为该资源 `\"byResource\"` 设置降级规则，表示1秒钟内查询次数大于1，就跳转到`blockHandler`指定的`handleException()`方法：\n\n![image-20210907141330007](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907141330007.png)\n\n**方式2：指定URL**：\n\n```java\n@RestController\npublic class RateLimitController {\n    @GetMapping(\"/rateLimit/byUrl\")\n    @SentinelResource(value = \"byUrl\")\n    public CommonResult byUrl() {\n        return new CommonResult(200,\"按url降级测试OK\", new Payment(2020L,\"serial002\"));\n    }\n}\n```\n\n可以在降级规则中指定URL，这样符合该URL的请求在满足条件时都会调用自定义的降级方法：\n\n![image-20210907141239233](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907141239233.png)\n\n\n\n## Sentinel 热点规则\n\n> [官方文档](https://github.com/alibaba/Sentinel/wiki/热点参数限流)\n\n![image-20210907114601124](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907114601124.png)\n\n何为热点？**热点即经常访问的数据**。很多时候我们希望统计某个热点数据中访问频次最高的 Top K 数据，并对其访问进行限制。比如：\n\n- 商品 ID 为参数，统计一段时间内最常购买的商品 ID 并进行限制\n- 用户 ID 为参数，针对一段时间内频繁访问的用户 ID 进行限制\n\n热点参数限流会统计传入参数中的热点参数，并根据配置的限流阈值与模式，对包含热点参数的资源调用进行限流。热点参数限流可以看做是一种特殊的流量控制，**仅对包含热点参数的资源调用生效**。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/16d2ddeff96b7cb68a064b6ec05bde25.png)\n\nSentinel 利用 LRU 策略统计最近最常访问的热点参数，结合令牌桶算法来进行参数级别的流控。热点参数限流支持集群模式。\n\n热点 key 配置代码案例:\n\n- 使用 **@SentinelResource** 注解指定热点 key 值为`\"testHotKey\"`\n- 添加降级处理方法 `blockHandler=\"deal_testHotKey\"`，若不满足限流规则就执行降级处理方法\n\n```java\n@RestController\n@Slf4j\npublic class FlowLimitController\n{\n    @GetMapping(\"/testHotKey\")\n    @SentinelResource(value = \"testHotKey\", blockHandler = \"deal_testHotKey\")\n    public String testHotKey(@RequestParam(value = \"p1\",required = false) String p1,\n                             @RequestParam(value = \"p2\",required = false) String p2) {\n        //int age = 10/0;\n        return \"------testHotKey\";\n    }\n\n    /*兜底方法*/\n    public String deal_testHotKey (String p1, String p2, BlockException exception) {\n        return \"------deal_testHotKey,o(╥﹏╥)o\";  // sentinel 系统默认的提示：Blocked by Sentinel (flow limiting)\n    }\n}\n```\n\n配置热点规则，指定资源名为代码中的 `\"testHotKey\"`，且参数索引为0（即对第一个参数限流）：\n\n![image-20210907132824865](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907132824865.png)\n\n**测试**\n\n- error\n  - http://localhost:8401/testHotKey?p1=abc\n  - http://localhost:8401/testHotKey?p1=abc&p2=33\n- right\n  - http://localhost:8401/testHotKey?p2=abc\n\n### 热点规则参数例外项\n\n在“高级选项”中可以设置参数例外项，**即某个特殊值的时候限流值与其他普通值不同。**\n\n**前提条件** - 热点参数必须是基本类型或者String。参数例外项配置如下：\n\n![image-20210907133334167](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/image-20210907133334167.png)\n\n效果：\n\n- 普通参数值 - 超过1秒钟一个后，达到阈值1后马上被限流\n- **某个特殊值时，限流值为200**\n- 特例 - 假如当p1的值等于5时，它的阈值可以达到200\n\n测试：\n\n- right - http://localhost:8401/testHotKey?p1=5\n- error - http://localhost:8401/testHotKey?p1=3\n- 当p1等于5的时候，阈值变为200\n- 当p1不等于5的时候，阈值就是平常的1\n\n## Sentinel 系统规则\n\n> [官方文档](https://github.com/alibaba/Sentinel/wiki/系统自适应限流)\n\nSentinel 系统自适应限流从整体维度对应用入口流量进行控制，结合应用的 Load、CPU 使用率、总体平均 RT、入口 QPS 和并发线程数等几个维度的监控指标，通过自适应的流控策略，让系统的入口流量和系统的负载达到一个平衡，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性\n\n### 系统规则\n\n系统保护规则是从应用级别的入口流量进行控制，从单台机器的 load、CPU 使用率、平均 RT、入口 QPS 和并发线程数等几个维度监控应用指标，让系统尽可能跑在最大吞吐量的同时保证系统整体的稳定性。\n\n系统保护规则是应用整体维度的，而不是资源维度的，并且**仅对入口流量生效**。入口流量指的是进入应用的流量（EntryType.IN），比如 Web 服务或 Dubbo 服务端接收的请求，都属于入口流量。\n\n### 系统规则支持的模式\n\n- **Load 自适应**（仅对 Linux/Unix-like 机器生效）：系统的 load1 作为启发指标，进行自适应系统保护。当系统 load1 超过设定的启发值，且系统当前的并发线程数超过估算的系统容量时才会触发系统保护（BBR 阶段）。系统容量由系统的 `maxQps * minRt` 估算得出。设定参考值一般是 `CPU cores * 2.5`。\n- **CPU usage**（1.5.0+ 版本）：当系统 CPU 使用率超过阈值即触发系统保护（取值范围 0.0-1.0），比较灵敏。\n- **平均 RT**：当单台机器上所有入口流量的平均 RT 达到阈值即触发系统保护，单位是毫秒。\n- **并发线程数**：当单台机器上所有入口流量的并发线程数达到阈值即触发系统保护。\n- **入口 QPS**：当单台机器上所有入口流量的 QPS 达到阈值即触发系统保护。\n\n## @SentinelResource 配置\n\n### @SentinelResource 详解\n\n`@SentinelResource` 用于定义资源，并提供可选的异常处理和 `fallback` 配置项。该注解包含以下属性：\n\n- `value`：**资源名称**，必需项（不能为空），与控制台配置的资源名一一对应\n- `entryType`：entry 类型，可选项（默认为 `EntryType.OUT`）\n- `blockHandler` / `blockHandlerClass`：**`blockHandler` 对应处理 `BlockException` 的方法名称**，可选项。`blockHandler` 方法访问范围需要是 `public`，返回类型需要与原方法相匹配，参数类型需要和原方法相匹配并且最后加一个额外的参数，类型为 `BlockException`。`blockHandler` 方法默认需要和原方法在同一个类中。若希望使用其他类的方法，则可以指定 `blockHandlerClass` 为对应的类的 `Class` 对象，注意对应的方法**必须为 `static` 方法**，否则无法解析。\n- `fallback` /`fallbackClass`：`fallback` 方法名称，可选项，用于在抛出异常的时候提供 `fallback` 处理逻辑。`fallback` 方法可以针对所有类型的异常（除了`exceptionsToIgnore`里面排除掉的异常类型）进行处理。`fallback` 方法签名和位置要求：\n  - **返回值类型必须与原方法返回值类型一致**；\n  - **方法参数列表需要和原方法一致，或者可以额外多一个 `Throwable` 类型的参数用于接收对应的异常。**\n  - `fallback` 方法**默认需要和原方法在同一个类中**。若希望使用其他类的方法，则可以指定 `fallbackClass` 为对应的类的 `Class` 对象，注意**对应的方法必须为 `static` 方法**，否则无法解析。\n- `defaultFallback`（since 1.6.0）：默认的 `fallback` 方法名称，可选项，通常用于通用的 `fallback` 逻辑（即可以用于很多服务或方法）。默认 fallback 方法可以针对所有类型的异常（除了`exceptionsToIgnore`里面排除掉的异常类型）进行处理。若同时配置了 `fallback` 和 `defaultFallback`，则只有 `fallback` 会生效。`defaultFallback` 方法签名要求：\n  - 返回值类型必须与原方法返回值类型一致；\n  - 方法参数列表需要为空，或者可以额外多一个 `Throwable` 类型的参数用于接收对应的异常。\n  - defaultFallback 方法默认需要和原方法在同一个类中。若希望使用其他类的方法，则可以指定 `fallbackClass` 为对应的类的 `Class` 对象，注意对应的方法必需为 static 方法，否则无法解析。\n- `exceptionsToIgnore`（since 1.6.0）：用于指定哪些异常被排除掉，不会计入异常统计中，也不会进入 `fallback` 逻辑中，而是会原样抛出。\n\n### blockHandler 属性\n\n在 Controller 上使用 **@SentinelResource** 注解修饰目标方法，并设置**资源名**：`value = \"byResource\"`，同时设置满足限流条件时的回调方法`blockHandler = \"handleException\"`：\n\n```java\nimport com.alibaba.csp.sentinel.annotation.SentinelResource;\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport com.zhao.springcloud.alibaba.myhandler.CustomerBlockHandler;\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class RateLimitController {\n    \n    @GetMapping(\"/byResource\")\n    @SentinelResource(value = \"byResource\", blockHandler = \"handleException\")\n    public CommonResult byResource() {\n        return new CommonResult(200,\"按资源名称降级测试OK\",new Payment(2020L,\"serial001\"));\n    }\n    \n    public CommonResult handleException(BlockException exception) {\n        return new CommonResult(444,exception.getClass().getCanonicalName()+\"\\t 服务不可用\");\n    }\n}\n```\n\n### blockHandlerClass 属性\n\n上述方式自定义的处理方法和业务代码耦合在一块，不直观。同时每个业务方法都添加—个方法将导致代码膨胀加剧。全局统—的处理方法没有能够体现。\n\n解决方法：自定义限流处理类 - 创建 `CustomerBlockHandler` 类用于自定义限流处理逻辑（注意对应的方法**必须为 `static` 方法**，否则无法解析）：\n\n```java\nimport com.alibaba.csp.sentinel.slots.block.BlockException;\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\n\npublic class CustomerBlockHandler {\n    // 必须为 static 方法\n    public static CommonResult handlerException(BlockException exception) {\n        return new CommonResult(4444,\"按客戶自定义,global handlerException----1\");\n    }\n    \n    // 必须为 static 方法\n    public static CommonResult handlerException2(BlockException exception) {\n        return new CommonResult(4444,\"按客戶自定义,global handlerException----2\");\n    }\n}\n```\n\n`RateLimitController`上指定 `blockHandlerClass` ：\n\n```java\n@RestController\npublic class RateLimitController {\n    @GetMapping(\"/rateLimit/customerBlockHandler\")\n    @SentinelResource(value = \"customerBlockHandler\",\n                      blockHandlerClass = CustomerBlockHandler.class,//<-- 自定义限流处理类\n                      blockHandler = \"handlerException2\")//<-- 自定义类中的handlerException2方法\n    public CommonResult customerBlockHandler() {\n        return new CommonResult(200,\"按客戶自定义\",new Payment(2020L,\"serial003\"));\n    }\n}\n```\n\n-  `blockHandlerClass` ：指定自定义限流类 `CustomerBlockHandler.class`\n-  `blockHandler` ：指定该类中的指定限流方法 `handlerException2()`\n\n注意：\n\n- `blockHandler` 只能处理限流和降级相关的异常 `BlockException`，若是业务本身出现异常则不会响应 `blockHandler`  指定的方法，此情况需要使用 `fallback` 属性。\n- `blockHandlerClass` 里的方法**必须为 `static` 方法**，否则无法解析\n\n### fallback 属性\n\n`fallback` 只负责处理业务异常，若同时发生限流/降级异常 `BlockException`，则优先处理 `BlockException` 异常的处理方法。\n\n1. 开启 Ribbon 功能\n\n```java\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.client.RestTemplate;\n\n@Configuration\npublic class ApplicationContextConfig {\n    @Bean\n    @LoadBalanced\n    public RestTemplate getRestTemplate() {\n        return new RestTemplate();\n    }\n}\n```\n\n2. Controller 测试 `fallback` 和 `blockHandler` 的区别：\n\n```java\n@RestController\n@Slf4j\npublic class CircleBreakerController {\n    public static final String SERVICE_URL = \"http://nacos-payment-provider\";\n\n    @Resource\n    private RestTemplate restTemplate;\n\n    @RequestMapping(\"/consumer/fallback/{id}\")\n    //@SentinelResource(value = \"fallback\", fallback = \"handlerFallback\") // fallback只负责业务异常\n    //@SentinelResource(value = \"fallback\", blockHandler = \"blockHandler\") // blockHandler只负责sentinel控制台配置违规\n    @SentinelResource(value = \"fallback\", fallback = \"handlerFallback\", blockHandler = \"blockHandler\")\n    public CommonResult<Payment> fallback(@PathVariable Long id) {\n        CommonResult<Payment> result = restTemplate.getForObject(SERVICE_URL + \"/paymentSQL/\"+id,CommonResult.class,id);\n\n        if (id == 4) {\n            throw new IllegalArgumentException (\"IllegalArgumentException,非法参数异常....\");\n        }else if (result.getData() == null) {\n            throw new NullPointerException (\"NullPointerException,该ID没有对应记录,空指针异常\");\n        }\n\n        return result;\n    }\n    \n    //本例是fallback\n    public CommonResult handlerFallback(@PathVariable  Long id,Throwable e) {\n        Payment payment = new Payment(id,\"null\");\n        return new CommonResult<>(444,\"兜底异常handlerFallback,exception内容  \"+e.getMessage(),payment);\n    }\n\n    //本例是blockHandler\n    public CommonResult blockHandler(@PathVariable  Long id,BlockException blockException) {\n        Payment payment = new Payment(id,\"null\");\n        return new CommonResult<>(445,\"blockHandler-sentinel限流,无此流水: blockException  \"+blockException.getMessage(),payment);\n    }\n}\n```\n\n### exceptionsToIgnore 属性\n\n`exceptionsToIgnore`：忽略指定异常，即这些异常不用回调方法处理。\n\n```java\n@RestController\n@Slf4j\npublic class CircleBreakerController {\n    public static final String SERVICE_URL = \"http://nacos-payment-provider\";\n\n    @Resource\n    private RestTemplate restTemplate;\n    \n    @RequestMapping(\"/consumer/fallback/{id}\")\n    @SentinelResource(value = \"fallback\",fallback = \"handlerFallback\",blockHandler = \"blockHandler\",\n                      exceptionsToIgnore = {IllegalArgumentException.class})\n    public CommonResult<Payment> fallback(@PathVariable Long id) {\n        CommonResult<Payment> result = restTemplate.getForObject(SERVICE_URL + \"/paymentSQL/\"+id,CommonResult.class,id);\n\n        if (id == 4) {\n            //exceptionsToIgnore属性有IllegalArgumentException.class，\n            //所以IllegalArgumentException不会跳入指定的兜底程序。\n            throw new IllegalArgumentException (\"IllegalArgumentException,非法参数异常....\");\n        }else if (result.getData() == null) {\n            throw new NullPointerException (\"NullPointerException,该ID没有对应记录,空指针异常\");\n        }\n\n        return result;\n    }\n}\n```\n\n## Sentinel 整合 OpenFeign\n\n注意：Sentinel 整合 OpenFeign 的使用方法类似于 Hystrix 整合 OpenFeign（见文章[【Spring Cloud】Hystrix](https://yuyun-zhao.github.io/2021/08/30/%E3%80%90SpringCloud%E3%80%91Hystrix/#%E9%80%9A%E9%85%8D%E6%9C%8D%E5%8A%A1%E9%99%8D%E7%BA%A7-feignfallback)），区别在于配置文件中 feign 开启的是 sentinel 的降级处理\n\n1. 导入Maven依赖：\n\n```xml\n<!--SpringCloud openfeign -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n```\n\n2. 配置文件中添加 OpenFeign对 Sentinel 的支持：\n\n```yaml\n# 激活Sentinel对Feign的支持\nfeign:\n  sentinel:\n    enabled: true\n```\n\n3. 主启动类标志 **@EnableFeignClients** 注解开启 OpenFeign：\n\n```java\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@EnableDiscoveryClient\n@SpringBootApplication\n@EnableFeignClients // <------------------------\npublic class OrderNacosMain84 {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderNacosMain84.class, args);\n    }\n}\n```\n\n4. 业务接口标注 **@Feignclient** 注解，并指定降级处理实现类 `fallback = PaymentFallbackService.class`：\n\n```java\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\n\n@FeignClient(value = \"nacos-payment-provider\", fallback = PaymentFallbackService.class)\npublic interface PaymentService {\n    @GetMapping(value = \"/paymentSQL/{id}\")\n    public CommonResult<Payment> paymentSQL(@PathVariable(\"id\") Long id);\n}\n```\n\n5. 创建 `PaymentService` 接口的实现类 `PaymentFallbackService`，实现接口的所有方法，在其添加降级业务：\n\n```java\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class PaymentFallbackService implements PaymentService {\n    @Override\n    public CommonResult<Payment> paymentSQL(Long id) \n        return new CommonResult<>(44444, \"服务降级返回, ---PaymentFallbackService\", new Payment(id,\"errorSerial\"));\n    }\n}\n```\n\n6. Controller 调用 `PaymentService` 接口的动态代理类即可实现远程调用与负载均衡，同时若服务出现异常，则会调用 `PaymentFallbackService` 类的 `paymentSQL()` 方法进行降级：\n\n```java\n@RestController\n@Slf4j\npublic class CircleBreakerController {\n    // ================== OpenFeign ==================\n    @Resource\n    private PaymentService paymentService;\n\n    @GetMapping(value = \"/consumer/paymentSQL/{id}\")\n    public CommonResult<Payment> paymentSQL(@PathVariable(\"id\") Long id) {\n        return paymentService.paymentSQL(id);\n    }\n}\n```\n\n## Sentinel 持久化规则\n\n在未配置持久化时，一旦我们重启应用，之前配置的Sentinel规则将消失。因此生产环境需要将配置规则进行持久化。\n\n思路：将限流配置规则持久化进Nacos保存，只要刷新8401某个rest地址，sentinel控制台的流控规则就能看到，只要Nacos里面的配置不删除，针对8401上sentinel上的流控规则持续有效。\n\n实现方法：\n\n1. 修改 `cloudalibaba-sentinel-service8401`，加入Maven依赖：\n\n```xml\n<!--SpringCloud ailibaba sentinel-datasource-nacos 后续做持久化用到-->\n<dependency>\n    <groupId>com.alibaba.csp</groupId>\n    <artifactId>sentinel-datasource-nacos</artifactId>\n</dependency>\n```\n\n2. 修改配置文件，添加Nacos数据源配置：\n\n```yaml\nserver:\n  port: 8401\n\nspring:\n  application:\n    name: cloudalibaba-sentinel-service\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 # Nacos服务注册中心地址\n    sentinel:\n      transport:\n        dashboard: localhost:8080   # 配置Sentinel dashboard地址\n        port: 8719\n      datasource: # <-------------关注点，添加Nacos数据源配置\n        ds1:\n          nacos:\n            server-addr: localhost:8848  # 从Nacos服务中心获取指定名称的配置文件\n            dataId: cloudalibaba-sentinel-service\n            groupId: DEFAULT_GROUP\n            data-type: json\n            rule-type: flow\n\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: '*'\n\nfeign:\n  sentinel:\n    enabled: true # 激活Sentinel对Feign的支持\n```\n\n3. 添加Nacos业务规则配置（该配置需要与上述配置文件中的名称一致才能被sentinel获取到）：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/2401a6b2df715ee64f647da2f31e1eeb.png)\n\n配置内容解析：\n\n```json\n[\n    {\n        \"resource\": \"/rateLimit/byUrl\",\n        \"IimitApp\": \"default\",\n        \"grade\": 1,\n        \"count\": 1, \n        \"strategy\": 0,\n        \"controlBehavior\": 0,\n        \"clusterMode\": false\n    }\n]\n```\n\n- `resource`：资源名称；\n- `limitApp`：来源应用；\n- `grade`：阈值类型，0表示线程数, 1表示QPS；\n- `count`：单机阈值；\n- `strategy`：流控模式，0表示直接，1表示关联，2表示链路；\n- `controlBehavior`：流控效果，0表示快速失败，1表示Warm Up，2表示排队等待；\n- `clusterMode`：是否集群。\n\n4. 启动8401后刷新sentinel发现业务规则有了\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sentinel/c854e986254c09d0a7866811ec1e0cb4.png)\n\n5. 关闭8401再看sentinel，发现流控规则没有了\n6. 重新启动8401再看sentinel，多次访问 http://localhost:8401/rateLimit/byUrl 后发现配置重新出现，说明规则配置持久化成功\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】Spring Cloud Alibaba Nacos","url":"/2021/09/05/【SpringCloud】Nacos/","content":"\n## Spring Cloud Alibaba 简介\n\n> [Spring Cloud Alibaba 文档](https://spring.io/projects/spring-cloud-alibaba#learn)、[中文官网介绍](https://github.com/alibaba/spring-cloud-alibaba/blob/master/README-zh.md)\n\nSpring Cloud Alibaba 致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件，方便开发者通过 Spring Cloud 编程模型轻松使用这些组件来开发分布式应用服务。\n\n依托 Spring Cloud Alibaba，您只需要添加一些注解和少量配置，就可以将 Spring Cloud 应用接入阿里微服务解决方案，通过阿里中间件来迅速搭建分布式应用系统。\n\n诞生：2018.10.31，Spring Cloud Alibaba 正式入驻了Spring Cloud官方孵化器，并在Maven 中央库发布了第一个版本。\n\n### Spring Cloud Alibaba 能做什么\n\n- **服务限流降级**：默认支持 WebServlet、WebFlux, OpenFeign、RestTemplate、Spring Cloud Gateway, Zuul, Dubbo 和 RocketMQ 限流降级功能的接入，可以在运行时通过控制台实时修改限流降级规则，还支持查看限流降级 Metrics 监控。\n- **服务注册与发现**：适配 Spring Cloud 服务注册与发现标准，默认集成了 Ribbon 的支持。\n- **分布式配置管理**：支持分布式系统中的外部化配置，配置更改时自动刷新。\n- **消息驱动能力**：基于 Spring Cloud Stream 为微服务应用构建消息驱动能力。\n- **分布式事务**：使用 @GlobalTransactional 注解， 高效并且对业务零侵入地解决分布式事务问题。\n- **阿里云对象存储**：阿里云提供的海量、安全、低成本、高可靠的云存储服务。支持在任何应用、任何时间、任何地点存储和访问任意类型的数据。\n- **分布式任务调度**：提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。同时提供分布式的任务执行模型，如网格任务。网格任务支持海量子任务均匀分配到所有 Worker（schedulerx-client）上执行。\n- **阿里云短信服务**：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。\n\n### 相关技术栈\n\n- **Sentinel**：把流量作为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\n- **Nacos**：一个更易于构建云原生应用的动态服务发现、配置管理和服务管理平台。\n- **RocketMQ**：一款开源的分布式消息系统，基于高可用分布式集群技术，提供低延时的、高可靠的消息发布与订阅服务。\n- **Dubbo**：Apache Dubbo™ 是一款高性能 Java RPC 框架。\n- **Seata**：阿里巴巴开源产品，一个易于使用的高性能微服务分布式事务解决方案。\n- **Alibaba Cloud OSS**：阿里云对象存储服务（Object Storage Service，简称 OSS），是阿里云提供的海量、安全、低成本、高可靠的云存储服务。您可以在任何应用、任何时间、任何地点存储和访问任意类型的数据。\n- **Alibaba Cloud SchedulerX**：阿里中间件团队开发的一款分布式任务调度产品，提供秒级、精准、高可靠、高可用的定时（基于 Cron 表达式）任务调度服务。\n- **Alibaba Cloud SMS**：覆盖全球的短信服务，友好、高效、智能的互联化通讯能力，帮助企业迅速搭建客户触达通道。\n\n使用时在父工程导入Maven依赖：\n\n``` xml\n<dependencyManagement>\n    <dependencies>\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n            <version>2.2.5.RELEASE</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\n## Nacos 简介\n\n**Nacos: Dynamic Naming and Configuration Service**。它是一个更易于构建云原生应用的**动态服务发现**、**配置管理**和**服务管理平台**。\n\nNacos就是注册中心＋配置中心的组合 -> **Nacos = Eureka+Config+Bus**\n\n> 下载地址：https://github.com/alibaba/nacos/releases 、[官方文档](https://spring-cloud-alibaba-group.github.io/github-pages/greenwich/spring-cloud-alibaba.html#_spring_cloud_alibaba_nacos_discovery)\n\n### 各种注册中心比较\n\n| 服务注册与发现框架 | CAP模型 | 控制台管理 | 社区活跃度      |\n| ------------------ | ------- | ---------- | --------------- |\n| Eureka             | AP      | 支持       | 低(2.x版本闭源) |\n| Zookeeper          | CP      | 不支持     | 中              |\n| consul             | CP      | 支持       | 高              |\n| Nacos              | AP      | 支持       | 高              |\n\n> Nacos 安装见博客：https://blog.csdn.net/u011863024/article/details/114298288\n\n若在本地安装Nacos，则访问http://localhost:8848/nacos，默认账号密码都是nacos，进入以下界面：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/a3ad68ab8165ff76356641c1f49a7683.png)\n\n## Nacos 服务注册\n\n### 服务提供者\n\n1. 新建Module： `cloudalibaba-provider-payment9001`\n2. 在**父工程**中加入依赖 `spring-cloud-alibaba-dependencies`：\n\n``` xml\n<dependencyManagement>\n    <dependencies>\n        <!--spring cloud alibaba 2.2.1.RELEASE-->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n            <version>2.2.1.RELEASE</version>\n            <type>pom</type>\n            <scope>import</scope>\n        </dependency>\n    </dependencies>\n</dependencyManagement>\n```\n\n3. 本模块添加依赖\n\n```  xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloudalibaba-provider-payment9001</artifactId>\n\n    <dependencies>\n        <!--SpringCloud ailibaba nacos -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!-- SpringBoot整合Web组件 -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--日常通用jar包配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n</project>\n```\n\n4. 配置文件：\n\n``` yaml\nserver:\n  port: 9001\n\nspring:\n  # 注意需要在这里指定服务名称，否则Nacos管理台中无法显示该服务\n  application:\n    name: nacos-payment-provider\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848 # 配置Nacos地址，若使用Nginx部署Nacos集群则填写Nginx的端口\n\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: '*'\n```\n\n5. 主启动类：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@EnableDiscoveryClient\n@SpringBootApplication\npublic class PaymentMain9001 {\n    public static void main(String[] args) {\n            SpringApplication.run(PaymentMain9001.class, args);\n    }\n}\n```\n\n6. 业务类：\n\n``` java\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\npublic class PaymentController {\n    @Value(\"${server.port}\")\n    private String serverPort;\n\n    @GetMapping(value = \"/payment/nacos/{id}\")\n    public String getPayment(@PathVariable(\"id\") Integer id) {\n        return \"nacos registry, serverPort: \"+ serverPort+\"\\t id\"+id;\n    }\n}\n```\n\n7. 测试：启动微服务后，进入Nacos中心（例如本地的http://localhost:8848/nacos），即可在服务列表中找到该服务信息\n\n> 默认账号和密码都是 nacos\n\n再创建一个虚拟微服务，直接拷贝9001的配置，即可快速开启第二个微服务：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/2bef79cd8f72b8f23b815b49f4ba07ce.png)\n\n### 服务消费者和负载均衡\n\n1. 新建Module：`cloudalibaba-consumer-nacos-order83`\n2. 导入Maven依赖：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>LearnCloud</artifactId>\n        <groupId>com.lun.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloudalibaba-consumer-nacos-order83</artifactId>\n\n    <dependencies>\n        <!--SpringCloud ailibaba nacos -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n        <dependency>\n            <groupId>com.lun.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>1.0.0-SNAPSHOT</version>\n        </dependency>\n        <!-- SpringBoot整合Web组件 -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--日常通用jar包配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n</project>\n```\n\n为什么Nacos支持负载均衡？因为`spring-cloud-starter-alibaba-nacos-discovery`内含`netflix-ribbon`包，其内部使用 **Ribbon+RestTemplate** 实现负载均衡：\n\n![image-20210905163605462](/images/%E3%80%90SpringCloud%E3%80%91Nacos/image-20210905163605462.png)\n\n3. 配置文件：\n\n``` yaml\nserver:\n  port: 83\n\nspring:\n  application:\n    name: nacos-order-consumer\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n\n# 消费者将要去访问的微服务名称(注册成功进nacos的微服务提供者)\nservice-url:\n  nacos-user-service: http://nacos-payment-provider\n```\n\n4. 主启动类：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@EnableDiscoveryClient\n@SpringBootApplication\npublic class OrderNacosMain83 {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderNacosMain83.class,args);\n    }\n}\n```\n\n5. 配置类 `ApplicationContextConfig` 中注入 `RestTemplate`，并使用 `@LoadBalanced` 注解开启负载均衡功能 ：\n\n``` java\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.client.RestTemplate;\n\n@Configuration\npublic class ApplicationContextConfig {\n    @Bean\n    @LoadBalanced\n    public RestTemplate getRestTemplate() {\n        return new RestTemplate();\n    }\n}\n```\n\n6. 业务类：\n\n``` java\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\nimport org.springframework.web.client.RestTemplate;\n\nimport javax.annotation.Resource;\n\n@RestController\n@Slf4j\npublic class OrderNacosController {\n    \n    @Resource\n    private RestTemplate restTemplate;\n\n    @Value(\"${service-url.nacos-user-service}\")\n    private String serverURL;\n\n    @GetMapping(value = \"/consumer/payment/nacos/{id}\")\n    public String paymentInfo(@PathVariable(\"id\") Long id) {\n        return restTemplate.getForObject(serverURL+\"/payment/nacos/\"+id,String.class);\n    }\n}\n```\n\n7. 测试：访问http://localhost:83/consumer/payment/nacos/1，发现能够轮询访问9001和9011微服务。\n\n### 服务注册中心对比提升\n\n**Nacos全景图**\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/a9c35ea022a95aa76bfec990d6b73d8a.png)\n\nNacos与其他注册中心特性对比：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/62d5a8566a2dc588a5ed52346049a054.png)\n\n从上图可知，**Nacos支持AP和CP模式的切换**，可根据不同的使用场景手动切换成对应的模式。\n\n**Nacos服务发现实例模型**\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/6578e36df056a995a39034045c36fc40.png)\n\n**Nacos支持AP和CP模式的切换**\n\n- C是所有节点在同一时间看到的数据是一致的;\n- A的定义是所有的请求都会收到响应。\n\n何时选择使用何种模式?\n\n—般来说，如果不需要存储服务级别的信息且服务实例是通过nacos-client注册，并能够保持心跳上报，那么就可以选择AP模式。当前主流的服务如Spring cloud和Dubbo服务，都适用于AP模式，**AP模式为了服务的可能性而减弱了一致性，因此AP模式下只支持注册临时实例。**\n\n如果需要在**服务级别编辑或者存储配置信息**，那么CP是必须，K8S服务和DNS服务则适用于CP模式。CP模式下则支持注册持久化实例，此时则是以Raft协议为集群运行模式，该模式下注册实例之前必须先注册服务，如果服务不存在，则会返回错误。\n\nAP/CP模式切换命令：\n\n``` sh\ncurl -X PUT '$NACOS_SERVER:8848/nacos/v1/ns/operator/switches?entry=serverMode&value=CP\n```\n\n\n\n## Nacos 服务配置中心\n\n1. 新建Module：`cloudalibaba-config-nacos-client3377`\n2. 导入Maven依赖：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2020</artifactId>\n        <groupId>com.atguigu.springcloud</groupId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloudalibaba-config-nacos-client3377</artifactId>\n\n    <dependencies>\n        <!--nacos-config-->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n        </dependency>\n        <!--nacos-discovery-->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!--web + actuator-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--一般基础配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n</project>\n```\n\n3. 在配置文件 `bootstrap.yaml`中进行配置（该文件优先于 `application.yaml`加载）。注意，配置中心的内容必须在 `bootstarp.yaml` 中编写，如果和普通的配置参数一起写在 `application.yaml` 中，则无法从配置中心进行更新：\n\n``` yaml\n# nacos配置\nserver:\n  port: 3377\n\nspring:\n  application:\n    name: nacos-config-client\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848  # Nacos服务注册中心地址\n      config:\n        server-addr: localhost:8848  # Nacos作为配置中心地址\n        file-extension: yaml         # 指定yaml格式的配置\n        # 指定分组，根据生产/开发/测试环境进行分组（或将同功能的微服务放在一组）\n        group: DEV_GROUP\n        # 指定命名空间，实现环境隔离：根据微服务的功能进行区分隔离（或根据实现生产/开发/测试环境进行隔离）。该 id 在 Nacos Server上生成\n        namespace: 45d051b1-4440-4cd9-9de1-8992396f7d89\n\n# 在配置中心中创建配置文件，命名格式要求：\n# ${spring.application.name}-${spring.profile.active}.${spring.cloud.nacos.config.file-extension}\n# 本例子模块 nacos-config-client，profiles = dev，对应 Nacos server 上的配置文件：nacos-config-client-dev.yaml\n\n# nacos-config-client-test.yaml   ----> config.info\n```\n\n`application.yaml`：\n\n``` yaml\nspring:\n  profiles:\n    active: dev\n    # active: test\n```\n\nNacos同Spring Cloud Config一样，在项目初始化时，要保证先从配置中心进行配置拉取，拉取配置之后，才能保证项目的正常启动。Spring Boot中配置文件的加载是存在优先级顺序的，`bootstrap.yaml`优先级高于`application.yaml`\n\n其中，分组和命名空间可以根据项目需求进行设计，例如：\n\n- **分组**用于区分不同的环境，例如开发/生产/测试环境\n- **命名空间**用于区分不同的微服务，例如会员/商品/库存服务等\n\n4. 主启动类：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@EnableDiscoveryClient\n@SpringBootApplication\npublic class NacosConfigClientMain3377 {\n    public static void main(String[] args) {\n        SpringApplication.run(NacosConfigClientMain3377.class, args);\n    }\n}\n```\n\n5. 业务类：\n\n``` java\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.cloud.context.config.annotation.RefreshScope;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n\n// 注意！！！要写上该注解以支持Nacos的动态刷新功能，否则无法动态刷新\n@RefreshScope     \n@RestController\npublic class ConfigClientController {\n    @Value(\"${config.info}\")\n    private String configInfo;\n\n    @GetMapping(\"/config/info\")\n    public String getConfigInfo() {\n        return configInfo;\n    }\n}\n```\n\n配置信息通过 Spring Cloud 原生注解 **@RefreshScope** 实现配置**自动更新**，不需要像 Spring Cloud Config 一样还需要运维人员手动`curl`才能刷新。\n\n6. 在Nacos配置中心添加配置信息\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/c61619bbe5ea16f34efca8103b0f90ba.png)\n\n配置文件的`Data ID`命名规则：\n\n``` \n${prefix}-${spring-profile.active}.${file-extension}\n```\n\n- `prefix`默认为`spring.application.name`的值，也可以通过配置项`spring.cloud.nacos.config.prefix`来配置。\n- `spring.profile.active`即为当前环境对应的 `profile`，详情可以参考 Spring Boot文档。注意：当`spring.profile.active`为空时，对应的连接符 - 也将不存在，datald 的拼接格式变成`${prefix}.${file-extension}`\n- `file-exetension`为配置内容的数据格式，可以通过配置项`spring .cloud.nacos.config.file-extension`来配置。目前只支持`properties`和`yaml`类型。\n\n`Data ID`示例：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/b3bffc4a646b30f9bf64fc649bf26f7d.png)\n\n**自带动态刷新**\n\nNacos 的配置信息通过 Spring Cloud 原生注解 **@RefreshScope** 实现配置**自动更新**，不需要像 Spring Cloud Config 一样还需要运维人员手动`curl`才能刷新。修改下Nacos中的yaml配置文件，再次调用查看配置的接口，就会发现配置已经刷新。\n\n## Nacos 命名空间、分组和 Data ID\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/3a7d1ad9bea8356742997ed3ebbe9be3.png)\n\n**Namespace + Group + Data lD三者关系？为什么这么设计？**\n\n类似Java里面的`package`名和类名最外层的`namespace`是可以用于区分部署环境的，`Group`和`DatalD`逻辑上区分两个目标对象。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/60712abd615dd86ac6c119bf132a28d6.png)\n\n默认情况：`Namespace=public`，`Group=DEFAULT_GROUP`，默认`Cluster`是`DEFAULT`\n\n- Nacos默认的`Namespace`是`public`，`Namespace`主要用来实现隔离。比方说我们现在有三个环境：开发、测试、生产环境，我们就可以创建三个`Namespace`，不同的`Namespace`之间是隔离的。\n- `Group`默认是`DEFAULT_GROUP`，`Group`可以把不同的微服务划分到同一个分组里面去\n- `Service`就是微服务：一个`Service`可以包含多个`Cluster` (集群)，Nacos默认`Cluster`是`DEFAULT`，`Cluster`是对指定微服务的一个虚拟划分。比方说为了容灾，将`Service`微服务分别部署在了杭州机房和广州机房，这时就可以给杭州机房的`Service`微服务起一个集群名称(HZ) ，给广州机房的`Service`微服务起一个集群名称(GZ)，还可以尽量让同一个机房的微服务互相调用，以提升性能。\n- 最后是`Instance`，就是微服务的实例。\n\n###  Data ID 配置\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/5ea4b3fd5ca8cb6e7de6f0d9ac98f051.png)\n\n通过`spring.profile.active`属性就能进行多环境下配置文件的读取：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/281a70d387cb48ce82e94421adf17747.png)\n\n### Group 分组方案\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/bdf592aa566fe50f7f454118a70ca03c.png)\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/28aee2b45901bbb9a6776d5c4398a6bb.png)\n\n在 `config` 下增加一条 `group` 的配置即可。可配置为 `DEV_GROUP` 或 `TEST_GROUP`：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/342a167a8bd948d8ba5cbfd760cf66a6.png)\n\n### Namespace 空间方案\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/a10c71978c75c214aca5fa7057bb2834.png)\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/2a9f3fa415f5cead0219d404a47131a0.png)\n\n```yaml\n# nacos配置\nserver:\n  port: 3377\n\nspring:\n  application:\n    name: nacos-config-client\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848  # Nacos服务注册中心地址\n      config:\n        server-addr: localhost:8848  # Nacos作为配置中心地址\n        file-extension: yaml         # 指定yaml格式的配置\n        group: DEV_GROUP\n        namespace: 7d8f0f5a-6a53-4785-9686-dd460158e5d4  # <------------指定namespace\n```\n\n##  Nacos 集群\n\n架构图：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Nacos/681c3dc16a69f197896cbff482f2298e.png)\n\n具体配置流程见博客：https://blog.csdn.net/u011863024/article/details/114298282 与 https://blog.csdn.net/u011863024/article/details/114298288\n\n\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】Spring Cloud Sleuth","url":"/2021/09/04/【SpringCloud】Sleuth/","content":"\n## Spring Cloud Sleuth 介绍\n\n> https://github.com/spring-cloud/spring-cloud-sleuth\n\n在微服务框架中，一个由客户端发起的请求在后端系统中会经过多个不同的的服务节点调用来协同产生最后的请求结果，每一个前段请求都会形成一条复杂的分布式服务调用链路，链路中的任何一环出现高延时或错误都会引起整个请求最后的失败。\n\nSpring Cloud Sleuth 提供了一套完整的**服务跟踪**的解决方案。其在分布式系统中提供追踪解决方案并且兼容支持了zipkin。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sleuth/b40478e2b2c83d7181b9c71cdcae05ea.png)\n\nZipkin是 Twitter 的一个开源项目，基于 Google Dapper实现。可以使用它来收集各个服务器上请求链路的跟踪数据，并通过它提供的 REST API 接口来辅助我们查询跟踪数据以实现对分布式系统的监控程序，从而及时地发现系统中出现的延迟升高问题并找出系统性能瓶颈的根源。除了面向开发的API接口之外，它也提供了方便的 UI 组件帮助我们直观的搜索跟踪信息和分析请求链路明细，比如：可以查询某段时间内各用户请求的处理时间等。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sleuth/ca541262b26f809a0c25014feaa069d7.png)\n\n> sleuth\n> 英 [sluːθ] 美 [sluːθ]\n> n. 侦探\n\n<!-- More -->\n\n## Sleuth 之 zipkin 搭建安装\n\n> 下载地址：https://dl.bintray.com/openzipkin/maven/io/zipkin/java/zipkin-server/\n\nSpring Cloud 从 F 版起已不需要自己构建 Zipkin Server了，只需调用jar包即可：\n\n``` bash\njava -jar zipkin-server-2.12.9-exec.jar\n```\n\n运行控制台：http://localhost:9411/zipkin/\n\n请求链路，一条链路通过Trace ld唯一标识，Span标识发起的请求信息，各span通过parent id关联起来\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sleuth/ec45d9d026fee8c83eaaf7bf8cb6893d.png)\n\n—条链路通过Trace ld唯一标识，Span标识发起的请求信息，各span通过parent id关联起来。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sleuth/f75fcfd2146df03428b9c8c53d13c1f1.png)\n\n整个链路的依赖关系如下：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sleuth/c1d19c5e9724578ee9c8668903685fa4.png)\n\n名词解释\n\n- Trace：类似于树结构的Span集合，表示一条调用链路，存在唯一标识\n- span：表示调用链路来源，通俗的理解span就是一次请求信息\n\n## Sleuth 链路监控展现\n\n### 服务提供者\n\n在服务提供者 `cloud-provider-payment8001` 中添加 Sleuth 链路。\n\n1. 导入 Maven 依赖：\n\n``` xml\n<!--包含了sleuth+zipkin-->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zipkin</artifactId>\n</dependency>\n```\n\n2. 配置文件：\n\n``` yaml\nspring:\n  application:\n    name: cloud-payment-service\n\n  zipkin: #<------------------------------------- 关键 \n      base-url: http://localhost:9411\n  sleuth: #<------------------------------------- 关键\n    sampler:\n    # 采样率值介于 0 到 1 之间，1 则表示全部采集\n    probability: 1\n    \n  datasource:\n    type: com.alibaba.druid.pool.DruidDataSource            # 当前数据源操作类型\n    driver-class-name: org.gjt.mm.mysql.Driver              # mysql驱动包\n    url: jdbc:mysql://localhost:3306/db2019?useUnicode=true&characterEncoding=utf-8&useSSL=false\n    username: root\n    password: 123456\n```\n\n3. 业务类 PaymentController：\n\n``` java\n@RestController\n@Slf4j\npublic class PaymentController {\n    @GetMapping(\"/payment/zipkin\")\n    public String paymentZipkin() {\n        return \"hi ,i'am paymentzipkin server fall back，welcome to here, O(∩_∩)O哈哈~\";\n    }    \n}\n```\n\n### 服务消费者\n\n修改服务消费者 `cloud-consumer-order80`，添加 Sleuth 链路。\n\n1. 导入 Maven 依赖：\n\n``` xml\n<!--包含了sleuth+zipkin-->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zipkin</artifactId>\n</dependency>\n```\n\n2. 配置文件：\n\n``` yaml\nspring:\n    application:\n        name: cloud-order-service\n    zipkin:\n      base-url: http://localhost:9411\n    sleuth:\n      sampler:\n        probability: 1\n```\n\n3. 业务类 OrderController：\n\n``` java\n    ...\n    // ====================> zipkin+sleuth\n    @GetMapping(\"/consumer/payment/zipkin\")\n    public String paymentZipkin() {\n        String result = restTemplate.getForObject(\"http://localhost:8001\"+\"/payment/zipkin/\", String.class);\n        return result;\n    }\n}\n```\n\n测试：依次启动eureka7001/8001/80 - 80调用8001几次测试下。\n\n打开浏览器访问: http://localhost:9411：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Sleuth/733ad2e18037059045ec80cb59d8d2a3.png)\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】Spring Cloud Stream","url":"/2021/09/04/【SpringCloud】Stream/","content":"\n## Spring Cloud Stream 介绍\n\n> [Spring Cloud Stream 官方文档](https://spring.io/projects/spring-cloud-stream#overview)、[中文指导手册](https://m.wang1314.com/doc/webapp/topic/20971999.html)\n\nSpring Cloud Stream是一个构建**消息驱动**微服务的框架。\n\n### 为什么用 Stream？\n\n比方说我们用到了RabbitMQ和Kafka，由于这两个消息中间件的架构上的不同，像RabbitMQ有`Exchange`，kafka有`Topic`和`Partitions`分区。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Stream/5587b05def1c26b8c9d9874c78f80b28.png)\n\n这些中间件的差异性导致我们实际项目开发给我们造成了一定的困扰，我们如果用了两个消息队列的其中一种，后面的业务需求，我想往另外一种消息队列进行迁移，这时候无疑就是一个灾难性的，一大堆东西都要重新推倒重新做，因为它跟我们的系统耦合了，这时候Spring Cloud Stream给我们提供了—种**解耦合**的方式。\n\n### Stream 凭什么可以统一底层差异？\n\n在没有绑定器这个概念的情况下，我们的Spring Boot应用要直接与消息中间件进行信息交互的时候，由于各消息中间件构建的初衷不同，它们的实现细节上会有较大的差异性。**通过定义绑定器 Binder作为中间层**，完美地实现了**应用程序与消息中间件细节之间的隔离**。通过向应用程序暴露统一的Channel通道，使得应用程序不需要再考虑各种不同的消息中间件实现。所以，我们只需要搞清楚如何与Spring Cloud Stream交互就可以方便使用消息驱动的方式。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Stream/96256569e677453570b55209c26e0b8c.png)\n\n应用程序通过 `inputs` 或者 `outputs` 来与Spring Cloud Stream中 `binder` 对象交互。\n\n**Binder**：\n\n- `inputs`：对应于消费者\n- `outputs`：对应于生产者\n\nStream 中的消息通信方式遵循了 **发布-订阅模式**。使用Topic主题进行广播：\n\n- 在RabbitMQ就是`Exchange`\n- 在Kakfa中就是`Topic`\n\n<!-- More -->\n\n## Stream 常用注解\n\nStream 三个重要组成部分：\n\n- **Binder**：很方便的连接中间件，屏蔽差异。\n- **Channel**：通道，是队列Queue的一种抽象，在消息通讯系统中就是实现存储和转发的媒介，通过Channel对队列进行配置。\n- **Source** 和 **Sink**：简单的可理解为参照对象是Spring Cloud Stream自身，从Stream发布消息就是输出，接受消息就是输入。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Stream/1ca02dd31581d92a7a610bcd137f6848.png)\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Stream/077a3b34aec6eed91a7019a9d5ca4e3c.png)\n\n**编码 API 和常用注解**\n\n- **Middleware**：中间件，目前只支持RabbitMQ和Kafka\n- **Binder**：Binder是应用与消息中间件之间的封装，目前实行了Kafka和RabbitMQ的Binder，通过Binder可以很方便地连接中间件，可以动态的改变消息类型（对应于Kafka的topic,RabbitMQ的exchange），这些都可以通过配置文件来实现\n- **@Input**：注解标识输入通道，通过该输入通道接收到的消息进入应用程序\n- **@Output**：注解标识输出通道，发布的消息将通过该通道离开应用程序\n- **@StreamListener**：监听队列，用于消费者的队列的消息接收\n- **@EnableBinding**：指信道channel和exchange绑定在一起\n\n## Stream 实战\n\n工程中新建三个子模块\n\n- `cloud-stream-rabbitmq-provider8801`：消息生产者\n- `cloud-stream-rabbitmq-consumer8802`：消息消费者\n- `cloud-stream-rabbitmq-consumer8803`：消息消费者\n\n## Stream 生产者模块\n\n新建Module：`cloud-stream-rabbitmq-provider8801`\n\n1. 导入 Maven 依赖：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-stream-rabbitmq-provider8801</artifactId>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-stream-rabbit</artifactId>\n        </dependency>\n        <!--基础配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n2. 配置文件（注意需要在spring下单独配置RabbitMQ的信息）：\n\n``` yaml\nserver:\n  port: 8801\n\nspring:\n  application:\n    name: cloud-stream-provider\n\n  # 连接非本机的 RabbitMQ 时，需要单独配置 RabbitMQ，否则会报连接异常，除非关闭健康检查\n  rabbitmq:\n    host: 192.168.1.203\n    port: 5672\n    username: admin\n    password: admin\n\n  cloud:\n    stream:\n      binders:                             # 在此处配置要绑定的rabbitmq的服务信息；\n        defaultRabbit:                     # 表示定义的名称，用于于binding整合\n          type: rabbit                     # 消息组件类型\n          environment:                     # 设置rabbitmq的相关的环境配置\n            spring:\n              rabbitmq:\n                host: 192.168.1.203\n                port: 5672\n                username: admin\n                password: admin\n      bindings:                            # 服务的整合处理\n        output:                            # 这个名字是一个通道的名称\n          destination: studyExchange       # 表示要使用的Exchange名称定义\n          content-type: application/json   # 设置消息类型，本次为json，文本则设置“text/plain”\n          binder: defaultRabbit            # 设置要绑定的消息服务的具体设置\n\neureka:\n  client:    # 客户端进行Eureka注册的配置\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n  instance:\n    lease-renewal-interval-in-seconds: 2      # 设置心跳的时间间隔（默认是30秒）\n    lease-expiration-duration-in-seconds: 5   # 如果现在超过了5秒的间隔（默认是90秒）\n    instance-id: send-8801.com                # 在信息列表时显示主机名称\n    prefer-ip-address: true                   # 访问的路径变为IP地址\n```\n\n3. 主启动类 `StreamMQMain8801`\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class StreamMQMain8801 {\n    public static void main(String[] args) {\n        SpringApplication.run(StreamMQMain8801.class,args);\n    }\n}\n```\n\n4. 业务类：发送消息接口 `IMessageProvider` ：\n\n``` java\npublic interface IMessageProvider {\n    public String send();\n}\n```\n\n5. 发送消息接口实现类 `MessageProviderImpl `：\n\n``` java\nimport com.zhao.springcloud.service.IMessageProvider;\nimport org.springframework.cloud.stream.annotation.EnableBinding;\nimport org.springframework.cloud.stream.messaging.Source;\nimport org.springframework.integration.support.MessageBuilder;\nimport org.springframework.messaging.MessageChannel;\n\nimport javax.annotation.Resource;\nimport java.util.UUID;\n\n@EnableBinding(Source.class)   // 定义消息的推送管道\npublic class MessageProviderImpl implements IMessageProvider {\n    @Resource\n    private MessageChannel output; // 消息发送管道\n\n    @Override\n    public String send() {\n        String serial = UUID.randomUUID().toString();\n        output.send(MessageBuilder.withPayload(serial).build());\n        System.out.println(\"*****serial: \"+serial);\n        return null;\n    }\n}\n```\n\n6. Controller：\n\n``` java\nimport com.zhao.springcloud.service.IMessageProvider;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport javax.annotation.Resource;\n\n@RestController\npublic class SendMessageController {\n    @Resource\n    private IMessageProvider messageProvider;\n\n    @GetMapping(value = \"/sendMessage\")\n    public String sendMessage() {\n        return messageProvider.send();\n    }\n}\n```\n\n\n\n \n\n## Stream 消费者模块\n\n新建Module：`cloud-stream-rabbitmq-consumer8802`\n\n1. 导入 Maven 依赖：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-stream-rabbitmq-consumer8802</artifactId>\n    \n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-stream-rabbit</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--基础配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n2. 配置文件\n\n``` yaml\nserver:\n  port: 8802\n\nspring:\n  application:\n    name: cloud-stream-consumer\n\n  # 连接非本机的 RabbitMQ 时，需要单独配置 RabbitMQ，否则会报连接异常，除非关闭健康检查\n  rabbitmq:\n    host: 192.168.1.203\n    port: 5672\n    username: admin\n    password: admin\n\n  cloud:\n    stream:\n      binders:                             # 在此处配置要绑定的rabbitmq的服务信息；\n        defaultRabbit:                     # 表示定义的名称，用于于binding整合\n          type: rabbit                     # 消息组件类型\n          environment:                     # 设置rabbitmq的相关的环境配置\n            spring:\n              rabbitmq:\n                host: 192.168.1.203\n                port: 5672\n                username: admin\n                password: admin\n      bindings:                            # 服务的整合处理\n        output:                            # 这个名字是一个通道的名称\n          destination: studyExchange       # 表示要使用的Exchange名称定义\n          content-type: application/json   # 设置消息类型，本次为json，文本则设置“text/plain”\n          binder: defaultRabbit            # 设置要绑定的消息服务的具体设置\n\neureka:\n  client:    # 客户端进行Eureka注册的配置\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n  instance:\n    lease-renewal-interval-in-seconds: 2      # 设置心跳的时间间隔（默认是30秒）\n    lease-expiration-duration-in-seconds: 5   # 如果现在超过了5秒的间隔（默认是90秒）\n    instance-id: send-8801.com                # 在信息列表时显示主机名称\n    prefer-ip-address: true                   # 访问的路径变为IP地址\n```\n\n3. 主启动类 `StreamMQMain8802`：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class StreamMQMain8802 {\n    public static void main(String[] args) {\n        SpringApplication.run(StreamMQMain8802.class,args);\n    }\n}\n```\n\n4. 业务类使用 `@EnableBinding(Sink.class)`\n\n``` java\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.cloud.stream.annotation.EnableBinding;\nimport org.springframework.cloud.stream.annotation.StreamListener;\nimport org.springframework.cloud.stream.messaging.Sink;\nimport org.springframework.messaging.Message;\nimport org.springframework.stereotype.Component;\n\n@Component\n@EnableBinding(Sink.class)\npublic class ReceiveMessageListenerController {\n    @Value(\"${server.port}\")\n    private String serverPort;\n\n    @StreamListener(Sink.INPUT)\n    public void input(Message<String> message) {\n        System.out.println(\"消费者1号,----->接受到的消息: \"+message.getPayload()+\"\\t  port: \"+serverPort);\n    }\n}\n```\n\n### Stream 消息重复消费\n\n依照服务消费者8802，克隆出来一份运行 `8803 - cloud-stream-rabbitmq-consumer8803`。\n\n依次启动各个服务：\n\n- RabbitMQ 服务端\n- 服务注册中心 - 7001\n- 消息生产者 - 8801\n- 消息消费者 - 8802\n- 消息消费者 - 8803\n\n测试：\n\n- 发送请求 http://localhost:8801/sendMessage\n- 目前是8802/8803同时都收到了消息，存在重复消费问题\n\n解决方案：设置**分组group**\n\n### 生产实际案例\n\n比如在如下场景中，订单系统我们做集群部署，都会从RabbitMQ中获取订单信息，那如果一个订单同时被两个服务获取到，那么就会造成数据错误，我们得避免这种情况。这时我们就可以**使用Stream中的消息分组来解决**。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Stream/f61e83441af907a42e8886368bde59ff.png)\n\n注意在Stream中处于**同一个group中的多个消费者是竞争关系**，就能够保证消息只会被其中一个应用消费一次。不同组是可以全面消费的（重复消费）。\n\n\n\n## 设置分组解决消息重复消费\n\n微服务应用放置于同一个分组group中，就能够保证消息只会被其中一个应用消费一次。**不同的组是可以重复消费的，同一个组内会发生竞争关系**，只有其中一个可以消费默认情况下8802和8803处于不同的分组，因此会发生消息重复消费。\n\n解决方案：**将8802/8803变成相同组**：`group: A_Group`。分别修改8802和8803两个模块的配置文件，添加`group`属性：\n\n``` yaml\nspring:\n  application:\n    name: cloud-stream-provider\n  cloud:\n      stream:\n        binders:                 # 在此处配置要绑定的rabbitmq的服务信息；\n          defaultRabbit:         # 表示定义的名称，用于于binding整合\n            type: rabbit         # 消息组件类型\n            environment:         # 设置rabbitmq的相关的环境配置\n              spring:\n                rabbitmq:\n                  host: localhost\n                  port: 5672\n                  username: guest\n                  password: guest\n        bindings:                             # 服务的整合处理\n          output:                             # 这个名字是一个通道的名称\n            destination: studyExchange        # 表示要使用的Exchange名称定义\n            content-type: application/json    # 设置消息类型，本次为json，文本则设置“text/plain”\n            binder: defaultRabbit             # 设置要绑定的消息服务的具体设置\n            group: A_Group                    # <--------------------关键\n```\n\n将二者的`group`属性均设置为 `A_Group`。此时配置的两个微服务属于相同的组，即8802/8803实现了轮询分组，每次只有一个消费者，8801模块发的消息只能被8802或8803其中一个接收到，这样就避免了重复消费。\n\n**结论：同一个组的多个微服务实例，每次只会有一个拿到**\n\n\n\n\n\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】Spring Cloud Config & Bus","url":"/2021/09/04/【SpringCloud】Config/","content":"\n## Spring Cloud Config 介绍\n\nSpring Cloud Config 是一个分布式**配置中心**。\n\n微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务。由于每个服务都需要必要的配置信息才能运行，所以一套集中式的、动态的配置管理设施是必不可少的。\n\nSpring Cloud Config为微服务架构中的微服务提供集中化的外部配置支持，配置服务器为各个不同微服务应用的所有环境提供了一个**中心化的外部配置**。\n\n> 官网：https://cloud.spring.io/spring-cloud-static/spring-cloud-config/\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Config/d5462e3b8c3a063561f5f8fc7fde327e.png)\n\nSpring Cloud Config分为**服务端**和**客户端**两部分。\n\nConfig 服务端也称为**分布式配置中心**，它是一个独立的微服务应用，**用来连接配置服务器并为客户端提供获取配置信息，加密/解密信息等访问接口**。\n\nConfig 客户端则是**通过指定的配置中心（Config 服务端）来管理应用资源**，以及与业务相关的配置内容，**并在启动的时候从配置中心获取和加载配置信息**。配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理，并且可以通过git客户端工具来方便的管理和访问配置内容。\n\nConfig 客户端是不会主动去 Config 服务端更新配置信息的，而只会在等待运维人员发送 refresh 请求时才会去 Config 服务端请求更新配置信息（或配置消息总线后从消息队列中获取最新配置信息）。\n\n<!-- More -->\n\n### Config 作用\n\n- 集中管理配置文件\n- 不同环境不同配置，动态化的配置更新，分环境部署比如 `dev/test/prod/beta/release`\n- 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息\n- 当配置发生变动时，服务不需要重启即可感知到配置的变化并应用新的配置\n- 将配置信息以REST接口的形式暴露 - `post/crul` 访问刷新即可\n\n**与GitHub整合配置**\n\n由于Spring Cloud Config默认使用Git来存储配置文件（也有其它方式，比如支持SVN和本地文件），但最推荐的还是Git，而且使用的是`http/https`访问的形式。\n\n## Config 配置总控中心搭建\n\n### 创建远程仓库\n\n在Github上创建仓库 `springcloud-config`，其内存储三个不同环境的配置文件\n\n![image-20210905182125710](/images/%E3%80%90SpringCloud%E3%80%91Config/image-20210905182125710.png)\n\n- `config-dev.yml`：\n\n``` yaml\nconfig:\n  info: \"master branch,springcloud-config/config-dev.yml version=1\"\n```\n\n- `config-prod.yml`：\n\n``` yaml\nconfig:\n  info: \"master branch,springcloud-config/config-prod.yml version=1\"\n```\n\n- `config-test.yml`：\n\n``` yaml\nconfig:\n  info: \"master branch,springcloud-config/config-test.yml version=1\" \n```\n\n### 创建配置中心模块\n\n新建Module模块`cloud-config-center-3344`，它即为配置中心模块Cloud Config Center。\n\n1. 导入Maven依赖：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-config-center-3344</artifactId>\n\n    <properties>\n        <maven.compiler.source>8</maven.compiler.source>\n        <maven.compiler.target>8</maven.compiler.target>\n    </properties>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-config-server</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n2. 配置文件：\n\n```yaml\nserver:\n  port: 3344\n\nspring:\n  application:\n    name:  cloud-config-center # 注册进Eureka服务器的微服务名\n  cloud:\n    config:\n      server:\n        git:\n          # 如果uri使用https协议并且仓库为private，需要设置username和password\n          uri: https://github.com/YUYUN-ZHAO/springcloud-config.git\n          # ssh协议：git@github.com:YUYUN-ZHAO/springcloud-config.git #GitHub上面的git仓库名字\n          # 搜索目录\n          search-paths:\n            - springcloud-config\n          username: YUYUN-ZHAO\n          password: zhaoyuyun123.\n      # 读取分支\n      label: master\n\n# 服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n```\n\n3. 主启动类\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.config.server.EnableConfigServer;\n\n@SpringBootApplication\n// 当前微服务作为配置中心服务端\n@EnableConfigServer\npublic class ConfigCenterMain3344 \n    public static void main(String[] args) {\n            SpringApplication.run(ConfigCenterMain3344.class, args);\n    }\n}\n```\n\n4. 测试：\n\n- 启动`ConfigCenterMain3344`\n- 浏览器访问 - http://config-3344.com:3344/master/config-dev.yml\n- 页面返回结果：\n\n``` \nconfig:\n  info: \"master branch,springcloud-config/config-dev.yml version=7\"\n```\n\n上文中的**配置读取规则**见[官方文档](https://cloud.spring.io/spring-cloud-static/spring-cloud-config/2.2.1.RELEASE/reference/html/#_quick_start)。常用规则：`/{label}/{application}-{profile}.yml`\n\n例如`/master/config-dev.yml`对应了配置中心仓库里的`config-test.yaml`文件：\n\n![image-20210905182125710](/images/%E3%80%90SpringCloud%E3%80%91Config/image-20210905182125710.png)\n\n\n\n## Config 客户端搭建\n\n**Config 客户端通过 Config 服务端获取 Github 配置中心仓库里的配置文件。**\n\n1. 创建模块`cloud-config-client-3355`\n2. 导入Maven依赖\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-config-client-3355</artifactId>\n\n    <dependencies>\n        <!--添加消息总线RabbitMQ支持-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-bus-amqp</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-config</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n    \n</project>\n```\n\n3. 添加总配置文件`bootstrap.yml`\n\n``` yaml\nserver:\n  port: 3355\n\nspring:\n  application:\n    name: config-client\n  cloud:\n    # Config 客户端配置\n    config:\n      label: master # 分支名称\n      name: config # 配置文件名称\n      profile: dev # 读取后缀名称——上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml\n      uri: http://localhost:3344 # 配置中心地址\n\n# 服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n```\n\n该配置文件中配置的信息组合起来即为访问http://config-3344.com:3344/master/config-dev.yml，并通过 Config 服务端获取到配置中心仓库里的`config-dev.yaml`文件。\n\n说明：\n\n- `applicaiton.yml`是用户级的资源配置项\n- **`bootstrap.yml`是系统级的配置资源，优先级更加高**\n\nSpring Cloud会创建一个**BootstrapContext**，作为Spring应用的ApplicationContext的父上下文。初始化的时候，BootstrapContext负责从外部源加载配置属性并解析配置。这两个上下文共享一个从外部获取的Environment。\n\n**Bootstrap属性有高优先级**，默认情况下，它们不会被本地配置覆盖。BootstrapContext和ApplicationContext有着不同的约定，所以新增了一个`bootstrap.yml`文件，保证BootstrapContext和ApplicationContext配置的分离。\n\n要将Client模块下的`application.yml`文件改为`bootstrap.yml`，这是很关键的，因为`bootstrap.yml`是比`application.yml`先加载的。**`bootstrap.yml`优先级高于`application.yml`**。\n\n4. 修改`config-dev.yml`配置并提交到GitHub中，比如加个变量`age`或者版本号`version`\n5. 主启动类：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\n\n@EnableEurekaClient\n@SpringBootApplication\npublic class ConfigClientMain3355 {\n    public static void main(String[] args) {\n            SpringApplication.run(ConfigClientMain3355.class, args);\n    }\n}\n```\n\n6. 业务类：\n\n``` java\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.cloud.context.config.annotation.RefreshScope;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n@RestController\n@RefreshScope\npublic class ConfigClientController {\n    @Value(\"${config.info}\")\n    private String configInfo;\n\n    @GetMapping(\"/configInfo\")\n    public String getConfigInfo() {\n        return configInfo;\n    }\n}\n```\n\n7. 测试：启动3355作为Client访问 http://localhost:3355/configlnfo\n\n成功实现了客户端3355访问SpringCloud Config3344通过GitHub获取配置信息\n\n但此时问题在于：每次配置中心仓库的数据修改后，Config 客户端并不会被立即通知，需要重启服务才可以得到最新配置信息。解决方案：\n\n- 通过 `curl` 等命令手动刷新\n- 配置 Bus 消息总线\n\n## 手动刷新 Config 配置\n\n动态刷新步骤：\n\n1. 引入`actuator`监控依赖：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n```\n\n2. 修改YML，添加暴露监控端口配置：\n\n``` yaml\n# 暴露监控端点\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\n```\n\n3. 使用 **@RefreshScope** 注解修饰业务类 Controller，使得其能动态刷新配置文件：\n\n``` java\nimport org.springframework.cloud.context.config.annotation.RefreshScope;\n\n@RestController\n@RefreshScope\npublic class ConfigClientController {\n\t// ...\n}\n```\n\n4. 手动发送命令刷新 Config 客户端：\n\n``` java\n$ curl -X POST \"http://localhost:3355/actuator/refresh\"\n```\n\n\n\n## Spring Cloud Bus 介绍\n\nConfig 客户端是不会主动去 Config 服务端更新配置信息的，而只会在等待运维人员发送 refresh 请求时才会去 Config 服务端请求更新配置信息，此时使用 Spring Cloud Bus 配置消息总线即可实现配置信息的**自动**刷新。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Config/458fd679c01274ca84f785e1f75c1336.png)\n\nSpring Cloud Bus 是用来将分布式系统的节点与轻量级消息系统链接起来的框架，它整合了Java的事件处理机制和消息中间件的功能。Spring Clud Bus 目前支持 RabbitMQ 和 Kafka。\n\nSpring Cloud Bus 能**管理和传播分布式系统间的消息**，就像一个分布式执行器，可用于**广播状态更改**、**事件推送**等，也可以当作微服务间的通信通道。下图中黄色区域即为消息总线，本质上是一个消息队列，当收到更新配置的消息后通知所有的 Config 客户端更新最新配置：\n\n![image-20210909211926572](/images/%E3%80%90SpringCloud%E3%80%91Config/image-20210909211926572.png)\n\n### 基本原理\n\n在微服务架构的系统中，通常会使用轻量级的消息代理来构建一个共用的**消息主题**，并让系统中所有微服务实例都连接上来。由于**该主题中产生的消息会被所有实例监听和消费，所以称它为消息总线**。在总线上的各个实例，都可以方便地广播一些需要让其他连接在该主题上的实例都知道的消息。\n\n所有ConfigClient实例都监听MQ中同一个topic（在RabbitMQ中为某个交换机）。当一个服务刷新数据的时候，它会把这个信息放入到Topic中，这样其它监听同一Topic的服务就能得到通知，然后去更新自身的配置。\n\n### 工作流程\n\n1. 配置中心 Config Server 从GitHub仓库中读取配置信息保；向RabbitMQ服务端注册一个交换机，其他 Config Client 注册的消息队列都将绑定这个交换机；\n2. 所有 Config Client 从 Config Server 拉取到配置信息；每个 Config Client 都将创建一个消息队列，与 Config Server 注册的交换机进行绑定，并一直监听其刷新消息\n3. 运维人员修改GitHub仓库里的配置消息\n4. 发送 Post 请求到 Config Server，通知其配置信息需要更新\n5. Config Server 作为消息生产者发送刷新消息到RabbitMQ服务端的交换机\n6. 交换机将该消息发送到对应的队列中（默认是发送到所有消息队列，若设置了目标客户端的名称规则，则只会发送到对应的队列中）\n7. 发现消息队列中出现刷新事件的 Config Client 将主动拉去 Config Server 中的配置信息，从而完成自动更新配置信息\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Config/ccd5fcc8293edec24d7e889e189d0bfe.png)\n\n\n\n## Bus 之 RabbitMQ 环境配置\n\n新建 `cloud-config-client-3366`\n\n1. 导入 Maven 依赖：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>LearnCloud</artifactId>\n        <groupId>com.lun.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-config-client-3366</artifactId>\n\n    <dependencies>\n        <!--添加消息总线RabbitMQ支持-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-bus-amqp</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-config</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n</project>\n```\n\n2. 配置文件：\n\n``` yaml\nserver:\n  port: 3366\n\nspring:\n  application:\n    name: config-client\n  cloud:\n    # Config 客户端配置\n    config:\n      label: master     # 分支名称\n      name: config      # 配置文件名称\n      profile: dev      # 读取后缀名称  上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml\n      uri: http://localhost:3344 # 配置中心地址\n\n  # rabbitmq相关配置 15672是Web管理界面的端口；5672是MQ访问的端口\n  rabbitmq:\n    host: localhost\n    port: 5672\n    username: guest\n    password: guest\n\n# 服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n\n# 暴露监控端点\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\n```\n\n3. 主启动类：\n\n``` java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\n\n@EnableEurekaClient\n@SpringBootApplication\npublic class ConfigClientMain3366 {\n    public static void main(String[] args) {\n        SpringApplication.run(ConfigClientMain3366.class,args);\n    }\n}\n```\n\n5. Controller：\n\n``` java\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.cloud.context.config.annotation.RefreshScope;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\n/**\n */\n@RestController\n@RefreshScope\npublic class ConfigClientController {\n    @Value(\"${server.port}\")\n    private String serverPort;\n\n    @Value(\"${config.info}\")\n    private String configInfo;\n\n    @GetMapping(\"/configInfo\")\n    public String configInfo() {\n        return \"serverPort: \"+serverPort+\"\\t\\n\\n configInfo: \"+configInfo;\n    }\n}\n```\n\n## Bus 架构选型\n\n### 架构思想一\n\n利用消息总线触发一个客户端 `/bus/refresh`，而刷新所有客户端的配置：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Config/3a0975f4bac7393fe406821531e9daef.png)\n\n### 架构思想二\n\n利用消息总线触发一个服务端 ConfigServer 的 /`bus/refresh` 端点，而刷新所有客户端的配置：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Config/e2809f728b8eb3e776883e4f905b8712.png)\n\n架构思想二的架构显然更加适合，架构思想—不适合的原因如下：\n\n- 打破了微服务的职责单一性，因为微服务本身是业务模块，它本不应该承担配置刷新的职责。\n- 破坏了微服务各节点的对等性。\n- 有一定的局限性。例如，微服务在迁移时，它的网络地址常常会发生变化，此时如果想要做到自动刷新，那就会增加更多的修改。\n\n下文将介绍架构思想二下的案例。\n\n## Bus 动态刷新全局广播配置实现\n\n给上文中构建的 `cloud-config-center-3344` 配置中心服务端 Config Server 添加消息总线支持。\n\n1. 导入 Maven 依赖：\n\n``` xml\n<!--添加消息总线RabbitNQ支持-->\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-bus-amap</artifactId>\n</dependency>\n<dependency>\n\t<groupId>org-springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n```\n\n2. 配置文件\n\n``` yaml\nserver:\n  port: 3344\n\nspring:\n  application:\n    name:  cloud-config-center # 注册进Eureka服务器的微服务名\n  cloud:\n    config:\n      server:\n        git:\n          uri: https://github.com/YUYUN-ZHAO/springcloud-config.git # GitHub上面的git仓库名字\n        # 搜索目录\n          search-paths:\n            - springcloud-config\n          username: YUYUN-ZHAO\n          password: zhaoyuyun123.\n      # 读取分支\n      label: master\n      \n# rabbitmq相关配置\nrabbitmq:\n    host: localhost\n    port: 5672\n    username: guest\n    password: guest\n\n# 服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n\n# rabbitmq相关配置, 暴露bus刷新配置的端点\nmanagement:\n  endpoints: # 暴露bus刷新配置的端点\n    web:\n      exposure:\n        include: 'bus-refresh'\n```\n\n给`cloud-config-client-3355`客户端添加消息总线支持。\n\n1. 导入 Maven 依赖：\n\n``` xml\n<!--添加消息总线RabbitNQ支持-->\n<dependency>\n\t<groupId>org.springframework.cloud</groupId>\n\t<artifactId>spring-cloud-starter-bus-amap</artifactId>\n</dependency>\n<dependency>\n\t<groupId>org-springframework.boot</groupId>\n\t<artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n```\n\n2. 配置文件\n\n``` yaml\nserver:\n  port: 3355\n\nspring:\n  application:\n    name: config-client\n  cloud:\n    #Config客户端配置\n    config:\n      label: master    # 分支名称\n      name: config     # 配置文件名称\n      profile: dev     # 读取后缀名称  上述3个综合：master分支上config-dev.yml的配置文件被读取http://config-3344.com:3344/master/config-dev.yml\n      uri: http://localhost:3344  # 配置中心地址k\n\n# rabbitmq相关配置 15672是Web管理界面的端口；5672是MQ访问的端口\n  rabbitmq:\n    host: localhost\n    port: 5672\n    username: guest\n    password: guest\n\n# 服务注册到eureka地址\neureka:\n  client:\n    service-url:\n      defaultZone: http://localhost:7001/eureka\n\n# 暴露监控端点\nmanagement:\n  endpoints:\n    web:\n      exposure:\n        include: \"*\"\n```\n\n添加了消息总线和RabbitMQ配置后，再修改Github上配置文件内容，只需要给 Config Server 发送一次刷新消息即可实现所有Config客户端更新消息：\n\n``` bash\ncurl -X POST \"http://localhost:3344/actuator/bus-refresh\"\n```\n\n## Bus 动态刷新定点通知\n\n若只想通知部分Config Client更新消息，只需在发送刷新消息时遵循规则：`http://localhost:3344/actuator/bus-refresh/{destination}`\n\n此时 `/bus/refresh` 请求不再发送到具体的服务实例上，而是发给Config sServer通过`destination`参数类指定需要更新配置的服务或实例，示例：\n\n``` bash\ncurl -X POST \"http://localhost:3344/actuator/bus-refresh/config-client:3355\n```\n\n其代表只发给端口号为3355的应用名为 `config-client` 的配置客户端。\n\n总结：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Config/ccd5fcc8293edec24d7e889e189d0bfe.png)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【RabbitMQ】RabbitMQ 基础","url":"/2021/08/31/【RabbitMQ】RabbitMQ/","content":"\n![image-20210831143417355](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210831143417355.png)\n\n## MQ 简介\n\n### 什么是 MQ\n\nMQ (message queue)，从字面意思上看，本质是个队列，FIFO 先入先出，只不过队列中存放的内容是 message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中，MQ 是一种非常常见的上下游 “逻辑解耦 + 物理解耦” 的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不用依赖其他服务，由MQ将消息发送给下游消费者。\n\n### 为什么要用 MQ\n#### 流量消峰\n\n举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。\n\n#### 应用解耦\n\n以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在 这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。\n\n![image-20210831215725573](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210831215725573.png)\n\n#### 异步处理\n\n有些服务间调用是异步的，例如 A 调用 B，B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完。\n\n以前一般有两种方式，A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅。\n\n使用消息总线，可以很方便解决这个问题， A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ，MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样 B 服务也不用做这些操作，A 服务还能及时的得到异步处理成功的消息。\n\n![image-20210831215804163](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210831215804163.png)\n\n<!-- More -->\n\n### MQ 的分类\n#### ActiveMQ\n- 优点：单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，较低的概率丢失数据。\n- 缺点：官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。\n\n#### Kafka\n\n大数据的杀手锏，谈到大数据领域内的消息传输，则绕不开 Kafka，这款为**大数据**而生的消息中间件，以其百万级 TPS 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn，Uber, Twitter, Netflix 等大公司所采纳。\n\n- 优点：性能卓越，单机写入 TPS 约在百万条 / 秒，**最大的优点，就是吞吐量高**。时效性 ms 级，可用性非常高，kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用，消费者采用 Pull 方式获取消息，消息有序，通过控制能够保证所有消息被消费且仅被消费一次；有优秀的第三方 Kafka Web 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用。\n- 缺点：Kafka 单机超过 64 个队列 / 分区，Load 会发生明显的飙高现象，队列越多，load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；支持消息顺序，但是一台代理宕机后，就会产生消息乱序，**社区更新较慢**。\n\n#### RocketMQ\n\nRocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一 些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理，binglog 分发等场景。\n\n- 优点：**单机吞吐量十万级**，可用性非常高，分布式架构，消息可以做到 0 丢失，MQ 功能较为完善，还是分布式的，扩展性好，支持 10 亿级别的消息堆积，不会因为堆积导致性能下降。\n- 缺点：支持的客户端语言不多，目前是 java 及 c++，其中 c++ 不成熟；社区活跃度一般，没有在 MQ 核心中去实现 JMS 等接口，有些系统要迁移需要修改大量代码。\n\n#### RabbitMQ\n\n2007 年发布，是一个在 AMQP (高级消息队列协议) 基础上完成的，可复用的企业消息系统，**是当前最主流的消息中间件之一**。\n\n- 优点：由于 erlang 语言的高并发特性，性能较好；吞吐量到万级，MQ 功能比较完备，健壮、稳定、易用、跨平台、支持多种语言。如：Python、Ruby、.NET、Java、JMS、C、PHP、ActionScript、XMPP、STOMP 等，AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用，社区活跃度高；更新频率相当高。\n- 缺点：商业版需要收费，学习成本较高。\n\n### MQ 的选择\n\n#### Kafka\n\nKafka 主要特点是基于 Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。\n\n#### RocketMQ\n\n天生为**金融互联网**领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。\n\n#### RabbitMQ\n\n结合 erlang 语言本身的并发优势，性能好时效性微秒级，社区活跃度也比较高，管理界面用起来十分方便，如果你的**数据量没有那么大**，中小型公司优先选择功能比较完备的 RabbitMQ。\n\n> https://zhangc233.github.io/2021/07/23/RabbitMQ/\n\n许多消息中间件底层就是用JUC包下的阻塞队列**BlockingQueue**实现的。\n\n## RabbitMQ 简介\n\n### RabbitMQ 的概念\n\n> https://zhangc233.github.io/2021/07/23/RabbitMQ/ \n\nRabbitMQ是一个**异步消息**通信中间件，用erlang语言开发，实现了AMQP（Advanced Message Queue ）协议，是一个开源产品，官方网站：http://www.rabbitmq.com/\n\nRabbitMQ 是一个消息中间件，它**接受并转发**消息。你可以把它当做一个快递站点，当你要发送一个包裹时，你把你的包裹放到快递站，快递员最终会把你的快递送到收件人那里，按照这种逻辑 RabbitMQ 是 一个快递站，一个快递员帮你传递快件。\n\n但RabbitMQ 与快递站的主要区别在于，**它不处理快件，而是接收，存储和转发消息数据**。\n\n![image-20210831220251162](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210831220251162.png)\n\n### 四大核心概念\n\n- **生产者**：产生数据发送消息的程序。\n- **交换机**：是 RabbitMQ 非常重要的一个部件，**一方面它接收来自生产者的消息，另一方面它将消息推送到队列中**。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定。\n- **队列**：队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。\n- **消费者**：大多时候是一个等待接收消息的程序。请注意**生产者，消费者和消息中间件很多时候并不在同一机器上**。同一个应用程序既可以是生产者又是可以是消费者。\n\n**四者关系**：\n\n- **生产者只将消息发给交换机**，至于该交换机将消息发送给了哪个队列其是不知道的（通常将绑定的工作放到 Spring 的 `@Configuration` 配置类里，从而与生产者解耦，生产者本身并不知道绑定信息）\n- **消费者只从队列获取消息**，至于该消息来自哪个交换机其是不知道的\n- 交换机和队列是有对应的绑定关系的，通常在Spring的`@Configuration`配置类里进行配置，生产者和消费者对此并不知情，也无需知道，\n\n### RabbitMQ 工作原理\n\n![image-20210831220420923](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210831220420923.png)\n\n- **Broker**：**接收**和**分发**消息的应用，就是 RabbitMQ 服务器。\n- **Virtual host**：出于多用户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／queue 等。\n- **Connection**：publisher／consumer 和 broker 之间的 TCP 连接。\n- **Channel**：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯，AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。**Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销**。\n- **Exchange**：message 到达 broker 的第一站，根据分发规则，匹配查询表中的 `routing key`，分发消息到 queue 中去。常用的类型有：`direct (point-to-point)`，`topic (publish-subscribe)` and `fanout (multicast)`。\n- **Queue**：消息最终被送到这里等待 consumer 取走。\n- **Binding**：exchange 和 queue 之间的虚拟连接，binding 中可以包含 `routing key`，Binding 信息被保存到 exchange 中的查询表中，用于 message 的分发依据。\n\n其中，交换机和队列存储在 RabbitMQ 服务器内，生产者和消费者在其他服务器，二者通过声明的方式在 RabbitMQ 服务器内创建相应的交换机和队列。\n\n### 工作流程\n\n**生产者工作流程**：\n\n1. 生产者建立与 RabbitMQ 服务器的 Connection 连接并创建一个 Channel 与其通讯\n2. 生产者声明若干交换机与队列，声明后，RabbitMQ 服务器中将创建这些交换机与队列（`queueDeclare()`）\n3. 生产者绑定交换机与队列，即指定交换机与队列间的`routing key`与映射类型（`queueBind()`）\n4. 生产者向 RabbitMQ 服务器发送消息（`basicPublish()`）\n5. 生产者可以设置通道为[发布确认](#发布确认)模式 （`confirmSelect()`），这样 RabbitMQ 服务器在收到生产者发送的数据后会回调通知生产者，生产者异步地接收这些回调消息，从而得知当前消息是否被 RabbitMQ 服务器的交换机所接收到，若 RabbitMQ 服务器宕机生产者也可以即使得知，避免消息丢失 \n6. 仅开启发布确认模式只能得知当前消息是否被 RabbitMQ 服务器的交换机所接收到，而不能得知该消息能否成功传递到队列（若生产者发送了错误的 `routing key` 导致消息无法往下传递， RabbitMQ 服务器会将该消息删除而生产者并不知情），因此需要开启[回退消息](#回退消息)功能，在当消息传递过程中不可达目的地时将消息返回给生产者，通知生产者消息发送失败，考虑重新发送。通常[发布确认](发布确认)和[回退消息](#回退消息)一起使用，保证生产者发送的消息不能被顺利传递时能够被及时通知。\n\n**消费者工作流程**：\n\n1. 消费者建立与 RabbitMQ 服务器的 Connection 连接并创建一个 Channel 与其通讯\n2. 消费者指定监听哪个队列（`basicConsume()`），并设置接收消息成功/失败的回调方法（`Callback`）\n3. 消费者接收到消息后进行[消息应答](#消息应答)（`basicAck()`）：通知 RabbitMQ 服务器该消息已经成功接受，此时才将该消息从队列中删除\n4. 消费者可以设置[预期值分发](#预取值分发)（`basicQos()`），一次性从队列中获取多条消息进行异步消费\n\n**RabbitMQ 服务器工作流程**：\n\n1. 与 RabbitMQ 客户端（生产者与消费者）建立TCP连接\n2. 创建生产者与消费者声明的交换机与队列，并根据`routing key`与映射类型将其进行绑定\n3. 当交换机收到生产者发来的消息时，将此消息按照`routing key`分发到对应的队列中\n4. 队列中的消息将逐个转发到对应的消费者。注意，**一个消息只能被消费一次**。这个队列所对应的N个消费者将按照某种规则（例如轮询）消费该消息。例如该队列中共有4条消息，有两个消费者监听该队列，那么这两个消费者将分别消费2条消息\n5. 当 RabbitMQ 服务器接收到消费者传来的消息应答后，若消费者确认收到消息（`basicAck ()`），则将该消息从队列中删除；若消费者拒绝收到消息（`basicReject ()`），同样将其从队列中删除；若消费者长时间未回复消息应答，则将该[消息重新入队](#消息重新入队)\n6. 若 RabbitMQ 服务器判断得知某条消息成为死信（例如消息被拒绝、消息到期或队列达到最大长度），则将其路由到对应的[死信队列](#死信队列)，死信队列里的消息将由监听其的消费者消费\n7. 发送到[延迟队列](#延迟队列)里面的消息在阻塞一定时间后才会被放到死信队列里被相应的消费者消费（例如取消订单）\n\n## 安装 RabbitMQ\n\n> Linux上安装过程见[Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\n### RabbitMQ 端口\n\n- **15672：Web图形化管理界面端口**\n- **5672：AMQP协议的端口号**\n\n### 常用命令\n\n```sh\n# 启动服务\nsystemctl start rabbitmq-server\n\n# 查看服务状态\nsystemctl status rabbitmq-server\n\n# 开机自启动\nsystemctl enable rabbitmq-server\n\n# 停止服务\nsystemctl stop rabbitmq-server\n\n# 重启服务\nsystemctl restart rabbitmq-server\n```\n\n### Web 管理界面及授权操作\n\n1. 安装：\n\n```sh\nrabbitmq-plugins enable rabbitmq_management\n```\n\n2. 安装完毕以后，重启服务：\n\n```sh\nsystemctl restart rabbitmq-server\n```\n\n3. 访问 http://xxx.xxx.xxx.xxx:15672 ，用默认账号密码 (guest) 登录，出现权限问题，需要添加一个远程登录的用户：\n\n```sh\n# 创建账号和密码\nrabbitmqctl add_user admin 123456\n\n# 设置用户角色\nrabbitmqctl set_user_tags admin administrator\n\n# 为用户添加资源权限  添加配置、写、读权限\n# set_permissions [-p <vhostpath>] <user> <conf> <write> <read>\nrabbitmqctl set_permissions -p \"/\" admin \".*\" \".*\" \".*\"\n```\n\n用户级别：\n\n- **administrator**：可以登录控制台、查看所有信息、可以对 rabbitmq 进行管理。\n- **monitoring**：监控者 登录控制台，查看所有信息。\n- **policymaker**：策略制定者 登录控制台，指定策略。\n- **managment**：普通管理员 登录控制台。\n\n### Web 应用相关命令\n\n- 关闭Web应用的命令为：`rabbitmqctl stop_app`\n- 清除的命令为：`rabbitmqctl reset`\n- 重新启动命令为：`rabbitmqctl start_app`\n\n## RabbitMQ Hello World\n\n导入相关Maven依赖：\n\n```xml\n<dependencies>\n    <!--rabbitmq 依赖客户端-->\n    <dependency>\n        <groupId>com.rabbitmq</groupId>\n        <artifactId>amqp-client</artifactId>\n        <version>5.8.0</version>\n    </dependency>\n    <!--操作文件流的一个依赖-->\n    <dependency>\n        <groupId>commons-io</groupId>\n        <artifactId>commons-io</artifactId>\n        <version>2.6</version>\n    </dependency>\n</dependencies>\n```\n\n生产者：\n\n```java\npackage com.zhao;\n\nimport com.rabbitmq.client.*;\n\npublic class Producer {\n    private final static String QUEUE_NAME = \"queue-01\";\n    private static final String EXCHANGE_NAME = \"exchange-01\";\n\n\n    public static void main(String[] args) throws Exception {\n        // 创建一个连接工厂\n        ConnectionFactory factory = new ConnectionFactory();\n        factory.setHost(\"42.192.149.71\");\n        factory.setUsername(\"admin\");\n        factory.setPassword(\"123456\");\n\n        // 创建连接\n        Connection connection = factory.newConnection();\n        // 获取信道：channel 实现了自动 close 接口，不需要手动关闭\n        Channel channel = connection.createChannel();\n\n        // 声明一个交换机并指定类型为 direct\n        channel.exchangeDeclare(EXCHANGE_NAME, \"direct\");\n\n        /**\n         * 生成一个队列\n         * 1.队列名称\n         * 2.队列里面的消息是否持久化：是否用完就删除该消息，true：需要持久化\n         * 3.该队列是否只供一个消费者进行消费：是否是独家的，false：不是独家的，可以多个消费者消费\n         * 4.是否自动删除：最后一个消费者断开连接以后，该队列是否自动删除，true：自动删除\n         * 5.其他参数，例如配置死信交换机key等参数\n         */\n        channel.queueDeclare(QUEUE_NAME, true, false, false, null);\n\n        // 将队列和交换机进行绑定，并指定 routing key 为 \"info\"，这样发布消息时将根据 \"info\" 找到对应的队列\n        channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, \"info\");\n\n        String message = \"hello world\";\n\n        /**\n         * 发送一个消息\n         * 1.发送到那个交换机\n         * 2.发送的交换机要路由到队列的routing-key，交换机将使用该值找到对应的队列，若该队列不存在将抛异常\n         * 3.其他的参数信息，例如设置消息的优先级或到期时间expiration\n         * 4.发送消息的消息体\n         */\n        channel.basicPublish(EXCHANGE_NAME,  \"info\", null, message.getBytes());\n        System.out.println(\"消息发送完毕\");\n    }\n}\n```\n\n生产者声明了交换机和队列并进行绑定（设置`routingKey`为`\"info\"`），二者将由 RabbitMQ 服务器创建并维护。生产者将消息发往指定的交换机后，RabbitMQ 服务器将根据传入的`routingKey`找到对应的队列，将消息放入其中，等待消费者消费该队列中的消息。\n\n消费者：\n\n```java\npackage com.zhao;\n\nimport com.rabbitmq.client.*;\n\npublic class Consumer {\n    private final static String QUEUE_NAME = \"queue-01\";\n\n    public static void main(String[] args) throws Exception {\n        ConnectionFactory factory = new ConnectionFactory();\n        factory.setHost(\"42.192.149.71\");\n        factory.setUsername(\"admin\");\n        factory.setPassword(\"123456\");\n\n        Connection connection = factory.newConnection();\n        Channel channel = connection.createChannel();\n\n        // 预取值分发，当前消费者能同时异步地消费6条消息\n        int prefetchCount = 6;\n        channel.basicQos(prefetchCount);\n\n        System.out.println(\"等待接收消息.........\");\n\n        // 消费者成功消费的回调：处理队列中传来的消息\n        DeliverCallback deliverCallback = (consumerTag, delivery) -> {\n            // 获取消息内容\n            String message = new String(delivery.getBody());\n            System.out.println(\"接收到消息:\" + message);\n\n            // 消息应答：手动回复 RabbitMQ 服务器已收到消息，可以从队列中删除\n            // 获取到当前的消息编号Tag，只应答其自己，不批量应答\n            channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);\n        };\n\n        // 消费者取消消费的回调：如在消费的时候队列被删除掉了\n        CancelCallback cancelCallback = (consumerTag) -> {\n            System.out.println(\"消息消费被中断\");\n        };\n\n        /**\n         * 消费者消费消息 - 接受消息\n         * 1.消费哪个队列\n         * 2.消费成功之后是否要自动应答：true代表自动应答，false代表手动应答\n         * 3.消费者成功消费的回调\n         * 4.消费者取消消费的回调\n         */\n        channel.basicConsume(QUEUE_NAME, false, deliverCallback, cancelCallback);\n    }\n}\n```\n\n消费者将根据队列名从 RabbitMQ 服务器找到对应的队列，从中获取消息，设置了预取值分发则会同时异步地消费多条消息。\n\n## 预取值分发\n\n**一个消息只能被消费一次**。\n\n默认情况下，消费者采用**轮询**的方式进行消费：例如某队列中共有4条消息，有两个消费者监听该队列，那么这两个消费者将进行轮询消费，各自消费2条消息：\n\n![image-20210903203642528](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903203642528.png)\n\n但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮询分发的话，处理速度快的消费者很大一部分时间处于空闲状态（在等待另一个消费者消费完自己才能消费下一个消息），而处理慢的那个消费者一直在干活，此时轮询分配方式就不太好。\n\n为了避免这种情况，在消费者中消费之前，可以为每个消费者设置**预取值分发**，即预先取出一部分数量的消息进行消费。设置方法为：\n\n```java\n// 预取值分发，当前消费者能同时异步地消费6条消息\nint prefetchCount = 6;\nchannel.basicQos(prefetchCount);\n```\n\n通俗来讲，如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 RabbitMQ 就会把该任务分配给没有那么忙的那个空闲消费者。这样就可以根据服务器性能的不同事先设置好`prefetchCount`的值。\n\n当然如果所有的消费者都没有完成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。\n\n### 带权的消息分发\n\n本身消息的发送就是**异步**发送的，所以在任何时候，channel 上肯定不止只有一个消息，另外来自消费者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区，因此希望开发人员能**限制此缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题**。这个时候就可以通过使用 basic.qos 方法设置 “预取计数” 值来完成的。\n\n该值定义通道上允许的未确认消息的最大数量。一旦数量达到配置的数量， RabbitMQ 将停止在通道上传递更多消息，除非至少有一个未处理的消息被确认，例如，假设在通道上有未确认的消息 5、6、7，8，并且通道的预取计数设置为 4，此时 RabbitMQ 将不会在该通道上再传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag=6 这个消息刚刚被确认 ACK，RabbitMQ 将会感知这个情况到并再发送一条消息。消息应答和 QoS 预取值对用户吞吐量有重大影响。\n\n通常，增加预取值将提高向消费者传递消息的速度。**虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的 RAM 消耗**。应该小心使用具有无限预处理的自动确认模式或手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的内存消耗变大，所以找到合适的预取值是一个反复试验的过程，不同的负载该值取值也不同 100 到 300 范围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。\n\n预取值为 1 是最保守的。当然这将使吞吐量变得很低，特别是消费者连接延迟很严重的情况下，特别是在消费者连接等待时间较长的环境 中。对于大多数应用来说，稍微高一点的值将是最佳的。\n\n![image-20210903205627257](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903205627257.png)\n\n## 消息应答\n\n> 消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况？\n\n假设 RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息以及后续发送给该消费者的消息，因为它无法接收到。\n\n为了保证消息在发送过程中不丢失，引入**消息应答机制：消费者在接收到消息并且处理该消息之后，告诉 RabbitMQ 它已经处理完成了，RabbitMQ 服务器可以从队列中将该消息删除了。**\n\n### 自动应答\n\n消息发送后立即被认为已经传送成功，这种模式需要在**高吞吐量和数据传输安全性方面做权衡**，因为这种模式如果消息在接收到之前，消费者那边出现连接或者 Channel 关闭，那么消息就丢失了。当然另一方面这种模式消费者那边可以传递过载的消息，没有对传递的消息数量进行限制，当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，使得内存耗尽，最终这些消费者线程被操作系统杀死，所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。\n\n### 手动消息应答\n\n手动应答的好处是可以**批量应答**并且减少网络拥堵 ，其分为以下三类：\n\n- `Channel.basicAck` (用于肯定确认)：RabbitMQ 已知道该消息成功被处理，可以将其丢弃了。\n- `Channel.basicNack` (用于否定确认)\n- `Channel.basicReject` (用于否定确认)：与 `Channel.basicNack` 相比少一个参数，不处理该消息了，直接拒绝，可以将其丢弃了。\n\n**Multiple** 的解释：\n\n![image-20210903204201626](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903204201626.png)\n\n- true 代表批量应答 channel 上未应答的消息：比如说 channel 上有传送 tag 的消息 5、6、7、8， 当前 tag 是 8 那么此时 5-8 的这些还未应答的消息都会被确认收到消息应答。\n- false 同上面相比只会应答 tag=8 的消息， 5、6、7 这三个消息依然不会被确认收到消息应答。\n\n![image-20210903204307310](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903204307310.png)\n\n消费者设置消息手动应答：\n\n```java\nDeliverCallback deliverCallback = (consumerTag, delivery) -> {\n    // 获取消息内容\n    String message = new String(delivery.getBody());\n    System.out.println(\"接收到消息:\" + message);\n\n    // 消息应答：手动回复 RabbitMQ 服务器已收到消息，可以从队列中删除\n    // 获取到当前的消息编号Tag，只应答其自己，不批量应答\n    channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);\n};\n\nchannel.basicConsume(QUEUE_NAME, false, deliverCallback, cancelCallback);\n```\n\n### 消息重新入队\n\n如果消费者由于某些原因失去连接 (其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认，RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。\n\n![image-20210903204350479](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903204350479.png)\n\n测试消息重新入队：\n\n正常情况下消息发送方发送两个消息，C1 和 C2 分别接收到消息并进行处理。\n\n\n![image-20210903204919165](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903204919165.png)\n\n在发送者发送消息 dd，发出消息之后的把 C2 消费者停掉，按理说该 C2 来处理该消息，但是由于它处理时间较长，在还未处理完，也就是说 C2 还没有执行 ack 代码的时候，C2 被停掉了，此时会看到消息被 C1 接收到了，说明消息 dd 被重新入队，然后分配给能处理消息的 C1 处理了。\n\n![image-20210903204940385](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903204940385.png)\n\n## 消息/队列持久化\n\n当 RabbitMQ 服务停掉以后，消息生产者发送过来的消息不丢失要如何保障？默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事：我们需要将队列和消息都标记为持久化。\n\n### 队列持久化\n\n之前创建的队列都是非持久化的，RabbitMQ 如果重启的话，该队列就会被删除掉，如果要队列实现持久化需要在声明队列的时候把 `durable` 参数设置为持久化。\n\n```java\n// 让队列持久化\nboolean durable = true;\n// 声明队列\nchannel.queueDeclare(QUEUE_NAME, durable, false, false, null);\n```\n\n注意：如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误。\n\n### 消息持久化\n\n消息实现持久化需要在消息**生产者**修改代码，`MessageProperties.PERSISTENT_TEXT_PLAIN` 添加这个属性。\n\n\n![image-20210903205243652](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903205243652.png)\n\n将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备存储在磁盘的时候但是还没有存储完，消息还在缓存的一个间隔点。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。\n\n\n\n## 发布确认\n\n**发布确认是为了确保生产者发送的消息能够被 RabbitMQ 服务器接收到，若 RabbitMQ 服务器宕机无法接收消息，则生产者能及时察觉到，从而重新发送消息，防止消息丢失时生产者无法察觉。**\n\n生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式，所有在该信道上面发布的消息都将会被指派一个唯一的 ID (从 1 开始)，一旦消息被投递到所有匹配的队列之后，broker 就会发送一个确认给生产者 (包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出，broker 回传给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置 basic.ack 的 multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。\n\nconfirm 模式最大的好处在于它是**异步**的，**一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息**，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息， 生产者应用程序同样可以在回调方法中处理该 nack 消息。\n\n开启发布确认的方法：发布确认默认是没有开启的，如果要开启，需要调用方法 `confirmSelect()`：\n\n```java\n// 开启发布确认\nchannel.confirmSelect();\n```\n\n### 单个确认发布策略\n\n这是一种简单的确认方式，它是一种**同步确认发布**的方式，**也就是发布一个消息之后只有它被确认发布，后续的消息才能继续发布**，`waitForConfirmsOrDie(long)` 这个方法只有在消息被确认的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。\n\n这种确认方式有一个最大的缺点就是：**发布速度特别的慢**，因为如果没有确认发布的消息就会阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某些应用程序来说这可能已经足够了。\n\n此模式下，生产者将等待服务端返回确认消息程序才会继续执行，若服务端返回 false 或超时时间内未返回，则生产者可以消息重发。生产者端配置方式：\n\n``` java\nfor (int i = 0; i < MESSAGE_COUNT; i++) {\n    String message = i + \"\";\n    channel.basicPublish(\"\", queueName, null, message.getBytes());\n    \n    // 服务端返回 false 或超时时间内未返回，生产者可以消息重发\n    boolean flag = channel.waitForConfirms();\n    if (flag) {\n        System.out.println(\"消息发送成功\");\n    }\n}\n```\n\n### 批量确认发布策略\n\n上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地提高吞吐量，当然这种方式的缺点就是：当发生故障导致发布出现问题时，不知道是哪个消息出问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种方案仍然是同步的，也一样阻塞消息的发布。\n\n```java\n/**\n * 批量\n */\npublic static void publishMessageBatch() throws Exception {\n    Channel channel = RabbitMqUtils.getChannel();\n    //队列声明\n    String queueName = UUID.randomUUID().toString();\n    channel.queueDeclare(queueName, true, false, false, null);\n    //开启发布确认\n    channel.confirmSelect();\n    //批量确认消息大小\n    int batchSize = 100;\n    //未确认消息个数\n    int outstandingMessageCount = 0;\n    long begin = System.currentTimeMillis();\n\n    for (int i = 0; i < MESSAGE_COUNT; i++) {\n        String message = i + \"\";\n        channel.basicPublish(\"\", queueName, null, message.getBytes());\n        outstandingMessageCount++;\n        if (outstandingMessageCount == batchSize) {\n            channel.waitForConfirms();\n            outstandingMessageCount = 0;\n        }\n    }\n    //为了确保还有剩余没有确认消息 再次确认\n    if (outstandingMessageCount > 0) {\n        channel.waitForConfirms();\n    }\n    long end = System.currentTimeMillis();\n    System.out.println(\"发布\" + MESSAGE_COUNT + \"个批量确认消息,耗时\" + (end - begin) + \"ms\");\n}\n```\n\n### 异步确认发布策略\n\n异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都很高， 它是利用**回调函数**来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功。\n\n![image-20210903210632247](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903210632247.png)\n\n如何处理异步未确认消息？最好的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列， 比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传递。\n\n```java\npublic static void publishMessageAsync() throws Exception {\n    try (Channel channel = RabbitMqUtils.getChannel())\n    {\n        String queueName = UUID.randomUUID().toString();\n        channel.queueDeclare(queueName, false, false, false, null);\n        //开启发布确认\n        channel.confirmSelect();\n\n        /**\n         * 线程安全有序的一个哈希表，适用于高并发的情况\n         * 1.轻松的将序号与消息进行关联\n         * 2.轻松批量删除条目 只要给到序列号\n         * 3.支持并发访问\n         */\n        ConcurrentSkipListMap<Long, String> outstandingConfirms = new\n            ConcurrentSkipListMap<>();\n        \n        /**\n         * 确认收到消息的一个回调\n         * 1.sequenceNumber：消息序列号\n         * 2.multiple：批量消息应答，true 可以确认小于等于当前序列号的消息，false 确认当前序列号消息\n         */\n        ConfirmCallback ackCallback = (sequenceNumber, multiple) -> {\n            if (multiple) {\n                // 返回的是小于等于当前序列号的未确认消息 是一个 Map，其是原 Map 的一个浅拷贝，修改其即可修改原 Map\n                ConcurrentNavigableMap<Long, String> confirmed =\n                    outstandingConfirms.headMap(sequenceNumber, true);\n                // 清除该部分未确认消息\n                confirmed.clear();\n            }else{\n                //只清除当前序列号的消息\n                outstandingConfirms.remove(sequenceNumber);\n            }\n        };\n        \n        ConfirmCallback nackCallback = (sequenceNumber, multiple) ->\n        {\n            String message = outstandingConfirms.get(sequenceNumber);\n            System.out.println(\"发布的消息\"+message+\"未被确认，序列号\"+sequenceNumber);\n        };\n\n        /**\n         * 添加一个异步确认的监听器\n         * 1.确认收到消息的回调\n         * 2.未收到消息的回调 null\n         */\n        channel.addConfirmListener(ackCallback, null);\n \n        // 发布多条消息，将这些消息的信息同样保存到outstandingConfirms中，其可以在其他线程安全访问\n        for (int i = 0; i < MESSAGE_COUNT; i++) {\n            String message = \"消息\" + i;\n            /**\n        \t* channel.getNextPublishSeqNo()获取下一个消息的序列号\n        \t* 通过序列号与消息体进行一个关联\n        \t* 全部都是未确认的消息体\n         \t*/\n            outstandingConfirms.put(channel.getNextPublishSeqNo(), message);\n            channel.basicPublish(\"\", queueName, null, message.getBytes());\n        }\n    } \n}\n```\n\n> https://www.bilibili.com/video/BV1cb4y1o7zz?p=77\n\n以上 3 种发布策略确认速度对比：\n\n- **单独发布消息**：同步等待确认，简单，但吞吐量非常有限\n- **批量发布消息**：批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是哪条消息出现了问题\n- **异步处理**：最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些\n\n## 交换机 Exchanges\n\nRabbitMQ 消息传递模型的核心思想是：生产者生产的消息从不会直接发送到队列。实际上，**通常生产者甚至都不知道这些消息传递传递到了哪些队列中**。\n\n- 生产者只将消息发给交换机，至于该交换机将消息发送给了哪个队列其是不知道的（通常将绑定的工作放到Spring的`@Configuration`配置类里，从而与生产者解耦，生产者本身并不知道绑定信息）\n- 消费者只从队列获取消息，至于该消息来自哪个交换机其是不知道的\n\n相反，**生产者只能将消息发送到交换机 (exchange)** ，交换机工作的内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息，是应该把这些消息放到特定队列还是说把他们放到许多队列中还是说应该丢弃它们。这就由交换机的类型来决定。\n\nExchanges 的类型：\n\n- **直接 (direct)**：消息只去到它绑定的 `routingKey` 队列中去（该消息要发往的`routingKey` 由生产者发送消息时指定）\n- **主题 (topic)**：发送到类型是 topic 交换机的消息的 `routingKey` 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说：`\"stock.usd.nyse\"`。\n- **标题 (headers)**：\n- **扇出 (fanout)**：将接收到的所有消息**广播**到它知道的所有队列中\n\n### 主题 Topic 类型\n\n发送到类型是 topic 交换机的消息的 `routingKey` 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说：`\"stock.usd.nyse\"`。\n\n在这个规则列表中，其中有两个替换符是需要注意的：\n\n- \\*(星号) 可以代替一个单词\n- #(井号) 可以替代零个或多个单词\n\n![image-20210903213659559](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903213659559.png)\n\n上图对应关系：\n\n- Q1–> 绑定的是：\n  - 中间带 `orange` 带 3 个单词的字符串 (`*.orange.*`)\n- Q2–> 绑定的是：\n  - 最后一个单词是 `rabbit` 的 3 个单词 (`*.*.rabbit`)\n  - 第一个单词是 `lazy` 的多个单词 (`lazy.#`)\n\n注意：\n\n- 当一个队列绑定键是 #，那么这个队列将接收所有数据，就有点像 fanout 了\n- 如果队列绑定键当中没有 #和 * 出现，那么该队列绑定类型就是 direct 了\n\n\n\n## 死信队列\n\n### 死信的概念\n\n先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理解，一般来说，producer 将消息投递到 broker 或者直接到 queue 里了，consumer 从 queue 取出消息进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有了死信队列。\n\n应用场景：为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息消费发生异常时，将消息投入死信队列中。还有比如说：用户在商城下单成功并点击去支付后在指定时间未支付时自动失效。\n\n### 死信的来源\n\n- **消息 TTL 过期**：TTL 是 Time To Live 的缩写，也就是生存时间（`expiration`），当生存时间到了该消息还未被消费，则成为死信。\n- **队列达到最大长度**：若队列满了，无法再添加数据到队列中，那些无法加进去的消息成为死信。\n- **消息被拒绝**：当消息被消费者拒绝(`basicReject()` 或 `basicNack`) 并且 `requeue=false`时成为死信。\n\n### 死信实战\n\n情景：普通交换机 `normal_exchange`，使用 `routingKey=\"zhangsan\"` 路由到普通队列 `normal-queue`，消费者 `C1` 将获取该队列里的消息。若某个消息成为了死信，则其将被路由到死信交换机 `dead_exchange`，该死信交换机将使用 `routingKey=\"lisi\"` 路由到死信队列 `dead-queue`，消费者 C2 将获取死信队列里的消息进行处理。\n\n![image-20210903214211735](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903214211735.png)\n\n分别分析三种死信情况下的代码：\n\n### 死信之 “消息 TTL 过期” 情况\n\n消费者 C1 代码：\n\n```java\n/**\n * 死信队列 - 消费者C1\n */\npublic class Consumer01 {\n\n    //普通交换机名称\n    private static final String NORMAL_EXCHANGE = \"normal_exchange\";\n    //死信交换机名称\n    private static final String DEAD_EXCHANGE = \"dead_exchange\";\n\n    public static void main(String[] args) throws Exception {\n        Channel channel = RabbitMqUtils.getChannel();\n\n        //声明死信和普通交换机 类型为 direct\n        channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT);\n        channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT);\n\n        //声明死信队列\n        String deadQueue = \"dead-queue\";\n        channel.queueDeclare(deadQueue, false, false, false, null);\n        //死信队列绑定：队列、交换机、路由键（routingKey）\n        channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\");\n\n        //正常队列绑定死信队列信息\n        Map<String, Object> params = new HashMap<>();\n        //正常队列设置死信交换机 参数 key 是固定值\n        params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE);\n        //正常队列设置死信 routing-key 参数 key 是固定值\n        params.put(\"x-dead-letter-routing-key\", \"lisi\");\n\n        //正常队列\n        String normalQueue = \"normal-queue\";\n        channel.queueDeclare(normalQueue, false, false, false, params);\n        channel.queueBind(normalQueue, NORMAL_EXCHANGE, \"zhangsan\");\n\n        System.out.println(\"等待接收消息........... \");\n        DeliverCallback deliverCallback = (consumerTag, delivery) -> {\n            String message = new String(delivery.getBody(), \"UTF-8\");\n            System.out.println(\"Consumer01 接收到消息\" + message);\n        };\n        channel.basicConsume(normalQueue, true, deliverCallback, consumerTag -> {\n        });\n    }\n\n}\n```\n\n生产者代码：\n\n```java\npublic class Producer {\n    private static final String NORMAL_EXCHANGE = \"normal_exchange\";\n\n    public static void main(String[] argv) throws Exception {\n        Channel channel = RabbitMqUtils.getChannel();\n\n        channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT);\n        //设置消息的 TTL 时间 10s，即超过 10s 该消息将成为死信\n        AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().expiration(\"10000\").build();\n        //该信息是用作演示队列个数限制\n        for (int i = 1; i < 11; i++) {\n            String message = \"info\" + i;\n            channel.basicPublish(NORMAL_EXCHANGE, \"zhangsan\", properties, message.getBytes());\n            System.out.println(\"生产者发送消息:\" + message);\n        }\n\n    }\n}\n```\n\n启动 C1 ，之后关闭消费者，模拟其接收不到消息（这样消息就会过期），再启动生产者：\n\n![image-20210903214935805](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903214935805.png)\n\n消费者 C2 代码：以上步骤完成后，启动 C2 消费者，它消费死信队列里面的消息：\n\n```java\npublic class Consumer02 {\n    //死信交换机名称\n    private static final String DEAD_EXCHANGE = \"dead_exchange\";\n\n    public static void main(String[] args) throws Exception {\n        Channel channel = RabbitMqUtils.getChannel();\n\n        //声明交换机\n        channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT);\n        //声明队列\n        String deadQueue = \"dead-queue\";\n        channel.queueDeclare(deadQueue, false, false, false, null);\n        channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\");\n\n        System.out.println(\"等待接收死信消息........... \");\n        DeliverCallback deliverCallback = (consumerTag, delivery) -> {\n            String message = new String(delivery.getBody(), \"UTF-8\");\n            System.out.println(\"Consumer02 接收到消息\" + message);\n        };\n        channel.basicConsume(deadQueue, true, deliverCallback, consumerTag -> {\n        });\n    }\n}\n```\n\n![image-20210903215018034](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903215018034.png)\n\n### 死信之 “队列达到最大长度” 情况\n\n消息生产者代码去掉 TTL 属性：\n\n![image-20210903215130608](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903215130608.png)\n\nC1 消费者修改以下代码 （启动之后关闭该消费者，模拟其接收不到消息）:\n\n![image-20210903215202328](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903215202328.png)\n\n```java\n// 设置正常队列的长度限制为6，例如发10个消息，4个则为死信\nparams.put(\"x-max-length\",6);\n```\n\n**注意此时需要把原先队列删除，因为参数改变了。**\n\nC2 消费者代码不变 (启动 C2 消费者)：\n\n![image-20210903215400615](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903215400615.png)\n\n### 死信之 “消息被拒” 情况\n\n消息生产者代码同上生产者一致。\n\nC1 消费者代码 (启动之后关闭该消费者 模拟其接收不到消息) 拒收消息 “info5” ：\n\n```java\npublic class Consumer01 {\n\n    //普通交换机名称\n    private static final String NORMAL_EXCHANGE = \"normal_exchange\";\n    //死信交换机名称\n    private static final String DEAD_EXCHANGE = \"dead_exchange\";\n\n    public static void main(String[] args) throws Exception {\n        Channel channel = RabbitMqUtils.getChannel();\n\n        //声明死信和普通交换机 类型为 direct\n        channel.exchangeDeclare(NORMAL_EXCHANGE, BuiltinExchangeType.DIRECT);\n        channel.exchangeDeclare(DEAD_EXCHANGE, BuiltinExchangeType.DIRECT);\n\n        //声明死信队列\n        String deadQueue = \"dead-queue\";\n        channel.queueDeclare(deadQueue, false, false, false, null);\n        //死信队列绑定：队列、交换机、路由键（routingKey）\n        channel.queueBind(deadQueue, DEAD_EXCHANGE, \"lisi\");\n\n        //正常队列绑定死信队列信息\n        Map<String, Object> params = new HashMap<>();\n        //正常队列设置死信交换机 参数 key 是固定值\n        params.put(\"x-dead-letter-exchange\", DEAD_EXCHANGE);\n        //正常队列设置死信 routing-key 参数 key 是固定值\n        params.put(\"x-dead-letter-routing-key\", \"lisi\");\n        //        //设置正常队列的长度限制，例如发10个，4个则为死信\n        //        params.put(\"x-max-length\",6);\n\n        //正常队列\n        String normalQueue = \"normal-queue\";\n        channel.queueDeclare(normalQueue, false, false, false, params);\n        channel.queueBind(normalQueue, NORMAL_EXCHANGE, \"zhangsan\");\n\n        System.out.println(\"等待接收消息........... \");\n\n        DeliverCallback deliverCallback = (consumerTag, delivery) -> {\n            String message = new String(delivery.getBody(), \"UTF-8\");\n            if (message.equals(\"info5\")) {\n                System.out.println(\"Consumer01 接收到消息\" + message + \"并拒绝签收该消息\");\n                //requeue 设置为 false 代表拒绝重新入队 该队列如果配置了死信交换机将发送到死信队列中\n                channel.basicReject(delivery.getEnvelope().getDeliveryTag(), false);\n            } else {\n                System.out.println(\"Consumer01 接收到消息\" + message);\n                channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);\n            }\n\n        };\n        //开启手动应答\n        channel.basicConsume(normalQueue, false, deliverCallback, consumerTag -> {\n        });\n    }\n\n}\n```\n\n![image-20210903215518080](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903215518080.png)\n\nC2 消费者代码不变：启动消费者 1 然后再启动消费者 2：\n\n![image-20210903215531918](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210903215531918.png)\n\n## 延迟队列\n\n### 延迟队列概念\n\n延时队列内部是**有序的**，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。\n\n**使用延迟队列时，将需要延迟的消息放到延迟队列中（该队列设置到期时间），同时不指定任何消费者监听该队列，这样该队列内的消息在到达到期时间后就会进入死信队列。此时再指定相应的消费者监听死信队列，从中获取延迟的消息进行消费（例如取消订单等）**\n\n延迟队列使用场景：\n\n- 订单在十分钟之内未支付则自动取消；\n- 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒；\n- 用户注册成功后，如果三天内没有登陆则进行短信提醒；\n- 用户发起退款，如果三天内没有得到处理则通知相关运营人员；\n- 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议。\n\n这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭。那我们一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？\n\n如果数据量比较少，确实可以这样做，比如：对于 “如果账单一周内未支付则进行自动结算” 这样的需求， 如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。\n\n但对于数据量比较大，并且时效性较强的场景，如：“订单十分钟内未支付则关闭 “，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。\n\n![image-20210904144655029](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904144655029.png)\n\n### RabbitMQ 中的 TTL\n\nTTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，单位是毫秒。\n\n换句话说，**如果一条消息设置了 TTL 属性或者进入了设置 TTL 属性的队列，那么这条消息如果在 TTL 设置的时间内没有被消费，则会成为“死信”**。如果同时配置了队列的 TTL 和消息的 TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。\n\n- **队列设置 TTL**：在创建队列的时候设置队列的 `“x-message-ttl”` 属性\n\n![image-20210904144805663](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904144805663.png)\n\n- **消息设置 TTL**：是针对每条消息设置 TTL\n\n![image-20210904144916833](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904144916833.png)\n\n**两者的区别**：\n\n- 如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃 （如果配置了死信队列被丢到死信队列中），而第二种方式，消息即使过期，也不一定会被马上丢弃，因为消息是否过期是在即将投递到消费者之前判定的，如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间。\n- 另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。\n\n下面介绍在 Spring Boot 中使用延迟队列的示例\n\n### Spring Boot 整合 RabbitMQ\n\n1. 导入依赖\n\n```xml\n<dependencies>\n   <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter</artifactId>\n    </dependency>\n    <!--RabbitMQ 依赖-->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-amqp</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>fastjson</artifactId>\n        <version>1.2.47</version>\n    </dependency>\n    <dependency>\n        <groupId>org.projectlombok</groupId>\n        <artifactId>lombok</artifactId>\n    </dependency>\n    <!--swagger-->\n    <dependency>\n        <groupId>io.springfox</groupId>\n        <artifactId>springfox-swagger2</artifactId>\n        <version>3.0.0</version>\n    </dependency>\n    <dependency>\n        <groupId>io.springfox</groupId>\n        <artifactId>springfox-swagger-ui</artifactId>\n        <version>3.0.0</version>\n    </dependency>\n    <!--RabbitMQ 测试依赖-->\n    <dependency>\n        <groupId>org.springframework.amqp</groupId>\n        <artifactId>spring-rabbit-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n```\n\n2. 配置文件：\n\n``` properties\nspring.rabbitmq.host=42.192.149.71\nspring.rabbitmq.port=5672\nspring.rabbitmq.username=admin\nspring.rabbitmq.password=123456\n```\n\n3. 添加 Swagger 配置类：\n\n``` java\npackage com.zhao.config;\n\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport springfox.documentation.builders.ApiInfoBuilder;\nimport springfox.documentation.service.ApiInfo;\nimport springfox.documentation.service.Contact;\nimport springfox.documentation.spi.DocumentationType;\nimport springfox.documentation.spring.web.plugins.Docket;\nimport springfox.documentation.swagger2.annotations.EnableSwagger2;\n\n@Configuration\n@EnableSwagger2\npublic class SwaggerConfig {\n\n    @Bean\n    public Docket webApiConfig() {\n        return new Docket(DocumentationType.SWAGGER_2)\n            .groupName(\"webApi\")\n            .apiInfo(webApiInfo())\n            .select()\n            .build();\n    }\n\n    private ApiInfo webApiInfo() {\n        return new ApiInfoBuilder()\n            .title(\"rabbitmq 接口文档\")\n            .description(\"本文档描述了 rabbitmq 微服务接口定义\")\n            .version(\"1.0\")\n            .contact(new Contact(\"zhiyuan\", \"http://oddfar.com\", \"test@qq.com\"))\n            .build();\n    }\n}\n\n```\n\n### 延迟队列场景\n\n创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是 `direct`，创建一个死信队列 QD，它们的绑定关系如下：\n\n![image-20210904145729754](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904145729754.png)\n\n4. 创建 `@Configuration` 配置类，在其内声明队列和交换机并进行绑定：\n\n``` java\npackage com.zhao.config;\n\nimport org.springframework.amqp.core.*;\nimport org.springframework.beans.factory.annotation.Qualifier;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\n@Configuration\npublic class TtlQueueConfig {\n    public static final String X_EXCHANGE = \"X\";\n    public static final String QUEUE_A = \"QA\";\n    public static final String QUEUE_B = \"QB\";\n    // 死信交换机\n    public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\";\n    // 死信队列\n    public static final String DEAD_LETTER_QUEUE = \"QD\";\n\n    // 声明 xExchange\n    @Bean(\"xExchange\")\n    public DirectExchange xExchange() {\n        return new DirectExchange(X_EXCHANGE);\n    }\n\n    // 声明 死信队列交换机\n    @Bean(\"yExchange\")\n    public DirectExchange yExchange() {\n        return new DirectExchange(Y_DEAD_LETTER_EXCHANGE);\n    }\n\n    // 声明队列 A ttl 为 10s 并绑定到对应的死信交换机\n    @Bean(\"queueA\")\n    public Queue queueA() {\n        Map<String, Object> args = new HashMap<>(3);\n        //声明当前队列绑定的死信交换机\n        args.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE);\n        //声明当前队列的死信路由 key\n        args.put(\"x-dead-letter-routing-key\", \"YD\");\n        //声明队列的 TTL\n        args.put(\"x-message-ttl\", 10000);\n        return QueueBuilder.durable(QUEUE_A).withArguments(args).build();\n    }\n\n    // 声明队列 A 绑定 X 交换机\n    @Bean\n    public Binding queueaBindingX(@Qualifier(\"queueA\") Queue queueA,\n                                  @Qualifier(\"xExchange\") DirectExchange xExchange) {\n        return BindingBuilder.bind(queueA).to(xExchange).with(\"XA\");\n    }\n\n    // 声明队列 B ttl 为 40s 并绑定到对应的死信交换机\n    @Bean(\"queueB\")\n    public Queue queueB() {\n        Map<String, Object> args = new HashMap<>(3);\n        // 声明当前队列绑定的死信交换机\n        args.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE);\n        // 声明当前队列的死信路由 key\n        args.put(\"x-dead-letter-routing-key\", \"YD\");\n        // 声明队列的 TTL\n        args.put(\"x-message-ttl\", 40000);\n        return QueueBuilder.durable(QUEUE_B).withArguments(args).build();\n    }\n\n    // 声明队列 B 绑定 X 交换机\n    @Bean\n    public Binding queuebBindingX(@Qualifier(\"queueB\") Queue queue1B,\n                                  @Qualifier(\"xExchange\") DirectExchange xExchange) {\n        return BindingBuilder.bind(queue1B).to(xExchange).with(\"XB\");\n    }\n\n    // 声明死信队列 QD\n    @Bean(\"queueD\")\n    public Queue queueD() {\n        return new Queue(DEAD_LETTER_QUEUE);\n    }\n\n    // 声明死信队列 QD 绑定关系\n    @Bean\n    public Binding deadLetterBindingQAD(@Qualifier(\"queueD\") Queue queueD,\n                                        @Qualifier(\"yExchange\") DirectExchange yExchange) {\n        return BindingBuilder.bind(queueD).to(yExchange).with(\"YD\");\n    }\n\n}\n```\n\n5. 消息生产者代码：\n\n```java\npackage com.zhao.contorller;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport java.util.Date;\n\n@Slf4j\n@RequestMapping(\"ttl\")\n@RestController\npublic class SendMsgController {\n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n\n    @GetMapping(\"sendMsg/{message}\")\n    public void sendMsg(@PathVariable String message) {\n        log.info(\"当前时间：{},发送一条信息给两个 TTL 队列:{}\", new Date(), message);\n        rabbitTemplate.convertAndSend(\"X\", \"XA\", \"消息来自 ttl 为 10S 的队列: \" + message);\n        rabbitTemplate.convertAndSend(\"X\", \"XB\", \"消息来自 ttl 为 40S 的队列: \" + message);\n    }\n\n}\n```\n\n6. 消息消费者代码：\n\n``` java\npackage com.oddfar.contorller;\n\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport java.util.Date;\n\n@Slf4j\n@Component\npublic class DeadLetterQueueConsumer {\n    @RabbitListener(queues = \"QD\")\n    public void receiveD(Message message, Channel channel) throws IOException {\n        String msg = new String(message.getBody());\n        log.info(\"当前时间：{},收到死信队列信息{}\", new Date().toString(), msg);\n    }\n}\n```\n\n7. 测试：发起一个请求 `http://localhost:8080/ttl/sendMsg/嘻嘻嘻`\n\n![image-20210904150453631](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904150453631.png)\n\n第一条消息在 10S 后变成了死信消息，然后被消费者消费掉，第二条消息在 40S 之后变成了死信消息， 然后被消费掉，这样一个延时队列就打造完成了。\n\n不过，如果这样使用的话，岂不是每增加一个新的时间需求，就要新增一个队列，这里只有 10S 和 40S 两个时间选项，如果需要一个小时后处理，那么就需要增加 TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？\n\n### 延时队列 TTL 优化\n\n在这里新增了一个队列 QC，绑定关系如下，该队列不设置 TTL 时间\n\n![image-20210904150550667](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904150550667.png)\n\n配置文件类代码：\n\n``` java\n@Configuration\npublic class MsgTtlQueueConfig {\n    public static final String Y_DEAD_LETTER_EXCHANGE = \"Y\";\n    public static final String QUEUE_C = \"QC\";\n\n    // 声明队列 C 死信交换机\n    @Bean(\"queueC\")\n    public Queue queueB() {\n        Map<String, Object> args = new HashMap<>(3);\n        // 声明当前队列绑定的死信交换机\n        args.put(\"x-dead-letter-exchange\", Y_DEAD_LETTER_EXCHANGE);\n        // 声明当前队列的死信路由 key\n        args.put(\"x-dead-letter-routing-key\", \"YD\");\n        // 没有声明 TTL 属性\n        return QueueBuilder.durable(QUEUE_C).withArguments(args).build();\n    }\n\n    // 声明队列 B 绑定 X 交换机\n    @Bean\n    public Binding queuecBindingX(@Qualifier(\"queueC\") Queue queueC,\n                                  @Qualifier(\"xExchange\") DirectExchange xExchange) {\n        return BindingBuilder.bind(queueC).to(xExchange).with(\"XC\");\n    }\n}\n```\n\n生产者代码：\n\n``` java\n/**\n * 延时队列优化\n * @param message 消息\n * @param ttlTime 延时的毫秒\n */\n@GetMapping(\"sendExpirationMsg/{message}/{ttlTime}\")\npublic void sendMsg(@PathVariable String message, @PathVariable String ttlTime) {\n    rabbitTemplate.convertAndSend(\"X\", \"XC\", message, correlationData -> {\n        correlationData.getMessageProperties().setExpiration(ttlTime);\n        return correlationData;\n    });\n    log.info(\"当前时间：{},发送一条时长{}毫秒 TTL 信息给队列 C:{}\", new Date(), ttlTime, message);\n}\n```\n\n发起请求：\n\n- `http://localhost:8080/ttl/sendExpirationMsg/你好1/20000`\n- `http://localhost:8080/ttl/sendExpirationMsg/你好2/2000`\n\n![image-20210904150828988](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904150828988.png)\n\n看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时 “死亡”。\n\n**因为 RabbitMQ 只会检查第一个消息是否过期，如果过期则丢到死信队列， 如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行。这也就是为什么第二个延时 2 秒，却后执行。**\n\n为解决该问题，需要安装 RabbitMQ 的一个插件 `rabbitmq_delayed_message_exchange`\n\n### RabbitMQ 插件实现延迟队列 \n\n从[官网]( https://www.rabbitmq.com/community-plugins.html)下载 `rabbitmq_delayed_message_exchange` 插件，然后解压放置到 RabbitMQ 的插件目录。 进入 RabbitMQ 的安装目录下的 plugins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ `/usr/lib/rabbitmq/lib/rabbitmq_server-3.8.8/plugins` \n\n``` java\n$ rabbitmq-plugins enable rabbitmq_delayed_message_exchange\n```\n\n![image-20210904151314950](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904151314950.png)\n\n此时即可创建 `x-delayed-message` 类型的交换机，可创建自定义的交换机类型 `CustomExchange` ，并指定该交换机的转发类型为  `x-delayed-message`。 \n\n1. 修改配置类：\n\n``` java\n@Configuration\npublic class DelayedQueueConfig {\n    public static final String DELAYED_QUEUE_NAME = \"delayed.queue\";\n    public static final String DELAYED_EXCHANGE_NAME = \"delayed.exchange\";\n    public static final String DELAYED_ROUTING_KEY = \"delayed.routingkey\";\n    @Bean\n    public Queue delayedQueue() {\n        return new Queue(DELAYED_QUEUE_NAME);\n    }\n    // 自定义交换机 我们在这里定义的是一个延迟交换机\n    @Bean\n    public CustomExchange delayedExchange() { \n        Map<String, Object> args = new HashMap<>();\n        // 自定义交换机的类型\n        args.put(\"x-delayed-type\", \"direct\");\n        return new CustomExchange(DELAYED_EXCHANGE_NAME, \"x-delayed-message\", true, false, args);\n    }\n    @Bean\n    public Binding bindingDelayedQueue(@Qualifier(\"delayedQueue\") Queue queue,\n                                       @Qualifier(\"delayedExchange\") CustomExchange delayedExchange) {\n        return BindingBuilder.bind(queue).to(delayedExchange).with(DELAYED_ROUTING_KEY).noargs();\n    }\n}\n```\n\n2. 消息生产者，在发送消息时需要给消息带上属性`setDelay(delayTime)`\n\n``` java\npublic static final String DELAYED_EXCHANGE_NAME = \"delayed.exchange\";\npublic static final String DELAYED_ROUTING_KEY = \"delayed.routingkey\";\n@GetMapping(\"sendDelayMsg/{message}/{delayTime}\")\npublic void sendMsg(@PathVariable String message,@PathVariable Integer delayTime) {\n    rabbitTemplate.convertAndSend(DELAYED_EXCHANGE_NAME, DELAYED_ROUTING_KEY, message, correlationData -> {\n        correlationData.getMessageProperties().setDelay(delayTime);\n        return correlationData \n    });\n    log.info(\" 当 前 时 间 ： {}, 发 送 一 条 延 迟 {} 毫秒的信息给队列 delayed.queue:{}\", new Date(), delayTime, message);\n}\n```\n\n3. 消息消费者\n\n``` java\npublic static final String DELAYED_QUEUE_NAME = \"delayed.queue\";\n@RabbitListener(queues = DELAYED_QUEUE_NAME)\npublic void receiveDelayedQueue(Message message) {\n    String msg = new String(message.getBody());\n    log.info(\"当前时间：{},收到延时队列的消息：{}\", new Date().toString(), msg);\n}\n```\n\n4. 发起请求：\n   - `http://localhost:8080/ttl/sendDelayMsg/come on baby1/20000`\n   - `http://localhost:8080/ttl/sendDelayMsg/come on baby2/2000`\n\n![image-20210904154952551](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904154952551.png)\n\n第二个消息被先消费掉了，符合预期\n\n### 总结 \n\n延时队列在需要延时处理的场景下非常有用，使用 RabbitMQ 来实现延时队列可以很好的利用 RabbitMQ 的特性，如：消息可靠发送、消息可靠投递、死信队列来保障消息至少被消费一次以及未被正 确处理的消息不会被丢弃。另外，通过 RabbitMQ 集群的特性，可以很好的解决单点故障问题，不会因为 单个节点挂掉导致延时队列不可用或者消息丢失。 \n\n当然，延时队列还有很多其它选择，比如利用 Java 的 DelayQueue，利用 Redis 的 zset，利用 Quartz 或者利用 kafka 的时间轮，这些方式各有特点,看需要适用的场景\n\n## 发布确认高级\n\n在生产环境中由于一些不明原因，导致 RabbitMQ 重启，在 RabbitMQ 重启期间生产者消息投递失败， 导致消息丢失，需要手动处理和恢复。于是，我们开始思考，如何才能进行 RabbitMQ 的消息可靠投递呢？\n\n确认机制方案：\n\n![image-20210904155528622](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904155528622.png)\n\n代码架构图：\n\n![image-20210904155542060](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904155542060.png)\n\n在配置文件当中需要添加：\n\n```properties\n# 开启发布确认功能\nspring.rabbitmq.publisher-confirm-type=correlated\n\n# 开启消息退回功能，见后文分析\nspring.rabbitmq.publisher-returns=true\n```\n\n- `NONE` 值是禁用发布确认模式，是默认值。\n- `CORRELATED` 值是发布消息成功到交换器后会触发回调方法。\n- `SIMPLE` 值经测试有两种效果，其一效果和 `CORRELATED` 值一样会触发回调方法，其二在发布消息成功后使用 `rabbitTemplate` 调用 `waitForConfirms` 或 `waitForConfirmsOrDie` 方法等待 broker 节点返回发送结果，根据返回结果来判定下一步的逻辑，要注意的点是 `waitForConfirmsOrDie` 方法如果返回 false 则会关闭 channel，则接下来无法发送消息到 broker。\n\n1. 添加配置类：\n\n``` java\n@Configuration\npublic class ConfirmConfig {\n    public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\";\n    public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\";\n\n    //声明业务 Exchange\n    @Bean(\"confirmExchange\")\n    public DirectExchange confirmExchange() {\n        return new DirectExchange(CONFIRM_EXCHANGE_NAME);\n    }\n\n    // 声明确认队列\n    @Bean(\"confirmQueue\")\n    public Queue confirmQueue() {\n        return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build();\n    }\n\n    // 声明确认队列绑定关系\n    @Bean\n    public Binding queueBinding(@Qualifier(\"confirmQueue\") Queue queue,\n                                @Qualifier(\"confirmExchange\") DirectExchange exchange) {\n        return BindingBuilder.bind(queue).to(exchange).with(\"key1\");\n    }\n}\n```\n\n2. 消息生产者的回调接口\n\n```java\n@Component\n@Slf4j\npublic class MyCallBack implements RabbitTemplate.ConfirmCallback {\n    /**\n     * 交换机是否收到消息的一个回调方法\n     *\n     * @param correlationData 消息相关数据\n     * @param ack             交换机是否收到消息\n     * @param cause           为收到消息的原因\n     */\n    @Override\n    public void confirm(CorrelationData correlationData, boolean ack, String cause) {\n        String id = correlationData != null ? correlationData.getId() : \"\";\n        if (ack) {\n            log.info(\"交换机已经收到 id 为:{}的消息\", id);\n        } else {\n            log.info(\"交换机还未收到 id 为:{}消息，原因:{}\", id, cause);\n        }\n    }\n}\n```\n\n3. 消息生产者\n\n``` java\n@RestController\n@RequestMapping(\"/confirm\")\n@Slf4j\npublic class ProducerController {\n    public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\";\n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n    @Autowired\n    private MyCallBack myCallBack;\n\n    //依赖注入 rabbitTemplate 之后再设置它的回调对象\n    @PostConstruct\n    public void init() {\n        rabbitTemplate.setConfirmCallback(myCallBack);\n    }\n    \n    /**\n     * 消息回调和退回\n     *\n     * @param message\n     */\n    @GetMapping(\"sendMessage/{message}\")\n    public void sendMessage(@PathVariable String message) {\n\n        //指定消息 id 为 1\n        CorrelationData correlationData1 = new CorrelationData(\"1\");\n        String routingKey = \"key1\";\n        rabbitTemplate.convertAndSend(CONFIRM_EXCHANGE_NAME, routingKey, message + routingKey, correlationData1);\n        log.info(routingKey + \"发送消息内容:{}\", message + routingKey);\n\n        CorrelationData correlationData2 = new CorrelationData(\"2\");\n        routingKey = \"key2\";\n        rabbitTemplate.convertAndSend(CONFIRM_EXCHANGE_NAME, routingKey, message + routingKey, correlationData2);\n        log.info(routingKey + \"发送消息内容:{}\", message + routingKey);\n    }\n}\n```\n\n4. 消息消费者\n\n```java\n@Component\n@Slf4j\npublic class ConfirmConsumer {\n    public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\";\n\n    @RabbitListener(queues = CONFIRM_QUEUE_NAME)\n    public void receiveMsg(Message message) {\n        String msg = new String(message.getBody());\n        log.info(\"接受到队列 confirm.queue 消息:{}\", msg);\n    }\n}\n```\n\n结果分析：\n\n![image-20210904160122676](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904160122676.png)\n\n可以看到，发送了两条消息，第一条消息的 `RoutingKey` 为 `“key1”`，第二条消息的 `RoutingKey` 为 `“key2”`，两条消息都成功被交换机接收，也收到了交换机的确认回调，但消费者只收到了一条消息，因为第二条消息的 `RoutingKey` 与队列的 `BindingKey` 不一致，也没有其它队列能接收这个消息，所以第二条消息被直接丢弃了。丢弃的消息生产者是不知道的，需要解决告诉生产者消息传送失败。\n\n### 回退消息\n\n在仅开启了生产者确认机制的情况下，交换机接收到消息后，会直接给消息生产者发送确认消息，**如果发现该消息不可路由，那么消息会被直接丢弃，此时生产者是不知道消息被丢弃这个事件的**。\n\n那么如何让无法被路由的消息帮我想办法处理一下？最起码通知我一声，我好自己处理啊。通过设置 `mandatory` 参数可以在当消息传递过程中不可达目的地时将消息返回给生产者，通知生产者消息发送失败，考虑重新发送。\n\n```java\n/**\n * true：交换机无法将消息进行路由时，会将该消息返回给生产者\n * false：如果发现消息无法进行路由，则直接丢弃\n */\nrabbitTemplate.setMandatory(true);\n```\n\n同时需要在配置文件中开启消息回退功能：\n\n```properties\n# 开启消息退回功能\nspring.rabbitmq.publisher-returns=true\n```\n\n生产者代码：\n\n\n```java\n@Slf4j\n@Component\npublic class MessageProducer implements RabbitTeplate.ConfirmCallback, RabbitTemplate.ReturnCallback {\n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n    //rabbitTemplate 注入之后就设置该值\n\n    @PostConstruct\n    private void init() {\n        rabbitTemplate.setConfirmCallback(this);\n        /**\n         * true：交换机无法将消息进行路由时，会将该消息返回给生产者\n         * false：如果发现消息无法进行路由，则直接丢弃\n         */\n        rabbitTemplate.setMandatory(true);\n        // 设置回退消息交给谁处理\n        rabbitTemplate.setReturnCallback(this);\n    }\n\n    @GetMapping(\"sendMessage\")\n    public void sendMessage(String message) {\n        //让消息绑定一个 id 值\n        CorrelationData correlationData1 = new CorrelationData(UUID.randomUUID().toString());\n        rabbitTemplate.convertAndSend(\"confirm.exchange\",\"key1\",message+\"key1\",correlationData1);\n\n        log.info(\"发送消息 id 为:{}内容为{}\",correlationData1.getId(),message+\"key1\");\n        CorrelationData correlationData2 = new CorrelationData(UUID.randomUUID().toString());\n        rabbitTemplate.convertAndSend(\"confirm.exchange\",\"key2\",message+\"key2\",correlationData2);\n        log.info(\"发送消息 id 为:{}内容为{}\",correlationData2.getId(),message+\"key2\");\n    }\n\n    @Override\n    public void confirm(CorrelationData correlationData, boolean ack, String cause) {\n        String id = correlationData != null ? correlationData.getId() : \"\";\n        if (ack) {\n            log.info(\"交换机收到消息确认成功, id:{}\", id);\n        } else {\n            log.error(\"消息 id:{}未成功投递到交换机,原因是:{}\", id, cause);\n        }\n    }\n\n    @Override\n    public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) {\n        log.info(\"消息:{}被服务器退回，退回原因:{}, 交换机是:{}, 路由 key:{}\",\n                 new String(message.getBody()),replyText, exchange, routingKey);\n    }\n}\n```\n\n2. 回调接口\n\n``` java\n@Component\n@Slf4j\npublic class MyCallBack implements RabbitTemplate.ConfirmCallback,RabbitTemplate.ReturnCallback {\n    /**\n     * 交换机是否收到消息的一个回调方法\n     * CorrelationData：消息相关数据\n     * ack：交换机是否收到消息\n     */\n    @Override\n    public void confirm(CorrelationData correlationData, boolean ack, String cause) {\n        String id=correlationData!=null?correlationData.getId():\"\";\n        if(ack){\n            log.info(\"交换机已经收到 id 为:{}的消息\",id);\n        }else{\n            log.info(\"交换机还未收到 id 为:{}消息,由于原因:{}\",id,cause);\n        }\n    }\n    \n    // 当消息无法路由时的回调方法\n    @Override\n    public void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) {\n        log.error(\" 消 息 {}, 被 交 换 机 {} 退 回 ， 退 回 原 因 :{}, 路 由 key:{}\",new String(message.getBody()),exchange,replyText,routingKey);\n    }\n}\n```\n\n此时若交换机无法分发生产者发送的消息，则会调用 `returnedMessage()` 方法回退消息。\n\n### 备份交换机\n\n有了 `mandatory` 参数和回退消息，我们获得了对无法投递消息的感知能力，在生产者的消息无法被投递时发现并处理。但有时候，我们并不知道该如何处理这些无法路由的消息，最多打个日志，然后触发报警，再来手动处理。而通过日志来处理这些无法路由的消息是很不优雅的做法，特别是当生产者所在的服务有多台机器的时候，手动复制日志会更加麻烦而且容易出错。而且设置 `mandatory` 参数会增加生产者的复杂性，需要添加处理这些被退回的消息的逻辑。如果既不想丢失消息，又不想增加生产者的复杂性，该怎么做呢？\n\n前面在设置死信队列的章节中，我们提到，可以为队列设置死信交换机来存储那些处理失败的消息，可是这些不可路由消息根本没有机会进入到队列，因此无法使用死信队列来保存消息。 在 RabbitMQ 中，有一种**备份交换机**的机制存在，可以很好的应对这个问题。\n\n备份交换机可以理解为 RabbitMQ 中交换机的 “备胎”，当我们为某一个交换机声明一个对应的备份交换机时，就是为它创建一个备胎，**当交换机接收到一条不可路由消息时，将会把这条消息转发到备份交换机中，由备份交换机来进行转发和处理**，通常备份交换机的类型为 `Fanout` ，这样就能把所有消息都投递到与其绑定的队列中，**然后我们在备份交换机下绑定一个队列，这样所有那些原交换机无法被路由的消息，就会都进入这个队列了。我们还可以建立一个报警队列，用独立的消费者来进行监测和报警。**\n\n架构图：\n\n![image-20210904163932459](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904163932459.png)\n\n在配置类中添加绑定备份交换机：\n\n``` java\n@Configuration\npublic class ConfirmConfig {\n    public static final String CONFIRM_EXCHANGE_NAME = \"confirm.exchange\";\n    public static final String CONFIRM_QUEUE_NAME = \"confirm.queue\";\n    public static final String BACKUP_EXCHANGE_NAME = \"backup.exchange\";\n    public static final String BACKUP_QUEUE_NAME = \"backup.queue\";\n    public static final String WARNING_QUEUE_NAME = \"warning.queue\";\n\n    // 声明确认队列\n    @Bean(\"confirmQueue\")\n    public Queue confirmQueue() {\n        return QueueBuilder.durable(CONFIRM_QUEUE_NAME).build();\n    }\n\n    // 声明确认队列绑定关系\n    @Bean\n    public Binding queueBinding(@Qualifier(\"confirmQueue\") Queue queue,\n                                @Qualifier(\"confirmExchange\") DirectExchange exchange) {\n        return BindingBuilder.bind(queue).to(exchange).with(\"key1\");\n    }\n\n    // 声明备份 Exchange\n    @Bean(\"backupExchange\")\n    public FanoutExchange backupExchange(){\n        return new FanoutExchange(BACKUP_EXCHANGE_NAME);\n    }\n\n    // 声明确认 Exchange 交换机的备份交换机\n    @Bean(\"confirmExchange\")\n    public DirectExchange\n        confirmExchange() {\n        ExchangeBuilder exchangeBuilder =\n            ExchangeBuilder.directExchange(CONFIRM_EXCHANGE_NAME)\n            .durable(true)\n            //设置该交换机的备份交换机\n            .withArgument(\"alternate-exchange\", BACKUP_EXCHANGE_NAME);\n        return (DirectExchange)exchangeBuilder.build();\n    }\n    \n    // 声明警告队列\n    @Bean(\"warningQueue\")\n    public Queue warningQueue() {\n        return QueueBuilder.durable(WARNING_QUEUE_NAME).build();\n    }\n    \n    // 声明报警队列绑定关系\n    @Bean\n    public Binding warningBinding(@Qualifier(\"warningQueue\") Queue queue,\n                                  @Qualifier(\"backupExchange\") FanoutExchange\n                                  backupExchange) {\n        return BindingBuilder.bind(queue).to(backupExchange);\n    }\n    \n    // 声明备份队列\n    @Bean(\"backQueue\")\n    public Queue backQueue(){\n        return QueueBuilder.durable(BACKUP_QUEUE_NAME).build();\n    }\n    \n    // 声明备份队列绑定关系\n    @Bean\n    public Binding backupBinding(@Qualifier(\"backQueue\") Queue queue,\n                                 @Qualifier(\"backupExchange\") FanoutExchange backupExchange) {\n        return BindingBuilder.bind(queue).to(backupExchange);\n    }\n}\n```\n\n报警消费者：\n\n``` java\n@Component\n@Slf4j\npublic class WarningConsumer {\n    public static final String WARNING_QUEUE_NAME = \"warning.queue\";\n    @RabbitListener(queues = WARNING_QUEUE_NAME)\n    public void receiveWarningMsg(Message message) {\n        String msg = new String(message.getBody());\n        log.error(\"报警发现不可路由消息：{}\", msg);\n    }\n}\n```\n\n此时当交换机发现有无法处理的消息时就会转发给备份交换机，由其将消息转发给备份队列，令报警消费者监听该队列。\n\n**注意**：当`mandatory` 参数与备份交换机可以一起使用的时候，如果两者同时开启，消息究竟何去何从？谁优先级高，答案是**备份交换机优先级高**。\n\n## 幂等性\n\n### 概念\n\n用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。 举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常， 此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱 了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等.\n\n### 消息重复消费\n\n消费者在消费 MQ 中的消息时，MQ 已把消息发送给消费者，消费者在给 MQ 返回 ack 时网络中断， 故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。\n\n### 解决思路\n\nMQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识，比如时间戳或者 UUID ，订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。\n\n### 消费端的幂等性保障\n\n在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性， 这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。\n\n业界主流的幂等性有两种操作:\n\n- 唯一 ID + 指纹码机制，用数据库主键去重；\n- 利用 redis 的原子性去实现。\n\n### 唯一 ID + 指纹码机制\n指纹码：我们的一些规则或者时间戳加别的服务给到的唯一信息码，它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中，优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。\n\n### note Redis 原子性\n利用 redis 执行 setnx 命令，天然具有幂等性，从而实现不重复消费\n\n## 优先级队列\n\n### 使用场景\n\n在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单，淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧。\n\n但是，天猫商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果、小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化，如果发现是大客户的订单给一个相对比较高的优先级， 否则就是默认优先级。\n\n### 实现方式\n\n1. 控制台页面添加一个队列，给该队列设置最大优先级：\n\n![image-20210904170243555](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904170243555.png)\n\n2. 队列中代码添加优先级\n\n``` java\nMap<String, Object> params = new HashMap();\nparams.put(\"x-max-priority\", 10);\nchannel.queueDeclare(\"hello\", true, false, false, params);\n```\n\n3. 消息中代码添加优先级\n\n``` java\nAMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(10).build();\n```\n\n**注意事项**：要让队列实现优先级需要做的事情有：\n\n- 队列需要设置为优先级队列\n- 消息需要设置消息的优先级\n- 消费者需要等待消息已经发送到队列中才去消费，因为这样才有机会对消息进行排序。\n\n4. 生产者：\n\n``` java\npublic class PriorityProducer {\n    private static final String QUEUE_NAME = \"hello\";\n\n    public static void main(String[] args) throws Exception {\n        Channel channel = RabbitMqUtils.getChannel();\n\n        //给消息赋予一个 priority 属性\n        AMQP.BasicProperties properties = new AMQP.BasicProperties().builder().priority(10).build();\n\n        for (int i = 1; i < 11; i++) {\n            String message = \"info\" + i;\n            if (i == 5) {\n                channel.basicPublish(\"\", QUEUE_NAME, properties, message.getBytes());\n            } else {\n                channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes());\n            }\n            System.out.println(\"发送消息完成:\" + message);\n        }\n    }\n}\n```\n\n5. 消费者：\n\n``` java\npublic class PriorityConsumer {\n    private final static String QUEUE_NAME = \"hello\";\n\n    public static void main(String[] args) throws Exception {\n        Channel channel = RabbitMqUtils.getChannel();\n\n        // 设置队列的最大优先级 最大可以设置到 255 官网推荐 1-10 如果设置太高比较吃内存和 CPU\n        Map<String, Object> params = new HashMap();\n        params.put(\"x-max-priority\", 10);\n        channel.queueDeclare(QUEUE_NAME, true, false, false, params);\n\n        // 推送的消息如何进行消费的接口回调\n        DeliverCallback deliverCallback = (consumerTag, delivery) -> {\n            String message = new String(delivery.getBody());\n            System.out.println(message);\n        };\n        \n        // 取消消费的一个回调接口 如在消费的时候队列被删除掉了\n        CancelCallback cancelCallback = (consumerTag) -> {\n            System.out.println(\"消息消费被中断\");\n        };\n\n        channel.basicConsume(QUEUE_NAME, true, deliverCallback, cancelCallback);\n    }\n}\n```\n\n6. 测试：\n\n![image-20210904170543180](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904170543180.png)\n\n## 惰性队列\n\n### 使用场景\n\nRabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会尽可能的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当消费者由于各种各样的原因 (比如消费者下线、宕机亦或者是由于维护而关闭等) 而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。\n\n默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在**内存**之中， 这样可以更加快速的将消息发送给消费者。**即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份**。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法， 但是效果始终不太理想，尤其是在消息量特别大的时候。\n\n**惰性队列会将消息存储到硬盘中，只在内存中保存每条消息在硬盘中的索引，这样就不会消耗大量的内存资源。队列的持久化是指消息数据既保存在硬盘里又保存在内存中。**\n\n### 两种模式\n\n队列具备两种模式：`default` 和 `lazy`。默认的为 `default` 模式，在 3.6.0 之前的版本无需做任何变更。`lazy` 模式即为惰性队列的模式，可以通过调用 `channel.queueDeclare` 方法的时候在参数中设置，也可以通过 `Policy` 的方式设置，**如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级**。 如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。\n\n在队列声明的时候可以通过 `“x-queue-mode”` 参数来设置队列的模式，取值为 `“default”` 和 `“lazy”`。下面示例中演示了一个惰性队列的声明细节：\n\n``` java\nMap<String, Object> args = new HashMap<String, Object>();\nargs.put(\"x-queue-mode\", \"lazy\");\nchannel.queueDeclare(\"myqueue\", false, false, false, args);\n```\n\n在发送 1 百万条消息，每条消息大概占 1KB 的情况下，普通队列占用内存是 1.2GB，而惰性队列仅仅占用 1.5MB。\n\n## RabbitMQ 集群部署\n\n集群部署详细配置见[RabbitMQ文档](https://yuyun-zhao.github.io/documents/消息中间件RabbitMQ)\n\n## Federation Exchange \n\nFederation Exchange 见[RabbitMQ文档](https://yuyun-zhao.github.io/documents/消息中间件RabbitMQ)\n\n## Shovel\n\nFederation 具备的数据转发功能类似，Shovel 够可靠、持续地从一个 Broker 中的队列(作为源端，即 source)拉取数据并转发至另一个 Broker 中的交换器(作为目的端，即 destination)。作为源端的队列和作为 目的端的交换器可以同时位于同一个 Broker，也可以位于不同的 Broker 上。Shovel 可以翻译为\"铲子\"，是 一种比较形象的比喻，这个\"铲子\"可以将消息从一方\"铲子\"另一方。Shovel 行为就像优秀的客户端应用程 序能够负责连接源和目的地、负责消息的读写及负责连接失败问题的处理。\n\n### 搭建步骤\n\n1. 开启插件(需要的机器都开启)\n\n- `rabbitmq-plugins enable rabbitmq_shovel`  \n- `rabbitmq-plugins enable rabbitmq_shovel_management`\n\n2. 原理图(在源头发送的消息直接回进入到目的地队列)\n\n![image-20210904171357566](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904171357566.png)\n\n3. 添加 shovel 源和目的地\n\n![image-20210904171411419](/images/%E3%80%90RabbitMQ%E3%80%91RabbitMQ/image-20210904171411419.png)\n\n\n\n## RabbitMQ 面试题\n\n### RabbitMQ 是什么？\n\nRabbitMQ 是实现了 **高级消息队列协议（AMQP）** 的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ 服务器是用 Erlang 语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。\n\nPS: 也可能直接问什么是消息队列？消息队列就是一个使用队列来通信的组件。\n\n### RabbitMQ 特点？\n\n- 可靠性：RabbitMQ 使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。\n- 灵活的路由：在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。\n- 扩展性：多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。\n- 高可用性：队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。\n- 多种协议：RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP， MQTT 等多种消息中间件协议。\n- 多语言客户端：RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。\n- 管理界面：RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。\n- 插件机制：RabbitMQ 提供了许多插件， 以实现从多方面进行扩展，当然也可以编写自己的插件。\n\n### AMQP 是什么？\n\nRabbitMQ 就是 AMQP 协议的 Erlang 的实现（当然 RabbitMQ 还支持 STOMP2、 MQTT3 等协议 ）。 AMQP 的模型架构和 RabbitMQ 的模型架构是一样的，生产者将消息发送给交换器，交换器和队列绑定。\n\nRabbitMQ 中的交换器、交换器类型、队列、绑定、路由键等都是遵循的 AMQP 协议中相应的概念。目前 RabbitMQ 最新版本默认支持的是 AMQP 0-9-1。\n\n### AMQP 协议 3 层？\n\n- **Module Layer**：协议最高层，主要定义了一些客户端调用的命令，客户端可以用这些命令实现自己的业务逻辑。\n- **Session Layer**：中间层，主要负责客户端命令发送给服务器，再将服务端应答返回客户端，提供可靠性同步机制和错误处理。\n- **Transport Layer**：最底层，主要传输二进制数据流，提供帧的处理、信道复用、错误检测和数据表示等。\n\n### AMQP 模型的几大组件？\n\n- **交换器（Exchange）**：消息代理服务器中用于把消息路由到队列的组件。\n- **队列（Queue）**：用来存储消息的数据结构，位于硬盘或内存中。\n- **绑定（Binding）**：一套规则，告知交换器消息应该将消息投递给哪个队列。\n\n### 说说生产者 Producer 和消费者 Consumer?\n\n生产者：\n\n- 消息生产者，就是投递消息的一方。\n- 消息一般包含两个部分：消息体（payload）和标签（Label）。\n\n消费者：\n\n- 消费消息，也就是接收消息的一方。\n- 消费者连接到 RabbitMQ 服务器，并订阅到队列上。消费消息时只消费消息体，丢弃标签。\n\n### 为什么需要消息队列？\n\n从本质上来说是因为互联网的快速发展，业务不断扩张，促使技术架构需要不断的演进。\n\n从以前的单体架构到现在的微服务架构，成百上千的服务之间相互调用和依赖。从互联网初期一个服务器上有 100 个在线用户已经很了不得，到现在坐拥 10 亿日活的微信。此时，我们需要有一个「工具」来解耦服务之间的关系、控制资源合理合时的使用以及缓冲流量洪峰等等。因此，消息队列就应运而生了。\n\n它常用来实现：**异步处理**、**服务解耦**、**流量控制（削峰）**。\n\n### 说说 Broker 服务节点、Queue 队列、Exchange 交换器？\n\n- **Broker**：可以看做 RabbitMQ 的服务节点。一般请下一个 Broker 可以看做一个 RabbitMQ 服务器。\n- **Queue**：RabbitMQ 的内部对象，用于存储消息。多个消费者可以订阅同一队列，这时队列中的消息会被平摊（轮询）给多个消费者进行处理。\n- **Exchange**：生产者将消息发送到交换器，由交换器将消息路由到一个或者多个队列中。当路由不到时，或返回给生产者或直接丢弃。\n\n### 消息队列有什么优缺点\n\n优点上面已经说了，就是在特殊场景下有其对应的好处，解耦、异步、削峰。缺点有以下几个：\n\n- 系统可用性降低系统引入的外部依赖越多，越容易挂掉。万一 MQ 挂了，MQ 一挂，整套系统崩溃\n- 系统复杂度提高，硬生生加个 MQ 进来，怎么保证消息没有重复消费？怎么处理消息丢失的情况？\n- 怎么保证消息传递的顺序性？\n- 一致性问题， A 系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整？你这数据就不一致 了。\n\n### 如何保证消息的可靠性？\n\n消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢。\n\n- **生产者到 RabbitMQ**：事务机制和 Confirm 机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。\n- **RabbitMQ 自身**：持久化、集群、普通模式、镜像模式。\n- **RabbitMQ 到消费者**：basicAck 机制、死信队列、消息补偿机制。\n\n### 什么是 RoutingKey 路由键？\n\n生产者将消息发送给交换器的时候，会指定一个 `RoutingKey`, 用来指定这个消息的路由规则，这个 `RoutingKey` 需要与交换器类型和绑定键 （`BindingKey`） 联合使用才能最终生效。\n\n### Binding 绑定？\n\n通过绑定将交换器和队列关联起来，一般会指定一个 `BindingKey`, 这样 RabbitMQ 就知道如何正确路由消息到队列了。\n\n### 交换器 4 种类型？\n\n- **fanout**：把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。\n- **direct**：把消息路由到 `BindingKey` 和 `RoutingKey` 完全匹配的队列中。\n- **headers**：不依赖路由键匹配规则路由消息。是根据发送消息内容中的 headers 属性进行匹配。性能差，基本用不到。\n- **topic**：按照匹配规则分发。* 匹配一个单词，# 匹配多个或者 0 个\n\n### 生产者消息运转？\n\n- Producer 先连接到 Broker, 建立连接 Connection, 开启一个信道 （Channel）。\n- Producer 声明一个交换器并设置好相关属性。\n- Producer 声明一个队列并设置好相关属性。\n- Producer 通过路由键将交换器和队列绑定起来。\n- Producer 发送消息到 Broker，其中包含路由键、交换器等信息。\n- 相应的交换器根据接收到的路由键查找匹配的队列。\n- 如果找到，将消息存入对应的队列，如果没有找到，会根据生产者的配置丢弃或者退回给生产者。\n- 关闭信道。\n- 关闭连接。\n\n### 消费者接收消息过程？\n\n- Producer 先连接到 Broker, 建立连接 Connection, 开启一个信道 （Channel）。\n- 向 Broker 请求消费响应的队列中消息，可能会设置响应的回调函数。\n- 等待 Broker 回应并投递相应队列中的消息，接收消息。\n- 消费者确认收到的消息，ack。\n- RabbitMQ 从队列中删除已经确定的消息。\n- 关闭信道。\n- 关闭连接。\n\n### 交换器无法根据自身类型和路由键找到符合条件队列时，有哪些处理？\n\n- `mandatory: true` 返回消息给生产者。\n- `mandatory: false` 直接丢弃。\n\n对应[回退消息](#回退消息)章节\n\n### 死信队列？\n\nDLX，全称为 Dead-Letter-Exchange，死信交换器，死信邮箱。当消息在一个队列中变成死信 （dead message） 之后，它能被重新被发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。\n\n### 导致的死信的几种原因？\n\n- 消息被拒（`Basic.Reject /Basic.Nack`）且 `requeue = false`。\n- 消息 TTL 过期。\n- 队列满了，无法再添加。\n\n### 延迟队列？\n\n存储对应的延迟消息，指当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。\n\n### 优先级队列？\n\n- 优先级高的队列会先被消费。\n- 可以通过 `x-max-priority` 参数来实现。\n- 当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义\n\n### 事务机制？\n\nRabbitMQ 客户端中与事务机制相关的方法有三个：\n\n- `channel.txSelect` 用于将当前的信道设置成事务模式。\n- `channel.txCommit` 用于提交事务。\n- `channel.txRollback` 用于事务回滚，如果在事务提交执行之前由于 RabbitMQ 异常崩溃或者其他原因抛出异常，通过 `txRollback` 来回滚。\n\n### 发送确认机制？\n\n生产者把信道设置为 confirm 确认模式，设置后，所有再改信道发布的消息都会被指定一个唯一的 ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ 就会发送一个确认（`Basic.Ack`） 给生产者（包含消息的唯一 ID），这样生产者就知道消息到达对应的目的地了。\n\n### 消费者获取消息的方式？\n\n- 推\n- 拉\n\n### 消费者某些原因无法处理当前接受的消息如何来拒绝？\n\n- `channel.basicNack`\n- `channel.basicReject`\n\n### 消息传输保证层级？\n\n- `At most once`：最多一次。消息可能会丢失，但不会重复传输。\n- `At least once`：最少一次。消息绝不会丢失，但可能会重复传输。\n- `Exactly once`：恰好一次，每条消息肯定仅传输一次。\n\n### 了解 Virtual Host 吗？\n\n每一个 RabbitMQ 服务器都能创建虚拟的消息服务器，也叫虚拟主机 （virtual host），简称 vhost。默认为 `“/”`。\n\n### 集群中的节点类型？\n\n- **内存节点**：ram, 将变更写入内存。\n- **磁盘节点**：disc, 磁盘写入操作。\n\nRabbitMQ 要求最少有一个磁盘节点。\n\n### 队列结构？\n\n通常由以下两部分组成：\n\n- `rabbit_amqqueue_process`: 负责协议相关的消息处理，即接收生产者发布的消息、向消费者交付消息、处理消息的确认 （包括生产端的 confirm 和消费端的 ack） 等。\n- `backing_queue`: 是消息存储的具体形式和引擎，并向 `rabbit amqqueue process `提供相关的接口以供调用。\n\n### RabbitMQ 中消息可能有的几种状态？\n\n- `alpha`: 消息内容 （包括消息体、属性和 headers） 和消息索引都存储在内存中 。\n- `beta`: 消息内容保存在磁盘中，消息索引保存在内存中。\n- `gamma`: 消息内容保存在磁盘中，消息索引在磁盘和内存中都有 。\n- `delta`: 消息内容和索引都在磁盘中 。\n\n### 在何种场景下使用了消息中间件？\n\n- 接口之间耦合比较严重，中间加一层消息中间件解耦\n- 面对大流量并发时，容易被冲垮\n- 存在性能问题\n\n### 生产者如何将消息可靠投递到 MQ？\n\n- Client 发送消息给 MQ；\n- MQ 将消息持久化后，发送 Ack 消息给 Client，此处有可能因为网络问题导致 Ack 消息无法发送到 Client，那么 Client 在**等待超时**后，会重传消息；\n- Client 收到 Ack 消息后，认为消息已经投递成功。\n\n### MQ 如何将消息可靠投递到消费者？\n\n- MQ 将消息 push 给 Client（或 Client 来 pull 消息）\n- Client 得到消息并做完业务逻辑\n- Client 发送 Ack 消息给 MQ，通知 MQ 删除该消息，此处有可能因为网络问题导致 Ack 失败，那么 Client 会重复消费，这里就引出消费幂等的问题；\n- MQ 将已消费的消息删除\n\n### 如何保证 RabbitMQ 消息队列的高可用？\n\nRabbitMQ 有三种模式：**单机模式**，**普通集群模式**，**镜像集群模式**。\n\n- **单机模式**：就是 demo 级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式。\n- **普通集群模式**：意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。\n- **镜像集群模式**：这种模式，才是所谓的 RabbitMQ 的高可用模式，跟普通集群模式不一样的是，你创建的 queue，无论元数据 （元数据指 RabbitMQ 的配置数据） 还是 queue 里的消息都会存在于多个实例上，然后每次你写消息到 queue 的时候，都会自动把消息到多个实例的 queue 里进行消息同步。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["中间件","RabbitMQ"],"categories":["中间件","RabbitMQ"]},{"title":"【Spring Cloud】Spring Cloud Gateway","url":"/2021/08/30/【SpringCloud】Gateway/","content":"\n## Gateway 简介\n\n> [Gateway官网](https://cloud.spring.io/spring-cloud-static/spring-cloud-Gateway/2.2.1.RELEASE/reference/html/)\n\nSpring Cloud全家桶中有个很重要的组件就是**网关**，在1.x版本中都是采用的Zuul网关。但在2.x版本中，Zuul的升级一直跳票，Spring Cloud最后自己研发了一个网关替代Zuul，那就是Spring Cloud Gateway。—句话：Gateway是原zuul1.x版的替代。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Gateway/54b61d819aa1630bc61732de340b55b4.png)\n\nGateway是在Spring生态系统之上构建的API网关服务，基于Spring 5，Spring Boot 2和Project Reactor等技术。Gateway旨在提供一种简单而有效的方式来对API进行路由，以及提供一些强大的过滤器功能，例如：熔断、限流、重试等。\n\nSpring Cloud Gateway的目标是替代Zuul，在Spring Cloud 2.0以上版本中，没有对新版本的Zul 2.0以上最新高性能版本进行集成，仍然还是使用的Zuul 1.x非Reactor模式的老版本。而为了提升网关的性能，**Spring Cloud Gateway是基于WebFlux框架实现的，而WebFlux框架底层则使用了高性能的Reactor模式通信框架Netty**。\n\nSpring Cloud Gateway提供了统一的路由方式且基于Filter链的方式提供了网关基本的功能，例如:安全，监控/指标，和限流。\n\n<!-- More -->\n\n**微服务架构中网关的位置**\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Gateway/5877d4b9035ead9cd2d037609dceb442.png)\n\n有Zuul了怎么又出来Gateway？我们为什么选择Gateway?\n\n- 一方面因为Zuul1.0已经进入了维护阶段，而且Gateway是Spring Cloud团队研发的，是亲儿子产品，值得信赖。而且很多功能Zuul都没有用起来也非常的简单便捷。\n- Gateway是基于**异步非阻塞模型**上进行开发的，性能方面不需要担心。虽然Netflix早就发布了最新的Zuul 2.x，但Spring Cloud貌似没有整合计划，而且Netflix相关组件都宣布进入维护期。\n\n## Gateway 非阻塞异步模型\n\nSpring Cloud Gateway具有如下特性\n\n- 基于Spring Framework 5，Project Reactor和Spring Boot 2.0进行构建；\n- 动态路由：能够匹配任何请求属性；\n- 可以对路由指定Predicate （断言)和Filter（过滤器)；\n- 集成Hystrix的断路器功能；\n- 集成Spring Cloud 服务发现功能；\n- 易于编写的Predicate （断言)和Filter （过滤器)；\n- 请求限流功能；\n- 支持路径重写。\n\nSpring Cloud Gateway与Zuul的区别：\n\n- Zuul 1.x，是一个基于阻塞I/O的API Gateway。Zuul 1.x基于Servlet 2.5使用阻塞架构它不支持任何长连接（如WebSocket）。Zuul的设计模式和Nginx较像，每次I/О操作都是从工作线程中选择一个执行，请求线程被阻塞到工作线程完成，但是差别是Nginx用C++实现，Zuul用Java实现，而JVM本身会有第一次加载较慢的情况，使得Zuul的性能相对较差。\n- Zuul 2.x理念更先进，想基于Netty非阻塞和支持长连接，但Spring Cloud目前还没有整合。Zuul 2.x的性能较Zuul 1.x有较大提升。在性能方面，根据官方提供的基准测试，Spring Cloud Gateway的RPS（每秒请求数)是Zuul的1.6倍。\n- Spring Cloud Gateway建立在Spring Framework 5、Project Reactor和Spring Boot2之上，使用非阻塞API。\n- Spring Cloud Gateway还支持WebSocket，并且与Spring紧密集成拥有更好的开发体验\n\n### Zuul1.x模型\n\nSpring Cloud中所集成的Zuul版本，采用的是Tomcat容器，使用的是传统的Serviet IO处理模型。\n\nServlet的生命周期？Servlet由Servlet Container进行生命周期管理：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Gateway/b71ecbfb29c939615c988123a0704306.png)\n\n上述模式的缺点：\n\nServlet是一个简单的网络IO模型，当请求进入Servlet Container时，Servlet Container就会为其绑定一个线程，在并发不高的场景下这种模型是适用的。但是一旦高并发，线程数量就会上涨，而线程资源代价是昂贵的（上下文切换，内存消耗大）严重影响请求的处理时间。在一些简单业务场景下，不希望为每个Request分配一个线程，只需要1个或几个线程就能应对极大并发的请求，这种业务场景下Servlet模型没有优势。\n\n所以Zuul 1.X是基于Servlet之上的一个**阻塞式**处理模型，即Spring实现了处理所有Request请求的一个Servlet （DispatcherServlet）并由该Servlet阻塞式处理处理。所以Spring Cloud Zuul无法摆脱Servlet模型的弊端。\n\n### Gateway 模型\n\n> WebFlux：[官方文档](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#spring-webflux)\n\n传统的Web框架，比如说: Struts2，SpringMVC等都是基于Servlet APl与Servlet容器基础之上运行的。\n\n但是在Servlet3.1之后有了**异步非阻塞**的支持。而WebFlux是一个典型非阻塞异步的框架，它的核心是基于Reactor的相关API实现的。相对于传统的Web框架来说，它可以运行在诸如Netty，Undertow及支持Servlet3.1的容器上。**非阻塞式+函数式编程**（Spring 5必须让你使用Java 8）。\n\nSpring WebFlux是Spring 5.0 引入的新的响应式框架，区别于Spring MVC，它不需要依赖Servlet APl，**它是完全异步非阻塞的，并且基于Reactor来实现响应式流规范**。\n\n>  Spring Cloud Gateway requires the Netty runtime provided by Spring Boot and Spring Webflux. It does not work in a traditional Servlet Container or when built as a WAR.link\n\n## Gateway 工作流程\n\n### 三大核心概念\n\n- **Route（路由）** -  路由是构建网关的基本模块,它由ID,目标URI,一系列的断言和过滤器组成,如断言为true则匹配该路由；\n- **Predicate（断言）** -  参考的是Java8的`java.util.function.Predicate`，开发人员可以匹配HTTP请求中的所有内容(例如请求头或请求参数),如果请求与断言相匹配则进行路由；\n- **Filter（过滤）**-  指的是Spring框架中GatewayFilter的实例,使用过滤器,可以在请求被路由前或者之后对请求进行修改。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Gateway/70da1eecc951a338588356ee2db3fa1f.png)\n\nWeb请求，通过一些匹配条件，定位到真正的服务节点。并在这个转发过程的前后，进行一些精细化控制。Predicate就是我们的匹配条件；而Fliter，就可以理解为一个无所不能的拦截器。有了这两个元素，再加上目标uri，就可以实现一个具体的路由了。\n\n### Gateway 工作流程\n\n>  Gateway 工作流程：[官网总结](https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/#gateway-how-it-works)\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Gateway/62be54501c6e2b95620b79cc918a2e9a.png)\n\n- 客户端向Spring Cloud Gateway发出请求。然后在**Gateway Handler Mapping**中找到与请求相匹配的路由，将其发送到**GatewayWeb Handler**（类似于Spring MVC流程）。\n- `Handler`再通过指定的**过滤器链**来将请求发送到我们实际的服务执行业务逻辑，然后返回。\n- 过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前`(“pre”)`或之后`(“post\"`）执行业务逻辑。\n- Filter在`“pre”`类型的过滤器可以做参数校验、权限校验、流量监控、日志输出、协议转换等，在`“post”`类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等有着非常重要的作用。\n\n**核心逻辑：路由转发 + 执行过滤器链。**\n\n## Gateway 模块搭建\n\n1. 新建Module - `cloud-gateway-gateway9527`\n2. 导入Maven依赖，**注意Gateway项目里不能添加`spring-boot-starter-web`的依赖**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-gateway-gateway9527</artifactId>\n\n    <dependencies>\n        <!--gateway-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-gateway</artifactId>\n        </dependency>\n        <!-- 服务注册/发现 -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!-- 配置中心 -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n        </dependency>\n        <!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n        <dependency>\n            <groupId>com.zhao.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n        <!--一般基础配置类-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n3. 配置文件\n\n```yaml\nserver:\n  port: 9527\n\nspring:\n  application:\n    name: cloud-gateway  \n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n        \n############################# 新增网关配置 ###########################\n  cloud:\n    gateway:\n      routes:\n        - id: payment_routh # payment_route    # 路由的ID，没有固定规则但要求唯一，建议配合服务名\n          uri: http://localhost:8001          # 匹配后提供服务的路由地址\n          # uri: lb://cloud-payment-service # 匹配后提供服务的路由地址\n          predicates:\n            - Path=/payment/get/**         # 断言，路径相匹配的进行路由\n\n        - id: payment_routh2 #payment_route    # 路由的ID，没有固定规则但要求唯一，建议配合服务名\n          uri: http://localhost:8001          # 匹配后提供服务的路由地址\n          # uri: lb://cloud-payment-service # 匹配后提供服务的路由地址\n          predicates:\n            - Path=/payment/lb/**         # 断言，路径相匹配的进行路由\n####################################################################\n```\n\n4. 主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\n\n@SpringBootApplication\n@EnableDiscoveryClient // 将网关注册到Nacos注册中心\npublic class GateWayMain9527\n{\n    public static void main(String[] args) {\n        SpringApplication.run(GateWayMain9527.class, args);\n    }\n}\n```\n\n5. 测试：\n\n- 添加网关前 - http://localhost:8001/payment/get/1\n- 添加网关后 - http://localhost:9527/payment/get/1\n\n二者返回相同结果\n\n## Gateway 基于代码方式配置路由\n\n编写代码的方式配置路由需要向容器中注入**RouteLocator**组件，在其内自定义配置路由：\n\n```java\nimport org.springframework.cloud.gateway.route.RouteLocator;\nimport org.springframework.cloud.gateway.route.builder.RouteLocatorBuilder;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class GateWayConfig {\n    @Bean\n    public RouteLocator customRouteLocator(RouteLocatorBuilder routeLocatorBuilder) {\n        RouteLocatorBuilder.Builder routes = routeLocatorBuilder.routes();\n\n        routes.route(\"path_route_baidu\",\n                     r -> r.path(\"/guonei\")\n                     .uri(\"http://news.baidu.com/guonei\")).build();\n\n        return routes.build();\n    }\n}\n```\n\n测试：浏览器输入`http://localhost:9527/guonei`，返回`http://news.baidu.com/guonei`相同的页面\n\n## Gateway 配置动态路由\n\n默认情况下Gateway会根据注册中心注册的服务列表，以注册中心上微服务名为路径创建**动态路由进行转发，从而实现动态路由的功能**。\n\n- **静态路由**：上文中介绍的方式会在配置文件中基于HTTP协议指定目标服务的URI\n- **动态路由**：基于LB协议启用Gateway的负载均衡功能，使用服务名作为URI\n\n修改上文中的配置文件，使用LB协议`lb://serviceName`作为URI实现动态路由：\n\n```yaml\nserver:\n  port: 9527\n\nspring:\n  application:\n    name: cloud-gateway\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n          \n############################# 新增网关配置 ###########################\n  cloud:\n    gateway:\n      discovery:\n        locator:\n          enabled: true # 开启从注册中心动态创建路由的功能，利用微服务名进行路由\n      routes:\n        - id: payment_routh #payment_route    # 路由的ID，没有固定规则但要求唯一，建议配合服务名\n          # uri: http://localhost:8001          # 匹配后提供服务的路由地址\n          uri: lb://cloud-payment-service # 匹配后提供服务的路由地址\n          predicates:\n            - Path=/payment/get/**         # 断言，路径相匹配的进行路由\n\n        - id: payment_routh2 #payment_route    # 路由的ID，没有固定规则但要求唯一，建议配合服务名\n          # uri: http://localhost:8001          # 匹配后提供服务的路由地址\n          uri: lb://cloud-payment-service # 匹配后提供服务的路由地址\n          predicates:\n            - Path=/payment/lb/**         # 断言，路径相匹配的进行路由\n####################################################################\n\neureka:\n  instance:\n    hostname: cloud-gateway-service\n  client: # 网关注册进eureka服务列表内\n    service-url:\n      register-with-eureka: true\n      fetch-registry: true\n      defaultZone: http://eureka7001.com:7001/eureka\n```\n\n## Gateway 常用的 Predicate\n\n> [官方文档](https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/#gateway-request-predicates-factories)\n\nSpring Cloud Gateway将路由匹配作为Spring WebFlux HandlerMapping基础架构的一部分。\n\nSpring Cloud Gateway包括许多内置的Route Predicate工厂。所有这些Predicate都与HTTP请求的不同属性匹配。多个RoutePredicate工厂可以进行组合。\n\nSpring Cloud Gateway创建Route 对象时，使用RoutePredicateFactory 创建 Predicate对象，Predicate 对象可以赋值给Route。Spring Cloud Gateway包含许多内置的Route Predicate Factories。所有这些Predicate都匹配HTTP请求的不同属性。多种Predicate工厂可以组合，并通过逻辑and。\n\n简单地说，Predicate就是为了实现一组匹配规则，让请求过来找到对应的Route进行处理。\n\n常用的Route Predicate Factory：\n\n- The After Route Predicate Factory\n- The Before Route Predicate Factory\n- The Between Route Predicate Factory\n- The Cookie Route Predicate Factory\n- The Header Route Predicate Factory\n- The Host Route Predicate Factory\n- The Method Route Predicate Factory\n- The Path Route Predicate Factory\n- The Query Route Predicate Factory\n- The RemoteAddr Route Predicate Factory\n- The weight Route Predicate Factory\n\n示例：\n\n**The After Route Predicate Factory**\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: after_route\n        uri: https://example.org\n        predicates:\n        # 这个时间后才能起效\n        - After=2017-01-20T17:42:47.789-07:00[America/Denver]\n```\n\n可以通过下述方法获得上述格式的时间戳字符串：\n\n```java\nZonedDateTime zbj = ZonedDateTime.now(); // 默认时区\nSystem.out.println(zbj);\n```\n\n**The After Route Predicate Factory**\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: after_route\n        uri: https://example.org\n        predicates:\n        # 两个时间点之间\n        - Between=2017-01-20T17:42:47.789-07:00[America/Denver], 2017-01-21T17:42:47.789-07:00[America/Denver]\n```\n\n**The Cookie Route Predicate Factory**\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: after_route\n        uri: https://example.org\n        predicates:\n        - Cookie=chocolate, ch.p\n```\n\n测试：\n\n```bash\n# 该命令相当于发get请求，且没带cookie\ncurl http://localhost:9527/payment/lb\n\n# 带cookie的\ncurl http://localhost:9527/payment/lb --cookie \"chocolate=chip\"\n```\n\n**The Header Route Predicate Factory**\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: after_route\n        uri: https://example.org\n        predicates:\n        - Header=X-Request-Id, \\d+\n```\n\n测试：\n\n```sh\n# 带指定请求头的参数的CURL命令\ncurl http://localhost:9527/payment/lb -H \"X-Request-Id:123\"\n```\n\n说白了，Predicate就是为了实现一组匹配规则，让请求过来找到对应的Route进行处理。\n\n## Gateway 的 Filter\n\n> [官方文档](https://cloud.spring.io/spring-cloud-static/spring-cloud-gateway/2.2.1.RELEASE/reference/html/#gatewayfilter-factories)\n\n路由过滤器可用于修改进入的HTTP请求和返回的HTTP响应，路由过滤器只能指定路由进行使用。Spring Cloud Gateway内置了多种路由过滤器，他们都由GatewayFilter的工厂类来产生。常用的GatewayFilter：**AddRequestParameter**，**GatewayFilter**。\n\n- Spring Cloud Gateway Filter的生命周期：\n  - pre\n  - post\n- Spring Cloud Gateway Filter的种类（具体看官方文档）：\n  - GatewayFilter - 有31种\n  - GlobalFilter - 有10种\n    \n\n**实现了GlobalFilter接口的Filter都是全局过滤器，所有请求都会被拦截。**\n\n代码案例：GateWay9527项目添加**MyLogGateWayFilter**类：\n\n```java\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.cloud.gateway.filter.GatewayFilterChain;\nimport org.springframework.cloud.gateway.filter.GlobalFilter;\nimport org.springframework.core.Ordered;\nimport org.springframework.http.HttpStatus;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.server.ServerWebExchange;\nimport reactor.core.publisher.Mono;\n\nimport java.util.Date;\n\n@Component\n@Slf4j\npublic class MyLogGateWayFilter implements GlobalFilter, Ordered {\n\n    @Override\n    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        log.info(\"***********come in MyLogGateWayFilter:  \"+new Date());\n\n        String uname = exchange.getRequest().getQueryParams().getFirst(\"uname\");\n\n        if(uname == null) {\n            log.info(\"*******用户名为null，非法用户，o(╥﹏╥)o\");\n            exchange.getResponse().setStatusCode(HttpStatus.NOT_ACCEPTABLE);\n            return exchange.getResponse().setComplete();\n        }\n\n        return chain.filter(exchange);\n    }\n\n    // 数字越小，优先级越高\n    @Override\n    public int getOrder() {\n        return 0;\n    }\n}\n```\n\n测试：\n\n- http://localhost:9527/payment/lb - 访问异常\n- http://localhost:9527/payment/lb?uname=abc - 访问正常\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】Hystrix","url":"/2021/08/30/【SpringCloud】Hystrix/","content":"\n## Hystrix 简介\n\n### 概述\n\n分布式系统面临的问题：复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免地失败。\n\n**服务雪崩**：多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，这就是所谓的“扇出”。如果扇出的链路上某个微服务的调用响应时间过长或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。\n\n对于高流量的应用来说，单一的后避依赖可能会导致所有服务器上的所有资源都在几秒钟内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障。这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。\n\n所以，通常当你发现一个模块下的某个实例失败后，这时候这个模块依然还会接收流量，然后这个有问题的模块还调用了其他的模块，这样就会发生级联故障，或者叫雪崩。\n\n### Hystrix 是什么\n\n> Hystrix官网：https://github.com/Netflix/Hystrix/wiki/How-To-Use\n\nHystrix是一个用于处理分布式系统的**延迟**和**容错**的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时、异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整体服务失败，避免级联故障，以提高分布式系统的弹性。\n\n“断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似熔断保险丝)，向调用方返回一个符合预期的、可处理的备选响应（FallBack)，而不是长时间的等待或者抛出调用方无法处理的异常，这样就保证了服务调用方的线程不会被长时间、不必要地占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。\n\n<!-- More -->\n\n> hystrix\n> n. 豪猪属;猬草属;豪猪;豪猪亚属\n\n### 服务降级\n\n服务器忙，请稍后再试，不让客户端等待并立刻返回一个友好提示，fallback\n\n哪些情况会触发降级：\n\n- 程序运行导常\n- 超时\n- 服务熔断触发服务降级\n- 线程池/信号量打满\n\n类比保险丝达到最大服务访问后，直接拒绝访问，拉闸限电，然后调用服务降级的方法并返回友好提示。\n\n服务的降级 -> 进而熔断 -> 恢复调用链路\n\n**服务熔断和服务降级的区别：**\n\n- 服务降级是在服务执行的时候，出现超时或异常等情况中断执行，转去执行fallback里的代码\n- 服务熔断是在开启熔断机制后，服务不再尝试执行，而是直接进入fallback里的代码\n\n### 服务限流\n\n秒杀高并发等操作，严禁一窝蜂的过来拥挤，大家排队，一秒钟N个，有序进行。\t\n\n## Hystrix 支付微服务构建\n\n1. 新建服务提供者：`cloud-provider-hygtrix-payment8001`支付微服务。\n2. 导入Maven依赖\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-provider-hystrix-payment8001</artifactId>\n\n    <dependencies>\n        <!--hystrix-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>\n        </dependency>\n        <!--eureka client-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <!--web-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <dependency><!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n            <groupId>com.atguigu.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n3. 配置文件\n\n```yaml\nserver:\n  port: 8001\n\nspring:\n  application:\n    name: cloud-provider-hystrix-payment\n\neureka:\n  client:\n    register-with-eureka: true\n    fetch-registry: true\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka\n```\n\n4. 主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\n\n@SpringBootApplication\n@EnableEurekaClient\n@EnableCircuitBreaker  // 开启服务降级功能\npublic class PaymentHystrixMain8001\n{\n    public static void main(String[] args) {\n        SpringApplication.run(PaymentHystrixMain8001.class, args);\n    }\n}\n```\n\n5. 业务类`PaymentService` 添加 **@HystrixCommand** 注解指定`fallbackMethod`方法，—旦调用服务方法失败并抛出了错误信息后，会自动调用`@HystrixCommand`标注好的`fallbackMethod`调用类中的指定方法\n\n```java\nimport org.springframework.stereotype.Service;\nimport java.util.concurrent.TimeUnit;\n\n@Service\npublic class PaymentService{\n\n    @HystrixCommand(\n        fallbackMethod = \"paymentInfo_TimeOutHandler\" /*指定善后方法名*/,\n        commandProperties = {\n            @HystrixProperty(\n                name=\"execution.isolation.thread.timeoutInMilliseconds\",\n                value=\"3000\")\n    })\n    public String paymentInfo_TimeOut(Integer id)\n    {\n        //int age = 10/0;\n        try { TimeUnit.MILLISECONDS.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); }\n        return \"线程池:  \"+Thread.currentThread().getName()+\" id:  \"+id+\"\\t\"+\"O(∩_∩)O哈哈~\"+\"  耗时(秒): \";\n    } \n\n    // 用来善后的方法\n    public String paymentInfo_TimeOutHandler(Integer id)\n    {\n        return \"线程池:  \"+Thread.currentThread().getName()+\"  8001系统繁忙或者运行报错，请稍后再试,id:  \"+id+\"\\t\"+\"o(╥﹏╥)o\";\n    }\n\n}\n```\n\n上面故意制造两种异常:\n\n1. int age = 10/0，计算异常\n2. 我们能接受3秒钟，它运行5秒钟，超时异常。\n\n当前服务不可用了，做服务降级，兜底的方案都是`paymentInfo_TimeOutHandler()`方法。\n\n注意：主启动类需要添加 **@EnableCircuitBreaker** 注解以开启服务降级功能\n\n## Hystrix 订单微服务构建\n\n1. 创建订单消费微服务：`cloud-consumer-hygtrix-order80`\n2. 导入Maven依赖\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-consumer-feign-hystrix-order80</artifactId>\n\n    <dependencies>\n        <!--openfeign-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\n        </dependency>\n        <!--hystrix-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>\n        </dependency>\n        <!--eureka client-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n        </dependency>\n        <!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n        <dependency>\n            <groupId>com.zhao.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n        <!--web-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--一般基础通用配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n3. 配置文件\n\n```yaml\nserver:\n  port: 80\n\neureka:\n  client:\n    register-with-eureka: false\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka/\n\n# 开启hystrix\nfeign:\n  hystrix:\n    enabled: true\n```\n\n4. 主启动类需要添加 **@EnableHystrix** 注解\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.hystrix.EnableHystrix;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\n\n@SpringBootApplication\n@EnableFeignClients\n@EnableHystrix // 开启Hystrix\npublic class OrderHystrixMain80{\n    public static void main(String[] args){\n        SpringApplication.run(OrderHystrixMain80.class,args);\n    }\n}\n```\n\n5. 业务类\n\n```java\nimport com.zhao.springcloud.service.PaymentHystrixService;\nimport com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;\nimport com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport javax.annotation.Resource;\n\n@RestController\n@Slf4j\npublic class OrderHystirxController {\n    @Resource\n    private PaymentHystrixService paymentHystrixService;\n\n    @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\")\n    @HystrixCommand(fallbackMethod = \"paymentTimeOutFallbackMethod\",\n                    commandProperties = {\n                        @HystrixProperty(\n                            name=\"execution.isolation.thread.timeoutInMilliseconds\",\n                            value=\"1500\")\n    })\n    public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) {\n        //int age = 10/0;\n        String result = paymentHystrixService.paymentInfo_TimeOut(id);\n        return result;\n    }\n    \n    // 善后方法\n    public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id){\n        return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\";\n    }\n\n}\n```\n\n## 全局服务降级 DefaultProperties\n\n目前问题1：每个业务方法对应一个兜底的方法，代码膨胀\n\n解决方法：除了个别重要核心业务有专属，其它普通的可以通过`@DefaultProperties(defaultFallback = “xxx”)`统一跳转到处理结果页面。通用的和独享的各自分开，避免了代码膨胀，合理减少了代码量\n\n```java\nimport com.zhao.springcloud.service.PaymentHystrixService;\nimport com.netflix.hystrix.contrib.javanica.annotation.DefaultProperties;\nimport com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport javax.annotation.Resource;\n\n@RestController\n@Slf4j\n@DefaultProperties(defaultFallback = \"payment_Global_FallbackMethod\")\npublic class OrderHystirxController {\n    @Resource\n    private PaymentHystrixService paymentHystrixService;\n\n    @GetMapping(\"/consumer/payment/hystrix/ok/{id}\")\n    public String paymentInfo_OK(@PathVariable(\"id\") Integer id) {\n        String result = paymentHystrixService.paymentInfo_OK(id);\n        return result;\n    }\n\n    @GetMapping(\"/consumer/payment/hystrix/timeout/{id}\")\n    @HystrixCommand //用全局的fallback方法\n    public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id) {\n        //int age = 10/0;\n        String result = paymentHystrixService.paymentInfo_TimeOut(id);\n        return result;\n    }\n    public String paymentTimeOutFallbackMethod(@PathVariable(\"id\") Integer id) {\n        return \"我是消费者80,对方支付系统繁忙请10秒钟后再试或者自己运行出错请检查自己,o(╥﹏╥)o\";\n    }\n\n    // 下面是全局fallback方法\n    public String payment_Global_FallbackMethod() {\n        return \"Global异常处理信息，请稍后再试，/(ㄒoㄒ)/~~\";\n    }\n}\n```\n\n## 通配服务降级 FeignFallback\n\n目前问题2：统一和自定义的分开，代码混乱\n\n解决方案：本次案例服务降级处理是在客户端80实现完成的，与服务端8001没有关系，只需要为Feign客户端定义的接口添加一个服务降级处理的实现类即可实现解耦。\n\n**使用 OpenFeign + Hystrix fallback 实现消费者端服务降级**\n\n修改`cloud-consumer-feign-hystrix-order80`，根据`cloud-consumer-feign-hystrix-order80`已经有的`PaymentHystrixService`接口新建一个类实现该接口，统一为接口里面的方法进行异常处理。\n\n1. `PaymentHystrixService`接口：基于OpenFeign进行负载均衡和远程调用（见文章[【Spring Cloud】OpenFeign](https://yuyun-zhao.github.io/2021/08/29/%E3%80%90SpringCloud%E3%80%91OpenFeign/)）\n\n```java\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\n\n@Component\n@FeignClient(value = \"CLOUD-PROVIDER-HYSTRIX-PAYMENT\" ,//\n             fallback = PaymentFallbackService.class) //指定PaymentFallbackService类\npublic interface PaymentHystrixService {\n    @GetMapping(\"/payment/hystrix/ok/{id}\")\n    public String paymentInfo_OK(@PathVariable(\"id\") Integer id);\n\n    @GetMapping(\"/payment/hystrix/timeout/{id}\")\n    public String paymentInfo_TimeOut(@PathVariable(\"id\") Integer id);\n}\n```\n\n2. 新建`PaymentFallbackService`类实现`PaymentHystrixService`接口，在其内处理异常\n\n```java\nimport org.springframework.stereotype.Component;\n\n\n@Component\npublic class PaymentFallbackService implements PaymentHystrixService {\n    @Override\n    public String paymentInfo_OK(Integer id) {\n        return \"-----PaymentFallbackService fall back-paymentInfo_OK ,o(╥﹏╥)o\";\n    }\n\n    @Override\n    public String paymentInfo_TimeOut(Integer id) {\n        return \"-----PaymentFallbackService fall back-paymentInfo_TimeOut ,o(╥﹏╥)o\";\n    }\n}\n```\n\n3. 配置文件开启Hystrix\n\n```yaml\nserver:\n  port: 80\n\neureka:\n  client:\n    register-with-eureka: false\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka/\n\nfeign:\n  hystrix:\n    enabled: true\n```\n\n## Hystrix 服务熔断理论\n\n### 熔断机制概述\n\n熔断机制是应对雪崩效应的一种微服务链路保护机制。当扇出链路的某个微服务出错不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。\n\n在Spring Cloud框架里，熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阈值，缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是 **@HystrixCommand** 。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Hystrix/84d60234d01c4b7e9cae515066eb711b.png)\n\n### Hystrix 服务熔断案例\n\n修改`cloud-provider-hystrix-payment8001`工程的`PaymentService`，添加Hystrix**断路器**属性：\n\n```java\nimport cn.hutool.core.util.IdUtil;\nimport com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand;\nimport com.netflix.hystrix.contrib.javanica.annotation.HystrixProperty;\nimport org.springframework.stereotype.Service;\nimport org.springframework.web.bind.annotation.PathVariable;\n\nimport java.util.concurrent.TimeUnit;\n\n@Service\npublic class PaymentService {   \n    \n        // 服务熔断\n        @HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\",commandProperties = {\n            @HystrixProperty(name = \"circuitBreaker.enabled\",value = \"true\"), // 是否开启断路器\n            @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\",value = \"10\"), // 请求次数\n            @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\",value = \"10000\"), // 时间窗口期\n            @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\",value = \"60\"), // 失败率达到多少后跳闸\n        })\n        public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) {\n        if(id < 0) {\n            throw new RuntimeException(\"******id 不能负数\");\n        }\n        String serialNumber = IdUtil.simpleUUID();\n\n        return Thread.currentThread().getName()+\"\\t\"+\"调用成功，流水号: \" + serialNumber;\n    }\n    \n    public String paymentCircuitBreaker_fallback(@PathVariable(\"id\") Integer id) {\n        return \"id 不能负数，请稍后再试，/(ㄒoㄒ)/~~   id: \" +id;\n    }\n\n}\n```\n\n`Controller`：\n\n```java\n@RestController\n@Slf4j\npublic class PaymentController {\n    @Resource\n    private PaymentService paymentService;\n\n    // 服务熔断\n    @GetMapping(\"/payment/circuit/{id}\")\n    public String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) {\n        String result = paymentService.paymentCircuitBreaker(id);\n        log.info(\"**** result: \"+result);\n        return result;\n    }\n}\n```\n\n测试：\n\n- 正确 - http://localhost:8001/payment/circuit/1\n- 错误 - http://localhost:8001/payment/circuit/-1\n\n发出多次错误请求，再来次正确请求，显示的却是`paymentCircuitBreaker_fallback`方法里的信息，说明此时服务已经熔断，就算是正确的请求也不能访问到正常业务，而是直接转发到`paymentCircuitBreaker_fallback`方法。\n\n### 服务熔断工作原理\n\n熔断器工作原理示意图：\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Hystrix/84d60234d01c4b7e9cae515066eb711b.png)\n\n**熔断类型**\n\n- **熔断打开**：请求不再进行调用当前服务，内部设置时钟一般为MTTR(平均故障处理时间)，当打开时长达到所设时钟则进入半熔断状态。\n- **熔断关闭**：熔断关闭不会对服务进行熔断。\n- **熔断半开**：部分请求根据规则调用当前服务，如果请求成功且符合规则则认为当前服务恢复正常，关闭熔断。\n\n**官网断路器流程图**\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Hystrix/825d02fd7925521b1d76be0a21c15db0.png)\n\n**断路器参数属性：**\n\n```java\n@HystrixCommand(fallbackMethod = \"paymentCircuitBreaker_fallback\",commandProperties = {\n    @HystrixProperty(name = \"circuitBreaker.enabled\",value = \"true\"),// 是否开启断路器\n    @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\",value = \"10\"), // 请求次数\n    @HystrixProperty(name = \"circuitBreaker.sleepWindowInMilliseconds\",value = \"10000\"), // 时间窗口期\n    @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\",value = \"60\"), // 失败率达到多少后跳闸\n})\npublic String paymentCircuitBreaker(@PathVariable(\"id\") Integer id) {\n    ...\n}\n```\n\n涉及到断路器的三个重要参数：\n\n- **快照时间窗**：断路器确定是否打开需要统计一些请求和错误数据，而统计的时间范围就是快照时间窗，默认为最近的10秒，该时间窗内若错误请求比例达到阈值，则开启熔断。\n- **请求总数阀值**：在快照时间窗内，必须满足请求总数阀值才有资格熔断。默认为20，意味着在10秒内，如果该hystrix命令的调用次数不足20次7，即使所有的请求都超时或其他原因失败，断路器都不会打开。\n- **错误百分比阀值**：当请求总数在快照时间窗内超过了阀值，比如发生了30次调用，如果在这30次调用中，有15次发生了超时异常，也就是超过50%的错误百分比，在默认设定50%阀值情况下，这时候就会将断路器打开。\n\n**断路器开启或者关闭的条件**：\n\n- 到达以下阀值，断路器将会开启：\n  - 当满足一定的阀值的时候（默认10秒内超过20个请求次数)\n  - 当失败率达到一定的时候（默认10秒内超过50%的请求失败)\n- 当开启的时候，所有请求都不会进行转发、\n- 一段时间之后（默认是5秒)，这个时候断路器是半开状态，会让其中一个请求进行转发。如果成功，断路器会关闭，若失败，继续开启。\n\n**断路器打开之后再有请求调用的时候，将不会调用主逻辑，而是直接调用降级fallback**。通过断路器，实现了自动地发现错误并将降级逻辑切换为主逻辑，减少响应延迟的效果。\n\n原来的主逻辑要如何恢复呢？对于这一问题，hystrix也为我们实现了**自动恢复功能**：当断路器打开，对主逻辑进行熔断之后，hystrix会启动一个**休眠时间窗**，在这个时间窗内，**降级逻辑是临时成为主逻辑**，当休眠时间窗到期，断路器将进入半开状态，释放一次请求到原来的主逻辑上，如果此次请求正常返回，那么断路器将继续闭合，主逻辑恢复，如果这次请求依然有问题，断路器继续进入打开状态，休眠时间窗重新计时。\n\n**@HystrixProperty 所有配置**\n\n```java\n@HystrixCommand(fallbackMethod = \"fallbackMethod\", \n                groupKey = \"strGroupCommand\", \n                commandKey = \"strCommand\", \n                threadPoolKey = \"strThreadPool\",\n                \n                commandProperties = {\n                    // 设置隔离策略，THREAD 表示线程池 SEMAPHORE：信号池隔离\n                    @HystrixProperty(name = \"execution.isolation.strategy\", value = \"THREAD\"),\n                    // 当隔离策略选择信号池隔离的时候，用来设置信号池的大小（最大并发数）\n                    @HystrixProperty(name = \"execution.isolation.semaphore.maxConcurrentRequests\", value = \"10\"),\n                    // 配置命令执行的超时时间\n                    @HystrixProperty(name = \"execution.isolation.thread.timeoutinMilliseconds\", value = \"10\"),\n                    // 是否启用超时时间\n                    @HystrixProperty(name = \"execution.timeout.enabled\", value = \"true\"),\n                    // 执行超时的时候是否中断\n                    @HystrixProperty(name = \"execution.isolation.thread.interruptOnTimeout\", value = \"true\"),\n                    \n                    // 执行被取消的时候是否中断\n                    @HystrixProperty(name = \"execution.isolation.thread.interruptOnCancel\", value = \"true\"),\n                    // 允许回调方法执行的最大并发数\n                    @HystrixProperty(name = \"fallback.isolation.semaphore.maxConcurrentRequests\", value = \"10\"),\n                    // 服务降级是否启用，是否执行回调函数\n                    @HystrixProperty(name = \"fallback.enabled\", value = \"true\"),\n                    // 是否启用断路器\n                    @HystrixProperty(name = \"circuitBreaker.enabled\", value = \"true\"),\n                    // 该属性用来设置在滚动时间窗中，断路器熔断的最小请求数。例如，默认该值为 20 的时候，如果滚动时间窗（默认10秒）内仅收到了19个请求， 即使这19个请求都失败了，断路器也不会打开。\n                    @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"20\"),\n                    \n                    // 该属性用来设置在滚动时间窗中，表示在滚动时间窗中，在请求数量超过 circuitBreaker.requestVolumeThreshold 的情况下，如果错误请求数的百分比超过50, 就把断路器设置为 \"打开\" 状态，否则就设置为 \"关闭\" 状态。\n                    @HystrixProperty(name = \"circuitBreaker.errorThresholdPercentage\", value = \"50\"),\n                    // 该属性用来设置当断路器打开之后的休眠时间窗。 休眠时间窗结束之后，会将断路器置为 \"半开\" 状态，尝试熔断的请求命令，如果依然失败就将断路器继续设置为 \"打开\" 状态，如果成功就设置为 \"关闭\" 状态。\n                    @HystrixProperty(name = \"circuitBreaker.sleepWindowinMilliseconds\", value = \"5000\"),\n                    // 断路器强制打开\n                    @HystrixProperty(name = \"circuitBreaker.forceOpen\", value = \"false\"),\n                    // 断路器强制关闭\n                    @HystrixProperty(name = \"circuitBreaker.forceClosed\", value = \"false\"),\n                    // 滚动时间窗设置，该时间用于断路器判断健康度时需要收集信息的持续时间\n                    @HystrixProperty(name = \"metrics.rollingStats.timeinMilliseconds\", value = \"10000\"),\n                    \n                    // 该属性用来设置滚动时间窗统计指标信息时划分\"桶\"的数量，断路器在收集指标信息的时候会根据设置的时间窗长度拆分成多个 \"桶\" 来累计各度量值，每个\"桶\"记录了一段时间内的采集指标。\n                    // 比如 10 秒内拆分成 10 个\"桶\"收集这样，所以 timeinMilliseconds 必须能被 numBuckets 整除。否则会抛异常\n                    @HystrixProperty(name = \"metrics.rollingStats.numBuckets\", value = \"10\"),\n                    // 该属性用来设置对命令执行的延迟是否使用百分位数来跟踪和计算。如果设置为 false, 那么所有的概要统计都将返回 -1。\n                    @HystrixProperty(name = \"metrics.rollingPercentile.enabled\", value = \"false\"),\n                    // 该属性用来设置百分位统计的滚动窗口的持续时间，单位为毫秒。\n                    @HystrixProperty(name = \"metrics.rollingPercentile.timeInMilliseconds\", value = \"60000\"),\n                    // 该属性用来设置百分位统计滚动窗口中使用 “ 桶 ”的数量。\n                    @HystrixProperty(name = \"metrics.rollingPercentile.numBuckets\", value = \"60000\"),\n                    // 该属性用来设置在执行过程中每个 “桶” 中保留的最大执行次数。如果在滚动时间窗内发生超过该设定值的执行次数，\n                    // 就从最初的位置开始重写。例如，将该值设置为100, 滚动窗口为10秒，若在10秒内一个 “桶 ”中发生了500次执行，\n                    // 那么该 “桶” 中只保留 最后的100次执行的统计。另外，增加该值的大小将会增加内存量的消耗，并增加排序百分位数所需的计算时间。\n                    @HystrixProperty(name = \"metrics.rollingPercentile.bucketSize\", value = \"100\"),\n                    \n                    // 该属性用来设置采集影响断路器状态的健康快照（请求的成功、 错误百分比）的间隔等待时间。\n                    @HystrixProperty(name = \"metrics.healthSnapshot.intervalinMilliseconds\", value = \"500\"),\n                    // 是否开启请求缓存\n                    @HystrixProperty(name = \"requestCache.enabled\", value = \"true\"),\n                    // HystrixCommand的执行和事件是否打印日志到 HystrixRequestLog 中\n                    @HystrixProperty(name = \"requestLog.enabled\", value = \"true\"),\n\n                },\n                threadPoolProperties = {\n                    // 该参数用来设置执行命令线程池的核心线程数，该值也就是命令执行的最大并发量\n                    @HystrixProperty(name = \"coreSize\", value = \"10\"),\n                    // 该参数用来设置线程池的最大队列大小。当设置为 -1 时，线程池将使用 SynchronousQueue 实现的队列，否则将使用 LinkedBlockingQueue 实现的队列。\n                    @HystrixProperty(name = \"maxQueueSize\", value = \"-1\"),\n                    // 该参数用来为队列设置拒绝阈值。 通过该参数， 即使队列没有达到最大值也能拒绝请求。\n                    // 该参数主要是对 LinkedBlockingQueue 队列的补充,因为 LinkedBlockingQueue 队列不能动态修改它的对象大小，而通过该属性就可以调整拒绝请求的队列大小了。\n                    @HystrixProperty(name = \"queueSizeRejectionThreshold\", value = \"5\"),\n                }\n               )\npublic String doSomething() {\n\t...\n}\n```\n\n### 服务熔断整体流程\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Hystrix/hystrix-command-flow-chart.png)\n\n步骤说明：\n\n1. 创建`HystrixCommand` （用在依赖的服务返回单个操作结果的时候）或`HystrixObserableCommand`（用在依赖的服务返回多个操作结果的时候）对象\n2. 执行命令，并选择以下四种方法之一获取命令结果：\n   1. `HystrixCommand.execute()`：同步执行，从依赖的服务返回一个单一的结果对象或是在发生错误的时候抛出异常\n   2. `HystrixCommand.queue()`：异步执行，直接返回一个Future对象，其中包含了服务执行结束时要返回的单一结果对象\n   3. `HystrixObservableCommand.obseve()`：返回Observable对象，它代表了操作的多个统计结果，它是一个Hot Observable （不论“事件源”是否有“订阅者”，都会在创建后对事件进行发布，所以对于Hot Observable的每一个“订阅者”都有可能是从“事件源”的中途开始的，并可能只是看到了整个操作的局部过程）\n   4. `HystrixObservableCommand.toObservable()`：同样会返回Observable对象，也代表了操作的多个结果，但它返回的是一个Cold Observable（没有“订间者”的时候并不会发布事件，而是进行等待，直到有“订阅者\"之后才发布事件，所以对于Cold Observable 的订阅者，它可以保证从一开始看到整个操作的全部过程）\n3. 若当前命令的请求缓存功能是被启用的，并且该命令已经在缓存中，那么缓存的结果会立即以`Observable`对象的形式返回，**即若该命令之前已经执行成功，则直接返回缓存的结果，不需重复执行业务**\n4. 若命令没有缓存过，来到此步骤：检查断路器是否为打开状态。**如果断路器是打开的，那么Hystrix不会执行命令，而是转接到fallback处理逻辑（步骤8）**；如果断路器是关闭的，检查是否有可用资源来执行命令（步骤5）\n5. 若断路器关闭状态，来到此步骤：判断**线程池/请求队列信号量**是否占满。如果命令依赖服务的专有线程地和请求队列，或者**信号量（不使用线程的时候）已经被占满，那么Hystrix也不会执行命令，而是转接到fallback处理（步骤8）** \n6. 若线程池/请求队列信号量没有被占满，来到此步骤：此步骤执行目标方法，若执行出现异常或执行超时，则进行服务降级（跳转到步骤8）；若执行成功，则到步骤9。Hystrix会根据我们编写的方法来决定采取什么样的方式去请求依赖服务：\n   1. `HystrixCommand.run()`：返回一个单一的结果，或者抛出异常。\n   2. `HystrixObservableCommand.construct()`：返回一个`Observable`对象来发射多个结果，或通过`onError`发送错误通知。\n7. Hystix会将“成功”、“失败”、“拒绝”、“超时” 等信息报告给断路器，而**断路器会维护一组计数器来统计这些数据**。断路器会使用这些统计数据来决定是否要将断路器打开，来对某个依赖服务的请求进行\"熔断/短路\"。\n8. 当命令执行失败的时候，来到此步骤：Hystix会进入fallback尝试回退处理，我们通常也称此造作为“服务降级”。**而能够引起服务降级处理的情况有下面几种**：\n   1. 第4步∶当前命令处于“熔断/短路”状态，断洛器是打开的时候。\n   2. 第5步∶当前命令的钱程池、请求队列或者信号量被占满的时候。\n   3. 第6步∶执行目标方法抛出异常或执行超时。\n9. 当Hystrix命令执行成功之后，它会将处理结果直接返回或是以`Observable`的形式返回，并将当前命令保存到缓存中，之后再来重复命令就可以直接返回结果不需要再执行一次方法。\n\n**tips**：如果我们没有为命令实现降级逻辑或者在降级处理逻辑中抛出了异常，Hystrix依然会返回一个`Obsevable`对象，但是它不会发射任何数据结果，而是通过`onError`方法通知命令立即中断请求，并通过`onError`方法将引起命令失败的异常发送给调用者。\n\n## Hystrix 图形化 Dashboard 搭建\n\n除了隔离依赖服务的调用以外，Hystrix还提供了准实时的调用监控(Hystrix Dashboard)，Hystrix会持续地记录所有通过Hystrix发起的请求的执行信息，并以统计报表和图形的形式展示给用户，包括每秒执行多少请求多少成功，多少失败等。\n\nNetflix通过`hystrix-metrics-event-stream`项目实现了对以上指标的监控。Spring Cloud也提供了Hystrix Dashboard的整合，对监控内容转化成可视化界面。\n\n详细配置见博客 https://blog.csdn.net/u011863024/article/details/114298282\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】OpenFeign","url":"/2021/08/29/【SpringCloud】OpenFeign/","content":"\n## OpenFeign 简介\n\n>  [官方文档](https://cloud.spring.io/spring-cloud-static/Hoxton.SR1/reference/htmlsingle/#spring-cloud-openfeign) \n\nFeign是一个**声明式**的HTTP客户端，它的目的就是让远程调用更简单。它是Spring Cloud组件中的一个轻量级RESTful的HTTP服务客户端。使用Feign能让编写Web Service客户端更加简单。它的使用方法是定义一个**服务接口**然后在上面**添加注解**。使用Feign调用API就像调用本地方法一样，从避免了调用目标微服务时，需要不断的解析/封装JSON数据的繁琐。\n\nFeign也支持可拔插式的编码器和解码器。Spring Cloud对Feign进行了封装，使其支持了Spring MVC标准注解和`HttpMessageConverters`。Feign可以与Eureka和Ribbon组合使用以支持负载均衡。[Github地址](https://github.com/spring-cloud/spring-cloud-openfeign)\n\n**Feign集成了Ribbon和RestTemplate。Ribbon+Eureka是面向微服务编程，而Feign是面向接口编程。**\n\n### Feign 能干什么\n\nFeign旨在使编写Java HTTP客户端变得更容易。\n\n在使用`Ribbon + RestTemplate`进行服务调用时（见文章[【Spring Cloud】Ribbon](https://yuyun-zhao.github.io/2021/08/29/%E3%80%90SpringCloud%E3%80%91Ribbon/)），利用`RestTemplate`对HTTP请求的封装处理，形成了一套模版化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一些客户端类来包装这些依赖服务的调用。\n\n所以，Feign在此基础上做了进一步封装，由他来帮助我们定义和实现依赖服务接口的定义。在Feign的实现下，**我们只需创建一个接口并使用注解的方式来配置它**（类比Dao接口上面标注`@Mapper`注解，现在是一个微服务接口上面标注一个`@FeignClient`注解），即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon时封装服务调用客户端的开发量。\n\n**Feign利用动态代理机制对Ribbon和RestTemplate进行了封装，使用接口的方式实现负载均衡和服务调用。**\n\n<!-- More -->\n\n### Feign 集成了 Ribbon\n\n利用Ribbon维护了Payment的服务列表信息，并且通过轮询实现了客户端的负载均衡。而与Ribbon不同的是，通过Feign只需要**定义服务绑定接口**且以**声明式的方法**，优雅而简单地实现了服务调用。\n\n### Feign 和 OpenFeign 两者区别\n\nFeign是Spring Cloud组件中的一个轻量级RESTful的HTTP服务客户端。Feign内置了Ribbon，用来做客户端负载均衡，去调用服务注册中心的服务。Feign的使用方式是：使用Feign的注解定义接口，调用这个接口，就可以调用服务注册中心的服务。\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-feign</artifactId>\n</dependency>\n```\n\nOpenFeign是Spring Cloud在Feign的基础上**支持了SpringMVC的注解**，如`@RequesMapping`等等。OpenFeign的`@FeignClient`可以解析Spring MVC的`@RequestMapping`注解下的接口，并通过**动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务**。\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n```\n\n```java\n@Component\n@FeignClient(value = \"CLOUD-PAYMENT-SERVICE\")\npublic interface PaymentFeignService\n{\n    @GetMapping(value = \"/payment/get/{id}\")\n    public CommonResult<Payment> getPaymentById(@PathVariable(\"id\") Long id);\n}\n```\n\n## OpenFeign 服务调用\n\n**接口 + 注解：微服务调用接口 + `@FeignClient`**\n\n1. 新建`cloud-consumer-feign-order80`\n2. 导入依赖\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-consumer-feign-order80</artifactId>\n\n    <dependencies>\n        <!--openfeign-->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-openfeign</artifactId>\n        </dependency>\n               <!-- 服务注册/发现 -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n        </dependency>\n        <!-- 配置中心 -->\n        <dependency>\n            <groupId>com.alibaba.cloud</groupId>\n            <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n        </dependency>\n        <!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n        <dependency>\n            <groupId>com.zhao.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n        <!--web-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!--一般基础通用配置-->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n3. 配置文件\n\n```yaml\nserver:\n  port: 80\n\nspring:\n  cloud:\n    nacos:\n      discovery:\n        server-addr: localhost:8848\n\n```\n\n4. 主启动类使用 `@EnableFeignClients` 开启远程调用\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.openfeign.EnableFeignClients;\n\n@SpringBootApplication\n@EnableDiscoveryClient\n// 记得要开启远程调用注解，如果feign的接口不写@Component，则这里必须指定这些feign的接口在哪个包下，如果加了@Component就可以不写了\n@EnableFeignClients(basePackage = \"com.zhao.mall.member.feign\")\npublic class OrderFeignMain80 {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderFeignMain80.class, args);\n    }\n}\n```\n\n5. 业务类：业务逻辑接口 + `@FeignClient`配置调用provider服务。新建`PaymentFeignService`接口并新增注解`@FeignClient`，该接口将通过**动态代理的方式产生实现类，实现类中做负载均衡并调用其他服务**。\n\n```java\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.stereotype.Component;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\n\n// 将其注册到 Spring 容器中，否则无法获取该类，就不能进行远程调用\n@Component\n@FeignClient(value = \"CLOUD-PAYMENT-SERVICE\")\npublic interface PaymentFeignService {\n    // 调用该方法时，将会去注册中心找到 CLOUD-PAYMENT-SERVICE 服务，并向其发出 /payment/get/{id} 请求并获得返回结果，从而实现远程调用\n    @GetMapping(value = \"/payment/get/{id}\")\n    public CommonResult<Payment> getPaymentById(@PathVariable(\"id\") Long id);\n    \n    // 发送post请求给远程服务，将@RequestBody注解修饰的实体对象转换成JSON格式发送给远程服务，其在接收到JSON数据后进行转换，解析出对应的数据\n    @PostMapping(value = \"/payment/save\")\n    public CommonResult<Payment> savePayment(@RequestBody Entity entity);\n}\n```\n\n6. 控制层Controller调用该代理对象\n\n```java\nimport com.zhao.springcloud.entities.CommonResult;\nimport com.zhao.springcloud.entities.Payment;\nimport com.zhao.springcloud.service.PaymentFeignService;\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\nimport org.springframework.web.bind.annotation.RestController;\nimport javax.annotation.Resource;\n\n@RestController\n@Slf4j\npublic class OrderFeignController {\n    @Resource\n    private PaymentFeignService paymentFeignService;\n\n    @GetMapping(value = \"/consumer/payment/get/{id}\")\n    public CommonResult<Payment> getPaymentById(@PathVariable(\"id\") Long id) {\n        return paymentFeignService.getPaymentById(id);\n    }\n    \n    @PostMapping(value = \"/consumer/payment/save\")\n    public CommonResult<Payment> savePayment(@RequestBody Entity entity) {\n        return paymentFeignService.savePayment(entity);\n    }\n}\n```\n\n## OpenFeign 超时控制\n\nOpenFeign默认等待1秒钟，超过后报错。YML文件里需要开启OpenFeign客户端超时控制：\n\n```yaml\n# 设置Feign客户端超时时间(OpenFeign默认支持Ribbon)(单位：毫秒)\nribbon:\n  # 指的是建立连接后从服务器读取到可用资源所用的时间\n  ReadTimeout: 5000\n  # 指的是建立连接所用的时间，适用于网络状况正常的情况下，两端连接所用的时间\n  ConnectTimeout: 5000\n```\n\n## OpenFeign 日志增强\n\n### 日志打印功能\n\nFeign提供了日志打印功能，我们可以通过配置来调整日志级别，从而了解Feign中Http请求的细节。即对Feign接口的调用情况进行监控和输出\n\n### 日志级别\n\n- `NONE`：默认的，不显示任何日志;\n- `BASIC`：仅记录请求方法、URL、响应状态码及执行时间;\n- `HEADERS`：除了`BASIC`中定义的信息之外，还有请求和响应的头信息;\n- `FULL`：除了`HEADERS`中定义的信息之外，还有请求和响应的正文及元数据。\n\n### 配置日志 Bean\n\n```java\nimport feign.Logger;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class FeignConfig {\n    @Bean\n    Logger.Level feignLoggerLevel() {\n        return Logger.Level.FULL;\n    }\n}\n```\n\nYML文件里需要开启日志的Feign客户端\n\n```yaml\nlogging:\n  level:\n    # feign日志以什么级别监控哪个接口\n    com.zhao.springcloud.service.PaymentFeignService: debug\n```\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Spring Cloud】Ribbon","url":"/2021/08/29/【SpringCloud】Ribbon/","content":"\n## Ribbon 简介\n\nSpring Cloud Ribbon是基于Netflix Ribbon实现的一套**客户端负载均衡工具**。[Github - Ribbon](https://github.com/Netflix/ribbon/wiki/Getting-Started)\n\nRibbon是Netflix发布的开源项目，主要功能是提供客户端的**软件负载均衡算法**和**服务调用**。Ribbon客户端组件提供一系列完善的配置项如连接超时，重试等。\n\n简单地说，就是在配置文件中列出**Load Balancer**（简称LB）后面所有的机器，Ribbon会自动基于某种规则（如简单轮询，随机连接等）去连接这些机器。我们很容易使用Ribbon实现**自定义的**负载均衡算法。\n\n**Ribbon = 负载均衡 + RestTemplate调用**\n\n> ribbon\n> n. (用于捆绑或装饰的)带子;丝带;带状物;狭长的东西;绶带;勋带\n\n<!-- More -->\n\nNetflix的Ribbon目前也进入维护模式，未来可能被Spring Cloud LoadBalacer替代，但其目前在大量的生产环境仍然工作。\n\n## Load Balance 负载均衡\n\n负载均衡简单地说就是将用户的请求平摊分配到多个服务上，从而达到系统的HA （高可用）。常见的负载均衡有软件Nginx，LVS，硬件F5等。\n\nRibbon本地负载均衡客户端 VS Nginx服务端负载均衡区别\n\n- Nginx：用来对用户发来的请求进行负载均衡，即用户发来请求访问某一台**服务消费者微服务**，Nginx基于负载均衡算法选择出合适的**消费者微服务**；\n- Ribbon：当用户发来的请求经过Nginx进行负载均衡后，选择了某一台**服务消费者微服务**，在调用其接口时候，消费者会从注册中心获取**服务提供者微服务**的列表，再基于自己的负载均衡算法选择某一台提供者实现RPC远程服务调用。\n\n### 集中式LB\n\n即在服务的消费方和提供方之间使用独立的LB设施（可以是硬件，如F5，也可以是软件，如Nginx)，由该设施负责把访问请求通过某种策略转发至服务的提供方;\n\n### 进程内LB\n\n将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选择出一个合适的服务器。\n\n**Ribbon就属于进程内LB**，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址。\n\n## Ribbon 的负载均衡和 Rest 调用\n\n基于Ribbon实现负载均衡的方法：在**RestTemplate**对象上添加 **@LoadBalanced** 注解，之后调用其方法时将服务名作为URL传入，即可开启负载均衡功能。（**RestTemplate**本身不具有负载均衡能力，需要开启Ribbon的注解）\n\n### 架构说明\n\n总结：Ribbon其实就是一个软负载均衡的客户端组件，它可以和其他所需请求的客户端结合使用，和Eureka结合只是其中的一个实例。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Ribbon/145b915e56a85383b3ad40f0bb2256e0.png)\n\nRibbon在工作时分成两步：\n\n- 第一步先选择Eureka Server，它优先选择在同一个区域内**负载较少**的Server；\n- 第二步再根据用户指定的策略，从取到的服务注册列表中选择一个地址。\n\n其中Ribbon提供了多种策略：比如轮询、随机和根据响应时间加权。\n\n### 导入 Maven 依赖\n\n导入`spring-cloud-starter-ribbon`即可：\n\n```xml\n<dependency>\n    <groupld>org.springframework.cloud</groupld>\n    <artifactld>spring-cloud-starter-netflix-ribbon</artifactid>\n</dependency>\n```\n\n若导入了`spring-cloud-starter-netflix-eureka-client`，其自带`spring-cloud-starter-ribbon`依赖。\n\n### RestTemplate 用法\n\n[RestTemplate Java Doc](https://docs.spring.io/spring-framework/docs/5.2.2.RELEASE/javadoc-api/org/springframework/web/client/RestTemplate.html)\n\n- **getForObject()** / **getForEntity()** - GET请求方法\n  - **getForObject()**：返回对象为响应体中数据转化成的对象，基本上可以理解为Json。\n  - **getForEntity()**：返回对象为**ResponseEntity**对象，包含了响应中的一些重要信息，比如响应头、响应状态码、响应体等。\n- **postForObject() / postForEntity()** - POST请求方法\n\n```java\n@GetMapping(\"/consumer/payment/getForEntity/{id}\")\npublic CommonResult<Payment> getPayment2(@PathVariable(\"id\") Long id) {\n    ResponseEntity<CommonResult> entity = restTemplate.getForEntity(PAYMENT_URL+\"/payment/get/\"+id,CommonResult.class);\n\n    if(entity.getStatusCode().is2xxSuccessful()){\n        return entity.getBody();//getForObject()\n    }else{\n        return new CommonResult<>(444,\"操作失败\");\n    }\n}\n```\n\n### 开启负载均衡功能\n\n在支付服务搭建Eureka集群后，订单服务使用 **@LoadBalanced** 注解开启**负载均衡**功能，此注解在Spring Cloud提供的`LoadBalacer`包下：\n\n```java\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\n\n@Configuration\npublic class ApplicationContextConfig {\n\n    // 赋予RestTemplate负载均衡的能力\n    @LoadBalanced\n    @Bean\n    public RestTemplate getRestTemplate() {\n        return new RestTemplate();\n    }\n}\n```\n\n此时`PAYMENT_URL` 需要写成支付服务对应的服务名： `http://CLOUD-PAYMENT-SERVICE`\n\n\n```java\n@Slf4j\n@RestController\npublic class OrderController {\n    // public static final String PAYMENT_URL = \"http://localhost:8001\";\n    public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\";\n\n    @Autowired\n    private RestTemplate restTemplate;\n\n    @GetMapping(value = \"/consumer/payment/create\")\n    public CommonResult create(Payment payment) {\n        // 以JSON的形式发送POST请求给8001端口，payment数据信息保存在request body中，因此对应的Controller需要加@RequestBody注解\n        return restTemplate.postForObject(PAYMENT_URL + \"/payment/create\", payment, CommonResult.class);\n    }\n\n    @GetMapping(\"/consumer/payment/get/{id}\")\n    public CommonResult<Payment> getPayment(@PathVariable(\"id\") Long id) {\n        log.info(\"1211\");\n\n        return restTemplate.getForObject(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class);\n    }\n}\n```\n\n此时消费者访问提供者时即开启了负载均衡功能\n\n## Ribbon 默认自带的负载规则\n\n**lRule**：根据特定算法中从服务列表中选取一个要访问的服务\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Ribbon/87243c00c0aaea211819c0d8fc97e445.png)\n\n- **RoundRobinRule**：轮询\n- **RandomRule**：随机\n- **RetryRule**：先按照`RoundRobinRule`的策略获取服务，如果获取服务失败则在指定时间内会进行重\n- **WeightedResponseTimeRule**：对`RoundRobinRule`的扩展，响应速度越快的实例选择权重越大，越容易被选择\n- **BestAvailableRule**：会先过滤掉由于多次访问故障而处于断路器跳闸状态的服务，然后选择一个并发量最小的服务\n- **AvailabilityFilteringRule**：先过滤掉故障实例，再选择并发较小的实例\n- **ZoneAvoidanceRule**：**默认规则**，复合判断Server所在区域的性能和Server的可用性选择服务器\n\n## Ribbon 负载规则替换\n\n官方文档明确给出了警告：修改Ribbon负载规则的自定义配置类不能放在**@ComponentScan**所扫描的当前包下以及子包下，否则我们自定义的这个配置类就会被所有的Ribbon客户端所共享，达不到特殊化定制的目的了。（也就是说不要将Ribbon配置类与主启动类同包）\n\n1. 新建package - `com.zhao.myrule`，在`com.zhao.myrule`下新建**MySelfRule**规则类：\n\n```java\nimport com.netflix.loadbalancer.IRule;\nimport com.netflix.loadbalancer.RandomRule;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class MySelfRule {\n\n    @Bean\n    public IRule myRule(){\n        return new RandomRule();\n    }\n}\n```\n\n2. 主启动类添加 **@RibbonClient**\n\n```java\nimport com.zhao.myrule.MySelfRule;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\nimport org.springframework.cloud.netflix.ribbon.RibbonClient;\n\n@SpringBootApplication\n@EnableEurekaClient\n//添加到此处\n@RibbonClient(name = \"CLOUD-PAYMENT-SERVICE\", configuration = MySelfRule.class)\npublic class OrderMain80\n{\n    public static void main( String[] args ){\n        SpringApplication.run(OrderMain80.class, args);\n    }\n}\n```\n\n在启动类上配置了 **@RibbonClient** 注解后，该微服务即开启了Ribbon功能，此时再使用**RestTemplate**调用服务端时即开启了负载均衡功能。\n\n## Ribbon 默认负载轮询算法原理\n\n**默认负载轮训算法：rest接口第几次请求数 % 服务器集群总数量 = 实际调用服务器位置下标，每次服务重启动后rest接口计数从1开始**。\n\n```java\nList<Servicelnstance> instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\");\n```\n\n如:\n\n- `List [0] instances = 127.0.0.1:8002`\n- `List [1] instances = 127.0.0.1:8001`\n\n8001 + 8002组合成为集群，它们共计2台机器，集群总数为2，按照轮询算法原理：\n\n- 当总请求数为1时：1%2=1对应下标位置为1，则获得服务地址为`127.0.0.1:8001`\n- 当总请求数位2时：2%2=О对应下标位置为0，则获得服务地址为`127.0.0.1:8002`\n- 当总请求数位3时：3%2=1对应下标位置为1，则获得服务地址为`127.0.0.1:8001`\n- 当总请求数位4时：4%2=О对应下标位置为0，则获得服务地址为`127.0.0.1:8002`\n- 如此类推…\n\n## RoundRobinRule 源码分析\n\n```java\npublic interface IRule{\n    /*\n     * choose one alive server from lb.allServers or\n     * lb.upServers according to key\n     * \n     * @return choosen Server object. NULL is returned if none\n     *  server is available \n     */\n\n    //重点关注这方法\n    public Server choose(Object key);\n    \n    public void setLoadBalancer(ILoadBalancer lb);\n    \n    public ILoadBalancer getLoadBalancer();    \n}\n```\n\n```java\npackage com.netflix.loadbalancer;\n\nimport com.netflix.client.config.IClientConfig;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.List;\nimport java.util.concurrent.atomic.AtomicInteger;\n\n/**\n * The most well known and basic load balancing strategy, i.e. Round Robin Rule.\n *\n * @author stonse\n * @author Nikos Michalakis <nikos@netflix.com>\n *\n */\npublic class RoundRobinRule extends AbstractLoadBalancerRule {\n\n    private AtomicInteger nextServerCyclicCounter;\n    private static final boolean AVAILABLE_ONLY_SERVERS = true;\n    private static final boolean ALL_SERVERS = false;\n\n    private static Logger log = LoggerFactory.getLogger(RoundRobinRule.class);\n\n    public RoundRobinRule() {\n        nextServerCyclicCounter = new AtomicInteger(0);\n    }\n\n    public RoundRobinRule(ILoadBalancer lb) {\n        this();\n        setLoadBalancer(lb);\n    }\n\n    //重点关注这方法。\n    public Server choose(ILoadBalancer lb, Object key) {\n        if (lb == null) {\n            log.warn(\"no load balancer\");\n            return null;\n        }\n\n        Server server = null;\n        int count = 0;\n        while (server == null && count++ < 10) {\n            List<Server> reachableServers = lb.getReachableServers();\n            List<Server> allServers = lb.getAllServers();\n            int upCount = reachableServers.size();\n            int serverCount = allServers.size();\n\n            if ((upCount == 0) || (serverCount == 0)) {\n                log.warn(\"No up servers available from load balancer: \" + lb);\n                return null;\n            }\n\n            int nextServerIndex = incrementAndGetModulo(serverCount);\n            server = allServers.get(nextServerIndex);\n\n            if (server == null) {\n                /* Transient. */\n                Thread.yield();\n                continue;\n            }\n\n            if (server.isAlive() && (server.isReadyToServe())) {\n                return (server);\n            }\n\n            // Next.\n            server = null;\n        }\n\n        if (count >= 10) {\n            log.warn(\"No available alive servers after 10 tries from load balancer: \"\n                    + lb);\n        }\n        return server;\n    }\n\n    /**\n     * Inspired by the implementation of {@link AtomicInteger#incrementAndGet()}.\n     *\n     * @param modulo The modulo to bound the value of the counter.\n     * @return The next value.\n     */\n    private int incrementAndGetModulo(int modulo) {\n        for (;;) {\n            int current = nextServerCyclicCounter.get();\n            int next = (current + 1) % modulo;//求余法\n            if (nextServerCyclicCounter.compareAndSet(current, next))\n                return next;\n        }\n    }\n\n    @Override\n    public Server choose(Object key) {\n        return choose(getLoadBalancer(), key);\n    }\n\n    @Override\n    public void initWithNiwsConfig(IClientConfig clientConfig) {\n    }\n}\n```\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【MySQL】Linux 搭建 MySQL 环境","url":"/2021/08/28/【MySQL】Linux搭建MySQL环境/","content":"\n![image-20210913132511709](/images/%E3%80%90MySQL%E3%80%91MySQL%E9%AB%98%E7%BA%A7/image-20210913132511709.png)\n\n> https://www.cnblogs.com/fps2tao/p/13052990.html\n\n普通离线安装流程见[Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)。下面演示在 Docker 中安装 MySQL 的步骤。\n\n<!-- More -->\n\n## 环境安装\n\n```shell\n# 查看Linux服务器上是否安装过MySQL\nrpm -qa | grep -i mysql # 查询出所有mysql依赖包\n\n# 1、拉取镜像\ndocker pull mysql:5.7\n\n# 2、创建实例并启动\ndocker run -p 3306:3306 --name mysql \\\n-v /root/mysql/log:/var/log/mysql \\\n-v /root/mysql/data:/var/lib/mysql \\\n-v /root/mysql/conf:/etc/mysql \\\n-e MYSQL_ROOT_PASSWORD=333 \\\n-d mysql:5.7\n\n# 3、mysql配置 /root/mysql/conf/my.conf\n[client]\n#mysqlde utf8字符集默认为3位的，不支持emoji表情及部分不常见的汉字，故推荐使用utf8mb4\ndefault-character-set=utf8\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld]\n#设置client连接mysql时的字符集,防止乱码\ninit_connect='SET collation_connection = utf8_general_ci'\ninit_connect='SET NAMES utf8'\n\n#数据库默认字符集\ncharacter-set-server=utf8\n\n#数据库字符集对应一些排序等规则，注意要和character-set-server对应\ncollation-server=utf8_general_ci\n\n# 跳过mysql程序起动时的字符参数设置 ，使用服务器端字符集设置\nskip-character-set-client-handshake\n\n# 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。但需要注意，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求！\nskip-name-resolve\n\n# 4、重启mysql容器\ndocker restart mysql\n\n# 5、进入到mysql容器\ndocker exec -it mysql /bin/bash\n\n# 6、查看修改的配置文件\ncat /etc/mysql/my.conf\n```\n\n## 安装位置\n\n`Docker`容器就是一个小型的`Linux`环境，进入到`MySQL`容器中。\n\n```shell\ndocker exec -it mysql /bin/bash\n```\n\n`Linux`环境下`MySQL`的安装目录。\n\n| 路径                | 解释                     |\n| ------------------- | ------------------------ |\n| `/var/lib/mysql`    | MySQL数据库文件存放位置  |\n| `/usr/share/mysql`  | 错误消息和字符集文件配置 |\n| `/usr/bin`          | 客户端程序和脚本         |\n| `/etc/init.d/mysql` | 启停脚本相关             |\n\n## 修改字符集\n\n```shell\n# 1、进入到mysql数据库并查看字符集\n# show variables like 'character%';\n# show variables like '%char%';\n\nmysql> show variables like 'character%';\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8                       |\n| character_set_connection | utf8                       |\n| character_set_database   | utf8                       |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8                       |\n| character_set_server     | utf8                       |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n+--------------------------+----------------------------+\n8 rows in set (0.00 sec)\n\nmysql> show variables like '%char%';\n+--------------------------+----------------------------+\n| Variable_name            | Value                      |\n+--------------------------+----------------------------+\n| character_set_client     | utf8                       |\n| character_set_connection | utf8                       |\n| character_set_database   | utf8                       |\n| character_set_filesystem | binary                     |\n| character_set_results    | utf8                       |\n| character_set_server     | utf8                       |\n| character_set_system     | utf8                       |\n| character_sets_dir       | /usr/share/mysql/charsets/ |\n+--------------------------+----------------------------+\n8 rows in set (0.01 sec)\n```\n\n`MySQL5.7`配置文件位置是`/etc/my.cnf`或者`/etc/mysql/my.cnf`，如果字符集不是`utf-8`直接进入配置文件修改即可。\n\n```shell\n[client]\ndefault-character-set=utf8\n\n[mysql]\ndefault-character-set=utf8\n\n[mysqld]\n# 设置client连接mysql时的字符集,防止乱码\ninit_connect='SET NAMES utf8'\ninit_connect='SET collation_connection = utf8_general_ci'\n\n# 数据库默认字符集\ncharacter-set-server=utf8\n\n#数据库字符集对应一些排序等规则，注意要和character-set-server对应\ncollation-server=utf8_general_ci\n\n# 跳过mysql程序起动时的字符参数设置 ，使用服务器端字符集设置\nskip-character-set-client-handshake\n\n# 禁止MySQL对外部连接进行DNS解析，使用这一选项可以消除MySQL进行DNS解析的时间。但需要注意，如果开启该选项，则所有远程主机连接授权都要使用IP地址方式，否则MySQL将无法正常处理连接请求！\nskip-name-resolve\n```\n\n**注意：安装`MySQL`完毕之后，第一件事就是修改字符集编码。**\n\n## 配置文件\n\n**`MySQL`配置文件讲解：https://www.cnblogs.com/gaoyuechen/p/10273102.html**\n\n1、二进制日志`log-bin`：主从复制。\n\n```shell\n# my,cnf\n# 开启mysql binlog功能\nlog-bin=mysql-bin\n```\n\n2、错误日志`log-error`：默认是关闭的，记录严重的警告和错误信息，每次启动和关闭的详细信息等。\n\n```shell\n# my,cnf\n# 数据库错误日志文件\nlog-error = error.log\n```\n\n3、查询日志`log`：默认关闭，记录查询的`sql`语句，如果开启会降低`MySQL`整体的性能，因为记录日志需要消耗系统资源。\n\n```shell\n# my,cnf\n# 慢查询sql日志设置\nslow_query_log = 1\nslow_query_log_file = slow.log\n```\n\n4、数据文件。\n\n- `frm文件`：存放表结构。\n- `myd`文件：存放表数据。\n- `myi`文件：存放表索引。\n\n```shell\n# mysql5.7 使用.frm文件来存储表结构\n# 使用 .ibd文件来存储表索引和表数据\n-rw-r-----  1 mysql mysql   8988 Jun 25 09:31 pms_category.frm\n-rw-r-----  1 mysql mysql 245760 Jul 21 10:01 pms_category.ibd\n```\n\n`MySQL5.7`的`Innodb`存储引擎可将所有数据存放于`ibdata*`的共享表空间，也可将每张表存放于独立的`.ibd`文件的独立表空间。\n共享表空间以及独立表空间都是针对数据的存储方式而言的。\n\n- 共享表空间: 某一个数据库的所有的表数据，索引文件全部放在一个文件中，默认这个共享表空间的文件路径在`data`目录下。 默认的文件名为`:ibdata1` 初始化为`10M`。\n- 独立表空间: 每一个表都将会生成以独立的文件方式来进行存储，每一个表都有一个`.frm`表描述文件，还有一个`.ibd`文件。 其中这个文件包括了单独一个表的数据内容以及索引内容，默认情况下它的存储位置也是在表的位置之中。在配置文件`my.cnf`中设置： `innodb_file_per_table`。\n\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"【Spring Cloud】Eureka","url":"/2021/08/28/【SpringCloud】Eureka/","content":"\n## Eureka 简介\n\n### 服务治理\n\nSpring Cloud封装了Netflix公司开发的Eureka模块来实现**服务治理**。\n\n**服务治理**：在传统的RPC远程调用框架中，管理每个服务与服务之间依赖关系比较复杂，管理比较复杂，所以需要使用服务治理，**管理服务与服务之间依赖关系**，可以实现服务调用、负载均衡、容错等，实现**服务发现与注册**。\n\nEureka采用了CS的设计架构，Eureka Sever作为服务注册功能的服务器，它是服务注册中心。而系统中的其他微服务，使用Eureka的客户端连接到Eureka Server并维持心跳连接。这样系统的维护人员就可以通过Eureka Server来监控系统中各个微服务是否正常运行。\n\n### 服务注册与服务发现\n\n**服务注册**：在服务注册与发现中，有一个注册中心。当服务器启动的时候，会把当前自己服务器的信息比如服务地址通讯地址等以别名方式注册到注册中心上。\n\n**服务发现**：另一方（消费者服务提供者），以该别名的方式去注册中心上获取到实际的服务通讯地址，之后再实现本地RPC调用。\n\n总结：\n\n- **服务注册**：将服务信息注册进注册中心\n- **服务发现**：从注册中心上获取服务信息\n\nRPC远程调用框架核心设计思想在于注册中心，因为使用注册中心管理每个服务与服务之间的一个依赖关系（服务治理概念）。在任何RPC远程框架中，都会有一个注册中心存放服务地址相关信息（接口地址）\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Eureka/3956561052b9dc3909f16f1ff26d01bb.png)\n\nEureka包含两个组件：**Eureka Server** 和 **Eureka Client**\n\n- **Eureka Server**：提供服务注册服务。各个微服务节点通过配置启动后，会在Eureka Server中进行注册，这样Eureka Server中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观看到。\n- **Eureka Client**：注册到注册中心的服务。是一个Java客户端，用于简化Eureka Server的交互，客户端同时也具备一个内置的、使用轮询(round-robin)负载算法的负载均衡器（Ribbon）。在应用启动后，将会向Eureka Server发送心跳(默认周期为30秒)。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除（默认90秒）\n\n<!-- More -->\n\n## Eureka Server\n\n1. 创建名为`cloud-eureka-server7001`的Maven工程\n2. 修改`pom.xml`，添加依赖：\n\n```xml\n<!-- 老版本（2018）-->\n<dependency>\n    <groupid>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-eureka</artifactId>\n</dependency>\n\n<!-- 新版本（2020.2）-->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>\n</dependency>\n```\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    <parent>\n        <artifactId>cloud2021</artifactId>\n        <groupId>com.zhao.springcloud</groupId>\n        <version>1.0.0-SNAPSHOT</version>\n    </parent>\n    <modelVersion>4.0.0</modelVersion>\n\n    <artifactId>cloud-eureka-server7001</artifactId>\n\n    <dependencies>\n        <!-- eureka-server -->\n        <dependency>\n            <groupId>org.springframework.cloud</groupId>\n            <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>\n        </dependency>\n        <!-- 引入自己定义的api通用包，可以使用Payment支付Entity -->\n        <dependency>\n            <groupId>com.lun.springcloud</groupId>\n            <artifactId>cloud-api-commons</artifactId>\n            <version>${project.version}</version>\n        </dependency>\n        <!-- boot web actuator -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-web</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-actuator</artifactId>\n        </dependency>\n        <!-- 一般通用配置 -->\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-devtools</artifactId>\n            <scope>runtime</scope>\n            <optional>true</optional>\n        </dependency>\n        <dependency>\n            <groupId>org.projectlombok</groupId>\n            <artifactId>lombok</artifactId>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-test</artifactId>\n            <scope>test</scope>\n        </dependency>\n        <dependency>\n            <groupId>junit</groupId>\n            <artifactId>junit</artifactId>\n        </dependency>\n    </dependencies>\n\n</project>\n```\n\n3. 修改`application.yaml`\n\n```yaml\nserver:\n  port: 7001\n\neureka:\n  instance:\n    hostname: locathost #eureka服务端的实例名称\n  client:\n    # alse表示不向注册中心注册自己。\n    register-with-eureka: false\n    # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务\n    fetch-registry: false\n    service-url:\n      # 设置与Eureka server交互的地址查询服务和注册服务都需要依赖这个地址。\n      defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/\n```\n\n4. 创建主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;\n\n@SpringBootApplication\n@EnableEurekaServer // 标注当前Spring Boot服务为Server端\npublic class EurekaMain7001 {\n    public static void main(String[] args) {\n        SpringApplication.run(EurekaMain7001.class, args);\n    }\n}\n```\n\n5. 测试运行`EurekaMain7001`，浏览器输入`http://localhost:7001/`回车，会查看到Spring Eureka服务主页。\n\n## Eureka Client\n\n创建Eureka Client端：`cloud-provider-payment8001`订单提供者服务，并注册进Eureka Server成为服务提供者provider。\n\n1. 创建`cloud-provider-payment8001`模块（订单提供者服务）作为Eureka Client端\n2. 修改`pom.xml`，添加依赖：\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n</dependency>\n```\n\n3. 修改`application.yaml`\n\n```yaml\nspring:\n  application:\n    name: cloud-payment-service\n    \neureka:\n  client:\n    # 表示是否将自己注册进Eurekaserver默认为true。\n    register-with-eureka: true\n    # 是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合Ribbon使用负载均衡\n    fetchRegistry: true\n    service-url:\n      defaultZone: http://localhost:7001/eureka # 指向Eureka Server的地址\n  instance:\n    instance-id: payment8001 # 设置可读性高的名称，将显示在Eureka主页服务列表里，代替ip地址\n    prefer-ip-address: true # 将鼠标指针移至payment8001名下，会有IP地址提示\n```\n\n4. 创建主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.EnableEurekaClient;\n\n@SpringBootApplication\n@EnableEurekaClient   // 标注当前Spring Boot服务为Client端\npublic class PaymentMain001 {\n\n    public static void main(String[] args) {\n        SpringApplication.run(PaymentMain001.class, args);\n    }\n}\n```\n\n5. 测试：启动`cloud-provider-payment8001`和`cloud-eureka-server7001`工程。浏览器输入 - http://localhost:7001/。\n\n## Eureka 集群原理\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Eureka/14570c4b7c4dd8653be6211da2675e45.png)\n\n- **服务注册**：将服务信息注册进注册中心\n- **服务发现**：从注册中心上获取服务信息\n\n**实质：存key服务名，取value调用地址**\n\n流程：\n\n- 先启动Eureka注册中心\n- 启动服务提供者payment支付服务\n- 支付服务启动后会把自身信息（以服务地址URL以别名方式注册进Eureka）\n- 消费者order服务在需要调用接口时，使用服务别名去注册中心获取实际的RPC远程调用地址\n- 消费者调用地址后，底层实际是利用HttpClient技术实现远程调用\n- 消费者获得的服务地址后会缓存在本地jvm内存中，默认每间隔30秒更新—次服务调用地址\n\n问题：微服务RPC远程服务调用最核心的是什么？\n\n答：高可用，试想注册中心假设只有一个，万一它出故障了，会导致整个为服务环境不可用。\n\n解决办法：搭建Eureka注册中心**集群**，实现负载均衡 + 故障容错。**互相注册，相互守望**。\n\n## Eureka 集群环境构建\n\n创建`cloud-eureka-server7002`工程作为第二个Eureka Server，与`cloud-eureka-server7001`相互注册。\n\n首先修改本地的host映射：\n\n```\n127.0.0.1 eureka7001.com\n127.0.0.1 eureka7002.com\n```\n\n1. 修改`cloud-eureka-server7001`的配置文件\n\n```yaml\nserver:\n  port: 7001\n\neureka:\n  instance:\n    hostname: eureka7001.com# Eureka服务端的实例名称\n  client:\n    register-with-eureka: false     # false表示不向注册中心注册自己。\n    fetch-registry: false     # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务\n    service-url:\n    # 指向其它Eureka集群\n      defaultZone: http://eureka7002.com:7002/eureka/\n    # 单机就是7001自己\n      # defaultZone: http://eureka7001.com:7001/eureka/\n```\n\n2. 修改`cloud-eureka-server7002`配置文件\n\n```yaml\nserver:\n  port: 7002\n\neureka:\n  instance:\n    hostname: eureka7002.com # Eureka服务端的实例名称\n  client:\n    register-with-eureka: false     # false表示不向注册中心注册自己。\n    fetch-registry: false     # false表示自己端就是注册中心，我的职责就是维护服务实例，并不需要去检索服务\n    service-url:\n    # 指向其它Eureka集群\n      defaultZone: http://eureka7001.com:7001/eureka/\n    # 单机就是7002自己\n      # defaultZone: http://eureka7002.com:7002/eureka/\n```\n\n3. 将支付服务8001微服务注册到上面2台Eureka集群配置中\n\n```yaml\neureka:\n  client:\n    # 表示是否将自己注册进Eurekaserver默认为true。\n    register-with-eureka: true\n    # 是否从EurekaServer抓取已有的注册信息，默认为true。单节点无所谓，集群必须设置为true才能配合ribbon使用负载均衡\n    fetchRegistry: true\n    service-url:\n      defaultZone: http://eureka7001.com:7001/eureka, http://eureka7002.com:7002/eureka\n  instance:\n    instance-id: payment8001 # 设置可读性高的名称，将显示在Eureka主页服务列表里，代替ip地址\n    prefer-ip-address: true # 将鼠标指针移至payment8001名下，会有IP地址提示\n```\n\n支付服务集群配置：https://blog.csdn.net/u011863024/article/details/114298270\n\n4. 支付服务搭建集群后，订单服务需要开启**负载均衡**功能，此注解在Spring Cloud提供的`LoadBalacer`包下\n\n```java\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\n\n@Configuration\npublic class ApplicationContextConfig {\n\n    // 赋予RestTemplate负载均衡的能力\n    @LoadBalanced\n    @Bean\n    public RestTemplate getRestTemplate() {\n        return new RestTemplate();\n    }\n\n}\n```\n\n此时`PAYMENT_URL` 需要写成支付服务对应的服务名： `http://CLOUD-PAYMENT-SERVICE`\n\n\n```java\n@Slf4j\n@RestController\npublic class OrderController {\n    // public static final String PAYMENT_URL = \"http://localhost:8001\";\n    public static final String PAYMENT_URL = \"http://CLOUD-PAYMENT-SERVICE\";\n\n    @Autowired\n    private RestTemplate restTemplate;\n\n    @GetMapping(value = \"/consumer/payment/create\")\n    public CommonResult create(Payment payment) {\n        // 以JSON的形式发送POST请求给8001端口，payment数据信息保存在request body中，因此对应的Controller需要加@RequestBody注解\n        return restTemplate.postForObject(PAYMENT_URL + \"/payment/create\", payment, CommonResult.class);\n    }\n\n    @GetMapping(\"/consumer/payment/get/{id}\")\n    public CommonResult<Payment> getPayment(@PathVariable(\"id\") Long id) {\n        log.info(\"1211\");\n\n        return restTemplate.getForObject(PAYMENT_URL + \"/payment/get/\" + id, CommonResult.class);\n    }\n}\n```\n\n## Discovery 服务发现\n\n对于注册进Eureka里面的微服务，可以通过服务发现来获得该服务的信息。\n\n1. 修改`cloud-provider-payment8001`的Controller\n\n```java\n@RestController\n@Slf4j\npublic class PaymentController{\n    ...\n\n        // 用于获取注册中心的服务信息\n        @Resource\n        private DiscoveryClient discoveryClient;\n\n    ...\n\n        @GetMapping(value = \"/payment/discovery\")\n        public Object discovery()\n    {\n        List<String> services = discoveryClient.getServices();\n        for (String element : services) {\n            log.info(\"*****element: \"+element);\n        }\n\n        List<ServiceInstance> instances = discoveryClient.getInstances(\"CLOUD-PAYMENT-SERVICE\");\n        for (ServiceInstance instance : instances) {\n            log.info(instance.getServiceId()+\"\\t\"+instance.getHost()+\"\\t\"+instance.getPort()+\"\\t\"+instance.getUri());\n        }\n\n        return this.discoveryClient;\n    }\n}\n```\n\n2. 修改主启动类\n\n```java\n@SpringBootApplication\n@EnableEurekaClient\n@EnableDiscoveryClient // 开启服务发现功能\npublic class PaymentMain001 {\n    public static void main(String[] args) {\n        SpringApplication.run(PaymentMain001.class, args);\n    }\n}\n```\n\n## Eureka 自我保护机制\n\n保护模式主要用于一组客户端和Eureka Server之间存在网络分区场景下的保护。一旦进入保护模式，Eureka Server将会尝试保护其服务注册表中的信息，不再删除服务注册表中的数据，也就是不会注销任何微服务。\n\n如果在Eureka Server的首页看到以下这段提示，则说明Eureka进入了保护模式:\n\n```\nEMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT. RENEWALS ARE LESSER THANTHRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUSTTO BE SAFE\n```\n\n**导致原因：某时刻某一个微服务不可用了，Eureka不会立刻清理，依旧会对该微服务的信息进行保存。**\n\n Eureka属于CAP里面的AP类型（ZooKeeper属于CP），即保证服务高可用，即使数据不一致也必须要可用。\n\n为什么会产生Eureka自我保护机制：为了EurekaClient可以正常运行，在与Eureka Server网络不通情况下，Eureka Server不会立刻将Eureka Client服务剔除\n\n什么是自我保护模式：默认情况下，如果Eureka Server在一定时间内没有接收到某个微服务实例的心跳，EurekaServer将会注销该实例（默认90秒）。但是当网络分区故障发生（延时、卡顿、拥挤）时，微服务与Eureka Server之间无法正常通信，以上行为可能变得非常危险了——因为微服务本身其实是健康的，此时本不应该注销这个微服务。Eureka通过“自我保护模式”来解决这个问题——当EurekaServer节点在短时间内丢失过多客户端时（可能发生了网络分区故障），那么这个节点就会进入自我保护模式。\n\n自我保护机制：默认情况下Eureka Client定时向Eureka Server端发送心跳包。如果Eureka Server在一定时间内（默认90秒）没有收到Eureka Client发送心跳包，便会直接从服务注册列表中剔除该服务，但是在短时间（90秒）内丢失了大量的服务实例心跳，这时候Eureka Server会开启自我保护机制，不会剔除该服务（该现象可能出现在如果网络不通但是Eureka Client未出现宕机，此时如果换做别的注册中心如果一定时间内没有收到心跳会将剔除该服务，这样就出现了严重失误，因为客户端还能正常发送心跳，只是网络延迟问题，而保护机制是为了解决此问题而产生的）。\n\n在自我保护模式中，Eureka Server会保护服务注册表中的信息，不再注销任何服务实例。它的设计哲学就是宁可保留错误的服务注册信息，也不盲目注销任何可能健康的服务实例。\n\n综上，自我保护模式是一种应对网络异常的安全保护措施。它的架构哲学是宁可同时保留所有微服务（健康的微服务和不健康的微服务都会保留）也不盲目注销任何健康的微服务。使用自我保护模式，可以让Eureka集群更加的健壮、稳定。\n\n\n\n## 三个注册中心异同点\n\n| 组件名    | 语言 | CAP  | 对外暴露接口 | Spring Cloud集成 |\n| --------- | ---- | ---- | ------------ | ---------------- |\n| Eureka    | Java | AP   | 可配支持     | HTTP             |\n| Consul    | Go   | CP   | 支持         | HTTP/DNS         |\n| Zookeeper | Java | CP   | 支持客户端   | 已集成           |\n\nCAP：\n\n- C：Consistency (强一致性)\n- A：Availability (可用性)\n- P：Partition tolerance （分区容错性)\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Eureka/b41e0791c9652955dd3a2bc9d2d60983.png)\n\n最多只能同时较好的满足两个。\n\nCAP理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求。因此，根据CAP原理将NoSQL数据库分成了满足CA原则、满足CP原则和满足AP原则三大类:\n\n- CA - 单点集群，满足—致性，可用性的系统，通常在可扩展性上不太强大。\n- CP - 满足一致性，分区容忍性的系统，通常性能不是特别高。\n- AP - 满足可用性，分区容忍性的系统，通常可能对一致性要求低一些。\n\n### AP 架构（Eureka）\n\n当网络分区出现后，为了保证可用性，系统B可以返回旧值，保证系统的可用性。结论：违背了一致性C的要求，只满足可用性和分区容错，即AP。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Eureka/2d07748539300b9c466eb1d9bac5cd1b.png)\n\n### CP 架构（ZooKeeper/Consul）\n\n当网络分区出现后，为了保证一致性，就必须拒接请求，否则无法保证一致性。结论：违背了可用性A的要求，只满足一致性和分区容错，即CP。例如ZooKeeper在进行Leader选举时不能响应客户端的请求，此时不满足高可用性A，而是选择了满足数据一致性。\n\n![img](/images/%E3%80%90SpringCloud%E3%80%91Eureka/c6f2926a97420015fcebc89b094c5598.png)\n\n","tags":["Spring Cloud"],"categories":["Spring Cloud"]},{"title":"【Maven】Maven","url":"/2021/08/28/【Maven】Maven/","content":"\n![image-20210913132641433](/images/%E3%80%90Maven%E3%80%91Maven/image-20210913132641433.png)\n\n##  Maven 简介\n\n### 软件开发中的阶段\n\n- **需要分析**： 分析项目具体完成的功能，有什么要求，具体怎么实现\n- **设计阶段**：根据分析的结果，设计项目的使用什么技术，解决难点\n- **开发阶段**：编码实现功能，编译代码，自我测试\n- **测试阶段**：专业的测试人员，测整个项目的功能十分符合设计要求。出一个测试报告\n- **发布阶段**： 项目的打包，给用户安装项目\n\n### 什么是 Maven\n\nmaven是apache基金会的开源项目，使用java语法开发。Maven这个单词的本意是：专家，内行。maven是项目的自动化构建工具，用于管理项目的依赖。下载地址： http://maven.apache.org/ \t\n\n### Maven 能做什么\n\n- 项目的自动构建，帮助开发人员做项目代码的编译，测试，打包，安装，部署等工作\n- 管理依赖（管理项目中使用的各种jar包）\n\n依赖：项目中需要使用的其他资源，常见的是jar。比如项目要使用mysql驱动。我们就说项目依赖mysql驱动。\n\n### Maven 中的概念\n\n- POM\n- 约定的目录结构\n- 坐标\n- 依赖管理\n- 仓库管理\n- 生命周期\n- 插件和目标\n- 继承\n- 聚合\n\n<!-- More -->\n\n## Maven 的核心概念\n\n### 约定的目录结构\n\nmaven项目使用的大多人遵循的目录结构，叫做**约定的目录结构**。\n\n一个maven项目是一个文件夹，例如：\n\n![image-20210828195930150](/images/%E3%80%90Maven%E3%80%91Maven/image-20210828195930150-1630154443250.png)\n\n### POM \n\nPOM： **Project Object Model** 项目对象模型，maven把项目当做模型处理，操作这个模型就是操作项目。\n\nmaven通过`pom.xml`文件实现项目的构建和依赖的管理：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n<!-- project是根标签，后面的是约束文件 -->\n<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n    \n    <!-- pom模型的版本，就是4.0.0 -->  \n    <modelVersion>4.0.0</modelVersion>\n\n    <!-- 坐标 -->  \n    <artifactId>cloud2021</artifactId>\n    <groupId>com.zhao.springcloud</groupId>\n    <version>1.0-SNAPSHOT</version>\n\n    <properties>\n        <java.version>1.8</java.version>\n        <maven.compiler.source>1.8</maven.compiler.source>\n        <maven.compiler.target>1.8</maven.compiler.target>\n    </properties>\n\n</project>\n```\n\n### 坐标 gav\n\n坐标概念来自数学，坐标组成是 **groupid, artifiactId, version**。 \n\n坐标作用：确定资源的，是资源的唯一标识。在maven中，每个资源都是坐标。坐标值是唯一的，简称叫gav：\n\n```xml\n<groupId>com.bjpowernode</groupId>\n<artifactId>ch01-maven</artifactId>\n<version>1.0-SNAPSHOT</version>\n<packaging>jar</packaging>\n```\n\n- **groupId**：组织名称，代码，公司，团体或者单位的标识。这个值常使用的公司域名的倒写\n- **artifactId**：项目名称，如果groupId中有项目，此时当前的值就是子项目名。项目名称是唯一的\n- **version**：版本，项目的版本号，使用的数字。三位组成。例如：5.2.5（主版本号.次版本号.小版本号）  注意：版本号中有`-SNAPSHOT`，表示快照，不是稳定的版本。     \n\n**packaging**为项目打包的类型，有**jar ，war，ear，pom**等等。默认是jar。区别：\n\n- **jar**：将项目打成jar包，可以使用java命令直接执行\n- **war**：将项目打成war包，需要放到Tomcat中执行\n- **pom**：**常用于Maven父工程**，用于让子模块继承该父工程的`pom`文件。代表当前工程是纯pom工程，没有业务代码，只用于管理依赖，让子模块继承，从而做到依赖版本统一\n\n搜索坐标的地址： https://mvnrepository.com/\n\n### 依赖 dependency\n\n依赖：项目中要使用的其他资源（jar）。 需要使用maven表示依赖，管理依赖。通过使用dependency和gav一起完成依赖的使用\n\n需要在`pom.xml`文件中，使用dependencies和dependency，还有gav完成依赖的说明。格式：\n\n```xml\n<dependencies>\n    <!-- 日志 -->\n    <dependency>\n        <groupId>log4j</groupId>\n        <artifactId>log4j</artifactId>\n        <version>1.2.17</version>\n    </dependency>\n\n    <!-- mysql驱动 -->\n    <dependency>\n        <groupId>mysql</groupId>\n        <artifactId>mysql-connector-java</artifactId>\n        <version>5.1.16</version>\n    </dependency>\n\n</dependencies> \n```\n\n### 仓库\n\n仓库是存东西的，maven的仓库存放的是：\n\n1. maven工具自己的jar包\n2. 第三方的其他jar，比如项目中要使用mysql驱动\n3. 自己写的程序，可以打包为jar，存放到仓库。\n\n\n仓库的分类：\n\n本地仓库（本机仓库）： 位于你自己的计算机，它是磁盘中的某个目录。修改本地仓库的位置：修改maven工具的配置文件（maven的安装路径`/conf/setting.xml`）\n\n远程仓库： 需要通过联网访问的\n\n- 中央仓库： 一个ftp服务器，存放了所有的资源。\n- 中央仓库的镜像： 就是中央仓库的拷贝。在各大主要城市都有镜像。\n- 私服：在局域网中使用的。私服就是自己的仓库服务器，在公司内部使用的。\n\nmaven使用仓库： maven自动使用仓库，当项目启动后，执行了maven的命令，maven首先访问的是本地仓库，从仓库中获取所需的jar，如果本地仓库没有 ，需要访问私服或者中央仓库或者镜像。\n\n![image-20201016114322189](/images/%E3%80%90Maven%E3%80%91Maven/image-20201016114322189-1630154443251.png)\n\n### Maven 的生命周期，插件和命令\n\nmaven的生命周期： 项目构建的各个阶段。包括**清理，编译，测试，报告，打包，安装，部署**\n\n- 插件：要完成构建项目的各个阶段，要使用maven的命令，执行命令的功能是通过插件完成的。插件就是jar，一些类。\n- 命令： 执行maven功能是由命令发出的。比如 `mvn compile`\n\n常用命令：\n\n- `mvn clean`：清理命令，作用是删除以前生成的数据，即删除`target`目录\n- `mvn compile`：编译命令，执行的代码编译，把`src/main/java`目录中的java代码编译为`.class`文件。同时把`.class`文件拷贝到`target/classes`目录。这个目录`classes`是存放类文件的根目录（也叫做类路径，`classpath`）\n- `mvn test-compile`：编译命令，编译`src/test/java`目录中的源文件，把生成的`.class`拷贝到`target/test-classes`目录。同时把`src/test/resources`目录中的文件拷贝到 `test-clasess`目录\n- `mvn test`：测试命令，作用执行 `test-classes`目录的程序，测试`src/main/java`目录中的主程序代码是否符合要求。\n- `mvn package`：打包，作用是把项目中的资源`.class`文件和配置文件都放到一个压缩文件中，默认压缩文件是jar类型的。web应用是war类型，扩展是jar，war的。\n- `mvn install`：把生成的打包的文件 ，安装到maven仓库。\n\n### 自定义配置插件\n\n在`pom.xml`文件中，`<build>`标签里设置插件\n\n```xml\n<!-- 设置构建项目相关的内容 -->\n<build>\n    <plugins>\n        <!-- 设置插件 -->\n        <plugin>\n            <groupId>org.apache.maven.plugins</groupId>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <version>3.8.1</version>\n            <configuration>\n                <source>1.8</source> <!-- 指定编译代码的jdk版本 -->\n                <target>1.8</target> <!-- 运行java程序使用的jdk版本-->\n            </configuration>\n        </plugin>\n    </plugins>\n</build> \n```\n\n## Maven 和 IDEA 的集成\n\nIDEA中有一个自带的maven，我们要让idea使用自己本地安装的maven。\n\n1. 选择 `File- Settings` \n\n![image-20201016151034872](/images/%E3%80%90Maven%E3%80%91Maven/image-20201016151034872-1630154443251.png)\n\n![image-20201016151528678](/images/%E3%80%90Maven%E3%80%91Maven/image-20201016151528678-1630154443251.png)\n\n​\t设置项： `-DarchetypeCatalog=internal`\n\n2. `File - Other Settings`\n\n![image-20201016151823967](/images/%E3%80%90Maven%E3%80%91Maven/image-20201016151823967-1630154443251.png)\n\n同上的设置\n\n## 依赖管理\n\n依赖范围：使用`scope`表示依赖的范围。依赖范围表示： 这个依赖（jar和里面类）在项目构建的那个阶段起作用。\n\n依赖范围`scope` 类型：\n\n- **compile**：默认，参与构建项目的所有阶段\n- **test**：测试，在测试阶段使用，比如执行`mvn test`会使用junit 。\n- **provided**：提供，项目在部署到服务器时，不需要提供这个依赖的jar ，而是由服务器这个依赖的jar包。例如`servlet`和`jsp`依赖需要使用`provided`范围，让部署的Tomcat提供其依赖。\n- **import**：必须用在`<dependencyManagement>`标签内，与`scope`中的`pom`类型配合使用，用于将目标工程的`pom`文件中的依赖内容直接复制到当前项目中，从而做到分类管理，即将不同类型的依赖放在不同的`pom`文件中，使用这些大量的依赖只需要`import`少量的`pom`文件即可，例如：\n\n```xml\n<!-- spring boot 2.2.2 -->\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-dependencies</artifactId>\n    <version>2.2.2.RELEASE</version>\n    <type>pom</type>\n    <scope>import</scope>\n</dependency>\n<!-- spring cloud Hoxton.SR1 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-dependencies</artifactId>\n    <version>Hoxton.SR1</version>\n    <type>pom</type>\n    <scope>import</scope>\n</dependency>\n<!-- spring cloud 阿里巴巴 -->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n    <version>2.1.0.RELEASE</version>\n    <type>pom</type>\n    <scope>import</scope>\n</dependency>\n```\n\n只需要`import`三个`pom`文件即可导入大量的依赖，从而做到依赖的分类管理。其中导入的`spring-boot-dependencies`的`scope`类型为`pom`：\n\n```xml\n<groupId>org.springframework.boot</groupId>\n<artifactId>spring-boot-dependencies</artifactId>\n<version>2.2.2.RELEASE</version>\n<packaging>pom</packaging>\n<name>Spring Boot Dependencies</name>\n```\n\n`<dependencyManagement>`标签常用于父工程中，用于管理子模块的依赖。在其下创建的子模块不再需要填写依赖的版本号（版本号都在父工程中指定了），若需要自定义版本号，只需要在子模块的pom文件里自定义修改即可，其会遵循就近原则。\n\n父工程使用如下两种标签管理依赖时的区别：\n\n- `<dependencies>`：其内的所有依赖都会被子模块直接继承，坏处是引入了大量的冗余依赖\n- `<dependencyManagement>`：其内的依赖子模块不会直接拥有，需要子模块自己按需添加`<dependency>`标签引入，好处是不需要全部引入父工程的所有依赖\n\nMaven父工程里只能有pom文件，不需要有`src`目录和`target`目录，其作用仅仅是用于定义子模块需要用到的依赖版本，不需要有业务代码。\n\n## 常用设置\n\n`properties`里面的配置：\n\n```xml\n<properties>\n    <maven.compiler.source>1.8</maven.compiler.source> 源码编译 jdk 版本\n    <maven.compiler.target>1.8</maven.compiler.target> 运行代码的 jdk 版本\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding> 项目\n    构建使用的编码，避免中文乱码\n    <project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding> 生成报告的编码\n</properties>\n```\n\n### 全局变量\n\n在`properties`定义标签，这个标签就是一个变量，标签的文本就是变量的值。使用全局变量表示多个依赖使用的版本号。\n\n使用步骤：\n\n1. 在`properties`标签中，定义一个标签，指定版本的值\n\n```xml\n<properties>\n    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\n    <maven.compiler.source>1.8</maven.compiler.source>\n    <maven.compiler.target>1.8</maven.compiler.target>\n    <!--自定义变量-->\n    <spring.version>5.2.5.RELEASE</spring.version>\n    <junit.version>4.11</junit.version>\n</properties>\n```\n\n2. 使用全局变量，语法 `${变量名}`\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-core</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-web</artifactId>\n    <version>${spring.version}</version>\n</dependency>\n```\n\n3. 使用资源插件，处理配置文件的信息\n\n- maven会把`src/main/resources`目录中的文件，拷贝到`target/classes`目录下\n- maven只处理`src/main/java`目录中的 `.java`文件，把这些`.java`文件编译为`.class`，拷贝到 `target/classes`目录中。不处理其他文件。\n\n```xml\n<build>\n    <!--资源插件：告诉maven把src/main/java目录中的指定扩展名的文件拷贝到 target/classes目录中。\n  -->\n    <resources>\n        <resource>\n            <directory>src/main/java</directory> <!--所在的目录-->\n            <includes>\n                <!--包括目录下的 .properties,.xml 文件都会扫描到-->\n                <include>**/*.properties</include>\n                <include>**/*.xml</include>\n            </includes>\n            <!--  filtering 选项 false 不启用过滤器，*.property 已经起到过滤的作用了 -->\n            <filtering>false</filtering>\n        </resource>\n    </resources>\n</build>\n```\n\n以上配置可用于解决MyBatis的mapper文件导出问题。","tags":["Maven"],"categories":["Maven"]},{"title":"【Spring Boot】Spring Boot2 整合第三方技术","url":"/2021/08/28/【SpringBoot】SpringBoot2整合第三方技术/","content":"\n本文将介绍Spring Boot整合第三方技术的配置、原理与示例。\n\n\n\n- **DataSourceAutoConfiguration**：数据源自动配置类\n- **MybatisAutoConfiguration**：MyBatis自动配置类（第三方）\n- **RedisAutoConfiguration：Redis**自动配置类\n\n\n\n<!-- More -->\n\n## 整合 Druid 数据源\n\n### 导入 JDBC 场景\n\n1、在Maven中导入JDBC场景`spring-boot-starter-data-jdbc`：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-jdbc</artifactId>\n</dependency>\n```\n\n导入该场景后，将出现数据源Hikari、JDBC和事务等依赖：\n\n![image-20210804152401123](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210804152401123.png)\n\n2、导入数据库MySQL驱动的依赖：\n\n```xml\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>8.0.22</version>\n</dependency>\n```\n\n> MySQL 官方推荐使用的驱动版本是 8.0，其向下兼容 5.6, 5.7, 8.0 版本的 MySQL。\n\n---\n\nSpring Boot2提供的MySQL驱动的默认版本：`<mysql.version>8.0.22</mysql.version>`。若想要修改版本，可以：\n\n1. 直接依赖引入具体版本（maven的就近依赖原则）\n2. 重新声明版本（maven的属性的就近优先原则）\n\n```xml\n<properties>\n    <java.version>1.8</java.version>\n    <mysql.version>5.1.49</mysql.version>\n</properties>\n\n<!-- 或者：-->\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.49</version>\n</dependency>\n```\n\n---\n\n3、修改**数据源**的配置项：\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/tableName?useUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai\n    username: root\n    password: zhaoyuyun\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    # 注意：MySQL5.0版本的驱动类名和8.0版本的不同\n    # 5.0版本的驱动类名：com.mysql.jdbc.Driver\n```\n\n### 数据源自动配置原理\n\n**DataSourceAutoConfiguration**： 数据源的自动配置类\n\n- 修改**数据源**相关的配置前缀：`\"spring.datasource\"`\n- **数据库连接池**的配置，是容器中**没有自定义的DataSource时**才自动配置的\n- 底层自动配置的数据源是：**HikariDataSource**\n\n![image-20210804153524354](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210804153524354.png)\n\n其他数据库相关的自动配置类：\n\n- **DataSourceTransactionManagerAutoConfiguration**： 事务管理器的自动配置\n- **JdbcTemplateAutoConfiguration**： JdbcTemplate的自动配置，可以来对数据库进行crud。容器中有**JdbcTemplate**这个组件，可以修改配置前缀  `\"spring.jdbc\"` 来修改JdbcTemplate的配置。\n- **JndiDataSourceAutoConfiguration**： jndi的自动配置\n- **XADataSourceAutoConfiguration**： 分布式事务相关的\n\n### Druid 数据源\n\nDruid官方github地址：https://github.com/alibaba/druid\n\n4、引入Druid官方提供的`starter`场景依赖：\n\n```xml\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>druid-spring-boot-starter</artifactId>\n    <version>1.1.17</version>\n</dependency>\n```\n\n其向容器中添加了一个Druid数据源自动配置类**DruidDataSourceAutoConfigure**：\n\n![image-20210804202513107](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210804202513107.png)\n\n- 该配置器在Spring Boot自带的数据源自动配置器**DataSourceAutoConfiguration**之前配置，因此不再注册Spring Boot默认的数据源**HikariDataSource**。\n- 该配置器绑定了**DataSourceProperties**和**DruidStatProperties**资源配置类，分别对应资源路径`\"spring.datasource\"`和`\"spring.datasource.druid\"`\n- 该配置器导入了其他相关的配置类，用于开启配置页、防火墙、Web监控等功能\n\n导入的其他相关配置类如下：\n\n- **DruidSpringAopConfiguration.class**（`spring.datasource.druid.aop-patterns`）：监控Spring Bean\n- **DruidStatViewServletConfiguration.class**（`spring.datasource.druid.stat-view-servlet`）：配置监控页：\n- **DruidWebStatFilterConfiguration.class**（`spring.datasource.druid.web-stat-filter`）：Web监控配置\n- **DruidFilterConfiguration.class**：配置Druid的所有Filters：\n\n```java\nprivate static final String FILTER_STAT_PREFIX = \"spring.datasource.druid.filter.stat\";\nprivate static final String FILTER_CONFIG_PREFIX = \"spring.datasource.druid.filter.config\";\nprivate static final String FILTER_ENCODING_PREFIX = \"spring.datasource.druid.filter.encoding\";\nprivate static final String FILTER_SLF4J_PREFIX = \"spring.datasource.druid.filter.slf4j\";\nprivate static final String FILTER_LOG4J_PREFIX = \"spring.datasource.druid.filter.log4j\";\nprivate static final String FILTER_LOG4J2_PREFIX = \"spring.datasource.druid.filter.log4j2\";\nprivate static final String FILTER_COMMONS_LOG_PREFIX = \"spring.datasource.druid.filter.commons-log\";\nprivate static final String FILTER_WALL_PREFIX = \"spring.datasource.druid.filter.wall\";\n```\n\n### 配置示例\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/tableName?useUnicode=true&characterEncoding=utf8&useSSL=true\n    username: root\n    password: 123456\n    driver-class-name: com.mysql.cj.jdbc.Driver\n\t# 5.0版本的驱动要使用：com.mysql.jdbc.Driver\n\t\n    druid:\n      aop-patterns: com.zhao.admin.*  # 监控SpringBean\n      filters: stat,wall     # 底层开启功能，stat（sql监控），wall（防火墙）\n      \n      stat-view-servlet:   # 配置监控页功能\n        enabled: true\n        login-username: admin\n        login-password: admin\n        resetEnable: false\n\n      web-stat-filter:  # 监控web\n        enabled: true\n        urlPattern: /*\n        exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*'\n\n      filter:\n        stat:    # 对上面filters里面的stat的详细配置\n          slow-sql-millis: 1000\n          logSlowSql: true\n          enabled: true\n        wall:\n          enabled: true\n          config:\n            drop-table-allow: false\n```\n\nSpringBoot配置示例：https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter\n\n配置项列表：[https://github.com/alibaba/druid/wiki/DruidDataSource%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E5%88%97%E8%A1%A8](https://github.com/alibaba/druid/wiki/DruidDataSource配置属性列表)\n\n## 整合 MyBatis\n\nMyBatis官方链接：https://github.com/mybatis\n\n### 原理\n\n1、导入MyBatis的`starter`场景依赖：\n\n```XML\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.4</version>\n</dependency>\n```\n\n---\n\n其导入了如下包：\n\n![image-20210805142616006](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805142616006.png)\n\n其中，MyBatis的自动配置器**MybatisAutoConfiguration**会在Spring Boot启动时注册到容器中：\n\n![image-20210805143359047](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805143359047.png)\n\n该类绑定了**MybatisProperties**，对应Spring Boot的配置文件中以`\"mybatis\"`为前缀的属性：\n\n![image-20210805144216362](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805144216362.png)\n\n1. **MybatisAutoConfiguration**向容器中注册了**sqlSessionFactory**，其使用容器中存在的数据源，并且从配置资源类**MybatisProperties**中获取MyBatis的配置属性值：\n\n![image-20210805143832167](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805143832167.png)\n\n2. **MybatisAutoConfiguration**向容器中注册了**SqlSessionTemplate**，其可以执行批量的**SqlSession**：\n\n![image-20210805144629709](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805144629709.png)\n\n![image-20210805144721508](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805144721508.png)\n\n3. **MybatisAutoConfiguration**向容器中注册了**AutoConfiguredMapperScannerRegistrar**，其用于扫描容器中带有 **@Mapper** 注解的组件：\n\n![image-20210805151107546](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805151107546.png)\n\n---\n\n### 使用 MyBatis\n\n开启MyBatis流程：\n\n- 导入MyBatis官方starter场景： `mybatis-spring-boot-starter`\n- 编写`xxxMapper`接口，并在其上使用 **@Mapper** 注解（也可以使用 **@MapperScan()**  简化）\n- 编写sql映射文件`xxxMapper.xml`（放置在`classpath:mapper/*.xml`下）并绑定`xxxMapper`接口\n- 在`application.yaml`中指定mapper配置文件的位置`mapper-locations`，以及指定全局配置文件的信息\n\n具体步骤如下：\n\n1. 导入MyBatis的starter场景： `mybatis-spring-boot-starter`\n\n```XML\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.4</version>\n</dependency>\n```\n\n2. 编写`UserMapper`接口，并在其上使用 **@Mapper** 注解（也可以使用 **@MapperScan(\"com.zhao.mapper\")**  简化）\n\n```java\n@Mapper\npublic interface UserMapper {\n\n    // 可以使用注解代替xml里的sql语句\n    @Select(\"select * from user where id = #{id}\")\n    User selectUser(Long id);\n\n    void deleteUser(Long id);\n}\n```\n\n3. 编写sql映射文件`userMapper.xml`（放置在`classpath:mapper/*.xml`下）\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.zhao.admin.mapper.UserMapper\">\n    <select id=\"selectUser\" resultType=\"com.zhao.admin.bean.User\">\n        select * from user where id = #{id}\n    </select>\n\n    <delete id=\"deleteUser\" parameterType=\"long\">\n        delete from user where id = #{id}\n    </delete>\n</mapper>\n```\n\n4. 在`application.yaml`中配置MyBatis：\n\n```yaml\nmybatis:\n  #  config-location: classpath:mybatis/mybatis-config.xml\n  mapper-locations: classpath:mapper/*.xml\n  \n  # 可以不写mybatis-config.xml，所有全局配置文件的配置都放在configuration配置项中即可\n  configuration:\n    map-underscore-to-camel-case: true  \n```\n\n项目结构：\n\n![image-20210805212017625](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805212017625.png)\n\n### 整合 MyBatis Plus\n\n1、导入MyBatis-Plus的`starter`场景：`mybatis-plus-boot-starter`\n\n```xml\n<dependency>\n    <groupId>com.baomidou</groupId>\n    <artifactId>mybatis-plus-boot-starter</artifactId>\n    <version>3.4.1</version>\n</dependency>\n```\n\n---\n\n其会向容器中导入**MybatisPlusAutoConfiguration**：\n\n![image-20210805194210051](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805194210051.png)\n\n其对应的配置前缀为`\"mybatis-plus\"`，其会默认扫描`\"classpath*:/mapper/**/*.xml\"`，即当前模块类路径（包括引用其他jar包的类路径，`classpath:/mapper...`则只会包含自己的类路径）下mapper目录下的所有`.xml`文件都会被作为MyBatis的`.xml`进行扫描（开发人员将sql映射文件放置在该目录下即可）：\n\n![image-20210805193856503](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805193856503.png)\n\n注意：`\"classpath*:/mapper/**/*.xml\"`所指的类路径不仅包含当前模块的类路径，而且还包含了当前模块引用的其他包的类路径。若想只引用自己模块的类路径，则可以写：`\"classpath:/mapper/**/*.xml\"`\n\n---\n\n2、使用时，自定义的Mapper接口继承 `BaseMapper<User>` 接口即可自动实现简单功能的CRUD:\n\n```java\n@Mapper\npublic interface UserMapper extends BaseMapper<User> {\n\n}\n```\n\n `BaseMapper<User>` 接口中默认实现了简单CRUD的方法：\n\n![image-20210805213009214](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210805213009214.png)\n\n使用MyBatis Plus提供的`IService`，`ServiceImpl`，减轻Service层开发工作。\n\n``` java\nimport com.zhao.hellomybatisplus.model.User;\nimport com.baomidou.mybatisplus.extension.service.IService;\n\nimport java.util.List;\n\n/**\n *  Service 的CRUD也不用写了\n */\npublic interface UserService extends IService<User> {\n\t//此处故意为空\n}\n```\n\n``` java\nimport com.zhao.hellomybatisplus.model.User;\nimport com.zhao.hellomybatisplus.mapper.UserMapper;\nimport com.zhao.hellomybatisplus.service.UserService;\nimport com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport java.util.List;\n\n@Service\npublic class UserServiceImpl extends ServiceImpl<UserMapper,User> implements UserService {\n\t//此处故意为空\n}\n```\n\n## 整合 Redis\n\n导入Redis的`starter`场景依赖：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n\n<!-- spring2.X 集成redis所需common-pool2-->\n<dependency>\n    <groupId>org.apache.commons</groupId>\n    <artifactId>commons-pool2</artifactId>\n</dependency>\n\n<!--导入jedis-->\n<dependency>\n    <groupId>redis.clients</groupId>\n    <artifactId>jedis</artifactId>\n</dependency>\n```\n\nRedis相关的组件都由 **RedisAutoConfiguration** 完成配置和注入：\n\n![image-20210914141335348](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2%E6%95%B4%E5%90%88%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8A%80%E6%9C%AF/image-20210914141335348.png)\n\n其绑定了 `spring.redis` 属性，并且向容器中注入了：\n\n- `RedisTemplate<Object, Object>`\n- `StringRedisTemplate`，其 key-value 都是String类型\n\n提供了两种 Redis 客户端：\n\n- **Lettuce**：默认，基于Netty框架的客户端，线程安全，性能较好。\n- **Jedis**\n\n### 配置文件\n\n``` yaml\nspring:\n  redis:\n    host: 192.168.1.203\n    port: 6379\n    password:  \n    database: 0             # Redis 数据库索引（默认为0）\n    client-type: lettuce    # Redis 客户端类型\n    timeout: 1800000        # 连接超时时间（毫秒）\n    lettuce:\n       pool:\n         max-active: 10     # 连接池最大连接数（使用负值表示没有限制）\n         max-wait: -1       # 最大阻塞等待时间（负数表示没限制）\n         min-idle: 5        # 连接池中的最大空闲连接\n         min-idle: 0        # 连接池中的最小空闲连接\n\n    # 也可以配置客户端为 jedis      \n    # jedis:\n      # pool:\n        # max-active: 10\n```\n\n### Redis 配置类\n\n``` java\n@EnableCaching\n@Configuration\npublic class RedisConfig extends CachingConfigurerSupport {\n\n    @Bean\n    public RedisTemplate<String, Object> redisTemplate(RedisConnectionFactory factory) {\n        RedisTemplate<String, Object> template = new RedisTemplate<>();\n        RedisSerializer<String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        template.setConnectionFactory(factory);\n        // key序列化方式\n        template.setKeySerializer(redisSerializer);\n        // value序列化\n        template.setValueSerializer(jackson2JsonRedisSerializer);\n        // value hashmap序列化\n        template.setHashValueSerializer(jackson2JsonRedisSerializer);\n        return template;\n    }\n\n    @Bean\n    public CacheManager cacheManager(RedisConnectionFactory factory) {\n        RedisSerializer<String> redisSerializer = new StringRedisSerializer();\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);\n        // 解决查询缓存转换异常的问题\n        ObjectMapper om = new ObjectMapper();\n        om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);\n        om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);\n        jackson2JsonRedisSerializer.setObjectMapper(om);\n        // 配置序列化（解决乱码的问题）, 过期时间600秒\n        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()\n            .entryTtl(Duration.ofSeconds(600))\n            .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))\n            .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))\n            .disableCachingNullValues();\n        RedisCacheManager cacheManager = RedisCacheManager.builder(factory)\n            .cacheDefaults(config)\n            .build();\n        return cacheManager;\n    }\n}\n```\n\n### 业务类测试\n\n``` java\n@RestController\n@RequestMapping(\"/redisTest\")\npublic class RedisTestController {\n    @Autowired\n    private RedisTemplate redisTemplate;\n    \n    @Autowired\n    private StringRedisTemplate redisTemplate;\n    \n    @Autowired\n    private RedisConnectionFactory redisConnectionFactory;\n\n    @GetMapping\n    public String testRedis01() {\n        // 设置值到redis\n        redisTemplate.opsForValue().set(\"name\",\"lucy\");\n\n        // 从redis获取值\n        String name = (String)redisTemplate.opsForValue().get(\"name\");\n        return name;\n    }\n    \n    @GetMapping\n    void testRedis02(){\n        ValueOperations<String, String> operations = redisTemplate.opsForValue();\n        operations.set(\"hello\",\"world\");\n        String hello = operations.get(\"hello\");\n        \n        System.out.println(hello);\n        System.out.println(redisConnectionFactory.getClass());\n    }\n}\n```\n\n### 统计 URL 访问次数\n\n自定义拦截器统计URL的访问次数\n\n``` java\n@Component\npublic class RedisUrlCountInterceptor implements HandlerInterceptor {\n    @Autowired\n    StringRedisTemplate redisTemplate;\n\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n        String uri = request.getRequestURI();\n        // 默认每次访问当前uri就会计数+1\n        redisTemplate.opsForValue().increment(uri);\n        return true;\n    }\n}\n```\n\n注册URL统计拦截器：\n\n``` java\n@Configuration\npublic class AdminWebConfig implements WebMvcConfigurer{\n    @Autowired\n    RedisUrlCountInterceptor redisUrlCountInterceptor;\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(redisUrlCountInterceptor)\n            .addPathPatterns(\"/**\")\n            .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/fonts/**\",\"/images/**\",\n                                 \"/js/**\",\"/aa/**\");\n    }\n}\n```\n\n调用Redis内的统计数据：\n\n``` java\n@Slf4j\n@Controller\npublic class IndexController {\n\n\t@Autowired\n    StringRedisTemplate redisTemplate;\n    \n\t@GetMapping(\"/main.html\")\n    public String mainPage(HttpSession session,Model model){\n        log.info(\"当前方法是：{}\",\"mainPage\");\n\n        ValueOperations<String, String> opsForValue =\n                redisTemplate.opsForValue();\n\n        String s = opsForValue.get(\"/main.html\");\n        String s1 = opsForValue.get(\"/sql\");\n\n        model.addAttribute(\"mainCount\",s);\n        model.addAttribute(\"sqlCount\",s1);\n\n        return \"main\";\n    }\n}\n```\n\n\n\n\n\n\n\n## 整合 RabbitMQ\n\n强调需要单独把rabbitmq属性配置到spring下。否则会走默认的本地端口\n\n15672是web界面的端口\n\n5672是服务端的端口\n\n\n\n## 整合 ZooKeeper\n\nZooKeeper是一个分布式协调工具，可以实现注册中心功能，Spring Cloud中整合ZooKeeper时创建的服务节点是**临时节点**。ZooKeeper详细介绍参考文章[ 【ZooKeeper】ZooKeeper](https://yuyun-zhao.github.io/2021/08/18/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/)。\n\n### 支付服务\n\n1. 新建名为`cloud-provider-payment8004`的支付服务Maven工程，占用端口8004。\n2. 引入 Maven 依赖\n\n```xml\n<!-- Spring Cloud整合zookeeper客户端 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zookeeper-discovery</artifactId>\n    <!--先排除自带的zookeeper3.5.3 防止与3.4.9起冲突-->\n    <exclusions>\n        <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n\n<!--添加zookeeper3.4.9版本-->\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.4.9</version>\n</dependency>\n```\n\n需要注意，`spring-cloud-starter-zookeeper-discovery`场景启动器自带一个ZooKeeper依赖，其版本可能与自己的ZooKeeper版本不兼容，从而无法启动Spring Boot项目，因此在pom文件中首先排除掉`spring-cloud-starter-zookeeper-discovery`中的ZooKeeper依赖，再自己添加符合自己版本的ZooKeeper依赖。（也可能会出现log4j依赖的冲突，解决方案相同）\n\n3. 修改配置文件\n\n```yaml\n# 8004表示注册到zookeeper服务器的支付服务提供者端口号\nserver:\n  port: 8004\n\n# 服务别名----注册zookeeper到注册中心名称\nspring:\n  application:\n    name: cloud-provider-payment\n  cloud:\n    zookeeper:\n      connect-string: 127.0.0.1:2181 # 192.168.111.144:2181 #\n```\n\n4. 创建主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@SpringBootApplication\n@EnableDiscoveryClient // 该注解用于向使用consul或者zookeeper作为注册中心时注册服务\npublic class PaymentMain8004 {\n    public static void main(String[] args) {\n        SpringApplication.run(PaymentMain8004.class, args);\n    }\n}\n```\n\n5. 创建 Controller\n\n```java\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport java.util.UUID;\n\n@RestController\n@Slf4j\npublic class PaymentController\n{\n    @Value(\"${server.port}\")\n    private String serverPort;\n\n    @RequestMapping(value = \"/payment/zk\")\n    public String paymentzk()\n    {\n        return \"springcloud with zookeeper: \" + serverPort + \"\\t\" +  UUID.randomUUID().toString();\n    }\n}\n```\n\n6. 测试\n\n启动支付服务8004注册进ZooKeeper（要先启动zookeeper的server）\n\n- 验证测试：浏览器 - http://localhost:8004/payment/zk\n- 验证测试2 ：接着用ZooKeeper客户端操作\n\n```bash\n[zk: localhost:2181(CONNECTED) 0] ls /\n[services, zookeeper]\n[zk: localhost:2181(CONNECTED) 1] ls /services/cloud-provider-payment\n[a4567f50-6ad9-47a3-9fbb-7391f41a9f3d]\n[zk: localhost:2181(CONNECTED) 2] get /services/cloud-provider-payment/a4567f50-6ad9-47a3-9fbb-7391f41a9f3d\n{\"name\":\"cloud-provider-payment\",\"id\":\"a4567f50-6ad9-47a3-9fbb-7391f41a9f3d\",\"address\":\"192.168.199.218\",\"port\":8004,\"ss\nlPort\":null,\"payload\":{\"@class\":\"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\",\"id\":\"application-1\",\"\nname\":\"cloud-provider-payment\",\"metadata\":{}},\"registrationTimeUTC\":1612811116918,\"serviceType\":\"DYNAMIC\",\"uriSpec\":{\"pa\nrts\":[{\"value\":\"scheme\",\"variable\":true},{\"value\":\"://\",\"variable\":false},{\"value\":\"address\",\"variable\":true},{\"value\":\"\n:\",\"variable\":false},{\"value\":\"port\",\"variable\":true}]}}\n[zk: localhost:2181(CONNECTED) 3]\n```\n\njson格式化`get /services/cloud-provider-payment/a4567f50-6ad9-47a3-9fbb-7391f41a9f3d`的结果：\n\n```json\n{\n    \"name\": \"cloud-provider-payment\", \n    \"id\": \"a4567f50-6ad9-47a3-9fbb-7391f41a9f3d\", \n    \"address\": \"192.168.199.218\", \n    \"port\": 8004, \n    \"sslPort\": null, \n    \"payload\": {\n        \"@class\": \"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\", \n        \"id\": \"application-1\", \n        \"name\": \"cloud-provider-payment\", \n        \"metadata\": { }\n    }, \n    \"registrationTimeUTC\": 1612811116918, \n    \"serviceType\": \"DYNAMIC\", \n    \"uriSpec\": {\n        \"parts\": [\n            {\n                \"value\": \"scheme\", \n                \"variable\": true\n            }, \n            {\n                \"value\": \"://\", \n                \"variable\": false\n            }, \n            {\n                \"value\": \"address\", \n                \"variable\": true\n            }, \n            {\n                \"value\": \":\", \n                \"variable\": false\n            }, \n            {\n                \"value\": \"port\", \n                \"variable\": true\n            }\n        ]\n    }\n}\n```\n\n### 订单服务\n\n1. 新建名为`cloud-consumerzk-order80`的订单服务Maven工程，端口号为80。\n2. 引入 Maven 依赖\n\n```xml\n<!-- Spring Cloud整合zookeeper客户端 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zookeeper-discovery</artifactId>\n    <!--先排除自带的zookeeper3.5.3 防止与3.4.9起冲突-->\n    <exclusions>\n        <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<!--添加zookeeper3.4.9版本-->\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.4.9</version>\n</dependency>\n```\n\n需要注意，`spring-cloud-starter-zookeeper-discovery`场景启动器自带一个ZooKeeper依赖，其版本可能与自己的ZooKeeper版本不兼容，从而无法启动Spring Boot项目，因此在pom文件中首先排除掉`spring-cloud-starter-zookeeper-discovery`中的ZooKeeper依赖，再自己添加符合自己版本的ZooKeeper依赖。（也可能会出现log4j依赖的冲突，解决方案相同）\n\n3. 修改配置文件\n\n```yaml\nserver:\n  port: 80\n\n# 服务别名----注册zookeeper到注册中心名称\nspring:\n  application:\n    name: cloud-consumer-order\n  cloud:\n    zookeeper:\n      connect-string: 127.0.0.1:2181 # 192.168.111.144:2181 #\n```\n\n4. 创建主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class OrderZKMain80 {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderZKMain80.class, args);\n    }\n}\n```\n\n5. 业务类\n\n```java\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.client.RestTemplate;\n\n@Configuration\npublic class ApplicationContextConfig\n{\n    @Bean\n    @LoadBalanced // 负载均衡\n    public RestTemplate getRestTemplate()\n    {\n        return new RestTemplate();\n    }\n}\n```\n\n```java\nimport javax.annotation.Resource;\n\n@RestController\n@Slf4j\npublic class OrderZKController\n{\n    public static final String INVOKE_URL = \"http://cloud-provider-payment\";\n\n    @Resource\n    private RestTemplate restTemplate;\n\n    @GetMapping(value = \"/consumer/payment/zk\")\n    public String paymentInfo()\n    {\n        String result = restTemplate.getForObject(INVOKE_URL+\"/payment/zk\",String.class);\n        return result;\n    }\n}\n```\n\n6. 测试\n\n先后运行ZooKeeper服务端，`cloud-consumerzk-order80`，`cloud-provider-payment8004`。\n\n打开ZooKeeper客户端：\n\n```bash\n[zk: localhost:2181(CONNECTED) 0] ls /\n[services, zookeeper]\n[zk: localhost:2181(CONNECTED) 1] ls /services\n[cloud-consumer-order, cloud-provider-payment]\n[zk: localhost:2181(CONNECTED) 2]\n```\n\n访问测试地址：http://localhost/consumer/payment/zk\n\n### 原理\n\n80客户端将从ZooKeeper中订阅8004服务端的URL信息，从而利用RestTemplate对象调用该URL对应的Rest请求，从而实现远程调用的效果\n\n\n\n\n\n","tags":["Spring","Spring Boot"],"categories":["Spring","Spring Boot"]},{"title":"【ZooKeeper】Spring Boot 整合 ZooKeeper","url":"/2021/08/28/【ZooKeeper】SpringBoot整合ZooKeeper/","content":"\nZooKeeper是一个分布式协调工具，可以实现注册中心功能，Spring Cloud中整合ZooKeeper时创建的服务节点是**临时节点**。ZooKeeper详细介绍参考文章[ 【ZooKeeper】ZooKeeper](https://yuyun-zhao.github.io/2021/08/18/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/)。\n\n本文将给出 Spring Boot 整合 ZooKeeper 的案例。\n\n## 支付服务\n\n新建名为`cloud-provider-payment8004`的支付服务Maven工程，占用端口8004。\n\n### 引入 Maven 依赖\n\n```xml\n<!-- Spring Cloud整合zookeeper客户端 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zookeeper-discovery</artifactId>\n    <!--先排除自带的zookeeper3.5.3 防止与3.4.9起冲突-->\n    <exclusions>\n        <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<!--添加zookeeper3.4.9版本-->\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.4.9</version>\n</dependency>\n```\n\n需要注意，`spring-cloud-starter-zookeeper-discovery`场景启动器自带一个ZooKeeper依赖，其版本可能与自己的ZooKeeper版本不兼容，从而无法启动Spring Boot项目，因此在pom文件中首先排除掉`spring-cloud-starter-zookeeper-discovery`中的ZooKeeper依赖，再自己添加符合自己版本的ZooKeeper依赖。（也可能会出现log4j依赖的冲突，解决方案相同）\n\n<!-- More -->\n\n### 修改配置文件\n\n```yaml\n# 8004表示注册到zookeeper服务器的支付服务提供者端口号\nserver:\n  port: 8004\n\n# 服务别名----注册zookeeper到注册中心名称\nspring:\n  application:\n    name: cloud-provider-payment\n  cloud:\n    zookeeper:\n      connect-string: 127.0.0.1:2181 # 192.168.111.144:2181 #\n```\n\n### 创建主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@SpringBootApplication\n@EnableDiscoveryClient // 该注解用于向使用consul或者zookeeper作为注册中心时注册服务\npublic class PaymentMain8004 {\n    public static void main(String[] args) {\n        SpringApplication.run(PaymentMain8004.class, args);\n    }\n}\n```\n\n### 创建 Controller\n\n```java\nimport lombok.extern.slf4j.Slf4j;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.RestController;\n\nimport java.util.UUID;\n\n@RestController\n@Slf4j\npublic class PaymentController\n{\n    @Value(\"${server.port}\")\n    private String serverPort;\n\n    @RequestMapping(value = \"/payment/zk\")\n    public String paymentzk()\n    {\n        return \"springcloud with zookeeper: \" + serverPort + \"\\t\" +  UUID.randomUUID().toString();\n    }\n}\n```\n\n### 测试\n\n启动支付服务8004注册进ZooKeeper（要先启动zookeeper的server）\n\n- 验证测试：浏览器 - http://localhost:8004/payment/zk\n- 验证测试2 ：接着用ZooKeeper客户端操作\n\n```bash\n[zk: localhost:2181(CONNECTED) 0] ls /\n[services, zookeeper]\n[zk: localhost:2181(CONNECTED) 1] ls /services/cloud-provider-payment\n[a4567f50-6ad9-47a3-9fbb-7391f41a9f3d]\n[zk: localhost:2181(CONNECTED) 2] get /services/cloud-provider-payment/a4567f50-6ad9-47a3-9fbb-7391f41a9f3d\n{\"name\":\"cloud-provider-payment\",\"id\":\"a4567f50-6ad9-47a3-9fbb-7391f41a9f3d\",\"address\":\"192.168.199.218\",\"port\":8004,\"ss\nlPort\":null,\"payload\":{\"@class\":\"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\",\"id\":\"application-1\",\"\nname\":\"cloud-provider-payment\",\"metadata\":{}},\"registrationTimeUTC\":1612811116918,\"serviceType\":\"DYNAMIC\",\"uriSpec\":{\"pa\nrts\":[{\"value\":\"scheme\",\"variable\":true},{\"value\":\"://\",\"variable\":false},{\"value\":\"address\",\"variable\":true},{\"value\":\"\n:\",\"variable\":false},{\"value\":\"port\",\"variable\":true}]}}\n[zk: localhost:2181(CONNECTED) 3]\n```\n\njson格式化`get /services/cloud-provider-payment/a4567f50-6ad9-47a3-9fbb-7391f41a9f3d`的结果：\n\n```json\n{\n    \"name\": \"cloud-provider-payment\", \n    \"id\": \"a4567f50-6ad9-47a3-9fbb-7391f41a9f3d\", \n    \"address\": \"192.168.199.218\", \n    \"port\": 8004, \n    \"sslPort\": null, \n    \"payload\": {\n        \"@class\": \"org.springframework.cloud.zookeeper.discovery.ZookeeperInstance\", \n        \"id\": \"application-1\", \n        \"name\": \"cloud-provider-payment\", \n        \"metadata\": { }\n    }, \n    \"registrationTimeUTC\": 1612811116918, \n    \"serviceType\": \"DYNAMIC\", \n    \"uriSpec\": {\n        \"parts\": [\n            {\n                \"value\": \"scheme\", \n                \"variable\": true\n            }, \n            {\n                \"value\": \"://\", \n                \"variable\": false\n            }, \n            {\n                \"value\": \"address\", \n                \"variable\": true\n            }, \n            {\n                \"value\": \":\", \n                \"variable\": false\n            }, \n            {\n                \"value\": \"port\", \n                \"variable\": true\n            }\n        ]\n    }\n}\n```\n\n## 订单服务\n\n新建名为`cloud-consumerzk-order80`的订单服务Maven工程，端口号为80。\n\n### 引入 Maven 依赖\n\n```xml\n<!-- Spring Cloud整合zookeeper客户端 -->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-zookeeper-discovery</artifactId>\n    <!--先排除自带的zookeeper3.5.3 防止与3.4.9起冲突-->\n    <exclusions>\n        <exclusion>\n            <groupId>org.apache.zookeeper</groupId>\n            <artifactId>zookeeper</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<!--添加zookeeper3.4.9版本-->\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.4.9</version>\n</dependency>\n```\n\n需要注意，`spring-cloud-starter-zookeeper-discovery`场景启动器自带一个ZooKeeper依赖，其版本可能与自己的ZooKeeper版本不兼容，从而无法启动Spring Boot项目，因此在pom文件中首先排除掉`spring-cloud-starter-zookeeper-discovery`中的ZooKeeper依赖，再自己添加符合自己版本的ZooKeeper依赖。（也可能会出现log4j依赖的冲突，解决方案相同）\n\n### 修改配置文件\n\n```yaml\nserver:\n  port: 80\n\n# 服务别名----注册zookeeper到注册中心名称\nspring:\n  application:\n    name: cloud-consumer-order\n  cloud:\n    zookeeper:\n      connect-string: 127.0.0.1:2181 # 192.168.111.144:2181 #\n```\n\n### 创建主启动类\n\n```java\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.client.discovery.EnableDiscoveryClient;\n\n@SpringBootApplication\n@EnableDiscoveryClient\npublic class OrderZKMain80 {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderZKMain80.class, args);\n    }\n}\n```\n\n### 业务类\n\n```java\nimport org.springframework.cloud.client.loadbalancer.LoadBalanced;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.web.client.RestTemplate;\n\n@Configuration\npublic class ApplicationContextConfig\n{\n    @Bean\n    @LoadBalanced // 负载均衡\n    public RestTemplate getRestTemplate()\n    {\n        return new RestTemplate();\n    }\n}\n```\n\n```java\nimport javax.annotation.Resource;\n\n@RestController\n@Slf4j\npublic class OrderZKController\n{\n    public static final String INVOKE_URL = \"http://cloud-provider-payment\";\n\n    @Resource\n    private RestTemplate restTemplate;\n\n    @GetMapping(value = \"/consumer/payment/zk\")\n    public String paymentInfo()\n    {\n        String result = restTemplate.getForObject(INVOKE_URL+\"/payment/zk\",String.class);\n        return result;\n    }\n}\n```\n\n### 测试\n\n先后运行ZooKeeper服务端，`cloud-consumerzk-order80`，`cloud-provider-payment8004`。\n\n打开ZooKeeper客户端：\n\n```bash\n[zk: localhost:2181(CONNECTED) 0] ls /\n[services, zookeeper]\n[zk: localhost:2181(CONNECTED) 1] ls /services\n[cloud-consumer-order, cloud-provider-payment]\n[zk: localhost:2181(CONNECTED) 2]\n```\n\n访问测试地址：http://localhost/consumer/payment/zk\n\n### 原理\n\n80客户端将从ZooKeeper中订阅8004服务端的URL信息，从而利用RestTemplate对象调用该URL对应的Rest请求，从而实现远程调用的效果","tags":["ZooKeeper"],"categories":["ZooKeeper"]},{"title":"【Java】SPI 机制","url":"/2021/08/25/【Java】SPI-机制/","content":"\n## SPI 简介\n\n> https://dubbo.apache.org/zh/docsv2.7/dev/source/dubbo-spi/\n\nSPI 全称为 Service Provider Interface，是一种**服务发现机制**。它是Java提供的一套用来被第三方实现或者扩展的API，它可以用来启用框架扩展和替换组件。\n\nSPI 的本质是将接口实现类的全限定名配置在文件中，并由服务加载器读取配置文件，加载实现类。这样可以在运行时，动态为接口替换实现类。正因此特性，我们可以很容易的通过 SPI 机制为我们的程序提供拓展功能。SPI 机制在第三方框架中也有所应用，比如 Dubbo 就是通过 SPI 机制加载所有的组件。不过，Dubbo 并未使用 Java 原生的 SPI 机制，而是对其进行了增强，使其能够更好的满足需求。\n\n> https://www.jianshu.com/p/46b42f7f593c\n\n![img](/images/%E3%80%90Java%E3%80%91SPI-%E6%9C%BA%E5%88%B6/5618238-5d8948367cb9b18e.png)\n\nJava SPI 实际上是“**基于接口的编程＋策略模式＋配置文件**”组合实现的动态加载机制。\n\n系统设计的各个抽象，往往有很多不同的实现方案，在面向的对象的设计里，一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。\n\nJava SPI 就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。所以SPI的核心思想就是**解耦**。\n\n<!-- More -->\n\n## 使用场景\n\n概括地说，适用于：**调用者根据实际使用需要，启用、扩展、或者替换框架的实现策略**\n\n比较常见的例子：\n\n- 数据库驱动加载接口实现类的加载：JDBC加载不同类型数据库的驱动\n- 日志门面接口实现类加载：SLF4J加载不同提供商的日志实现类\n- Spring：Spring中大量使用了SPI，比如：Spring Boot中自动配置原理；对servlet3.0规范对ServletContainerInitializer的实现、自动类型转换Type Conversion SPI（Converter SPI、Formatter SPI）等\n- Dubbo：Dubbo中也大量使用SPI的方式实现框架的扩展, 不过它对Java提供的原生SPI做了封装，允许用户扩展实现Filter接口\n\n以Spring Boot的自动配置原理为例，程序在运行时读取`\"META-INF/spring.factories\"`位置处的资源文件，从中读取到当前依赖环境下需要启动的配置类，从而实现解耦地扩展程序功能。\n\nJava SPI 使用示例见https://www.jianshu.com/p/46b42f7f593c","tags":["Java"],"categories":["Java"]},{"title":"【操作系统】操作系统","url":"/2021/08/25/【操作系统】操作系统/"},{"title":"【Linux】tmux 常用命令","url":"/2021/08/21/【Linux】tmux常用命令/","content":"\n## tmux 简介\n\n>  https://zhuanlan.zhihu.com/p/98384704\n\ntmux 是一个 terminal multiplexer（终端复用器），它可以启动一系列终端会话。它解绑了会话和终端窗口。关闭终端窗口再打开，会话并不终止，而是继续运行在执行。将会话与终端窗后彻底分离。\n\n## 安装 tmux\n\n```sh\n# Ubuntu 或 Debian\n$ sudo apt-get install tmux\n\n# CentOS 或 Fedora\n$ sudo yum install tmux\n\n# Mac\n$ brew install tmux\n```\n\n## 常用命令\n\n### 开启会话\n\n```sh\n# 启动tmux\n$ tmux\n\n# 退出\n$ exit 或 Ctrl+D\n\n# 启动命名tmux\n$ tmux new -s <name>\n```\n\n<!-- More -->\n\n### 分离会话\n\n在会话窗口上，执行`cd demo`操作后，再执行`tmux detach`，可见退出了tmux伪窗口\n\n```sh\n# 分离会话\n$ tmux detach\n```\n\n执行`tmux ls`可看到当前所有的 tmux 伪窗口：\n\n![img](/images/%E3%80%90Linux%E3%80%91tmux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/v2-695c424b8638dc60c1f8e09c709be89e_1440w.jpg)\n\n### 重接会话\n\n通过`tmux detach`关闭tmux伪窗口后，再次进入某一个会话窗口：\n\n```sh\n# 重接会话 使用伪窗口编号\n$ tmux attach -t 0\n\n# 重接会话 使用伪窗口名称\n$ tmux attach -t <name>\n```\n\n### 杀死会话\n\n```sh\n# 使用会话编号\n$ tmux kill-session -t 0\n\n# 使用会话名称\n$ tmux kill-session -t <name>\n```\n\n### 切换会话\n\n```sh\n# 使用会话编号\n$ tmux switch -t 0\n\n# 使用会话名称\n$ tmux switch -t <session-name>\n```\n\n### 创建/切换窗格\n\n```\n# 水平划分窗格\nControl + b + %\n\n# 垂直划分窗格\nControl + b + \"\n\n# 切换到上一个窗格\nControl + b + ;\n\n# 切换到上一个窗格\nControl + b + o\n```\n\n### 重命名会话\n\n```sh\n$ tmux rename-session -t 0 <new-name>\n```\n\n### 其他命令\n\n```sh\n# 列出所有快捷键，及其对应的 Tmux 命令\n$ tmux list-keys\n\n# 列出所有 Tmux 命令及其参数\n$ tmux list-commands\n\n# 列出当前所有 Tmux 会话的信息\n$ tmux info\n\n# 重新加载当前的 Tmux 配置\n$ tmux source-file ~/.tmux.conf\n```\n\n","tags":["Linux","MacOS"],"categories":["Linux","MacOS"]},{"title":"【MacOS】MacOS 安装 Homebrew","url":"/2021/08/21/【MacOS】MacOS安装Homebrew/","content":"\n![有趣的Homebrew 命名及 keg-only 的意思](/images/%E3%80%90MacOS%E3%80%91MacOS%E5%AE%89%E8%A3%85Homebrew/v2-0b3ccbc27e177698d793ebb341ef6fb8_1440w.jpg)\n\n## Homebrew 简介\n\nHomebrew是一款MacOS平台下的软件包管理工具，拥有安装、卸载、更新、查看、搜索等很多实用的功能，类似于CentOS下的apt-get/yum。只需简单的一条指令就可以实现包管理，而不用你关心各种依赖和文件路径的情况，十分方便快捷。\n\n## Homebrew 名称由来\n\n> https://zhuanlan.zhihu.com/p/196667957\n\n首先， **brew** 本身是酿造、酿酒的意思，会用这个字的原因是 **homebrew** 的安装方式为下载 **source code** 回来做编译，由于是在自己电脑做 **local compile** 编译套件，所以这个工具叫做 **homebrew** **自家酿酒**。\n\n酿酒需要有配方 **formula**，当你需要安装套件时，流程就是下 **brew** 命令去根据配方 **formula**, 酿造出一桶（ **keg**）酒来。所以 **keg** 指的是整个编译完成的套件资料夹。\n\n再来，放置套件的位置在 **/usr/local/Cellar/**（或**/opt/homebrew/Cellar/**）， **Cellar** 就是地窖，一桶一桶酿好的酒当然要存放在地窖里，所以编译安成的套件资料夹 **keg** 预设目录在 **/usr/local/Cellar/**。\n\n回到「**keg-only**」整个词，字面上意思现在就很清楚，表示这个套件只会存放在桶子里，不会跑出桶子外。实际上的行为是 **brew** 不会帮你做 **symlink** 到 **/usr/local**，避免你的原生系统内还有一套 **readline** 而打架，所以提示消息说 **readline** 套件是 **keg-only**。\n\n> https://www.zhihu.com/people/morlay\n\n**brew cask（木桶）** 是对于 **brew** 的扩展，可以采用 **brew** 的方式安装**图形界面**的软件。**brew cask** 仅仅是下载解压已经编译好了的应用包 （.dmg/.pkg），并放在统一的目录中（ **/opt/homebrew-cask/Caskroom** ），省掉了自己去下载、解压、拖拽等步骤。\n\n## 脚本配置安装\n\n>  https://zhuanlan.zhihu.com/p/98384704\n\n使用作者[@Mintimate](https://www.mintimate.cn/2020/04/05/Homebrew/)配置的脚本安装：\n\n```ruby\n$ /bin/zsh -c \"$(curl -fsSL 'https://host.mintimate.cn/fileHost/download/MTEyMjMz')\"\n```\n\n卸载homebrew：\n\n```ruby\n$ /bin/zsh -c \"$(curl -fsSL 'https://host.mintimate.cn/fileHost/download/MjIzMzQ0')\"\n```\n\n## Homebrew 常用命令\n\n安装任意包\n\n```ruby\n$ brew install <packageName>\n```\n\n示例：安装node\n\n```ruby\n$ brew install node\n```\n\n卸载任意包\n\n```ruby\n$ brew uninstall <packageName>\n```\n\n查询可用包\n\n```ruby\n$ brew search <packageName>\n```\n\n查看已安装包列表\n\n```ruby\n$ brew list\n```\n\n查看任意包信息\n\n```ruby\n$ brew info <packageName>\n```\n\n更新Homebrew\n\n```ruby\n$ brew update\n```\n\n查看Homebrew版本\n\n```ruby\n$ brew -v\n```\n\nHomebrew帮助信息\n\n```ruby\n$ brew -h\n```\n\n>  https://www.jianshu.com/p/de6f1d2d37bf\n> \n\n<!-- More -->\n\n下载的脚本内容：\n\n```sh\n#HomeBrew自动安装脚本\n#路径表.\nUNAME_MACHINE=\"$(uname -m)\"\nif [[ \"$UNAME_MACHINE\" == \"arm64\" ]]; then\n    # On ARM macOS, this script installs to /opt/homebrew only\n    HOMEBREW_PREFIX=\"/opt/homebrew\"\n    HOMEBREW_REPOSITORY=\"${HOMEBREW_PREFIX}\"\nelse\n    # On Intel macOS, this script installs to /usr/local only\n    HOMEBREW_PREFIX=\"/usr/local\"\n    HOMEBREW_REPOSITORY=\"${HOMEBREW_PREFIX}/Homebrew\"\nfi\nHOMEBREW_CACHE=\"${HOME}/Library/Caches/Homebrew\"\n\nSTAT=\"stat -f\"\nCHOWN=\"/usr/sbin/chown\"\nCHGRP=\"/usr/bin/chgrp\"\nGROUP=\"admin\"\n\n#获取前面两个.的数据\nmajor_minor() {\n  echo \"${1%%.*}.$(x=\"${1#*.}\"; echo \"${x%%.*}\")\"\n}\n\n#获取系统版本\nmacos_version=\"$(major_minor \"$(/usr/bin/sw_vers -productVersion)\")\"\n#获取系统时间\nTIME=$(date \"+%Y-%m-%d %H:%M:%S\")\n\nJudgeSuccess()\n{\n    if [ $? -ne 0 ];then\n        echo '\\033[1;31m此步骤失败 '$1'\\033[0m'\n    else\n        echo \"\\033[1;32m此步骤成功\\033[0m\"\n\n    fi\n}\n# 判断是否有系统权限\nhave_sudo_access() {\n  if [[ -z \"${HAVE_SUDO_ACCESS-}\" ]]; then\n    /usr/bin/sudo -l mkdir &>/dev/null\n    HAVE_SUDO_ACCESS=\"$?\"\n  fi\n\n  if [[ \"$HAVE_SUDO_ACCESS\" -ne 0 ]]; then\n    echo \"获取权限失败!\"\n  fi\n\n  return \"$HAVE_SUDO_ACCESS\"\n}\n\nshell_join() {\n  local arg\n  printf \"%s\" \"$1\"\n  shift\n  for arg in \"$@\"; do\n    printf \" \"\n    printf \"%s\" \"${arg// /\\ }\"\n  done\n}\n\nexecute() {\n  if ! \"$@\"; then\n    abort \"$(printf \"Failed during: %s\" \"$(shell_join \"$@\")\")\"\n  fi\n}\n\n# 管理员运行\nexecute_sudo() {\n  local -a args=(\"$@\")\n  if [[ -n \"${SUDO_ASKPASS-}\" ]]; then\n    args=(\"-A\" \"${args[@]}\")\n  fi\n  if have_sudo_access; then\n    execute \"/usr/bin/sudo\" \"${args[@]}\"\n  else\n    execute \"${args[@]}\"\n  fi\n}\n\nCreateFolder()\n{\n    echo '-> 创建文件夹' $1\n    execute_sudo \"/bin/mkdir\" \"-p\" \"$1\"\n    JudgeSuccess\n    execute_sudo \"/bin/chmod\" \"g+rwx\" \"$1\"\n    execute_sudo \"$CHOWN\" \"$USER\" \"$1\"\n    execute_sudo \"$CHGRP\" \"$GROUP\" \"$1\"\n}\n\nRmCreate()\n{\n    sudo rm -rf $1\n    CreateFolder $1\n}\n\n#git提交\ngit_commit(){\n    git add .\n    git commit -m \"your del\"\n}\n\n#version_gt 判断$1是否大于$2\nversion_gt() {\n  [[ \"${1%.*}\" -gt \"${2%.*}\" ]] || [[ \"${1%.*}\" -eq \"${2%.*}\" && \"${1#*.}\" -gt \"${2#*.}\" ]]\n}\n#version_ge 判断$1是否大于等于$2\nversion_ge() {\n  [[ \"${1%.*}\" -gt \"${2%.*}\" ]] || [[ \"${1%.*}\" -eq \"${2%.*}\" && \"${1#*.}\" -ge \"${2#*.}\" ]]\n}\n#version_lt 判断$1是否小于$2\nversion_lt() {\n  [[ \"${1%.*}\" -lt \"${2%.*}\" ]] || [[ \"${1%.*}\" -eq \"${2%.*}\" && \"${1#*.}\" -lt \"${2#*.}\" ]]\n}\n\n#一些警告判断\nwarning_if(){\n  git_https_proxy=$(git config --global https.proxy)\n  git_http_proxy=$(git config --global http.proxy)\n  if [[ -z \"$git_https_proxy\"  &&  -z \"$git_http_proxy\" ]]; then\n  echo \"未发现Git代理（属于正常状态）\"\n  else\n  echo \"\\033[1;33m\n      提示：发现你电脑设置了Git代理，如果Git报错，请运行下面两句话：\n\n              git config --global --unset https.proxy\n              git config --global --unset http.proxy\n  \"\n  fi\n}\n\necho '\n033[1;32m开始执行Brew自动安装程序\\033[0m\n['$TIME']['$macos_version']\n\\033[1;36m_____________________________________________________________\\033[0m\n\\033[1;36m    _   _\\033[0m\n\\033[1;36m    /  /|     ,                 ,\\033[0m\n\\033[1;36m---/| /-|----------__---_/_---------_--_-----__---_/_-----__-\\033[0m\n\\033[1;36m  / |/  |   /    /   )  /     /    / /  )  /   )  /     /___)\\033[0m\n\\033[1;36m_/__/___|__/____/___/__(_ ___/____/_/__/__(___(__(_ ___(___ _\\033[0m\n\\033[1;36m         Mintimate’s Blog:https://www.mintimate.cn \\033[0m\n\\033[1;36m_____________________________________________________________\\033[0m\n              \\033[1;36m作者：Mintimate\\033[0m'\n#选择一个下载源\necho '\\033[1;32m\n请选择一个下载镜像，例如中科大，输入1回车。\n\\033[1;33m 1、中科大下载源(推荐)  2、清华大学下载源  3、阿里下载源（cask使用中科大）\\033[0m'\nread \"MY_DOWN_NUM?请输入序号: \"\nif [[ \"$MY_DOWN_NUM\" -eq \"2\" ]];then\n  echo \"你选择了清华大学下载源\"\n  USER_HOMEBREW_BOTTLE_DOMAIN=https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles\n  #HomeBrew基础框架\n  USER_BREW_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git\n  #HomeBrew Core\n  USER_CORE_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\n  #HomeBrew Cask\n  USER_CASK_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git\n  USER_CASK_FONTS_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git\n  USER_CASK_DRIVERS_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-drivers.git\nelif  [[ \"$MY_DOWN_NUM\" -eq \"3\" ]];then\necho \"你选择了阿里下载源\"\n  USER_HOMEBREW_BOTTLE_DOMAIN=https://mirrors.aliyun.com/homebrew/homebrew-bottles\n  #HomeBrew基础框架\n  USER_BREW_GIT=https://mirrors.aliyun.com/homebrew/brew.git\n  #HomeBrew Core\n  USER_CORE_GIT=https://mirrors.aliyun.com/homebrew/homebrew-core.git\n  #HomeBrew Cask\n  echo \"阿里无cask源，使用清华大学cask源\"\n  USER_CASK_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git\n  USER_CASK_FONTS_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git\n  USER_CASK_DRIVERS_GIT=https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-drivers.git\nelse\n  echo \"你选择了中国科学技术大学下载源\"\n  #HomeBrew 下载源 install\n  USER_HOMEBREW_BOTTLE_DOMAIN=https://mirrors.ustc.edu.cn/homebrew-bottles\n  #HomeBrew基础框架\n  USER_BREW_GIT=https://mirrors.ustc.edu.cn/brew.git\n  #HomeBrew Core\n  USER_CORE_GIT=https://mirrors.ustc.edu.cn/homebrew-core.git\n  #HomeBrew Cask\n  USER_CASK_GIT=https://mirrors.ustc.edu.cn/homebrew-cask.git\nfi\necho '==> 通过命令删除之前的brew、创建一个新的Homebrew文件夹\n\\033[1;36m请输入开机密码，输入过程不显示，输入完后回车\\033[0m'\n# 让环境暂时纯粹，重启终端后恢复\nexport PATH=/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin\nRmCreate ${HOMEBREW_REPOSITORY}\necho '==> 删除之前brew环境，重新创建'\nsudo rm -rf ${HOMEBREW_CACHE}/\nsudo rm -rf /Users/$(whoami)/Library/Logs/Homebrew/\nsudo rm -rf ${HOMEBREW_PREFIX}/Caskroom\nsudo rm -rf ${HOMEBREW_PREFIX}/Cellar\nsudo rm -rf ${HOMEBREW_PREFIX}/var/homebrew\n\necho '==> 克隆Homebrew基本文件(brew.git仓库 32M+)'\nsudo git --version\nif [ $? -ne 0 ];then\n  sudo rm -rf \"/Library/Developer/CommandLineTools/\"\n  echo '\\033[1;36m安装Git\\033[0m后再运行此脚本，\\033[1;31m在系统弹窗中点击“安装”按钮\n如果没有弹窗的老系统，需要自己下载安装：https://git-scm.com/downloads \\033[0m'\n  xcode-select --install\n  exit 0\nfi\nsudo git clone $USER_BREW_GIT ${HOMEBREW_REPOSITORY}\nJudgeSuccess 尝试切换下载源或者网络\n\necho '==> 创建brew的快捷方式到系统环境变量'\nif [[ \"$UNAME_MACHINE\" == \"arm64\" ]]; then\n   echo 'arm64架构，自动跳过软链接'\nelse\n    find ${HOMEBREW_PREFIX}/bin -name brew -exec sudo rm -f {} \\;\n    sudo ln -s ${HOMEBREW_REPOSITORY}/bin/brew ${HOMEBREW_PREFIX}/bin/brew\n    JudgeSuccess\nfi\nwarning_if\necho '==> 克隆Homebrew Core(Homebrew core仓库 224M+) \n\\033[1;36m此处如果显示Password表示需要再次输入开机密码，输入完后回车\\033[0m'\nsudo mkdir -p ${HOMEBREW_REPOSITORY}/Library/Taps/homebrew/homebrew-core\nsudo git clone $USER_CORE_GIT ${HOMEBREW_REPOSITORY}/Library/Taps/homebrew/homebrew-core/\nJudgeSuccess 尝试切换下载源或者网络\necho '==> 克隆Homebrew Cask(Homebrew cask仓库 248M+) \n\\033[1;36m此处如果显示Password表示需要再次输入开机密码，输入完后回车\\033[0m'\nsudo mkdir -p ${HOMEBREW_REPOSITORY}/Library/Taps/homebrew/homebrew-cask\nsudo git clone $USER_CASK_GIT ${HOMEBREW_REPOSITORY}/Library/Taps/homebrew/homebrew-cask/\nJudgeSuccess 尝试切换下载源或者网络\n\nif [[ \"$UNAME_MACHINE\" == \"arm64\" ]]; then\n    echo '==> 配置ARM64架构Homebrew初始化到配置文件'\n    echo 'eval $(/opt/homebrew/bin/brew shellenv)' >> ~/.zshrc\nelse\n    echo '==> 配置X86架构Homebrew初始化到配置文件'\n    echo 'export PATH=\"/usr/local/sbin:$PATH\"' >> ~/.zshrc\nfi\n\necho '==> 配置国内下载地址'\ngit -C \"$(brew --repo homebrew/core)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git\ngit -C \"$(brew --repo homebrew/cask)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git\ngit -C \"$(brew --repo homebrew/cask-fonts)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git\ngit -C \"$(brew --repo homebrew/cask-drivers)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-drivers.git\ngit -C \"$(brew --repo homebrew/cask-versions)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-versions.git\n\nsource ~/.zshrc\necho '\n==> 安装完成，brew版本\n'\n#判断系统版本\nif version_gt \"$macos_version\" \"10.13\"; then\n    echo \"$macos_version\"\nelse\n    echo '\\033[1;31m检测到你的系统比较老，会有一些报错，请稍等Ruby下载安装;\n    '\nfi\n\nsudo chown -R $(whoami) ${HOMEBREW_REPOSITORY}\n#先暂时设置到清华大学源，中科大没有Ruby下载镜像\nHOMEBREW_BOTTLE_DOMAIN=https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles\necho 'brew -v\n'\nbrew -v\nif [ $? -ne 0 ];then\n    echo '\n    \\033[1;31m失败 留言我看到会回复(附带前面提示“此步骤失败”以及它的前6句)\n    或者使用手动安装方法（https://www.mintimate.cn/categories/Mac/）\n    或QQ咨询：198330181（可能会收费）\n    '\n    ls -al /usr/local \n    echo '--end\n    \\033[0m'\n    exit 0\nelse\n    echo \"\\033[1;32mBrew前期配置成功\\033[0m\"\nfi\necho '\n==> brew update\n'\nHOMEBREW_BOTTLE_DOMAIN=${USER_HOMEBREW_BOTTLE_DOMAIN}\nbrew update\nif [ $? -ne 0 ];then\n    echo '\n    \\033[1;31m失败 留言我看到会回复(附带前面提示“此步骤失败”以及它的前6句)\n    '\nelse\n    echo \"\n        \\033[1;32m上一句如果提示Already up-to-date表示成功\\033[0m\n            \\033[1;32mBrew自动安装程序运行完成\\033[0m\n              \\033[1;32m国内地址已经配置完成\\033[0m\n\n                初步介绍几个brew命令\n\n        本地软件库列表：brew ls\n        查找软件：brew search Software（其中SoftWare替换为要查找的软件关键字）\n        查看brew版本：brew -v  更新brew版本：brew update\n\n        Formulae（方案库 例如安装Python3）\n        安装方案库：brew install Python3（其中Python3替换为要安装的软件库名称）\n        卸载方案库：brew uninstall Python3（其中Python3替换为要卸载的软件库名称）\n\n        Casks   （界面软件 例如谷歌浏览器）\n        安装软件：brew cask install visual-studio-code（其中visual-studio-code替换为安装的软件名字，例如google-chrome）\n        卸载软件：brew cask uninstall visual-studio-code（其中visual-studio-code替换为要卸载的软件名字，例如google-chrom\n    \"\nfi\n```\n\n","tags":["MacOS"],"categories":["MacOS"]},{"title":"【MacOS】Iterm2 常用快捷键","url":"/2021/08/21/【MacOS】Iterm2常用快捷键/","content":"\n![image-20210821160959204](/images/%E3%80%90MacOS%E3%80%91Iterm2%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/image-20210821160959204.png)\n\n## 标签\n\n```bash\n新建标签：command + t\n\n关闭标签：command + w\n\n切换标签：command + 数字 command + 左右方向键\n\n切换全屏：command + enter\n\n查找：command + f\n```\n\n`command + f` 选中文本后按`Tab`键自动高亮当前文本后的内容，再按`Enter`键将高亮文本自动保存到剪切板上。\n\n- `fn + 左右方向键`：移动到行首/尾\n- `command + 左右方向键`：切换窗口\n- `option + 左右方向键`：移动到下一个单词（需要设置映射keys替换默认的`esc + b/f`）\n\n## 分屏\n\n```bash\n垂直分屏：command + d\n\n水平分屏：command + shift + d\n\n切换屏幕：command + option + 方向键 command + [ 或 command + ]\n\n查看历史命令：command + ;\n\n查看剪贴板历史：command + shift + h\n```\n\n## 其他\n\n```bash\n清除当前行：ctrl + u\n\n到行首：ctrl + a\n\n到行尾：ctrl + e\n\n前进后退：ctrl + f/b (相当于左右方向键)\n\n上一条命令：ctrl + p\n\n搜索命令历史：ctrl + r\n\n删除当前光标的字符：ctrl + d\n\n删除光标之前的字符：ctrl + h\n\n删除光标之前的单词：ctrl + w\n\n删除到文本末尾：ctrl + k\n\n交换光标处文本：ctrl + t\n\n清屏1：command + r\n\n清屏2：ctrl + l\n\n⌘ + 数字在各 tab 标签直接来回切换\n\n选择即复制 + 鼠标中键粘贴，这个很实用\n\n⌘ + f 所查找的内容会被自动复制\n\n⌘ + d 横着分屏 / ⌘ + shift + d 竖着分屏\n\n⌘ + r = clear，而且只是换到新一屏，不会想 clear 一样创建一个空屏\n\nctrl + u 清空当前行，无论光标在什么位置\n\n输入开头命令后 按 ⌘ + ; 会自动列出输入过的命令\n\n⌘ + shift + h 会列出剪切板历史\n\n可以在 Preferences > keys 设置全局快捷键调出 iterm，这个也可以用过 Alfred 实现\n```\n\n> 原文地址：https://cnbin.github.io/blog/2015/06/20/iterm2-kuai-jie-jian-da-quan/","tags":["MacOS"],"categories":["MacOS"]},{"title":"【Linux】Linux/Mac 配置 zsh + oh-my-zsh","url":"/2021/08/20/【Linux】Linux-Mac配置ZSH-Oh-My-ZSH/","content":"\n## 安装 zsh\n\n查看当前Shell\n\n```sh\necho $SHELL\n```\n\n查看自己操作系统上都安装了哪些shell：\n\n```ruby\n$ cat /etc/shells\n```\n\n显示如下：\n\n```bash\n/bin/bash\n/bin/csh\n/bin/ksh\n/bin/sh\n/bin/tcsh\n/bin/zsh # 默认没有\n```\n\n### 安装 zsh\n\n> https://www.jianshu.com/p/57acb275806c\n\n```ruby\n# macOS\n$ brew install zsh zsh-completions\n\n# Ubuntu\n$ sudo apt-get install zsh\n\n# CentOS\n$ sudo yum -y install zsh\n```\n\n注意：默认安装的zsh为旧版本，不支持powerlevel10k等主题，需要手动安装最新版的zsh：https://blog.csdn.net/weixin_42000303/article/details/106027827\n\n### 切换为默认 shell\n\n```sh\n$ chsh -s /bin/zsh\n```\n\n切换后重新打开终端\n\n<!-- More -->\n\n## 安装 Oh My Zsh\n\n> https://www.mintimate.cn/2021/02/05/configZsh/\n\n### 官方安装\n\n`Linux/Mac` 打开终端，输入官方提供的脚本：\n\n```ruby\n$ sh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\nCopy\n```\n\n为了保证脚本能顺利运行，你的 `Linux/Mac` 服务器需要：\n\n- 提前安装`git`、`curl`\n- 可以成功连接GitHub\n- 如果有`~/.zshrc`文件，最好提前备份\n\n![官方方法安装](/images/%E3%80%90Linux%E3%80%91Linux-Mac%E9%85%8D%E7%BD%AEZSH-Oh-My-ZSH/installOhMyZshOfficial.png)\n\n### 脚本安装\n\n若连接 Github 超时，可以使用作者[@Mintimate](https://www.mintimate.cn/2021/02/05/configZsh/)配置的脚本安装：\n\n\n```\nzsh -c \"$(curl -fsSL 'https://host.mintimate.cn/fileHost/download/MTM1NjkzNzI1OTIxMDg0NjIwOQ==')\"\n```\n\n为了保证脚本能顺利运行，你的`Linux/Mac`服务器需要：\n\n- 提前安装`curl`、`unzip`\n- 如果有`~/.zshrc`文件，最好提前备份，否则本脚本自动更改原本的`.zshrc`文件为`zshrcBak`\n\n### 配置插件\n\nOh My ZSH 支持许多插件，例如：\n\n- `zsh-autosuggestions`：命令自动补全\n- `autojump`：自动跳转\n- `zsh-syntax-highlighting`：命令高亮\n\n在`~/.zshrc`文件中添加这些插件：\n\n```\nplugins=(zsh-autosuggestions autojump zsh-syntax-highlighting)\n```\n\n### 插件安装方法\n\n将第三方插件 `git clone` 到 `$ZSH_CUSTOM/plugins/` ，再配置到 `~/.zshrc` 文件中即可\n\n`zsh-autosuggestions`插件：\n\n```sh\n$ git clone https://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions\n```\n\n`zsh-syntax-highlighting`插件：\n\n```sh\n$ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git $ZSH_CUSTOM/plugins/zsh-syntax-highlighting\n```\n\n`autojump`插件：\n\n```sh\n# 下载插件autojump到/.oh-my-zsh/custom/plugins目录中\n$ git clone git://github.com/joelthelion/autojump.git $ZSH_CUSTOM/plugins/autojump\n\n# cd到目录autojump中\n$ cd $ZSH_CUSTOM/plugins/autojump\n\n# 执行install.py\n$ ./install.py\n```\n\n之后根据提示在`.zshrc`文件中添加：\n\n```\n[[ -s ~/.autojump/etc/profile.d/autojump.sh ]] && . ~/.autojump/etc/profile.d/autojump.sh\n```\n\n### 安装主题\n\n若想安装第三方主题，只需先将对应主题从 Github 上`clone`到本地，再将`clone`得到的`xxx-.zsh-theme`文件拷贝到`~/.oh-my-zsh/themes/`下即可。（个别主题可能需要将lib文件下的配置文件也拷贝到`~/.oh-my-zsh/themes/lib/`下）\n\n## 使用技巧\n\n> https://michael728.github.io/2018/03/11/tools-zsh-tutorial/\n\n- 连按两次Tab会列出所有的补全列表并直接开始选择，补全项可以使用 ctrl+n/p/f/b上下左右切换\n- 智能跳转，安装了 autojump 之后，zsh 会自动记录你访问过的目录，通过 j 目录名 可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过 hadoop-1.0.0 目录，输入j hado 即可正确跳转。j –stat 可以看你的历史路径库。\n- 命令选项补全。在zsh中只需要键入 tar - 就会列出所有的选项和帮助说明\n- 在当前目录下输入 .. 或 … ，或直接输入当前目录名都可以跳转，你甚至不再需要输入 `cd` 命令了。在你知道路径的情况下，比如 `/usr/local/bin` 你可以输入`cd /u/l/b` 然后按进行补全快速输入\n- 目录浏览和跳转：输入 d，即可列出你在这个会话里访问的目录列表，输入列表前的序号，即可直接跳转。\n- 命令参数补全。键入`kill <tab>` 就会列出所有的进程名和对应的进程号\n- 更智能的历史命令。在用或者方向上键查找历史命令时，zsh支持限制查找。比如，输入ls,然后再按方向上键，则只会查找用过的ls命令。而此时使用则会仍然按之前的方式查找，忽略 ls\n- 多个终端会话共享历史记录\n- 通配符搜索：`ls -l **/*.sh`，可以递归显示当前目录下的 shell 文件，文件少时可以代替 `find`。使用 `**/` 来递归搜索\n- 扩展环境变量，输入环境变量然后按 就可以转换成表达的值\n- 在 .zshrc 中添加 `setopt HIST_IGNORE_DUPS` 可以消除重复记录，也可以利用`sort -t \";\" -k 2 -u ~/.zsh_history | sort -o ~/.zsh_history`手动清除\n\n## 安装 Powerlevel10k 主题\n\n> https://www.jianshu.com/p/57acb275806c\n\n**注意：使用 Powerlevel10k 需要ZSH版本在5.1以上**\n\n[Powerlevel10k ](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fromkatv%2Fpowerlevel10k%2F)主题安装：\n\n```sh\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/themes/powerlevel10k\n```\n\n克隆下来之后，在 zsh 的配置文件 `~/.zshrc` 中设置 `ZSH_THEME=powerlevel10k/powerlevel10k` 即可。\n\n### 安装 Nerd Font 字体\n\n完成上述操作之后，你可能会发现终端出现了乱码，这是因为你的电脑不支持那么多字体，需要安装扩展字体。\n\n [nerd-fonts GitHub ](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fryanoasis%2Fnerd-fonts%23patched-fonts)安装：\n\n```sh\ngit clone https://github.com/ryanoasis/nerd-fonts.git --depth 1\ncd nerd-fonts \n./install.sh\ncd ..\nrm -rf nerd-fonts\n```\n\n安装之后，对于 iTerm2 来说，在 `Preferences-Profiles-Text-Font` 设置为对应字体。Windows Terminal 在 `settings.json` 配置中加入 `\"fontFace\": \"MesloLGS NF\"` 即可。\n\n### 配置 Powerlevel10k\n\n配置分为两步，首先使用自动化配置脚本，其次根据个人喜好进行个性化设置。Powerlevel10k 提供了一个配置脚本，运行脚本后只需回答几个简单的问题即可完成配置。\n\n直接输入 `p10k configure` 即可进入配置问答界面，完成后会生成一个配置文件 `~/.p10k.zsh`，并且在 `~/.zshrc` 中自动加入了\n\n```sh\n# To customize prompt, run `p10k configure` or edit ~/.p10k.zsh.\n[[ -f ~/.p10k.zsh ]] && source ~/.p10k.zsh\n```\n\n在配置过程中需要注意的是，`Instant Promt Mode` 尽量选择打开，可以加快终端启动速度，详情请见[这里](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fromkatv%2Fpowerlevel10k%23instant-prompt)。\n\n## 安装 zplug\n\nzplug用于管理zsh的各种插件，可以使用zplug结合powerlevel9k定制化自己的主题图标：\n\n\n\n## 安装 Dracula 主题\n\n> https://juejin.cn/post/6844904071359545352\n>\n> https://blog.csdn.net/daiyuhe/article/details/88667875\n\n","tags":["Linux","MacOS"],"categories":["Linux","MacOS"]},{"title":"【ZooKeeper】ZooKeeper","url":"/2021/08/18/【ZooKeeper】ZooKeeper/","content":"\n![Apache ZooKeeper - Wikipedia](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/1200px-Apache_ZooKeeper_logo.svg.png)\n\n## ZooKeeper 简介\n\nZooKeeper 是一个开源的分布式的，为分布式框架提供协调服务的Apache项目。ZooKeeper安装见[Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\n![image-20210824153402010](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824153402010.png)\n\n> 本文档参考尚硅谷ZooKeeper教程：https://www.bilibili.com/video/BV1to4y1C7gw?p=2\n\n### ZooKeeper 工作机制\n\nZooKeeper从设计模式角度来理解：是一个基于**观察者模式**设计的分布式服务管理框架，它负责存储和管理大家都关心的数据，然后接受观察者的注册，一旦这些数据的状态发生变化，Zookeeper就将负责通知已经在Zookeeper上注册的那些观察者做出相应的反应。ZooKeeper服务器采用NIO与客户端进行通讯\n\n**ZooKeeper = 文件系统 + 通知机制**\n\n![image-20210824154028992](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154028992.png)\n\n<!-- More -->\n\n### ZooKeeper 特点\n\n- ZooKeeper：一个领导者（Leader），多个跟随者（Follower）组成的集群。\n- 集群中只要有**半数以上**节点存活，ZooKeeper集群就能正常服务。所以ZooKeeper适合安装**奇数**台服务器。\n- **全局数据一致**：每个Server保存一份相同的数据副本，Client无论连接到哪个Server，数据都是一致的。 \n- 更新请求顺序执行，来自同一个Client的更新请求按其发送顺序依次执行。 \n- **数据更新原子性**:一次数据更新要么成功，要么失败。 \n- 实时性：在一定时间范围内，Client能读到最新数据。\n\n![image-20210824153726239](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824153726239.png)\n\n## ZooKeeper 应用场景\n\n### 统一命名服务\n\n![image-20210824153921084](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824153921084.png)\n\n### 统一配置管理\n\n![image-20210824153938000](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824153938000.png)\n\n### 统一集群管理\n\n![image-20210824154010757](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154010757.png)\n\n### 服务器动态上下线\n\n![image-20210824154028992](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154028992.png)\n\n### 软负载均衡\n\n![image-20210824154140428](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154140428.png)\n\n### CAP 理论\n\n![image-20210824171128237](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171128237.png)\n\n**ZooKeeper保证的是CP**\n\n- ZooKeeper**不能保证每次服务请求的可用性，但需要保证数据的一致性**。（注：在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要 重新请求才能获得结果）。所以说，ZooKeeper不能保证服务可用性。\n- 例如进行Leader选举时集群都是不可用。\n\n\n\n## ZooKeeper 选举机制\n\n### 第一次启动时\n\n根据SID决定，投票都交给SID大的，一旦到达半数就选举出了Leader，其后的服务器都作为Follower。因此若服务器台数为奇数，则Leader为中位数位置的服务器。\n\n![image-20210824154209202](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154209202.png)\n\n### 非第一次启动\n\n选举Leader规则： \n\n1. `EPOCH`大的直接胜出\n2. `EPOCH`相同，`ZXID`大的胜出\n3. `ZXID`相同，`SID`大的胜出\n\n![image-20210824154403538](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154403538.png)\n\n\n\n## ZooKeeper 安装\n\nZooKeeper本地安装见[Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\n### 操作 ZooKeeper\n\n启动 ZooKeeper\n\n```sh\n$ ~/bin/zkServer.sh start\n```\n\n查看状态\n\n```sh\n$ bin/zkServer.sh status\nZooKeeper JMX enabled by default\nUsing config: /opt/module/zookeeper-3.5.7/bin/../conf/zoo.cfg\nMode: standalone\n```\n\n启动客户端\n\n```bash\n$ bin/zkCli.sh\n```\n\n退出客户端\n\n```sh\n[zk: localhost:2181(CONNECTED) 0] quit\n```\n\n停止 ZooKeeper\n\n```sh\n$ bin/zkServer.sh stop\n```\n\n### 配置参数解读\n\nZooKeeper中的配置文件`zoo.cfg`中参数含义解读如下：\n\n- `tickTime = 2000`：通信心跳时间，ZooKeeper服务器与客户端心跳时间，单位毫秒\n\n![image-20210824160926660](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824160926660.png)\n\n- `initLimit = 10`：LF初始通信时限（Leader和Follower初始连接时能容忍的**最多心跳数**（tickTime的数量））\n- `syncLimit = 5`：LF同步通信时限（Leader和Follower之间通信时间如果超过syncLimit * tickTime，Leader认为Follwer死亡，从服务器列表中删除Follwer）\n- `dataDir`：保存Zookeeper中的数据（注意：默认的tmp目录，容易被Linux系统定期删除，所以一般不用默认的tmp目录）\n- `clientPort = 2181`：客户端连接端口，通常不做修改\n\n### ZooKeeper 集群安装\n\nZooKeeper 集群安装见视频：https://www.bilibili.com/video/BV1to4y1C7gw?p=9\n\n### 常用命令\n\n| 命令基本语法 | 功能描述                                                     |\n| ------------ | ------------------------------------------------------------ |\n| help         | 显示所有操作命令                                             |\n| ls path      | 使用 ls 命令来查看当前 znode 的子节点 [可监听] -w 监听子节点变化 -s 附加次级信息 |\n| create       | 普通创建 -s 含有序列 -e 临时（重启或者超时消失）             |\n| get path     | 获得节点的值 [可监听] -w 监听节点内容变化 -s 附加次级信息    |\n| set          | 设置节点的具体值                                             |\n| stat         | 查看节点状态                                                 |\n| delete       | 删除节点                                                     |\n| deleteall    | 递归删除节点                                                 |\n\n启动客户端\n\n```sh\n$ bin/zkCli.sh -server xxx:2181\n```\n\n显示所有操作命令\n\n```sh\n[zk: hadoop102:2181(CONNECTED) 1] help\n```\n\n查看当前znode中所包含的详细内容\n\n```sh\n[zk: hadoop102:2181(CONNECTED) 5] ls -s /\n[zookeeper]cZxid = 0x0\nctime = Thu Jan 01 08:00:00 CST 1970\nmZxid = 0x0\nmtime = Thu Jan 01 08:00:00 CST 1970\npZxid = 0x0\ncversion = -1\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 0\nnumChildren = 1\n```\n\n- `czxid`：创建节点的事务 zxid 每次修改 ZooKeeper 状态都会产生一个 ZooKeeper 事务 ID。事务 ID 是 ZooKeeper 中所 有修改总的次序。每次修改都有唯一的 zxid，如果 zxid1 小于 zxid2，那么 zxid1 在 zxid2 之 前发生。 \n- `ctime`：znode 被创建的毫秒数（从 1970 年开始） \n- `mzxid`：znode 最后更新的事务 zxid \n- `mtime`：znode 最后修改的毫秒数（从 1970 年开始） \n- `pZxid`：znode 最后更新的子节点 zxid\n- `cversion`：znode 子节点变化号，znode 子节点修改次数 \n- `dataversion`：znode 数据变化号 \n- `aclVersion`：znode 访问控制列表的变化号 \n- `ephemeralOwner`：如果是临时节点，这个是 znode 拥有者的 session id。如果不是 临时节点则是 0。 \n- `dataLength`：znode 的数据长度 \n- `numChildren`：znode 子节点数量\n\n\n\n## 节点类型\n\n- 持久（Persistent）：客户端和服务器端断开连接后，创建的节点不删除\n- 短暂（Ephemeral）：客户端和服务器端断开连接后，创建的节点自己删除\n\n![image-20210824154555708](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154555708.png)\n\n### 操作节点\n\n1. 分别创建2个普通节点：永久节点 + 不带序号（注意：创建节点时，要赋值）\n\n```sh\n[zk: localhost:2181(CONNECTED) 3] create /sanguo \"diaochan\"\nCreated /sanguo\n[zk: localhost:2181(CONNECTED) 4] create /sanguo/shuguo \"liubei\"\nCreated /sanguo/shuguo\n```\n\n2. 获得节点的值\n\n```sh\n[zk: localhost:2181(CONNECTED) 5] get -s /sanguo\ndiaochan\ncZxid = 0x100000003\nctime = Wed Aug 29 00:03:23 CST 2018\nmZxid = 0x100000003\nmtime = Wed Aug 29 00:03:23 CST 2018\npZxid = 0x100000004\ncversion = 1\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 7\nnumChildren = 1\n\n[zk: localhost:2181(CONNECTED) 6] get -s /sanguo/shuguo\nliubei\ncZxid = 0x100000004\nctime = Wed Aug 29 00:04:35 CST 2018\nmZxid = 0x100000004\nmtime = Wed Aug 29 00:04:35 CST 2018\npZxid = 0x100000004\ncversion = 0\ndataVersion = 0\naclVersion = 0\nephemeralOwner = 0x0\ndataLength = 6\nnumChildren = 0\n```\n\n3. 创建带序号的节点：永久节点 + 带序号\n\n先创建一个普通的根节点/sanguo/weiguo\n\n```sh\n[zk: localhost:2181(CONNECTED) 1] create /sanguo/weiguo \"caocao\"\nCreated /sanguo/weiguo\n```\n\n创建带序号的节点\n\n```sh\n[zk: localhost:2181(CONNECTED) 2] create -s /sanguo/weiguo/zhangliao \"zhangliao\"\nCreated /sanguo/weiguo/zhangliao0000000000\n\n[zk: localhost:2181(CONNECTED) 3] create -s /sanguo/weiguo/zhangliao \"zhangliao\"\nCreated /sanguo/weiguo/zhangliao0000000001\n\n[zk: localhost:2181(CONNECTED) 4] create -s /sanguo/weiguo/xuchu \"xuchu\"\nCreated /sanguo/weiguo/xuchu0000000002\n```\n\n如果原来没有序号节点，序号从0开始依次递增。如果原节点下已有2个节点，则再排序时从 2 开始，以此类推。\n\n4. 创建短暂节点（短暂节点 + 不带序号 or 带序号）\n\n创建短暂的不带序号的节点\n\n```sh\n[zk: localhost:2181(CONNECTED) 7] create -e /sanguo/wuguo \"zhouyu\"\nCreated /sanguo/wuguo\n```\n\n创建短暂的带序号的节点\n\n```sh\n[zk: localhost:2181(CONNECTED) 2] create -e -s /sanguo/wuguo \"zhouyu\"\nCreated /sanguo/wuguo0000000001\n```\n\n在当前客户端是能查看到的\n\n```sh\n[zk: localhost:2181(CONNECTED) 3] ls /sanguo\n[wuguo, wuguo0000000001, shuguo]\n```\n\n5. 修改节点数据值\n\n```sh\n[zk: localhost:2181(CONNECTED) 6] set /sanguo/weiguo \"simayi\"\n```\n\n## 监听器原理\n\n- 在主程序中创建（new）ZooKeeper客户端`zkClient`，这时就会创建两个线程：\n  - 一个线程负责网络连接通信（connect）\n  - 一个线程负责监听（listener）\n- 通过`connect`线程将注册的监听事件发送给ZooKeeper服务器`zkServer`\n- 在`zkServer`的注册监听器列表中将注册的监听事件添加到列表中\n- 当`zkServer`监听到相应事件发生时（有数据或路径变化），就会将这个消息发送给之前注册的`zkClient`的`listener`线程\n- `zkClient`的`listener`线程调用重写的`process()`方法。\n\n![image-20210824154624360](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824154624360.png)\n\n客户端`zkClient`的代码实现：\n\n```java\nzk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {\n    @Override\n    public void process(WatchedEvent watchedEvent) {\n\t\t// 当zk服务器监听到相应事件后发生时，调用当前zk客户端重写的process()方法\n        try {\n            getServerList();\n        } catch (KeeperException e) {\n            e.printStackTrace();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n});\n```\n\n常见的监听：\n\n- 监听节点数据的变化：`get path [watch]`\n- 监听子节点增减的变化：`ls path [watch]`\n\n## 客户端向服务器写数据的流程\n\n### 当客户端直接向Leader写数据时\n\n- 客户端发来的消息（create  xxx）发送给了Leader\n- Leader将该消息发送给其他的Follower直到半数以上Follower回复了确认消息ack\n- 此时再返回给客户端已收到了消息ack\n- 之后Leader继续将该消息发送给其他的Follower直到所有的Follower都收到了消息\n- 最后所有的服务器再一起执行命令（create xxx）\n\n注意：ZooKeeper服务器同步的是消息命令（create xxx）而非数据本身。当所有服务器都收到了消息命令才会分别执行该命令。详细原理见[消息广播](#消息广播)\n\n![image-20210824163406289](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824163406289.png)\n\n### 当客户端向Follower写数据时\n\n- 该Follower会将该消息发送给Leader\n- 再由Leader将该消息同步到其他Follower，\n- 当半数以上Follower收到了该消息后，Leader回复最开始的Follower消息ack\n- 该Follower再回复客户端已收到消息ack\n- 之后Leader继续同步该消息直到所有Follower都收到了该消息命令\n- 所有服务器都收到消息后再分别执行该消息命令\n\n与第一种情况相比多了一步：收到消息的Follower向Leader汇报收到了客户端的命令，Leader再将该命令进行同步。\n\n**总结：消息同步由Leader负责执行**\n\n![image-20210824163357554](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824163357554.png)\n\n## 服务器动态上下线监听案例\n\n先在集群上创建/servers 节点\n\n```sh\n[zk: localhost:2181(CONNECTED) 10] create /servers \"servers\"\nCreated /servers\n```\n\n引入Maven依赖：\n\n```xml\n<dependency>\n    <groupId>org.apache.zookeeper</groupId>\n    <artifactId>zookeeper</artifactId>\n    <version>3.5.7</version>\n</dependency>\n```\n\n服务端代码：\n\n```java\npackage com.zhao.case1;\n\nimport org.apache.zookeeper.*;\n\nimport java.io.IOException;\n\npublic class DistributeServer {\n\n    private String connectString = \"hadoop102:2181,hadoop103:2181,hadoop104:2181\";\n    private int sessionTimeout = 2000;\n    private ZooKeeper zk;\n\n    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {\n\n        DistributeServer server = new DistributeServer();\n        // 1 获取zk连接\n        server.getConnect();\n\n        // 2 注册服务器到zk集群\n        server.regist(args[0]);\n\n\n        // 3 启动业务逻辑（睡觉）\n        server.business();\n\n    }\n\n    private void business() throws InterruptedException {\n        Thread.sleep(Long.MAX_VALUE);\n    }\n\n    private void regist(String hostname) throws KeeperException, InterruptedException {\n        String create = zk.create(\"/servers/\"+hostname, hostname.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);\n\n        System.out.println(hostname +\" is online\") ;\n    }\n\n    private void getConnect() throws IOException {\n\n        zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {\n            @Override\n            public void process(WatchedEvent watchedEvent) {\n\n            }\n        });\n    }\n}\n```\n\n客户端代码：\n\n```java\npackage com.zhao.case1;\n\nimport org.apache.zookeeper.KeeperException;\nimport org.apache.zookeeper.WatchedEvent;\nimport org.apache.zookeeper.Watcher;\nimport org.apache.zookeeper.ZooKeeper;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\n\npublic class DistributeClient {\n\n    private String connectString = \"hadoop102:2181,hadoop103:2181,hadoop104:2181\";\n    private int sessionTimeout = 2000;\n    private ZooKeeper zk;\n\n    public static void main(String[] args) throws IOException, KeeperException, InterruptedException {\n        DistributeClient client = new DistributeClient();\n\n        // 1 获取zk连接\n        client.getConnect();\n\n        // 2 监听/servers下面子节点的增加和删除\n        client.getServerList();\n\n        // 3 业务逻辑（睡觉）\n        client.business();\n\n    }\n\n    private void business() throws InterruptedException {\n        Thread.sleep(Long.MAX_VALUE);\n    }\n\n    private void getServerList() throws KeeperException, InterruptedException {\n        List<String> children = zk.getChildren(\"/servers\", true);\n\n        ArrayList<String> servers = new ArrayList<>();\n\n        for (String child : children) {\n\n            byte[] data = zk.getData(\"/servers/\" + child, false, null);\n\n            servers.add(new String(data));\n        }\n\n        // 打印\n        System.out.println(servers);\n    }\n\n    private void getConnect() throws IOException {\n        zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {\n            @Override\n            public void process(WatchedEvent watchedEvent) {\n\n                try {\n                    getServerList();\n                } catch (KeeperException e) {\n                    e.printStackTrace();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        });\n    }\n}\n```\n\n### ZooKeeper 分布式锁\n\n假设\"进程 1\"在使用该资源的时候，会先去获得锁，\"进程 1\"获得锁以后会对该资源保持独占，这样其他进程就无法访问该资源，\"进程 1\"用完该资源以后就将锁释放掉，让其他进程来获得锁，那么通过这个锁机制，我们就能保证了分布式系统中多个进程能够有序的 访问该临界资源。那么我们把这个分布式环境下的这个锁叫作分布式锁。\n\n![image-20210824164337198](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824164337198.png)\n\n### 原生 Zookeeper 实现分布式锁案例\n\n```java\npackage com.zhao.case2;\n\nimport org.apache.zookeeper.*;\nimport org.apache.zookeeper.data.Stat;\n\nimport java.io.IOException;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.concurrent.CountDownLatch;\n\npublic class DistributedLock {\n\n    private final String connectString = \"hadoop102:2181,hadoop103:2181,hadoop104:2181\";\n    private final int sessionTimeout = 2000;\n    private final ZooKeeper zk;\n\n    private CountDownLatch connectLatch = new CountDownLatch(1);\n    private CountDownLatch waitLatch = new CountDownLatch(1);\n\n    private String waitPath;\n    private String currentMode;\n\n    public DistributedLock() throws IOException, InterruptedException, KeeperException {\n\n        // 获取连接\n        zk = new ZooKeeper(connectString, sessionTimeout, new Watcher() {\n            @Override\n            public void process(WatchedEvent watchedEvent) {\n                // connectLatch  如果连接上zk  可以释放\n                if (watchedEvent.getState() == Event.KeeperState.SyncConnected){\n                    connectLatch.countDown();\n                }\n\n                // waitLatch  需要释放\n                if (watchedEvent.getType()== Event.EventType.NodeDeleted && watchedEvent.getPath().equals(waitPath)){\n                    waitLatch.countDown();\n                }\n            }\n        });\n\n        // 等待zk正常连接后，往下走程序\n        connectLatch.await();\n\n        // 判断根节点/locks是否存在\n        Stat stat = zk.exists(\"/locks\", false);\n\n        if (stat == null) {\n            // 创建一下根节点\n            zk.create(\"/locks\", \"locks\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        }\n    }\n\n    // 对zk加锁\n    public void zklock() {\n        // 创建对应的临时带序号节点\n        try {\n            currentMode = zk.create(\"/locks/\" + \"seq-\", null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL_SEQUENTIAL);\n\n            // wait一小会, 让结果更清晰一些\n            Thread.sleep(10);\n\n            // 判断创建的节点是否是最小的序号节点，如果是获取到锁；如果不是，监听他序号前一个节点\n\n            List<String> children = zk.getChildren(\"/locks\", false);\n\n            // 如果children 只有一个值，那就直接获取锁； 如果有多个节点，需要判断，谁最小\n            if (children.size() == 1) {\n                return;\n            } else {\n                Collections.sort(children);\n\n                // 获取节点名称 seq-00000000\n                String thisNode = currentMode.substring(\"/locks/\".length());\n                // 通过seq-00000000获取该节点在children集合的位置\n                int index = children.indexOf(thisNode);\n\n                // 判断\n                if (index == -1) {\n                    System.out.println(\"数据异常\");\n                } else if (index == 0) {\n                    // 就一个节点，可以获取锁了\n                    return;\n                } else {\n                    // 需要监听  他前一个节点变化\n                    waitPath = \"/locks/\" + children.get(index - 1);\n                    zk.getData(waitPath,true,new Stat());\n\n                    // 等待监听\n                    waitLatch.await();\n\n                    return;\n                }\n            }\n\n\n        } catch (KeeperException e) {\n            e.printStackTrace();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n\n\n    }\n\n    // 解锁\n    public void unZkLock() {\n\n        // 删除节点\n        try {\n            zk.delete(this.currentMode,-1);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } catch (KeeperException e) {\n            e.printStackTrace();\n        }\n\n    }\n}\n```\n\n测试代码：\n\n```java\npackage com.zhao.case2;\n\nimport org.apache.zookeeper.KeeperException;\n\nimport java.io.IOException;\n\npublic class DistributedLockTest {\n\n    public static void main(String[] args) throws InterruptedException, IOException, KeeperException {\n\n       final  DistributedLock lock1 = new DistributedLock();\n\n        final  DistributedLock lock2 = new DistributedLock();\n\n       new Thread(new Runnable() {\n           @Override\n           public void run() {\n               try {\n                   lock1.zklock();\n                   System.out.println(\"线程1 启动，获取到锁\");\n                   Thread.sleep(5 * 1000);\n\n                   lock1.unZkLock();\n                   System.out.println(\"线程1 释放锁\");\n               } catch (InterruptedException e) {\n                   e.printStackTrace();\n               }\n           }\n       }).start();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n\n                try {\n                    lock2.zklock();\n                    System.out.println(\"线程2 启动，获取到锁\");\n                    Thread.sleep(5 * 1000);\n\n                    lock2.unZkLock();\n                    System.out.println(\"线程2 释放锁\");\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n\n    }\n}\n```\n\n## Curator 框架实现分布式锁案例\n\n### 原生的 Java API 开发存在的问题 \n\n- 会话连接是异步的，需要自己去处理。比如使用 `CountDownLatch`\n- Watch 需要重复注册，不然就不能生效 \n- 开发的复杂性还是比较高的\n- 不支持多节点删除和创建，需要自己去递归\n\n**Curator 是一个专门解决分布式锁的框架**，解决了原生 JavaAPI 开发分布式遇到的问题。 详情请查看官方文档：https://curator.apache.org/index.html \n\n### Curator 案例实操\n\n引入Maven依赖\n\n```xml\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-framework</artifactId>\n    <version>4.3.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-recipes</artifactId>\n    <version>4.3.0</version>\n</dependency>\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-client</artifactId>\n    <version>4.3.0</version>\n</dependency>\n```\n\n代码：\n\n```java\npackage com.zhao.case3;\n\nimport org.apache.curator.framework.CuratorFramework;\nimport org.apache.curator.framework.CuratorFrameworkFactory;\nimport org.apache.curator.framework.recipes.locks.InterProcessMutex;\nimport org.apache.curator.retry.ExponentialBackoffRetry;\n\npublic class CuratorLockTest {\n\n    public static void main(String[] args) {\n\n        // 创建分布式锁1\n        InterProcessMutex lock1 = new InterProcessMutex(getCuratorFramework(), \"/locks\");\n\n        // 创建分布式锁2\n        InterProcessMutex lock2 = new InterProcessMutex(getCuratorFramework(), \"/locks\");\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    lock1.acquire();\n                    System.out.println(\"线程1 获取到锁\");\n\n                    lock1.acquire();\n                    System.out.println(\"线程1 再次获取到锁\");\n\n                    Thread.sleep(5 * 1000);\n\n                    lock1.release();\n                    System.out.println(\"线程1 释放锁\");\n\n                    lock1.release();\n                    System.out.println(\"线程1  再次释放锁\");\n\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n\n        new Thread(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    lock2.acquire();\n                    System.out.println(\"线程2 获取到锁\");\n\n                    lock2.acquire();\n                    System.out.println(\"线程2 再次获取到锁\");\n\n                    Thread.sleep(5 * 1000);\n\n                    lock2.release();\n                    System.out.println(\"线程2 释放锁\");\n\n                    lock2.release();\n                    System.out.println(\"线程2  再次释放锁\");\n\n                } catch (Exception e) {\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n    }\n\n    private static CuratorFramework getCuratorFramework() {\n\n        ExponentialBackoffRetry policy = new ExponentialBackoffRetry(3000, 3);\n\n        CuratorFramework client = CuratorFrameworkFactory.builder().connectString(\"hadoop102:2181,hadoop103:2181,hadoop104:2181\")\n            .connectionTimeoutMs(2000)\n            .sessionTimeoutMs(2000)\n            .retryPolicy(policy).build();\n\n        // 启动客户端\n        client.start();\n\n        System.out.println(\"zookeeper 启动成功\");\n        return client;\n    }\n}\n```\n\n## ZooKeeper 常见问题\n\n### 选举机制 \n\n**半数机制**，超过半数的投票通过，即通过。 \n\n- 第一次启动选举规则： 投票过半数时，服务器 id 大的胜出 \n- 第二次启动选举规则： \n  - EPOCH 大的直接胜出\n  - EPOCH 相同，事务 id 大的胜出\n  - 事务 id 相同，服务器 id 大的胜出\n\n### 生产集群安装多少 zk 合适？\n\n 安装奇数台。 生产经验： \n\n-  10 台服务器：3 台 zk； \n- 20 台服务器：5 台 zk； \n- 100 台服务器：11 台 zk； \n- 200 台服务器：11 台 zk \n\n服务器台数多：好处，提高可靠性；坏处：提高通信延时\n\n### 常用命令\n\n ls、get、create、delete\n\n## ZooKeeper 原理\n\n> https://www.bilibili.com/video/BV1to4y1C7gw?p=30\n\n### Paxos 算法\n\n![image-20210824170129496](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170129496.png)\n\nPaxos算法描述\n\n![image-20210824170151117](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170151117.png)\n\nPaxos算法流程\n\n![image-20210824170206961](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170206961.png)\n\n情况1：\n\n![image-20210824170235036](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170235036.png)\n\n情况2：\n\n![image-20210824170251898](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170251898.png)\n\n情况3：\n\n![image-20210824170313230](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170313230.png)\n\n### 消息广播\n\n![image-20210824170331885](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170331885.png)\n\nZAB协议针对事务请求的处理过程类似于一个两阶段提交过程 ：\n\n- 广播事务阶段 \n- 广播提交操作 \n\n有可能因为Leader宕机带来数据不一致，比如 \n\n- Leader 发 起 一 个 事 务 Proposal1 后 就 宕 机 ， Follower 都 没 有 Proposal1 \n- Leader收到半数ACK宕机， 没来得及向Follower发送Commit \n\n怎么解决呢？ZAB引入了崩溃恢复模式。\n\n### 崩溃恢复——异常假设\n\n一旦Leader服务器出现崩溃或者由于网络原因导致Leader服务器失去了与过半 Follower的联系，那么就会进入崩溃恢复模式。\n\n![image-20210824170416176](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170416176.png)\n\n### 崩溃恢复——Leader 选举\n\n![image-20210824170947242](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824170947242.png)\n\n### 崩溃恢复——数据恢复\n\n![image-20210824171017628](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171017628.png)\n\n### 崩溃恢复——异常提案处理\n\n![image-20210824171113705](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171113705.png)\n\n### CAP 理论\n\n![image-20210824171128237](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171128237.png)\n\n**ZooKeeper保证的是CP**\n\n- ZooKeeper不能保证每次服务请求的可用性。（注：在极端环境下，ZooKeeper可能会丢弃一些请求，消费者程序需要 重新请求才能获得结果）。所以说，ZooKeeper不能保证服务可用性。\n- 进行Leader选举时集群都是不可用。\n\n### 持久化\n\n每台服务器都会在磁盘保存**snapShot快照**和**TxnLog编辑日志**，二者合起来就等于内存中的数据。其中服务器在收到命令时会更新TxnLog编辑日志的内容，过一段时间后再持久化到snapShot快照中。\n\n![image-20210824171159816](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171159816.png)\n\n### 服务器间同步化\n\n![image-20210824171447010](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171447010.png)\n\n### ZK服务端初始化源码解析\n\n![image-20210824171524730](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171524730.png)\n\n![image-20210824171532346](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171532346.png)\n\n### ZK选举源码解析\n\n![image-20210824171547184](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171547184.png)\n\n### ZK选举准备源码解析\n\n![image-20210824171608595](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171608595.png)\n\n### ZK选举执行源码解析\n\n![image-20210824171754085](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171754085.png)\n\n### Follower 和 Leader 状态同步源码解析\n\n![image-20210824171809053](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171809053.png)\n\n### Follower 和 Leader 状态同步源码解析\n\n![image-20210824171829473](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171829473.png)\n\n### 服务端Leader启动\n\n![image-20210824171851563](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171851563.png)\n\n### 服务端Follower启动\n\n![image-20210824171904655](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171904655.png)\n\n### 客户端初始化源码解析\n\n![image-20210824171925106](/images/%E3%80%90ZooKeeper%E3%80%91ZooKeeper/image-20210824171925106.png)","tags":["Linux","ZooKeeper","中间件"],"categories":["Linux","ZooKeeper","中间件"]},{"title":"【JavaWeb】Web中访问资源路径问题汇总","url":"/2021/08/17/【JavaWeb】Web中访问资源路径问题汇总/","content":"\n## Web中 / 斜杠的不同意义\n\n- 浏览器内代表所有资源：`/**`\n- 服务器内代表所有资源：`/`\n\n在Web中，/ 是**绝对路径**：\n\n- / 如果被**浏览器**解析，得到的地址是：`http://ip:port/` （指写在静态html代码中，无法被服务器解析，只能被浏览器解析）\n\n``` html\n<a href=\"/\">斜杠</a>\n```\n\n- / 如果被**服务器**解析，得到的地址是：`http://ip:port/工程路径/`\n\n``` java\n// 映射\n<url-pattern>/servlet1<url-pattern>\n\n// 获取绝对路径\nservletContext.getRealPath(\"/\");\n\n// 请求转发\nrequest.getRequestDispacther(\"/\");\n```\n\n- 特殊情况：`response.sendRedirect(\"/\"); `会将斜杠发送给浏览器解析，得到`http://ip:port/` ，因此需要再加上工程名`response.sendRedirect(\"/projectName/xxx\");`\n\n**/WEB-INF/目录下的资源文件，客户端无法直接访问（即不能在浏览器中输入url直接跳转），而只能在servlet程序中跳转**\n\n**在IDEA中，\"/\"代表的项目文件路径为\"`target/项目名-1.0-SNAPSHOT/`\"**\n\n在Web应用的前端程序（.jsp）中：\n\n- 不以 / 开始的相对路径找资源时以**当前资源的路径为基准**，容易出现问题（不推荐使用）\n- 以 / 开始的相对路径找资源时以`http://ip:port/`为基准，不包含**当前项目名称路径**，因此需要在资源前加上`${pageContext.request.contextPath}/`以使程序能找到\"`target/项目名-1.0-SNAPSHOT/`\"下的资源文件（`项目名-1.0-SNAPSHOT`为Maven工程打包后生成的工程根目录）。例如若想在.jsp文件中引入css文件的路径，需要写 `href=\"${pageContext.request.contextPath}/css/style.css\"`\n\n![image-20210604105603326](/images/%E3%80%90Memo%E3%80%91Web%E4%B8%AD%E8%AE%BF%E9%97%AE%E8%B5%84%E6%BA%90%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/image-20210604105603326.png)\n\n<!-- More -->\n\n## Spring MVC资源路径映射\n\n在Spring MVC的`web.xml`中配置路径时，常用 `/`\n\n```xml\n<!-- / 匹配所有的请求；（不包括.jsp）-->\n<!-- /* 匹配所有的请求；（包括.jsp）-->\n<servlet-mapping>\n    <servlet-name>springmvc</servlet-name>\n    <url-pattern>/</url-pattern>\n</servlet-mapping>\n```\n**注意点**：\n\n- `/ ` 不会匹配 .jsp\n- `/*` 匹配所有的请求，包括 .jsp\n\n`*.jsp` 由Tomcat负责处理，不需要SpringMVC拦截处理。因此常用 `/`\n\n### 原因分析\n\n所有JavaWeb项目里的`web.xml`都继承自Tomcat的父`web.xml`，其内配置了一个默认的**DefaultServlet**：\n\n```xml\n<servlet>\n    <servlet-name>defaultServlet</servlet-name>\n    <servlet-class>org.apache.catalina.servlets.DefaultServlet</servlet-class>\n    <init-param>\n        <param-name>readonly</param-name>\n        <param-value>false</param-value>\n    </init-param>\n</servlet>\n<servlet-mapping>\n    <servlet-name>defaultServlet</servlet-name>\n    <url-pattern>/</url-pattern>\n</servlet-mapping>\n```\n\n**DefaultServlet**是Tomcat用于处理静态资源（除了jsp和servlet之外都是静态资源）的处理器，当**DefaultServlet**判断得知url中访问的是静态资源文件时，就会直接去服务器目录下找该资源是否存在。其配置了`url-pattern：/`\n\n而Spring MVC中我们同样配置了`url-pattern：/`，因此会覆盖Tomcat中的DefaultServlet，使得静态资源不能被Tomcat里的**DefaultServlet**所处理，只能被我们配置的**DispatcherServlet**拦截处理。静态资源被**DispatcherServlet**拦截时会判断哪个方法的`@RequestMapping`是这个静态资源，显然并不能找到，因此无法正常显示。\n\n`*.jsp` 处理问题：Tomcat里的web.xml中配置了对jsp文件的处理，该处理器将处理jsp文件：\n\n``` xml\n<servlet-mapping>\n    <servlet-name>jsp</servlet-name>\n    <url-pattern>*.jsp</url-pattern>\n    <url-pattern>*.jspx</url-pattern>\n</servlet-mapping>\n```\n\n若我们在SpringMVC配置中只添加`url-pattern：/`而没有添加`url-pattern：*.jsp`，则将只覆盖父web.xml里的`url-pattern：/`（处理静态资源），并没有覆盖`url-pattern：*.jsp`。因此这种情况下，遇到jsp文件，则由Tomcat里的默认处理器处理；遇到普通请求，由**DispatcherServlet**处理；遇到静态资源，因覆盖了Tomcat，则无法处理。\n\n若配置`url-pattern：/*`，则所有请求资源都将被拦截处理。\n\n因此，若想在使用Spring MVC的**DispatcherServlet**的同时仍能处理静态资源，则需要添加：\n\n```xml\n<mvc:default-servlet-handler/>\n```\n\n其能将Spring MVC无法处理的请求交给Tomcat默认的Servlet处理，让Spring MVC不处理静态资源。","tags":["JavaWeb"],"categories":["JavaWeb"]},{"title":"【Netty】Netty","url":"/2021/08/14/【Netty】Netty/","content":"\n![img](/images/%E3%80%90Netty%E3%80%91Netty/153862342369097)\n\n## Netty 概述\n\n### 原生 NIO 存在的问题\n\n> NIO的介绍见[【Java】NIO](https://yuyun-zhao.github.io/2021/08/13/%E3%80%90Java%E3%80%91NIO/)\n\n- `NIO` 的类库和 `API` 繁杂，使用麻烦：需要熟练掌握 `Selector`、`ServerSocketChannel`、`SocketChannel`、`ByteBuffer`等。\n- 需要具备其他的额外技能：要熟悉 `Java` 多线程编程，因为 `NIO` 编程涉及到 `Reactor` 模式，你必须对多线程和网络编程非常熟悉，才能编写出高质量的 `NIO` 程序。\n- 开发工作量和难度都非常大：例如客户端面临断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流的处理等等。\n- `JDK NIO` 的 `Bug`：例如臭名昭著的 `Epoll Bug`，它会导致 `Selector` 空轮询，最终导致 `CPU100%`。直到 `JDK1.7` 版本该问题仍旧存在，没有被根本解决。\n\n### Netty 官网说明\n\n官网：https://netty.io/\n\n>  Netty is an asynchronous event-driven network application framework for rapid development of maintainable high performance protocol servers & clients.\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter04_01.png)\n\n### Netty 的优点\n\n`Netty` 对 `JDK` 自带的 `NIO` 的 `API` 进行了封装，解决了上述问题。\n\n- 设计优雅：适用于各种传输类型的统一 `API` 阻塞和非阻塞 `Socket`；基于灵活且可扩展的事件模型，可以清晰地分离关注点；高度可定制的线程模型-单线程，一个或多个线程池。\n- 使用方便：详细记录的 `Javadoc`，用户指南和示例；没有其他依赖项，`JDK5（Netty3.x）`或 `6（Netty4.x）`就足够了。\n- 高性能、吞吐量更高：延迟更低；减少资源消耗；最小化不必要的内存复制。\n- 安全：完整的 `SSL/TLS` 和 `StartTLS` 支持。\n- 社区活跃、不断更新：社区活跃，版本迭代周期短，发现的 `Bug` 可以被及时修复，同时，更多的新功能会被加入。\n\n### Netty 版本说明\n\n`Netty` 版本分为 `Netty 3.x` 和 `Netty 4.x`、`Netty 5.x`。目前推荐使用的是 `Netty 4.x`的稳定版本。\n\n<!-- More -->\n\n> 博客参考：https://dongzl.github.io/netty-handbook/#/_content/chapter01\n\n## Netty 高性能架构设计\n\n### 线程模型基本介绍\n\n目前存在的线程模型有：传统阻塞 `I/O` 服务模型 `Reactor` 模式。\n\n根据 `Reactor` 的数量和处理资源池线程的数量不同，有 `3` 种典型的实现：\n\n- 单 `Reactor` 单线程；\n- 单 `Reactor`多线程；\n- 主从 `Reactor`多线程\n\n`Netty` 线程模式主要基于**主从 `Reactor` 多线程模型**做了一定的改进，其中主从 `Reactor` 多线程模型有多个 `Reactor`\n\n### 传统阻塞 I/O 服务模型\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_01.png)\n\n黄色的框表示对象，蓝色的框表示线程，白色的框表示方法（`API`）\n\n模型特点：\n\n- 采用阻塞 `IO` 模式获取输入的数据\n- 每个连接都需要独立的线程完成数据的输入，业务处理，数据返回\n\n问题分析：\n\n- 当并发数很大，就会创建大量的线程，占用很大系统资源\n- 连接创建后，如果当前线程暂时没有数据可读，该线程会阻塞在 `read` 操作，造成线程资源浪费\n\n### Reactor 模式\n\n针对传统阻塞 I/O 服务模型的 2 个缺点，解决方案：\n\n1. **基于 `I/O` 复用模型**：**多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接**。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理 `Reactor` 对应的叫法：\n   - 反应器模式\n   - 分发者模式（Dispatcher）\n   - 通知者模式（notifier）\n2. **基于线程池复用线程资源**：不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_02.png)\n\nI/O 复用结合线程池，就是 Reactor 模式基本设计思想，如图：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_03.png)\n\n对上图说明：\n\n- `Reactor` 模式，通过一个或多个输入同时传递给服务处理器的模式（基于事件驱动）\n- 服务器端程序处理传入的多个请求，并将它们同步分派到相应的处理线程，因此 `Reactor` 模式也叫 `Dispatcher` 模式\n- `Reactor` 模式使用 `IO` 复用监听事件，收到事件后，分发给某个线程（进程），这点就是网络服务器高并发处理关键\n\n### Reactor 模式中核心组成\n\n`Reactor`：`Reactor` 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理程序来对 `IO` 事件做出反应。它就像公司的电话接线员，它接听来自客户的电话并将线路转移到适当的联系人。\n\n`Handlers`：处理程序执行 `I/O` 事件要完成的实际事件，类似于客户想要与之交谈的公司中的实际官员。`Reactor` 通过调度适当的处理程序来响应 `I/O` 事件，处理程序执行非阻塞操作。\n\n### Reactor 模式分类\n\n根据 `Reactor` 的数量和处理资源池线程的数量不同，有 `3` 种典型的实现\n\n- 单 `Reactor` 单线程\n- 单 `Reactor` 多线程\n- 主从 `Reactor` 多线程\n\n### 单 Reactor 单线程\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_04.png)\n\n- `Select` 是前面 `I/O` 复用模型介绍的标准网络编程 `API`，可以实现应用程序通过一个阻塞对象监听多路连接请求\n- `Reactor` 对象通过 `Select` 监控客户端请求事件，收到事件后通过 `Dispatch` 进行分发\n- 如果是建立连接请求事件，则由 `Acceptor` 通过 `Accept` 处理连接请求，然后创建一个 `Handler` 对象处理连接完成后的后续业务处理\n- 如果不是建立连接事件，则 `Reactor` 会分发调用连接对应的 `Handler` 来响应\n- `Handler` 会完成 `Read` → 业务处理 → `Send` 的完整业务流程\n\n结合实例：服务器端用一个线程通过多路复用搞定所有的 `IO` 操作（包括连接，读、写等），编码简单，清晰明了，但是如果客户端连接数量较多，将无法支撑，**NIO 就属于这种模型**。\n\n优缺点分析：\n\n- 优点：模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成\n- 缺点：性能问题，只有一个线程，无法完全发挥多核 `CPU` 的性能。`Handler`在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈\n- 缺点：可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障\n\n使用场景：客户端的数量有限，业务处理非常快速，比如 `Redis` 在业务处理的时间复杂度 `O(1)` 的情况\n\n### 单 Reactor 多线程\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_05.png)\n\n- `Reactor` 对象通过 `Select` 监控客户端请求事件，收到事件后，通过 `Dispatch` 进行分发\n- 如果建立连接请求，则右 `Acceptor` 通过 `accept` 处理连接请求，然后创建一个 `Handler` 对象处理完成连接后的各种事件\n- 如果不是连接请求，则由 `Reactor` 分发调用连接对应的 `handler` 来处理\n- `handler` 只负责响应事件，不做具体的业务处理，通过 `read` 读取数据后，会分发给后面的 `worker` 线程池的某个线程处理业务\n- `worker` 线程池会分配独立线程完成真正的业务，并将结果返回给 `handler`\n- `handler` 收到响应后，通过 `send` 将结果返回给 `client`\n\n优缺点分析：\n\n- 优点：可以充分利用多核 `cpu` 的处理能力\n- 缺点：多线程数据共享和访问比较复杂，`Reactor` 处理所有的事件的监听和响应，在单线程运行，在高并发场景容易出现性能瓶颈。\n\n### 主从 Reactor 多线程\n\n针对单 `Reactor` 多线程模型中，`Reactor` 在单线程中运行，高并发场景下容易成为性能瓶颈，**可以让 `Reactor` 在多线程中运行**：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_06.png)\n\n- `Reactor` 主线程 `MainReactor` 对象通过 `select` 监听连接事件，收到事件后，通过 `Acceptor` 处理连接事件\n- 当 `Acceptor` 处理连接事件后，`MainReactor` 将连接分配给 `SubReactor`\n- `subreactor` 将连接加入到连接队列进行监听，并创建 `handler` 进行各种事件处理\n- 当有新事件发生时，`Subreactor` 就会调用对应的 `handler` 处理\n- `handler` 通过 `read` 读取数据，分发给后面的 `worker` 线程处理\n- `worker` 线程池分配独立的 `worker` 线程进行业务处理，并返回结果\n- `handler` 收到响应的结果后，再通过 `send` 将结果返回给 `client`\n- `Reactor` 主线程可以对应多个 `Reactor` 子线程，即 `MainRecator` 可以关联多个 `SubReactor`\n\nScalable IO in Java 对 Multiple Reactors 的原理图解：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_07.png)\n\n优缺点说明：\n\n- 优点：父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。\n- 优点：父线程与子线程的数据交互简单，`Reactor` 主线程只需要把新连接传给子线程，子线程无需返回数据。\n- 缺点：编程复杂度较高\n\n结合实例：这种模型在许多项目中广泛使用，包括 `Nginx` 主从 `Reactor` 多进程模型，`Memcached` 主从多线程，`Netty` 主从多线程模型的支持\n\n### Reactor 模式小结\n\n3 种模式用生活案例来理解：\n\n- 单 `Reactor` 单线程，前台接待员和服务员是同一个人，全程为顾客服务\n- 单 `Reactor` 多线程，`1` 个前台接待员，多个服务员，接待员只负责接待\n- 主从 `Reactor` 多线程，多个前台接待员，多个服务生\n\nReactor 模式具有如下的优点：\n\n- 响应快，不必为单个同步时间所阻塞，虽然 `Reactor` 本身依然是同步的\n- 可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销\n- 扩展性好，可以方便的通过增加 `Reactor` 实例个数来充分利用 `CPU` 资源\n- 复用性好，`Reactor` 模型本身与具体事件处理逻辑无关，具有很高的复用性\n\n## Netty 模型\n\n### Netty 模型工作原理图\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_09.png)\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_10.png)\n\n- `Netty` 抽象出两组线程池： `BossGroup` 专门负责接收客户端的连接，`WorkerGroup` 专门负责网络的读写。`BossGroup` 和 `WorkerGroup` 类型都是 `NioEventLoopGroup`\n- `NioEventLoopGroup` 相当于一个**事件循环组**，这个组中含有多个事件循环，每一个事件循环是 `NioEventLoop`。\n- **`NioEventLoop` 表示一个不断循环的执行处理任务的线程，每个 `NioEventLoop` 都有一个 `Selector`，用于监听绑定在其上的 `socket` 的网络通讯，该Selector会一直循环查询哪个注册过的Channel有就绪的I/O事件（与NIO原理相同）**\n- `NioEventLoopGroup` 可以有多个线程，即可以含有多个 `NioEventLoop`\n\n每个**BossNioEventLoop**循环执行的步骤：\n\n- 轮询 `accept` 事件\n- 处理 `accept` 事件，与 `client` 建立连接，生成 `NioScocketChannel`，并将其注册到某个 `Worker` 的`NIOEventLoop` 中的 `Selector`上\n- 处理任务队列的任务，即 `runAllTasks`\n\n每个**WorkerNIOEventLoop**循环执行的步骤：\n\n- 轮询 `read`，`write` 事件\n- 处理 `I/O` 事件，即 `read`，`write` 事件，在对应 `NioScocketChannel` 处理\n- 处理任务队列的任务，即 `runAllTasks`\n\n每个 `Worker` 的`NIOEventLoop` 在处理业务时，会使用 `Pipeline`（管道），每个`Pipeline` 都对应了一个 `Channel`，即通过 `Pipeline` 可以获取到对应通道，管道中维护了很多的处理器`Handler`，在管道内按照处理器的注册顺序执行这些处理器，直到所有处理器执行完毕。\n\n总结：\n\n- `Netty` 抽象出两组线程池，**BossGroup**专门负责接收客户端连接，**WorkerGroup**专门负责网络读写操作。这两组线程池都是**NioEventLoopGroup**类型。\n- **NioEventLoop**表示一个不断循环执行处理任务的**线程**，每个 `NioEventLoop` 都有一个 `Selector`，用于监听绑定在其上的 `socket`网络通道。\n- `NioEventLoop` 内部采用**串行化**设计，从消息的 **读取->解码->处理->编码->发送**，始终由 `IO` 线程 `NioEventLoop` 负责\n\n**NioEventLoopGroup**下包含多个 **NioEventLoop**\n\n- 每个 `NioEventLoop` 中包含有一个 `Selector`，一个 `taskQueue`\n- 每个 `NioEventLoop` 的 `Selector` 上可以注册监听多个 `NioChannel`\n- 每个 `NioChannel` 只会绑定在唯一的 `NioEventLoop` 上\n- 每个 `NioChannel` 都绑定有一个自己的 `ChannelPipeline`\n\n`Pipeline`中`Handler`执行顺序：\n\n`Pipeline`双向链表中维护了一些`ChannelHandlerContext`，每个`ChannelHandlerContext`维护了一个`Handler`。每个`ChannelHandlerContext`都维护了两个属性`inbound/outbound(boolean)`，其代表了当前`Handler`属于入站/出站类型。这样在`Pipeline`中不同类型的`Handler`就能区分开，从而互不干扰的工作：\n\n`Socket`收到消息后，入站事件在`Pipeline`中按照 `head -> tail` 的顺序依次通过入站类型的`Handler`（不通过出站类型的），全部入站类型的`Handler`执行完毕后再按照 `tail -> head` 的顺序依次通过出站类型的`Handler`，最后通过Socket发出出站消息。\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_01.png)\n\n上图中各个核心组件的分析见**Netty 核心组件**章节\n\n### Netty 快速入门实例 - TCP 服务\n\n实例要求：\n\n1. `Netty` 服务器在 `6668` 端口监听，客户端能发送消息给服务器`\"hello, 服务器~\"`\n2. 服务器可以回复消息给客户端`\"hello, 客户端~\"`\n\n`NettyServer.java`：\n\n```java\npackage com.zhao.netty.simple;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelFutureListener;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.ChannelOption;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\n\npublic class NettyServer {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建BossGroup 和 WorkerGroup\n        //说明\n        //1. 创建两个线程组 bossGroup 和 workerGroup\n        //2. bossGroup 只是处理连接请求, 真正的和客户端业务处理，会交给 workerGroup完成\n        //3. 两个都是无限循环\n        //4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数\n        //   默认实际 cpu核数 * 2\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(); //默认为cpu核数 * 2\n\n        try {\n            //创建服务器端的启动对象，配置参数\n            ServerBootstrap bootstrap = new ServerBootstrap();\n            //使用链式编程来进行设置\n            bootstrap.group(bossGroup, workerGroup) //设置两个线程组\n                .channel(NioServerSocketChannel.class) //使用NioSocketChannel作为服务器的通道实现\n                .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数\n                .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态\n                //.handler(null) // 该 handler对应 bossGroup , childHandler 对应 workerGroup\n                .childHandler(new ChannelInitializer<SocketChannel>() {//创建一个通道初始化对象(匿名对象)\n                    //给pipeline 设置处理器\n                    @Override\n                    protected void initChannel(SocketChannel ch) throws Exception {\n                        System.out.println(\"客户socketchannel hashcode=\" + ch.hashCode()); //可以使用一个集合管理 SocketChannel， 再推送消息时，可以将业务加入到各个channel 对应的 NIOEventLoop 的 taskQueue 或者 scheduleTaskQueue\n                        ch.pipeline().addLast(new NettyServerHandler());\n                    }\n                }); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器\n\n            System.out.println(\".....服务器 is ready...\");\n\n            //绑定一个端口并且同步, 生成了一个 ChannelFuture 对象\n            //启动服务器(并绑定端口)\n            ChannelFuture cf = bootstrap.bind(6668).sync();\n\n            //给cf注册监听器，监控我们关心的事件\n\n            cf.addListener(new ChannelFutureListener() {\n                @Override\n                public void operationComplete(ChannelFuture future) throws Exception {\n                    if (cf.isSuccess()) {\n                        System.out.println(\"监听端口 6668 成功\");\n                    } else {\n                        System.out.println(\"监听端口 6668 失败\");\n                    }\n                }\n            });\n\n            //对关闭通道进行监听\n            cf.channel().closeFuture().sync();\n        }finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n```\n\n`NettyServerHandler.java`\n\n\n``` java\npackage com.zhao.netty.simple;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.Channel;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.channel.ChannelPipeline;\nimport io.netty.util.CharsetUtil;\n\n/**\n * 说明\n * 1. 我们自定义一个Handler 需要继承netty规定好的某个HandlerAdapter(规范)\n * 2. 这时我们自定义一个Handler, 才能称为一个handler\n */\npublic class NettyServerHandler extends ChannelInboundHandlerAdapter {\n\n    //读取数据实际(这里我们可以读取客户端发送的消息)\n    /**\n     * 1. ChannelHandlerContext ctx:上下文对象, 含有管道pipeline, 通道channel, 地址等信息；\n     每一个处理器Handler都有一个对应的ChannelHandlerContext，其内保存了上一个Context：prev和下一个Context：next \n     * 2. Object msg: 就是客户端发送的数据 默认Object\n     */\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        System.out.println(\"服务器读取线程 \" + Thread.currentThread().getName() + \" channle =\" + ctx.channel());\n        System.out.println(\"server ctx =\" + ctx);\n        System.out.println(\"看看channel 和 pipeline的关系\");\n        Channel channel = ctx.channel();\n        ChannelPipeline pipeline = ctx.pipeline(); //本质是一个双向链接, 出站入站\n\n        //将 msg 转成一个 ByteBuf\n        //ByteBuf 是 Netty 提供的，不是 NIO 的 ByteBuffer.\n        ByteBuf buf = (ByteBuf) msg;\n        System.out.println(\"客户端发送消息是:\" + buf.toString(CharsetUtil.UTF_8));\n        System.out.println(\"客户端地址:\" + channel.remoteAddress());\n    }\n\n    //数据读取完毕\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\n        //writeAndFlush 是 write + flush\n        //将数据写入到缓存，并刷新\n        //一般讲，我们对这个发送的数据进行编码\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^<)喵1\", CharsetUtil.UTF_8));\n    }\n\n    //处理异常, 一般是需要关闭通道\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        ctx.close();\n    }\n}\n```\n\n`NettyClient.java`\n\n``` java\npackage com.zhao.netty.simple;\n\nimport io.netty.bootstrap.Bootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioSocketChannel;\n\npublic class NettyClient {\n\n    public static void main(String[] args) throws Exception {\n\n        //客户端需要一个事件循环组\n        EventLoopGroup group = new NioEventLoopGroup();\n        try {\n            //创建客户端启动对象\n            //注意客户端使用的不是 ServerBootstrap 而是 Bootstrap\n            Bootstrap bootstrap = new Bootstrap();\n            //设置相关参数\n            bootstrap.group(group) //设置线程组\n                .channel(NioSocketChannel.class) // 设置客户端通道的实现类(反射)\n                .handler(new ChannelInitializer<SocketChannel>() {\n                    @Override\n                    protected void initChannel(SocketChannel ch) throws Exception {\n                        ch.pipeline().addLast(new NettyClientHandler()); //加入自己的处理器\n                    }\n                });\n\n            System.out.println(\"客户端 ok..\");\n            //启动客户端去连接服务器端\n            //关于 ChannelFuture 要分析，涉及到netty的异步模型\n            ChannelFuture channelFuture = bootstrap.connect(\"127.0.0.1\", 6668).sync();\n            //给关闭通道进行监听\n            channelFuture.channel().closeFuture().sync();\n        } finally {\n            group.shutdownGracefully();\n        }\n    }\n}\n```\n\n`NettyClientHandler.java`\n\n``` java\npackage com.zhao.netty.simple;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.util.CharsetUtil;\n\npublic class NettyClientHandler extends ChannelInboundHandlerAdapter {\n    //当通道就绪就会触发该方法\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n        System.out.println(\"client \" + ctx);\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, server: (>^ω^<)喵\", CharsetUtil.UTF_8));\n    }\n\n    //当通道有读取事件时，会触发\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n        ByteBuf buf = (ByteBuf) msg;\n        System.out.println(\"服务器回复的消息:\" + buf.toString(CharsetUtil.UTF_8));\n        System.out.println(\"服务器的地址： \" + ctx.channel().remoteAddress());\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n\n### 任务队列\n\n任务队列中的 Task 有 3 种典型使用场景\n\n1. 用户程序自定义的普通任务\n2. 用户自定义定时任务\n3. 非当前 `Reactor` 线程调用 `Channel` 的各种方法。例如在推送系统的业务线程里面，根据用户的标识，找到对应的 `Channel` 引用，然后调用 `Write` 类方法向该用户推送消息，就会进入到这种场景。最终的 `Write` 会提交到任务队列中后被异步消费\n\n```java\npackage com.zhao.netty.simple;\n\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.util.CharsetUtil;\n\nimport java.util.concurrent.TimeUnit;\n\n/**\n * 说明\n * 1. 我们自定义一个Handler 需要继承netty规定好的某个HandlerAdapter(规范)\n * 2. 这时我们自定义一个Handler , 才能称为一个handler\n */\npublic class NettyServerHandler extends ChannelInboundHandlerAdapter {\n\n    //读取数据实际(这里我们可以读取客户端发送的消息)\n    /**\n     * 1. ChannelHandlerContext ctx:上下文对象, 含有 管道pipeline , 通道channel, 地址\n     * 2. Object msg: 就是客户端发送的数据 默认Object\n     */\n    @Override\n    public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\n\n        // 比如这里我们有一个非常耗时长的业务-> 异步执行 -> 提交该channel对应的\n        // NIOEventLoop 到 taskQueue中,\n\n        // 解决方案1：用户程序自定义的普通任务\n        ctx.channel().eventLoop().execute(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(5 * 1000);\n                    ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^<)喵2\", CharsetUtil.UTF_8));\n                    System.out.println(\"channel code=\" + ctx.channel().hashCode());\n                } catch (Exception ex) {\n                    System.out.println(\"发生异常\" + ex.getMessage());\n                }\n            }\n        });\n\n        ctx.channel().eventLoop().execute(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(5 * 1000);\n                    ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^<)喵3\", CharsetUtil.UTF_8));\n                    System.out.println(\"channel code=\" + ctx.channel().hashCode());\n                } catch (Exception ex) {\n                    System.out.println(\"发生异常\" + ex.getMessage());\n                }\n            }\n        });\n\n        //解决方案2: 用户自定义定时任务 -> 该任务提交到scheduleTaskQueue中\n        ctx.channel().eventLoop().schedule(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(5 * 1000);\n                    ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^<)喵4\", CharsetUtil.UTF_8));\n                    System.out.println(\"channel code=\" + ctx.channel().hashCode());\n                } catch (Exception ex) {\n                    System.out.println(\"发生异常\" + ex.getMessage());\n                }\n            }\n        }, 5, TimeUnit.SECONDS);\n\n        System.out.println(\"go on ...\");\n\n    }\n\n    //数据读取完毕\n    @Override\n    public void channelReadComplete(ChannelHandlerContext ctx) throws Exception {\n        //writeAndFlush 是 write + flush\n        //将数据写入到缓存，并刷新\n        //一般讲，我们对这个发送的数据进行编码\n        ctx.writeAndFlush(Unpooled.copiedBuffer(\"hello, 客户端~(>^ω^<)喵1\", CharsetUtil.UTF_8));\n    }\n\n    //处理异常, 一般是需要关闭通道\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        ctx.close();\n    }\n}\n```\n\n### Netty 异步模型\n\n异步的概念和同步相对。当一个异步过程调用发出后，调用者不能立刻得到结果。实际处理这个调用的组件在完成后，通过状态、通知和回调来通知调用者。\n\n**`Netty` 中的 `I/O` 操作是异步的**，包括 `Bind、Write、Connect` 等操作会简单的返回一个 `ChannelFuture`。调用者并不能立刻获得结果，而是通过 **Future-Listener** 机制，用户可以方便的主动获取或者通过通知机制获得 `IO` 操作结果。\n\n`Netty` 的异步模型是建立在 `Future` 和 `Callback` 的之上的。`callback` 就是回调。重点说 `Future`，它的核心思想是：假设一个方法 `fun`，计算过程可能非常耗时，等待 `fun` 返回显然不合适。那么可以在调用 `fun` 的时候，立马返回一个 `Future`，后续可以通过 `Future` 去监控方法 `fun` 的处理过程（即：`Future-Listener` 机制）\n\n`Future` 说明：\n\n- 表示异步的执行结果，可以通过它提供的方法来检测执行是否完成，比如检索计算等等。\n- `ChannelFuture` 是一个接口：`public interface ChannelFuture extends Future<void>` 我们可以添加监听器，当监听的事件发生时，就会通知到监听器。\n\n工作原理示意图：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_11.png)\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter05_12.png)\n\n说明：\n\n- 在使用 `Netty` 进行编程时，拦截操作和转换出入站数据只需要提供 `Callback` 或利用 `Future` 即可。这使得链式操作简单、高效，并有利于编写可重用的、通用的代码。\n- `Netty` 框架的目标就是让业务逻辑从网络基础应用编码中分离出来、解脱出来。\n\n### Future-Listener 机制\n\n当 `Future` 对象刚刚创建时，处于非完成状态，调用者可以通过返回的 `ChannelFuture` 来获取操作执行的状态，注册监听函数来执行完成后的操作。\n\n常见有如下操作：\n- 通过 `isDone` 方法来判断当前操作是否完成；\n- 通过 `isSuccess` 方法来判断已完成的当前操作是否成功；\n- 通过 `getCause` 方法来获取已完成的当前操作失败的原因；\n- 通过 `isCancelled` 方法来判断已完成的当前操作是否被取消；\n- 通过 `addListener` 方法来注册监听器，当操作已完成（`isDone`方法返回完成），将会通知指定的监听器；如果 `Future` 对象已完成，则通知指定的监听器\n\n举例说明：绑定端口是异步操作，当绑定操作处理完，将会调用相应的监听器处理逻辑\n\n```java\n//绑定一个端口并且同步,生成了一个ChannelFuture对象\n//启动服务器(并绑定端口)\nChannelFuture cf = bootstrap.bind(6668).sync();\n//给cf注册监听器，监控我们关心的事件\ncf.addListener(new ChannelFutureListener() {\n    @Override\n    public void operationComplete (ChannelFuture future) throws Exception {\n        if (cf.isSuccess()) {\n            System.out.println(\"监听端口6668成功\");\n        } else {\n            System.out.println(\"监听端口6668失败\");\n        }\n    }\n});\n```\n\n### Netty 快速入门实例 - HTTP服务\n\n1. 实例要求：使用 `IDEA` 创建 `Netty` 项目\n2. `Netty` 服务器在 `6668` 端口监听，浏览器发出请求 `http://localhost:6668/`\n3. 服务器可以回复消息给客户端`\"Hello!我是服务器5\"`,并对特定请求资源进行过滤。\n\n`TestServer.java`\n\n```java\npackage com.zhao.netty.http;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\n\npublic class TestServer {\n\n    public static void main(String[] args) throws Exception {\n\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup();\n\n        try {\n            ServerBootstrap serverBootstrap = new ServerBootstrap();\n\n            serverBootstrap.group(bossGroup, workerGroup)\n                .channel(NioServerSocketChannel.class)\n                .childHandler(new TestServerInitializer());\n\n            ChannelFuture channelFuture = serverBootstrap.bind(6668).sync();\n\n            channelFuture.channel().closeFuture().sync();\n\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n```\n\n`TestServerInitializer.java`\n\n``` java\npackage com.zhao.netty.http;\n\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.ChannelPipeline;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.handler.codec.http.HttpServerCodec;\n\npublic class TestServerInitializer extends ChannelInitializer<SocketChannel> {\n    //向管道加入处理器\n    @Override\n    protected void initChannel(SocketChannel ch) throws Exception { \n        //得到管道\n        ChannelPipeline pipeline = ch.pipeline();\n\n        //加入一个netty提供的httpServerCodec codec => [coder - decoder]\n        //HttpServerCodec 说明\n        //1. HttpServerCodec是netty提供的处理http的编-解码器\n        pipeline.addLast(\"MyHttpServerCodec\", new HttpServerCodec());\n        //2. 增加一个自定义的handler\n        pipeline.addLast(\"MyTestHttpServerHandler\", new TestHttpServerHandler());\n\n        System.out.println(\"ok~~~~\");\n    }\n}\n```\n\n`TestHttpServerHandler.java`\n\n``` java\npackage com.zhao.netty.http;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\nimport io.netty.handler.codec.http.*;\nimport io.netty.util.CharsetUtil;\n\nimport java.net.URI;\n\n/**\n * 说明\n * 1. SimpleChannelInboundHandler 是 ChannelInboundHandlerAdapter\n * 2. HttpObject 客户端和服务器端相互通讯的数据被封装成 HttpObject\n */\npublic class TestHttpServerHandler extends SimpleChannelInboundHandler<HttpObject> {\n\n    //channelRead0 读取客户端数据\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, HttpObject msg) throws Exception {\n\n        System.out.println(\"对应的channel=\" + ctx.channel() + \" pipeline=\" + ctx\n                           .pipeline() + \" 通过pipeline获取channel\" + ctx.pipeline().channel());\n\n        System.out.println(\"当前ctx的handler=\" + ctx.handler());\n\n        //判断 msg 是不是 httprequest请求\n        if (msg instanceof HttpRequest) {\n\n            System.out.println(\"ctx 类型=\" + ctx.getClass());\n\n            System.out.println(\"pipeline hashcode\" + ctx.pipeline().hashCode() + \" TestHttpServerHandler hash=\" + this.hashCode());\n\n            System.out.println(\"msg 类型=\" + msg.getClass());\n            System.out.println(\"客户端地址\" + ctx.channel().remoteAddress());\n\n            HttpRequest httpRequest = (HttpRequest) msg;\n            //获取uri, 过滤指定的资源\n            URI uri = new URI(httpRequest.uri());\n            if (\"/favicon.ico\".equals(uri.getPath())) {\n                System.out.println(\"请求了 favicon.ico, 不做响应\");\n                return;\n            }\n            //回复信息给浏览器 [http协议]\n\n            ByteBuf content = Unpooled.copiedBuffer(\"hello, 我是服务器\", CharsetUtil.UTF_8);\n\n            //构造一个http的相应，即 httpresponse\n            FullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content);\n\n            response.headers().set(HttpHeaderNames.CONTENT_TYPE, \"text/plain\");\n            response.headers().set(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes());\n\n            //将构建好 response返回\n            ctx.writeAndFlush(response);\n        }\n    }\n}\n```\n\n## Netty 核心组件\n\n### Bootstrap、ServerBootstrap\n\n`Bootstrap` 意思是引导，一个 `Netty` 应用通常由一个 `Bootstrap` 开始，主要作用是配置整个 `Netty` 程序，串联各个组件，`Netty` 中 `Bootstrap` 类是客户端程序的启动引导类，`ServerBootstrap` 是服务端启动引导类。\n\n`Bootstrap` 常见的方法有：\n\n- `public ServerBootstrap group(EventLoopGroup parentGroup, EventLoopGroup childGroup)`，该方法用于服务器端，用来设置两个 `EventLoop`\n- `public B group(EventLoopGroup group)`，该方法用于客户端，用来设置一个 `EventLoop`\n- `public B channel(Class<? extends C> channelClass)`，该方法用来设置一个服务器端的通道实现\n- `public <T> B option(ChannelOption<T> option, T value)`，用来给 `ServerChannel` 添加配置\n- `public <T> ServerBootstrap childOption(ChannelOption<T> childOption, T value)`，用来给接收到的通道添加配置\n- `public ServerBootstrap childHandler(ChannelHandler childHandler)`，该方法用来设置业务处理类（自定义的`handler`）\n- `public ChannelFuture bind(int inetPort)`，该方法用于服务器端，用来设置占用的端口号\n- `public ChannelFuture connect(String inetHost, int inetPort)`，该方法用于客户端，用来连接服务器端\n\n### Future、ChannelFuture\n\n`Netty` 中所有的 `IO` 操作都是异步的，不能立刻得知消息是否被正确处理。但是可以过一会等它执行完成或者直接注册一个监听，具体的实现就是通过 `Future` 和 `ChannelFutures`，他们可以注册一个监听，当操作执行成功或失败时监听会自动触发注册的监听事件。\n\n常见的方法有：\n\n- `Channel channel()`，返回当前正在进行 `IO` 操作的通道\n- `ChannelFuture sync()`，等待异步操作执行完毕\n\n### Channel\n\n`Channel`是`Netty` 网络通信的组件，能够用于执行网络 `I/O` 操作。通过 `Channel` 可获得当前网络连接的通道的状态和网络连接的配置参数（例如接收缓冲区大小）。\n\n`Channel` 提供异步的网络 `I/O` 操作(如建立连接，读写，绑定端口)，异步调用意味着任何 `I/O` 调用都将立即返回，并且不保证在调用结束时所请求的 `I/O` 操作已完成。调用立即返回一个 `ChannelFuture` 实例，通过注册监听器到 `ChannelFuture` 上，可以 在`I/O` 操作成功、失败或取消时回调通知调用方\n\n不同协议、不同的阻塞类型的连接都有不同的`Channel`类型与之对应，常用的`Channel`类型：\n\n- `NioSocketChannel`，异步的客户端 `TCP` `Socket` 连接。\n- `NioServerSocketChannel`，异步的服务器端 `TCP` `Socket` 连接。\n- `NioDatagramChannel`，异步的 `UDP` 连接。\n- `NioSctpChannel`，异步的客户端 `Sctp` 连接。\n- `NioSctpServerChannel`，异步的 `Sctp` 服务器端连接，这些通道涵盖了 `UDP` 和 `TCP` 网络 `IO` 以及文件 `IO`。\n\n### Selector\n\n`Netty` 基于 `Selector` 对象实现 `I/O` 多路复用，通过 `Selector` 一个线程可以监听多个连接的 `Channel` 事件。\n\n当向一个 `Selector` 中注册 `Channel` 后，`Selector` 内部的机制就可以自动不断地查询（`Select`）这些注册的 `Channel` 是否有已就绪的 `I/O` 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 `Channel`\n\n### ChannelHandler 及其实现类\n\n`ChannelHandler` 是一个接口，处理 `I/O` 事件或拦截 `I/O` 操作，并将其转发到其 `ChannelPipeline`（业务处理链）中的下一个处理程序。\n\n`ChannelHandler` 本身并没有提供很多方法，因为这个接口有许多的方法需要实现，方便使用期间，可以继承它的子类。`ChannelHandler` 及其实现类一览图：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_01.png)\n\n我们经常需要自定义一个 `Handler` 类去继承 `ChannelInboundHandlerAdapter`，同时根据该处理器传入的参数对象类型指定相应的`泛型<>`。例如处理`String`的`Handler`需要在泛型中指定`<String>`；处理`HttpObject`的`Handler`需要在泛型中指定`<HttpObject>`。\n\n然后通过重写相应方法实现业务逻辑，一般都需要重写：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_02.png)\n\n### Pipeline 和 ChannelPipeline\n\n**`ChannelPipeline` 是一个 `Handler` 的集合**，它负责处理和拦截 `inbound` 或者 `outbound` 的事件和操作，相当于一个贯穿 `Netty` 的链。（也可以这样理解：`ChannelPipeline` 是保存 `ChannelHandler` 的 `List`，用于处理或拦截 `Channel` 的入站事件和出站操作）\n\n`ChannelPipeline` 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 `Channel` 中各个的 `ChannelHandler` 如何相互交互\n\n在 `Netty` 中每个 `Channel` 都有且仅有一个 `ChannelPipeline` 与之对应，它们的组成关系如下：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_03.png)\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_04.png)\n\n**入事件和出站事件在一个双向链表中，入站事件会从链表head往后传递到最后一个入站的handler，出站事件会从链表tail往前传递到最前一个出站的handler，两种类型的handler互不干扰。**\n\n常用方法：\n\n- ` ChannelPipeline addFirst(ChannelHandler... handlers)`，把一个业务处理类（`handler`）添加到链中的第一个位置\n- `ChannelPipeline addLast(ChannelHandler... handlers)`，把一个业务处理类（`handler`）添加到链中的最后一个位置\n\n`Pipeline`双向链表中维护了一些`ChannelHandlerContext`，每个`ChannelHandlerContext`维护了一个`Handler`。每个`ChannelHandlerContext`都维护了两个属性`inbound/outbound(boolean)`，其代表了当前`Handler`属于入站/出站类型。这样在`Pipeline`中不同类型的`Handler`就能区分开，从而互不干扰的工作：\n\n`Socket`收到消息后，入站事件在`Pipeline`中按照 `head -> tail` 的顺序依次通过入站类型的`Handler`（不通过出站类型的），全部入站类型的`Handler`执行完毕后再按照 `tail -> head` 的顺序依次通过出站类型的`Handler`，最后通过Socket发出出站消息。\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_01.png)\n\n### ChannelHandlerContext\n\n`ChannelHandlerContext`用于保存 `Channel` 相关的所有上下文信息，同时关联一个 `ChannelHandler` 对象。即 `ChannelHandlerContext` 中包含一个具体的事件处理器 `ChannelHandler`。\n\n`Pipeline`双向链表中维护了一些`ChannelHandlerContext`，每个`ChannelHandlerContext`维护了一个`Handler`。每个`ChannelHandlerContext`都维护了两个属性`inbound/outbound(boolean)`，其代表了当前`Handler`属于入站/出站类型。这样在`Pipeline`中不同类型的`Handler`就能区分开，从而互不干扰的工作。\n\n同时 `ChannelHandlerContext` 中也绑定了对应的 `Pipeline` 和 `Channel` 的信息，方便对 `ChannelHandler` 进行调用。\n\n每一个处理器`Handler`都有一个对应的`ChannelHandlerContext`，其内保存了上一个`ChannelHandlerContext：prev`和下一个`ChannelHandlerContext：next` \n\n常用方法：\n\n- `ChannelFuture close()`，关闭通道\n- `ChannelOutboundInvoker flush()`，刷新\n- `ChannelFuture writeAndFlush(Object msg)`，将数据写到`ChannelPipeline` 中当前 `ChannelHandler` 的下一个 `ChannelHandler` 开始处理（出站）\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_05.png)\n\n### ChannelOption\n\n`Netty` 在创建 `Channel` 实例后，一般都需要设置 `ChannelOption` 参数。`ChannelOption` 参数如下：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_06.png)\n\n### EventLoopGroup 和其实现类 NioEventLoopGroup\n\n`EventLoopGroup` 是一组 `EventLoop` 的抽象，`Netty` 为了更好的利用多核 `CPU` 资源，一般会有多个 `EventLoop` 同时工作，每个 `EventLoop` 维护着一个 `Selector` 实例。\n\n`EventLoopGroup` 提供 `next` 接口，可以从组里面按照一定规则获取其中一个 `EventLoop` 来处理任务。在 `Netty` 服务器端编程中，我们一般都需要提供两个 `EventLoopGroup`，例如：`BossEventLoopGroup` 和 `WorkerEventLoopGroup`。\n\n通常一个服务端口即一个 `ServerSocketChannel` 对应一个 `Selector` 和一个 `EventLoop` 线程。`BossEventLoop` 负责接收客户端的连接并将 `SocketChannel` 交给 `WorkerEventLoopGroup` 来进行 `IO` 处理，如下图所示\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_07.png)\n\n常用方法 `public NioEventLoopGroup()`，构造方法 `public Future<?> shutdownGracefully()`，断开连接，关闭线程\n\n### Unpooled 类\n\n`Netty` 提供一个专门用来操作缓冲区（即 `Netty` 的数据容器）的工具类。常用方法如下：\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_08.png)\n\n举例说明 `Unpooled` 获取 `Netty` 的数据容器 `ByteBuf` 的基本使用\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_09.png)\n\n案例 1\n\n```java\npackage com.zhao.netty.buf;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\n\npublic class NettyByteBuf01 {\n\n    public static void main(String[] args) {\n\n        //创建一个ByteBuf\n        //说明\n        //1. 创建 对象，该对象包含一个数组arr , 是一个byte[10]\n        //2. 在netty 的buffer中，不需要使用flip 进行反转\n        //   底层维护了 readerindex 和 writerIndex\n        //3. 通过 readerindex 和  writerIndex 和  capacity， 将buffer分成三个区域\n        // 0---readerindex 已经读取的区域\n        // readerindex---writerIndex ， 可读的区域\n        // writerIndex -- capacity, 可写的区域\n        ByteBuf buffer = Unpooled.buffer(10);\n\n        for (int i = 0; i < 10; i++) {\n            buffer.writeByte(i);\n        }\n\n        System.out.println(\"capacity=\" + buffer.capacity());//10\n        //输出\n        //        for(int i = 0; i<buffer.capacity(); i++) {\n        //            System.out.println(buffer.getByte(i));\n        //        }\n        for (int i = 0; i < buffer.capacity(); i++) {\n            System.out.println(buffer.readByte());\n        }\n        System.out.println(\"执行完毕\");\n    }\n}\n```\n\n案例 2\n\n```java\npackage com.zhao.netty.buf;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\n\nimport java.nio.charset.Charset;\n\npublic class NettyByteBuf02 {\n\n    public static void main(String[] args) {\n\n        //创建ByteBuf\n        ByteBuf byteBuf = Unpooled.copiedBuffer(\"hello,world!\", Charset.forName(\"utf-8\"));\n\n        //使用相关的方法\n        if (byteBuf.hasArray()) { // true\n\n            byte[] content = byteBuf.array();\n\n            //将 content 转成字符串\n            System.out.println(new String(content, Charset.forName(\"utf-8\")));\n\n            System.out.println(\"byteBuf=\" + byteBuf);\n\n            System.out.println(byteBuf.arrayOffset()); // 0\n            System.out.println(byteBuf.readerIndex()); // 0\n            System.out.println(byteBuf.writerIndex()); // 12\n            System.out.println(byteBuf.capacity()); // 36\n\n            //System.out.println(byteBuf.readByte()); //\n            System.out.println(byteBuf.getByte(0)); // 104\n\n            int len = byteBuf.readableBytes(); //可读的字节数  12\n            System.out.println(\"len=\" + len);\n\n            //使用for取出各个字节\n            for (int i = 0; i < len; i++) {\n                System.out.println((char) byteBuf.getByte(i));\n            }\n\n            //按照某个范围读取\n            System.out.println(byteBuf.getCharSequence(0, 4, Charset.forName(\"utf-8\")));\n            System.out.println(byteBuf.getCharSequence(4, 6, Charset.forName(\"utf-8\")));\n        }\n    }\n}\n```\n\n### Netty 应用实例-群聊系统\n\n实例要求：\n\n1. 编写一个 `Netty` 群聊系统，实现服务器端和客户端之间的数据简单通讯（非阻塞）\n2. 实现多人群聊\n3. 服务器端：可以监测用户上线，离线，并实现消息转发功能\n4. 客户端：通过 `channel` 可以无阻塞发送消息给其它所有用户，同时可以接受其它用户发送的消息（有服务器转发得到）\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter06_10.png)\n\n代码如下：\n\n```java\npackage com.zhao.netty.groupchat;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.*;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\nimport io.netty.handler.codec.string.StringDecoder;\nimport io.netty.handler.codec.string.StringEncoder;\n\npublic class GroupChatServer {\n\n    private int port; //监听端口\n\n    public GroupChatServer(int port) {\n        this.port = port;\n    }\n\n    //编写run方法，处理客户端的请求\n    public void run() throws Exception {\n\n        //创建两个线程组\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop\n\n        try {\n            ServerBootstrap b = new ServerBootstrap();\n\n            b.group(bossGroup, workerGroup)\n                .channel(NioServerSocketChannel.class)\n                .option(ChannelOption.SO_BACKLOG, 128)\n                .childOption(ChannelOption.SO_KEEPALIVE, true)\n                .childHandler(new ChannelInitializer<SocketChannel>() {\n\n                    @Override\n                    protected void initChannel(SocketChannel ch) throws Exception {\n                        //获取到pipeline\n                        ChannelPipeline pipeline = ch.pipeline();\n                        //向pipeline加入解码器\n                        pipeline.addLast(\"decoder\", new StringDecoder());\n                        //向pipeline加入编码器\n                        pipeline.addLast(\"encoder\", new StringEncoder());\n                        //加入自己的业务处理handler\n                        pipeline.addLast(new GroupChatServerHandler());\n                    }\n                });\n\n            System.out.println(\"netty 服务器启动\");\n            ChannelFuture channelFuture = b.bind(port).sync();\n\n            //监听关闭\n            channelFuture.channel().closeFuture().sync();\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n\n        new GroupChatServer(7000).run();\n    }\n}\n\n\npackage com.zhao.netty.groupchat;\n\nimport io.netty.channel.Channel;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\nimport io.netty.channel.group.ChannelGroup;\nimport io.netty.channel.group.DefaultChannelGroup;\nimport io.netty.util.concurrent.GlobalEventExecutor;\n\nimport java.text.SimpleDateFormat;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\npublic class GroupChatServerHandler extends SimpleChannelInboundHandler<String> {\n\n    //public static List<Channel> channels = new ArrayList<Channel>();\n\n    //使用一个hashmap 管理\n    //public static Map<String, Channel> channels = new HashMap<String,Channel>();\n\n    //定义一个channle 组，管理所有的channel\n    //GlobalEventExecutor.INSTANCE) 是全局的事件执行器，是一个单例\n    private static ChannelGroup channelGroup = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);\n    SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n\n\n    //handlerAdded 表示连接建立，一旦连接，第一个被执行\n    //将当前channel 加入到  channelGroup\n    @Override\n    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {\n        Channel channel = ctx.channel();\n        //将该客户加入聊天的信息推送给其它在线的客户端\n        /*\n        该方法会将 channelGroup 中所有的channel 遍历，并发送 消息，\n        我们不需要自己遍历\n         */\n        channelGroup.writeAndFlush(\"[客户端]\" + channel.remoteAddress() + \" 加入聊天\" + sdf.format(new java.util.Date()) + \" \\n\");\n        channelGroup.add(channel);\n\n\n    }\n\n    //断开连接, 将xx客户离开信息推送给当前在线的客户\n    @Override\n    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\n\n        Channel channel = ctx.channel();\n        channelGroup.writeAndFlush(\"[客户端]\" + channel.remoteAddress() + \" 离开了\\n\");\n        System.out.println(\"channelGroup size\" + channelGroup.size());\n\n    }\n\n    //表示channel 处于活动状态, 提示 xx上线\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n\n        System.out.println(ctx.channel().remoteAddress() + \" 上线了~\");\n    }\n\n    //表示channel 处于不活动状态, 提示 xx离线了\n    @Override\n    public void channelInactive(ChannelHandlerContext ctx) throws Exception {\n\n        System.out.println(ctx.channel().remoteAddress() + \" 离线了~\");\n    }\n\n    //读取数据\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n\n        //获取到当前channel\n        Channel channel = ctx.channel();\n        //这时我们遍历channelGroup, 根据不同的情况，回送不同的消息\n\n        channelGroup.forEach(ch -> {\n            if (channel != ch) { //不是当前的channel,转发消息\n                ch.writeAndFlush(\"[客户]\" + channel.remoteAddress() + \" 发送了消息\" + msg + \"\\n\");\n            } else {//回显自己发送的消息给自己\n                ch.writeAndFlush(\"[自己]发送了消息\" + msg + \"\\n\");\n            }\n        });\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        //关闭通道\n        ctx.close();\n    }\n}\n\npackage com.zhao.netty.groupchat;\n\nimport io.netty.bootstrap.Bootstrap;\nimport io.netty.channel.*;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioSocketChannel;\nimport io.netty.handler.codec.string.StringDecoder;\nimport io.netty.handler.codec.string.StringEncoder;\n\nimport java.util.Scanner;\n\n\npublic class GroupChatClient {\n\n    //属性\n    private final String host;\n    private final int port;\n\n    public GroupChatClient(String host, int port) {\n        this.host = host;\n        this.port = port;\n    }\n\n    public void run() throws Exception {\n        EventLoopGroup group = new NioEventLoopGroup();\n\n        try {\n\n            Bootstrap bootstrap = new Bootstrap()\n                .group(group)\n                .channel(NioSocketChannel.class)\n                .handler(new ChannelInitializer<SocketChannel>() {\n\n                    @Override\n                    protected void initChannel(SocketChannel ch) throws Exception {\n\n                        //得到pipeline\n                        ChannelPipeline pipeline = ch.pipeline();\n                        //加入相关handler\n                        pipeline.addLast(\"decoder\", new StringDecoder());\n                        pipeline.addLast(\"encoder\", new StringEncoder());\n                        //加入自定义的handler\n                        pipeline.addLast(new GroupChatClientHandler());\n                    }\n                });\n\n            ChannelFuture channelFuture = bootstrap.connect(host, port).sync();\n            //得到channel\n            Channel channel = channelFuture.channel();\n            System.out.println(\"-------\" + channel.localAddress() + \"--------\");\n            //客户端需要输入信息，创建一个扫描器\n            Scanner scanner = new Scanner(System.in);\n            while (scanner.hasNextLine()) {\n                String msg = scanner.nextLine();\n                //通过channel 发送到服务器端\n                channel.writeAndFlush(msg + \"\\r\\n\");\n            }\n        } finally {\n            group.shutdownGracefully();\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        new GroupChatClient(\"127.0.0.1\", 7000).run();\n    }\n}\n\n\npackage com.zhao.netty.groupchat;\n\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\n\npublic class GroupChatClientHandler extends SimpleChannelInboundHandler<String> {\n\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n        System.out.println(msg.trim());\n    }\n}\n```\n\n### Netty 心跳检测机制\n\n使用空闲状态处理器**IdleStateHandler**发送读写空闲事件**IdleStateEvent**。当 `IdleStateEvent` 触发后，就会传递给管道的下一个`handler`去处理。通过调用（触发）下一个`handler` 的 `userEventTiggered()`方法 ，在该方法中去处理 `IdleStateEvent`（读空闲，写空闲，读写空闲）\n\n实例要求：\n\n1. 编写一个 `Netty` 心跳检测机制案例,当服务器超过 `3` 秒没有读时，就提示读空闲\n2. 当服务器超过 `5` 秒没有写操作时，就提示写空闲\n3. 实现当服务器超过 `7` 秒没有读或者写操作时，就提示读写空闲\n\n```java\npackage com.zhao.netty.heartbeat;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.ChannelPipeline;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\nimport io.netty.handler.logging.LogLevel;\nimport io.netty.handler.logging.LoggingHandler;\nimport io.netty.handler.timeout.IdleStateHandler;\n\nimport java.util.concurrent.TimeUnit;\n\npublic class MyServer {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建两个线程组\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop\n        try {\n\n            ServerBootstrap serverBootstrap = new ServerBootstrap();\n\n            serverBootstrap.group(bossGroup, workerGroup);\n            serverBootstrap.channel(NioServerSocketChannel.class);\n            serverBootstrap.handler(new LoggingHandler(LogLevel.INFO));\n            serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\n\n                @Override\n                protected void initChannel(SocketChannel ch) throws Exception {\n                    ChannelPipeline pipeline = ch.pipeline();\n                    //加入一个netty 提供 IdleStateHandler\n                    /*\n                    说明\n                    1. IdleStateHandler 是netty 提供的处理空闲状态的处理器\n                    2. long readerIdleTime : 表示多长时间没有读, 就会发送一个心跳检测包检测是否连接\n                    3. long writerIdleTime : 表示多长时间没有写, 就会发送一个心跳检测包检测是否连接\n                    4. long allIdleTime : 表示多长时间没有读写, 就会发送一个心跳检测包检测是否连接\n\n                    5. 文档说明\n                    triggers an {@link IdleStateEvent} when a {@link Channel} has not performed\n * read, write, or both operation for a while.\n *                  6. 当 IdleStateEvent 触发后, 就会传递给管道的下一个handler去处理\n *                  通过调用(触发)下一个handler 的 userEventTiggered , 在该方法中去处理 IdleStateEvent(读空闲，写空闲，读写空闲)\n                     */\n                    pipeline.addLast(new IdleStateHandler(7000, 7000, 10, TimeUnit.SECONDS));\n                    //加入一个对空闲检测进一步处理的handler(自定义)\n                    pipeline.addLast(new MyServerHandler());\n                }\n            });\n\n            //启动服务器\n            ChannelFuture channelFuture = serverBootstrap.bind(7000).sync();\n            channelFuture.channel().closeFuture().sync();\n\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\n\npackage com.zhao.netty.heartbeat;\n\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.ChannelInboundHandlerAdapter;\nimport io.netty.handler.timeout.IdleStateEvent;\n\npublic class MyServerHandler extends ChannelInboundHandlerAdapter {\n\n    /**\n     * @param ctx 上下文\n     * @param evt 事件\n     * @throws Exception\n     */\n    @Override\n    public void userEventTriggered(ChannelHandlerContext ctx, Object evt) throws Exception {\n\n        if (evt instanceof IdleStateEvent) {\n            //将 evt 向下转型 IdleStateEvent\n            IdleStateEvent event = (IdleStateEvent) evt;\n            String eventType = null;\n            switch (event.state()) {\n                case READER_IDLE:\n                    eventType = \"读空闲\";\n                    break;\n                case WRITER_IDLE:\n                    eventType = \"写空闲\";\n                    break;\n                case ALL_IDLE:\n                    eventType = \"读写空闲\";\n                    break;\n            }\n            System.out.println(ctx.channel().remoteAddress() + \"--超时时间--\" + eventType);\n            System.out.println(\"服务器做相应处理..\");\n\n            //如果发生空闲，我们关闭通道\n            // ctx.channel().close();\n        }\n    }\n}\n```\n\n### Netty 通过 WebSocket 编程实现服务器和客户端长连接\n\n> WebSocket介绍：http://www.ruanyifeng.com/blog/2017/05/websocket.html\n\n实例要求：\n\n1. `Http` 协议是无状态的，浏览器和服务器间的请求响应一次，下一次会重新创建连接。\n2. 要求：实现基于 `WebSocket` 的长连接的全双工的交互\n3. 改变 `Http` 协议多次请求的约束，实现长连接了，服务器可以发送消息给浏览器\n4. 客户端浏览器和服务器端会相互感知，比如服务器关闭了，浏览器会感知，同样浏览器关闭了，服务器会感知\n\n```java\npackage com.zhao.netty.websocket;\n\nimport io.netty.bootstrap.ServerBootstrap;\nimport io.netty.channel.ChannelFuture;\nimport io.netty.channel.ChannelInitializer;\nimport io.netty.channel.ChannelPipeline;\nimport io.netty.channel.EventLoopGroup;\nimport io.netty.channel.nio.NioEventLoopGroup;\nimport io.netty.channel.socket.SocketChannel;\nimport io.netty.channel.socket.nio.NioServerSocketChannel;\nimport io.netty.handler.codec.http.HttpObjectAggregator;\nimport io.netty.handler.codec.http.HttpServerCodec;\nimport io.netty.handler.codec.http.websocketx.WebSocketServerProtocolHandler;\nimport io.netty.handler.logging.LogLevel;\nimport io.netty.handler.logging.LoggingHandler;\nimport io.netty.handler.stream.ChunkedWriteHandler;\n\npublic class MyServer {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建两个线程组\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        EventLoopGroup workerGroup = new NioEventLoopGroup(); //8个NioEventLoop\n        try {\n\n            ServerBootstrap serverBootstrap = new ServerBootstrap();\n\n            serverBootstrap.group(bossGroup, workerGroup);\n            serverBootstrap.channel(NioServerSocketChannel.class);\n            serverBootstrap.handler(new LoggingHandler(LogLevel.INFO));\n            serverBootstrap.childHandler(new ChannelInitializer<SocketChannel>() {\n\n                @Override\n                protected void initChannel(SocketChannel ch) throws Exception {\n                    ChannelPipeline pipeline = ch.pipeline();\n\n                    //因为基于http协议，使用http的编码和解码器\n                    pipeline.addLast(new HttpServerCodec());\n                    //是以块方式写，添加ChunkedWriteHandler处理器\n                    pipeline.addLast(new ChunkedWriteHandler());\n\n                    /*\n                    说明\n                    1. http数据在传输过程中是分段, HttpObjectAggregator ，就是可以将多个段聚合\n                    2. 这就就是为什么，当浏览器发送大量数据时，就会发出多次http请求\n                     */\n                    pipeline.addLast(new HttpObjectAggregator(8192));\n                    /*\n                    说明\n                    1. 对应websocket ，它的数据是以 帧(frame) 形式传递\n                    2. 可以看到WebSocketFrame 下面有六个子类\n                    3. 浏览器请求时 ws://localhost:7000/hello 表示请求的uri\n                    4. WebSocketServerProtocolHandler 核心功能是将 http协议升级为 ws协议 , 保持长连接\n                    5. 是通过一个 状态码 101\n                     */\n                    pipeline.addLast(new WebSocketServerProtocolHandler(\"/hello2\"));\n\n                    //自定义的handler ，处理业务逻辑\n                    pipeline.addLast(new MyTextWebSocketFrameHandler());\n                }\n            });\n\n            //启动服务器\n            ChannelFuture channelFuture = serverBootstrap.bind(7000).sync();\n            channelFuture.channel().closeFuture().sync();\n\n        } finally {\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        }\n    }\n}\n\npackage com.zhao.netty.websocket;\n\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\nimport io.netty.handler.codec.http.websocketx.TextWebSocketFrame;\n\nimport java.time.LocalDateTime;\n\n//这里 TextWebSocketFrame 类型，表示一个文本帧(frame)\npublic class MyTextWebSocketFrameHandler extends SimpleChannelInboundHandler<TextWebSocketFrame> {\n\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception {\n\n        System.out.println(\"服务器收到消息 \" + msg.text());\n\n        //回复消息\n        ctx.channel().writeAndFlush(new TextWebSocketFrame(\"服务器时间\" + LocalDateTime.now() + \" \" + msg.text()));\n    }\n\n    //当web客户端连接后， 触发方法\n    @Override\n    public void handlerAdded(ChannelHandlerContext ctx) throws Exception {\n        //id 表示唯一的值，LongText 是唯一的 ShortText 不是唯一\n        System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asLongText());\n        System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asShortText());\n    }\n\n\n    @Override\n    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\n\n        System.out.println(\"handlerRemoved 被调用\" + ctx.channel().id().asLongText());\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        System.out.println(\"异常发生 \" + cause.getMessage());\n        ctx.close(); //关闭连接\n    }\n}\n```\n\n`hello.html`\n\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n    <head>\n        <meta charset=\"UTF-8\">\n        <title>Title</title>\n    </head>\n    <body>\n        <script>\n            var socket;\n            //判断当前浏览器是否支持websocket\n            if(window.WebSocket) {\n                //go on\n                socket = new WebSocket(\"ws://localhost:7000/hello2\");\n                //相当于channelReado, ev 收到服务器端回送的消息\n                socket.onmessage = function (ev) {\n                    var rt = document.getElementById(\"responseText\");\n                    rt.value = rt.value + \"\\n\" + ev.data;\n                }\n\n                //相当于连接开启(感知到连接开启)\n                socket.onopen = function (ev) {\n                    var rt = document.getElementById(\"responseText\");\n                    rt.value = \"连接开启了..\"\n                }\n\n                //相当于连接关闭(感知到连接关闭)\n                socket.onclose = function (ev) {\n\n                    var rt = document.getElementById(\"responseText\");\n                    rt.value = rt.value + \"\\n\" + \"连接关闭了..\"\n                }\n            } else {\n                alert(\"当前浏览器不支持websocket\")\n            }\n\n            //发送消息到服务器\n            function send(message) {\n                if(!window.socket) { //先判断socket是否创建好\n                    return;\n                }\n                if(socket.readyState == WebSocket.OPEN) {\n                    //通过socket 发送消息\n                    socket.send(message)\n                } else {\n                    alert(\"连接没有开启\");\n                }\n            }\n        </script>\n        <form onsubmit=\"return false\">\n            <textarea name=\"message\" style=\"height: 300px; width: 300px\"></textarea>\n            <input type=\"button\" value=\"发生消息\" onclick=\"send(this.form.message.value)\">\n            <textarea id=\"responseText\" style=\"height: 300px; width: 300px\"></textarea>\n            <input type=\"button\" value=\"清空内容\" onclick=\"document.getElementById('responseText').value=''\">\n        </form>\n    </body>\n</html>\n```\n\n## Google Protobuf\n\n### 编码和解码的基本介绍\n\n编写网络应用程序时，因为数据在网络中传输的都是二进制字节码数据，在发送数据时就需要编码，接收数据时就需要解码。\n\n`codec`（编解码器）的组成部分有两个：`decoder`（解码器）和 `encoder`（编码器）。`encoder` 负责把业务数据转换成字节码数据，`decoder` 负责把字节码数据转换成业务数据。\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter07_01.png)\n\n### Netty 本身的编码解码的机制和问题分析\n\n`Netty` 自身提供了一些 `codec`(编解码器)：\n\n- `Netty` 提供的编码器 `StringEncoder`，对字符串数据进行编码 `ObjectEncoder`，对Java对象进行编码...\n- `Netty` 提供的解码器 `StringDecoder`，对字符串数据进行解码 `ObjectDecoder`，对 `Java` 对象进行解码...\n- `Netty` 本身自带的 `ObjectDecoder` 和 `ObjectEncoder` 可以用来实现 `POJO` 对象或各种业务对象的编码和解码，底层使用的仍是Java序列化技术,而Java序列化技术本身效率就不高，存在如下问题\n  - 无法跨语言\n  - 序列化后的体积太大，是二进制编码的5倍多。\n  - 序列化性能太低\n\n引出新的解决方案：`Google` 的 `Protobuf`\n\n### Protobuf\n\n`Protobuf` 是 `Google` 发布的开源项目，全称 `Google Protocol Buffers`，是一种轻便高效的结构化数据存储格式，可以用于结构化数据串行化，或者说序列化。它很适合做数据存储或 `RPC` [远程过程调用 `remote procedure call` ]数据交换格式。目前很多公司使用 `http + json tcp + protobuf`\n\n> 参考文档：https://developers.google.com/protocol-buffers/docs/proto 语言指南\n\n`Protobuf` 是以 `message` 的方式来管理数据的。优点：\n\n- 支持跨平台、跨语言，即[客户端和服务器端可以是不同的语言编写的]（支持目前绝大多数语言，例如 `C++`、`C#`、`Java`、`python` 等）\n- 高性能，高可靠性\n- 使用 `Protobuf` 编译器能自动生成代码，`Protobuf` 是将类的定义使用 `.proto` 文件进行描述。说明，在 `idea` 中编写 `.proto` 文件时，会自动提示是否下载 `.ptoto` 编写插件.可以让语法高亮。\n- 然后通过 `protoc.exe` 编译器根据 `.proto` 自动生成 `.java` 文件\n\n`Protobuf` 使用示意图\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter07_02.png)\n\n### Protobuf 快速入门实例\n\n编写程序，使用 `Protobuf` 完成如下功能\n\n1. 客户端可以发送一个 `StudentPoJo` 对象到服务器(通过 `Protobuf` 编码)\n2. 服务端能接收 `StudentPoJo` 对象，并显示信息(通过 `Protobuf` 解码)\n\n`Student.proto`：\n\n```protobuf\nsyntax = \"proto3\"; //版本\noption java_outer_classname = \"StudentPOJO\"; // 生成的外部类名，同时也是文件名\n\n// protobuf 使用message 管理数据\nmessage Student { //会在 StudentPOJO 外部类生成一个内部类 Student， 他是真正发送的POJO对象\n    int32 id = 1; // Student 类中有 一个属性 名字为 id 类型为int32(protobuf类型) 1表示属性序号，不是值\n    string name = 2;\n}\n```\n\n编译：`protoc.exe --java_out=.Student.proto`。将生成的 `StudentPOJO` 放入到项目使用。\n\n### Protobuf 快速入门实例 2\n\n编写程序，使用 `Protobuf` 完成如下功能\n\n1. 客户端可以随机发送 `StudentPoJo` / `WorkerPoJo` 对象到服务器(通过 `Protobuf` 编码)\n2. 服务端能接收 `StudentPoJo` / `WorkerPoJo` 对象(需要判断是哪种类型)，并显示信息(通过 `Protobuf` 解码)\n\n`Student.proto：`\n\n```protobuf\nsyntax = \"proto3\";\noption optimize_for = SPEED; // 加快解析\noption java_package=\"com.zhao.netty.codec2\";   //指定生成到哪个包下\noption java_outer_classname=\"MyDataInfo\"; // 外部类名, 文件名\n\n//protobuf 可以使用message 管理其他的message\nmessage MyMessage {\n\n    //定义一个枚举类型\n    enum DataType {\n        StudentType = 0; //在proto3 要求enum的编号从0开始\n        WorkerType = 1;\n    }\n\n    //用data_type 来标识传的是哪一个枚举类型\n    DataType data_type = 1;\n\n    //表示每次枚举类型最多只能出现其中的一个, 节省空间\n    oneof dataBody {\n        Student student = 2;\n        Worker worker = 3;\n    }\n\n}\n\n\nmessage Student {\n    int32 id = 1;//Student类的属性\n    string name = 2; //\n}\nmessage Worker {\n    string name=1;\n    int32 age=2;\n}\n```\n\n> https://www.bilibili.com/video/BV1DJ411m7NR?p=77\n\n\n\n## Netty 编解码器和 Handler 调用机制\n\n### 基本说明\n\n`Netty` 的组件设计：`Netty` 的主要组件有 `Channel`、`EventLoop`、`ChannelFuture`、`ChannelHandler`、`ChannelPipe` 等\n\n`ChannelHandler` 充当了处理入站和出站数据的应用程序逻辑的容器。例如，实现 `ChannelInboundHandler` 接口（或 `ChannelInboundHandlerAdapter`），你就可以接收入站事件和数据，这些数据会被业务逻辑处理。当要给客户端发送响应时，也可以从 `ChannelInboundHandler` 冲刷数据。业务逻辑通常写在一个或者多个 `ChannelInboundHandler` 中。`ChannelOutboundHandler` 原理一样，只不过它是用来处理出站数据的\n\n`ChannelPipeline` 提供了 `ChannelHandler` 链的容器。以客户端应用程序为例，如果事件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过 `pipeline` 中的一系列 `ChannelOutboundHandler`，并被这些 `Handler` 处理，反之则称为入站的。\n\n`Pipeline`双向链表中维护了一些`ChannelHandlerContext`，每个`ChannelHandlerContext`维护了一个`Handler`。每个`ChannelHandlerContext`都维护了两个属性`inbound/outbound(boolean)`，其代表了当前`Handler`属于入站/出站类型。这样在`Pipeline`中不同类型的`Handler`就能区分开，从而互不干扰的工作：\n\n`Socket`收到消息后，入站事件在`Pipeline`中按照 `head -> tail` 的顺序依次通过入站类型的`Handler`（不通过出站类型的），全部入站类型的`Handler`执行完毕后再按照 `tail -> head` 的顺序依次通过出站类型的`Handler`，最后通过Socket发出出站消息。\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_01.png)\n\n### 编码解码器\n\n当 `Netty` 发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式（比如 `java` 对象）；如果是出站消息，它会被编码成字节。\n\n`Netty` 提供一系列实用的编解码器，他们都实现了 `ChannelInboundHadnler` 或者 `ChannelOutboundHandler` 接口。在这些类中，`channelRead` 方法已经被重写了。以入站为例，对于每个从入站 `Channel` 读取的消息，这个方法会被调用。随后，它将调用由解码器所提供的 `decode()` 方法进行解码，并将已经解码的字节转发给 `ChannelPipeline` 中的下一个 `ChannelInboundHandler`。\n\n### 解码器 - ByteToMessageDecoder\n\n关系继承图\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_02.png)\n\n由于不可能知道远程节点是否会一次性发送一个完整的信息，`tcp` 有可能出现粘包拆包的问题，这个类会对入站数据进行缓冲，直到它准备好被处理.\n\n一个关于 `ByteToMessageDecoder` 实例分析\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_03.png)\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_04.png)\n\n### Netty 的 handler 链的调用机制\n\n`Pipeline`双向链表中维护了一些`ChannelHandlerContext`，每个`ChannelHandlerContext`维护了一个`Handler`。每个`ChannelHandlerContext`都维护了两个属性`inbound/outbound(boolean)`，其代表了当前`Handler`属于入站/出站类型。这样在`Pipeline`中不同类型的`Handler`就能区分开，从而互不干扰的工作：\n\n`Socket`收到消息后，入站事件在`Pipeline`中按照 `head -> tail` 的顺序依次通过入站类型的`Handler`（不通过出站类型的），全部入站类型的`Handler`执行完毕后再按照 `tail -> head` 的顺序依次通过出站类型的`Handler`，最后通过Socket发出出站消息。\n\n- 不论解码器 `handler` 还是编码器 `handler` 即接收的消息类型必须与待处理的消息类型一致，否则该 `handler` 不会被执行\n- 在解码器进行数据解码时，需要判断缓存区（`ByteBuf`）的数据是否足够，否则接收到的结果会期望结果可能不一致\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_05.png)\n\n### 解码器 - ReplayingDecoder\n\n`public abstract class ReplayingDecoder<S> extends ByteToMessageDecoder`\n\n`ReplayingDecoder` 扩展了 `ByteToMessageDecoder` 类，使用这个类，我们不必调用 `readableBytes()` 方法。参数 `S` 指定了用户状态管理的类型，其中 `Void` 代表不需要状态管理\n\n应用实例：使用 `ReplayingDecoder` 编写解码器，对前面的案例进行简化\n\n```java\npackage com.zhao.netty.inboundhandlerandoutboundhandler;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.ReplayingDecoder;\n\nimport java.util.List;\n\npublic class MyByteToLongDecoder2 extends ReplayingDecoder<Void> {\n    \n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n        System.out.println(\"MyByteToLongDecoder2 被调用\");\n        //在 ReplayingDecoder 不需要判断数据是否足够读取，内部会进行处理判断\n        out.add(in.readLong());\n    }\n}\n```\n\n`ReplayingDecoder`使用方便，但它也有一些局限性：\n\n- 并不是所有的 `ByteBuf` 操作都被支持，如果调用了一个不被支持的方法，将会抛出一个 `UnsupportedOperationException`。\n- `ReplayingDecoder` 在某些情况下可能稍慢于 `ByteToMessageDecoder`，例如网络缓慢并且消息格式复杂时，消息会被拆成了多个碎片，速度变慢\n\n ### 其它编解码器\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter08_06.png)\n\n- `LineBasedFrameDecoder`：这个类在 `Netty` 内部也有使用，它使用行尾控制字符（\\n或者\\r\\n）作为分隔符来解析数据。\n- `DelimiterBasedFrameDecoder`：使用自定义的特殊字符作为消息的分隔符。\n- `HttpObjectDecoder`：一个 `HTTP` 数据的解码器\n- `LengthFieldBasedFrameDecoder`：通过指定长度来标识整包消息，这样就可以自动的处理黏包和半包消息。\n\n## TCP 粘包和拆包及解决方案\n\n### TCP 粘包和拆包基本介绍\n\n`TCP` 是面向连接的，面向流的，提供高可靠性服务。收发两端（客户端和服务器端）都要有一一成对的 `socket`，因此，发送端为了将多个发给接收端的包，更有效的发给对方，使用了优化方法（`Nagle` 算法），将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样做虽然提高了效率，但是接收端就难于分辨出完整的数据包了，因为面向流的通信是无消息保护边界的\n\n由于 `TCP` 无消息保护边界,需要在接收端处理消息边界问题，也就是我们所说的粘包、拆包问题\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter09_01.png)\n\n对图的说明: 假设客户端分别发送了两个数据包 `D1` 和 `D2` 给服务端，由于服务端一次读取到字节数是不确定的，故可能存在以下四种情况：\n\n1. 服务端分两次读取到了两个独立的数据包，分别是 `D1` 和 `D2`，没有粘包和拆包\n2. 服务端一次接受到了两个数据包，`D1` 和 `D2` 粘合在一起，称之为 `TCP` 粘包\n3. 服务端分两次读取到了数据包，第一次读取到了完整的 `D1` 包和 `D2` 包的部分内容，第二次读取到了 `D2` 包的剩余内容，这称之为 `TCP` 拆包\n4. 服务端分两次读取到了数据包，第一次读取到了 `D1` 包的部分内容 `D1_1`，第二次读取到了 `D1` 包的剩余部分内容 `D1_2` 和完整的 `D2` 包。\n\n### TCP 粘包和拆包现象实例\n\n在编写 `Netty` 程序时，如果没有做处理，就会发生粘包和拆包的问题\n\n`MyClientHandler.java`\n\n```java\npackage com.zhao.netty.tcp;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\n\nimport java.nio.charset.Charset;\n\npublic class MyClientHandler extends SimpleChannelInboundHandler<ByteBuf> {\n\n    private int count;\n\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n        //使用客户端发送10条数据 hello,server 编号\n        for (int i = 0; i < 10; ++i) {\n            ByteBuf buffer = Unpooled.copiedBuffer(\"hello,server \" + i, Charset.forName(\"utf-8\"));\n            ctx.writeAndFlush(buffer);\n        }\n    }\n\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception {\n        byte[] buffer = new byte[msg.readableBytes()];\n        msg.readBytes(buffer);\n\n        String message = new String(buffer, Charset.forName(\"utf-8\"));\n        System.out.println(\"客户端接收到消息=\" + message);\n        System.out.println(\"客户端接收消息数量=\" + (++this.count));\n\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        cause.printStackTrace();\n        ctx.close();\n    }\n}\n```\n\n`MyServerHandler.java`\n\n``` java\npackage com.zhao.netty.tcp;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.buffer.Unpooled;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\n\nimport java.nio.charset.Charset;\nimport java.util.UUID;\n\npublic class MyServerHandler extends SimpleChannelInboundHandler<ByteBuf> {\n    \n    private int count;\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        //cause.printStackTrace();\n        ctx.close();\n    }\n\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, ByteBuf msg) throws Exception {\n\n        byte[] buffer = new byte[msg.readableBytes()];\n        msg.readBytes(buffer);\n\n        //将buffer转成字符串\n        String message = new String(buffer, Charset.forName(\"utf-8\"));\n\n        System.out.println(\"服务器接收到数据 \" + message);\n        System.out.println(\"服务器接收到消息量=\" + (++this.count));\n\n        //服务器回送数据给客户端, 回送一个随机id ,\n        ByteBuf responseByteBuf = Unpooled.copiedBuffer(UUID.randomUUID().toString() + \" \", Charset.forName(\"utf-8\"));\n        ctx.writeAndFlush(responseByteBuf);\n\n    }\n}\n```\n\n### TCP 粘包和拆包解决方案\n\n1. 使用自定义协议+编解码器来解决\n2. 关键就是要解决服务器端每次读取数据长度的问题，这个问题解决，就不会出现服务器多读或少读数据的问题，从而避免的 `TCP` 粘包、拆包。\n\n实例\n\n1. 要求客户端发送 `5` 个 `Message` 对象，客户端每次发送一个 `Message` 对象\n2. 服务器端每次接收一个 `Message`，分 `5` 次进行解码，每读取到一个 `Message`，会回复一个 `Message` 对象给客户端。\n\n![img](/images/%E3%80%90Netty%E3%80%91Netty/chapter09_02.png)\n\n```java\npackage com.zhao.netty.protocoltcp;\n\n//协议包\npublic class MessageProtocol {\n\n    private int len; //关键\n\n    private byte[] content;\n\n    public int getLen() {\n        return len;\n    }\n\n    public void setLen(int len) {\n        this.len = len;\n    }\n\n    public byte[] getContent() {\n        return content;\n    }\n\n    public void setContent(byte[] content) {\n        this.content = content;\n    }\n}\n\npackage com.zhao.netty.protocoltcp;\n\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\n\nimport java.nio.charset.Charset;\n\npublic class MyClientHandler extends SimpleChannelInboundHandler<MessageProtocol> {\n\n    private int count;\n\n    @Override\n    public void channelActive(ChannelHandlerContext ctx) throws Exception {\n        //使用客户端发送10条数据 \"今天天气冷，吃火锅\" 编号\n        for (int i = 0; i < 5; i++) {\n            String mes = \"今天天气冷，吃火锅\";\n            byte[] content = mes.getBytes(Charset.forName(\"utf-8\"));\n            int length = mes.getBytes(Charset.forName(\"utf-8\")).length;\n\n            //创建协议包对象\n            MessageProtocol messageProtocol = new MessageProtocol();\n            messageProtocol.setLen(length);\n            messageProtocol.setContent(content);\n            ctx.writeAndFlush(messageProtocol);\n        }\n    }\n\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, MessageProtocol msg) throws Exception {\n\n        int len = msg.getLen();\n        byte[] content = msg.getContent();\n\n        System.out.println(\"客户端接收到消息如下\");\n        System.out.println(\"长度=\" + len);\n        System.out.println(\"内容=\" + new String(content, Charset.forName(\"utf-8\")));\n\n        System.out.println(\"客户端接收消息数量=\" + (++this.count));\n    }\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        System.out.println(\"异常消息=\" + cause.getMessage());\n        ctx.close();\n    }\n}\n\npackage com.zhao.netty.protocoltcp;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.MessageToByteEncoder;\n\npublic class MyMessageEncoder extends MessageToByteEncoder<MessageProtocol> {\n\n    @Override\n    protected void encode(ChannelHandlerContext ctx, MessageProtocol msg, ByteBuf out) throws Exception {\n        System.out.println(\"MyMessageEncoder encode 方法被调用\");\n        out.writeInt(msg.getLen());\n        out.writeBytes(msg.getContent());\n    }\n}\n\npackage com.zhao.netty.protocoltcp;\n\nimport io.netty.buffer.ByteBuf;\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.handler.codec.ReplayingDecoder;\n\nimport java.util.List;\n\npublic class MyMessageDecoder extends ReplayingDecoder<Void> {\n\n    @Override\n    protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) throws Exception {\n        System.out.println(\"MyMessageDecoder decode 被调用\");\n        //需要将得到二进制字节码-> MessageProtocol 数据包(对象)\n        int length = in.readInt();\n\n        byte[] content = new byte[length];\n        in.readBytes(content);\n\n        //封装成 MessageProtocol 对象，放入 out， 传递下一个handler业务处理\n        MessageProtocol messageProtocol = new MessageProtocol();\n        messageProtocol.setLen(length);\n        messageProtocol.setContent(content);\n        out.add(messageProtocol);\n    }\n}\n\npackage com.zhao.netty.protocoltcp;\n\nimport io.netty.channel.ChannelHandlerContext;\nimport io.netty.channel.SimpleChannelInboundHandler;\n\nimport java.nio.charset.Charset;\nimport java.util.UUID;\n\n\n//处理业务的handler\npublic class MyServerHandler extends SimpleChannelInboundHandler<MessageProtocol> {\n\n    private int count;\n\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n        //cause.printStackTrace();\n        ctx.close();\n    }\n\n    @Override\n    protected void channelRead0(ChannelHandlerContext ctx, MessageProtocol msg) throws Exception {\n        //接收到数据，并处理\n        int len = msg.getLen();\n        byte[] content = msg.getContent();\n\n        System.out.println();\n        System.out.println();\n        System.out.println();\n        System.out.println(\"服务器接收到信息如下\");\n        System.out.println(\"长度=\" + len);\n        System.out.println(\"内容=\" + new String(content, Charset.forName(\"utf-8\")));\n\n        System.out.println(\"服务器接收到消息包数量=\" + (++this.count));\n\n        //回复消息\n        String responseContent = UUID.randomUUID().toString();\n        int responseLen = responseContent.getBytes(\"utf-8\").length;\n        byte[] responseContent2 = responseContent.getBytes(\"utf-8\");\n        //构建一个协议包\n        MessageProtocol messageProtocol = new MessageProtocol();\n        messageProtocol.setLen(responseLen);\n        messageProtocol.setContent(responseContent2);\n\n        ctx.writeAndFlush(messageProtocol);\n    }\n}\n```\n\n\n\n\n\n\n\nzhao \n\n","tags":["Netty"],"categories":["Netty"]},{"title":"【Java】NIO","url":"/2021/08/13/【Java】NIO/","content":"\n## I/O 模型\n\n### I/O 模型简介\n\n`I/O` 模型简单的理解：就是用什么样的通道进行数据的发送和接收，很大程度上决定了程序通信的性能。\n\n共有三种`I/O` 模型：\n\n> https://blog.csdn.net/tomcyndi/article/details/79087578\n\n**1. 同步阻塞**：在调用read方法时，stream里没有数据可读，线程停止向下执行，直至stream有数据。\n\n> 阻塞：体现在这个线程不能干别的了，只能在这里等着\n>\n> 同步：是体现在消息通知机制上的，即stream有没有数据是需要我自己来判断的。\n\n**2. 同步非阻塞**：调用read方法后，如果stream没有数据，方法就返回，然后这个线程就就干别的事（例如NIO中`Selector`所在的线程不会一直阻塞在某一个IO，而是会循环判断当前有没有能处理的IO，没有就做别的事，过一段时间再判断一下有没有要处理的IO，此时仍然是同步的，因为线程一直在循环）。\n\n> 非阻塞：体现在这个线程可以去干别的，不需要一直在这等着\n>\n> 同步：体现在消息通知机制，这个线程仍然要定时的读取stream，判断数据有没有准备好，client采用循环的方式去读取，可以看出CPU大部分被浪费了\n\n**3. 异步非阻塞**：服务端调用read方法，若stream中无数据则返回，程序继续向下执行。当stream中有数据时，操作系统会负责把数据拷贝到用户空间，然后通知这个线程，这里的消息通知机制就是异步。而不是像NIO那样，自己起一个线程去监控stream里面有没有数据。\n\n### BIO、NIO、AIO \n\n`Java` 共支持 `3` 种网络编程模型 `I/O` 模式：`BIO`、`NIO`、`AIO`。\n\n1. `Java BIO`：同步并阻塞（传统阻塞型），服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销。\n\n![image-20210813230944094](/images/%E3%80%90Java%E3%80%91NIO/image-20210813230944094.png)\n\n<!-- More -->\n\n> https://dongzl.github.io/netty-handbook/#/_content/chapter02\n\n2. `Java NIO`：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮询到连接有 `I/O` 请求就进行处理。\n\n![img](/images/%E3%80%90Java%E3%80%91NIO/chapter02_02.png)\n\n3. `Java AIO(NIO.2)`：异步非阻塞，`AIO` 引入异步通道的概念，采用了 `Proactor` 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用。\n\n### BIO、NIO、AIO 使用场景\n\n1. `BIO` 方式适用于**连接数目比较小且固定**的架构，这种方式对服务器资源要求比较高，并发局限于应用中，`JDK1.4` 以前的唯一选择，但程序简单易理解。\n2. `NIO` 方式适用于**连接数目多且连接比较短**（轻操作）的架构，比如聊天服务器，弹幕系统，服务器间通讯等。编程比较复杂，`JDK1.4` 开始支持。\n3. `AIO` 方式使用于**连接数目多且连接比较长**（重操作）的架构，比如相册服务器，充分调用 `OS` 参与并发操作，编程比较复杂，`JDK7` 开始支持。\n\n## BIO\n\n- `Java BIO` 就是传统的 `Java I/O` 编程，其相关的类和接口在 `java.io`。\n- `BIO(BlockingI/O)`：同步阻塞，服务器实现模式为一个连接一个线程，即客户端有连接请求时服务器端就需要启动一个线程进行处理，如果这个连接不做任何事情会造成不必要的线程开销，可以通过线程池机制改善（实现多个客户连接服务器）。\n- `BIO` 方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，`JDK1.4` 以前的唯一选择，程序简单易理解。\n\n### BIO 工作机制\n\n![img](/images/%E3%80%90Java%E3%80%91NIO/chapter02_03.png)\n\n对 `BIO` 编程流程的梳理\n\n1. 服务器端启动一个 `ServerSocket`。\n2. 客户端启动 `Socket` 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。\n3. 客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。\n4. 如果有响应，客户端线程会等待请求结束后，在继续执行。\n\n### BIO 应用实例\n\n实例说明：\n\n1. 使用 `BIO` 模型编写一个服务器端，监听 `6666` 端口，当有客户端连接时，就启动一个线程与之通讯。\n2. 要求使用线程池机制改善，可以连接多个客户端。\n3. 服务器端可以接收客户端发送的数据（`telnet` 方式即可）。\n4. 代码演示：\n\n```java\npackage com.zhao.bio;\n\nimport java.io.InputStream;\nimport java.net.ServerSocket;\nimport java.net.Socket;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class BIOServer {\n\n    public static void main(String[] args) throws Exception {\n        //线程池机制\n        //思路\n        //1. 创建一个线程池\n        //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法)\n        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();\n        //创建ServerSocket\n        ServerSocket serverSocket = new ServerSocket(6666);\n        System.out.println(\"服务器启动了\");\n        while (true) {\n            System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n            //监听，等待客户端连接\n            System.out.println(\"等待连接....\");\n            final Socket socket = serverSocket.accept();\n            System.out.println(\"连接到一个客户端\");\n            //就创建一个线程，与之通讯(单独写一个方法)\n            newCachedThreadPool.execute(new Runnable() {\n                public void run() {//我们重写\n                    //可以和客户端通讯\n                    handler(socket);\n                }\n            });\n        }\n    }\n\n    //编写一个handler方法，和客户端通讯\n    public static void handler(Socket socket) {\n        try {\n            System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n            byte[] bytes = new byte[1024];\n            //通过socket获取输入流\n            InputStream inputStream = socket.getInputStream();\n            //循环的读取客户端发送的数据\n            while (true) {\n                System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n                System.out.println(\"read....\");\n                int read = inputStream.read(bytes);\n                if (read != -1) {\n                    System.out.println(new String(bytes, 0, read));//输出客户端发送的数据\n                } else {\n                    break;\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            System.out.println(\"关闭和client的连接\");\n            try {\n                socket.close();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n### BIO 问题分析\n\n1. 每个请求都需要创建独立的线程，与对应的客户端进行数据 `Read`，业务处理，数据 `Write`。\n2. 当并发数较大时，需要创建大量线程来处理连接，系统资源占用较大。\n3. 连接建立后，如果当前线程暂时没有数据可读，则线程就阻塞在 `Read` 操作上，造成线程资源浪费。\n\n\n\n## NIO\n\n`Java NIO` 全称 **`Java non-blocking IO`** ，是指 `JDK` 提供的新 `API`。从 `JDK1.4` 开始，`Java` 提供了一系列改进的输入/输出的新特性，被统称为 `NIO`（即 `NewIO`），是同步非阻塞的。\n\n**阻塞IO和非阻塞IO的区别在于，发起IO请求是否会被阻塞，如果阻塞直到IO请求完成那么就是传统的阻塞IO，如果不阻塞，那么就是非阻塞IO。**\n\n同步非阻塞：调用read方法后，如果stream没有数据，方法就返回，然后这个线程就就干别的事。例如NIO中`Selector`所在的线程不会一直阻塞在某一个IO，而是会循环判断当前有没有能处理的IO，没有就做别的事，过一段时间再判断一下有没有要处理的IO，此时仍然是同步的，因为线程一直在循环。\n\n- 非阻塞：体现在这个线程可以去干别的，不需要一直在这等着\n- 同步：体现在消息通知机制，这个线程仍然要定时的读取stream，判断数据有没有准备好，client采用循环的方式去读取，可以看出CPU大部分被浪费了\n\n`NIO` 相关类都被放在 **`java.nio`** 包及子包下，并且对原 `java.io` 包中的很多类进行改写。`NIO` 有三大核心部分:\n\n- **Channel（通道）**\n- **Buffer（缓冲区）**\n- **Selector（选择器）** \n\n`NIO` 是**面向缓冲区，或者面向块编程**的。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩性网络。\n\n`Java NIO` 的非阻塞模式，使一个线程从某通道发送请求或者读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。\n\n通俗理解：`NIO` 是可以做到用一个线程来处理多个操作的。假设有 `10000` 个请求过来,根据实际情况，可以分配 `50` 或者 `100` 个线程来处理。不像之前的阻塞 `IO` 那样，非得分配 `10000` 个。\n\n`HTTP 2.0` 使用了**多路复用技术**，做到同一个连接并发处理多个请求，而且并发请求的数量比 `HTTP 1.1` 大了好几个数量级。\n\nNIO符合**单 Reactor 单线程**模型：\n\n![img](/images/%E3%80%90Java%E3%80%91NIO/chapter05_04.png)\n\n### NIO 三大核心原理示意图\n\n `NIO` 的 `Selector`、`Channel` 和 `Buffer` 的关系图：\n\n![img](/images/%E3%80%90Java%E3%80%91NIO/chapter03_01.png)\n\n- 每个 `Channel` 都会对应一个 `Buffer`。\n- `Selector` 对应一个线程，一个线程对应多个 `Channel`（连接）。\n- 该图反应了有三个 `Channel` 注册到该 `Selector` //程序\n- 程序切换到哪个 `Channel` 是由事件决定的，`Event` 就是一个重要的概念。\n- `Selector` 会根据不同的事件，在各个通道上切换。\n- `Buffer` 就是一个内存块，底层是有一个数组。\n- 数据的读取写入是通过 `Buffer`，这个和 `BIO`，`BIO` 中要么是输入流，或者是输出流，不能双向，但是 `NIO` 的 `Buffer` 是可以读也可以写，需要 `flip` 方法切换 `Channel` 是双向的，可以返回底层操作系统的情况，比如 `Linux`，底层的操作系统通道就是双向的。\n\n### NIO 和 BIO 的比较\n\n- `BIO` 以流的方式处理数据，而 `NIO` 以块的方式处理数据，块 `I/O` 的效率比流 `I/O` 高很多。\n- `BIO` 是阻塞的，`NIO` 则是非阻塞的。\n- `BIO` 基于字节流和字符流进行操作，而 `NIO` 基于 `Channel`（通道）和 `Buffer`（缓冲区）进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入到通道中。`Selector`（选择器）用于监听多个通道的事件（比如：连接请求，数据到达等），因此使用单个线程就可以监听多个客户端通道。\n\n## 缓冲区（Buffer）\n\n### 简介\n\n缓冲区（`Buffer`）：缓冲区本质上是一个**可以读写数据的内存块**，可以理解成是一个**容器对象（含数组）**，该对象提供了一组方法，可以更轻松地使用内存块，缓冲区对象内置了一些机制，能够跟踪和记录缓冲区的状态变化情况。`Channel` 提供从文件、网络读取数据的渠道，但是读取或写入的数据都必须经由 `Buffer`，如图：\n\n![img](/images/%E3%80%90Java%E3%80%91NIO/chapter03_02.png)\n\n`Channel`通过`Buffer`进行读写：\n\n- 从Channel中读取数据时，使用`Channel.read(Buffer)`将`Channel`中的数据读取到`Buffer`中，用户再从`Buffer`中读取传来的数据。\n- 向`Channel`中写出数据时，用户首先将数据写出到`Buffer`中，再使用`Channel.write(Buffer)`将`Buffer`中的数据写到`Channel`中。\n\n### Buffer类及其子类\n\n在 `NIO` 中，`Buffer` 是一个顶层父类，它是一个抽象类，类的层级关系图：\n\n![image-20210813231415284](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231415284.png)\n\n`Buffer` 类定义了所有的缓冲区都具有的四个属性来提供关于其所包含的数据元素的信息：\n\n![image-20210813231435261](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231435261.png)\n\n`Buffer` 类相关方法一览\n\n![image-20210813231523283](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231523283.png)\n\n### ByteBuffer\n\n从前面可以看出对于 `Java` 中的基本数据类型（`boolean` 除外），都有一个 `Buffer` 类型与之相对应，最常用的自然是 `ByteBuffer` 类（二进制数据），该类的主要方法如下：\n\n![image-20210813231558337](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231558337.png)\n\n案例说明 `NIO` 的 `Buffer`\n\n```java\npackage com.zhao.nio;\n\nimport java.nio.IntBuffer;\n\npublic class BasicBuffer {\n\n    public static void main(String[] args) {\n\n        //举例说明 Buffer 的使用(简单说明)\n        //创建一个 Buffer，大小为 5，即可以存放 5 个 int\n        IntBuffer intBuffer = IntBuffer.allocate(5);\n\n        //向buffer存放数据\n        //intBuffer.put(10);\n        //intBuffer.put(11);\n        //intBuffer.put(12);\n        //intBuffer.put(13);\n        //intBuffer.put(14);\n        for (int i = 0; i < intBuffer.capacity(); i++) {\n            intBuffer.put(i * 2);\n        }\n        //如何从 buffer 读取数据\n        //将 buffer 转换，读写切换(!!!)\n        intBuffer.flip();\n        while (intBuffer.hasRemaining()) {\n            System.out.println(intBuffer.get());\n        }\n    }\n}\n```\n\n## 通道（Channel）\n\n### 简介\n\n\n   NIO的通道类似于流，但有些区别如下：\n\n   - 通道可以同时进行读写，而流只能读或者只能写\n   - 通道可以实现异步读写数据\n   - 通道可以从缓冲读数据，也可以写数据到缓冲s\n\n`BIO` 中的 `Stream` 是单向的，例如 `FileInputStream` 对象只能进行读取数据的操作，而 `NIO` 中的通道（`Channel`）是双向的，可以读操作，也可以写操作。\n\n`Channel` 在 `NIO` 中是一个接口 `public interface Channel extends Closeable{}`。常用的 `Channel` 子类有：**`FileChannel`、`DatagramChannel`、`ServerSocketChannel` 和 `SocketChannel`**。【`ServerSocketChanne` 类似 `ServerSocket`、`SocketChannel` 类似 `Socket`】\n\n`FileChannel` 用于文件的数据读写，`DatagramChannel` 用于 `UDP` 的数据读写，`ServerSocketChannel` 和 `SocketChannel` 用于 `TCP` 的数据读写。\n\n![image-20210813231614234](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231614234.png)\n\n### FileChannel 类\n\n`FileChannel` 主要用来对本地文件进行 `IO` 操作，常见的方法有：\n\n- `public int read(ByteBuffer dst)`，从通道读取数据并放到缓冲区中\n- `public int write(ByteBuffer src)`，把缓冲区的数据写到通道中\n- `public long transferFrom(ReadableByteChannel src, long position, long count)`，从目标通道中复制数据到当前通道\n- `public long transferTo(long position, long count, WritableByteChannel target)`，把数据从当前通道复制给目标通道\n\n### 应用实例1 - 本地文件写数据\n\n实例要求：\n\n- 使用 `ByteBuffer`（缓冲）和 `FileChannel`（通道），将 \"hello,尚硅谷\" 写入到 `file01.txt` 中\n- 文件不存在就创建\n\n```java\npackage com.zhao.nio;\n\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel01 {\n\n    public static void main(String[] args) throws Exception {\n        String str = \"hello,尚硅谷\";\n        //创建一个输出流 -> channel\n        FileOutputStream fileOutputStream = new FileOutputStream(\"d:\\\\file01.txt\");\n\n        //通过 fileOutputStream 获取对应的 FileChannel\n        //这个 fileChannel 真实类型是 FileChannelImpl\n        FileChannel fileChannel = fileOutputStream.getChannel();\n\n        //创建一个缓冲区 ByteBuffer\n        ByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\n        //将 str 放入 byteBuffer\n        byteBuffer.put(str.getBytes());\n\n        //对 byteBuffer 进行 flip\n        byteBuffer.flip();\n\n        //将 byteBuffer 数据写入到 fileChannel\n        fileChannel.write(byteBuffer);\n        fileOutputStream.close();\n    }\n}\n```\n\n### 应用实例2 - 本地文件读数据\n\n实例要求：\n\n- 使用 `ByteBuffer`（缓冲）和 `FileChannel`（通道），将 `file01.txt` 中的数据读入到程序，并显示在控制台屏幕\n- 假定文件已经存在\n\n```java\npackage com.zhao.nio;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel02 {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建文件的输入流\n        File file = new File(\"d:\\\\file01.txt\");\n        FileInputStream fileInputStream = new FileInputStream(file);\n        \n        //通过 fileInputStream 获取对应的 FileChannel -> 实际类型 FileChannelImpl\n        FileChannel fileChannel = fileInputStream.getChannel();\n        \n        //创建缓冲区\n        ByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length());\n        \n        //将通道的数据读入到 Buffer\n        fileChannel.read(byteBuffer);\n        \n        //将 byteBuffer 的字节数据转成 String\n        System.out.println(new String(byteBuffer.array()));\n        fileInputStream.close();\n    }\n}\n```\n\n### 应用实例3 - 使用一个 Buffer 完成文件读取、写入\n\n实例要求：\n\n- 使用 `FileChannel`（通道）和方法 `read、write`，完成文件的拷贝\n- 拷贝一个文本文件 `1.txt`，放在项目下即可\n\n![image-20210813231631581](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231631581.png)\n\n```java\npackage com.zhao.nio;\n\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel03 {\n\n    public static void main(String[] args) throws Exception {\n\n        FileInputStream fileInputStream = new FileInputStream(\"1.txt\");\n        FileChannel fileChannel01 = fileInputStream.getChannel();\n        FileOutputStream fileOutputStream = new FileOutputStream(\"2.txt\");\n        FileChannel fileChannel02 = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        \n        while (true) { //循环读取\n\n            //这里有一个重要的操作，一定不要忘了\n            /*\n            public final Buffer clear() {\n                position = 0;\n                limit = capacity;\n                mark = -1;\n                return this;\n            }\n            */\n            byteBuffer.clear(); //清空 buffer\n            int read = fileChannel01.read(byteBuffer);\n            System.out.println(\"read = \" + read);\n            if (read == -1) { //表示读完\n                break;\n            }\n\n            //将 buffer 中的数据写入到 fileChannel02--2.txt\n            byteBuffer.flip();\n            fileChannel02.write(byteBuffer);\n        }\n\n        //关闭相关的流\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n### 应用实例4 - 拷贝文件 transferFrom 方法\n\n实例要求：\n\n- 使用 `FileChannel`（通道）和方法 `transferFrom`，完成文件的拷贝\n- 拷贝一张图片\n\n```java\npackage com.zhao.nio;\n\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel04 {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建相关流\n        FileInputStream fileInputStream = new FileInputStream(\"d:\\\\a.jpg\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"d:\\\\a2.jpg\");\n        \n        //获取各个流对应的 FileChannel\n        FileChannel sourceCh = fileInputStream.getChannel();\n        FileChannel destCh = fileOutputStream.getChannel();\n\n        //使用 transferForm 完成拷贝\n        destCh.transferFrom(sourceCh, 0, sourceCh.size());\n\n        //关闭相关通道和流\n        sourceCh.close();\n        destCh.close();\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n### 关于 Buffer 和 Channel 的注意事项和细节\n\n`ByteBuffer` 支持类型化的 `put` 和 `get`，`put` 放入的是什么数据类型，`get` 就应该使用相应的数据类型来取出，否则可能有 `BufferUnderflowException` 异常。\n\n```java\npackage com.zhao.nio;\n\nimport java.nio.ByteBuffer;\n\npublic class NIOByteBufferPutGet {\n\n    public static void main(String[] args) {\n        \n        //创建一个 Buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        //类型化方式放入数据\n        buffer.putInt(100);\n        buffer.putLong(9);\n        buffer.putChar('尚');\n        buffer.putShort((short) 4);\n\n        //取出\n        buffer.flip();\n        \n        System.out.println();\n        \n        System.out.println(buffer.getInt());\n        System.out.println(buffer.getLong());\n        System.out.println(buffer.getChar());\n        System.out.println(buffer.getShort());\n    }\n}\n```\n\n可以将一个普通 `Buffer` 转成只读 `Buffer`\n\n```java\npackage com.zhao.nio;\n\nimport java.nio.ByteBuffer;\n\npublic class ReadOnlyBuffer {\n\n    public static void main(String[] args) {\n\n        //创建一个 buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        for (int i = 0; i < 64; i++) {\n            buffer.put((byte) i);\n        }\n\n        //读取\n        buffer.flip();\n\n        //得到一个只读的 Buffer\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer();\n        System.out.println(readOnlyBuffer.getClass());\n\n        //读取\n        while (readOnlyBuffer.hasRemaining()) {\n            System.out.println(readOnlyBuffer.get());\n        }\n\n        readOnlyBuffer.put((byte) 100); //ReadOnlyBufferException\n    }\n}\n```\n\n`NIO` 还提供了 `MappedByteBuffer`，可以让文件直接在内存（堆外的内存）中进行修改，而如何同步到文件由 `NIO` 来完成。\n\n```java\npackage com.zhao.nio;\n\nimport java.io.RandomAccessFile;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\n\n/**\n * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次\n */\npublic class MappedByteBufferTest {\n\n    public static void main(String[] args) throws Exception {\n\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"1.txt\", \"rw\");\n        //获取对应的通道\n        FileChannel channel = randomAccessFile.getChannel();\n\n        /**\n         * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式\n         * 参数 2：0：可以直接修改的起始位置\n         * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存\n         * 可以直接修改的范围就是 0-5\n         * 实际类型 DirectByteBuffer\n         */\n        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n\n        mappedByteBuffer.put(0, (byte) 'H');\n        mappedByteBuffer.put(3, (byte) '9');\n        mappedByteBuffer.put(5, (byte) 'Y');//IndexOutOfBoundsException\n\n        randomAccessFile.close();\n        System.out.println(\"修改成功~~\");\n    }\n}\n```\n\n前面的读写操作，都是通过一个 `Buffer` 完成的，`NIO` 还支持通过多个 `Buffer`（即 `Buffer`数组）完成读写操作，即 `Scattering` 和 `Gathering`\n\n```java\npackage com.zhao.nio;\n\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Arrays;\n\n/**\n * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散]\n * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读\n */\npublic class ScatteringAndGatheringTest {\n\n    public static void main(String[] args) throws Exception {\n        \n        //使用 ServerSocketChannel 和 SocketChannel 网络\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);\n\n        //绑定端口到 socket，并启动\n        serverSocketChannel.socket().bind(inetSocketAddress);\n\n        //创建 buffer 数组\n        ByteBuffer[] byteBuffers = new ByteBuffer[2];\n        byteBuffers[0] = ByteBuffer.allocate(5);\n        byteBuffers[1] = ByteBuffer.allocate(3);\n\n        //等客户端连接 (telnet)\n        SocketChannel socketChannel = serverSocketChannel.accept();\n\n        int messageLength = 8; //假定从客户端接收 8 个字节\n\n        //循环的读取\n        while (true) {\n            int byteRead = 0;\n\n            while (byteRead < messageLength) {\n                long l = socketChannel.read(byteBuffers);\n                byteRead += l; //累计读取的字节数\n                System.out.println(\"byteRead = \" + byteRead);\n                //使用流打印,看看当前的这个 buffer 的 position 和 limit\n                Arrays.asList(byteBuffers).stream().map(buffer -> \"position = \" + buffer.position() + \", limit = \" + buffer.limit()).forEach(System.out::println);\n            }\n\n            //将所有的 buffer 进行 flip\n            Arrays.asList(byteBuffers).forEach(buffer -> buffer.flip());\n            //将数据读出显示到客户端\n            long byteWirte = 0;\n            while (byteWirte < messageLength) {\n                long l = socketChannel.write(byteBuffers);//\n                byteWirte += l;\n            }\n            \n            //将所有的buffer进行clear\n            Arrays.asList(byteBuffers).forEach(buffer -> {\n                buffer.clear();\n            });\n            \n            System.out.println(\"byteRead = \" + byteRead + \", byteWrite = \" + byteWirte + \", messagelength = \" + messageLength);\n        }\n    }\n}\n```\n\n## Selector（选择器）\n\n### 简介\n\n`Java` 的 `NIO`，用非阻塞的 `IO` 方式。可以用一个线程，处理多个的客户端连接，就会使用到 `Selector`（选择器）。\n\n`Selector` 能够检测多个注册的通道上是否有事件发生（注意：多个 `Channel` 以事件的方式可以注册到同一个 `Selector`），如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理多个通道，也就是管理多个连接和请求。\n\n只有在连接/通道真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程。避免了多线程之间的上下文切换导致的开销。\n\n### Selector示意图和特点说明\n\n![image-20210813231658958](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231658958.png)\n\n说明如下：\n\n- `Netty` 的 `IO` 线程 `NioEventLoop` 聚合了 `Selector`（选择器，也叫多路复用器），可以同时并发处理成百上千个客户端连接。\n- 当线程从某客户端 `Socket` 通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。\n- 线程通常将非阻塞 `IO` 的空闲时间用于在其他通道上执行 `IO` 操作，所以单独的线程可以管理多个输入和输出通道。\n- 由于读写操作都是非阻塞的，这就可以充分提升 `IO` 线程的运行效率，避免由于频繁 `I/O` 阻塞导致的线程挂起。\n- 一个 `I/O` 线程可以并发处理 `N` 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 `I/O` 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。\n\n### Selector类相关方法\n\n![image-20210813231714990](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231714990.png)\n\n注意事项：\n\n`NIO` 中的 `ServerSocketChannel` 功能类似 `ServerSocket`、`SocketChannel` 功能类似 `Socket`。\n\nSelector相关方法说明\n\n- `selector.select();` ：阻塞\n- `selector.select(1000);` ：阻塞 1000 毫秒，在 1000 毫秒后返回\n- `selector.wakeup();` ：唤醒 selector\n- `selector.selectNow();` ：不阻塞，立马返还\n\n### NIO 非阻塞网络编程原理分析图\n\n`NIO` 非阻塞网络编程相关的（`Selector`、`SelectionKey`、`ServerScoketChannel` 和 `SocketChannel`）关系梳理图\n\n![image-20210813231729938](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231729938.png)\n\n对上图的说明：\n\n1. 当客户端连接时，会通过 `ServerSocketChannel` 得到 `SocketChannel`。\n2. `Selector` 进行监听 `select` 方法，返回有事件发生的通道的个数。\n3. 将 `socketChannel` 注册到 `Selector` 上，`register(Selector sel, int ops)`，一个 `Selector` 上可以注册多个 `SocketChannel`。\n4. 注册后返回一个 `SelectionKey`，会和该 `Selector` 关联（集合）。\n5. 进一步得到各个 `SelectionKey`（有事件发生）。\n6. 在通过 `SelectionKey` 反向获取 `SocketChannel`，方法 `channel()`。\n7. 可以通过得到的 `channel`，完成业务处理。\n\n### SelectionKey\n\n\n   `SelectionKey`表示`Selector`和网络通道的注册关系，共四种：\n\n   - `int OP_ACCEPT`：有新的网络连接可以 `accept`，值为 `16`\n   - `int OP_CONNECT`：代表连接已经建立，值为 `8`\n   - `int OP_READ`：代表读操作，值为 `1`\n   - `int OP_WRITE`：代表写操作，值为 `4`\n\n源码中：\n\n```java\npublic static final int OP_READ = 1 << 0;\npublic static final int OP_WRITE = 1 << 2;\npublic static final int OP_CONNECT = 1 << 3;\npublic static final int OP_ACCEPT = 1 << 4;\n```\n\n1. `SelectionKey` 相关方法\n\n![image-20210813231747671](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231747671.png)\n\n### ServerSocketChannel\n\n`ServerSocketChannel` 在服务器端监听新的客户端 `Socket` 连接。相关方法如下：\n\n![image-20210813231800081](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231800081.png)\n\n### SocketChannel\n\n`SocketChannel`，网络 `IO` 通道，具体负责进行读写操作。`NIO` 把缓冲区的数据写入通道，或者把通道里的数据读到缓冲区。相关方法如下：\n\n![image-20210813231833709](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231833709.png)\n\n### NIO 网络编程应用实例 - 群聊系统\n\n实例要求：\n\n1. 编写一个 `NIO` 群聊系统，实现服务器端和客户端之间的数据简单通讯（非阻塞）\n2. 实现多人群聊\n3. 服务器端：可以监测用户上线，离线，并实现消息转发功能\n4. 客户端：通过 `Channel` 可以无阻塞发送消息给其它所有用户，同时可以接受其它用户发送的消息（有服务器转发得到）\n5. 目的：进一步理解 `NIO` 非阻塞网络编程机制\n\n示意图：\n\n![image-20210813231853991](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231853991.png)\n\n代码：\n\n```java\n// 服务端：\n\npackage com.zhao.nio.groupchat;\n\nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.Channel;\nimport java.nio.channels.SelectionKey;\nimport java.nio.channels.Selector;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Iterator;\n\npublic class GroupChatServer {\n\n    //定义属性\n    private Selector selector;\n    private ServerSocketChannel listenChannel;\n\n    private static final int PORT = 6667;\n\n    //构造器\n    //初始化工作\n    public GroupChatServer() {\n        try {\n            //得到选择器\n            selector = Selector.open();\n            //ServerSocketChannel\n            listenChannel = ServerSocketChannel.open();\n            //绑定端口\n            listenChannel.socket().bind(new InetSocketAddress(PORT));\n            //设置非阻塞模式\n            listenChannel.configureBlocking(false);\n            //将该 listenChannel 注册到 selector\n            listenChannel.register(selector, SelectionKey.OP_ACCEPT);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    public void listen() {\n        try {\n            //循环处理\n            while (true) {\n                int count = selector.select();\n                if (count > 0) { //有事件处理\n                    // 遍历得到 selectionKey 集合\n                    Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();\n                    while (iterator.hasNext()) {\n                        //取出 selectionkey\n                        SelectionKey key = iterator.next();\n                        //监听到 accept\n                        if (key.isAcceptable()) {\n                            SocketChannel sc = listenChannel.accept();\n                            sc.configureBlocking(false);\n                            //将该 sc 注册到 seletor\n                            sc.register(selector, SelectionKey.OP_READ);\n                            //提示\n                            System.out.println(sc.getRemoteAddress() + \" 上线 \");\n                        }\n                        if (key.isReadable()) {//通道发送read事件，即通道是可读的状态\n                            // 处理读(专门写方法..)\n                            readData(key);\n                        }\n                        //当前的 key 删除，防止重复处理\n                        iterator.remove();\n                    }\n                } else {\n                    System.out.println(\"等待....\");\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            //发生异常处理....\n        }\n    }\n\n    //读取客户端消息\n    public void readData(SelectionKey key) {\n        SocketChannel channel = null;\n        try {\n            //得到 channel\n            channel = (SocketChannel) key.channel();\n            //创建 buffer\n            ByteBuffer buffer = ByteBuffer.allocate(1024);\n            int count = channel.read(buffer);\n            //根据 count 的值做处理\n            if (count > 0) {\n                //把缓存区的数据转成字符串\n                String msg = new String(buffer.array());\n                //输出该消息\n                System.out.println(\"form客户端:\" + msg);\n                //向其它的客户端转发消息(去掉自己),专门写一个方法来处理\n                sendInfoToOtherClients(msg, channel);\n            }\n        } catch (IOException e) {\n            try {\n                System.out.println(channel.getRemoteAddress() + \"离线了..\");\n                //取消注册\n                key.cancel();\n                //关闭通道\n                channel.close();\n            } catch (IOException e2) {\n                e2.printStackTrace();\n            }\n        }\n    }\n\n    //转发消息给其它客户(通道)\n    private void sendInfoToOtherClients(String msg, SocketChannel self) throws IOException {\n\n        System.out.println(\"服务器转发消息中...\");\n        //遍历所有注册到 selector 上的 SocketChannel,并排除 self\n        for (SelectionKey key : selector.keys()) {\n            //通过 key 取出对应的 SocketChannel\n            Channel targetChannel = key.channel();\n            //排除自己\n            if (targetChannel instanceof SocketChannel && targetChannel != self) {\n                //转型\n                SocketChannel dest = (SocketChannel) targetChannel;\n                //将 msg 存储到 buffer\n                ByteBuffer buffer = ByteBuffer.wrap(msg.getBytes());\n                //将 buffer 的数据写入通道\n                dest.write(buffer);\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        //创建服务器对象\n        GroupChatServer groupChatServer = new GroupChatServer();\n        groupChatServer.listen();\n    }\n}\n\n// 客户端：\n\npackage com.zhao.nio.groupchat;\n\nimport java.io.IOException;\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.SelectionKey;\nimport java.nio.channels.Selector;\nimport java.nio.channels.SocketChannel;\nimport java.util.Iterator;\nimport java.util.Scanner;\n\npublic class GroupChatClient {\n\n    //定义相关的属性\n    private final String HOST = \"127.0.0.1\";//服务器的ip\n    private final int PORT = 6667;//服务器端口\n    private Selector selector;\n    private SocketChannel socketChannel;\n    private String username;\n\n    //构造器,完成初始化工作\n    public GroupChatClient() throws IOException {\n\n        selector = Selector.open();\n        //连接服务器\n        socketChannel = SocketChannel.open(new InetSocketAddress(HOST, PORT));\n        //设置非阻塞\n        socketChannel.configureBlocking(false);\n        //将 channel 注册到selector\n        socketChannel.register(selector, SelectionKey.OP_READ);\n        //得到 username\n        username = socketChannel.getLocalAddress().toString().substring(1);\n        System.out.println(username + \" is ok...\");\n    }\n\n    //向服务器发送消息\n    public void sendInfo(String info) {\n        info = username + \" 说：\" + info;\n        try {\n            socketChannel.write(ByteBuffer.wrap(info.getBytes()));\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n\n    //读取从服务器端回复的消息\n    public void readInfo() {\n        try {\n            int readChannels = selector.select();\n            if (readChannels > 0) {//有可以用的通道\n                Iterator<SelectionKey> iterator = selector.selectedKeys().iterator();\n                while (iterator.hasNext()) {\n                    SelectionKey key = iterator.next();\n                    if (key.isReadable()) {\n                        //得到相关的通道\n                        SocketChannel sc = (SocketChannel) key.channel();\n                        //得到一个 Buffer\n                        ByteBuffer buffer = ByteBuffer.allocate(1024);\n                        //读取\n                        sc.read(buffer);\n                        //把读到的缓冲区的数据转成字符串\n                        String msg = new String(buffer.array());\n                        System.out.println(msg.trim());\n                    }\n                }\n                iterator.remove(); //删除当前的 selectionKey,防止重复操作\n            } else {\n                //System.out.println(\"没有可以用的通道...\");\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n\n        //启动我们客户端\n        GroupChatClient chatClient = new GroupChatClient();\n        //启动一个线程,每个 3 秒，读取从服务器发送数据\n        new Thread() {\n            public void run() {\n                while (true) {\n                    chatClient.readInfo();\n                    try {\n                        Thread.currentThread().sleep(3000);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n        }.start();\n\n        //发送数据给服务器端\n        Scanner scanner = new Scanner(System.in);\n        while (scanner.hasNextLine()) {\n            String s = scanner.nextLine();\n            chatClient.sendInfo(s);\n        }\n    }\n}\n```\n\n## NIO 与 零拷贝\n\n### 零拷贝基本介绍\n\n1. 零拷贝是网络编程的关键，很多性能优化都离不开。\n2. 在 `Java` 程序中，常用的零拷贝有 `mmap`（内存映射）和 `sendFile`。那么，他们在 `OS` 里，到底是怎么样的一个的设计？我们分析 `mmap` 和 `sendFile` 这两个零拷贝\n3. 另外我们看下 `NIO` 中如何使用零拷贝\n\n### 传统 IO 数据读写\n\n`Java` 传统 `IO` 和网络编程的一段代码\n\n```java\nFile file = new File(\"test.txt\");\nRandomAccessFile raf = new RandomAccessFile(file, \"rw\");\n\nbyte[] arr = new byte[(int) file.length()];\nraf.read(arr);\n\nSocket socket = new ServerSocket(8080).accept();\nsocket.getOutputStream().write(arr);\n```\n\n### 传统 IO 模型\n\n![image-20210813231925494](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231925494.png)\n\n**DMA**：`direct memory access` 直接内存拷贝（不使用 `CPU`）\n\n### mmap 优化\n\n1. `mmap` 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户空间的拷贝次数。如下图\n   2. `mmap` 示意图\n\n![image-20210813231940879](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231940879.png)\n\n### sendFile 优化\n\n1. `Linux2.1` 版本提供了 `sendFile` 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 `SocketBuffer`，同时，由于和用户态完全无关，就减少了一次上下文切换\n2. 示意图和小结\n\n![image-20210813231958625](/images/%E3%80%90Java%E3%80%91NIO/image-20210813231958625.png)\n\n1. 提示：零拷贝从操作系统角度，是没有 `cpu` 拷贝\n2. `Linux在2.4` 版本中，做了一些修改，避免了从内核缓冲区拷贝到 `Socketbuffer` 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。具体如下图和小结：\n\n![image-20210813232020998](/images/%E3%80%90Java%E3%80%91NIO/image-20210813232020998.png)\n\n1. 这里其实有一次 `cpu` 拷贝 `kernel buffer` -> `socket buffer` 但是，拷贝的信息很少，比如 `lenght`、`offset` 消耗低，可以忽略\n\n### 零拷贝的再次理解\n\n1. 我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 `kernel buffer` 有一份数据）。\n2. 零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 `CPU` 缓存伪共享以及无 `CPU` 校验和计算。\n\n### mmap 和 sendFile 的区别\n\n1. `mmap` 适合小数据量读写，`sendFile` 适合大文件传输。\n2. `mmap` 需要 `4` 次上下文切换，`3` 次数据拷贝；`sendFile` 需要 `3` 次上下文切换，最少 `2` 次数据拷贝。\n3. `sendFile` 可以利用 `DMA` 方式，减少 `CPU` 拷贝，`mmap` 则不能（必须从内核拷贝到 `Socket`缓冲区）。\n\n### NIO 零拷贝案例\n\n案例要求：\n\n1. 使用传统的 `IO` 方法传递一个大文件\n2. 使用 `NIO` 零拷贝方式传递（`transferTo`）一个大文件\n3. 看看两种传递方式耗时时间分别是多少\n\n```java\nNewIOServer.java\n\npackage com.zhao.nio.zerocopy;\n\nimport java.net.InetSocketAddress;\nimport java.net.ServerSocket;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\n\n//服务器\npublic class NewIOServer {\n\n    public static void main(String[] args) throws Exception {\n        InetSocketAddress address = new InetSocketAddress(7001);\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        ServerSocket serverSocket = serverSocketChannel.socket();\n        serverSocket.bind(address);\n\n        //创建buffer\n        ByteBuffer byteBuffer = ByteBuffer.allocate(4096);\n\n        while (true) {\n            SocketChannel socketChannel = serverSocketChannel.accept();\n            int readcount = 0;\n            while (-1 != readcount) {\n                try {\n                    readcount = socketChannel.read(byteBuffer);\n                } catch (Exception ex) {\n                    // ex.printStackTrace();\n                    break;\n                }\n                //\n                byteBuffer.rewind(); //倒带 position = 0 mark 作废\n            }\n        }\n    }\n}\n\nNewIOClient.java\n\npackage com.zhao.nio.zerocopy;\n\nimport java.io.FileInputStream;\nimport java.net.InetSocketAddress;\nimport java.nio.channels.FileChannel;\nimport java.nio.channels.SocketChannel;\n\npublic class NewIOClient {\n\n    public static void main(String[] args) throws Exception {\n        SocketChannel socketChannel = SocketChannel.open();\n        socketChannel.connect(new InetSocketAddress(\"localhost\", 7001));\n        String filename = \"protoc-3.6.1-win32.zip\";\n        //得到一个文件channel\n        FileChannel fileChannel = new FileInputStream(filename).getChannel();\n        //准备发送\n        long startTime = System.currentTimeMillis();\n        //在 linux 下一个 transferTo 方法就可以完成传输\n        //在 windows 下一次调用 transferTo 只能发送 8m, 就需要分段传输文件,而且要主要\n        //传输时的位置=》课后思考...\n        //transferTo 底层使用到零拷贝\n        long transferCount = fileChannel.transferTo(0, fileChannel.size(), socketChannel);\n        System.out.println(\"发送的总的字节数 = \" + transferCount + \" 耗时: \" + (System.currentTimeMillis() - startTime));\n\n        //关闭\n        fileChannel.close();\n    }\n}\n```\n\n## AIO\n\n1. `JDK7` 引入了 `AsynchronousI/O`，即 `AIO`。在进行 `I/O` 编程中，常用到两种模式：`Reactor` 和 `Proactor`。`Java` 的 `NIO` 就是 `Reactor`，当有事件触发时，服务器端得到通知，进行相应的处理\n2. `AIO` 即 `NIO2.0`，叫做异步不阻塞的 `IO`。`AIO` 引入异步通道的概念，采用了 `Proactor` 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用\n3. 目前 `AIO` 还没有广泛应用，`Netty` 也是基于 `NIO`，而不是 `AIO`，因此我们就不详解 `AIO` 了，有兴趣的同学可以参考[《Java新一代网络编程模型AIO原理及Linux系统AIO介绍》](http://www.52im.net/thread-306-1-1.html)\n\n### BIO、NIO、AIO 对比表\n\n|          | BIO      | NIO                    | AIO        |\n| -------- | -------- | ---------------------- | ---------- |\n| IO模型   | 同步阻塞 | 同步非阻塞（多路复用） | 异步非阻塞 |\n| 编程难度 | 简单     | 复杂                   | 复杂       |\n| 可靠性   | 差       | 好                     | 好         |\n| 吞吐量   | 低       | 高                     | 高         |\n\n**举例说明**\n\n1. 同步阻塞：到理发店理发，就一直等理发师，直到轮到自己理发。\n2. 同步非阻塞：到理发店理发，发现前面有其它人理发，给理发师说下，先干其他事情，一会过来看是否轮到自己.\n3. 异步非阻塞：给理发师打电话，让理发师上门服务，自己干其它事情，理发师自己来家给你理发\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n尚硅谷替换 zhao\n\n\n\n","tags":["Java","Netty"],"categories":["Java","Netty"]},{"title":"【Dubbo】Dubbo 源码分析","url":"/2021/08/11/【Dubbo】Dubbo源码分析/","content":"\n## Dubbo 框架设计\n\n![image-20210826221319345](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826221319345.png)\n\n该图描述了服务注册中心、服务提供方、服务消费方、服务监控中心之间的调用关系：\n\n- **服务提供者（Provider）**：暴露服务的服务提供方。服务提供者在启动时完成以下步骤进行服务**暴露**：\n  - **本地暴露**：创建Netty服务端**NettyServer**，启动并监听配置文件中指定的Dubbo服务端口20880，等待消费者客户端发送远程调用当前服务的请求；\n  - **注册服务信息到本地缓存**：将服务信息注册到提供者注册表（本地缓存`Map`）中；\n  - **注册服务信息到注册中心**：向注册中心注册自己提供的服务信息，例如在ZooKeeper的Dubbo节点下创建提供的服务节点，该节点包含该服务的接口名、Provider服务端（通常为**NettyServer**）的URL等信息；服务信息将被保存成`Map`结构：`服务名 : List<URL>`。\n- **服务消费者（Consumer）**: 调用远程服务的服务消费方。服务消费者在启动时，完成以下步骤进行**服务引用**：\n  - 获取注册中心地址并据此创建ZooKeeper注册中心类`registry`；\n  - **根据服务名称**从注册中心`registry`订阅服务的URL列表 `List<URL>`（只订阅当前工程引用的服务，其他服务不订阅）；\n  - 获取到服务URL信息后，创建`NettyClient`客户端与其进行通讯，并创建`invoker`（包含了远程服务的信息，后续使用其进行远程服务调用）；\n  - 将`invoker`保存到消费者的本地缓存`Map`中，这样即使ZooKeeper宕机本地工程也能使用缓存中的`invoker`调用远程服务。\n- 服务消费者在进行**服务调用**时将进行以下步骤：\n  - 使用服务的代理对象调用方法时将逐层调用其内嵌套的多个不同功能的`invoker`，基于软负载均衡算法，从服务URL列表中选择其中的一台提供者进行远程调用；\n  - 多层`invoker`调用后将创建出Netty客户端`NettyClient`与服务端`NettyServer`进行通讯；\n  - 将要调用的接口名、方法名和方法参数等信息经过编码序列化后发送给`NettyServer`，服务端收到该请求后**创建目标服务对应的代理对象执行服务方法**，待其执行完毕后再将方法的返回结果发送给客户端；\n  - 远程调用原理：选择其中的某一个URL作为目标服务端`NettyServer`，创建`NettyClient`与其进行通讯，将要执行的**服务接口名、方法名、方法参数类型列表与方法值列表发送给NettyServer**，令其创建**代理对象**调用该方法，从而实现远程调用目标方法。如果选中的服务器调用失败，再选另一台调用。\n- **注册中心（Registry）**：\n  - 注册中心负责保存服务提供者发来的服务信息，同时在消费者发来订阅请求时返回服务提供者地址列表（包含ip/port等信息）给消费者，如果有变更，注册中心将基于**长连接**推送变更数据给消费者。\n  - 当注册中心检测到有Dubbo提供者宕机时，将从节点中删除该提供者信息（超时检测机制），同时通知所有消费者节点信息发生改变，修改消费者本地缓存中的服务数据（使用ZooKeeper里的监听机制，在消费者从注册中心订阅时就绑定监听了注册中心服务节点信息改变事件）\n- **监控中心（Monitor）**：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n- **框架容器（Container）**：Dubbo容器（Spring容器）。\n\n图中线条代表含义：\n\n- **紫色虚线**代表Dubbo容器启动时执行的步骤，先后为：\n  - `0.start`：启动Dubbo容器\n  - `1.register`：服务提供者在注册中心内注册信息（服务端的ip地址和端口号等信息）\n  - `2.subscribe`：服务消费者向注册中心订阅所有服务提供者的信息\n- **蓝色虚线**代表异步执行，当注册中心发现服务提供者发生改变时，会通知服务消费者该变化。服务提供者和服务消费者会定期向监控中心发送数据；\n- **蓝色实线**代表服务消费者同步执行服务提供者的方法。\n\n![image-20210827133552495](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827133552495-1630052803222.png)\n\n> https://dubbo.apache.org/zh/docsv2.7/dev/design/\n\nDubbo 整体设计图：\n\n![/dev-guide/images/dubbo-framework.jpg](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/dubbo-framework.jpg)\n\n<!-- More -->\n\n## Dubbo 组件标签解析\n\n两种使用Dubbo的方式：\n\n- 基于xml配置文件方式\n- 基于注解方式（和Spring Boot整合）\n\n### 基于 xml 配置文件方式\n\nSpring容器在启动时将创建**DubboNamespaceHandler**组件，并调用其`init()`方法。该方法内将创建Dubbo组件的定义解析器**registerBeanDefinitionParser**，该类用于解析.xml文件中定义的所有Dubbo组件的信息，即根据配置文件中每个组件所赋予的属性值创建出相应的Dubbo组件。\n\n![image-20210825102509354](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825102509354.png)\n\n上图中**registerBeanDefinitionParser**解析的组件在xml文件中对应如下标签：\n\n```xml\n<!--1、指定当前服务/应用的名字(同样的服务名字相同，不要和别的服务同名)-->\n<dubbo:application name=\"user-service-provider\"></dubbo:application>\n\n<!--2、指定注册中心的位置-->\n<!--<dubbo:registry address=\"zookeeper://127.0.0.1:2181\"></dubbo:registry>-->\n<dubbo:registry protocol=\"zookeeper\" address=\"127.0.0.1:2181\"></dubbo:registry>\n\n<!--3、指定通信规则（通信协议? 服务端口）：服务可以通过什么协议被消费者调用-->\n<dubbo:protocol name=\"dubbo\" port=\"20880\"></dubbo:protocol>\n\n<!--4、暴露服务让其他模块调用，ref指向服务的真正实现对象-->\n<dubbo:service interface=\"com.zhao.gmail.service.UserService\" ref=\"userServiceImpl\"></dubbo:service>\n\n<!--服务的实现-->\n<bean id=\"userServiceImpl\" class=\"com.zhao.gmail.service.impl.UserServiceImpl\"></bean>\n\n<!--dubbo-monitor-simple监控中心发现的配置-->\n<!--使用registry协议，去注册中心自动监控-->\n<dubbo:monitor protocol=\"registry\"></dubbo:monitor>\n<!--<dubbo:monitor address=\"127.0.0.1:7070\"></dubbo:monitor>-->\n\n<!--配置当前消费者的统一规则,当前所有的服务都不启动时检查-->\n<dubbo:consumer check=\"false\"></dubbo:consumer>\n```\n\n其中**registerBeanDefinitionParser**解析Dubbo标签，创建对应组件的具体代码：\n\n![image-20210825104559439](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825104559439.png)\n\n依次解析每个Dubbo标签，创建出对应的组件并注入到容器中，即完成了Dubbo组件的初始化工作。\n\n### 基于注解方式（和Spring Boot整合）\n\n若采用Spring Boot整合的方式，则无需手动配置xml文件。\n\n使用方式：直接导入`dubbo-starter`，在`application.properties`配置属性，使用 **@Service**暴露服务，使用 **@Reference** 引用服务。\n\n此时Dubbo组件的注册将交由Spring Boot的自动配置机制实现，具体原理见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n## 服务暴露流程\n\n服务暴露功能由**ServiceBean**组件实现，该类实现了Spring的多个接口：\n\n```java\npublic class ServiceBean<T> extends ServiceConfig<T> implements \n    InitializingBean, DisposableBean, ApplicationContextAware, ApplicationListener<ContextRefreshedEvent>, BeanNameAware {\n\n    private static final long serialVersionUID = 213195494150089726L;\n    private static transient ApplicationContext SPRING_CONTEXT;\n    private final transient Service service;\n    private transient ApplicationContext applicationContext;\n    private transient String beanName;\n    private transient boolean supportedApplicationListener;\n\n    public ServiceBean() {\n        super();\n        this.service = null;\n    }\n\n    public ServiceBean(Service service) {\n        super(service);\n        this.service = service;\n    }\n}\n```\n\n其中较为重要的接口作用：\n\n- **InitializingBean**：在`ServiceBean`组件对象创建完毕后将调用其实现的**InitializingBean**接口的 `afterPropertiesSet()` 方法\n- **ApplicationListener\\<ContextRefreshedEvent\\>**：Spring的监听器，负责监听IoC容器刷新完成事件。当IoC容器刷新完成，即容器中所有组件都创建完成后（此时已创建了Dubbo的其他配置类组件）调用其 `onApplicationEvent()` 方法\n\n### afterPropertiesSet() 方法\n\n**InitializingBean**接口的 `afterPropertiesSet()` 方法用于将Dubbo相关的组件保存到当前`ServiceBean`组件里，例如`Provider`，`Application`，`Module`，`Registries`，`Monitor`等。这样`ServiceBean`就可以在后续获取到注册中心、服务协议等信息。\n\n![image-20210825135725282](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825135725282.png)\n\n### onApplicationEvent() 方法\n\n**ApplicationListener\\<ContextRefreshedEvent\\>** 接口的 **onApplicationEvent()** 方法会在IoC容器完成刷新后调用（响应`ContextRefreshedEvent`事件），其内调用了 **export()** 方法进行服务暴露，即将服务信息（如接口名，方法名，方法参数列表等）暴露给注册中心ZooKeeper：\n\n![image-20210825135831748](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825135831748.png)\n\n该方法经过多层方法栈后将调用 **doExportUrls()** 方法暴露URL到注册中心：\n\n![image-20210825140131870](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825140131870.png)\n\n该方法的作用：\n\n- 读取注册中心（ZooKeeper）的URL地址（可能有多个注册中心组成集群）\n- 使用配置文件中指定的协议暴露当前服务（可能有多个协议，即可以配置多个`dubbo_protocol`标签）。例如将当前服务的接口名、方法名等信息注册到注册中心ZooKeeper中。\n\n![image-20210825140558697](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825140558697.png)\n\n上述注册中心和协议分别为我们在配置文件中指定的内容：\n\n```xml\n<!--2、指定注册中心的位置，可以有多个注册中心组成集群-->\n<!--<dubbo:registry address=\"zookeeper://127.0.0.1:2181\"></dubbo:registry>-->\n<dubbo:registry protocol=\"zookeeper\" address=\"127.0.0.1:2181\"></dubbo:registry>\n\n<!--3、指定通信规则（通信协议? 服务端口）：服务可以通过什么协议被消费者调用。可以有多个协议、端口号-->\n<dubbo:protocol name=\"dubbo\" port=\"20880\"></dubbo:protocol>\n```\n\n进入 **doExportUrlsFor1Protocol()** 方法后：\n\n![image-20210825161725034](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825161725034.png)\n\n首先将要暴露的服务**实现类**、**接口**和**注册中心的URL**等信息包装成一个执行器`invoker`，该执行器内含有该服务的接口名，方法名，方法参数列表等参数。后续在接收到客户端调用服务时即可使用该执行器即可调用该服务的内容。\n\n接着再使用协议对象`protocol`暴露该执行器并保存生成的导出器，该`export()`暴露方法共做三件事：\n\n- **本地暴露**：创建Netty服务端**NettyServer**，启动并监听配置文件中指定的Dubbo服务端口20880，等待消费者客户端发送远程调用当前服务的请求；\n- **注册服务信息到本地缓存**：将服务信息注册到提供者注册表（本地缓存`Map`）中；\n- **注册服务信息到注册中心**：向注册中心注册自己提供的服务信息，例如在ZooKeeper的Dubbo节点下创建提供的服务节点，该节点包含该服务的接口名、Provider服务端（通常为**NettyServer**）的URL等信息；服务信息将被保存成`Map`结构：`服务名 : List<URL>`；\n\n---\n\nDubbo支持的所有协议：\n\n![image-20210825152318380](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825152318380.png)\n\nDubbo基于自己独特的SPI机制获取到当前项目满足的协议对象`protocol`，其将根据当前工程导入的依赖判断使用哪种协议：\n\n![image-20210825163420576](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825163420576.png)\n\n默认情况下上文中的`protocol`对象为**RegistryProtocol**类型（注册协议），**该协议的作用为：将服务信息注册到注册中心。**\n\n同时该协议内部又调用了**DubboProtocol**协议的`export()`方法，该协议的作用为：在底层创建Netty服务端**NettyServer**，启动并监听配置文件中指定的端口20880。==待确定）==这样消费者客户端就可以通过Netty连接到提供者的服务端口，发送要调用的服务信息==，从而远程调用服务端的代理对象invoker执行方法==\n\n==即注册协议**RegistryProtocol**默认会调用Dubbo协议**DubboProtocol**，先创建**NettyServer**绑定端口并开启监听，再将服务信息注册到注册中心。==\n\n---\n\n进入`protocol`对象（**RegistryProtocol**类型）的 **export()** 方法：\n\n![image-20210826203228308](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826203228308.png)\n\n下面分别介绍上述三个关键方法：\n\n### 1. doLocalExport()：启动Netty服务端并绑定服务端口\n\n该方法内将首先调用 **doLocalExport()** 方法进行本地暴露，即使用**DubboProtocol**协议的 **export()** 方法在底层创建Netty服务端**NettyServer**，启动并监听配置文件中指定的Dubbo服务端口20880。\n\n```xml\n<!--3、指定通信规则（通信协议? 服务端口），可以有多个协议、端口号-->\n<dubbo:protocol name=\"dubbo\" port=\"20880\"></dubbo:protocol>\n```\n\n **doLocalExport()** 方法内将调用**DubboProtocol**协议的 **export()** 方法：\n\n![image-20210825164256973](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825164256973.png)\n\n![image-20210825165344016](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210825165344016.png)\n\n### 2. registerProvider() ：注册服务信息到本地缓存\n\n该方法用于将服务信息注册到本地缓存的`Map`中。进入 **registerProvider()** 方法：\n\n![image-20210826171112848](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826171112848.png)\n\n1. 首先将执行器**invoker**（在上文中包装得到，包含要暴露的服务**实现类**、**接口**和**注册中心的URL**等信息）、注册URL和服务URL等信息包装成一个**ProviderInvokerWrapper**对象`wrapperInvoker`；\n2. 接着从本地缓存的执行器包装类集合**providerInvokers**（`Map`类型）里取出当前服务对应的执行器包装类`Set`集合（该`Map`的存储结构为**服务名称：服务执行器包装类集合**）；\n3. 若返回的执行器包装类`Set`集合为空，说明该服务还未注册，则在`Map`中新建一组数据，存储当前服务名与其对应的服务执行器包装类`wrapperInvoker`；\n4. 若返回的执行器包装类`Set`集合不为空，则获取该服务对应的Set集合，将当前的`wrapperInvoker`添加进去\n\n---\n\n**providerInvokers**：\n\n![image-20210826172358632](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826172358632.png)\n\n其中存储的**服务名称**包含以下信息：\n\n- 接口名\n- Group\n- Version\n\n![image-20210826172946074](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826172946074.png)\n\n---\n\n### 3. register()：注册服务信息到注册中心\n\n**register()** 方法用于将服务URL信息（包含暴露的Netty服务端口号、接口名、方法参数等信息）注册到注册中心：\n\n![image-20210826195943484](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826195943484.png)\n\n- 根据注册中心URL获取到对应的注册器（例如`ZooKeeperRegistry`）\n- 调用该注册器的`register()`方法，将提供者URL信息注册到注册中心\n\n此时注册中心就记录了每个服务与其对应的URL（该服务所在的Netty服务端地址和端口号），后续消费者访问该URL即可访问到了绑定该服务的Netty服务端。\n\n---\n\n其中URL类内包含以下信息：\n\n![image-20210826200137647](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826200137647.png)\n\n![image-20210826200443713](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826200443713.png)\n\nURL示例：dubbo://192.168.1.101:20880/com.zhao.gmall.service.UserService?anyhost=true&application=order-service-consumer&....version=1.0...\n\n---\n\n总结：服务暴露的整个流程图：\n\n![dubbo-服务暴露](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/dubbo-%E6%9C%8D%E5%8A%A1%E6%9A%B4%E9%9C%B2.jpg)\n\n## 服务引用流程\n\n服务引用功能由**ReferenceBean**组件实现，该类实现了Spring的多个接口：\n\n![image-20210827100909250](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827100909250.png)\n\n其`getObject()`方法中的`get()`方法用于获取引用对象的**代理对象**`ref`（基于Java JDK 动态代理机制），该代理对象内包含了能够远程调用当前服务的执行器`invoker`（`invoker`创建过程见下文分析）：\n\n![image-20210827101104100](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827101104100.png)\n\n![image-20210827101027069](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827101027069.png)\n\n在上图中的`init()`方法中将根据`map`对象创建出对应的代理对象`ref`：\n\n![image-20210827101320120](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827101320120.png)\n\n该`map`对象保存了服务的信息，例如：\n\n- `side=consumer`：代表是消费者端\n- `register.ip=192.168.1.101`：消费者的ip地址（用于向注册中心注册消费者的ip地址，从而在后续监听到服务信息变更事件后通知消费者）\n- `method=getUserAddressList`：引用服务的方法名\n-  `default.check=false`：代表当前所有的服务都不启动时检查\n-  `pid=47980`：进程id\n- `interface=com.zhao.gmall.service.UserService`：服务的接口名\n- `version=*`：服务版本号\n\n`createProxy(map)`方法内将调用`refprotocol`远程引用服务：\n\n![image-20210827102408840](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827102408840.png)\n\n使用`refprotocol.ref()`进行服务引用的流程与在服务暴露中使用`protocol.export()`进行服务暴露的流程相似，共有以下主要流程：\n\n- 获取注册中心地址并据此创建ZooKeeper注册中心类`registry`\n- 根据注册中心地址订阅当前服务的信息（只订阅当前工程引用的服务，其他服务不订阅），获取到服务URL信息后，创建`NettyClient`客户端与其进行通讯，并创建`invoker`（包含了远程服务的信息，后续使用其进行远程[服务调用](#服务调用流程)）\n- 将`invoker`保存到消费者的本地缓存`Map`中，这样即使ZooKeeper宕机本地工程也能使用缓存中的`invoker`调用远程服务\n\n下面逐一分析上述过程的具体代码：\n\n进入`refprotocol.ref()`方法，此时调用的是**RegistryProtocol**类型（与服务暴露时顺序相同）：\n\n![image-20210827104447523](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827104447523.png)\n\n`doRefer()` 方法内（仍为**RegistryProtocol**协议的方法）：\n\n![image-20210827110250618](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827110250618.png)\n\n在`subscribe()`订阅时将调用**DubboProtocol**的`refer()`方法：\n\n![image-20210827105657596](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210827105657596.png)\n\n该方法内将创建一个`NettyClient`与远程服务的`NettyServer`进行连接，并返回一个`invoker`（包含目标服务的URL等信息）。后续的[服务调用](#服务引用流程)将使用该`invoker`对象进行服务的远程调用。\n\n同时该`invoker`将被保存到消费者的本地缓存`Map`中，这样即使ZooKeeper宕机本地工程也能使用缓存中的`invoker`调用远程服务。\n\n总结：服务引用的整个流程：\n\n![dubbo-服务引用](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/dubbo-%E6%9C%8D%E5%8A%A1%E5%BC%95%E7%94%A8.jpg)\n\n\n\n## 服务调用流程\n\n```java\npublic class ConsumerApplication {\n    public static void main(String[] args) {\n        ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"consumer.xml\");\n        OrderService orderService = applicationContext.getBean(OrderService.class);\n\n        //调用方法查询出数据\n        orderService.initOrder(\"1\");\n        System.out.println(\"调用完成...\");\n        System.in.read();\n    }\n}\n```\n\n客户端进行服务调用时，将使用**Java JDK的动态代理机制**创建出的目标服务类的代理对象`orderService`（创建过程见[服务引用流程](#服务引用流程)）。调用该代理对象，**逐层调用其内嵌套的多个不同功能的`invoker`，直至创建出Netty客户端`NettyClient`与服务端`NettyServer`进行通讯**，将要调用的接口名、方法名和方法参数等信息经过编码序列化后发送给`NettyServer`，服务端收到该请求后**创建目标服务对应的代理对象执行服务方法**，待其执行完毕后再将方法返回结果发送给客户端，从而完成远程调用服务方法。\n\n![image-20210826222218361](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826222218361.png)\n\n上图中的`invoker`为**MockClusterInvoker**类型内又嵌套了许多其他类型的`invoker`：\n\n![image-20210826223808769](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210826223808769.png)\n\n该`invoker`将逐层调用其内嵌套的每个`invoker`，执行其相应的功能。\n\n整个服务调用流程图：\n\n![/dev-guide/images/dubbo-extension.jpg](/images/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/dubbo-extension.jpg)\n\n下面按照从下到上的顺序（客户端到服务端）分析上图：\n\n- 首先客户端获取到服务的代理对象，并调用其`invoke()`方法：\n- 如果配置了容错缓存等功能则经过一层过滤器`Filter`\n- 从`Cluster`中选出一个`Invoker`（`Cluster`内封装了多个`Invoker`）：如果有多个`Invoker`，则使用负载均衡机制选择其中的一个`Invoker`，若其执行失败（例如超时），则再换一个`Invoker`（`Invoker`中保存了从ZooKeeper注册中心`Registry`中获取到的服务URL信息）\n- 选出`Invoker`后再经过一些`Filter`，例如计数、监控等\n- 调用Dubbo协议的`Invoker`，其底层创建了一个`NettyClient`，该客户端连接服务端`NettyServer`，将要调用的接口名、方法名、方法参数、版本号等信息经过**编码和序列化**后发送给`NettyServer`\n- 服务端收到该请求后创建目标服务对应的代理对象执行服务方法，待其执行完毕后再基于`NettyChannel`将方法返回结果发送给客户端，从而完成远程调用服务方法。\n\n\n\n\n\n\n\n","tags":["源码分析","Dubbo"],"categories":["源码分析","Dubbo"]},{"title":"【Dubbo】Dubbo","url":"/2021/08/11/【Dubbo】Dubbo/","content":"\n![image-20210826221319345](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210826221319345.png)\n\n## 分布式简介\n\n> https://blog.csdn.net/qq_41157588/article/details/106737191\n\n分布式系统是若干**独立计算机**的集合，这些计算机对于用户来说就像单个相关系统。老式系统(单一应用架构)就是把一个系统，统一放到一个服务器当中。如果说要更新代码的话，每一个服务器上的系统都要重新去部署十分的麻烦。\n\n**而分布式系统就是将一个完整的系统拆分成多个不同的服务，然后在将每一个服务单独的放到一个服务器当中**。\n\n### 应用架构及发展演变\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/1077977-20170427162130881-822422851.png)\n\n<!-- More -->\n\n### ORM：单一应用架构\n\n**单一应用架构**：一个项目装到一个服务器当中。也可以运行多个服务器，每一个服务器当中都装一个项目。缺点：\n\n- 如果要添加某一个功能的话就要把一个项目重新打包，在分别部署到每一个服务器当中去。\n- 如果后期项目越来越大的话单台服务器跑一个项目压力会很大的。会不利于维护，开发和程序的性能。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200205165935907.png)\n\n### MVC：垂直应用架构\n\n**垂直应用架构**：将应用切割成几个互不相干的小应用，在**将每个小应用独立放到一个服务器上**，如果哪一个应用的访问数量多就多加几台服务器。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200205165948633.png)\n\n### RPC：分布式应用架构\n\n**分布式应用架构(远程过程调用)**：当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为**独立的服务**，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。\n\n**RPC(Remote Procedure Call)** 是指**远程过程调用**，是一种**进程间**通信方式，它是一种技术的思想，而不是规范。它允许程序调用另一个地址空间(通常是共享网络的另一台机器上)的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。\n\n> RPC的本质就是向远程目标服务器发出 HTTP 请求，令其解析该请求后执行相应的服务方法\n\nDubbo一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。\n\n> http://blog.csdn.net/smartbetter/article/details/100360835\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612180812112.png)\n\n#### RPC工作原理\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/2020061015260046.png)\n\n- Client像调用本地服务似的调用远程服务；\n- Client stub（存根）接收到调用后，将方法、参数序列化\n- 客户端通过sockets将消息发送到服务端\n- Server stub 收到消息后进行解码（将消息对象反序列化）\n- Server stub 根据解码结果调用本地的服务\n- 本地服务执行(对于服务端来说是本地执行)并将结果返回给Server stub\n- Server stub将返回结果打包成消息（将结果消息对象序列化）\n- 服务端通过sockets将消息发送到客户端\n- Client stub接收到结果消息，并进行解码（将结果消息发序列化）\n- 客户端得到最终结果。\n\n**RPC 调用分以下两种：**\n\n- **同步调用**：客户方等待调用执行完成并返回结果。\n- **异步调用**：客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果。\n\n#### RPC步骤解析\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200610174636250.png)\n\n### SOA：流动计算架构\n\n**流动计算架构**：在分布式应用架构的基础上增加了一个**调度、治理中心**基于访问压力实时管理集群容量、提高集群的利用率，用于提高机器利用率的**资源调度和治理中心**(SOA) 是关键 **(不浪费计算机资源)**\n\n## Dubbo 介绍\n\n> Dubbo官网： https://dubbo.apache.org/zh/\n\n![image-20210811154552749](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210811154552749.png)\n\n**Dubbo是一款高性能、轻量级的开源Java RPC框架**。它是一个**分布式服务框架**，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。它提供了三大核心能力：**面向接口的远程方法调用**，**智能容错和负载均衡**，**服务自动注册和发现**。\n\n### Dubbo 特性一览\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200610170234620.png)\n\n### Dubbo 设计架构\n\n![image-20210826221319345](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210826221319345.png)\n\n该图描述了服务注册中心、服务提供方、服务消费方、服务监控中心之间的调用关系：\n\n- **服务提供者（Provider）**：暴露服务的服务提供方。服务提供者在启动时完成以下步骤进行服务**暴露**：\n  - **本地暴露**：创建Netty服务端**NettyServer**，启动并监听配置文件中指定的Dubbo服务端口20880，等待消费者客户端发送远程调用当前服务的请求；\n  - **注册服务信息到本地缓存**：将服务信息注册到提供者注册表（本地缓存`Map`）中；\n  - **注册服务信息到注册中心**：向注册中心注册自己提供的服务信息，例如在ZooKeeper的Dubbo节点下创建提供的服务节点，该节点包含该服务的接口名、Provider服务端（通常为**NettyServer**）的URL等信息；服务信息将被保存成`Map`结构：`服务名 : List<URL>`。\n- **服务消费者（Consumer）**: 调用远程服务的服务消费方。服务消费者在启动时，完成以下步骤进行**服务引用**：\n  - 获取注册中心地址并据此创建ZooKeeper注册中心类`registry`；\n  - **根据服务名称**从注册中心`registry`订阅服务的URL列表 `List<URL>`（只订阅当前工程引用的服务，其他服务不订阅）；\n  - 获取到服务URL信息后，创建`NettyClient`客户端与其进行通讯，并创建`invoker`（包含了远程服务的信息，后续使用其进行远程服务调用）；\n  - 将`invoker`保存到消费者的本地缓存`Map`中，这样即使ZooKeeper宕机本地工程也能使用缓存中的`invoker`调用远程服务。\n- 服务消费者在进行**服务调用**时将进行以下步骤：\n  - 使用服务的代理对象调用方法时将逐层调用其内嵌套的多个不同功能的`invoker`，基于软负载均衡算法，从服务URL列表中选择其中的一台提供者进行远程调用；\n  - 多层`invoker`调用后将创建出Netty客户端`NettyClient`与服务端`NettyServer`进行通讯；\n  - 将要调用的接口名、方法名和方法参数等信息经过编码序列化后发送给`NettyServer`，服务端收到该请求后**创建目标服务对应的代理对象执行服务方法**，待其执行完毕后再将方法的返回结果发送给客户端；\n  - 远程调用原理：选择其中的某一个URL作为目标服务端`NettyServer`，创建`NettyClient`与其进行通讯，将要执行的**服务接口名、方法名、方法参数类型列表与方法值列表发送给NettyServer**，令其创建**代理对象**调用该方法，从而实现远程调用目标方法。如果选中的服务器调用失败，再选另一台调用。\n- **注册中心（Registry）**：\n  - 注册中心负责保存服务提供者发来的服务信息，同时在消费者发来订阅请求时返回服务提供者地址列表（包含ip/port等信息）给消费者，如果有变更，注册中心将基于**长连接**推送变更数据给消费者。\n  - 当注册中心检测到有Dubbo提供者宕机时，将从节点中删除该提供者信息（超时检测机制），同时通知所有消费者节点信息发生改变，修改消费者本地缓存中的服务数据（使用ZooKeeper里的监听机制，在消费者从注册中心订阅时就绑定监听了注册中心服务节点信息改变事件）\n- **监控中心（Monitor）**：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。\n- **框架容器（Container）**：Dubbo框架容器。\n\n图中线条代表含义：\n\n- **紫色虚线**代表Dubbo容器启动时执行的步骤，先后为：\n  - `0.start`：启动Dubbo容器\n  - `1.register`：服务提供者在注册中心内注册信息（服务端的ip地址和端口号等信息）\n  - `2.subscribe`：服务消费者向注册中心订阅所有服务提供者的信息\n- **蓝色虚线**代表异步执行，当注册中心发现服务提供者发生改变时，会通知服务消费者该变化。服务提供者和服务消费者会定期向监控中心发送数据。\n- **红色实线**代表服务消费者同步执行服务提供者的方法。\n\n![image-20210827133552495](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210827133552495.png)\n\nDubbo详细源码分析见[【Dubbo】Dubbo 源码分析](https://yuyun-zhao.github.io/2021/08/11/%E3%80%90Dubbo%E3%80%91Dubbo%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n### Dubbo 特性\n\n**（1）服务注册中心**\n\n相比Hessian类RPC框架，Dubbo有自己的服务中心，写好的服务可以注册到服务中心，客户端从服务中心寻找服务，然后再到相应的服务提供者机器获取服务。通过服务中心可以实现集群、负载均衡、高可用(容错) 等重要功能。\n\n服务中心一般使用ZooKeeper实现，也有Redis和其他一些方式。以使用ZooKeeper作为服务中心为例，**服务提供者启动后会在ZooKeeper的Dubbo节点下创建提供的服务节点，包含服务提供者ip、port等信息。服务提供者关闭时会从ZooKeeper中移除对应的服务。**\n\n服务使用者会从注册中心ZooKeeper中寻找服务，同一个服务可能会有多个提供者，Dubbo会帮我们找到合适的服务提供者，也就是针对服务提供者的负载均衡。\n\n**（2）负载均衡**\n\n当同一个服务有多个提供者在提供服务时，客户端如何正确的选择提供者实现负载均衡呢？Dubbo也给我们提供了几种方案：\n\n- random：随机选提供者，并可以给提供者设置权重\n- roundrobin：轮询选择提供者\n- leastactive：最少活跃调用数，相同活跃数的随机，活跃数：指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。\n- consistenthash：一致性hash，相同参数的请求发到同一台机器上。\n\n**（3）简化测试，允许直连提供者**\n\n在开发阶段为了方便测试，通常系统客户端能指定调用某个服务提供者，那么可以在引用服务时加一个url参数去指定服务提供者。 配置如下：\n\n ``` xml\n<dubbo:reference id=\"xxxService\" interface=\"com.alibaba.xxx.XxxService\" url=\"dubbo://localhost:20890\"/>\n ```\n\n**（4）服务版本，服务分组（灰度发布）**\n\n在Dubbo配置文件中可以通过制定版本实现连接制定提供者，也就是通过服务版本可以控制服务的不兼容升级；当同一个服务有多种实现时，可以使用服务分组进行区分。\n\n### Dubbo 和 Spring Cloud 对比\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200613161517225.png)\n\n## Dubbo 监控配置\n\n### 配置 ZooKeeper\n\n配置流程见[Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\n### 管理控制台 dubbo-admin 配置\n\n**1、下载dubbo-admin**\n\ndubbo-admin下载地址 ：https://github.com/apache/dubbo-admin/tree/master\n\n![image-20210811161121956](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210811161121956.png)\n\n**2、解压后进入目录修改指定ZooKeeper地址**\n\n进入如下地址：`dubbo-admin-master/dubbo-admin/src/main/resources/application.properties`将ZooKeeper的监控中心的地址配置为对应端口\n\n``` proper\n# 注册中心的地址\ndubbo.registry.address=zookeeper://127.0.0.1:2181\n```\n\n配置完毕后，在`dubo-zookeeper/dubbo-admin-master/dubbo-admin`文件夹下打包测试下。\n\n``` bash\nmvn clean package\n```\n\n使用 `java -jar dubbo-admin-0.0.1-SNAPSHOT.jar`运行打包好的jar包。启动成功后，在本地的7001端口即可访问到注册中心，账号密码默认均为\"root\"：\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200610180358177.png)\n\n此时，ZooKeeper的管理控制台配置完成。\n\n### 简易监控中心 dubbo-monitor-simple 配置\n\n> https://blog.csdn.net/qq_41157588/article/details/106737191\n\n进入`dubbo-monitor-simple`文件，执行`mvn package`命令将当前项目打包成jar包。\n\n将 `dubbo-monitor-simple-2.0.0-assembly.tar.gz` 压缩包解压至当前文件夹，解压后config文件查看properties的配置是否是对应的zookeeper。之后打开解压后的 `assembly.bin` 文件，`start.bat` 启动`dubbo-monitor-simple`监控中心。\n\n配置完成后，在`localhost:8080` ，可以看到一个监控中心。\n\n之后在服务提供者和消费者的xml中配置以下内容，再次启动服务提供和消费者启动类。\n\n```xml\n<!--dubbo-monitor-simple监控中心发现的配置-->\n<!--使用registry协议，去注册中心自动监控-->\n<dubbo:monitor protocol=\"registry\"></dubbo:monitor>\n<!--<dubbo:monitor address=\"127.0.0.1:7070\"></dubbo:monitor>-->\n```\n\n配置后即可在监控中心观察到服务提供者和消费者信息：\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612085805476.png)\n\n## Dubbo 用法\n\n### 服务提供者模块\n\n创建服务提供者模块，导入如下依赖（非Spring Boot配置）：\n\n```xml\n<!--dubbo-->\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>dubbo</artifactId>\n    <version>2.6.2</version>\n</dependency>\n<!--注册中心是 Zookeeper，引入zookeeper客户端-->\n<dependency>\n    <groupId>org.apache.curator</groupId>\n    <artifactId>curator-framework</artifactId>\n    <version>2.12.0</version>\n</dependency>\n```\n在配置文件中添加Dubbo相关配置`provider.xml`：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n                           http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\n                           http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\">\n    <!--1、指定当前服务/应用的名字(同样的服务名字相同，不要和别的服务同名)-->\n    <dubbo:application name=\"user-service-provider\"></dubbo:application>\n\n    <!--2、指定注册中心的位置-->\n    <!--<dubbo:registry address=\"zookeeper://127.0.0.1:2181\"></dubbo:registry>-->\n    <dubbo:registry protocol=\"zookeeper\" address=\"127.0.0.1:2181\"></dubbo:registry>\n\n    <!--3、指定通信规则（通信协议? 服务端口）：服务可以通过什么协议被消费者调用-->\n    <dubbo:protocol name=\"dubbo\" port=\"20880\"></dubbo:protocol>\n\n    <!--4、暴露服务让其他模块调用，ref指向服务的真正实现对象-->\n    <dubbo:service interface=\"com.zhao.gmail.service.UserService\" ref=\"userServiceImpl\"></dubbo:service>\n\n    <!--服务的实现-->\n    <bean id=\"userServiceImpl\" class=\"com.zhao.gmail.service.impl.UserServiceImpl\"></bean>\n\n    <!--dubbo-monitor-simple监控中心发现的配置-->\n    <!--使用registry协议，去注册中心自动监控-->\n    <dubbo:monitor protocol=\"registry\"></dubbo:monitor>\n    <!--<dubbo:monitor address=\"127.0.0.1:7070\"></dubbo:monitor>-->\n\n    <!--配置当前消费者的统一规则,当前所有的服务都不启动时检查-->\n    <dubbo:consumer check=\"false\"></dubbo:consumer>\n</beans>\n```\n\n编写一个`ProviderApplication`启动类程序，运行测试配置：\n\n```java\npublic class MailApplication {\n    public static void main(String[] args) throws IOException {\n        ClassPathXmlApplicationContext applicationContext= new ClassPathXmlApplicationContext(\"provider.xml\");\n        applicationContext.start();\n        System.in.read();\n    }\n}\n```\n\n首先启动zookeeper注册中心的zkServer和zkCli服务。运行 `java -jar dubbo-admin-0.0.1-SNAPSHOT.jar`。\n\n之后启动项目，我们可以看到在ZooKeeper中已经发现服务提供者：\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200611161736122.png)\n\n### 服务消费者模块\n\n创建服务消费者模块，同样引入依赖（与上文相同）。创建配置文件`consumer.xml`：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:dubbo=\"http://dubbo.apache.org/schema/dubbo\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n                           http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.3.xsd\n                           http://dubbo.apache.org/schema/dubbo http://dubbo.apache.org/schema/dubbo/dubbo.xsd\n                           http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\">\n    <!--包扫描-->\n    <context:component-scan base-package=\"com.zhao.gmail.service.impl\"/>\n\n    <!--指定当前服务/应用的名字(同样的服务名字相同，不要和别的服务同名)-->\n    <dubbo:application name=\"order-service-consumer\"></dubbo:application>\n\n    <!--指定注册中心的位置-->\n    <dubbo:registry address=\"zookeeper://127.0.0.1:2181\"></dubbo:registry>\n\n    <!--调用远程暴露的服务，生成远程服务代理-->\n    <dubbo:reference interface=\"com.zhao.gmail.service.UserService\" id=\"userService\"></dubbo:reference>\n\n    <!--dubbo-monitor-simple监控中心发现的配置-->\n    <!--使用registry协议，去注册中心自动监控-->\n    <dubbo:monitor protocol=\"registry\"></dubbo:monitor>\n    <!--<dubbo:monitor address=\"127.0.0.1:7070\"></dubbo:monitor>-->\n\n    <!--配置当前消费者的统一规则,当前所有的服务都不启动时检查-->\n    <dubbo:consumer check=\"false\"></dubbo:consumer>\n</beans>\n```\n\n把消费者模块中创建的`OrderServiceImpl`类中加上注解`@Component`以加入到容器中：\n\n```java\n@Component\npublic class OrderServiceImpl implements OrderService {\n    @Autowired\n    public UserService userService;\n    public void initOrder(String userID) {\n        //调用OrderService的远程代理对象查询用户的收货地址\n        List<UserAddress> userAddressList = userService.getUserAddressList(userID);\n    }\n}\n```\n\n编写一个`ConsumerApplication`启动类程序，运行测试配置：\n\n```java\npublic class ConsumerApplication {\n    public static void main(String[] args) {\n        ClassPathXmlApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"consumer.xml\");\n        OrderService orderService = applicationContext.getBean(OrderService.class);\n\n        //调用方法查询出数据\n        orderService.initOrder(\"1\");\n        System.out.println(\"调用完成...\");\n        System.in.read();\n    }\n}\n```\n\n\n注意：消费者的运行测试需要先启动提供者。启动服务提供者、消费者。及zookeeper的和dubbo-admin，查看监控信息：\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/2020061208334559.png)\n\n## Dubbo 和 Spring Boot 整合\n\nDubbo和Spring Boot整合的三种方式：\n\n1. 导入`dubbo-starter`，在`application.properties`配置属性，使用 **@Service**暴露服务，使用 **@Reference** 引用服务\n2. 导入`dubbo-starter`，保留Dubbo相关的xml配置文件，使用 **@ImportResource** 导入Dubbo的xml配置文件\n3. 导入`dubbo-starter`，创建 **@Configuration** 配置类，使用 **@Bean** 将每一个组件手动配置到容器中，让Dubbo来扫描其他的组件\n\n下面介绍第一种方式：\n\n### 服务提供者模块\n\n导入Dubbo的场景依赖`dubbo-spring-boot-starter`：\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter</artifactId>\n    </dependency>\n\n    <dependency>\n        <groupId>com.alibaba.boot</groupId>\n        <artifactId>dubbo-spring-boot-starter</artifactId>\n        <version>0.2.0</version>\n    </dependency>\n</dependencies>\n```\n\n配置 `application.properties`：\n\n```properties\ndubbo.application.name=boot-user-service-provider\ndubbo.registry.address=127.0.0.1:2181\ndubbo.registry.protocol=zookeeper\n\ndubbo.protocol.name=dubbo\ndubbo.protocol.port=20880\n\n#连接监控中心\ndubbo.monitor.protocol=registry\n```\n\n使用 **@DubboService** 注解将 `user-service-provider` 服务提供者模块中的UserServiceImpl暴露\n\n```java\n@DubboService // 将当前服务暴露\n@Component\npublic class UserServiceImpl implements UserService {\n    public List<UserAddress> getUserAddressList(String userId) {\n\t\t// 业务\n        return list;\n    }\n}\n```\n\n`BootProviderApplication`启动类需要写上 **@EnableDubbo** 注解以开启基于注解的Dubbo功能：\n\n```java\n@EnableDubbo //开启基于注解的dubbo功能\n@SpringBootApplication\npublic class BootProviderApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(BootProviderApplication.class, args);\n    }\n}\n```\n\n### 服务消费者模块\n\n导入Dubbo的场景依赖（同上文）。\n\n创建`application.properties`配置：\n\n```java\nserver.port=8081\ndubbo.application.name=boot-order-service-consumer\ndubbo.registry.address=zookeeper://127.0.0.1:2181\n\n# 连接监控中心 注册中心协议\ndubbo.monitor.protocol=registry\n```\n\n改写配置版中的`OrderServiceImpl`，在其内的`UserService`上添加 **@DubboReference** 注解以引用远程提供者服务：\n\n```java\n@Service\npublic class OrderServiceImpl implements OrderService {\n\n    @DubboReference //引用远程提供者服务\n    UserService userService;\n\n    public List<UserAddress> initOrder(String userID) {\n        //查询用户的收货地址\n        List<UserAddress> userAddressList = userService.getUserAddressList(userID);\n\n        System.out.println(\"当前接收到的userId=> \"+userID);\n        System.out.println(\"**********\");\n        System.out.println(\"查询到的所有地址为：\");\n        for (UserAddress userAddress : userAddressList) {\n            //打印远程服务地址的信息\n            System.out.println(userAddress.getUserAddress());\n        }\n        return userAddressList;\n    }\n}\n```\n\n创建`OrderController`控制器：\n\n```java\n@Controller\npublic class OrderController {\n    @Autowired\n    OrderService orderService;\n\n    @RequestMapping(\"/initOrder\")\n    @ResponseBody\n    public List<UserAddress> initOrder(@RequestParam(\"uid\")String userId) {\n        return orderService.initOrder(userId);\n    }\n}\n```\n\n创建`BootConsumerApplication`启动类，使用**@EnableDubbo**注解开启Dubbo功能：\n\n``` java\n@EnableDubbo //开启基于注解的dubbo功能\n@SpringBootApplication\npublic class BootConsumerApplication {\n    public static void main(String[] args){\n        SpringApplication.run(BootConsumerApplication.class,args);\n    }\n}\n```\n\n至此，Duboo的Spring Boot整合配置完成。\n\n## Dubbo 配置\n\n### 配置优先级原则\n\n- JVM 启动 `-D 参数` 优先，这样可以使用户在部署和启动时进行参数重写，比如在启动时需改变协议的端口。\n- XML次之，如果在 XML中有配置，则 `dubbo.properties` 中的相应配置项无效。\n- Properties 最后，相当于缺省值，只有 XML 没有配置时，`dubbo.properties` 的相应配置项才会生效，通常用于共享公共配置，比如应用名。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612152343133.png)\n\n**Dubbo推荐在Provider上尽量多配置Consumer端属性**：\n\n1. 作为服务的提供者，比服务使用方更清楚服务性能参数，如调用的超时时间，合理的重试次数，等等\n2. **在Provider配置后，Consumer不配置则会使用Provider的配置值，即Provider配置可以作为Consumer的缺省值**。否则，Consumer会使用Consumer端的全局设置，这对于Provider是不可控的，并且往往是不合理的\n\n配置的覆盖规则：\n\n1. **方法级别**配置别优于**接口级别**，即小Scope优先\n2. Consumer端配置优于Provider配置优于全局配置\n3. 最后是Dubbo Hard Code的配置值（见配置文档）\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612160853853.png)\n\n### 启动时检查\n\nDubbo缺省会在启动时检查依赖的服务是否可用，**不可用时会抛出异常**，阻止 Spring 初始化完成，以便上线时，能及早发现问题，默认 `check=\"true\"`。\n\n可以通过 `check=\"false\"` 关闭检查，比如，测试时有些服务不关心，或者出现了循环依赖，必须有一方先启动。另外，如果 Spring 容器是懒加载的，或者通过 API 编程延迟引用服务，请关闭 `check`，否则服务临时不可用时，会抛出异常，拿到 null 引用，如果 `check=\"false\"`，**总是会返回引用**，当服务恢复时，能自动连上。\n\n以`order-service-consumer`消费者为例，在`consumer.xml`中添加配置\n\n``` xml\n<!--配置当前消费者的统一规则,当前所有的服务都不启动时检查-->\n<dubbo:consumer check=\"false\"></dubbo:consumer>\n```\n\n添加后，**即使服务提供者不启动，启动当前的消费者，也不会出现错误**，否则必须先开启服务提供者，才能正常开启服务消费者。\n\n### 超时和重试次数配置\n\n``` xml\n<!-- 全局超时配置，默认是1000ms -->\n<dubbo:provider timeout=\"5000\" />\n\n<!-- 指定接口以及特定方法超时配置，若远程调用失败再进行3次尝试 -->\n<dubbo:provider interface=\"com.zhao.BarService\" timeout=\"2000\">\n    <dubbo:method name=\"sayHello\" timeout=\"3000\" retries=\"3\"/>\n</dubbo:provider>\n```\n\n### 本地存根\n\n远程服务后，**客户端通常只剩下接口**，而**实现全在服务器端**，但提供方有些时候想在客户端也执行部分逻辑，比如：做 ThreadLocal 缓存，提前验证参数，调用失败后伪造容错数据等等，此时就需要在 API 中带上 Stub，**客户端生成 Proxy 代理实例，会把 Proxy 通过构造函数传给 Stub**，然后把 Stub 暴露给用户，Stub 可以决定要不要去调 Proxy。\n\n![image-20210811205943858](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210811205943858.png)\n\n过程：\n\n- 本地引用**XxxService**接口，该接口在本地没有实现类，只在远程Provider模块内有实现类。本地并无法直接调用该接口的实现类方法，只能远程调用。\n- 在本地创建**XxxService**接口的本地存根**XxxServiceStub**，该类实现了**XxxService**接口，并在配置文件中添加了相应配置。\n- Dubbo将在其构造方法中自动传入**XxxServiceProxy**代理对象，此时本地存根**XxxServiceStub**即可使用该代理对象**远程调用**Provider模块的**XxxServiceImpl**里的方法。\n\n使用本地存根（stub）技术可以在本模块中获取到远程模块的某个实现类对象，从而在本地调用该远程模块实现类的对象，进行一定的操作。\n\n添加哪个类为存根Stub：\n\n``` xml\n<dubbo:reference interface=\"com.zhao.gmail.service.UserService\" id=\"userService\" stub=\"com.zhao.gmall.service.impl.UserServiceStub\"></dubbo:reference>\n```\n\n该对象的构造函数需要带上UserService远程接口的Proxy代理对象，由Dubbo自动传入\n\n\n``` java\nclass UserServiceStub implements UserService {\n    private UserService userService; // 本地只有该接口，没有其实现类\n\n    // 传入的是userService远程接口的Proxy代理对象，由Dubbo自动传入\n    public UserServiceStub(UserService userService) {\n        super();\n        // 此时即可获得远程接口的代理对象，可以在本地调用该对象的方法\n        this.userService = userService\n    }\n\n    @Override\n    public List<UserAddress> getUserAddressList(String userId) {\n        // 此代码在客户端执行, 你可以在客户端做ThreadLocal本地缓存，或预先验证参数是否合法，等等\n        try {\n            return this.userService.getUserAddressList(userId); \n        } catch (Exception e) {\n            // 你可以容错，可以做任何AOP拦截事项\n            return \"容错数据\";\n        }\n    }\n}\n```\n\n### 多版本控制\n\n服务提供者若有多个不同版本的服务类，可以指定消费端使用不同的版本：\n\n![image-20210811202831736](/images/%E3%80%90Dubbo%E3%80%91Dubbo/image-20210811202831736.png)\n\n服务消费者调用时，可自由配置版本\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612163603598.png)\n\n## Dubbo 高可用\n\n### ZooKeeper 宕机与 Dubbo 直连\n\n当ZooKeeper注册中心宕机时，仍然可以使用Dubbo暴露的服务。原因：\n\n- **监控中心宕掉**不影响使用，只是丢失部分采样数据\n- **数据库宕掉**后，注册中心仍能通过**缓存**提供服务列表查询，但不能注册新服务\n- 注册中心对等**集群**，任意一台宕掉后，将**自动切换到另一台**\n- **注册中心全部宕掉后，服务提供者和服务消费者仍能通过==本地缓存==通讯**（本地缓存了远程服务的ip端口号等信息，就算没有了注册中心，也可以直接使用ip和端口号与远程服务进行通讯）\n- 服务提供者无状态，任意一台宕掉后，不影响使用\n- 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复\n\n高可用：通过设计，减少系统不能提供服务的时间。\n\n### 集群下 Dubbo 负载均衡配置\n\nDubbo提供了多种集群负载均衡策略，缺省为 `random`： 随机调用。共有如下四种策略：\n\n- **Random LoadBalance**：基于权重的随机负载均衡机制\n- **RoundRobin LoadBalance**： 基于权重的轮询负载均衡机制\n- **LeastActive LoadBalance**： 最少活跃数负载均衡机制\n- **ConsistentHash LoadBalance**： 一致性Hash负载均衡机制\n\n负载均衡配置方法：\n\n```xml\n<dubbo:service interface=\"...\" loadbalance=\"roundrobin\" />\n```\n\n详细介绍：\n\n**Random LoadBalance 基于权重的随机负载均衡机制**\n\n随机，按权重设置随机概率。 调用量越大分布越均匀，而且按概率使用权重后也比较均匀，有利于动态调整提供者权重。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612180908789.png)\n\n**RoundRobin LoadBalance 基于权重的轮询负载均衡机制**\n\n轮循，按公约后的权重设置轮循比率。 存在慢的提供者累积请求的问题，比如：第二台机器很慢，但没挂，当请求调到第二台时就卡在那，久而久之，所有请求都卡在调到第二台上。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612180928170.png)\n\n**LeastActive LoadBalance 最少活跃数负载均衡机制**\n\n最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。 使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612180951468.png)\n\n**ConsistentHash LoadBalance 一致性Hash负载均衡机制**\n\n一致性 Hash，**相同参数的请求总是发到同一提供者**。 当某一台提供者挂时，原本发往该提供者的请求，基于虚拟节点，平摊到其它提供者，不会引起剧烈变动。\n\n![img](/images/%E3%80%90Dubbo%E3%80%91Dubbo/20200612181007825.png)\n\n算法参见：http://en.wikipedia.org/wiki/Consistent_hashing 。缺省只对第一个参数 Hash，如果要修改，请配置：\n\n```xml\n<dubbo:parameter key=\"hash.arguments\" value=\"0,1\" /> \n```\n\n缺省用 160 份虚拟节点，如果要修改，请配置：\n\n```xml\n<dubbo:parameter key=\"hash.nodes\" value=\"320\" />\n```\n\n### 服务降级\n\n服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的**当不处理或换种简单的方式处理**，从而释放服务器资源以保证核心交易正常运作或高效运作。\n\n可以通过服务降级功能临时屏蔽某个出错的非关键服务，并定义降级后的返回策略。向注册中心写入动态配置覆盖规则：\n\n``` java\nRegistryFactory registryFactory = ExtensionLoader.getExtensionLoader(RegistryFactory.class).getAdaptiveExtension();\nRegistry registry = registryFactory.getRegistry(URL.valueOf(\"zookeeper://10.20.153.10:2181\"));\nregistry.register(URL.valueOf(\"override://0.0.0.0/com.foo.BarService?category=configurators&dynamic=false&application=foo&mock=force:return+null\"));\n```\n\n其中两种服务降级方式：\n\n- `mock=force:return+null`（强制返回null)）表示消费方对该服务的方法调用**都直接返回null值**，不发起远程调用。用来屏蔽不重要服务**不可用时**对调用方的影响。\n-  `mock=fail:return+null` （失败才返回null）表示消费方对该服务的方法调用在**失败后再返回null值**，不抛异常。用来容忍不重要服务**不稳定时**对调用方的影响。\n\n### 集群服务容错\n\n在服务调用失败时，Dubbo提供了多种容错方案，缺省为`failover`：失败重试。\n\n集群服务容错模式：\n\n- **Failover Cluster**：**失败自动切换**，当出现失败，**重试其它服务器**。通常用于读操作，但重试会带来更长延迟。可通过 `retries=\"2\"` 来设置重试次数（不含第一次）。\n- **Failfast Cluster**：**快速失败**，只发起一次调用，**失败立即报错**。通常用于**非幂等性**的写操作，比如新增记录。\n- **Failsafe Cluster**：**失败安全**，出现异常时，**直接忽略**。通常用于写入审计日志等操作。\n- **Failback Cluster**：**失败自动恢复**，后台记录失败请求，**定时重发**。通常用于消息通知操作。\n- **Forking Cluster**：**并行**调用多个服务器，**只要一个成功即返回**。通常用于**实时性要求较高的读操作**，但需要浪费更多服务资源。可通过 `forks=\"2\"` 来设置最大并行数。\n- **Broadcast Cluster**：**广播调用所有提供者**，逐个调用，任意一台报错则报错。通常用于**通知**所有提供者更新缓存或日志等本地资源信息。\n\n集群服务模式配置：\n\n\n``` xml\n<dubbo:service cluster=\"failsafe\" />\n或\n<dubbo:reference cluster=\"failsafe\" />\n```\n\n### 整合Hystrix\n\n服务熔断错处理配置参考=> https://www.cnblogs.com/xc-xinxue/p/12459861.html\n\nHystrix旨在通过控制那些访问远程系统、服务和第三方库的节点，从而对延迟和故障提供更强大的容错能力。Hystrix具备拥有回退机制和断路器功能的线程和信号隔离，请求缓存和请求打包，以及监控和配置等功能。\n\n配置`spring-cloud-starter-netflix-hystrix`。Spring Boot官方提供了对Hystrix的集成，直接在`pom.xml`里加入依赖：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-hystrix</artifactId>\n    <version>1.4.4.RELEASE</version>\n</dependency>\n```\n\n然后在`ProviderApplication`类上增加 **@EnableHystrix** 来启用hystrix starter：\n\n``` java\n@SpringBootApplication\n@EnableHystrix // 开启服务容错功能\npublic class ProviderApplication {\n\t//...启动方法\n}\n```\n\n**配置Provider端**\n\n在Dubbo的Provider上增加 **@HystrixCommand** 配置，这样子调用就会经过Hystrix代理。\n\n``` java\n@Service(version = \"1.0.0\")\npublic class HelloServiceImpl implements HelloService {\n    @HystrixCommand(commandProperties = {\n        @HystrixProperty(name = \"circuitBreaker.requestVolumeThreshold\", value = \"10\"),\n        @HystrixProperty(name = \"execution.isolation.thread.timeoutInMilliseconds\", value = \"2000\") })\n    @Override\n    public String sayHello(String name) {\n        // System.out.println(\"async provider received: \" + name);\n        // return \"annotation: hello, \" + name;\n        throw new RuntimeException(\"Exception to show hystrix enabled.\");\n    }\n}\n```\n\n**配置Consumer端**\n\n对于Consumer端，则可以增加一层method调用，并在method上配置 **@HystrixCommand** 。当调用出错时，会走到 `fallbackMethod = \"reliable\"` 的调用里。\n\n``` java\n@Reference(version = \"1.0.0\")\nprivate HelloService demoService;\n\n@HystrixCommand(fallbackMethod = \"reliable\")\npublic String doSayHello(String name) {\n    return demoService.sayHello(name);\n}\npublic String reliable(String name) {\n    return \"hystrix fallback value\";\n}\n```\n\n","tags":["Dubbo"],"categories":["Dubbo"]},{"title":"【Nginx】Nginx","url":"/2021/07/26/【Nginx】Nginx/","content":"\n![nginx](/images/%E3%80%90Nginx%E3%80%91Nginx/nginx.png)\n\n## Nginx 简介\n\n> Nginx 1.8.0 下载：https://nginx.org/ ，在Linux上安装见 [Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\nNginx 是高性能的 HTTP 和反向代理的服务器，处理高并发能力是十分强大的，能经受高负载的考验，有报告表明能支持高达 50,000 个并发连接数。\n\n\nNginx 能用来：\n\n- 反向代理\n- 负载均衡\n- 动静分离\n\n## Nginx 常用命令\n\n1. 进入 Nginx 的目录 `cd /usr/local/nginx/sbin`\n2. 查看 Nginx 版本号：\n\n```sh\n./nginx -v\n```\n\n3. 启动 Nginx（注意在防火墙开放相应的端口号80）：\n\n```sh\n./nginx\n```\n\n4. 停止 Nginx\n\n```sh\n./nginx -s stop\n```\n\n5. 热部署重新加载 Nginx（修改配置文件后需要重新加载）\n\n```sh\n./nginx -s reload\n```\n\n<!-- More -->\n\n> https://www.bilibili.com/video/av68136734\n\n## Nginx 配置文件\n\nNginx 配置文件位置： `/usr/local/nginx/conf/nginx.conf`\n\n配置文件包含三部分内容\n\n- 全局块：配置服务器整体运行的配置指令，比如 `worker_processes 1;` 处理并发数的配置 \n- `events` 块：影响 Nginx 服务器与用户的网络连接，比如 `worker_connections 1024;` 支持的最大连接数为1024\n- `http` 块：是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。包含 `http` 全局块和 `server` 块\n\n### 全局块：配置服务器整体运行的配置指令\n\n主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 服务器的用户（组）、允许生成的 `worker process` 数（工作进程数），进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。\n\n`worker_processes` （工作进程数）是 Nginx 服务器**并发处理服务**的关键配置，值越大，可以支持的**并发处理量**也越多，但是会受到硬件、软件等设备的制约，常设置为cpu核数：\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029102802614-510328292.png)\n\n### events 块：影响 Nginx 服务器与用户的网络连接\n\n`events` 块涉及的指令主要影响**Nginx 服务器与用户的网络连接**，常用的设置包括是否开启对多 `work_process`下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 `word_process` 可以同时支持的最大连接数等。\n\n**`work_process 1024` 表示支持的最大并发连接数为 1024**\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029102827884-232471630.png)\n\n### http 块\n\nNginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是：http 块也可以包括 **http 全局块**、**server 块**。\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029102837788-914776640.png)\n\n#### http 全局块\n\nhttp 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等：\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029102851922-1592334025.png)\n\n#### server 块\n\n这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。\n\n**每个 http 块可以包括多个 server 块，而每个 server 块就相当于一个虚拟主机。**而每个 server 块也分为全局 server 块，以及**可以同时包含多个 locaton 块**。\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029102901346-2016909563.png)\n\n**全局 server 块**最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。\n\n一个 server 块可以配置多个 location 块。这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是 IP 别名）之外的字符串（例如前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。\n\n## Nginx 反向代理配置\n\n- 修改配置文件 `server` 块的 `server_name` 为本机的ip地址\n- 在 `location` 里添加 `proxy_pass` 代理路径（即要跳转到的路径）\n\n![image-20210831214700318](/images/%E3%80%90Nginx%E3%80%91Nginx/image-20210831214700318.png)\n\n### 反向代理案例\n\n- 访问 `http://192.168.17.129:9001/edu/` 直接跳转到 `127.0.0.1:8080` \n- 访问 `http:// 192.168.17.129:9001/vod/` 直接跳转到 `127.0.0.1:8081`\n\n准备工作：\n\n- 准备两个 Tomcat 服务器，一个 8080 端口，一个 8081 端口\n- 创建文件夹和测试页面\n\n修改配置文件，监听Nginx所在服务器ip的9001端口，将匹配正则表达`/edu/`和`/vod/`的请求分别映射到本机Tomcat的8080和8081端口\n\n![image-20210831215100428](/images/%E3%80%90Nginx%E3%80%91Nginx/image-20210831215100428.png)\n\n## Nginx 负载均衡配置\n\n### 准备工作\n\n- 准备两台 Tomcat 服务器，一台 8080，一台 8081\n- 在两台 Tomcat 里面 `webapps` 目录中，创建名称是 `edu` 文件夹，在 `edu` 文件夹中创建页面 a.html，用于测试\n\n### 在 Nginx 的配置文件中进行负载均衡的配置\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103257021-406101154.png)\n\n### Nginx 分配服务器策略\n\n#### 第一种 轮询（默认）\n\n每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。\n\n#### 第二种 weight\n\nweight 代表权重默认为 1，权重越高被分配的客户端越多\n\n ![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103434709-133983538.png)\n\n#### 第三种 ip_hash\n\n每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器\n\n ![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103440910-1253898902.png)\n\n#### 第四种 fair（第三方）\n\n按后端服务器的响应时间来分配请求，响应时间短的优先分配。\n\n ![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103448391-1932086344.png)\n\n## Nginx 动静分离配置\n\nNginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。动静分离从目前实现角度来讲大致分为两种，一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案；另外一种方法就是动态跟静态文件混合在一起发布，通过 Nginx 来分开。\n\n通过 `location` 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用 Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重新下载，返回状态码 200。\n\n### 准备工作\n\n在 liunx 系统中准备静态资源，用于进行访问：\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103551408-155195568.png)\n\n### 具体配置\n\n在 Nginx 配置文件中进行配置，重点是修改 `location` 的 `root` 目录，令其指向存放静态资源的根目录，这样访问浏览器里的 http://192.168.17.129/www/image/01.jpg 就会映射到服务器中的 `/data/image/01.jpg` 文件：\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103601180-712857275.png)\n\n### 测试\n\n浏览器中输入地址 http://192.168.17.129/image/01.jpg\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103613911-2017185401.png)\n\n配置文件配置了 `autoindex on`，访问`image`路径时会展示出`image`目录下的所有文件，点击即可下载。\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103620555-1775332206.png)\n\n### 总结\n\n> https://zhuanlan.zhihu.com/p/55698543\n\n```\nserver {\n    location / {\n        root /data/www/;\n    }\n\n    location /images/ {\n        alias /data/;\n    }\n}\n```\n\n- root 响应的路径：**root 后配置的路径 + 完整访问路径（完整的location配置路径+静态文件）**\n- alias 响应的路径：**alias 后配置路径 + 静态文件（去除location中配置的路径）**\n\n> 使用alias时目录名后面一定要加`“/”`。一般情况下，在 location / 中配置root，在 location /other 中配置alias\n\n示例：上述配置下，请求 http://servername/images/figure1.png 分别访问到的资源路径：\n\n- root：`/data/www/images/figure1.png`\n- alias：`/data/figur1.png`\n\n即，alias 将请求路径中符合 location 的前缀给替换成了 `/data`；而 root 则不会进行替换，直接拼接到 `/data/www` 中。\n\n注意，一旦配置了 `location /`，则 `root /data/www/` 目录下的所有资源文件都可以通过 http://servername/xxx 的形式访问到，因此放在该目录下的文件不需要额外配置路由规则也可直接被外界访问。\n\n\n\n## Nginx 高可用集群\n\n### 准备工作\n\n- 需要两台服务器 `192.168.17.129` 和 `192.168.17.131` \n- 在两台服务器安装 nginx \n- 在两台服务器安装 keepalived\n\n1. 安装 keepalived：\n\n```sh\nyum install keepalived –y\n```\n\n2. 安装之后，在 `/etc/keepalived/`生成文件 `keepalived.conf`\n\n### 完成高可用配置（主从配置）\n\n1. 修改`/etc/keepalived/keepalivec.conf` 配置文件\n\n```\nglobal_defs {\n\tnotification_email {\n\t\tacassen@firewall.loc\n\t\tfailover@firewall.loc\n\t\tsysadmin@firewall.loc\n\t}\n\tnotification_email_from Alexandre.Cassen@firewall.loc\n\tsmtp_server 192.168.17.129 # 本机ip\n\tsmtp_connect_timeout 30\n\trouter_id LVS_DEVEL # 路由id，通过该id可以访问到当前主机，该名字存储在/etc/host文件中，可以添加一个自定义的名字\n}\n\nvrrp_script chk_http_port {\n\tscript \"/usr/local/src/nginx_check.sh\"\n\tinterval 2 #（检测脚本执行的间隔）\n\tweight 2   # 权重：若当前脚本里的判断条件成立，把当前主机权重+2\n}\n\n# 设置虚拟ip信息\nvrrp_instance VI_1 {\n\tstate BACKUP          # 备份服务器上将 MASTER 改为 BACKUP\n\tinterface ens33       # 设置将虚拟ip绑定到哪个网卡\n\tvirtual_router_id 51  # 主、备机的 virtual_router_id 必须相同\n\tpriority 90           # 主、备机取不同的优先级，主机值较大，备份机值较小\n\tadvert_int 1          # 每隔一秒发送一个请求查看当前主机是否存活\n\t\n\t# 权限校验方式和密码\n\tauthentication {\n\t\tauth_type PASS\n\t\tauth_pass 1111\n\t}\n\t\t\n\tvirtual_ipaddress {\n\t\t192.168.17.50 # VRRP H 虚拟地址\n\t}\n}\n```\n\n2. 在`/usr/local/src` 添加检测脚本\n\n```sh\n#!/bin/bash\nA=`ps -C nginx –no-header |wc -l`\nif [ $A -eq 0 ];then\n /usr/local/nginx/sbin/nginx\n sleep 2\n if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then\n killall keepalived\n fi\nfi\n```\n\n3. 把两台服务器上 nginx 和 keepalived 启动\n\n```\n./nginx\nsystemctl start keepalived.service\n```\n\n### 测试\n\n在浏览器地址栏输入 **虚拟 ip 地址** 192.168.17.50，发现能正常访问，当关掉一台Nignx服务器后再访问仍然能正常访问\n\n![image-20210902191355104](/images/%E3%80%90Nginx%E3%80%91Nginx/image-20210902191355104.png)\n\n## Nginx 原理\n\n### Master 和 worker\n\nMaster进程为主进程，用于协调管理worker进程，本身并不处理业务。\n\n ![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103710873-640599395.png)\n\n ![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103717881-58535625.png)\n\n### worker 如何进行工作的\n\n当客户端发来请求时，Master进程将该请求告诉所有能够工作的worker进程，之后多个worker进程争抢该请求，抢到的worker进程将处理该请求，同时woker进程采用多路复用技术，开启唯一线程非阻塞地处理请求。\n\n![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103730680-1429030716.png)\n\n### 一个 Master 和多个 woker 有好处\n\n- 可以使用 `nginx –s reload` 热部署，利用 Nginx 进行热部署操作，当收到请求时，其他不工作的先更新配置，正在工作的进程暂时不更新，当其工作完毕后再更新。\n- 每个 woker 是独立的进程，如果有其中的一个 woker 出现问题，其他 woker 独立的，继续进行争抢，实现请求过程，不会造成服务中断\n\n### 设置多少个 woker 合适\n\nworker 数和服务器的 cpu 数相等是最为适宜的\n\n### 连接数 worker_connection\n\n问题一：发送请求，占用了 woker 的几个连接数？\n\n答案：2 或者 4 个\n\n ![img](/images/%E3%80%90Nginx%E3%80%91Nginx/1455597-20191029103745507-149451607.png)\n\n问题二：Nginx 有一个 Master，有四个 woker，每个 woker 支持最大的连接数 1024，支持的最大并发数是多少？\n\n- 普通的静态访问最大并发数是： `worker_connections * worker_processes /2`\n- 而如果是 HTTP 作为反向代理来说，最大并发数量应该是 `worker_connections * worker_processes/4`\n\n\n\n\n\n\n\n\n\n","tags":["Linux","Nginx"],"categories":["Linux","Nginx"]},{"title":"【Linux】Linux 常用命令","url":"/2021/07/21/【Linux】Linux常用命令/","content":"\n## Linux 和 Unix\n\n>  https://www.zhihu.com/question/24217234/answer/360949879\n\nUnix于1969年由贝尔实验室开发出来，使用至今已变更了很多个版本。目前主流的Unix系统有三种，分别是AIX、HP-UX、Solaris，这些Unix系统互不兼容。\n\nLinux于1991年由芬兰大学生Linus开发出来，是一个类Unix系统，但是其代码不源自任何Unix版本，完全不是Unix的一个分支，而是一个**开源版**的模仿。\n\n> 安装Linux虚拟机教程：https://blog.csdn.net/qq_41571900/article/details/84728480; https://mp.weixin.qq.com/s/onVwwEQ1DAwbvK7qS2YNxg\n\n[Linux 开发环境配置文档](https://yuyun-zhao.github.io/documents/linux开发环境配置.pdf)\n\n## Linux 目录结构\n\nlinux的文件系统是采用**级层式的树状**目录结构，在此结构中的最上层是根目录**“ / ”**，然后在此目录下再创建其他的目录。在Linux世界里，一切皆文件。\n\n![image-20210721140508417](/images/%E3%80%90Linux%E3%80%91Linux%E6%8C%87%E4%BB%A4/image-20210721140508417.png)\n\n- **/bin** (/usr/bin、/usr/local/bin)：是Binary的缩写，这个目录存放着最经常使用的**命令**\n- /sbin (/usr/sbin、/usr/local/sbin)：Super User Binary的缩写，这里存放的是**系统管理员**使用的系统管理程序\n- **/home**：存放**普通用户**的主目录，在Linux中每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的\n- **/root**：**系统管理员**目录，也称作超级权限者的用户主目录\n- /lib：系统开机所需要最基本的**动态连接共享库 .so**，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库\n- /lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件\n- **/etc**：所有的系统管理所需要的**配置文件和子目录 my.conf**\n- **/usr**：Unix System Resource的缩写，存放**Unix系统的资源**。这是一个非常重要的目录，用户的很多**应用程序和文件**都放在这个目录下，类似于windows下的program files目录\n- **/boot**：存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件\n- /proc：这个目录是一个虚拟的目录，它是系统内存的映射，访问这个目录来获取系统信息\n- /srv：service缩写，该目录存放一些服务启动之后需要提取的数据\n- /sys：这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统\n- /tmp：这个目录是用来存放一些临时文件的\n- /dev：类似于windows的设备管理器，把所有的**硬件**用文件的形式存储\n- **/media**：linux系统会自动识别一些**设备**，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。\n- **/mnt**：系统提供该目录是为了让用户**临时挂载**别的文件系统的，我们可以将外部的存储挂载在/mnt/上，然后进入该目录就可以查看里的内容了。比如共享文件夹 `D:/myshare`\n- /opt：这是存放应用程序**压缩包**的目录。如安装ORACLE数据库的压缩包就可放到该目录下。默认为空。\n- **/usr/local**：主要存放那些**手动安装的软件**的目录。一般是通过**编译源码**或解压压缩包的方式安装的程序。例如安装JDK环境。\n- **/var**：这个目录中存放着在不断扩充着的东西，习惯将经常被修改的文件和目录放在这个目录下。包括各种日志文件。\n- /selinux [security-enhanced linux]：SELinux是一种安全子系统，它能控制程序只能访问特定文件。\n\n<!-- More -->\n\n## 硬链接和软链接\n\n> https://www.huaweicloud.com/articles/e2aa9d7612d1446629d95ced9b16a1d5.html\n\n- **硬链接**：新建的文件是已经存在的文件的一个别名，当原文件删除时，新建的文件仍然可以使用\n- **软链接**：也称为**符号链接**，新建的文件以“路径”的形式来表示另一个文件，和Windows的快捷方式十分相似，新建的软链接可以指向不存在的文件\n\n硬链接和原来的文件没有什么区别，而且共享一个 inode 号（文件在文件系统上的唯一标识）；而软链接不共享 inode，也可以说是个特殊的 inode，所以和原来的 inode 有区别。若原文件删除了，则该软连接则不可以访问，而硬连接则是可以的。由于符号链接的特性，导致其可以跨越磁盘分区，但硬链接不具备这个特性。\n\n创建硬链接：\n\n``` bash\n[root@localhost root] touch f1  #创建一个测试文件f1\n\n[root@localhost root] ln f1 f2  #创建f1的一个硬链接文件f2\n```\n\n创建软链接\n\n``` bash\n[root@localhost root] ln -s f1 f3  #创建f1的一个符号连接文件f3\n```\n\n## 用户管理\n\n增加用户\n\n``` bash\n[root@localhost root] useradd -g 用户组名 用户名\n```\n\n查看用户信息\n\n``` bash\n[root@localhost root] id 用户名\n```\n\n增加组\n\n``` bash\n[root@localhost root] groupadd 用户组名\n```\n\n修改用户密码\n\n```bash\n[root@localhost root] passwd 用户名\n```\n\n**/etc/passwd**：用户（user）的配置文件，记录用户的各种信息。每行的含义：用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell\n\n![image-20210722210112194](/images/%E3%80%90Linux%E3%80%91Linux%E6%8C%87%E4%BB%A4/image-20210722210112194.png)\n\n\n\n**/etc/group**：组(group)的配置文件，记录Linux包含的组的信息。每行含义：组名:口令:组标识号:组内用户列表\n\n![image-20210722210316408](/images/%E3%80%90Linux%E3%80%91Linux%E6%8C%87%E4%BB%A4/image-20210722210316408.png)\n\n**/etc/shadow**：口令的配置文件。每行的含义：登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n\n![image-20210722210303001](/images/%E3%80%90Linux%E3%80%91Linux%E6%8C%87%E4%BB%A4/image-20210722210303001.png)\n\n## 组管理\n\n在linux中的每个用户必须属于一个组，不能独立于组外。在linux中每个文件有所有者、所在组、其它组的概念。\n\n修改文件所有者（chown：change owner）\n\n``` bash\n[root@localhost root] chown [-R] 用户名 文件名/文件目录名\n```\n\n修改文件所在组（chgrp：change group）\n\n``` bash\n[root@localhost root] chgrp [-R] 组名 文件名/文件目录名\n```\n\n改变用户所在组（usermod：user modify）\n\n``` bash\n[root@localhost root] usermod –g 组名 用户名\n\n[root@localhost root] usermod –d 目录名 用户名 改变该用户登陆的初始目录。\n```\n\n参数选项\n\n- -R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改。\n\n## 权限\n\n> https://www.runoob.com/linux/linux-file-attr-permission.html\n\n![image-20210724193608190](/images/%E3%80%90Linux%E3%80%91Linux/image-20210724193608190.png)\n\n在 Linux 中我们可以使用 **ll** 或者 **ls –l** 命令来显示一个文件的属性以及文件所属的用户和组，如：\n\n```bash\n[root@localhost root] ls -l\ntotal 64\ndr-xr-xr-x   2 root root 4096 Dec 14  2012 bin\ndr-xr-xr-x   4 root root 4096 Apr 19  2012 boot\n……\n```\n\n实例中，**bin** 文件的第一个属性用 **d** 表示。**d** 在 Linux 中代表该文件是一个目录文件。\n\n在 Linux 中第一个字符代表这个文件是目录、文件或链接文件等等。\n\n- 当为 **d** 则是目录\n- 当为 **-** 则是文件；\n- 若是 **l** 则表示为链接文档(link file)；\n- 若是 **b** 则表示为装置文件里面的可供储存的接口设备(可随机存取装置)；\n- 若是 **c** 则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。\n\n接下来的字符中，以三个为一组，且均为 **rwx** 的三个参数的组合。其中， **r** 代表可读(read)、 **w** 代表可写(write)、 **x** 代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号 **-** 而已。\n\n每个文件的属性由左边第一部分的 10 个字符来确定（如下图）：\n\n![image-20210724193922713](/images/%E3%80%90Linux%E3%80%91Linux/image-20210724193922713.png)\n\n从左至右用 **0-9** 这些数字来表示。\n\n第0位确定文件类型，第1-3位确定属主（该文件的所有者）拥有该文件的权限。第4-6位确定属组（所有者的同组用户）拥有该文件的权限，第7-9位确定其他用户拥有该文件的权限。\n\n其中，第 1、4、7位表示读权限，如果用 **r** 字符表示，则有读权限，如果用 **-** 字符表示，则没有读权限；第2、5、8位表示写权限，如果用 **w** 字符表示，则有写权限，如果用 **-** 字符表示没有写权限；第3、6、9位表示可执行权限，如果用 **x** 字符表示，则有执行权限，如果用 **-** 字符表示，则没有执行权限。\n\n**rwx作用到文件**\n\n- [ r ] 代表可读(read): 可以读取,查看\n- [ w ] 代表可写(write): 可以修改,但是不代表可以删除该文件,删除一个文件的**前提条件**是对该文件所在的**目录**有写权限，才能删除该文件.\n- [ x ] 代表可执行(execute):**可以被执行**\n\n**rwx作用到目录**\n\n- [ r ] 代表可读(read): 可以读取，ls查看目录内容\n- [ w ] 代表可写(write): 可以修改,**目录内创建+删除+重命名目录**\n- [ x ] 代表可执行(execute):**可以进入该目录**\n\nrwx作用到文件和目录上的区别：\n\n- 对[ r ]来说，二者都是读取内容；\n- 对[ w ]来说，若文件没有该权限，则无法修改和删除该文件；若目录没有该权限，则无法在该目录内创建和删除文件，也无法重命名；\n- 对[ x ]来说，若文件没有该权限，则**无法被执行**；若目录没有该权限，则**无法进入该目录**\n\n### 权限相关指令\n\n修改权限：\n\nu: 所有者 g: 所有组 o: 其他人 a: 所有人(u、g、o的总和)\n\n``` bash\n[root@localhost root] chmod [-R] u=rwx,g=rx,0=x 文件目录名  # 给文件目录\n\n[root@localhost root] chmod o+w 文件目录名 # 给文件目录增加权限\n\n[root@localhost root] chmod u=rwx,g=rx,o=x 文件目录名\n# 上述命令等价于：\n[root@localhost root] chmod 751 文件目录名\n```\n\n-R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改\n\n## Linux 系统运行级别\n\n- 0 ：关机\n- 1 ：单用户模式，不需要输入密码【可用于找回丢失密码】\n- 2：多用户状态没有网络服务\n- **3：多用户状态有网络服务**\n- 4：系统未使用，保留给用户\n- **5：图形界面**\n- 6：系统重启\n\n常用运行级别是3和5 ，要修改默认的运行级别可改文件\n\n![image-20210722210529000](/images/%E3%80%90Linux%E3%80%91Linux%E6%8C%87%E4%BB%A4/image-20210722210529000.png)\n\n切换到指定的运行级别命令：\n\n```bash\n[root@localhost root] init [0~6]\n```\n\n使用案例：找回丢失的root密码？\n\n 思路：进入到**单用户模式**，修改root密码。因为进入单用户模式，root不需要密码就可以登录\n\n## 常用命令\n\n**man**：获得帮助信息\n\n``` bash\n[root@localhost root] man [命令或配置文件]\n```\n\n**help**：获得帮助信息\n\n``` bash\n[root@localhost root] help [命令]\n```\n\n#### 文件目录类\n\n**mkdir**：创建目录\n\n``` bash\n[root@localhost root] mkdir [选项] 要创建的目录\n```\n\n常用选项：`-p`  创建多级目录\n\n**rmdir**：删除空目录（只能删除空目录，如果目录下有内容时无法删除）\n\n``` bash\n[root@localhost root] rmdir [选项] 要删除的空目录\n```\n\n如果需要删除非空目录，需要使用`rm -rf` \n\n**rm**：移除文件或目录\n\n``` bash\n[root@localhost root] rm [选项] 要删除的文件或目录\n```\n\n常用选项：\n\n- `-r` ：递归删除整个文件夹\n- `-f `：强制删除不提示\n\n**mv**：移动文件与目录或重命名\n\n``` bash\n[root@localhost root] mv oldNameFile newNameFile (功能描述：重命名)\n\n[root@localhost root] mv /temp/movefile /targetFolder (功能描述：移动文件)\n```\n\n**touch**：创建空文件\n\n``` bash\n[root@localhost root] touch hello.java\n```\n\n**cp**：拷贝文件到指定目录\n\n``` bash\n[root@localhost root] cp [选项] /home/aaa.txt /home/dest/\n```\n\n常用选项：`-r`  递归复制整个文件夹\n\n#### 文件阅读类\n\n**cat**：查看文件内容（concatenate）。**cat** 只能浏览文件，而不能修改文件，为了浏览方便，一般会带上管道命令 | more\n\n``` bash\n[root@localhost root] cat [选项] 要查看的文件\n```\n\n常用选项：`-n`  显示行号\n\n**more**：是一个基于vi编辑器的文本过滤器，它以全屏幕的方式按页显示文本文件的内容。more指令中内置了若干快捷键\n\n> https://zhuanlan.zhihu.com/p/50383258\n\n``` bash\n[root@localhost root] more 要查看的文件\n```\n\n| 操作          | 功能说明                                |\n| ------------- | --------------------------------------- |\n| 空白键(space) | 代表向下翻一页；                        |\n| Enter         | 代表向下翻一行；                        |\n| /hello        | 查找文本中`hello`字段，按N查找下一个    |\n| q             | 代表立刻离开more ，不再显示该文件内容。 |\n| Ctrl+F        | 向下滚动一屏                            |\n| Ctrl+B        | 返回上一屏                              |\n| =             | 输出当前行的行号                        |\n| :f            | 输出文件名和当前行的行号                |\n\n**less**：用来分屏查看文件内容，它的功能与**more**指令类似，但是比**more**指令更加强大，支持各种显示终端。**less**指令在显示文件内容时，**并不是一次将整个文件加载之后才显示，而是根据显示需要加载内容，对于显示大型文件具有较高的效率**。\n\n``` bash\n[root@localhost root] less 要查看的文件\n```\n\n| 操作          | 功能说明                                                     |\n| ------------- | ------------------------------------------------------------ |\n| 空白键(space) | 向下翻一页；                                                 |\n| [pagedown]    | 向下翻动一页                                                 |\n| [pageup]      | 向上翻动一页；                                               |\n| q             | 代表立刻离开more ，不再显示该文件内容。                      |\n| /字串         | 向下搜寻『字串』的功能；n：向下查找；N：向上查找；下滚动一屏 |\n| ?字串         | 向上搜寻『字串』的功能；n：向上查找；N：向下查找；           |\n\n对比：\n\n- `more` – 传统且基础的分页阅读工具，仅支持向下翻页和有限次数的向上翻页。\n- `less` – 比 `more` 功能丰富，支持向下翻页和向上翻页，也支持文本搜索。在打开大文件的时候，比 `vi` 这类文本编辑器启动得更快。\n- `most` – 在上述两个工具功能的基础上，还加入了同时打开多个文件、同时锁定或滚动多个屏幕、分屏等等大量功能\n\n**head**：显示文件的开头部分内容，默认情况下head指令显示文件的前10行内容\n\n``` bash\n[root@localhost root] head -n 5 文件(功能描述：查看文件头5行内容，5可以是任意行数)\n```\n\n**tail**：输出文件中尾部的内容，默认情况下tail指令显示文件的后10行内容。\n\n``` bash\n[root@localhost root] tail 文件（功能描述：查看文件后10行内容）\n\n[root@localhost root] tail -n 5 文件（功能描述：查看文件后5行内容，5可以是任意行数）\n\n[root@localhost root] tail -f 文件（功能描述：实时追踪该文档的所有更新）\n```\n\n主要区别：\n\n- **cat**命令可以一次显示整个文件，如果文件比较大，使用不是很方便；\n- **more**命令可以让屏幕在显示满一屏幕时暂停，按空格往前翻页，按b往后翻页。\n- **less**命令也可以分页显示文件，和more命令的区别就在于：\n  - 支持上下键卷动屏幕、查找。\n  - 不需要在一开始就读取整个文件，**打开大文件时比more、vim更快**。\n- **head**命令用于查看文件的前n行。\n- **tail**命令用于查看文件的后n行。加上-f命令，查看在线日志非常方便，可以打印最新增加的日志。\n\n`>` 指令和 `>>` 指令\n\n- `>`：输出重定向（覆盖写）\n- `>>`：追加（不覆盖）\n\n``` bash\n[root@localhost root] ls -l > 文件（功能描述：列表的内容写入文件a.txt中（覆盖写））\n\n[root@localhost root] ls -al >> 文件（功能描述：列表的内容追加到文件aa.txt的末尾）\n\n[root@localhost root] cat 文件1 > 文件2（功能描述：将文件1的内容覆盖到文件2）\n\n[root@localhost root] echo \"内容\" >> 文件\n```\n\n**history**：查看已经执行过历史命令,也可以执行历史指令\n\n#### 搜索查找类\n\n**find**：\n\n从根目录开始搜索文件/目录\n\n``` bash\n[root@localhost root] find / -name file1\n```\n\n搜索用户user1的文件/目录\n\n``` bash\n[root@localhost root] find / -user user1\n```\n\n**locate**：\n\nlocate指令可以快速定位文件路径。locate指令利用事先建立的系统中所有文件名称及路径的locate数据库实现快速定位给定的文件。Locate指令无需遍历整个文件系统，查询速度较快。为了保证查询结果的准确度，管理员必须定期更新locate时刻。\n\n``` bash\n[root@localhost root] locate <关键词> \n```\n\n由于locate指令基于数据库进行查询，所以第一次运行前，必须使用**updatedb**指令创建locate数据库。\n\n**grep**：Global regular expression print。用于查找文件里符合条件的字符串。\n\n全局正则表达搜索：\n\n``` bash\n[root@localhost root] grep xxx hello.txt # 在⽂件hello.txt中查找关键词 xxx\n```\n\n**gzip/gunzip**：\n\n``` bash\n[root@localhost root] gzip 文件       # 压缩文件，只能将文件压缩为*.gz文件\n\n[root@localhost root] gunzip 文件.gz  # 解压缩文件命令\n```\n\n**zip/unzip**：\n\n``` bash\n[root@localhost root] zip xxx.zip file # 压缩⾄zip包\n\n[root@localhost root] zip -r xxx.zip file1 file2 dir1 # 将多个⽂件+⽬录压成zip包\n\n[root@localhost root] unzip XXX.zip  # 解压缩文件\n```\n\n**tar**：\n\ntar 指令是打包指令，最后打包后的文件是.tar.gz 的文件。\n\n| 选项 |        功能        |\n| :--: | :----------------: |\n|  -c  |  产生.tar打包文件  |\n|  -v  |    显示详细信息    |\n|  -f  | 指定压缩后的文件名 |\n|  -z  |    打包同时压缩    |\n|  -x  |    解包.tar文件    |\n\n```bash\n[root@localhost root] tar -cvf xxx.tar file1 file2 dir1 # 将多个⽂件+⽬录打tar包\n\n[root@localhost root] tar -tf xxx.tar # 查看tar包的内容\n\n[root@localhost root] tar -xvf xxx.tar # 解压tar包\n\n[root@localhost root] tar -xvf xxx.tar -C /dir # 将tar包解压⾄指定⽬录\n\n[root@localhost root] tar -cvfj xxx.tar.bz2 dir # 创建bz2压缩包\n\n[root@localhost root] tar -jxvf xxx.tar.bz2 # 解压bz2压缩包\n\n[root@localhost root] tar -cvfz xxx.tar.gz dir # 创建gzip压缩包\n\n[root@localhost root] tar -zxvf xxx.tar.gz # 解压gzip压缩包\n```\n\n#### 网络通讯类\n\n>  Telnet协议是[TCP/IP协议](https://baike.baidu.com/item/TCP%2FIP协议)族中的一员，是Internet远程登录服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程[主机](https://baike.baidu.com/item/主机/455151)工作的能力。在[终端](https://baike.baidu.com/item/终端/1903878)使用者的电脑上使用telnet程序，用它连接到[服务器](https://baike.baidu.com/item/服务器/100571)。[终端](https://baike.baidu.com/item/终端/1903878)使用者可以在telnet程序中输入命令，这些命令会在[服务器](https://baike.baidu.com/item/服务器/100571)上运行，就像直接在服务器的控制台上输入一样。可以在本地就能控制[服务器](https://baike.baidu.com/item/服务器/100571)。要开始一个telnet会话，必须输入用户名和密码来登录[服务器](https://baike.baidu.com/item/服务器/100571)。Telnet是常用的[远程控制](https://baike.baidu.com/item/远程控制/934368)Web[服务器](https://baike.baidu.com/item/服务器)的方法。\n\n**telnet**：\n\n```bash\n[root@localhost root] telnet IP 端口\n```\n\n**dhclient**：为本机分配一个网络内可用的IP地址\n\n```bash\n[root@localhost root] dhclient\n```\n\n编辑虚拟机系统网卡配置：\n\n```bash\n[root@localhost root] vim /etc/sysconfig/network-scripts/ifcfg-ens33\n```\n\n修改配置如下：\n\n```\nTYPE=Ethernet\nPROXY_METHOD=none\nBROWSER_ONLY=no\n// 修改为静态IP\nBOOTPROTO=static\nDEFROUTE=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_FAILURE_FATAL=no\nIPV6_ADDR_GEN_MODE=stable-privacy\nNAME=ens33\nUUID=824ec4bd-a9ae-4410-8346-17ce7f3dd111\nDEVICE=ens33\n// 设置IP地址等信息\nONBOOT=yes\nIPADDR=192.168.31.21\nNETMASK=255.255.255.0\nGATEWAY=192.168.31.1\nDNS1=119.29.29.29\n```\n\n编辑完成，重启网络设置即可\n\n```bash\n[root@localhost root] systemctl restart network.service\n```\n\n\n\n## 实用指令\n\n**which**：在环境变量 `$PATH` 设置的目录里查找符合条件的文件。\n\n查看 Java 的安装路径\n\n``` bash\n[root@localhost root] which java\n```\n\n**nohup**： no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。\n\n语法格式：\n\n```\nnohup Command [ Arg … ] [　& ]\n```\n\n- **Command**：要执行的命令。\n- **Arg**：一些参数，可以指定输出文件。\n- **&**：让命令在后台执行，终端退出后命令仍旧执行。\n\n示例：\n\n``` bash\n[root@localhost root] nohup java -jar xxx.java &\n```\n\n> & 最经常被用到，其用在一个命令的最后，可以把这个命令放到后台执行，不挂起\n\n\n\n**jobs**：查看有哪些任务正在后台运行\n\n> jobs 详解：https://www.cnblogs.com/mfryf/archive/2012/05/09/2491322.html\n\n``` bash\n[root@localhost root] jobs -l        # 显示当前系统的任务列表\n```\n\n上面的命令执行后，将显示出当前系统下的任务列表信息，具体如下所示：\n\n```\n[1] + 1903 运行中          nohup java -jar xxx.java &\n```\n\n\n\n**sz**：把日志文件下载到本地\n\n\n\n**rename** 命令：\n\n``` bash\n# Perl语言版本格式\n[root@localhost root] rename 's/a/b/' *  # 将当前目录下的所有文件名中的 a 替换为 b\n\n# C语言版本格式\n[root@localhost root] rename a b *\n```\n\n> https://blog.51cto.com/jiemian/1846951\n\nfree 命令：查看系统可用内存大小：\n\n``` bash\n[root@localhost root] free -m\n```\n\n\n\n\n\n\n\n## 定时任务调度\n\n> https://www.runoob.com/w3cnote/linux-crontab-tasks.html\n\n任务调度：是指系统在某个时间执行的特定的命令或程序。任务调度分类：\n\n- 系统工作：有些重要的工作必须周而复始地执行，如病毒扫描等\n- 个别用户工作：个别用户可能希望执行某些程序，比如对mysql数据库的备份。\n\n指令：\n\n``` bash\n[root@localhost root] crontab [选项]\n```\n\n| 参数选项 |                    功能                     |\n| :------: | :-----------------------------------------: |\n|    -e    |             编辑crontab定时任务             |\n|    -l    |        列出当前有哪些crontab任务调度        |\n|    -r    | 终止任务调度，删除当前用户所有的crontab任务 |\n\n使用 **crontab -e** 进入当前用户的工作表编辑，是常见的vim界面。每行是一条命令。\n\ncrontab 的命令构成为 时间+动作，其时间有**分、时、日、月、周**五种，操作符有\n\n- ***** 取值范围内的所有数字\n- **/** 每过多少个数字\n- **-** 从X到Z\n- **，**散列数字\n\n时间说明：\n\n```bash\n# .---------------- minute (0 - 59) \n# |  .------------- hour (0 - 23)\n# |  |  .---------- day of month (1 - 31)\n# |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ... \n# |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7)  OR\n#sun,mon,tue,wed,thu,fri,sat \n# |  |  |  |  |\n# *  *  *  *  *  command to be executed\n```\n\n- minute：代表一小时内的第几分，范围 0-59。\n- hour：代表一天中的第几小时，范围 0-23。\n- mday：代表一个月中的第几天，范围 1-31。\n- month：代表一年中第几个月，范围 1-12。\n- wday：代表星期几，范围 0-7 (0及7都是星期天)。\n- who：要使用什么身份执行该指令，当您使用 crontab -e 时，不必加此字段。\n- command：所要执行的指令\n\n更多使用案例见：https://www.runoob.com/w3cnote/linux-crontab-tasks.html\n\n重启任务调度\n\n``` bash\n[root@localhost root] service crond restart\n```\n\n### 案例\n\n#### 案例一\n\n使用 `crontab -e` 的方式直接编辑命令：\n\n- 设置任务调度文件：`/etc/crontab`\n- 设置个人任务调度。执行 `crontab –e` 命令。\n- 接着输入任务到调度文件如：`*/1 * * * * ls –l /etc/ > /tmp/to.txt`，意思说每小时的每分钟执行 `ls –l /etc/ > /tmp/to.txt` 命令\n- `crontab -r` 终止任务\n\n#### 案例二\n\n如果指令比较复杂，可以将其先写入到一个 .sh 文件中，然后再在 `crontab -e` 中执行该脚本文件\n\n- 编写脚本文件：`/home/mytask.sh`，在其内写上要执行的命令\n- 给 `mytask.sh` 赋予可执行的权限\n- 执行 `crontab -e ` 命令\n- 在其中输入 `*/1 * * * * /home/mytask.sh`即可\n- `crontab -r` 终止任务\n\n\n\n## 分区\n\n补充：Linux兄弟连\n\nLinux来说无论有几个分区，分给哪一目录使用，它归根结底就只有一个根目录，一个独立且唯一的文件结构，Linux中每个分区都是用来组成整个文件系统的一部分。\n\nLinux采用了一种叫“载入”的处理方法，它的整个文件系统中包含了一整套的文件和目录，且将一个分区和一个目录联系起来。这时要载入的一个分区将使它的存储空间在一个目录下获得。\n\n查看所有设备挂载情况：\n\n``` bash\n[root@localhost root] lsblk\n```\n\n挂载：将一个分区与一个目录联系起来（`mount 设备名称 挂载目录`）\n\n``` bash\n[root@localhost root] mount /dev/sdb1 /newdisk\n\n[root@localhost root] umount/dev/sdb1 或者 umount/newdisk\n```\n\n**用命令行挂载重启后会失效**。永久挂载：通过修改`/etc/fstab`实现挂载。添加完成后执行`mount –a` 即刻生效。\n\n查询系统整体磁盘使用情况：\n\n```bash\n[root@localhost root] df -h\n```\n\n查询指定目录的磁盘占用情况，默认为当前目录：\n\n``` bash\n[root@localhost root] du -h /目录\n```\n\n参数：\n\n- -s指定目录占用大小汇总\n- -h 带计量单位\n- -a 含文件\n- --max-depth=1 子目录深度\n- -c 列出明细的同时，增加汇总值\n\n## 进程\n\n在LINUX中，每个执行的程序（代码）都称为一个进程。每一个进程都分配一个ID号。每一个进程，都会对应一个父进程，而这个父进程可以复制多个子进程。例如www服务器。\n\n每个进程都可能以两种方式存在的。前台与后台，所谓前台进程就是用户目前的屏幕上可以进行操作的。后台进程则是实际在操作，但由于屏幕上无法看到的进程，通常使用后台方式执行。一般系统的服务都是以后台进程的方式存在，而且都会常驻在系统中。直到关机才结束。\n\n### 进程历史\n\n==补充兄弟连==\n\n> https://www.cnblogs.com/zwcry/p/9602756.html\n\n历史上，Linux 的启动一直采用`init`进程。CentOS 6.0中使用下面的命令用来启动服务。\n\n> ```bash\n> $ sudo /etc/init.d/apache2 start\n> # 或者\n> $ service apache2 start\n> ```\n\n这种方法有两个缺点：\n\n- 一是启动时间长。`init`进程是串行启动，只有前一个进程启动完，才会启动下一个进程。\n- 二是启动脚本复杂。`init`进程只是执行启动脚本，不管其他事情。脚本需要自己处理各种情况，这往往使得脚本变得很长。\n\n### Systemd 概述\n\n`Systemd` 就是为了解决这些问题而诞生的。它的设计目标是为系统的启动和管理提供一套完整的解决方案。根据 Linux 惯例，字母`d`是守护进程（daemon）的缩写。 `Systemd` 这个名字的含义，就是**它要守护整个系统**。\n\n使用了 `Systemd`，就不需要再用`init`了。`Systemd` 取代了`initd`，**成为系统的第一个进程（PID 等于 1），其他进程都是它的子进程**\n\n> ```bash\n> $ systemctl --version\n> ```\n\n上面的命令查看 `Systemd` 的版本。\n\n`Systemd` 的优点是功能强大，使用方便，缺点是体系庞大，非常复杂。`Systemd` 并不是一个命令，而是一组命令，涉及到系统管理的方方面面。\n\n**`systemctl`是 Systemd 的主命令，用于管理系统。**\n\n```bash\n# 重启系统\n$ sudo systemctl reboot\n\n# 关闭系统，切断电源\n$ sudo systemctl poweroff\n\n# CPU停止工作\n$ sudo systemctl halt\n\n# 暂停系统\n$ sudo systemctl suspend\n\n# 让系统进入冬眠状态\n$ sudo systemctl hibernate\n\n# 让系统进入交互式休眠状态\n$ sudo systemctl hybrid-sleep\n\n# 启动进入救援状态（单用户状态）\n$ sudo systemctl rescue\n```\n\n`systemctl`命令是Linux系统服务管理器指令，它实际上将 service 和 chkconfig 这两个命令组合到一起。`ctl`代表`Control`\n\n> systemctl — Control the systemd system and service manager\n\n### 查看进程\n\n`ps`（process status）命令是用来查看目前系统中，有哪些正在执行，以及它们执行的状况。可以不加任何参数。\n\n1. 查看某种服务的进程（例如查看java相关服务的进程）：\n\n``` bash\n[root@localhost root] ps –aux | grep xxx\n\n[root@localhost root] ps –aux | grep java\n\n[root@localhost root] ps –aux | grep sshd\n```\n\n参数说明：\n\n- `-a` 显示所有用户的进程(show processes for all users) \n- `-u` 显示用户(display the process's user/owner) \n- `-x` 显示无控制终端的进程(also show processes not attached to a terminal)\n\n2. 以全格式显示当前所有的进程：\n\n``` bash\n[root@localhost root] ps -ef\n```\n\n参数说明：\n\n- `-e` 显示所有进程\n- `-f` 全格式\n\n``` bash\n[root@localhost root] ps -ef | grep xxx\n```\n\n3. 以树状结构展示进程\n\n```bash\n[root@localhost root] pstree\n```\n\n4. 终止进程（强迫进程立即停止）：\n\n``` bash\n[root@localhost root] kill -9 进程号\n```\n\n详解：\n\n> https://cloud.tencent.com/developer/user/1410546\n\n`ps -aux` 是以BSD方式显示 \n\n> a 显示所有用户的进程(show processes for all users) u 显示用户(display the process's user/owner) x 显示无控制终端的进程(also show processes not attached to a terminal)\n\n`ps -ef` 是以System V方式显示，该种方式比BSD方式显示的多 \n\n> e 显示所有用户的进程(all processes)此参数的效果和指定\"a\"参数相同 f 用ASCII字符显示树状结构，表达程序间的相互关系(ASCII art forest)\n\n下面看两个命令各自显示哪些内容： \n\n```bash\n$ ps -aux \nUSER       PID %CPU %MEM   VSZ  RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.0  4828  516 ?        Ss    2014   1:28 init [3]         \nroot         2  0.0  0.0     0    0 ?        S     2014   0:00 [kthreadd]\nroot         3  0.0  0.0     0    0 ?        S     2014   0:43 [migration/0]\nroot         4  0.0  0.0     0    0 ?        S     2014   7:34 [ksoftirqd/0]\nroot         5  0.0  0.0     0    0 ?        S     2014   0:01 [migration/0]\nroot         6  0.0  0.0     0    0 ?        S     2014   0:03 [watchdog/0]\nroot         7  0.0  0.0     0    0 ?        S     2014   3:04 [migration/1]\nroot         8  0.0  0.0     0    0 ?        S     2014   0:01 [migration/1]\nroot         9  0.0  0.0     0    0 ?        S     2014   1:44 [ksoftirqd/1]\nroot        10  0.0  0.0     0    0 ?        S     2014   0:01 [watchdog/1]\nroot        11  0.0  0.0     0    0 ?        S     2014   2:21 [migration/2]\nroot        12  0.0  0.0     0    0 ?        S     2014   0:01 [migration/2]\n```\n\n其中显示了： \n\n> 1、USER 哪个用户启动了这个命令 2、PID 进程ID 3、CPU CPU占用率 4、MEM 内存使用量 5、VSZ 如果一个程序完全驻留在内存的话需要占用多少内存空间 6、RSS 当前实际占用了多少内存 7、TTY: 终端的次要装置号码 (minor device number of tty) 8、STAT 进程当前的状态(\"S\":中断 sleeping,进程处在睡眠状态,表明这些进程在等待某些事件发生--可能是用户输入或者系统资源的可用性;\"D\":不可中断 uninterruptible sleep;\"R\":运行 runnable;\"T\":停止 traced or stopped;\"Z\":僵死 a defunct zombie process) 9、START 启动命令的时间点 10、TIME 进程执行起到现在总的CPU暂用时间 11、COMMAND 启动这个进程的命令\n\n```bash\n$ ps -ef \nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0  2014 ?        00:01:28 init [3]         \nroot         2     0  0  2014 ?        00:00:00 [kthreadd]\nroot         3     2  0  2014 ?        00:00:43 [migration/0]\nroot         4     2  0  2014 ?        00:07:34 [ksoftirqd/0]\nroot         5     2  0  2014 ?        00:00:01 [migration/0]\nroot         6     2  0  2014 ?        00:00:03 [watchdog/0]\nroot         7     2  0  2014 ?        00:03:04 [migration/1]\nroot         8     2  0  2014 ?        00:00:01 [migration/1]\nroot         9     2  0  2014 ?        00:01:44 [ksoftirqd/1]\nroot        10     2  0  2014 ?        00:00:01 [watchdog/1]\nroot        11     2  0  2014 ?        00:02:21 [migration/2]\nroot        12     2  0  2014 ?        00:00:01 [migration/2]\n```\n\n其中显示了： \n\n> 1、UID 用户号 2、PID 进程ID 3、PPID 父进程号 4、C CPU占用率 5、TTY 终端的次要装置号码 (minor device number of tty) 6、TIME 进程执行起到现在总的CPU暂用时间 7、COMMAND 启动这个进程的命令\n\n一般使用这两个命令的作用是查看预期的进程是否启动，或者杀死指定的进程，例如查看memcached进程是否正常启动： \n\n```bash\n$ ps -ef | grep 'memcached'\nwork   14896  5034  0 16:30 pts/12   00:00:00 grep memcached\nwork   27799     1  0  2014 ?        00:01:08 /home/work/local/memcache/bin/memcached -d -m 8096 -p 11215 -c 256\n```\n\n通过grep命令可以查找指定的进程名称，上面例子查找发现正常运行了，但如果我要关闭这个进程，可以通过杀死PID来完成，例如memcached的PID是27799，那么执行下面kill命令即可： \n\n```bash\n$ kill 27799\n$ ps -ef | grep 'memcached'\nwork   14896  5034  0 16:30 pts/12   00:00:00 grep memcached\n```\n\n再次查找进程已经消失。 \n\n### 服务管理\n\n服务(service) 本质就是进程，但是是运行在后台的，通常都会监听某个端口，等待其它程序的请求，比如(mysql , sshd 防火墙等)，因此我们又称为守护进程。\n\nCentOS 6.0：\n\n``` bash\n[root@localhost root] service 服务名 [start | stop | restart | reload | status] \n```\n\nCentOS 7.0 后不再使用`service`，而是`systemctl`：\n\n``` bash\n[root@localhost root] systemctl [start | stop | restart | reload | status] 服务名\n```\n\n例如修改网络设置后，重启网络设置：\n\n```bash\n[root@localhost root] systemctl restart network.service\n```\n\n查看服务名：查看 `/etc/init.d/服务名称` \n\n- 当使用指令关闭或者启用防火墙后，将立即生效。[`telnet` 测试某个端口即可]\n- 但这种方式只是临时生效，当重启系统后，还是回归以前对服务的设置。\n- 如果希望设置某个服务自启动或关闭永久生效，要使用`chkconfig`指令\n\n### 防火墙管理\n\n查看防火墙状态：\n\n```sh\n[root@localhost root] systemctl status firewalld\n\n[root@localhost root] systemctl disable firewalld\n```\n\n关闭防火墙：\n\n```bash\n[root@localhost root] systemctl stop firewalld\n```\n\n查看防火墙开放的端口号：\n\n```\n[root@localhost root] firewall-cmd --list-all\n```\n\n开放防火墙的某些端口号：\n\n```sh\n[root@localhost root] firewall-cmd --add-service=http –permanent\n\n[root@localhost root] firewall-cmd --add-port=80/tcp --permanent\n```\n\n重启防火墙：\n\n```\n[root@localhost root] firewall-cmd –reload\n```\n\n### 服务的运行级别(runlevel)\n\n查看或者修改默认级别：`vi /etc/inittab`\n\nLinux系统有7种运行级别(runlevel)：**常用的是级别3和5**\n\n- 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启\n- 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆\n- 运行级别2：多用户状态(没有NFS)，不支持网络\n- 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式\n- 运行级别4：系统未使用，保留\n- 运行级别5：X11控制台，登陆后进入图形GUI模式\n- 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动\n\n![image-20210806210724476](/images/%E3%80%90Linux%E3%80%91Linux/image-20210806210724476.png)\n\n### chkconfig指令\n\n> https://cloud.tencent.com/developer/article/1114438\n\n通过`chkconfig`命令可以给每个服务的各个运行级别设置**开机自启动/关闭**。`chkconfig`重新设置服务后自启动或关闭，需要重启机器reboot才能生效。\n\n查看服务：\n\n``` bash\n[root@localhost root] chkconfig --list | grep xxx\n\n[root@localhost root] chkconfig 服务名 --list\n\n[root@localhost root] chkconfig --level 5 服务名 on/off\n```\n\n### 动态监控进程\n\n`top`与`ps`命令很相似。它们都用来显示正在执行的进程。`top`与`ps`最大的不同之处，在于`top`在执行一段时间可以更新正在运行的的进程。\n\n``` bash\n[root@localhost root] top [选项]\n```\n\n| 选项    | 功能                                                         |\n| ------- | ------------------------------------------------------------ |\n| -d 秒数 | 指定top命令每隔几秒更新。默认是3秒在top命令的交互模式当中可以执行的命令 |\n| -i      | 使top不显示任何闲置或者僵死进程                              |\n| -p      | 通过指定监控进程ID来仅仅监控某个进程的状态                   |\n\n交互操作说明：\n\n| 操作 | 功能                          |\n| ---- | ----------------------------- |\n| P    | 以CPU使用率排序，默认就是此项 |\n| M    | 以内存的使用率排序            |\n| N    | 以PID排序                     |\n| q    | 退出top                       |\n\n应用案例：\n\n案例1. 监视特定用户：\n\n- 输入top命令，按回车键，查看执行的进程。\n- u：然后输入“u”回车，再输入用户名，即可\n\n案例2：终止指定的进程。\n\n- 输入top命令，按回车键，查看执行的进程。\n- k：然后输入“k”回车，再输入要结束的进程ID号\n\n### 监控网络状态\n\n查看系统网络情况`netstat`：\n\n``` bash\n[root@localhost root] netstat [选项]\n```\n\n选项说明：\n\n- -a 显示所有连接信息（包括LISTEN），包括常用于服务器的一些端口监听连接\n- -n 不显示别名信息，用数字代替，可以加快命令的执行速度\n- -p protocol，显示指定网络协议的连接，全部协议在`/etc/protocols`里\n- -v 显示更多信息，可以显示对应连接的PID\n- -r 显示网络路由表信息\n- -L 显示出监听队列的信息\n\n举例：查看监听状态的端口：\n\n```\nnetstat -an | grep LISTEN\n```\n\n\n## RPM包管理\n\nRPM：一种用于互联网下载包的打包及安装工具，它包含在某些Linux分发版中。它生成具有.RPM扩展名的文件。RPM是RedHat Package Manager（RedHat软件包管理工具）的缩写，类似windows的setup.exe，这一文件格式名称虽然打上了RedHat的标志，但理念是通用的。Linux的分发版本都有采用（suse,redhat, centos 等等），可以算是公认的行业标准。\n\n一个rpm包名：`firefox-45.0.1-1.el6.centos.x86_64.rpm`\n\n- 名称:firefox\n- 版本号：45.0.1-1\n- 适用操作系统: el6.centos.x86_64\n- 表示centos6.x的64位系统\n- 如果是i686、i386表示32位系统，noarch表示通用\n\n查询安装的所有rpm软件包\n\n``` bash\n[root@localhost root] rpm –qa | grep xx\n```\n\n查询软件包是否安装\n\n``` bash\n[root@localhost root] rpm -q 软件包名\n```\n\n查询软件包信息\n\n``` bash\n[root@localhost root] rpm -qi 软件包名\n```\n\n查询软件包中的文件\n\n``` bash\n[root@localhost root] rpm -ql 软件包名\n```\n\n查询文件所属的软件包\n\n``` bash\n[root@localhost root] rpm -qf 文件全路径名\n```\n\n**卸载rpm包**\n\n``` bash\n[root@localhost root] rpm -e 包的名称\n```\n\n**安装rpm包**\n\n``` bash\n[root@localhost root] rpm -ivh 包全路径名称\n```\n\n参数说明\n\n- i=install 安装\n- v=verbose 提示\n- h=hash 进度条\n\n## YUM包管理\n\nYUM（Yellowdog Updater, Modified）是一个**Shell前端软件包管理器**。基于RPM包管理，能够从指定的服务器**自动下载RPM包并且安装**，可以**自动处理依赖性**关系，并且一次安装所有依赖的软件包。\n\n查询yum服务器是否有需要安装的软件\n\n``` bash\n[root@localhost root] yum list | grep xx软件列表\n```\n\n安装指定的yum包\n\n``` bash\n[root@localhost root] yum install xxx\n```\n\n## vi 和 vim\n\n> **Vim**是从[vi](https://zh.wikipedia.org/wiki/Vi)发展出来的一个[文本编辑器](https://zh.wikipedia.org/wiki/文本编辑器)。其代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。和[Emacs](https://zh.wikipedia.org/wiki/Emacs)并列成为[类Unix系统](https://zh.wikipedia.org/wiki/类Unix系统)用户最喜欢的编辑器。\n>\n> Vim的第一个版本由[布莱姆·米勒](https://zh.wikipedia.org/wiki/布萊姆·米勒)在1991年发布。最初的简称是**V**i **IM**itation，随着功能的不断增加，正式名称改成了**V**i **IM**proved。现在是在[开放源代码](https://zh.wikipedia.org/wiki/开放源代码)方式下发行的[自由软件](https://zh.wikipedia.org/wiki/自由软件)。\n\nvi和vim它们都是多模式编辑器，不同的是vim是vi的升级版本，它不仅兼容vi的所有指令，而且还有一些新的特性在里面。\n\nvim的这些优势主要体现在以下几个方面：\n\n1. 多级撤消：我们知道在vi里，按u只能撤消上次命令，而在vim里可以无限制的撤消。\n2. 易用性：vi只能运行于unix中，而vim不仅可以运行于unix,windows ,mac等多操作平台。\n3. 语法加亮：vim可以用不同的颜色来加亮你的代码。\n4. 可视化操作：vim不仅可以在终端运行，也可以运行于x window、 mac os、 windows。\n5. 对vi的完全兼容：某些情况下，可以把vim当成vi来使用。\n6. vi和vim都是Linux中的编辑器，不同的是vim比较高级，可以视为vi的升级版本。vi使用于文本编辑，但是vim更适用于coding。\n\nvi有3个模式： \n\n- 插入模式：在此模式下可以输入字符，按ESC将回到命令模式。 \n- 命令模式：可以移动光标、删除字符等。 \n- 低行模式：可以保存文件、退出vi、设置vi、查找等功能(低行模式也可以看作是命令模式里的)。 \n\n\n\n## SHELL 编程\n\n### 常用的脚本\n\n依次遍历当前目录下的所有子目录，将其中的文件拷贝到当前目录下：\n\n``` shell\n for dir in `ls .`\n do\n   if [ -d $dir ]\n   then\n     echo $dir\n     cd $dir\n     cp * ..\n     cd ..\n   fi\ndone \n```\n\n\n\n","tags":["Linux"],"categories":["Linux"]},{"title":"【Spring】Spring5 IoC 源码分析","url":"/2021/07/14/【Spring】Spring5-IoC源码分析/","content":"\n## IoC容器\n\nIoC容器就是保存组件的地方，其内本质上是一些map对象存储组件。\n\n在容器启动时，首先将所有定义的组件创建，并添加到这些map对象中。之后开发人员再从容器中getBean()获取组件时，将直接从该map中取出该组件，无需再创建\n\n\n\nBeanFactory和ApplicationContext的区别：ApplicationContext是BeanFactory的子接口。\n\nBeanFactory：Bean工厂接口，负责创建Bean实例，其内保存的单例Bean都保存在一个map中\n\nApplicationContext：容器接口，更多的负责容器功能的实现，其可以基于BeanFactory创建好的对象之上完成强大的容器功能，其可以从map中获取这些Bean，并且AOP，DI都在ApplicationContext接口下的类中。\n\nBeanFactory 是 Spring最底层的接口，ApplicationContext是留给程序员使用的IOC容器；ApplicationContext是BeanFactory的子接口。\n\n对象由BeanFactory 创建。对象间的动态装配和管理由ApplicationContext完成。\n\n\n\nSpring中最大的模式是工厂模式，其帮助用户创建和管理组件。\n\n\n\n\n\n<!-- More -->\n\n## IoC容器详细创建过程\n\n### 1. 传入配置类，创建IoC容器\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210630203107349.png)\n\n### 2. refresh()：后续流程均在该方法内执行\n\n进入**AnnotationConfigApplicationContext**的构造器，调用`refresh()`方法\n\n![image-20210714142709396](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714142709396.png)\n\nonRefresh()：调用ApplicationContext子类的重写方法，例如spring boot里的**ServletWebServerApplicationContext**\n\n\n\n待补充\n\n\n\n该方法内调用 **finishBeanFactoryInitialization()** 方法注册**所有非@Lazy修饰的单实例普通组件**。\n\n![image-20210714161257818](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714161257818.png)\n\n### 3. finishBeanFactoryInitialization()：注册普通组件\n\n该方法将注册**所有非@Lazy修饰的单实例普通组件**。进入该方法后，调用 `beanFactory.preInstantiateSingletons()`方法实例化所有非@Lazy修饰的单实例普通组件。\n\n![image-20210714161526478](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714161526478.png)\n\n此处的`beanFactory`为**DefaultListableBeanFactory**类对象。\n\n进入 `beanFactory.preInstantiateSingletons()` 方法：\n\n3.1 首先获取到所有定义的组件名字：\n\n![image-20210714161659116](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714161659116.png)\n\n3.2 按顺序创建组件：\n\n![image-20210714162218894](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714162218894.png)\n\n创建组件的内容在 **getBean()** 方法中：\n\n### 4. getBean(beanName)：创建组件对象\n\n![image-20210714145712663](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714145712663.png)\n\n其调用了 **doGetBean()** 方法，该方法在`AbstractBeanFactory`类中。进入该方法内：\n\n4.1 首先调用 **getSingleton()** 方法从已经注册的所有单实例组件缓存map中检查有没有该组件（该过程具体分析见后文）。容器第一次创建该组件时从map中找不到该组件，则执行后续代码将其创建，并添加到map中。\n\n![image-20210714150118137](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714150118137.png)\n\n4.2 创建当前组件所依赖的其他组件\n\n![image-20210714153153739](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714153153739.png)\n\n4.3 根据组件定义信息判断其是否单例，若是则创建该组件，若不是则暂时不创建：\n\n![image-20210714153335632](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714153335632.png)\n\n进入`getSingleton()`方法后，首先从缓存中判断是否已经存在该组件，若不存在，则调用上图中Lambda表达式的匿名方法中的**createBean()**创建该组件，并将其**添加到组件缓存map中**。下面为具体流程：\n\n4.3.1 下图红色框中的**singletonObjects**是`DefaultSingletonBeanRegistry`类中的属性，其保存了所有已创建的单实例对象的信息。在容器创建完毕后，后续再次调用getBean()方法从容器中获取组件时，将直接从该map对象中获取（见该小节最后分析）。\n\n==singletonFactory是采购员，再取一次判断是否为空，是因为可能其他线程此时创建了该对象，是为了线程安全==\n\n同时加了双重检测\n\n![image-20210714155928184](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714155928184.png)\n\n![image-20210714154108704](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714154108704.png)\n\n4.3.2 接着执行下图中黄色框的`singletonFactory.getObject()`方法创建该组件。\n\n**注意：该方法即是4.3中的Lambda表达式的匿名方法，这里Spring4之前的写法不是Lambda表达式，而是直接传入一个singletonFactory（即Bean单例工厂），其getObject()方法中调用了createBean()方法创建了单例Bean**。\n\n执行该方法相当于执行该匿名方法（绿色框）。其返回红色框 **createBean()** 方法执行的结果，即创建出的组件。因此==创建组件==的具体代码需要分析 **createBean()** 方法（在此之前都还未创建组件）。（见下文步骤5） \n\n==这个getObejct就是之前笔记代码里的bean仓库获取对象，对比代码里的getSingleton==\n\n![image-20210714155505160](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714155505160.png)\n\n4.3.3 创建出组件后，调用 **addSingleton()** 方法将其添加到组件缓存map中。\n\n![image-20210714154015017](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714154015017.png)\n\n`addSingleton()`方法内，将刚才创建的组件保存到**singletonObjects**缓存map中：\n\n![image-20210714154526356](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714154526356.png)\n\n\n\n==上图中有三级缓存==\n\n---\n\n在容器启动时，将逐一执行上述过程将每个组件添加到**singletonObjects**这个缓存map中。在容器创建完毕后，开发人员调用 **getBean()** 方法从容器中获取组件时，将首先执行 **getSingleton()** 方法（见4.1步），其将尝试从**singletonObjects**中获取该组件（下图橙色框），若之前已经注册过该组件，则此处将直接将其返回，无需再执行4.2 - 4.3步骤的创建过程。\n\n![image-20210714163739295](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714163739295.png)\n\n---\n\n**总结：至此，已经创建出了该组件，并将其添加到了缓存map中。其中，具体创建组件的createBean()方法分析如下：**\n\n\n\n### 5. createBean()方法：\n\n略，见AOP\n\n\n\n\n\n\n\n\n\n\n\n\n\n![image-20210714143755100](/images/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210714143755100.png)","tags":["源码分析","SSM","Spring"],"categories":["源码分析","Spring","SSM"]},{"title":"【Spring MVC】Spring MVC 源码分析","url":"/2021/07/13/【SpringMVC】SpringMVC-源码分析/","content":"\n\n\n## Spring MVC 执行流程\n\n- 客户端点击链接发送请求： `http://localhost:8080/项目名/helloworld`\n- 请求来到tomcat服务器\n- SpringMVC的前端控制器收到所有客户端发来的请求\n- 查找请求地址和哪个`@RequestMapping`标注的方法匹配\n- 前端控制器找到了目标处理器类的目标方法，利用反射执行目标方法\n- 方法执行完后的返回值被SpringMVC的视图解析器解析拼接，得到完整的页面地址，并跳转到相应的页面\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/kuangstudy0214fd0a-0df0-4910-a467-5b7d61712868.png)\n\n\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/20180708224853769)\n\n<!-- More -->\n\n整理一段话面试用：\n\nSpring MVC原理：\n\n在Tomcat中注册配置了一个**DispatcherServlet**，该Servlet的默认请求映射路径为 \"/\" ，当客户端收到符合该路径的请求时，将执行该Servlet的doService方法，其都会执行一个doDispatch() 方法，在其内进行请求映射、参数解析、返回值处理、内容协商、页面解析跳转等操作。\n\n\n\n## DispatcherServlet\n\n**DispatcherServlet**类继承自**FrameworkServlet**类，该类最终继承自**HttpServlet**类。\n\n![image-20210715163040938](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715163040938.png)\n\n**FrameworkServlet**类中有多个处理请求的方法（`doGet/doPost/doPut/doDelete`），他们都调用了同一个方法`this.processRequest(request, response)`。（**DispatcherServlet**类中并没有重写这些`doXxx`方法和`processRequest()`方法，因此调用的是**FrameworkServlet**类里的这些方法）\n\n![image-20210715162521522](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715162521522.png)\n\n`processRequest(request, response)`方法中最关键的一步为调用`this.doService(request, response)`方法。但该方法在**FrameworkServlet**类中为抽象方法，需要子类实现，因此调用的是**DispatcherServlet**类里的 **this.doService(request, response)** 方法。\n\n![image-20210715162814683](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715162814683.png)\n\n**FrameworkServlet**类重写的 **doService()** 方法：\n\n![image-20210715163548801](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715163548801.png)\n\n该方法调用了**FrameworkServlet**中的 **doDispatch(request, response)** 方法：\n\n![image-20210715163935578](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715163935578.png)\n\n因此分析清楚 **doDispatch(request, response)** 方法即可理解SpringMVC的大致原理。上述关系树见下图：\n\n![image-20210715164354367](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715164354367.png)\n\n## Spring MVC 详细执行流程\n\n客户端发来请求后，经过上述分析的流程，会执行**FrameworkServlet**类里的 **doDispatch(request, response)** 方法。下面按顺序分析该方法完成的工作：\n\n![image-20210715165846578](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715165846578.png)\n\n![image-20210719204334058](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210719204334058.png)\n\n![image-20210719205128323](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210719205128323.png)\n\n1. **this.checkMultipart()** ：判断当前请求是否为文件上传请求，若是，则将其进行包装\n2. **this.getHandler()**：根据当前的**url请求地址**`（\"/hello\"）`判断哪个**控制器**（`@Controller`）里的**映射方法**（`@RequestMapping(\"/hello\")`）与之对应（在**HandlerMapping**中找到这个请求的映射信息），返回一个**mappedHandler**。\n3. **this.noHandlerFound()**：如果没找到对应的处理器（控制器）能处理当前请求，则404抛异常\n4. **this.getHandlerAdapter()**：根据当前处理器**mappedHandler**获取相应的**适配器（反射工具）HandlerAdapter**。\n5. **ha.handle()**：此处真正执行目标方法。使用**适配器**执行目标方法，并将目标方法执行完毕后的返回值`(\"sucess\")`作为视图名保存到一个`ModelAndView`对象中。（此时执行目标方法，但还未转发页面）\n6. **this.applyDefaultViewName()**：如果目标方法返回值类型为void，即没有指定返回的视图名，则执行默认的视图名（转发到请求地址本身）\n7. **this.processDispatchResult()**：根据目标方法最终执行完成后封装的`ModelAndView`内的信息转发到相应的页面（页面信息保存在view里），并且可以从请求域中取出`ModelAndView`中保存的数据。\n\n下面详细分析上述步骤中的重要细节：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Spring MVC 的九大组件\n\n**DispatchServlet**组件中有九个组件，SpringMVC在工作时，关键功能都是由这些组件完成的。其共同点：九大组件全部都是接口。接口就是规范。\n\n```java\n/** 文件上传解析器 */\n@Nullable\nprivate MultipartResolver multipartResolver;\n\n/** 区域信息解析器（国际化） */\n@Nullable\nprivate LocaleResolver localeResolver;\n\n/** 主题解析器：主题效果更换 */\n@Nullable\nprivate ThemeResolver themeResolver;\n\n/** HandlerMapping 处理器映射器 */\n@Nullable\nprivate List<HandlerMapping> handlerMappings;\n\n/** 处理器对应的适配器 */\n@Nullable\nprivate List<HandlerAdapter> handlerAdapters;\n\n/** 处理器异常解析器：强大的异常解析功能 */\n@Nullable\nprivate List<HandlerExceptionResolver> handlerExceptionResolvers;\n\n/** 若方法返回值为void，把请求的地址转换为视图名 */\n@Nullable\nprivate RequestToViewNameTranslator viewNameTranslator;\n\n/** 允许重定向携带数据的功能 */\n@Nullable\nprivate FlashMapManager flashMapManager;\n\n/** 视图解析器 */\n@Nullable\nprivate List<ViewResolver> viewResolvers;\n```\n\n这些组件在容器启动时进行初始化：\n\n![image-20210720161209851](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720161209851.png)\n\n组件初始化的过程简单来说就是去容器中找这个组件，如果找不到就用**默认的配置策略**。有些组件在容器中是使用类型查找，有些组件是使用id查找。示例：\n\n![image-20210720161841815](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720161841815.png)\n\n\n\n## \n\n","tags":["源码分析","SSM","Spring","Spring MVC"],"categories":["源码分析","Spring","SSM","Spring MVC"]},{"title":"【Spring Boot】Spring Boot2 源码分析","url":"/2021/07/12/【SpringBoot】SpringBoot2-源码分析/","content":"\n本文将逐一介绍 Spring Boot 中的原理\n\n\n\n常用的自动配置类**xxxAutoConfiguration**：\n\n- **AopAutoConfiguration**：AOP自动配置类\n- **DispatcherServletAutoConfiguration**：DispatcherServlet自动配置类\n- **WebMvcAutoConfiguration**：WebMVC相关自动配置类\n- **ServletWebServerFactoryAutoConfiguration**：ServletWebServerFactory自动配置类\n- **MultipartAutoConfiguration**：文件上传自动配置类\n- **ErrorMvcAutoConfiguration**：异常处理自动配置类\n- **DataSourceAutoConfiguration**：数据源自动配置类\n- **MybatisAutoConfiguration**：MyBatis自动配置类（第三方）\n- **RedisAutoConfiguration：Redis**自动配置类\n\n\n\nSpring里用到的设计模式：工厂模式，动态代理模式，责任链模式，\n\n策略模式？\n\n\n\n<!-- More -->\n\n初始化时调用ServletContextListener的contextInitialization 用来创建IOC\n\n里面createWebapplicationContext -> ioc\n\nspring web项目 启动流程 先listener 再 servlet\n\n\n\n\n\n\n\n\n\n\n\n## 自动配置原理\n\n### 依赖管理\n\n当前新建的Spring Boot项目的父项目：\n\n``` xml\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.3.4.RELEASE</version>\n</parent>\n```\n\n其父项目又依赖`spring-boot-dependencies.pom`：\n\n```xml\n<parent>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-dependencies</artifactId>\n  <version>2.3.4.RELEASE</version>\n</parent>\n```\n\n该文件中声明了开发中常用的jar包版本，因此其子项目中不需要给依赖写上版本号，会自动导入父项目里版本的jar包。该特性被称为**版本仲裁**。\n\n```xml\n<properties>\n  <activemq.version>5.15.13</activemq.version>\n  <antlr2.version>2.7.7</antlr2.version>\n  <appengine-sdk.version>1.9.82</appengine-sdk.version>\n  <artemis.version>2.12.0</artemis.version>\n  <aspectj.version>1.9.6</aspectj.version>\n  <assertj.version>3.16.1</assertj.version>\n    ...\n</properties>\n```\n\n#### 自定义依赖版本\n\n若想自定义修改依赖的版本，则只需要在当前项目里指定配置版本号，其会覆盖父项目中的默认版本号。\n\n```xml\n<properties>\n    <mysql.version>5.1.43</mysql.version>\n</properties>\n```\n\n#### 场景启动器\n\n`spring-boot-starter-*` 代表某种场景，只要引入了该starter，这个场景的所有依赖都会自动引入。第三方提供的简化开发的场景启动器命名格式：`*-spring-boot-starter`。[官方所有支持的Starter](https://docs.spring.io/spring-boot/docs/current/reference/html/using.html#using.build-systems.starters)\n\n所有场景启动器最底层的依赖，**SpringBoot自动配置的核心依赖**：**spring-boot-starter**\n\n```xml\n<dependency>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-starter</artifactId>\n  <version>2.3.4.RELEASE</version>\n  <scope>compile</scope>\n</dependency>\n```\n\n该starter场景将导入Spring Boot提供的127种自动配置类**xxxAutoConfiguration**，这些自动配置类将导入许多常用的组件用于简化开发（例如`DispatcherServlet`等），无需开发人员手动添加这些组件。\n\n`spring-boot-starter.pom`的主要内容：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\"\n    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n  <!-- This module was also published with a richer model, Gradle metadata,  -->\n  <!-- which should be used instead. Do not delete the following line which  -->\n  <!-- is to indicate to Gradle or any Gradle module metadata file consumer  -->\n  <!-- that they should prefer consuming it instead. -->\n  <!-- do_not_remove: published-with-gradle-metadata -->\n  <modelVersion>4.0.0</modelVersion>\n  <groupId>org.springframework.boot</groupId>\n  <artifactId>spring-boot-starter</artifactId>\n  <version>2.5.3</version>\n  <name>spring-boot-starter</name>\n  <description>Core starter, including auto-configuration support, logging and YAML</description>\n\n  <dependencies>\n    <dependency>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot</artifactId>\n      <version>2.5.3</version>\n      <scope>compile</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot-autoconfigure</artifactId>\n      <version>2.5.3</version>\n      <scope>compile</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework.boot</groupId>\n      <artifactId>spring-boot-starter-logging</artifactId>\n      <version>2.5.3</version>\n      <scope>compile</scope>\n    </dependency>\n    <dependency>\n      <groupId>jakarta.annotation</groupId>\n      <artifactId>jakarta.annotation-api</artifactId>\n      <version>1.3.5</version>\n      <scope>compile</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.springframework</groupId>\n      <artifactId>spring-core</artifactId>\n      <version>5.3.9</version>\n      <scope>compile</scope>\n    </dependency>\n    <dependency>\n      <groupId>org.yaml</groupId>\n      <artifactId>snakeyaml</artifactId>\n      <version>1.28</version>\n      <scope>compile</scope>\n    </dependency>\n  </dependencies>\n</project>\n```\n\n### 场景启动器starter工作原理\n\n![image-20210809210934337](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210809210934337.png)\n\n场景启动器工作原理的本质：调用的`xxx-starter`项目导入的所有`xxx-autoconfigure`项目中编写了许多自动配置类`xxxAutoConfiguration`，这些自动配置类将在Spring Boot启动时被注册到容器中，从而将其内编写的组件按照条件注册到容器中，因此开发人员可以在自己的项目中调用到这些组件。\n\n### 自动配置原理\n\nSpringBoot的主程序类（标有 **@SpringBootApplication**注解的类）**所在包及其下面的所有子包**里面的组件都会被默认扫描进来，这些组件不再需要额外指定扫描路径。而若想要扫描其他路径下的组件，则可以在主程序类上添加：\n\n- `@SpringBootApplication(scanBasePackages=\"com.zhao.xxx\")`\n- `@ComponentScan(\"com.zhao.xxx\") `\n\n`@SpringBootApplication`是一个合成注解，其效果等同于下面三个注解的组合。\n\n``` java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\"com.zhao.xxx\")\n```\n\nSpring Boot的各种配置都拥有默认值。这些默认配置最终都是映射到某个类上，如：`MultipartProperties`。配置文件的值最终会绑定在某个类上，这个类会在容器中创建对象。\n\nSpring Boot所有的**自动配置功能**都在 `spring-boot-autoconfigure` 包里面（第三方的starter场景也有相应的`xxx-autoconfigure`包）。\n\n**@SpringBootApplication**是一个合成注解，其效果等同于下面三个注解的组合：\n\n```java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\n    excludeFilters = {@Filter(\n    type = FilterType.CUSTOM,\n    classes = {TypeExcludeFilter.class}\n), @Filter(\n    type = FilterType.CUSTOM,\n    classes = {AutoConfigurationExcludeFilter.class}\n)}\n)\npublic @interface SpringBootApplication \n```\n\n下面逐一分析上述三者的作用\n\n### 1、@SpringBootConfiguration\n\n表明被 **@SpringBootApplication** 修饰的类本质上也是一个 **@Configuration** 配置类\n\n```java\n@Configuration\npublic @interface SpringBootConfiguration\n```\n\n### 2、@ComponentScan\n\n指定要扫描的组件（按照`@Filter`里设置的类型过滤一些组件）\n\n### 3、@EnableAutoConfiguration\n\n重点，自动配置是通过该注解实现的。\n\n``` java\n@AutoConfigurationPackage\n@Import({AutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration\n```\n\n**3.1、@AutoConfigurationPackage：自动配置包，将MainApplication主程序类所在包下的所有组件注册到容器中**\n\n```java\n@Import({Registrar.class})\npublic @interface AutoConfigurationPackage\n```\n\n该注解通过`@Import`注解向容器中导入了一个**Registrar**组件，该组件实现了`ImportBeanDefinitionRegistrar`接口（[【Spring】Spring5 源码中常用接口的底层原理](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/)），其作用是**将MainApplication主程序类所在包下的所有组件都注册到容器中**。这也解释了默认的扫描包路径为`MainApplication`所在包的路径。\n\n![image-20210711201544965](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711201544965.png)\n\n其中传入的参数`AnnotationMetadata metadata`是指SpringBoot主程序类`MainApplication`的注解元信息，用于获取其所在的包路径，从而将该包下的所有子包下的类都注册到容器中。\n\n**3.2、@Import({AutoConfigurationImportSelector.class})：向容器中注册自动配置类**\n\n**第一步：引导加载自动配置类**\n\n该注解向容器中注册了**AutoConfigurationImportSelector**类型的组件，该类的重要方法  **selectImports()** 中利用 **getAutoConfigurationEntry(annotationMetadata)**  方法向容器中导入一些**自动配置类**组件（先获取所有的自动配置类，再根据实际情况筛选出符合条件的自动配置类注册到容器中）。\n\n![image-20210711202049677](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711202049677.png)\n\n进入`getAutoConfigurationEntry(annotationMetadata)`方法后，首先调用`getCandidateConfigurations()`方法获取所有**候选**的自动配置类组件（AutoConfiguration），共有127个。并在后续进行删选后**按需开启**自动配置项（即用不到的自动配置类无需开启）。\n\n获取这些`AutoConfiguration`的具体过程：\n\n![image-20210711202306425](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711202306425.png)\n\n![image-20210711203848177](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711203848177.png)\n\n在`getCandidateConfigurations()`方法内通过`SpringFactoriesLoader`工厂加载器加载一些组件。\n\n![image-20210711202745443](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711202745443.png)\n\n![image-20210711203253301](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711203253301.png)\n\n在该方法内使用类加载器读取`\"META-INF/spring.factories\"`位置处的资源文件。有些包下有这个文件，比如最关键的`spring-boot-autoconfigure-2.3.4.RELEASE.jar`包（导入的其他第三方包中也可以会含有`\"META-INF/spring.factories\"`文件，例如MyBatis的`mybatis-spring-boot-autoconfigure-2.1.4.jar`包也会有该文件，Spring Boot启动时也会加载该包下的`xxxAutoConfiguration`类）：\n\n![image-20210711203525691](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711203525691.png)\n\n该文件内配置了Spring Boot启动时就要向容器中加载的所有自动配置类（**xxxAutoConfiguration**）（共127个，正好对应上文中的127个自动配置类组件）：\n\n![image-20210711203725837](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711203725837.png)\n\n上文中注册到容器中的127个自动配置类组件`configurations`：\n\n![image-20210711203855246](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711203855246.png)\n\n但这127个自动配置类并不会都注册到容器中，而会按需开启。\n\n**第二步：按需开启自动配置项**\n\n虽然上述127个自动配置类在启动的时候会默认全部加载，但每个`xxxAutoConfiguration`会按照条件装配规则（**@Conditional**）**按需配置**。\n\n以`BatchAutoConfiguration`类为例，该类因`@ConditionalOnClass({JobLauncher.class, DataSource.class})`的存在，若想被注册到容器中，需要满足当前项目中有`JobLauncher`类的存在，但若开发人员没有导入该类相关的maven依赖，则无法找到该类，因此该自动配置类将不会被注册到容器中。因此上述127个自动配置类会按照实际容器中配置组件的情况按需注册到容器中，不需要的配置类将不会被注册。\n\n同时这些自动配置类里的配置属性通过 **@EnableConfigurationProperties** 注解从**xxxProperties**组件中获取（`xxxProperties`组件和相应的配置文件绑定在了一起）\n\n![image-20210711211618512](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711211618512.png)\n\n以AOP自动配置器**AopAutoConfiguration**为例：\n\n![image-20210804150325041](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210804150325041.png)\n\n------\n\n举例：上文描述了如何向容器中注册常用的自动配置类，下面以web开发必须的自动配置类**DispatcherServletAutoConfiguration**为例：\n\n![image-20210711213124840](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711213124840.png)\n\n该自动配置类满足`@Conditional`的条件，因此会在程序加载时被注册到容器中。同时该自动配置类中会向容器中注册**DispatcherServlet**组件，这正是Spring MVC开发时需要的转发器组件。\n\n也就是说Spring Boot在启动时，会将传统SSM中开发人员配置在xml中的必备组件自动地注册到容器中，无需开发人员再手动注册。\n\n![image-20210711213412654](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210711213412654.png)\n\n---\n\n**第三步：修改默认配置**\n\n以自动配置类**DispatcherServletAutoConfiguration**中的**MultipartResolver**组件为例，该组件为Spring MVC中的文件上传组件，其会被`DispatcherServletAutoConfiguration`注册到容器中。\n\n其依赖于**MultipartResolver**组件（该组件默认存在于容器中，但开发人员可以再手动注册一个），同时判断该组件的名称是否为指定的`MULTIPART_RESOLVER_BEAN_NAME = multipartResolver `。\n\n若不是，可能的情况为开发人员自己手动注册了一个，但名称不符合规范。此时容器通过调用`multipartResolver()`方法注册了该组件，同时注册的组件名就是方法名**multipartResolver**，因此起到**组件名规范化**的效果。\n\n```java\n@Bean\n@ConditionalOnBean(MultipartResolver.class)  // 容器中默认有这个类型组件\n@ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) //容器中没有这个名字 multipartResolver 的组件\npublic MultipartResolver multipartResolver(MultipartResolver resolver) {\n    //给@Bean标注的方法传入了对象参数，这个参数的值就会从容器中找。\n    //SpringMVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范\n    // Detect if the user has created a MultipartResolver but named it incorrectly\n    return resolver;\n```\n\nSpringBoot默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先：\n\n```java\n@Bean\n@ConditionalOnMissingBean\npublic CharacterEncodingFilter characterEncodingFilter() {\n}\n```\n\n### 总结\n\n- Spring Boot首先加载所有的自动配置类 **xxxxxAutoConfiguration**（127个）\n- 每个自动配置类按照条件判断进行生效，默认都会绑定配置文件指定的值。（从**xxxxProperties**组件里面读取，**xxxProperties**组件和配置文件进行了绑定）\n- 生效的配置类就会向容器中注册响应的组件\n\n定制化配置：\n\n- 开发人员手动使用`@Bean`替换容器中默认注册的组件；\n- 在配置文件中修改相应配置属性以修改默认组件的属性值\n\n**xxxxxAutoConfiguration **—> 注册组件 —> 组件属性通过**xxxxProperties**从配置文件**application.properties**中取值\n\n常用的自动配置类**xxxAutoConfiguration**：\n\n- **AopAutoConfiguration**：AOP自动配置类\n- **DispatcherServletAutoConfiguration**：`DispatcherServlet`自动配置类\n- **WebMvcAutoConfiguration**：`WebMVC`相关自动配置类\n- **ServletWebServerFactoryAutoConfiguration**：`ServletWebServerFactory`自动配置类\n- **MultipartAutoConfiguration**：文件上传自动配置类\n- **ErrorMvcAutoConfiguration**：异常处理自动配置类\n- **DataSourceAutoConfiguration**：数据源自动配置类\n- **MybatisAutoConfiguration**：MyBatis自动配置类（第三方）\n\n## 静态资源原理\n\nSpringBoot在启动时会默认加载许多**xxxAutoConfiguration**自动配置类，其中包括SpringMVC功能的自动配置类：**WebMvcAutoConfiguration**。\n\n![image-20210723132157765](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723132157765.png)\n\n该配置类向容器中添加了许多组件，例如**WebMvcAutoConfigurationAdapter**。\n\n### WebMvcAutoConfigurationAdapter\n\n![image-20210723132356529](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723132356529.png)\n\n该类用于解析配置文件中与**mvc**和**resources**相关的配置信息。其中**WebMvcProperties**配置类与**spring.mvc**属性绑定，**ResourceProperties**配置类与**spring.resources**属性绑定。\n\n同时**WebMvcAutoConfigurationAdapter只有一个有参构造器**，该构造器中的所有参数值都将从容器中获取，因此将获取到配置文件中与**mvc**和**resources**相关的配置信息：\n\n![image-20210723161237562](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723161237562.png)\n\n其参数有以下几种，都是从容器中获取：\n\n- **ResourceProperties**：获取和`spring.resources`绑定的所有的值的对象\n- **WebMvcProperties**：获取和`spring.mvc`绑定的所有的值的对象\n- **ListableBeanFactory**：获取Spring的`beanFactory`\n- **HttpMessageConverters**：找到所有的`HttpMessageConverters`\n- **ResourceHandlerRegistrationCustomizer**：找到资源处理器的自定义器。\n- **DispatcherServletPath**\n- **ServletRegistrationBean**：给应用注册Servlet、Filter等组件\n\n### 资源路径映射原理\n\n**WebMvcAutoConfigurationAdapter**配置类里的**addResourceHandlers**方法完成**静态资源路径映射**的功能：\n\n![image-20210723164630095](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723164630095.png)\n\n**红色框**：通过配置`add-mappings`属性可以禁止所有静态资源规则（红色框）。\n\n```yaml\nspring:\n  resources:\n    add-mappings: false   #禁用所有静态资源规则\n```\n\n**黄色框**：设置`webjars`的路径映射规则，即从`\"/webjars/**\"` 映射成 `\"classpath:/META-INF/resources/webjars/\"`，浏览器收到的满足规则的请求都会映射到指定的路径下。\n\n**橙色框**：设置静态资源的路径映射规则，即从**staticPathPattern** 映射成 **.getStaticLocations()** 的值，浏览器收到的满足规则的请求都会映射到指定的路径下。\n\n其中**staticPathPattern**值为配置文件中指定的静态资源路径访问前缀（默认为`/**`）：\n\n```yaml\nspring:\n  mvc:\n    static-path-pattern: /myPath/**\n```\n\n**this.resourceProperties.getStaticLocations()** 的值为配置文件中指定的静态资源路径（默认为` /static` or` /public` or` /resources` or `/META-INF/resources`）：\n\n```yaml\nresources:\n  static-locations: [classpath:/static/]\n```\n\n### 欢迎页的处理规则\n\nSpring MVC中的**handlerMapping**：处理器映射器，其内保存了每一个处理器能处理哪些方法的映射信息。\n\n**WelcomePageHandlerMapping**是SpringBoot中自动注册到容器中的一个处理器映射器。在浏览器传来的url为`\"/\"`，且其他已存在的`HandlerMapping`无法处理该请求时，其会将该请求转发到欢迎页面。下图中展示了Spring Boot在启动时容器中存在的五个`HandlerMapping`，可以看到`WelcomePageHandlerMapping`排在最后，即其只会在其他四个处理器映射器都无法处理请求时工作。\n\n![image-20210720095314175](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720095314175.png)\n\n其在转发到欢迎页面前会先判断`mvcProperties`中的`staticPathPattern`属性值是否为`/**`，若是，则转发到欢迎页`index.html`\n\n![image-20210723171723749](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723171723749.png)\n\n默认情况下`static-path-pattern = /**`，但若开发人员在配置文件中配置了自定义的`static-path-pattern`，则`WelcomePageHandlerMapping`无法工作，欢迎页面和小图标将失效。\n\n![image-20210723171856063](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723171856063.png)\n\n## Rest 映射实现原理\n\n实现Rest风格支持的核心Filter：**HiddenHttpMethodFilter**。其本质是一个过滤器，因此会在所有请求响应前进行拦截过滤，将`DELETE`请求和`PUT`请求进行包装后放行到后续过滤器。\n\n```yaml\nspring:\n  mvc:\n    hiddenmethod:\n      filter:\n        enabled: true   #开启页面表单的Rest功能\n```\n\n开启**HiddenHttpMethodFilter**后，若想发送`DELETE`或`PUT`请求，则需要创建一个表单，在表单项中携带一个`_method`参数，这个参数的值可以设置为`DELETE`或`PUT`。\n\n\n```xml\n<form action=\"/user\" method=\"get\">\n    <input value=\"REST-GET提交\" type=\"submit\" />\n</form>\n\n<form action=\"/user\" method=\"post\">\n    <input value=\"REST-POST提交\" type=\"submit\" />\n</form>\n\n<form action=\"/user\" method=\"post\">\n    <input name=\"_method\" type=\"hidden\" value=\"DELETE\"/>\n    <input value=\"REST-DELETE 提交\" type=\"submit\"/>\n</form>\n\n<form action=\"/user\" method=\"post\">\n    <input name=\"_method\" type=\"hidden\" value=\"PUT\" />\n    <input value=\"REST-PUT提交\"type=\"submit\" />\n<form>\n```\n\n```java\n@GetMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.GET)\npublic String getUser(){\n    return \"GET-张三\";\n}\n\n@PostMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.POST)\npublic String saveUser(){\n    return \"POST-张三\";\n}\n\n@PutMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.PUT)\npublic String putUser(){\n    return \"PUT-张三\";\n}\n\n@DeleteMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.DELETE)\npublic String deleteUser(){\n    return \"DELETE-张三\";\n}\n```\n\n容器在启动时，自动配置类**WebMvcAutoConfiguration**会向容器中注册一个继承了**HiddenHttpMethodFilter**的过滤器组件**OrderedHiddenHttpMethodFilter**，其本质上是一个过滤器，因此会在所有请求响应前进行拦截过滤，将`DELETE`请求和`PUT`请求进行包装后放行到后续过滤器。\n\n![image-20210723192029596](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210723192029596.png)\n\n### HiddenHttpMethodFilter源码分析\n\n`HiddenHttpMethodFilter`类里的拦截方法具体如下：\n\n```java\nprotected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException {\n    \n    // 首先获取传入参数 methodParam = _method 里的值，也就是DELETE\n    String paramValue = request.getParameter(this.methodParam);\n    \n    // 判断当前表单是否是POST提交\n    if (\"POST\".equals(request.getMethod()) && StringUtils.hasLength(paramValue)) {\n        // DELETE变成大写\n        String method = paramValue.toUpperCase(Locale.ENGLISH);\n        \n        // 创建包装后的Request类型对象wrapper，该对象的getMethod()方法被重写了，调用时将返回DELETE\n        HttpServletRequest wrapper = new HiddenHttpMethodFilter.HttpMethodRequestWrapper(request, method);\n        \n        // 将包装后的Request传递给了拦截器链，后续调用getMethod()获取到的都是DELETE\n        filterChain.doFilter(wrapper, response);\n    } else {\n        filterChain.doFilter(request, response);\n    }\n\n}\n```\n\nwrapper对象被重写的`getMethod()`方法将直接返回`_method`里的值`DELETE`。并且包装后的wrapper对象被传递到了拦截器链中，从而后续的拦截器在调用此wrapper对象的`getMethod()`时将获取到`DELETE`，因此实现了Rest风格的映射。\n\n![image-20210715100050957](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715100050957.png)\n\n## 内嵌 Servlet 容器工作原理\n\n内嵌服务器工作原理：手动调用要启动的服务器的 **start()** 方法开启服务。\n\n在Spring Boot启动时，发现当前项目是Web应用（因为引入了Web场景包和Tomcat场景包），则将创建一个Web版的IoC容器：**ServletWebServerApplicationContext**。在该容器启动时，通过**TomcatServletWebServerFactory**创建出一个Tomcat服务器**tomcatWebServer**并调用其 **start()** 方法启动了Tomcat服务。\n\n**ServletWebServerApplicationContext**实现了**ApplicationContext**接口，本质上也是一个IoC容器。\n\n![image-20210807111225531](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807111225531.png)\n\n**ServletWebServerApplicationContext**将在启动时搜索**ServletWebServerFactory**（ServletWeb服务器工厂，用于生产ServletWeb服务器）\n\nSpring Boot底层默认有很多的**ServletWebServerFactory**：\n\n- `TomcatServletWebServerFactory`\n- `JettyServletWebServerFactory`\n- `UndertowServletWebServerFactory`\n\n这些工厂由**ServletWebServerFactoryAutoConfiguration**导入的**ServletWebServerFactoryConfiguration**（ServletWeb服务器工厂配置类）自动注册到容器中：\n\n![image-20210807112649353](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807112649353.png)\n\n因此，在**ServletWebServerApplicationContext**启动时：\n\n- 注册**ServletWebServerFactoryAutoConfiguration**自动配置类；\n- 该自动配置类将导入**ServletWebServerFactoryConfiguration**工厂配置类；\n- 该工厂配置类根据动态判断系统中到底导入了哪个Web服务器的包（默认导入Tomcat的包），注册相应的**WebServlet服务器**：\n  - `TomcatServletWebServerFactory`\n  - `JettyServletWebServerFactory`\n  - `UndertowServletWebServerFactory`\n- 使用默认导入的**TomcatServletWebServerFactory**创建出Tomcat服务器并启动。\n\n**ServletWebServerApplicationContext**在启动时，将调用其重写的 **onRefresh()** 方法，用于创建Web服务器**webServer**：\n\n![image-20210807142357270](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807142357270.png)\n\n创建**webServer**的流程：\n\n- 获取当前场景支持的Web服务器工厂，默认为**TomcatServletWebServerFactory**\n- 使用该工厂创建Tomcat的Web服务器对象**webServer**，并在该对象构造器中调用 **start()** 方法开启Tomcat服务\n\n![image-20210807143433400](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807143433400.png)\n\n![image-20210807144851940](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807144851940.png)\n\n![image-20210807145011358](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807145011358.png)\n\n内嵌服务器工作原理：手动调用要启动的服务器的 **start()** 方法开启服务。\n\n### 切换Servlet容器\n\n要想切换服务器，则导入相应的starter场景即可：\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-web</artifactId>\n    <exclusions>\n        <exclusion>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-tomcat</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-undertow</artifactId>\n</dependency>\n```\n\n### 定制Servlet容器\n\n- 修改配置文件中的 `server.xxx` 属性（最方便）\n- 自定义**ConfigurableServletWebServerFactory**代替**TomcatServletWebServerFactory**，并将其注册到容器中\n- 实现  `WebServerFactoryCustomizer<ConfigurableServletWebServerFactory>` ，把配置文件的值和**ServletWebServerFactory**进行绑定（**xxxCustomizer**：定制化器，可以改变xxx的默认规则）：\n\n```java\n@Component\npublic class MyTomcatWebServerFactoryCustomizer implements WebServerFactoryCustomizer<TomcatServletWebServerFactory> {\n\n    @Override\n    public void customize(TomcatServletWebServerFactory server) {\n        server.addConnectorCustomizers((connector) -> connector.setAsyncTimeout(Duration.ofSeconds(20).toMillis()));\n    }\n\n}\n```\n\n## 定制化原理\n\n### Spring Boot定制化的四种方式\n\n1. 修改配置文件中的属性值以定制化；\n2. 编写自定义的配置类 **xxxConfiguration**，通过使用 **@Bean** 注解向容器中添加自定义的组件（例如视图解析器等）；\n3. 编写 **xxxCustomizer**，重写其方法以实现定制化；\n4. **常用：编写一个实现了WebMvcConfigurer某些接口的配置类，并添加@Configuration注解**。在该配置类中添加各种功能（例如添加拦截器，消息转换器，内容协商策略等）。注意这时不能标注 **@EnableWebMvc** 注解（若开启，则变成全面接管Spring MVC，就需要把所有Spring MVC配置好的规则全部自定义实现）\n\n方式4使用示例：\n\n```java\n@Configuration\npublic class myConfig implements WebMvcConfigurer {\n\n    // 添加自定义的拦截器\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(new LoginInterceptor())\n            .addPathPatterns(\"/**\")   // 写 /** 时所有请求都会被拦截，包括静态资源\n            .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/fonts/**\",\"/images/**\",\"/js/**\");\n    }\n\n    // 添加自定义的Converter，用于根据url中传入的字符串解析POJO内容\n    @Override\n    public void addFormatters(FormatterRegistry registry) {\n        registry.addConverter(new Converter<String, Person>() {\n            @Override\n            public Person convert(String s) {\n                Person person = new Person();\n                // 定制化的解析方法...\n                return person;\n            }\n        });\n    }\n\n    // 添加自定义的消息转换器，用于转换自定义的媒体格式\n    @Override\n    public void extendMessageConverters(List<HttpMessageConverter<?>> converters) {\n        converters.add(new MyMessageConverter());\n    }\n\n    @Override\n    public void configureContentNegotiation(ContentNegotiationConfigurer configurer) {\n        // 指定三种媒体类型映射关系\n        Map<String, MediaType> mediaTypes = new HashMap<>();\n        mediaTypes.put(\"json\", MediaType.APPLICATION_JSON);\n        mediaTypes.put(\"xml\", MediaType.APPLICATION_XML);\n        mediaTypes.put(\"myFormat\", MediaType.parseMediaType(\"application/x-zhao\"));\n\n        // 基于请求参数的内容协商策略：支持解析哪些参数对应哪些媒体类型\n        ParameterContentNegotiationStrategy parameterStrategy =\n            new ParameterContentNegotiationStrategy(mediaTypes);\n        // parameterStrategy.setParameterName(\"format\");\n\n        // 基于请求头的内容协商策略\n        HeaderContentNegotiationStrategy headerStrategy = new HeaderContentNegotiationStrategy();\n\n        configurer.strategies(Arrays.asList(parameterStrategy, headerStrategy));\n    }\n\n}\n```\n\n### 定制化原理\n\n**@EnableWebMvc** 注解会向容器中导入一个**DelegatingWebMvcConfiguration**，其作用是：\n\n1. 向容器中添加一些**最基础**的组件，例如映射器等\n2. 添加系统中所有的**WebMvcConfigurer**（包括自定义的），令这些定制的功能都生效\n\n![image-20210807155031104](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807155031104.png)\n\n**DelegatingWebMvcConfiguration**继承自**WebMvcConfigurationSupport**，用于添加所有的**WebMvcConfigurer**：\n\n![image-20210807160226619](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807160226619.png)\n\n**DelegatingWebMvcConfiguration**只能向容器中添加比较基础的组件（只保证最基础的应用，静态资源映射解析等功能均无法实现）。\n\n==即开启了 **@EnableWebMvc** 注解，将向容器中添加**DelegatingWebMvcConfiguration**，其只能实现**最基础**的应用（以及开发人员自己添加的应用），无法实现Spring Boot中默认配置的许多高级功能（例如静态资源映射解析等）==\n\n而这些更高级的功能，都由**WebMvcAutoConfiguration**完成注册：\n\n**WebMvcAutoConfiguration**是Spring Boot中默认的Spring MVC自动配置类：\n\n![image-20210807155131164](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210807155131164.png)\n\n其向容器中注册了许多Spring MVC相关的**高级功能组件**：例如Rest风格过滤器，消息转换器等。其若想生效，需要满足 **@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)** ，即容器中不能存在**WebMvcConfigurationSupport**类型的组件。\n\n而**DelegatingWebMvcConfiguration**类正是继承自**WebMvcConfigurationSupport**。因此若使用了 **@EnableWebMvc** 注解，则其 **@Import** 导入的**DelegatingWebMvcConfiguration**将使得功能更加完善的**WebMvcAutoConfiguration**失效，从而导致许多高级功能（如静态资源映射解析）无法生效。\n\n==因此使用了 **@EnableWebMvc** 注解就无法再开启**WebMvcAutoConfiguration**中的功能，就需要开发人员**全面接管**Spring MVC。==\n\n总结：若想定制化功能，则编写一个实现了**WebMvcConfigurer**某些接口的配置类，并添加 **@Configuration** 注解。注意这时不能标注 **@EnableWebMvc** 注解。\n\n## Spring Boot 启动原理\n\nSpring Boot程序从主程序配置类的main方法开始执行：\n\n![image-20210818155426532](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818155426532.png)\n\n调用`SpringApplication`类的静态方法`run()`，将Spring Boot主程序配置类传入：\n\n![image-20210818155701782](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818155701782.png)\n\n![image-20210818155917510](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818155917510.png)\n\nSpring Boot整个启动过程分为两个阶段：\n\n- 创建**SpringApplication**\n- 运行**SpringApplication.run()**\n\n### 创建 SpringApplication\n\n![image-20210818160118910](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818160118910.png)\n\n调用有参构造器初始化`SpringApplication`，从`spring.factories`文件中读取：\n\n- **bootstrappers**：初始化启动引导器\n- **ApplicationContextInitializer**：应用容器初始化器\n- **ApplicationListener**：应用容器监听器 \n\n这些组件会在后续的`run()`方法中使用，用于向IoC容器中配置相应的环境\n\n![image-20210818161738903](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818161738903.png)\n\n上述`getSpringFactoriesInstances()`方法用于从`spring.factories`中读取配置属性。`spring.factories`：\n\n```factories\n...\n\n# Application Context Initializers\norg.springframework.context.ApplicationContextInitializer=\\\norg.springframework.boot.context.ConfigurationWarningsApplicationContextInitializer,\\\norg.springframework.boot.context.ContextIdApplicationContextInitializer,\\\norg.springframework.boot.context.config.DelegatingApplicationContextInitializer,\\\norg.springframework.boot.rsocket.context.RSocketPortInfoApplicationContextInitializer,\\\norg.springframework.boot.web.context.ServerPortInfoApplicationContextInitializer\n\n# Application Listeners\norg.springframework.context.ApplicationListener=\\\norg.springframework.boot.ClearCachesApplicationListener,\\\norg.springframework.boot.builder.ParentContextCloserApplicationListener,\\\norg.springframework.boot.context.FileEncodingApplicationListener,\\\norg.springframework.boot.context.config.AnsiOutputApplicationListener,\\\norg.springframework.boot.context.config.DelegatingApplicationListener,\\\norg.springframework.boot.context.logging.LoggingApplicationListener,\\\norg.springframework.boot.env.EnvironmentPostProcessorApplicationListener,\\\norg.springframework.boot.liquibase.LiquibaseServiceLocatorApplicationListener\n\n...\n```\n\n### 运行SpringApplication.run()\n\n在**SpringApplication**创建完毕后，将调用其`run()`方法以启动**SpringApplication**。\n\n```java\npublic class SpringApplication {\n\n    ...\n\n        public ConfigurableApplicationContext run(String... args) {\n        StopWatch stopWatch = new StopWatch(); // 创建计时器\n        stopWatch.start(); // 开始计时，记录应用的启动时间\n\n        // 1.创建引导上下文bootstrapContext（Context环境）\n        // 获取到所有bootstrappers逐个执行intitialize()来完成对引导启动器上下文环境的设置\n        // bootstrappers在SpringApplication创建时从spring.factories里读取到\n        DefaultBootstrapContext bootstrapContext = createBootstrapContext();\n\n        // 2.到run()方法最终执行完毕会返回一个ConfigurableApplicationContext，其就是Spring IoC容器\n        ConfigurableApplicationContext context = null;\n\n        // 3.让当前应用进入headless模式（Headless模式是系统的一种配置模式。在该模式下，系统缺少了显示设备、键盘或鼠标）\n        configureHeadlessProperty();\n\n        // 4.获取所有RunListener（运行监听器），为了方便所有Listener进行事件感知\n        SpringApplicationRunListeners listeners = getRunListeners(args);\n\n        // 5.遍历SpringApplicationRunListener调用starting()方法；\n        // 相当于通知所有感兴趣系统正在启动过程的人，项目正在starting。\n        listeners.starting(bootstrapContext, this.mainApplicationClass);\n        try {\n            // 6.保存命令行参数 ApplicationArguments\n            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);\n\n            // 7.准备配置环境\n            ConfigurableEnvironment environment = prepareEnvironment(listeners, bootstrapContext, applicationArguments);\n            configureIgnoreBeanInfo(environment);\n\n            /*打印标志\n              .   ____          _            __ _ _\n             /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n            ( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n             \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n              '  |____| .__|_| |_|_| |_\\__, | / / / /\n             =========|_|==============|___/=/_/_/_/\n             :: Spring Boot ::                (v2.4.2)\n            */\n            Banner printedBanner = printBanner(environment);\n\n            // 创建IoC容器：createApplicationContext（）\n            // 根据项目类型webApplicationType（NONE,SERVLET,REACTIVE）创建容器，\n            // 当前会创建 AnnotationConfigServletWebServerApplicationContext\n            context = createApplicationContext();\n            context.setApplicationStartup(this.applicationStartup);\n\n            // 8.准备ApplicationContext IoC容器的基本信息\n            prepareContext(bootstrapContext, context, environment, listeners, applicationArguments, printedBanner);\n\n            // 9.刷新IOC容器,创建容器中的所有组件，这部分属于Spring IoC启动原理内容\n            refreshContext(context);\n\n            // 该方法没内容，大概为将来填入\n            afterRefresh(context, applicationArguments);\n            stopWatch.stop(); // 停止计时\n            if (this.logStartupInfo) { // this.logStartupInfo默认是true\n                new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);\n            }\n            // 10.通知所有的监听器started()\n            listeners.started(context);\n\n            // 11.调用所有runners\n            callRunners(context, applicationArguments);\n        }\n        catch (Throwable ex) {\n            // 处理运行失败错误，调用Listener的failed()\n            handleRunFailure(context, ex, listeners);\n            throw new IllegalStateException(ex);\n        }\n\n        try {\n            // 12. 通知所有的监听器running()\n            listeners.running(context);\n        }\n        catch (Throwable ex) {\n            // 13. 处理运行失败错误，调用Listener的failed()\n            handleRunFailure(context, ex, null);\n            throw new IllegalStateException(ex);\n        }\n        return context;\n    }\n\n    // 1.创建引导上下文bootstrapContext（Context环境）并逐一调用初始化方法\n    private DefaultBootstrapContext createBootstrapContext() {\n        DefaultBootstrapContext bootstrapContext = new DefaultBootstrapContext();\n        this.bootstrappers.forEach((initializer) -> initializer.intitialize(bootstrapContext));\n        return bootstrapContext;\n    }\n\n    // 3.让当前应用进入headless模式（Headless模式是系统的一种配置模式。在该模式下，系统缺少了显示设备、键盘或鼠标）\n    private void configureHeadlessProperty() {\n        //this.headless默认为true\n        System.setProperty(SYSTEM_PROPERTY_JAVA_AWT_HEADLESS,\n                           System.getProperty(SYSTEM_PROPERTY_JAVA_AWT_HEADLESS, Boolean.toString(this.headless)));\n    }\n\n    private static final String SYSTEM_PROPERTY_JAVA_AWT_HEADLESS = \"java.awt.headless\";\n\n    // 4.获取所有RunListener（运行监听器），为了方便所有Listener进行事件感知\n    private SpringApplicationRunListeners getRunListeners(String[] args) {\n        Class<?>[] types = new Class<?>[] { SpringApplication.class, String[].class };\n        //getSpringFactoriesInstances 去 spring.factories 找 SpringApplicationRunListener\n        return new SpringApplicationRunListeners(logger,\n                                                 getSpringFactoriesInstances(SpringApplicationRunListener.class, types, this, args),\n                                                 this.applicationStartup);\n    }\n\n    // 7.准备配置环境\n    private ConfigurableEnvironment prepareEnvironment(SpringApplicationRunListeners listeners,\n                                                       DefaultBootstrapContext bootstrapContext, ApplicationArguments applicationArguments) {\n        // Create and configure the environment\n        //返回或者创建基础环境信息对象，如：StandardServletEnvironment, StandardReactiveWebEnvironment\n        ConfigurableEnvironment environment = getOrCreateEnvironment();\n        //配置环境信息对象,读取所有的配置源的配置属性值。\n        configureEnvironment(environment, applicationArguments.getSourceArgs());\n        //绑定环境信息\n        ConfigurationPropertySources.attach(environment);\n        // 7.1 通知所有的监听器当前环境准备完成\n        listeners.environmentPrepared(bootstrapContext, environment);\n        DefaultPropertiesPropertySource.moveToEnd(environment);\n        configureAdditionalProfiles(environment);\n        bindToSpringApplication(environment);\n        if (!this.isCustomEnvironment) {\n            environment = new EnvironmentConverter(getClassLoader()).convertEnvironmentIfNecessary(environment,\n                                                                                                   deduceEnvironmentClass());\n        }\n        ConfigurationPropertySources.attach(environment);\n        return environment;\n    }\n\n    // 8.准备ApplicationContext IoC容器的基本信息\n    private void prepareContext(DefaultBootstrapContext bootstrapContext, ConfigurableApplicationContext context,\n                                ConfigurableEnvironment environment, SpringApplicationRunListeners listeners,\n                                ApplicationArguments applicationArguments, Banner printedBanner) {\n        // 保存环境信息\n        context.setEnvironment(environment);\n        // IOC容器的后置处理流程\n        postProcessApplicationContext(context);\n        // 应用初始化器\n        applyInitializers(context);\n        // 8.1 遍历所有的 listener 调用 contextPrepared。\n        // EventPublishRunListenr通知所有的监听器contextPrepared\n        listeners.contextPrepared(context);\n        bootstrapContext.close(context);\n        if (this.logStartupInfo) {\n            logStartupInfo(context.getParent() == null);\n            logStartupProfileInfo(context);\n        }\n        // Add boot specific singleton beans\n        ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();\n        beanFactory.registerSingleton(\"springApplicationArguments\", applicationArguments);\n        if (printedBanner != null) {\n            beanFactory.registerSingleton(\"springBootBanner\", printedBanner);\n        }\n        if (beanFactory instanceof DefaultListableBeanFactory) {\n            ((DefaultListableBeanFactory) beanFactory)\n            .setAllowBeanDefinitionOverriding(this.allowBeanDefinitionOverriding);\n        }\n        if (this.lazyInitialization) {\n            context.addBeanFactoryPostProcessor(new LazyInitializationBeanFactoryPostProcessor());\n        }\n        // Load the sources\n        Set<Object> sources = getAllSources();\n        Assert.notEmpty(sources, \"Sources must not be empty\");\n        load(context, sources.toArray(new Object[0]));\n        // 8.2 监听器加载上下文\n        listeners.contextLoaded(context);\n    }\n\n    // 11.调用所有runners\n    private void callRunners(ApplicationContext context, ApplicationArguments args) {\n        List<Object> runners = new ArrayList<>();\n\n        // 获取容器中的ApplicationRunner\n        runners.addAll(context.getBeansOfType(ApplicationRunner.class).values());\n        // 获取容器中的CommandLineRunner\n        runners.addAll(context.getBeansOfType(CommandLineRunner.class).values());\n        // 合并所有runner并且按照@Order进行排序\n        AnnotationAwareOrderComparator.sort(runners);\n        // 遍历所有的runner，调用run方法\n        for (Object runner : new LinkedHashSet<>(runners)) {\n            if (runner instanceof ApplicationRunner) {\n                callRunner((ApplicationRunner) runner, args);\n            }\n            if (runner instanceof CommandLineRunner) {\n                callRunner((CommandLineRunner) runner, args);\n            }\n        }\n    }\n\n    // 13.处理运行失败错误，调用Listener的failed()\n    private void handleRunFailure(ConfigurableApplicationContext context, Throwable exception,\n                                  SpringApplicationRunListeners listeners) {\n        try {\n            try {\n                handleExitCode(context, exception);\n                if (listeners != null) {\n                    //14.\n                    listeners.failed(context, exception);\n                }\n            }\n            finally {\n                reportFailure(getExceptionReporters(context), exception);\n                if (context != null) {\n                    context.close();\n                }\n            }\n        }\n        catch (Exception ex) {\n            logger.warn(\"Unable to close ApplicationContext\", ex);\n        }\n        ReflectionUtils.rethrowRuntimeException(exception);\n    }\n\n    ...\n}\n```\n\n`SpringApplication(primarySources).run(args)` 最后返回的IoC容器`context`：\n\n``` java\npublic interface ConfigurableApplicationContext extends ApplicationContext, Lifecycle, Closeable {\n    String CONFIG_LOCATION_DELIMITERS = \",; \\t\\n\";\n    String CONVERSION_SERVICE_BEAN_NAME = \"conversionService\";\n    String LOAD_TIME_WEAVER_BEAN_NAME = \"loadTimeWeaver\";\n    String ENVIRONMENT_BEAN_NAME = \"environment\";\n    String SYSTEM_PROPERTIES_BEAN_NAME = \"systemProperties\";\n    String SYSTEM_ENVIRONMENT_BEAN_NAME = \"systemEnvironment\";\n    String APPLICATION_STARTUP_BEAN_NAME = \"applicationStartup\";\n    String SHUTDOWN_HOOK_THREAD_NAME = \"SpringContextShutdownHook\";\n\n    void setId(String var1);\n\n    void setParent(@Nullable ApplicationContext var1);\n\n    void setEnvironment(ConfigurableEnvironment var1);\n\n    ConfigurableEnvironment getEnvironment();\n\n    void setApplicationStartup(ApplicationStartup var1);\n\n    ApplicationStartup getApplicationStartup();\n\n    void addBeanFactoryPostProcessor(BeanFactoryPostProcessor var1);\n\n    void addApplicationListener(ApplicationListener<?> var1);\n\n    void setClassLoader(ClassLoader var1);\n\n    void addProtocolResolver(ProtocolResolver var1);\n\n    void refresh() throws BeansException, IllegalStateException;\n\n    void registerShutdownHook();\n\n    void close();\n\n    boolean isActive();\n\n    ConfigurableListableBeanFactory getBeanFactory() throws IllegalStateException;\n}\n```\n\n上文源码中的**SpringApplicationRunListeners**运行监听器需要配置在`spring.factories`文件里，例如**EventPublishingRunListener**事件发布运行监听器：\n\n```factories\n# Run Listeners\norg.springframework.boot.SpringApplicationRunListener=\\\norg.springframework.boot.context.event.EventPublishingRunListener\n```\n\n**SpringApplicationRunListeners**运行监听器：\n\n```java\nclass SpringApplicationRunListeners {\n\n    private final Log log;\n\n    private final List<SpringApplicationRunListener> listeners;\n\n    private final ApplicationStartup applicationStartup;\n\n    SpringApplicationRunListeners(Log log, Collection<? extends SpringApplicationRunListener> listeners,\n                                  ApplicationStartup applicationStartup) {\n        this.log = log;\n        this.listeners = new ArrayList<>(listeners);\n        this.applicationStartup = applicationStartup;\n    }\n\n    // 5.遍历 SpringApplicationRunListener 调用starting()方法；\n    // 相当于通知所有感兴趣系统正在启动过程的人，项目正在starting。\n    void starting(ConfigurableBootstrapContext bootstrapContext, Class<?> mainApplicationClass) {\n        doWithListeners(\"spring.boot.application.starting\", (listener) -> listener.starting(bootstrapContext),\n                        (step) -> {\n                            if (mainApplicationClass != null) {\n                                step.tag(\"mainApplicationClass\", mainApplicationClass.getName());\n                            }\n                        });\n    }\n\n    // 7.1\n    void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) {\n        doWithListeners(\"spring.boot.application.environment-prepared\",\n                        (listener) -> listener.environmentPrepared(bootstrapContext, environment));\n    }\n\n    // 8.1\n    void contextPrepared(ConfigurableApplicationContext context) {\n        doWithListeners(\"spring.boot.application.context-prepared\", (listener) -> listener.contextPrepared(context));\n    }\n\n    // 8.2\n    void contextLoaded(ConfigurableApplicationContext context) {\n        doWithListeners(\"spring.boot.application.context-loaded\", (listener) -> listener.contextLoaded(context));\n    }\n\n    // 10.\n    void started(ConfigurableApplicationContext context) {\n        doWithListeners(\"spring.boot.application.started\", (listener) -> listener.started(context));\n    }\n\n    // 12.\n    void running(ConfigurableApplicationContext context) {\n        doWithListeners(\"spring.boot.application.running\", (listener) -> listener.running(context));\n    }\n\n    // 14.\n    void failed(ConfigurableApplicationContext context, Throwable exception) {\n        doWithListeners(\"spring.boot.application.failed\",\n                        (listener) -> callFailedListener(listener, context, exception), (step) -> {\n                            step.tag(\"exception\", exception.getClass().toString());\n                            step.tag(\"message\", exception.getMessage());\n                        });\n    }\n\n    private void doWithListeners(String stepName, Consumer<SpringApplicationRunListener> listenerAction,\n                                 Consumer<StartupStep> stepAction) {\n        StartupStep step = this.applicationStartup.start(stepName);\n        this.listeners.forEach(listenerAction);\n        if (stepAction != null) {\n            stepAction.accept(step);\n        }\n        step.end();\n    }\n\n    ...\n\n}\n```\n\n### 自定义事件监听组件\n\n`MyApplicationContextInitializer.java`\n\n```java\nimport org.springframework.context.ApplicationContextInitializer;\nimport org.springframework.context.ConfigurableApplicationContext;\n\npublic class MyApplicationContextInitializer implements ApplicationContextInitializer {\n    @Override\n    public void initialize(ConfigurableApplicationContext applicationContext) {\n        System.out.println(\"MyApplicationContextInitializer ....initialize.... \");\n    }\n}\n```\n\n`MyApplicationListener.java`\n\n```java\nimport org.springframework.context.ApplicationEvent;\nimport org.springframework.context.ApplicationListener;\n\npublic class MyApplicationListener implements ApplicationListener {\n    @Override\n    public void onApplicationEvent(ApplicationEvent event) {\n        System.out.println(\"MyApplicationListener.....onApplicationEvent...\");\n    }\n}\n```\n\n`MyApplicationRunner.java`\n\n```java\nimport org.springframework.boot.ApplicationArguments;\nimport org.springframework.boot.ApplicationRunner;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n\n\n@Order(1)\n@Component//放入容器\npublic class MyApplicationRunner implements ApplicationRunner {\n    @Override\n    public void run(ApplicationArguments args) throws Exception {\n        System.out.println(\"MyApplicationRunner...run...\");\n    }\n}\n```\n\n`MyCommandLineRunner.java`\n\n``` java\nimport org.springframework.boot.CommandLineRunner;\nimport org.springframework.core.annotation.Order;\nimport org.springframework.stereotype.Component;\n/**\n * 应用启动做一个一次性事情\n */\n@Order(2)\n@Component//放入容器\npublic class MyCommandLineRunner implements CommandLineRunner {\n    @Override\n    public void run(String... args) throws Exception {\n        System.out.println(\"MyCommandLineRunner....run....\");\n    }\n}\n```\n\n`MySpringApplicationRunListener.java`\n\n``` java\nimport org.springframework.boot.ConfigurableBootstrapContext;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.SpringApplicationRunListener;\nimport org.springframework.context.ConfigurableApplicationContext;\nimport org.springframework.core.env.ConfigurableEnvironment;\n\npublic class MySpringApplicationRunListener implements SpringApplicationRunListener {\n\n    private SpringApplication application;\n    public MySpringApplicationRunListener(SpringApplication application, String[] args){\n        this.application = application;\n    }\n\n    @Override\n    public void starting(ConfigurableBootstrapContext bootstrapContext) {\n        System.out.println(\"MySpringApplicationRunListener....starting....\");\n\n    }\n\n\n    @Override\n    public void environmentPrepared(ConfigurableBootstrapContext bootstrapContext, ConfigurableEnvironment environment) {\n        System.out.println(\"MySpringApplicationRunListener....environmentPrepared....\");\n    }\n\n\n    @Override\n    public void contextPrepared(ConfigurableApplicationContext context) {\n        System.out.println(\"MySpringApplicationRunListener....contextPrepared....\");\n\n    }\n\n    @Override\n    public void contextLoaded(ConfigurableApplicationContext context) {\n        System.out.println(\"MySpringApplicationRunListener....contextLoaded....\");\n    }\n\n    @Override\n    public void started(ConfigurableApplicationContext context) {\n        System.out.println(\"MySpringApplicationRunListener....started....\");\n    }\n\n    @Override\n    public void running(ConfigurableApplicationContext context) {\n        System.out.println(\"MySpringApplicationRunListener....running....\");\n    }\n\n    @Override\n    public void failed(ConfigurableApplicationContext context, Throwable exception) {\n        System.out.println(\"MySpringApplicationRunListener....failed....\");\n    }\n}\n```\n\n注册`MyApplicationContextInitializer`，`MyApplicationListener`，`MySpringApplicationRunListener`到当前项目的`resources / META-INF / spring.factories`中：\n\n``` factories\norg.springframework.context.ApplicationContextInitializer=\\\n  com.lun.boot.listener.MyApplicationContextInitializer\n\norg.springframework.context.ApplicationListener=\\\n  com.lun.boot.listener.MyApplicationListener\n\norg.springframework.boot.SpringApplicationRunListener=\\\n  com.lun.boot.listener.MySpringApplicationRunListener\n```\n\n## Spring MVC 执行流程\n\n\n\n![image-20210715165846578](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715165846578.png)\n\n![image-20210719204334058](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210719204334058.png)\n\n![image-20210731205850800](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731205850800.png)\n\n==超链接==\n\n==重新截图带上拦截器里面的所有整合==\n\n截图时带上异常处理的内容\n\n\n\n下面将详细分析Spring MVC的执行流程，分别分析**请求映射原理**、**参数解析原理**、**内容协商原理**、**视图解析原理**等。并在其中穿插Spring MVC执行过程中的==n==大主线：\n\n- 主线1. 获取请求处理器：**this.getHandler()**\n- 主线2. 获取目标处理器的适配器：**this.getHandlerAdapter()**\n- 主线3. 使用适配器执行目标方法：**ha.handle()**\n- 主线4. 使用ModelAndView进行视图解析：**processDispatchResult()**\n\n## DispatcherServlet\n\n**DispatcherServlet**类继承自**FrameworkServlet**类，该类最终继承自**HttpServlet**类。==**其本质上也是一个Servlet，也需要注册到Tomcat中才能响应到客户端传来的请求。**==\n\n![image-20210715163040938](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715163040938.png)\n\n**FrameworkServlet**类中有多个处理请求的方法（`doGet/doPost/doPut/doDelete`），他们都调用了同一个方法`this.processRequest(request, response)`。（**DispatcherServlet**类中并没有重写这些`doXxx`方法和`processRequest()`方法，因此调用的是**FrameworkServlet**类里的这些方法）\n\n![image-20210715162521522](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715162521522.png)\n\n`processRequest(request, response)`方法中最关键的一步为调用`this.doService(request, response)`方法。但该方法在**FrameworkServlet**类中为抽象方法，需要子类实现，因此调用的是**DispatcherServlet**类里的 **this.doService(request, response)** 方法。\n\n![image-20210715162814683](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715162814683.png)\n\n**FrameworkServlet**类重写的 **doService()** 方法：\n\n![image-20210715163548801](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715163548801.png)\n\n该方法调用了**FrameworkServlet**中的 **doDispatch(request, response)** 方法：\n\n![image-20210715163935578](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715163935578.png)\n\n因此分析清楚 **doDispatch(request, response)** 方法即可理解Spring MVC的原理。上述关系树见下图：\n\n![image-20210715164354367](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715164354367.png)\n\n### 在Tomcat中注册DispatcherServlet \n\nSpring Boot中有一个自动配置类：**DispatcherServletAutoConfiguration**。其用于进行**DispatcherServlet**的自动注册和配置。\n\n**DispatcherServlet**将在Spring Boot启动时添加到容器中，该组件绑定了**WebMvcProperties**配置类，其对应的配置文件前缀为 **\"spring.mvc\"** ，修改该前缀下的属性即可自定义功能。\n\n![image-20210803202035420](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210803202035420.png)\n\n但仅仅将**DispatcherServlet**注册到容器中还不够，**此时该组件尚未与Tomcat服务器产生联系，Tomcat服务器并不能使用该Servlet进行请求映射**（即此时客户端发来的请求 **\"/\"** 并不能被**DispatcherServlet**获取到，而会有Tomcat中存在的其他Servlet获取进行请求映射）。因此需要将**DispatcherServlet**注册到Tomcat中才能响应到客户端传来的请求。\n\n使用**DispatcherServletRegistrationBean**将**DispatcherServlet**注册到Tomcat中：\n\n![image-20210803203720388](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210803203720388.png)\n\n**DispatcherServletRegistrationBean**用于向Tomcat服务器中注册配置**DispatcherServlet**，并为其指定映射路径**webMvcProperties.getServlet().getPath()**，该值默认为 **\"/\"** ，开发人员也可以自定义该路径：\n\n```properties\nspring.mvc.servlet.path=\"/my/\"\n```\n\n**DispatcherServletRegistrationBean**继承自 **`ServletRegistrationBean<DispatcherServlet>`** ，其是一种**Servlet注册组件**，用于向Tomcat服务器中注册配置Web原生**Servlet**组件，此时的泛型为**DispatcherServlet**类型，因此会向Tomcat服务器中注册配置**DispatcherServlet**。\n\n![image-20210803204836013](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210803204836013.png)\n\n==**总结**==：使用**DispatcherServletRegistrationBean**向Tomcat中注册了**DispatcherServlet**后，Tomcat即可将符合 **\"/\"** 的请求映射到**DispatcherServlet**。之后客户端发来符合要求的请求时，即可执行**DispatcherServlet**的 **doDispatch()** 方法，从而进行后续的请求映射、参数解析、数据响应和视图解析等步骤（见下文分析）。\n\n---\n\n补充：Tomcat路径的优先精确匹配原则\n\n在Tomcat中若配置了多个Servlet，则将优先匹配更精确的路径，例如**DispatcherServlet**的匹配路径为`\"/\"`，自定义的其他Servlet的匹配路径为`\"/my/\"`，则Tomcat将优先匹配到更精确的Servlet，而不会匹配到**DispatcherServlet**。此时该请求将不再被容器中配置的拦截器所拦截，也不能使用**DispatcherServlet**的页面转发等功能，只能使用原生的Servlet方法。\n\n![image-20210803212019087](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210803212019087.png)\n\n---\n\n## 文件上传原理\n\n标准文件上传解析器**StandardServletMultipartResolver**由**MultipartAutoConfiguration**注册到容器中：\n\n![image-20210801203151706](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801203151706.png)\n\n其绑定了**MultipartProperties**属性：\n\n![image-20210801203234072](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801203234072.png)\n\n### 包装原始请求：this.checkMultipart(request)\n\n==此处开始分析 **doDispatch()** 方法==：\n\n进入 **doDispatch()** 方法后，首先进行**文件上传请求包装**： **this.checkMultipart(request)**\n\n![image-20210715165846578](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715165846578.png)\n\n进入**this.checkMultipart(request)** 方法后，将调用唯一的一个参数解析器**StandardServletMultipartResolver**判断当前请求是否是文件上传请求：\n\n![image-20210801204553429](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801204553429.png)\n\n参数解析器**StandardServletMultipartResolver**判断的方式 **isMultipart() **为：\n\n![image-20210801204739367](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801204739367.png)\n\n如果当前请求是文件上传请求，则将当前请求封装成一个**StandardMultipartHttpServletRequest**类型的请求：\n\n![image-20210801205746126](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801205746126.png)\n\n后续分析使用的请求就是这个已经被封装后的**StandardMultipartHttpServletRequest**请求。\n\n### 解析文件内容\n\n获得包装后的请求后，该请求中包含的文件内容将在 **ha.handle()** 方法中进行解析：\n\n在所有的参数解析器中有一个请求文件参数解析器**RequestPartMethodArgumentResolver**，Spring MVC将使用该解析器将请求中的文件内容封装成一个**MultipartFile**对象。\n\n![image-20210801210620885](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801210620885.png)\n\n解析得到的文件类型**MultipartFile**：\n\n![image-20210801214140507](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801214140507.png)\n\n关于文件上传参数解析器的具体细节见[文件上传参数解析器](#文件上传参数解析器)\n\n## 请求映射原理\n\n经过文件上传的封装后，即开始进行请求映射：\n\n### 主线1. 获取请求处理器：this.getHandler() \n\n![image-20210715165846578](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715165846578.png)\n\n**this.getHandler()**：根据当前的**url请求地址**`（\"/hello\"）`判断哪个**控制器**（`@Controller`）里的**目标方法**（`@RequestMapping(\"/hello\")`）与之对应：\n\n**url：\"/hello\" ——> HelloController#handle01() 方法**\n\n![image-20210720135457338](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720135457338.png)\n\n**this.getHandler()** 方法返回的**mappedHandler**对象的类型为**HandlerExecutionChain**，即**目标方法处理器的执行链**，其内保存了与当前请求地址`\"/hello\"`匹配的目标方法**HelloController#handle01()** （这个请求信息在容器启动时就添加到了**RequestMappingHandlerMapping**中，因此可以在后续匹配到）:\n\n![image-20210720094927124](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720094927124.png)\n\n**this.getHandler() 方法内部细节**：\n\n---\n\n**this.getHandler()** 方法传入了`HttpServletRequest`类型的请求对象，其内包含了响应的url等信息：\n\n![image-20210720101645865](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720101645865.png)\n\n==**this.handlerMappings**：**处理器映射器**==，其内保存了每一个处理器能处理映射的方法信息。（以下为Spring Boot中存在的映射器，纯Spring MVC工程中只有两个`handlerMapping`，分别为基于xml方式的**BeanNameUrlHandlerMapping**和基于注解方式的**RequestMappingHandlerMapping**）\n\n![image-20210720095314175](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720095314175-1627472434897.png)\n\n==**RequestMappingHandlerMapping**里保存了所有 **@RequestMapping** 与 **handler** 的映射规则==，为**基于注解方式**的处理器映射器，其内包含了所有开发人员自定义的`@RequestMapping`方法，**mappingRegistry**属性保存了所有的映射信息：\n\n![image-20210720101836077](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720101836077.png)\n\nIoC容器在启动创建`@Controller`对象时扫描每个控制器的方法能响应什么请求，并保存在**RequestMappingHandlerMapping**对象的**mappingRegistry**属性中（该属性中保存了所有开发人员自定义的基于注解的控制器信息）。下一次请求过来，判断`handlerMapping`中有无存在匹配的映射关系。\n\n![image-20210720101645865](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720101645865.png)\n\n在**getHandler()** 方法中，依次遍历所有的**handlerMapping**对象，其会解析当前传入的`request`对象，判断哪个**handlerMapping**对象符合当前的url请求信息，将符合信息的返回一个**HandlerExecutionChain**对象。下图为匹配到的`handler`，该`handler`内保存了该url请求对应的目标 **HelloController#handle01()** 方法：\n\n![image-20210720105316770](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720105316770.png)\n\n---\n\n**this.getHandler() 总结**\n\n![image-20210720101645865](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720101645865.png)\n\n在**this.getHandler()** 方法内遍历每个**HandlerMapping**，判断哪个**HandlerMapping**能处理当前的请求地址（开发人员自定义的方法将由**RequestMappingHandlerMapping**处理），并返回一个**HandlerExecutionChain**对象。\n\n其中IoC容器在启动时就会向**HandlerMapping**内保存每个`@RequestMapping(\"xxx\")`信息，以在后续收到浏览器的url请求时能够匹配到对应的**RequestMappingHandlerMapping**处理器信息。\n\n### 主线2. 获取目标处理器的适配器：this.getHandlerAdapter()\n\n![image-20210719204334058](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210719204334058.png)\n\n将上一步得到的**请求映射处理器mappedHandler**传入到 **this.getHandlerAdapter()** 方法中，返回该处理器所对应的**适配器adapter**：\n\n![image-20210720141752006](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720141752006.png)\n\n共有四种类型的适配器：\n\n![image-20210720141620095](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720141620095.png)\n\n其中**RequestMappingHandlerAdapter**是基于**注解**方式的适配器，对应于**RequestMappingHandlerMapping**。后续步骤将使用该适配器执行目标方法（基于反射机制）。\n\n至此，分析了**请求映射**原理，即根据请求url的不同映射得到相应的请求处理器与适配器，接着使用该适配器 **ha.handle()** 执行目标方法（基于反射机制）。\n\n\n\n### 拦截器\n\n\n\n==补充拦截器原理==\n\n\n\n### 主线3. 使用适配器执行目标方法：ha.handle()\n\n![image-20210719204334058](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210719204334058.png)\n\n在主线2中得到**处理器适配器HandlerAdapter**后，调用其 **ha.handler()** 方法执行目标方法。\n\n**ha.handler()** 方法最终返回的**ModelAndView**对象`mv`，其中既包括了要转发的目标页面视图名，又包括了目标方法保存在`Model/Map`中的数据：\n\n![image-20210728215546942](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210728215546942.png)\n\n进入 **ha.handler()** 方法后，将通过调用 **this.invokeHandlerMethod()** 执行目标方法，得到的`mav`即为 **ha.handler()** 方法返回的**ModelAndView**对象`mv`：\n\n![image-20210720144223605](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210720144223605.png)\n\n**this.invokeHandlerMethod()** 方法内部细节：\n\n---\n\n![image-20210724153751013](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724153751013.png)\n\n![image-20210725215637180](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725215637180.png)\n\n==上述方法运行完后invocableMethod内的信息==：截图带上getModelAndVIew\n\n![image-20210724161349706](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724161349706.png)\n\n==全部分析完后修改，重新截图带上文件上传==流程图\n\n大致流程如下：\n\n**准备工作**：\n\n- 首先将传入的目标方法处理器**handlerMethod**（其内保存了**HelloController#handle01()** 的信息）封装成一个可执行的处理器方法**invocableMethod**，后续使用该对象执行目标方法；\n- 为**invocableMethod**设置**参数解析器argumentResolvers**，用于解析目标方法传来的所有参数值；为**invocableMethod**设置**返回值处理器returnValueHandlers**，用于定义方法的返回值支持的类型；为**invocableMethod**设置其他信息；\n\n**准备工作完成后**，即可调用该对象的 **invokeAndHandle()** 方法，利用反射机制真正执行目标方法：\n\n- 目标方法执行前，先==使用**参数解析器argumentResolver**解析目标方法传入的所有参数==，得到`Object[] args`，其内保存了所有解析后的参数对象信息，例如解析完毕后已赋值的POJO以及内容尚且为空的`Model/Map`对象。【详细分析见[**参数解析原理**](#参数解析原理)章节】\n  - `Model/Map`均为接口，程序运行时实际上是通过多态性质创建的是唯一的一个**BindingAwareModelMap**类型的对象；\n  - 该对象此时内容为空，因为还未给其赋值，将在目标方法执行时为其赋值。\n- 得到参数后，基于**反射机制**执行目标方法 **HelloController#handle01()** 。【详细分析见[**参数解析原理**](#参数解析原理)章节】\n  - 目标方法使用参数解析器解析出的`args[]`执行业务逻辑代码；\n  - 经过目标方法的执行，**BindingAwareModelMap**中保存的内容将被保存到**ModelAndViewContainer**类型的对象`mavContainer`中，同时目标方法参数中的POJO（从请求参数中确定值）也会被保存到`mavContainer`中；\n  - `mavContainer`中保存的`Model/Map`数据将在 **getModelAndView()** 方法执行后保存到**ModelAndView**类型对象`mv`中，并作为返回值返回给上一侧 **ha.handle()** ；\n  - 在主线4里使用该**ModelAndView**类型对象进行**视图解析**等操作。其内容最终都会**被保存到request域中**。【详细分析见[**视图解析原理**](#视图解析原理)章节】\n- 目标方法执行完毕后，==使用**返回值处理器returnValueHandlers**处理目标方法的返回值==，此时根据返回值类型的不同分为多种情况【详细分析见[**数据响应与内容协商原理**](#数据响应与内容协商原理)章节】：\n  - 若目标方法使用 **@ResoponseBody** 注解，即要返回JSON等格式的数据，则进行**内容协商**，使用**转换器Converters**将POJO数据内容转换为指定格式（如JSON、XML等）\n  - 若返回值为要跳转的页面视图名，则将返回值`\"/sucess\"`作为视图名**viewName**保存到**ModelAndView**对象`mv`中，主线4将使用该对象进行页面转发\n- 处理完返回值后，将执行 **getModelAndView()** 方法将`mavContainer`对象转换成**ModelAndView**对象`mv`，返回给 **ha.handle()** 方法，用于后续的视图解析。\n\n---\n\n下文将详细分析上述流程。\n\n## 参数解析原理\n\n在**this.invokeHandlerMethod()** 方法内，首先将传入的目标方法处理器**handlerMethod**（其内保存了**HelloController#handle01()** 的信息）封装成一个可执行的处理器方法**invocableMethod**，后续使用该对象执行目标方法；\n\n接着为**invocableMethod**设置**参数解析器argumentResolvers**，用于解析目标方法传来的所有参数值（橙色框）：\n\n![image-20210724153751013](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724153751013.png)\n\n为**invocableMethod**设置完参数解析器和返回值处理器后，将调用其 **invokeAndHandle()** 方法：\n\n![image-20210725215637180](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725215637180.png)\n\n该方法将先后完成**解析目标方法参数**、**基于反射机制执行目标方法**、**处理目标方法返回值**：\n\n![image-20210725171847138](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725171847138.png)\n\n![image-20210724161138834](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724161138834.png)\n\n![image-20210724161223870](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724161223870.png)\n\n**invocableMethod.invokeAndHandle()** 方法内逻辑：\n\n- **invokeForRequest()**：解析参数并执行目标方法\n  1. **Object[] args = getMethodArgumentValues()** ：解析获取目标方法的所有参数值(例如[解析POJO内容](#pojo参数解析器)，[解析原生Servlet API](#原生servlet-api解析器)，[解析Model/Map](#modelmap参数解析器))\n  2. **doInvoke(args)** ：利用反射机制执行目标方法（该方法返回`mavContainer`对象，其中保存`Model/Map`中的内容、目标方法参数中的POJO内容（从请求参数中确定值）以及要跳转的视图名`viewName`）\n- **returnValueHandlers.handleReturnValue()**：处理目标方法返回值，分两种情况【详细分析见[**数据响应与内容协商原理**](#数据响应与内容协商原理)章节】：\n  1. 若目标方法使用 **@ResoponseBody** 注解，即要返回JSON等格式的数据，则进行**内容协商**，使用**转换器Converters**将POJO数据内容转换为指定格式（如JSON、XML等）\n  2. 若返回值为要跳转的页面视图名，则将返回值`\"/sucess\"`作为视图名**viewName**保存到**ModelAndView**对象`mv`中，==主线4==将使用该对象进行页面转发\n\n本章节将分析 **invokeForRequest()** 方法内的细节：\n\n### 解析参数：getMethodArgumentValues() \n\n![image-20210724161138834](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724161138834.png)\n\n **getMethodArgumentValues()** 方法（上图黄色框）用于进行目标方法的参数解析，将参数解析完毕后，返回的`args[]`中存储了所有参数信息（`Model/Map`里的内容还都为空，因为此时还未执行目标方法），之后调用 **doInvoke(args)** 执行目标方法，将`Model/Map`中的内容保存到`mavContainer`对象中。 **getMethodArgumentValues()** 方法内的逻辑如下：\n\n![image-20210724163554136](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724163554136.png)\n\n首先获取所有参数**parameters**，然后逐一遍历每一个参数，寻找能解析该参数的[参数解析器](#参数解析器：argumentResolvers)。其中最关键的两处 **this.resolvers.supportsParameter()** 和 **this.resolvers.resolveArgument()** (黄色框和绿色框)：\n\n- **this.resolvers.supportsParameter()** ：遍历每个参数解析器，判断参数解析器是否支持当前参数\n-  **this.resolvers.resolveArgument()** ：若支持当前参数，则使用该解析器解析参数，返回解析得到的参数`args[i]`\n\n **this.resolvers.supportsParameter()** ：遍历每个参数解析器，判断参数解析器是否支持当前参数，若找不到符合的参数解析器，则抛出异常：\n\n![image-20210801212435861](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801212435861.png)\n\n其中，传入的`parameter`为目标方法中的每一个参数：\n\n![image-20210725163947016](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725163947016.png)\n\n **this.resolvers.resolveArgument()** ：在该方法内首先调用 **getArgumentResolver()** 方法获取到匹配的参数解析器（遍历每一个参数解析器，寻找到符合的），再调用匹配到的参数解析器的 **resolveArgument()** 方法解析当前参数：\n\n![image-20210801212341993](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801212341993.png)\n\n **getArgumentResolver()** 方法内遍历每一个参数解析器，寻找到匹配的参数解析器：\n\n![image-20210724163420298](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724163420298-1627527227460.png)\n\n若支持当前参数，则使用该解析器解析参数，返回解析得到的参数`args[i]`。示例：获取要解析的参数名，并使用servlet原生API解析该值：\n\n![image-20210724165301621](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724165301621.png)\n\n遍历所有参数并解析后，得到`Object[] args`，接着调用 **doInvoke(args)** 执行目标方法，该方法返回`mavContainer`对象，其中保存`Model/Map`中的内容以及要跳转的视图名`viewName`，供后续返回值处理使用。\n\n![image-20210724161138834](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724161138834.png)\n\n至此目标方法执行完毕，得到了`mavContainer`对象用于后续的返回值处理操作【详细分析见[**数据响应与内容协商原理**](#数据响应与内容协商原理)章节】\n\n### 参数解析器：argumentResolvers\n\n**argumentResolvers**内存储了所有Spring MVC支持的参数解析器，每个参数注解都对应了一个参数解析器，如 **@RequestParam** 注解对应**RequestParamMethodArgumentResolver**解析器：\n\n![image-20210724152930296](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724152930296.png)\n\n这些参数解析器都实现了**HandlerMethodArgumentResolver**接口，将首先调用**supportsParameter()** 方法判断是否能够解析传入的参数类型，若可以则执行**参数解析方法resolveArgument()** 解析参数：\n\n![image-20210724153442677](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724153442677.png)\n\n### 常用参数解析器\n\n![image-20210725153449237](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725153449237.png)\n\n#### 原生Servlet-API解析器\n\n**ServletRequestMethodArgumentResolver**用于解析原生的Servlet API，例如**ServletRequest、HttpSession**等：\n\n![image-20210725153121790](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725153121790.png)\n\n#### 文件上传参数解析器\n\n文件上传参数解析器为**RequestPartMethodArgumentResolver**，该解析器重写的 **supportParameter()** 方法（其会判断当前参数是否标有 **@RequestPart** 注解）：\n\n![image-20210801212958379](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801212958379.png)\n\n该解析器重写的 **resolveArgument()** 方法：\n\n![image-20210801213316328](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801213316328.png)\n\n返回的 **Object mpArg** 即为解析得到的**MultipartFile**类型的对象或数组：\n\n![image-20210801214140507](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210801214140507.png)\n\n解析参数时，将标注有 **@RequestPart** 注解的参数都存放到了一个 **MultiValueMap<String, MultipartFile>** 中，之后获取值的时候直接从该map中 **get(name)** 即可。\n\n#### Model/Map参数解析器\n\n`Model`和`Map`的参数解析器在解析完毕后都会返回**同一个BindingAwareModelMap**对象，但此对象中还没有保存内容（`size=0`），因为此时目标方法还未执行，还没有向`Model/Map`中存放内容。在目标方法执行时才为其赋值，并保存到**ModelAndViewContainer**对象`mavContainer`中，其内容最终都会**被保存到request域中**。示例：\n\n```java\n@GetMapping(\"/testMap\")\npublic String testMapParam(Map<String, Object> map,\n                           Model model,\n                           HttpServletRequest request,\n                           HttpServletResponse response) {\n    map.put(\"map\", \"this is map\");\n    model.addAttribute(\"model\", \"this is model\");\n    request.setAttribute(\"request\", \"this is request\");\n\n    Cookie cookie = new Cookie(\"cookie\", \"cookie\");\n    response.addCookie(cookie);\n    return \"forward:/success\";\n}\n\n@ResponseBody\n@GetMapping(\"/success\")\npublic Map success(HttpServletRequest request) {\n    Object mapValue = request.getAttribute(\"map\");\n    Object modelValue = request.getAttribute(\"model\");\n    Object requestValue = request.getAttribute(\"request\");\n\n    Map<String, Object> map = new HashMap<>();\n    map.put(\"map\", mapValue);\n    map.put(\"model\", modelValue);\n    map.put(\"request\", requestValue);\n\n    return map;\n}\n```\n\n---\n\n补充：使用`Map`，`Model `和`ModelMap`本质上是使用了Spring的**BindingAwareModelMap**在工作，相当于在`BindingAwareModelMap`中保存的数据**都会放到请求域中**。Spring MVC在运行时拥有唯一的一个`BindingAwareModelMap`对象，各个方法中获取到的`Map/ModelMap`都会被转换成同一个该对象，从而可以做到多个方法中的数据共享。\n\n![image-20210715151056836](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210715151056836.png)\n\n\n\n1. Map解析器：**MapMethodProcessor**\n\n![image-20210724163554136](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724163554136-1627531852946.png)\n\n![image-20210725165354073](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725165354073.png)\n\n该解析器会从**ModelAndViewContatiner**对象中获取到**BindingAwareModelMap**对象。注意此时解析方法返回的**BindingAwareModelMap**对象中还没有保存内容（`size=0`），因为此时目标方法还未执行，还没有向`map`中存放属性值，将在后续赋值并将内容存放到`request`域中。\n\n![image-20210725165951720](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725165951720.png)\n\n**ModelAndViewContatiner**对象中的**BindingAwareModelMap**：\n\n![image-20210725165001942](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725165001942.png)\n\n2. Model解析器：**ModelMethodProcessor**\n\n![image-20210725164443575](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725164443575.png)\n\n该解析器逻辑与`Map`解析器相同，会返回同一个**BindingAwareModelMap**对象。\n\n经过`Map`和`Model`解析器后，返回的两个**BindingAwareModelMap**对象是**同一个对象**，说明Spring MVC在运行时拥有**唯一**的一个`BindingAwareModelMap`对象，各个方法中获取到的`Model/Map/ModelMap`内容都会转换成同一个`BindingAwareModelMap`对象中，其内容最终都会被保存到`request`域中。\n\n![image-20210725165951720](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725165951720.png)\n\n#### POJO参数解析器\n\n自定义类型参数使用**ServletModelAttributeMethodProcessor**参数解析器解析。其会先判断传入的参数是否是简单类型，自定义类型不是简单类型，因此黄色框整体返回true，该解析器将进行解析：\n\n![image-20210725210434816](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725210434816.png)\n\n简单类型如下：\n\n![image-20210725210610893](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725210610893.png)\n\n在解析时首先创建一个空的POJO组件（其内属性值都为Null），之后再将`request`域中的数据和POJO封装成一个**WebDataBinder数据绑定器**。该绑定器内有许多**转换器Converters**（见下文），用于将HTTP协议中的数据进行转换解析（例如将`String`转换成`Integer`）：\n\n![image-20210725211316411](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725211316411.png)\n\n![image-20210725221333706](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725221333706.png)\n\n- **binderFactory.createBinder()** 方法将`request`域中的值保存到POJO中，并封装返回了一个**WebDataBinder**类型变量，即**web数据绑定器**。该绑定器内不仅有POJO的所有属性，也有许多**conversionService**转换服务器（其内有许多**converters**转换器），==用于将HTTP请求传来的数据进行解析转换（例如将String转换成Integer）==。\n- **bindRequestParameters(binder, webRequest)** 方法将解析转换后的值绑定到POJO的属性中。\n\n==即**WebDataBinder**利用它里面的**converters**将请求数据转换成指定的数据类型，并绑定到POJO属性中，从而完成了POJO的创建==\n\n`binder`中的内容：\n\n![image-20210725220853504](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725220853504.png)\n\n在绑定每一个属性值时，遍历所有的`Converter`转换当前属性，并将其绑定到POJO的属性上。解析完毕后返回该参数对象加入到`args[]`中，开发人员可以自定义`Converter`接口的实现类，实现自定义的参数解析功能：\n\n![image-20210725223637931](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725223637931.png)\n\n---\n\n补充：自定义`Converter`解析请求中的参数：\n\n![image-20210726140103808](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726140103808.png)\n\n---\n\n## 数据响应与内容协商原理\n\n上一章[**参数解析原理**](#参数解析原理)分析了**参数解析**和**目标方法执行**的细节（下图中黄色框），本章将分析后续的数据响应与内容协商原理（处理目标方法返回值，下图中橙色框）：**returnValueHandlers.handleReturnValue()** \n\n![image-20210725171847138](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725171847138.png)\n\n在上一章节分析的目标方法执行完毕后，获得了**ModelAndViewContainer**类型的对象`mavContainer`，其内保存了要跳转的视图页面`viewName`和`Model/Map`中的内容。将该参数和返回值、`webRequest`参数传入到 **returnValueHandlers.handleReturnValue()** 方法中，下面详细分析该方法内的细节：\n\n### 处理返回值：handleReturnValue()\n\n![image-20210726142110761](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726142110761.png)\n\n进入该方法后，首先调用**selectHandler()** 方法：遍历所有的**返回值处理器returnValueHandlers**判断哪个处理器能处理目标方法的返回值（使用 **supportsReturnType()** 方法）：\n\n![image-20210726143359134](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726143359134.png)\n\n---\n\n#### 返回值处理器：returnValueHandlers\n\n**returnValueHandlers**的作用为处理目标方法的返回值，不同的处理器用于处理不同类型的目标方法返回值\n\nSpring MVC支持的返回值类型：\n\n- ModelAndView\n- Model\n- View\n- ResponseEntity\n- ResponseBodyEmitter \n- StreamingResponseBody \n- HttpEntity \n- HttpHeaders \n- Callable \n- DeferredResult\n- ListenableFuture \n- CompletionStage \n- WebAsyncTask\n- 标注了**@ModelAttribute**注解且为对象类型的\n- 标注了**@ResponseBody**注解，对应**RequestResponseBodyMethodProcessor**\n\n每种类型都对应着一个返回值处理器**returnValueHandler**：\n\n![image-20210724154755603](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210724154755603.png)\n\n---\n\n![image-20210726142110761](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726142110761.png)\n\n如果找到支持的返回值处理器，则执行其 **handler.handleReturnValue()** 方法。其中，**handleReturnValue()** 方法会根据返回值处理器**handler**类型的不同而执行不                                                                                                                                                                                                              同的重写方法：\n\n- 如果目标方法返回`String`类型对象，代表要跳转到某个页面\n- 如果目标方法标注了 **@ResponseBody** 注解，则代表默认要返回JSON类型数据（也可以自定义其他类型\n\n下面逐一分析两种情况的细节。\n\n### 1. 目标方法返回String类型对象\n\n如果目标方法返回`String`类型对象，代表要跳转到某个页面。此时的返回值处理器类型为：**ViewNameMethodReturnValueHandler**。\n\n此时返回值类型是字符串序列，则`handleReturnValue()`方法将要跳转的视图名`viewName`保存到了**ModelAndViewContainer**对象`mavContainer`中，此时其内既保存了`Model/Map`中的数据，又保存了要跳转的视图名`viewName`，之后会将该对象转换成一个**ModelAndView**对象，并利用其进行页面转发（见==视图解析原理==）：\n\n![](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725193659805.png)\n\n### 2. 目标方法标注了@ResponseBody注解\n\n如果目标方法标注了 **@ResponseBody** 注解，则代表默认要返回JSON类型数据（也可以自定义其他媒体类型）。此时返回值处理器为：**RequestResponseBodyMethodProcessor**。\n\n该处理器将遍历所有的 ==**消息转换器MessageConverters**==，使用匹配的消息转换器将数据转换成 ==**客户端指定的媒体类型格式**== （如JSON/XML）：\n\n![image-20210726160912631](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726160912631.png)\n\n**writeWithMessageConverters()** ：使用消息转换器**MessageConverters**将返回值对象写成指定的媒体类型数据，此处以JSON举例（也可以自定义媒体类型）：\n\n![image-20210726162256930](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726162256930.png)\n\n![image-20210729210852492](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210729210852492.png)\n\n![image-20210727164955683](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727164955683.png)\n\n此情况大致执行流程：\n\n- 获取目标方法返回值对象\n- 判断当前请求头（或者请求参数format属性值）是否已经有确定的**媒体类型MediaType**\n- ==获取客户端（包括浏览器，Postman）支持的媒体类型**acceptableTypes**==：获取客户端发来请求中请求头`Request Headers`里的**Accept**字段）：默认使用**基于请求头**的**内容协商策略**，从`Request Headers`中获取Accept里的内容，也可以自定义添加其他内容协商策略。具体细节见[内容协商原理](#内容协商原理)和[内容协商策略](#内容协商策略)\n- 根据返回值对象类型得到服务器端可生产的媒体类型**produciableTypes**：遍历所有的**消息转换器HttpMessageConverter**，==判断当前的返回值对象类型能转换成什么类型的媒体类型**produciableTypes**==\n- **双重循环**，判断哪两个**acceptableTypes**和**produciableTypes**能最佳匹配，==即寻找**服务器端能提供的媒体类型**和**客户端能接收的媒体类型**之间的最佳匹配==，匹配到的`MediaType`即为返回值需要转换成的媒体类型【此过程即为**内容协商**，具体细节见[内容协商原理](#内容协商原理)】\n- 再次遍历所有的**消息转换器HttpMessageConverter**，判断哪个转换器能将当前的返回值类型转换成上文中**匹配到的最佳媒体类型MediaType**（如JSON/XML），在找到符合的转换器后，将其转换成指定的媒体类型。具体细节见[消息转换原理](#消息转换原理)\n\n### 内容协商原理\n\n内容协商：将**客户端能接收的媒体数据类型**和**服务器能转换的媒体数据类型**协商到二者能最佳匹配统一。从而**根据客户端接收能力的不同**，返回不同**媒体类型MediaType**的数据（例如JSON，XML，自定义类型等）。借助此原理，可以实现将不同客户端平台发来的数据转换成不同的媒体类型数据（例如PC端转换成JSON，手机端转换成XML，或转换成自定义类型等）。大致流程：\n\n- 判断当前响应头`Request Headers`（或者url请求参数`format`属性值）中是否已经有确定的**媒体类型MediaType**（如JSON/XML）\n- 获取客户端（浏览器，Postman）支持的媒体类型**acceptableTypes**（获取客户端发来请求中`Request Headers`里的**Accept**字段）：默认使用**基于请求头**的**内容协商策略**，从`Request Headers`中获取`Accept`里的内容，也可以自定义添加其他内容协商策略。\n- 遍历循环所有当前**消息转换器HttpMessageConverters**，看哪个支持转换当前返回值对象类型（`Person`），返回服务器端可以支持将返回值类型转换成的媒体类型**producibleTypes**\n\n![image-20210727100112607](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727100112607.png)\n\n![image-20210727164303895](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727164303895.png)\n\n浏览器支持的媒体类型（在浏览器请求头信息里。默认XML类型权重更大）：\n\n![image-20210727100940697](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727100940697.png)\n\n这些媒体类型携带在浏览器的请求头信息里。**请求头Request Headers**告诉服务器，客户端具有接收什么类型数据的能力（`Accept`），其中XML媒体类型权重更大：\n\n![image-20210727094454018](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727094454018.png)\n\n>在使用Postman改变请求头中的`Accpet`字段后(Http协议中规定的字段)，服务器可以得知客户端可以接收的数据类型，就能根据客户端能够接收的媒体类型返回不同的数据格式。\n\n服务端针对当前类型`Person`能处理的媒体类型（默认只处理JSON媒体类型，开发人员也可以添加XML类型和自定义类型，具体分析见后文）：\n\n![image-20210727101036395](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727101036395.png)\n\n之后进行内容协商：遍历**acceptableTypes**和**producibleTypes**，看哪两个能最佳匹配：\n\n![image-20210727101559706](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727101559706.png)\n\n在匹配到合适的转换器`Converter`后，就继续向下执行：\n\n### 消息转换原理\n\n经过内容协商后，选出了客户端能接收的媒体类型**selectedMediaType**，之后根据该媒体类型和返回值对象类型遍历所有**消息转换器HttpMessageConverter**，判断哪个转换器**能写canWrite()** 当前对象，并使用其将返回值对象转换成指定的媒体类型**selectedMediaType**（例如JSON/XML）。\n\n![image-20210727164955683](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727164955683.png)\n\n注意：**HttpMessageConverter**先后使用了两次，第一次遍历所有的Converters，找到能处理客户端响应的最佳匹配媒体类型（此过程为内容协商），此时即知道了客户端能接收哪种媒体类型；第二次遍历所有的`Converters`，根据已经得知的媒体类型，判断哪个`Converter`能将目标方法返回值对象（Person）转换成该媒体类型，从而进行转换。\n\n其中不同的`Converter`有不同的 **write()** 方法：\n\n```java\n@Override\npublic void write(Person person, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException {\n    // 数据的写出协议，不通过的Converter不同\n    String data = person.getName() + \";\" + person.getAge() + \";\" + person.getBirth();\n\n    // 将数据写出到浏览器中\n    OutputStream body = outputMessage.getBody();\n    body.write(data.getBytes());\n}\n```\n### 消息转换器：HttpMessageConverter\n\n**消息转换器HttpMessageConverter**：判断是否支持转换某类型的对象，并将其转成**媒体类型MediaType**类型的数据，例如将`Person`对象转换成JSON格式；或者将JSON格式转换成`Person`对象。\n\n![image-20210726190152432](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726190152432.png)\n\n容器中默认存在10个消息转换器，每个消息转换器都有自己支持的**媒体类型MediaType**，用来转换不同类型的返回值对象（此时容器中没有）：\n\n![image-20210726190609377](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726190609377.png)\n\n- 0 - 支持`Byte`类型\n- 1 - 支持`String`类型\n- 3 - 支持`Resource`类型\n- ...\n- 7 - 直接返回true，说明它可以处理任何类型的对象（用于将任意对象转换成JSON格式）\n\n**MappingJackson2HttpMessageConverter**消息转换器放在最后使用，其 **canWrite()** 方法直接返回true，代表其**可以处理任何类型**的对象。该转换器可以将任意的引用类型对象转换成JSON类型（利用底层`jackson`的**objectMapper**转换）。其中`hb`属性中保存了转换后的JSON内容。\n\n![image-20210726191949357](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210726191949357.png)\n\n#### 自定义HttpMessageConverter\n\n所有的**HttpMessageConverter**合起来可以支持各种媒体类型的操作（读和写），开发人员可以自定义消息处理器：\n\n```java\npublic class MyMessageConverter implements HttpMessageConverter<Person> {\n\n    @Override\n    public boolean canRead(Class<?> clazz, MediaType mediaType) {\n        return false;\n    }\n\n    @Override\n    public boolean canWrite(Class<?> clazz, MediaType mediaType) {\n        return clazz.isAssignableFrom(Person.class);\n    }\n\n    // 服务器需要统计所有MessageConverter都能写哪些类型；自定义的消息转换器支持解析 \"x-zhao\" 类型的内容\n    @Override\n    public List<MediaType> getSupportedMediaTypes() {\n        return MediaType.parseMediaTypes(\"application/x-zhao\");\n    }\n\n    @Override\n    public Person read(Class<? extends Person> clazz, HttpInputMessage inputMessage) throws IOException, HttpMessageNotReadableException {\n        return null;\n    }\n\n    @Override\n    public void write(Person person, MediaType contentType, HttpOutputMessage outputMessage) throws IOException, HttpMessageNotWritableException {\n        // 自定义协议数据的写出\n        String data = person.getName() + \";\" + person.getAge() + \";\" + person.getBirth();\n\n        // 将数据写出\n        OutputStream body = outputMessage.getBody();\n        body.write(data.getBytes());\n    }\n}\n```\n\n```java\n@Configuration()\npublic class WebConfig {\n    @Bean\n    public WebMvcConfigurer webMvcConfigurer() {\n        return new WebMvcConfigurer() {\n            // 在容器中添加自定义的消息转换器，用于转换自定义的媒体格式\n            @Override\n            public void extendMessageConverters(List<HttpMessageConverter<?>> converters) {\n                converters.add(new MyMessageConverter());\n            }\n\n        }\n    }\n}\n```\n\n### XML转换器：MappingJackson2XmlHttpMessageConverter\n\n服务器端默认只能将客户端传来的数据转换成JSON媒体类型，若开发人员希望能够转换成其他类型的媒体数据（如XML或自定义类型数据），则可以向容器中添加相应的消息转换器。例如向容器中添加XML消息转换器：**MappingJackson2XmlHttpMessageConverter**，只需在`pom.xml`中添加依赖：\n\n```xml\n<dependency>\n    <groupId>com.fasterxml.jackson.dataformat</groupId>\n    <artifactId>jackson-dataformat-xml</artifactId>\n</dependency>\n```\n\n此时XML消息转换器就会自动注入到容器中：\n\n![image-20210727145909685](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727145909685.png)\n\n![image-20210727150016279](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727150016279.png)\n\n在导入了XML消息转换器后，再次使用浏览器发送请求访问服务器端，此时服务器端可支持转换的媒体类型**producibleTypes**增加了XML类型和自定义类型（浏览器端可接收的媒体类型仍然不变）：\n\n![image-20210730101533304](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210730101533304.png)\n\n这是因为此时容器中有了XML消息转换器，即下图中的9和10（11为自定义的消息转换器）：\n\n![image-20210730103255329](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210730103255329.png)\n\n浏览器支持的媒体类型**acceptableTypes**（在浏览器请求头信息里。默认xml类型权重更大）：\n\n![image-20210727100940697](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727100940697.png)\n\n![image-20210730104019859](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210730104019859.png)\n\n此时经过双重循环匹配**acceptableTypes**和**producibleTypes**后，得到的**mediaTypesToUse**集合的内容为：\n\n![image-20210730103149685](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210730103149685.png)\n\n此时已经将优先级权重体现了出来，橙色框内的XML类型优先级高于黄色框内的JSON类型，因此在后续寻找最佳匹配时，**会匹配到XML类型的消息转换器**。\n\n接着第二次遍历消息转换器，遍历到XML消息转换器后，将目标方法返回值转换成XML类型。\n\n**总结**：如果在`pom.xml`中添加了XML转换器的依赖，则会将目标方法返回值解析成XML类型，因为浏览器发来的请求头信息中XML的权重更大；如果没有导入该依赖，则还是默认使用JSON转换器将返回值转换成JSON格式。\n\n### 内容协商策略\n\nSpring MVC支持多种内容协商策略，例如：\n\n- 基于**请求头Request Headers**方式的内容协商策略\n- 基于**请求参数**方式的内容协商策略\n\n上文中分析的内容协商策略均为基于**请求头Request Headers**方式的内容协商策略，此种策略下**acceptableTypes**是从客户端发来请求的**请求头Request Headers**信息获取到的。开发人员也可以选择基于**请求参数**方式的内容协商策略，这种策略下，**acceptableTypes**将从**请求参数**中的**format**属性中获取到。\n\n开启基于请求参数的内容协商策略：\n\n```yaml\nspring:\n  mvc:\n    contentnegotiation:\n      favor-parameter: true\n```\n\n开启该注解后，即会在容器中创建**基于请求参数**方式的请求协商策略**ParameterContentNegotiationStrategy**，该策略会解析请求参数中的**format**属性值，判断是JSON还是XML，并据此进行内容协商。\n\n>  此时在浏览器中发送请求：http://localhost:8080/test/person?format=json 或 http://localhost:8080/test/person?format=xml \n\n**getAcceptableMediaTypes()** 方法内将使用内容协商管理器**contentNegotiationManager**解析媒体类型：\n\n![image-20210727141446187](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727141446187.png)\n\n若开启了**基于请求参数**方式的内容协商策略，则该管理器中将存在**ParameterContentNegotiationStrategy**策略，用于解析请求参数中的`format`属性值，该策略优先于默认的请求头协商策略**HeaderContentNegotiationStrategy**，即不再使用默认的解析请求头的方式。\n\n![image-20210727142409445](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727142409445.png)\n\n- 0 - **ParameterContentNegotiationStrategy**：基于**请求头Request Headers**方式的内容协商策略\n- 1 - **HeaderContentNegotiationStrategy**：基于**请求参数**方式的内容协商策略\n\n**注意，此策略只支持JSON和XML**，如果想自定义新的格式，需要：\n\n```java\n@Configuration()\npublic class WebConfig {\n\n    @Bean\n    public WebMvcConfigurer webMvcConfigurer() {\n        return new WebMvcConfigurer() {\n            @Override\n            public void configureContentNegotiation(ContentNegotiationConfigurer configurer) {\n                // 指定三种媒体类型映射关系\n                Map<String, MediaType> mediaTypes = new HashMap<>();\n                mediaTypes.put(\"json\", MediaType.APPLICATION_JSON);\n                mediaTypes.put(\"xml\", MediaType.APPLICATION_XML);\n                mediaTypes.put(\"myFormat\", MediaType.parseMediaType(\"application/x-zhao\"));\n\n                // 基于请求参数的内容协商策略：支持解析哪些参数对应哪些媒体类型\n                ParameterContentNegotiationStrategy parameterStrategy =\n                    new ParameterContentNegotiationStrategy(mediaTypes);\n                // 可以自定义请求参数的属性名\n                // parameterStrategy.setParameterName(\"format\");\n\n                // 基于请求头的内容协商策略\n                HeaderContentNegotiationStrategy headerStrategy = new HeaderContentNegotiationStrategy();\n\n                configurer.strategies(Arrays.asList(parameterStrategy, headerStrategy));\n            }\n        };\n    }\n}\n```\n\n## 视图解析原理\n\n### 获取ModelAndView对象：getModelAndView()\n\n==**注意**：此时的方法栈仍然处于**主线3：ha.handle()** 方法中==。**getModelAndView() **方法为其内的最后一个方法，将返回**ModelAndView**对象`mv`用于后续的视图解析。\n\n![image-20210727193857347](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210727193857347.png)\n\n**getModelAndView()** 方法内：\n\n![image-20210731203910807](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731203910807.png)\n\n之后该**ModelAndView**对象`mv`将作为 **ha.handle()** 方法的返回值，用于后续的视图解析。\n\n==至此， **主线3：ha.handle()** 方法执行完毕。==\n\n### 主线4. 转发页面：this.processDispatchResult()\n\n**this.processDispatchResult()**：根据目标方法最终执行完成后封装的`ModelAndView`对象内的信息转发到相应的页面（页面信息保存在`viewName`里），并且可以从请求域中取出`ModelAndView`中保存的数据。\n\n![image-20210731205850800](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731205850800.png)\n\n![image-20210725201730427](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725201730427.png)\n\n该方法内调用 **render()** 方法：\n\n![image-20210731210317048](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731210317048.png)\n\n![image-20210731212421271](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731212421271.png)\n\n该方法调用 **resolveViewName()** 方法解析出该视图名对应的**View**类型对象，其定义了页面的渲染逻辑。之后将调用 **view.render()** 方法渲染页面。\n\n **resolveViewName()** 方法内遍历了所有的视图解析器，依次判断哪个能解析当前返回值，并使用匹配的解析器解析出**View**类型对象：\n\n![image-20210731210848419](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731210848419.png)\n\n共有5种视图解析器，其中**ContentNegotiatingViewResovler内容协商视图解析器**中包含了其他四种解析器：\n\n![image-20210731211417134](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731211417134.png)\n\n**ContentNegotiatingViewResovler内容协商视图解析器**解析视图名的方法：\n\n![image-20210731211605005](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731211605005.png)\n\n![image-20210731212028693](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731212028693.png)\n\n可以看出该方法内本质上还是依次遍历了其他四种视图解析器，判断哪个能解析当前视图名。\n\n 在遍历得到匹配的视图解析器后，将解析出对应的**View**类型对象，不同类型的返回值对应了不同的**View**类型对象：\n\n- **\"redirect:xxx\"** 对应 **RedirectView**\n- **\"forward:xxx\"** 对应 **InternalResourceView**\n- **\"/xxx\"**  对应 **ThymeleafView**\n\n\n\n最后调用 **view.render()** 方法渲染页面。不同的View类型对应了不同的渲染方法。\n\n![image-20210731212427561](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210731212427561.png)\n\n**RedirectView**类型渲染逻辑：\n\n- 获取要重定向的url地址，调用 **response.sendRedirect(encodedURL)** 方法进行重定向。\n\n**InternalResourceView**类型渲染逻辑：\n\n- **request.getRequestDispatcher(path).forward(request, response)**\n\n---\n\n补充：经过许多层调用后，在 **exposeModelAsRequestAttributes()** 方法内将前面**ModelAndView**里存放的值放到请求域中：\n\n![image-20210725202336384](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210725202336384.png)\n\n---\n\n至此，主线4分析完毕，完成了视图的解析与跳转。\n\n\n\n## 异常处理原理\n\n异常处理自动配置类**ErrorMvcAutoConfiguration**。其会在Spring Boot启动时被加载，该配置类会向容器中注册一些异常处理相关的组件：\n\n![image-20210802215420259](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802215420259.png)\n\n![image-20210802164252572](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802164252572.png)\n\n![image-20210802190349481](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802190349481.png)\n\n该配置类向容器中注册的异常处理相关组件：\n\n- **DefaultErrorAttributes**：在request域中保存异常信息，定义错误页面里能包含哪些内容。实现了**ErrorAttributes**接口和**HandlerExceptionResolver**接口（也是一种处理器异常解析器，用于将错误信息保存到request域中，安达市多撒）。其内保存了错误的状态信息。【该类用于自定义错误页面包含哪些信息】\n- **BasicErrorController**：处理异常错误消息的控制器，标注了 **@Controller** 注解。【该类用于进行异常错误消息的请求映射】\n  - 其用于处理默认的异常请求 `@RequestMapping(/error)`。\n  - 若是发浏览器端发来的`\"text/html\"`类型请求后，则返回一个 `new ModelAndView(\"error\", model)`\n  - 否则返回JSON类型的错误信息`ResponseEntity(body, status)`\n- **StaticView`(id=\"error\")`**：错误页面视图，实现了**View**接口。其 **render()** 方法定义了页面渲染的逻辑（渲染出**白页**错误信息页面）【该类用于渲染出**白页**错误信息页面】\n- **BeanNameViewResolver**：组件名称视图解析器，是视图解析器的一种。按照目标方法返回的视图名作为组件的id去容器中查找View对象。其用于按照组件名`\"error\"`去容器中查找到上述错误页面视图**StaticView**组件。【该类用于按照组件名称查找View对象】\n- **DefaultErrorViewResolver**：错误视图解析器，是视图解析器的一种。如果浏览器发送的url请求出现错误，则会以HTTP的状态码`status.series()`作为视图页地址`viewName`，返回一个**ModelAndView**对象。去找`error/`目录下对应的`404.html` 或 `5xx.html` 资源。【该类用于自定义指定错误视图的跳转规则】\n\n白页是谁解析的\n\n下面介绍这些组件的细节：\n\n### DefaultErrorAttributes\n\n**DefaultErrorAttributes**：在request域中保存异常信息，定义错误页面里能包含哪些内容。实现了**ErrorAttributes**接口和**HandlerExceptionResolver**接口。\n\n其内保存了错误的状态信息，并会在解析异常时调用 **resolveException()** 方法，==将异常信息存储在request域中==，并返回一个`null`的**ModelAndView**（此处分析见【异常处理执行流程】）。\n\n==**该类最关键的作用**==：在每个异常请求进来时首先使用该类进行解析，将异常信息保存在request域中，从而告诉服务器当前请求有异常，需要再次派发一个 **`\"/error\"`** 请求给**DispatchServlet**，该请求中保存了所有的异常信息，因此响应这个 **`\"/error\"`** 请求时就可以获取到了完整的异常信息，交给**DefaultErrorViewResolver**解析该异常请求。\n\n![image-20210802205927018](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802205927018.png)\n\n![image-20210802191937364](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802191937364.png)\n\n### BasicErrorController\n\n**BasicErrorController**：处理异常消息的控制器，标注了 **@Controller** 注解。\n\n当服务器端收到错误的url请求时==，将触==发`\"/error\"`，此时Spring MVC会将此请求映射到控制器**BasicErrorController**的 **errorHtml()** 方法或 **error()** 方法。\n\n**情况一**：若此请求的媒体类型为`\"text/html\"`，则将执行 **errorHtml()** 方法，该方法将返回一个 `viewName=\"error\"` 的**ModelAndView**。之后在视图解析步骤中将使用**BeanNameViewResolver**（组件名称视图解析器）去容器中查找`viewName`为`\"error\"`的**View**，并调用其**render()** 渲染出**白页**错误信息页面。（此种情况就解释了为什么在浏览器端访问了错误的url后会显示“白页”） DefaultViewErrorResolver还是 beanname\n\n**情况二**：若请求来自于非浏览器的其他机器，则将返回JSON类型的错误信息。\n\n![image-20210802213620722](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802213620722.png)\n\n### StaticView\n\n**StaticView**实现了**View**接口，也是一种视图。其 **render()** 方法将渲染出**白页**错误信息页面：\n\n![image-20210802192305382](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802192305382.png)\n\n### BeanNameViewResolver\n\n**BeanNameViewResolver**：组件名称视图解析器，是视图解析器的一种。其会按照目标方法返回的视图名作为组件的id去容器中查找View对象。\n\n![image-20210802185022754](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802185022754.png)\n\n**BasicErrorController.errorHtml()** 方法返回了`viewName=\"error\"`的视图**StaticView**。该解析器会按照组件名`\"error\"`去容器中查找到该`StaticView`组件，找到该组件后调用其 **render()** 方法渲染出**白页**错误信息页面\n\n### DefaultErrorViewResolver\n\n**DefaultErrorViewResolver**：错误视图解析器，是视图解析器的一种。如果浏览器发送的url请求出现错误，则会以HTTP的状态码`status.series()`作为视图页地址`viewName`，返回一个**ModelAndView**对象。去找`error/`目录下对应的`404.html` 或 `5xx.html` 资源。\n\n![image-20210802191120478](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802191120478.png)\n\n### 异常处理执行流程\n\n在 **doDispatch(request, response)** 方法中，目标方法的执行过程中出现的任何异常，都会被**dispatchException**捕获到：\n\n![image-20210802201853375](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802201853375.png)\n\n![image-20210802212022373](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802212022373.png)\n\n之后进入视图解析 **processDispatchResult()** ：\n\n![image-20210802202538535](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802202538535.png)\n\n关键分析 **processHandlerException()** 方法，该方法内处理了异常消息，并返回了一个**ModelAndView**对象。该方法内遍历了容器中存在的所有**处理器异常解析器HandlerExceptionResolver**，判断哪一个能处理当前异常：\n\n![image-20210802204759380](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802204759380.png)\n\n![image-20210802211043922](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802211043922.png)\n\n循环过程中，直到某个解析器解析异常后返回的**exMv**不为`null`，才跳出循环，默认没有任何解析器能够解析出exMv，异常将被抛出回 **processDispatchResult()** 所在的方法栈。该异常被catch后，将倒序执行**mappedHandler**中所有已执行过的拦截器的 **afterCompletion()** 方法：\n\n![image-20210802212022373](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802212022373.png)\n\n此时，当前带有异常的请求的执行流程分析完毕，此时并没有进行页面跳转等操作。接着，Spring MVC的底层将发送一个url为`\"/error\"`的请求，该请求将由**BasicErrorController**处理（见上文分析）\n\n\n\n\n\n\n\n---\n\n容器中默认存在的处理器异常解析器有：\n\n![image-20210802205006071](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802205006071.png)\n\n其中0 - **DefaultErrorAttributes** 即为之前分析过的**默认错误解析器**：\n\n**DefaultErrorAttributes**：定义错误页面里能包含哪些内容。实现了**ErrorAttributes**接口和**HandlerExceptionResolver**接口。\n\n其内保存了错误的状态信息，并会在解析异常时调用 **resolveException()** 方法，==将异常信息存储在request域中==，并返回一个`null`的**ModelAndView**：\n\n![image-20210802205927018](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210802205927018.png)\n\n---\n\n\n\n\n\n\n\n\n\n","tags":["源码分析","Spring","Spring Boot"],"categories":["源码分析","Spring","Spring Boot"]},{"title":"【Spring】Spring5 事务源码分析","url":"/2021/07/05/【Spring】Spring5-事务源码分析/","content":"\n## Spring声明式事务原理\n\n**@EnableTransactionManagement** 注解向容器中添加**AutoProxyRegistrar**和**ProxyTransactionManagementConfiguration**组件，二者作用分别为：\n\n- **AutoProxyRegistrar**：类似于AOP中的**AspectJAutoProxyRegistrar**，用于向容器中注册**InfrastructureAdvisorAutoProxyCreator**组件（类似于AOP里的自动代理器，一种后置处理器）来为普通组件进行代理包装，创建**代理对象**\n- **ProxyTransactionManagementConfiguration**：用于注册**事务增强器**，该增强器内设置有事务拦截器，将在代理对象执行目标方法时进行拦截，并调用其`invoke()`方法，**由事务管理器控制事务的提交与回滚**。\n\nSpring事务原理与AOP原理十分相似，都包含有**后置处理器**和**拦截器**思想，在组件创建后包装出代理对象、在代理对象执行目标方法时进行拦截，使用**事务管理器**控制事务的提交与回滚。\n\n<!--More -->\n\n## @EnableTransactionManagement\n\n要开启事务管理，配置类中需要**添加@EnableTransactionManagement。**其通过 **@Import** 注解向容器中导入**TransactionManagementConfigurationSelector**。\n\n![image-20210705162841045](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705162841045.png)\n\n**TransactionManagementConfigurationSelector**会根据`adviceMode`的值（见上图黄色框），选择导入什么类型的组件。默认导入：\n\n- **AutoProxyRegistrar**：类似于AOP中的**AspectJAutoProxyRegistrar**，用于向容器中注册**InfrastructureAdvisorAutoProxyCreator**组件（类似于AOP里的自动代理器，一种后置处理器）来为普通组件进行代理包装，创建代理对象\n- **ProxyTransactionManagementConfiguration**：用于注册**事务增强器**，该增强器内设置有事务拦截器，将在代理对象执行目标方法时进行拦截，并调用其`invoke()`方法，**由事务管理器控制事务的提交与回滚**。\n\n![image-20210705162739312](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705162739312.png)\n\n下面分别介绍**AutoProxyRegistrar**和**ProxyTransactionManagementConfiguration**的作用。\n\n## AutoProxyRegistrar\n\n**AutoProxyRegistrar**的作用类似于AOP中使用到的**AspectJAutoProxyRegistrar**。二者都能向容器中注册一个**自动代理创建器**的定义（见黄色框）\n\n- **AutoProxyRegistrar**：注册**InfrastructureAdvisorAutoProxyCreator**（基础的自动代理器）\n- **AspectJAutoProxyRegistrar**：注册**AnnotationAwareAspectJAutoProxyCreator**（注解装配模式的自动代理器）\n\n二者注册的自动代理创建器都实现了**SmartInstantiationAwareBeanPostProcessor**接口和**BeanFactoryAware**接口，因此都是一种**特殊的后置处理器**。\n\n![image-20210705165313341](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705165313341.png)\n\n![image-20210705165700051](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705165700051.png)\n\n### InfrastructureAdvisorAutoProxyCreator\n\n它实现了**SmartInstantiationAwareBeanPostProcessor**接口和**BeanFactoryAware**接口，是一种**特殊的后置处理器**。它的作用和**AnnotationAwareAspectJAutoProxyCreator**相似，都会在普通组件创建前后进行拦截，调用后置处理器的`postProcessAfterInitialization()`方法，将普通组件进行包装（wrap），为其创建一个代理对象（其内含有相应的增强器）。该代理对象在执行目标方法时，会被事务拦截器所拦截，并由事务管理器控制事务的提交与回滚。\n\n![image-20210705175257029](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705175257029.png)\n\n## ProxyTransactionManagementConfiguration\n\n**ProxyTransactionManagementConfiguration**被`@Configuration`修饰，是一个配置类。它会给容器中注册一个**事务增强器 BeanFactoryTransactionAttributeSourceAdvisor**。该增强器需要设置两个对象：\n\n- **事务注解属性解析器 TransactionAttributeSource**：用以解析事务注解里设置的属性值。\n- **事务拦截器 TransactionInterceptor**：是一种`MethodInterceptor`。其内保存了事务属性信息，事务管理器。在代理对象执行目标方法时被其拦截，并调用`invoke()`方法，**由事务管理器控制事务的提交与回滚**。\n\n![image-20210705180105446](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705180105446.png)\n\n事务拦截器和事务注解属性解析器：\n\n![image-20210705192545675](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705192545675.png)\n\n### TransactionAttributeSource\n\n**事务注解属性解析器：TransactionAttributeSource**，该组件同样在当前配置类中注册，其作用是解析 **@Transactional()** 注解里设置的属性值：\n\n![image-20210705180534636](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705180534636.png)\n\n### TransactionInterceptor\n\n**事务拦截器：TransactionInterceptor**，是一种`MethodInterceptor`方法拦截器，其会在代理对象执行目标方法时进行拦截（工作时机类似于AOP中的各种增强器拦截器），并执行其`invoke()`方法（拦截器功能的执行都是通过`invoke()`方法）：\n\n![image-20210705192758666](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705192758666.png)\n\n![image-20210705195121588](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705195121588.png)\n\n进入该方法内：\n\n1. 使用`TransactionAttributeSource`组件获取`@Transactional()`注解里设置的相关属性\n2. 获取事务管理器`PlatformTransactionManager`组件（若事先没有手动添加任何事务管理器，则会从容器中获取在配置类中注册的`PlatformTransactionManager`）\n\n获取`PlatformTransactionManager`组件的方法：\n\n![image-20210705193959819](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705193959819.png)\n\n3. 在代理对象执行目标方法时，使用`try catch`包裹业务代码，若出现异常可捕获并进行回滚（并将该异常再次抛出），若没有异常则提交事务：\n\n![image-20210818102456796](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818102456796.png)\n\n其中`createTransactionIfNecessary()`方法将创建一个事务的状态信息`txInfo`（上图第一行），**其内保存了事务的信息和事务管理器**：\n\n![image-20210816221209341](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210816221209341.png)\n\n返回的**TransactionInfo**对象中保存了当前事务的状态信息（包含事务注解里的信息，例如传播特性；事务管理器等），后文将使用该对象获取到事务管理器执行事务的提交和回滚：\n\n若发生异常，**则使用事务管理器进行回滚**，该事务管理器从上文中的**TransactionInfo**中获取（黄色框中回滚时从**txInfo**中获取到了事务的状态）：\n\n![image-20210705195609111](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705195609111.png)\n\n若没有发生异常，**则使用事务管理器提交事务**（黄色框中提交时从**txInfo**中获取到了事务的状态）：\n\n![image-20210705195711824](/images/%E3%80%90Spring%E3%80%91Spring5%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210705195711824.png)\n\n## 事务和线程的关系\n\n**当一个新的事务创建时，就会被绑定到当前线程上**。\n\n**TransactionAspectSupport**类中的`ThreadLocal<TransactionInfo>`在当前线程保存了一个事务的信息**TransactionInfo**：\n\n![image-20210818103221467](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818103221467.png)\n\n该线程会伴随着这个事务整个生命周期，直到事务提交、回滚或挂起（**临时解绑**）时该线程才会取消与该事务的绑定。\n\n同时一个线程只能绑定一个事务，若当前线程原本正绑定的事务还未执行完毕就被新的事务所挂起，则该线程与该事务进行临时解绑，并绑定到新创建的事务上；直到新建的事务提交或回滚后，该线程才会结束与该新建事务的绑定，再次重新绑定之前的事务。\n\n上述过程实现的原理为使用**链表结构**：创建一张`TransactionInfo`链表，将新创建的事务`TransactionInfo`链接到旧的事务`TransactionInfo`的尾部，待新事务执行完毕后再指回旧的事务`TransactionInfo`：\n\n![image-20210818104726262](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818104726262.png)\n\n![image-20210818105411421](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818105411421.png)\n\n当新创建的事务结束时恢复旧的事务状态：\n\n![image-20210818105517020](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210818105517020.png)\n\n**什么是事务挂起，如何实现挂起**\n\n对事务的配置在Spring内部会被封装成**TransactionInfo**，线程绑定了事务，自然也绑定了事务相关的**TransactionInfo**。**挂起事务时，把TransactionInfo取出临时存储，等待执行完成后，把之前临时存储的TransactionInfo重新绑定到该线程上**。\n\n**关于事务挂起的举例：（某事务挂起之后，任何操作都不在该事务的控制之下）**\n\n> https://blog.csdn.net/xiaoshuo566/article/details/83929465\n\n例如： 方法A支持事务，方法B不支持事务，即`PROPAGATION_NOT_SUPPORTED`。方法A调用方法B：\n\n- 在方法A开始运行时，系统为它建立Transaction，方法A中对于数据库的处理操作，会在该Transaction的控制之下。\n- 这时，方法A调用方法B，方法A打开的Transaction将挂起，方法B中任何数据库操作，都不在该Transaction的管理之下。\n- 当方法B返回，方法A继续运行，之前的Transaction恢复，后面的数据库操作继续在该Transaction的控制之下提交或回滚。\n","tags":["源码分析","Spring"],"categories":["源码分析","Spring"]},{"title":"【Spring Boot】Spring Boot2","url":"/2021/06/30/【SpringBoot】SpringBoot2/","content":"\n## Spring Boot 简介\n\n> Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can “just run” —— 能快速创建出生产级别的Spring应用\n>\n\n[Spring Boot 官方](https://spring.io/projects/spring-boot)\n\n[Spring Boot 官方手册](https://docs.spring.io/spring-boot/docs/current/reference/html/)\n\n### Spring Boot 优点\n\n- Create stand-alone Spring applications：创建独立Spring应用\n- Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)：内嵌web服务器\n- Provide opinionated ‘starter’ dependencies to simplify your build configuration：自动starter依赖，简化构建配置\n- Automatically configure Spring and 3rd party libraries whenever possible：自动配置Spring以及第三方功能\n- Provide production-ready features such as metrics, health checks, and externalized configuration：提供生产级别的监控、健康检查及外部化配置\n- Absolutely no code generation and no requirement for XML configuration：无代码生成、无需编写XML\n- Spring Boot是整合Spring技术栈的一站式框架\n- Spring Boot是简化Spring技术栈的快速开发脚手架\n\n<!-- More -->\n\n## Hello Spring Boot\n\n### 系统要求\n\n- Java 8 & 兼容Java14\n- Maven 3.3+\n\n### 配置 Maven 依赖\n\n```xml\n<!-- 继承 Spring Boot 父工程，其由继承自 spring-boot-dependencies，里面管理了大量的jar包 -->\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.3.4.RELEASE</version>\n</parent>\n\n<dependencies>\n    <!-- 导入 Spring Boot 依赖，版本默认使用 spring-boot-starter-parent 里指定的版本 -->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-web</artifactId>\n    </dependency>\n    <!-- 导入 Spring Boot 测试依赖 -->\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-starter-test</artifactId>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n\n<build>\n    <plugins>\n        <plugin>\n            <!-- 以Maven的方式为Spring Boot应用提供支持，能够将Spring Boot应用打包为可执行的jar或war文件，进行相应部署后即可启动Spring Boot应用 -->\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n            <configuration>\n                <fork>true</fork>\n                <addResources>true</addResources>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n`spring-boot-maven-plugin`插件以Maven的方式为Spring Boot应用提供支持，能够将Spring Boot应用打包为可执行的jar或war文件，进行相应部署后即可启动Spring Boot应用。\n\n### 创建主程序\n\n```java\npackage com.zhao.boot;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n/**\n * 主程序类\n * @SpringBootApplication：这是一个SpringBoot应用\n */\n@SpringBootApplication\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(MainApplication.class, args);\n    }\n}\n```\n\n### 编写业务代码\n\n```java\npackage com.zhao.boot.controller;\n\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.RequestMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\nimport org.springframework.web.bind.annotation.RestController;\n\n//@ResponseBody\n//@Controller\n@RestController\npublic class HelloController {\n\n    @RequestMapping(\"/hello\")\n    public String handle01() {\n        return \"Hello Spring Boot 2\";\n    }\n}\n```\n\n其中`@RestController`的作用等于`@Controller + @ResponseBody`\n\n### Spring 配置文件\n\n在`resources`目录下创建`application.properties`文件，在其内修改Spring Boot的配置属性\n\n![image-20210707200401205](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210707200401205.png)\n\n```properties\n# 设置端口号\nserver.port=8080\n\n# 设置项目前置访问路径\nserver.servlet.context-path: /projectName\n```\n\n[Springboot官方配置项文档](https://docs.spring.io/spring-boot/docs/current/reference/html/application-properties.html#application-properties.server)\n\n### 部署\n\n在maven的pom文件中添加插件\n\n```xml\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n        </plugin>\n    </plugins>\n</build>\n```\n\n​\t对当前工程进行打包：\n\n![image-20210707200542552](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210707200542552.png)\n\n得到`springboot-helloworld-1.0-SNAPSHOT.jar`后，直接在命令行运行：`java -jar springboot-helloworld-1.0-SNAPSHOT.jar`即可启动整个工程。\n\n## 常用注解\n\n### @Configuration\n\n在Spring 5版本之后，该注解添加了属性：`proxyBeanMethods`，该属性可用于两种模式：\n\n- Full模式（`proxyBeanMethods = true`）：`@Bean`方法返回的组件是单实例的（默认）\n- Lite模式（`proxyBeanMethods = false`）：`@Bean`方法返回的组件每次都是**新创建**的。\n\n`proxyBeanMethods `作用（经测试，在使用Spring基础框架创建配置类时该属性无效，均不返回代理对象）：\n\n- `proxyBeanMethods`值为true时，`@Configuration`配置类中注册的所有组件都会被创建其**代理对象并保存在容器中**。在配置类中写的所有组件注册方法在被外界调用时都会去容器中找是否已经存在该对象的**代理对象**，若存在则直接获取，若不存在则再创建**代理对象**，即单例模式。\n- `proxyBeanMethods`值为false时，在容器中不会再保存代理对象，在外界调用该方法时都会产生新的对象（非代理对象）。\n\n最佳实践：\n\n- 配置类组件之间**无依赖关系**用Lite模式加速容器启动过程，减少判断\n- 配置类组件之间**有依赖关系**，方法会在被调用得到之前单实例组件，用Full模式（默认）\n\n配置类`MyConfig.java`：\n\n``` java\n@Configuration(proxyBeanMethods = false)\npublic class MyConfig {\n    @Bean\n    public User user(){\n        User zhangsan = new User(\"zhangsan\", 18);\n        //user组件依赖了Pet组件\n        zhangsan.setPet(Pet());\n        return zhangsan;\n    }\n\n    @Bean(\"pet\")\n    public Pet Pet(){\n        return new Pet(\"gaolaoer\");\n    }\n}\n```\n\n测试：\n\n``` java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\"com.zhao.boot\")\npublic class MainApplication {\n\n    public static void main(String[] args) {\n        //1、返回IOC容器\n        ConfigurableApplicationContext run = SpringApplication.run(MainApplication.class, args);\n\n        //2、查看容器里面的组件\n        String[] names = run.getBeanDefinitionNames();\n        for (String name : names) {\n            System.out.println(name);\n        }\n\n        //3、从容器中获取组件\n        Pet pet01 = run.getBean(\"pet\", Pet.class);\n        Pet pet02 = run.getBean(\"pet\", Pet.class);\n        System.out.println(\"组件：\"+(pet01 == pet02));\n\n        //4、com.zhao.boot.config.MyConfig$$EnhancerBySpringCGLIB$$51f1e1ca@1654a892\n        MyConfig bean = run.getBean(MyConfig.class);\n        System.out.println(bean);\n\n        //如果@Configuration(proxyBeanMethods = true)代理对象调用方法。SpringBoot总会检查这个组件是否在容器中有。\n        //proxyBeanMethods = true时组件是单实例\n        //proxyBeanMethods = false时组件是多实例\n        User user = bean.user();\n        User user1 = bean.user();\n        System.out.println(user == user1);\n\n        //proxyBeanMethods = true时user2.pet等于pet\n        //proxyBeanMethods = false时user2.pet不等于pet\n        User user2 = run.getBean(\"user\", User.class);\n        Pet pet = run.getBean(\"pet\", Pet.class);\n\n        System.out.println(\"用户的宠物：\"+(user2.getPet() == pet));\n    }\n}\n```\n\n### @Conditional\n\n**条件装配：满足Conditional指定的条件，则进行组件注入**\n\n![img](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/20210205005453173.png)\n\n### @ImportResource\n\n使用`@ImportResource`可以导入其他Spring的xml文件，导入后该xml文件中的组件会被添加到当前配置类中，使用方法：\n\n``` java\n@ImportResource(\"classpath:beans.xml\")\npublic class MyConfig {\n    //...\n}\n```\n\n### @ConfigurationProperties\n\n使用`@ConfigurationProperties`进行配置绑定，将配置文件中的属性值赋给某个组件。\n\n1. 创建`application.properties`文件，在其中添加属性值：\n\n``` properties\nmycar.brand=BYD\nmycar.price=100000\n```\n\n2. 给某个类添加`@Component`注解，将其注册到容器中（只有在容器中的组件，才会拥有Spring Boot提供的强大功能）。\n\n``` java\n@Component\n@ConfigurationProperties(prefix = \"mycar\")\npublic class Car {\n    String brand;\n    String price;\n}\n```\n\n之后该组件中的属性将在配置文件中寻找同名的key，将其对应的value赋给属性值。\n\n**`@ConfigurationProperties`注解在Spring Boot底层大量使用，使用其修饰的组件将从Spring Boot核心配置文件`application.properties`中读取并绑定相关配置参数。**\n\n### @EnableConfigurationProperties\n\nSpring Boot另一种配置绑定方式：`@EnableConfigurationProperties` + ` @ConfigurationProperties`\n\n`@EnableConfigurationProperties`的功能：\n\n1. 开启配置绑定功能（让其能够绑定到配置文件）\n2. 把组件自动注册到容器中（使其可以不写`@Component`注解也能注册到容器中）\n\n``` java\n@EnableConfigurationProperties(Car.class)\npublic class MyConfig {\n\t// ...\n}\n```\n\n``` java\n@ConfigurationProperties(prefix = \"mycar\")\npublic class Car {\n\t// ...\n}\n```\n\n### 其他注解\n\n`@Bean`、`@Component`、`@Controller`、`@Service`、`@Repository`、`@Import`，它们是Spring的基本标签，在Spring Boot中并未改变它们原来的功能。\n\n## 自动配置原理\n\n### 依赖管理\n\n当前新建的Spring Boot项目的父项目：\n\n``` xml\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-parent</artifactId>\n    <version>2.3.4.RELEASE</version>\n</parent>\n```\n\n其父项目又依赖`spring-boot-dependencies.pom`：\n\n```xml\n<parent>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-dependencies</artifactId>\n    <version>2.3.4.RELEASE</version>\n</parent>\n```\n\n该文件中声明了开发中常用的jar包版本，因此其子项目中不需要给依赖写上版本号，会自动导入父项目里版本的jar包。该特性被称为**版本仲裁**。\n\n```xml\n<properties>\n    <activemq.version>5.15.13</activemq.version>\n    <antlr2.version>2.7.7</antlr2.version>\n    <appengine-sdk.version>1.9.82</appengine-sdk.version>\n    <artemis.version>2.12.0</artemis.version>\n    <aspectj.version>1.9.6</aspectj.version>\n    <assertj.version>3.16.1</assertj.version>\n    ...\n</properties>\n```\n\n#### 自定义依赖版本\n\n若想自定义修改依赖的版本，则只需要在当前项目里指定配置版本号，其会覆盖父项目中的默认版本号。\n\n```xml\n<properties>\n    <mysql.version>5.1.43</mysql.version>\n</properties>\n```\n\n#### 场景启动器\n\n`spring-boot-starter-*` 代表某种场景，只要引入了该starter，这个场景的所有依赖都会自动引入。第三方提供的简化开发的场景启动器命名格式：`*-spring-boot-starter`。[官方所有支持的Starter](https://docs.spring.io/spring-boot/docs/current/reference/html/using.html#using.build-systems.starters)\n\n所有场景启动器最底层的依赖，**SpringBoot自动配置的核心依赖**：**spring-boot-starter**\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter</artifactId>\n    <version>2.3.4.RELEASE</version>\n    <scope>compile</scope>\n</dependency>\n```\n\n该starter场景将导入Spring Boot提供的127种自动配置类**xxxAutoConfiguration**，这些自动配置类将导入许多常用的组件用于简化开发（例如`DispatcherServlet`等），无需开发人员手动添加这些组件。\n\n`spring-boot-starter.pom`的主要内容：\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n    <!-- This module was also published with a richer model, Gradle metadata,  -->\n    <!-- which should be used instead. Do not delete the following line which  -->\n    <!-- is to indicate to Gradle or any Gradle module metadata file consumer  -->\n    <!-- that they should prefer consuming it instead. -->\n    <!-- do_not_remove: published-with-gradle-metadata -->\n    <modelVersion>4.0.0</modelVersion>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter</artifactId>\n    <version>2.5.3</version>\n    <name>spring-boot-starter</name>\n    <description>Core starter, including auto-configuration support, logging and YAML</description>\n\n    <dependencies>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot</artifactId>\n            <version>2.5.3</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-autoconfigure</artifactId>\n            <version>2.5.3</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-logging</artifactId>\n            <version>2.5.3</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>jakarta.annotation</groupId>\n            <artifactId>jakarta.annotation-api</artifactId>\n            <version>1.3.5</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.springframework</groupId>\n            <artifactId>spring-core</artifactId>\n            <version>5.3.9</version>\n            <scope>compile</scope>\n        </dependency>\n        <dependency>\n            <groupId>org.yaml</groupId>\n            <artifactId>snakeyaml</artifactId>\n            <version>1.28</version>\n            <scope>compile</scope>\n        </dependency>\n    </dependencies>\n</project>\n```\n\n### 场景启动器starter工作原理\n\n![image-20210809210934337](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210809210934337.png)\n\n场景启动器工作原理的本质：调用的`xxx-starter`项目导入的所有`xxx-autoconfigure`项目中编写了许多自动配置类`xxxAutoConfiguration`，这些自动配置类将在Spring Boot启动时被注册到容器中，从而将其内编写的组件按照条件注册到容器中，因此开发人员可以在自己的项目中调用到这些组件。\n\n### 自动配置特性\n\nSpring Boot的主程序类（标有 **@SpringBootApplication**注解的类）**所在包及其下面的所有子包**里面的组件都会被默认扫描进来，这些组件不再需要额外指定扫描路径。而若想要扫描其他路径下的组件，则可以在主程序类上添加：\n\n- `@SpringBootApplication(scanBasePackages=\"com.zhao.xxx\")`\n- `@ComponentScan(\"com.zhao.xxx\") `\n\n`@SpringBootApplication`是一个合成注解，其效果等同于下面三个注解的组合。\n\n``` java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\"com.zhao.xxx\")\n```\n\nSpring Boot的各种配置都拥有默认值。这些默认配置最终都是映射到某个类上，如：`MultipartProperties`。配置文件的值最终会绑定在某个类上，这个类会在容器中创建对象。\n\nSpring Boot所有的**自动配置功能**都在 `spring-boot-autoconfigure` 包里面。\n\n### 【源码分析】自动配置原理\n\n**@SpringBootApplication**是一个合成注解，其效果等同于下面三个注解的组合：\n\n```java\n@SpringBootConfiguration\n@EnableAutoConfiguration\n@ComponentScan(\n    excludeFilters = {@Filter(\n    type = FilterType.CUSTOM,\n    classes = {TypeExcludeFilter.class}\n), @Filter(\n    type = FilterType.CUSTOM,\n    classes = {AutoConfigurationExcludeFilter.class}\n)}\n)\npublic @interface SpringBootApplication \n```\n\n下面逐一分析上述三者的作用\n\n#### 1、@SpringBootConfiguration\n\n表明被 **@SpringBootApplication** 修饰的类本质上也是一个 **@Configuration** 配置类\n\n```java\n@Configuration\npublic @interface SpringBootConfiguration\n```\n\n#### 2、@ComponentScan\n\n指定要扫描的组件（按照`@Filter`里设置的类型过滤一些组件）\n\n#### 3、@EnableAutoConfiguration\n\n重点，自动配置是通过该注解实现的。\n\n``` java\n@AutoConfigurationPackage\n@Import({AutoConfigurationImportSelector.class})\npublic @interface EnableAutoConfiguration\n```\n\n**3.1、@AutoConfigurationPackage：自动配置包，将MainApplication主程序类所在包下的所有组件注册到容器中**\n\n```java\n@Import({Registrar.class})\npublic @interface AutoConfigurationPackage\n```\n\n该注解通过`@Import`注解向容器中导入了一个**Registrar**组件，该组件实现了`ImportBeanDefinitionRegistrar`接口（[【Spring】Spring5 源码中常用接口的底层原理](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/)），其作用是**将MainApplication主程序类所在包下的所有组件都注册到容器中**。这也解释了默认的扫描包路径为`MainApplication`所在包的路径。\n\n![image-20210711201544965](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711201544965.png)\n\n其中传入的参数`AnnotationMetadata metadata`是指Spring Boot主程序类`MainApplication`的注解元信息，用于获取其所在的包路径，从而将该包下的所有子包下的类都注册到容器中。\n\n**3.2、@Import({AutoConfigurationImportSelector.class})：向容器中注册自动配置类**\n\n**第一步：引导加载自动配置类**\n\n该注解向容器中注册了**AutoConfigurationImportSelector**类型的组件，该类的重要方法  **selectImports()** 中利用**getAutoConfigurationEntry(annotationMetadata)** 方法向容器中导入一些**自动配置类**组件（先获取所有的自动配置类，再根据实际情况筛选出符合条件的自动配置类注册到容器中）。\n\n![image-20210711202049677](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711202049677.png)\n\n进入`getAutoConfigurationEntry(annotationMetadata)`方法后，首先调用`getCandidateConfigurations()`方法获取所有**候选**的自动配置类组件（AutoConfiguration），共有127个。并在后续进行删选后**按需开启**自动配置项（即用不到的自动配置类无需开启）。\n\n获取这些`AutoConfiguration`的具体过程：\n\n![image-20210711202306425](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711202306425.png)\n\n![image-20210711203848177](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711203848177.png)\n\n在`getCandidateConfigurations()`方法内通过`SpringFactoriesLoader`工厂加载器加载一些组件。\n\n![image-20210711202745443](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711202745443.png)\n\n![image-20210711203253301](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711203253301.png)\n\n在该方法内使用类加载器读取`\"META-INF/spring.factories\"`位置处的资源文件。有些包下有这个文件，比如最关键的`spring-boot-autoconfigure-2.3.4.RELEASE.jar`包（导入的其他第三方包中也可以会含有`\"META-INF/spring.factories\"`文件，例如MyBatis的`mybatis-spring-boot-autoconfigure-2.1.4.jar`包也会有该文件，Spring Boot启动时也会加载该包下的`xxxAutoConfiguration`类）：\n\n![image-20210711203525691](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711203525691.png)\n\n该文件内配置了Spring Boot启动时就要向容器中加载的所有自动配置类（`AutoConfiguration`）（共127个，正好对应上文中的127个自动配置类组件）：\n\n![image-20210711203725837](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711203725837.png)\n\n上文中注册到容器中的127个自动配置类组件Configurations：\n\n![image-20210711203855246](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711203855246.png)\n\n但这127个自动配置类并不会都注册到容器中，而会按需开启。\n\n**第二步：按需开启自动配置项**\n\n虽然上述127个自动配置类在启动的时候会默认全部加载，但每个`xxxxAutoConfiguration`会按照条件装配规则（**@Conditional**）**按需配置**。\n\n以`BatchAutoConfiguration`类为例，该类因`@ConditionalOnClass({JobLauncher.class, DataSource.class})`的存在，若想被注册到容器中，需要满足当前项目中有`JobLauncher`类的存在，但若开发人员没有导入该类相关的maven依赖，则无法找到该类，因此该自动配置类将不会被注册到容器中。因此上述127个自动配置类会按照实际容器中配置组件的情况按需注册到容器中，不需要的配置类将不会被注册。\n\n同时这些自动配置类里的配置属性通过 **@EnableConfigurationProperties** 注解从**xxxProperties**组件中获取（`xxxProperties`组件和相应的配置文件绑定在了一起）\n\n![image-20210711211618512](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711211618512.png)\n\n------\n\n举例：上文描述了如何向容器中注册常用的自动配置类，下面以web开发必须的自动配置类**DispatcherServletAutoConfiguration**为例：\n\n![image-20210711213124840](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711213124840.png)\n\n该自动配置类满足`@Conditional`的条件，因此会在程序加载时被注册到容器中。同时该自动配置类中会向容器中注册**DispatcherServlet**组件，这正是Spring MVC开发时需要的转发器组件。\n\n也就是说Spring Boot在启动时，会将传统SSM中开发人员配置在xml中的必备组件自动地注册到容器中，无需开发人员再手动注册。\n\n![image-20210711213412654](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210711213412654.png)\n\n以AOP自动配置器**AopAutoConfiguration**为例：\n\n![image-20210804150325041](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210804150325041.png)\n\n------\n\n\n\n---\n\n**第三步：修改默认配置**\n\n以自动配置类**DispatcherServletAutoConfiguration**中的**MultipartResolver**组件为例，该组件为Spring MVC中的文件上传组件，其会被`DispatcherServletAutoConfiguration`注册到容器中。\n\n其依赖于**MultipartResolver**组件（该组件默认存在于容器中，但开发人员可以再手动注册一个），同时判断该组件的名称是否为指定的`MULTIPART_RESOLVER_BEAN_NAME = multipartResolver `。\n\n若不是，可能的情况为开发人员自己手动注册了一个，但名称不符合规范。此时容器通过调用`multipartResolver()`方法注册了该组件，同时注册的组件名就是方法名**multipartResolver**，因此起到**组件名规范化**的效果。\n\n```java\n@Bean\n@ConditionalOnBean(MultipartResolver.class)  // 容器中默认有这个类型组件\n@ConditionalOnMissingBean(name = DispatcherServlet.MULTIPART_RESOLVER_BEAN_NAME) //容器中没有这个名字 multipartResolver 的组件\npublic MultipartResolver multipartResolver(MultipartResolver resolver) {\n    //给@Bean标注的方法传入了对象参数，这个参数的值就会从容器中找。\n    //Spring MVC multipartResolver。防止有些用户配置的文件上传解析器不符合规范\n    // Detect if the user has created a MultipartResolver but named it incorrectly\n    return resolver;\n```\n\nSpringBoot默认会在底层配好所有的组件。但是如果用户自己配置了以用户的优先：\n\n```java\n@Bean\n@ConditionalOnMissingBean\npublic CharacterEncodingFilter characterEncodingFilter() {\n}\n```\n\n### 总结\n\n- Spring Boot首先加载所有的自动配置类 **xxxxxAutoConfiguration**（127个）\n- 每个自动配置类按照条件判断进行生效，默认都会绑定配置文件指定的值。（从**xxxxProperties**组件里面读取，**xxxProperties**组件和配置文件进行了绑定）\n- 生效的配置类就会向容器中注册响应的组件\n\n定制化配置：\n\n- 开发人员手动使用`@Bean`替换容器中默认注册的组件；\n- 在配置文件中修改相应配置属性以修改默认组件的属性值\n\n**xxxxxAutoConfiguration **—> 注册组件 —> 组件属性通过**xxxxProperties**从配置文件**application.properties**中取值\n\n常用的自动配置类**xxxAutoConfiguration**：\n\n- **AopAutoConfiguration**：AOP自动配置类\n- **DispatcherServletAutoConfiguration**：DispatcherServlet自动配置类\n- **WebMvcAutoConfiguration**：WebMVC相关自动配置类\n- **ServletWebServerFactoryAutoConfiguration**：ServletWebServerFactory自动配置类\n- **MultipartAutoConfiguration**：文件上传自动配置类\n- **ErrorMvcAutoConfiguration**：异常处理自动配置类\n- **DataSourceAutoConfiguration**：数据源自动配置类\n- **MybatisAutoConfiguration**：MyBatis自动配置类（第三方）\n\n## 开发小技巧\n\n### Lombok 简化开发\n\nLombok用标签方式代替构造器、`getter/setter()`、`toString()`等代码。Spring Boot已经管理Lombok。引入依赖：\n\n``` xml\n<dependency>\n    <groupId>org.projectlombok</groupId>\n    <artifactId>lombok</artifactId>\n    <!-- 注意Spring Boot的依赖中已经制定了版本号，这里不能再制定自己的版本，否则可能造成版本冲突-->\n</dependency>\n```\n\nIDEA中`File->Settings->Plugins`，搜索安装Lombok插件。\n\n``` java\n@NoArgsConstructor\n//@AllArgsConstructor\n@Data\n@ToString\n@EqualsAndHashCode\npublic class User {\n\n    private String name;\n    private Integer age;\n\n    private Pet pet;\n\n    public User(String name,Integer age){\n        this.name = name;\n        this.age = age;\n    }\n}\n```\n\n简化日志开发\n\n``` java\n@Slf4j\n@RestController\npublic class HelloController {\n    @RequestMapping(\"/hello\")\n    public String handle01(@RequestParam(\"name\") String name){\n        log.info(\"请求进来了....\");\n        return \"Hello, Spring Boot 2!\"+\"你好：\"+name;\n    }\n}\n```\n\n### dev-tools “热部署”\n\n添加依赖：\n\n``` xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework.boot</groupId>\n        <artifactId>spring-boot-devtools</artifactId>\n        <scope>runtime</scope>\n        <optional>true</optional>\n    </dependency>\n</dependencies>\n```\n\n在IDEA中，项目或者页面修改以后使用：`Ctrl+F9`更新。本质上是重新启动项目，并非真正的热部署。\n\n### Spring Initailizr\n\n[Spring Initailizr](https://start.spring.io/)是创建Spring Boot工程向导。在IDEA中，菜单栏`New -> Project -> Spring Initailizr`快速构建Spring Boot项目。\n\n## 配置文件 YAML\n\nYAML 是 “YAML Ain’t Markup Language”（YAML 不是一种标记语言）的递归缩写。在开发的这种语言时，YAML 的意思其实是：“Yet Another Markup Language”（仍是一种标记语言）。**其非常适合用来做以数据为中心的配置文件**。\n\n### 基本语法\n\n- key: value；kv之间有空格\n- 大小写敏感\n- 使用缩进表示层级关系\n- 缩进不允许使用tab，只允许空格\n- 缩进的空格数不重要，只要相同层级的元素左对齐即可\n- '#'表示注释\n- 字符串无需加引号，如果要加，单引号’’、双引号\"\"表示字符串内容会被 转义、不转义\n\n### 数据类型\n\n- 字面量：单个的、不可再分的值。date、boolean、string、number、null\n\n``` yaml\nk: v\n```\n\n- 对象：键值对的集合。map、hash、set、object\n\n``` yaml\n#行内写法：  \nk: {k1:v1,k2:v2,k3:v3}\n\n#或\nk: \n  k1: v1\n  k2: v2\n  k3: v3\n```\n\n- 数组：一组按次序排列的值。array、list、queue\n\n``` yaml\n#行内写法：  \nk: [v1,v2,v3]\n\n#或者\nk:\n - v1\n - v2\n - v3\n```\n\n### 示例\n\n``` java\n@Data\npublic class Person {\n    private String userName;\n    private Boolean boss;\n    private Date birth;\n    private Integer age;\n    private Pet pet;\n    private String[] interests;\n    private List<String> animal;\n    private Map<String, Object> score;\n    private Set<Double> salarys;\n    private Map<String, List<Pet>> allPets;\n}\n\n@Data\npublic class Pet {\n    private String name;\n    private Double weight;\n}\n```\n\n用yaml表示以上对象\n\n``` yaml\nperson:\n  userName: zhangsan\n  boss: false\n  birth: 2019/12/12 20:12:33\n  age: 18\n  pet: \n    name: tomcat\n    weight: 23.4\n  interests: [篮球,游泳]\n  animal: \n    - jerry\n    - mario\n  score:\n    english: \n      first: 30\n      second: 40\n      third: 50\n    math: [131,140,148]\n    chinese: {first: 128,second: 136}\n  salarys: [3999,4999.98,5999.99]\n  allPets:\n    sick:\n      - {name: tom}\n      - {name: jerry,weight: 47}\n    health: [{name: mario,weight: 47}]\n```\n\n### 配置文件-自定义类绑定的配置提示\n\n自定义的类和配置文件绑定一般没有提示。若要提示，添加如下依赖：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-configuration-processor</artifactId>\n    <optional>true</optional>\n</dependency>\n\n<!-- 下面插件作用是工程打包时，不将spring-boot-configuration-processor打进包内，让其只在编码的时候有用 -->\n<build>\n    <plugins>\n        <plugin>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-maven-plugin</artifactId>\n            <configuration>\n                <excludes>\n                    <exclude>\n                        <groupId>org.springframework.boot</groupId>\n                        <artifactId>spring-boot-configuration-processor</artifactId>\n                    </exclude>\n                </excludes>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n## Web 开发\n\n### Spring MVC 自动配置概览\n\nSpring Boot为Spring MVC开发提供了大量的自动配置，无需开发人员再手动定义。默认配置如下：\n\n- 内容协商视图解析器`ContentNegotiatingViewResolver`和组件名视图解析器`BeanNameViewResolver`\n- 静态资源（包括`webjars`）\n- 自动注册 `Converter，GenericConverter，Formatter`\n- 支持消息转换器`HttpMessageConverters `\n- 自动注册 `MessageCodesResolver `（国际化用）\n- 静态 `index.html` 页支持\n- 自定义 `Favicon`\n- 自动使用 `ConfigurableWebBindingInitializer `（`DataBinder`负责将请求数据绑定到`JavaBean`上）\n\n若开发人员想要实现自定义的配置，则可以有三种方式：\n\n- 使用 **@Configuration + WebMvcConfigurer** 自定义规则，同时不能标注 **@EnableWebMvc** 注解（若开启，则变成全面接管Spring MVC，就需要把所有Spring MVC配置好的规则全部自定义实现）\n- 声明 **WebMvcRegistrations** 改变默认底层组件\n- 使用 **@EnableWebMvc+@Configuration+DelegatingWebMvcConfiguration** ==**全面接管**==Spring MVC【详细源码分析见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)】\n\n若想在容器中添加Spring MVC相关的**自定义组件**以覆盖默认组件，则可以在**@Configuration**中添加一个**WebMvcConfigurer**组件，在其内**重写相关方法**即可覆盖容器中默认的方法。示例：\n\n```java\n@Configuration\npublic class myConfig implements WebMvcConfigurer {\n\n    // 添加自定义的拦截器\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(new LoginInterceptor())\n            .addPathPatterns(\"/**\")   // 写 /** 时所有请求都会被拦截，包括静态资源\n            .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/fonts/**\",\"/images/**\",\"/js/**\");\n    }\n\n    // 添加自定义的Converter，用于根据url中传入的字符串解析POJO内容\n    @Override\n    public void addFormatters(FormatterRegistry registry) {\n        registry.addConverter(new Converter<String, Person>() {\n            @Override\n            public Person convert(String s) {\n                Person person = new Person();\n                // 定制化的解析方法...\n                return person;\n            }\n        });\n    }\n\n    // 添加自定义的消息转换器，用于转换自定义的媒体格式\n    @Override\n    public void extendMessageConverters(List<HttpMessageConverter<?>> converters) {\n        converters.add(new MyMessageConverter());\n    }\n\n    @Override\n    public void configureContentNegotiation(ContentNegotiationConfigurer configurer) {\n        // 指定三种媒体类型映射关系\n        Map<String, MediaType> mediaTypes = new HashMap<>();\n        mediaTypes.put(\"json\", MediaType.APPLICATION_JSON);\n        mediaTypes.put(\"xml\", MediaType.APPLICATION_XML);\n        mediaTypes.put(\"myFormat\", MediaType.parseMediaType(\"application/x-zhao\"));\n\n        // 基于请求参数的内容协商策略：支持解析哪些参数对应哪些媒体类型\n        ParameterContentNegotiationStrategy parameterStrategy =\n            new ParameterContentNegotiationStrategy(mediaTypes);\n        // parameterStrategy.setParameterName(\"format\");\n\n        // 基于请求头的内容协商策略\n        HeaderContentNegotiationStrategy headerStrategy = new HeaderContentNegotiationStrategy();\n\n        configurer.strategies(Arrays.asList(parameterStrategy, headerStrategy));\n    }\n\n}\n```\n\n### 静态资源目录\n\n只要静态资源放在类路径下的：` /static` (or` /public` or` /resources` or `/META-INF/resources`）目录，就可以通过 \"**当前项目根路径`/` + 静态资源名**\" 的方式访问到。原理： 静态映射 `/**`。\n\n收到请求后，先去找`Controller`看能不能处理；不能处理的所有请求又都交给**静态资源处理器**；静态资源也找不到则响应404页面。\n\n默认的静态资源路径可以通过修改\"`static-locations`\"属性值来定制化：\n\n``` yaml\nresources:\n  static-locations: [classpath:/myStaticPath/]\n```\n\n此时，浏览器在访问\"`static-locations`\"目录下的静态资源文件时，解析得到的请求路径不包含\"`static-locations`\"。例如：访问\"`/static/css/style.css`\"时，解析到的请求路径是\"**/css/style.css**\"。\n\n详细源码分析见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n### 静态资源访问前缀\n\n**当前项目名称 + `static-path-pattern` + 静态资源名** = 去`static-locations`属性配置的静态资源文件夹下找\"静态资源名\"文件\n\n``` yaml\nspring:\n  mvc:\n    static-path-pattern: /res/**\n```\n\n注意：配置了前缀后，就不能使用欢迎页功能了。\n\n### 禁用静态资源规则\n\n通过配置`add-mappings`属性可以禁止所有静态资源规则。\n\n```yaml\nspring:\n  resources:\n    add-mappings: false   #禁用所有静态资源规则\n```\n\n### webjar\n\n可用jar方式添加css，js等资源文件，https://www.webjars.org/。\n\n例如，添加jquery：\n\n``` xml\n<dependency>\n    <groupId>org.webjars</groupId>\n    <artifactId>jquery</artifactId>\n    <version>3.5.1</version>\n</dependency>\n```\n\n访问地址：[http://localhost:8080/webjars/**jquery/3.5.1/jquery.js**](http://localhost:8080/webjars/jquery/3.5.1/jquery.js) 后面地址要按照依赖里面的包路径。\n\n### 欢迎页支持\n\n在静态资源路径下创建 `index.html` 文件，其会被设置为欢迎页。可以自定义配置**静态资源路径**以在任意位置存放该文件，但注意不可以配置静态资源的**访问前缀**，否则导致 `index.html` 不能被默认访问。`controller`能处理 `/index` 。\n\n``` yaml\nspring:\n#  mvc:\n#    static-path-pattern: /res/**   这个会导致welcome page功能失效\n  resources:\n    static-locations: [classpath:/myPath/] # 可以自定义设置文件位置\n```\n\n### 自定义 Favicon\n\n指网页标签上的小图标。favicon.ico 放在静态资源目录下即可。但注意配置静态资源的**访问前缀**将导致Favicon功能失效\n\n``` yaml\nspring:\n#  mvc:\n#    static-path-pattern: /res/**   这个会导致 Favicon 功能失效\n```\n\n### Rest 请求映射实现\n\n实现Rest风格支持的核心Filter：**HiddenHttpMethodFilter**。其本质是一个过滤器，因此会在所有请求响应前进行拦截过滤，将`DELETE`请求和`PUT`请求进行包装后放行到后续过滤器。\n\n```yaml\nspring:\n  mvc:\n    hiddenmethod:\n      filter:\n        enabled: true   #开启页面表单的Rest功能\n```\n\n开启**HiddenHttpMethodFilter**后，若想发送`DELETE`或`PUT`请求，则需要创建一个表单，在表单项中携带一个`_method`参数，这个参数的值可以设置为`DELETE`或`PUT`。\n\n\n```xml\n<form action=\"/user\" method=\"get\">\n    <input value=\"REST-GET提交\" type=\"submit\" />\n</form>\n\n<form action=\"/user\" method=\"post\">\n    <input value=\"REST-POST提交\" type=\"submit\" />\n</form>\n\n<form action=\"/user\" method=\"post\">\n    <input name=\"_method\" type=\"hidden\" value=\"DELETE\"/>\n    <input value=\"REST-DELETE 提交\" type=\"submit\"/>\n</form>\n\n<form action=\"/user\" method=\"post\">\n    <input name=\"_method\" type=\"hidden\" value=\"PUT\" />\n    <input value=\"REST-PUT提交\"type=\"submit\" />\n<form>\n```\n\n```java\n@GetMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.GET)\npublic String getUser(){\n    return \"GET-张三\";\n}\n\n@PostMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.POST)\npublic String saveUser(){\n    return \"POST-张三\";\n}\n\n@PutMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.PUT)\npublic String putUser(){\n    return \"PUT-张三\";\n}\n\n@DeleteMapping(\"/user\")\n//@RequestMapping(value = \"/user\",method = RequestMethod.DELETE)\npublic String deleteUser(){\n    return \"DELETE-张三\";\n}\n```\n\n**HiddenHttpMethodFilter**的源码分析见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n### 常用请求参数注解使用\n\n- **@PathVariable**：路径变量\n- **@RequestHeader**：获取请求头\n- **@RequestParam**：获取请求参数（指问号后的参数，`url?a=1&b=2`）\n- **@CookieValue**：获取Cookie值\n- **@RequestAttribute**：获取request域属性\n- **@RequestBody**：获取请求体[POST]\n- **@MatrixVariable**：矩阵变量\n\n示例：\n\n```java\n@RestController\npublic class ParameterTestController {\n\n    // car/2/owner/zhangsan\n    @GetMapping(\"/car/{id}/owner/{username}\")\n    public Map<String,Object> getCar(@PathVariable(\"id\") Integer id,\n                                     @PathVariable(\"username\") String name,\n                                     @PathVariable Map<String,String> pv,\n                                     @RequestHeader(\"User-Agent\") String userAgent,\n                                     @RequestHeader Map<String,String> header,\n                                     @RequestParam(\"age\") Integer age,\n                                     @RequestParam(\"inters\") List<String> inters,\n                                     @RequestParam Map<String,String> params,\n                                     @CookieValue(\"_ga\") String _ga,\n                                     @CookieValue(\"_ga\") Cookie cookie){\n        Map<String,Object> map = new HashMap<>();\n        //map.put(\"id\",id);\n        //map.put(\"name\",name);\n        //map.put(\"pv\",pv);\n        //map.put(\"userAgent\",userAgent);\n        //map.put(\"headers\",header);\n        map.put(\"age\",age);\n        map.put(\"inters\",inters);\n        map.put(\"params\",params);\n        map.put(\"_ga\",_ga);\n        System.out.println(cookie.getName()+\"===>\"+cookie.getValue());\n        return map;\n    }\n\n    @PostMapping(\"/save\")\n    public Map postMethod(@RequestBody String content){\n        Map<String,Object> map = new HashMap<>();\n        map.put(\"content\",content);\n        return map;\n    }\n\n    @GetMapping(\"/goto\")\n    public String goToPage(HttpServletRequest request){\n        request.setAttribute(\"msg\",\"成功了...\");\n        request.setAttribute(\"code\",200);\n        return \"forward:/success\";  //转发到 /success 请求\n    }\n\n    @GetMapping(\"/params\")\n    public String testParam(Map<String,Object> map,\n                            Model model,\n                            HttpServletRequest request,\n                            HttpServletResponse response){\n        map.put(\"hello\",\"world666\");\n        model.addAttribute(\"world\",\"hello666\");\n        request.setAttribute(\"message\",\"HelloWorld\");\n\n        Cookie cookie = new Cookie(\"c1\",\"v1\");\n        response.addCookie(cookie);\n        return \"forward:/success\";\n    }\n\n    // @RequestAttribute(value = \"msg\")：获取request域中的\"msg\"属性\n    @ResponseBody\n    @GetMapping(\"/success\")\n    public Map success(@RequestAttribute(value = \"msg\", required = false) String msg,\n                       @RequestAttribute(value = \"code\", required = false)Integer code,\n                       HttpServletRequest request,\n                       RedirectAttributes ra){\n        // RedirectAttributes ra用于重定向时添加参数\n        Object msg1 = request.getAttribute(\"msg\");\n\n        Map<String,Object> map = new HashMap<>();\n        Object hello = request.getAttribute(\"hello\");\n        Object world = request.getAttribute(\"world\");\n        Object message = request.getAttribute(\"message\");\n\n        map.put(\"reqMethod_msg\",msg1);\n        map.put(\"annotation_msg\",msg);\n        map.put(\"hello\",hello);\n        map.put(\"world\",world);\n        map.put(\"message\",message);\n\n        return map;\n    }\n\n}\n```\n\n**@MatrixVariable**与**UrlPathHelper**\n\n**@MatrixVariable**请求路径格式：`/cars/sell;low=34;brand=byd,audi,yd`。示例：\n\n```java\n@RestController\npublic class ParameterTestController {\n    // url: /cars/sell;low=34;brand=byd,audi,yd\n    @GetMapping(\"/cars/{path}\")\n    public Map carsSell(@MatrixVariable(\"low\") Integer low,\n                        @MatrixVariable(\"brand\") List<String> brand,\n                        @PathVariable(\"path\") String path){\n        Map<String,Object> map = new HashMap<>();\n        map.put(\"low\",low);\n        map.put(\"brand\",brand);\n        map.put(\"path\",path);\n        return map;\n    }\n\n    // url: /boss/1;age=20/2;age=10\n    @GetMapping(\"/boss/{bossId}/{empId}\")\n    public Map boss(@MatrixVariable(value = \"age\",pathVar = \"bossId\") Integer bossAge,\n                    @MatrixVariable(value = \"age\",pathVar = \"empId\") Integer empAge){\n        Map<String,Object> map = new HashMap<>();\n        map.put(\"bossAge\",bossAge);\n        map.put(\"empAge\",empAge);\n        return map;\n    }\n}\n```\n\nSpring Boot **默认是禁用了**矩阵变量的功能。若想手动开启，需要自定义一个**WebMvcConfigurer**配置器的实现类，在其中将**UrlPathHelper**的属性**removeSemicolonContent**设置为`false`，让其支持矩阵变量的。具体做法：\n\n1. 方法一：实现**WebMvcConfigurer**接口，令其代替**@EnableWebMvc**注解，实现定制的配置：\n\n```java\n@Configuration(proxyBeanMethods = false)\npublic class WebConfig implements WebMvcConfigurer {\n    @Override\n    public void configurePathMatch(PathMatchConfigurer configurer) {\n        UrlPathHelper urlPathHelper = new UrlPathHelper();\n        // 不移除；后面的内容。矩阵变量功能就可以生效\n        urlPathHelper.setRemoveSemicolonContent(false);\n        configurer.setUrlPathHelper(urlPathHelper);\n    }\n}\n```\n\n2. 方法二：在容器中注入一个`WebMvcConfigurer`组件：\n\n```java\n@Configuration(proxyBeanMethods = false)\npublic class WebConfig{\n    @Bean\n    public WebMvcConfigurer webMvcConfigurer(){\n        return new WebMvcConfigurer() {\n            @Override\n            public void configurePathMatch(PathMatchConfigurer configurer) {\n                UrlPathHelper urlPathHelper = new UrlPathHelper();\n                // 不移除；后面的内容。矩阵变量功能就可以生效\n                urlPathHelper.setRemoveSemicolonContent(false);\n                configurer.setUrlPathHelper(urlPathHelper);\n            }\n        }\n    }\n}\n```\n\n原理分析：\n\n**WebMvcAutoConfigurationAdapter**类实现了**WebMvcConfigurer**接口，其中有**configurePathMatch()**方法，该方法将创建一个**UrlPathHelper**类对象用于解析url。\n\n\n![image-20210723205155974](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210723205155974.png)\n\n![image-20210723205449763](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210723205449763.png)\n\n默认创建的**UrlPathHelper**类对象会将分号 ；后的所有路径移除，因此默认配置下无法开启矩阵变量功能，需要重写**WebMvcConfigurer**接口的**configurePathMatch()**方法，自定义一个**UrlPathHelper**对象，并将**removeSemicolonContent**属性设置为`false`：\n\n```java\n@Configuration(proxyBeanMethods = false)\npublic class WebConfig implements WebMvcConfigurer {\n    @Override\n    public void configurePathMatch(PathMatchConfigurer configurer) {\n        UrlPathHelper urlPathHelper = new UrlPathHelper();\n        // 不移除；后面的内容。矩阵变量功能就可以生效\n        urlPathHelper.setRemoveSemicolonContent(false);\n        configurer.setUrlPathHelper(urlPathHelper);\n    }\n}\n```\n\n### 拦截器\n\n---\n\n面试题：Filter 和 Interceptor 几乎拥有相同的功能，二者有何区别？\n\n- Filter 是 Servlet 定义的原生组件，好处是可以脱离 Spring 应用也能使用；其工作时机早于 Interceptor（待确定），在请求映射前执行\n- Interceptor 是 Spring 定义的接口，可以使用 Spring 的自动装配等功能\n\n---\n\n所有拦截器都实现了**HandlerInterceptor**接口，要想自定义拦截器，需要以下步骤：\n\n1. 编写一个拦截器实现**HandlerInterceptor**接口\n\n```java\n@Slf4j\n// 需要配置拦截器要拦截哪些请求，并把这些配置放到容器中\npublic class LoginInterceptor implements HandlerInterceptor {\n\n    // 在目标方法执行前执行\n    @Override\n    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {\n        log.info(\"拦截的请求路径是\" + request.getRequestURI());\n\n        HttpSession session = request.getSession();\n        Object loginUser = session.getAttribute(\"loginUser\");\n\n        if (loginUser!=null){\n            return true;\n        }\n\n        request.setAttribute(\"msg\", \"请先登录\");\n        request.getRequestDispatcher(\"/\").forward(request, response);\n        return false;\n    }\n\n    // 在目标方法执行后执行\n    @Override\n    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception {\n\n    }\n\n    // 触发的时机:\n    //   1. 目标方法执行前，遍历所有拦截器，执行其preHandle()方法，若某个拦截器该方法返回false，则倒序执行所有在该拦截器之前执行的（即在之前判断过的，拦截器返回true的）拦截器的afterCompletion()方法\n    //   2. 页面渲染完成之前的所有步骤有任何地方出现异常，就会倒序触发所有已执行过的拦截器的afterCompletion()方法\n    //   3. 页面成功渲染之后，倒序触发所有已执行过的拦截器的afterCompletion()方法\n    @Override\n    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception {\n\n    }\n}\n```\n\n2. 将拦截器注册到容器中（实现**WebMvcConfigurer**接口的 **addInterceptors()** 方法）\n3. 指定拦截规则（如果设置路径为\"`/**`\"，则静态资源也会被拦截）\n\n```java\n@Configuration\npublic class AdminWebConfig implements WebMvcConfigurer {\n\n    @Override\n    public void addInterceptors(InterceptorRegistry registry) {\n        registry.addInterceptor(new LoginInterceptor())\n                .addPathPatterns(\"/**\")   // 写 /** 时所有请求都会被拦截，包括静态资源\n                .excludePathPatterns(\"/\",\"/login\",\"/css/**\",\"/fonts/**\",\"/images/**\",\"/js/**\");\n    }\n}\n```\n\n### 拦截器源码分析\n\n拦截器方法的执行在**DispatcherServlet**的 **doDispatch(request, response)** 方法栈中，大致流程为：\n\n- 根据当前url请求，获取到目标方法对应的处理器执行链**HandlerExecutionChain**，其内包含了**目标方法处理器handler**以及容器中所有的**拦截器interceptorList**\n- 在目标方法执行前，调用 **mappedHandler.applyPreHandle()** 方法**顺序**遍历容器中的所有拦截器，依次执行其 **preHandle()** 方法：\n  - 如果当前遍历到的拦截器的 **preHandle()** 方法返回true，则执行下一个拦截器的 **preHandle()** 方法\n  - 如果当前拦截器返回false，则**倒序**执行所有已执行过了的拦截器的 **afterCompletion()** 方法\n  - 如果任意一个拦截器返回了false，则 **doDispatch(request, response)** 方法直接return，不再向下执行目标方法等代码\n  - 如果所有拦截器都返回true，则继续向下执行目标方法等代码\n- 调用 **ha.handle()** 方法执行完目标方法后调用 **mappedHandler.applyPostHandle()** 方法**倒序**执行所有已执行过了的拦截器的 **postHandle()** 方法\n- 页面成功渲染后（ **processDispatchResult()** 方法内），**倒序**执行所有已执行过了的拦截器的 **afterCompletion()** 方法\n- 之前步骤中有任何地方发生异常都会**倒序**执行所有已执行过了的拦截器的 **afterCompletion()** 方法\n\n上述流程截图：\n\n![image-20210801162832090](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801162832090.png)\n\n![image-20210801170259405](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801170259405.png)\n\n==之后补充reiggerAfter 和 processDispatchResult()的注释==\n\n放到Spring Boot源码\n\n拦截器链的执行顺序：\n\n![image-20210803182159679](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210803182159679.png)\n\n### 上述方法内细节\n\n返回的**mappedHandler**即处理器执行链**HandlerExecutionChain**，其内包含了**目标方法处理器handler**以及容器中所有的**拦截器interceptorList**，其内包含了自定义的拦截器：\n\n![image-20210801161247788](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801161247788.png)\n\n**mappedHandler.applyPreHandle()** 方法内顺序遍历容器中的所有拦截器，依次执行其 **preHandle()** 方法：\n\n![image-20210801163545481](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801163545481.png)\n\n![image-20210801163656217](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801163656217.png)\n\n **mappedHandler.applyPostHandle()** 方法内倒序执行所有已执行过了的拦截器的 **postHandle()** 方法：\n\n![image-20210801170843544](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801170843544.png)\n\n**afterCompletion()** 方法的触发时机:\n\n1. 目标方法执行前，遍历所有拦截器，执行其preHandle()方法，若某个拦截器该方法返回false，则倒序执行所有在该拦截器之前执行的（即在之前判断过的，拦截器返回true的）拦截器的 **afterCompletion()** 方法\n2. 页面渲染完成之前的所有步骤有任何地方出现异常，就会倒序触发所有已执行过的拦截器的 **afterCompletion()** 方法\n3. 页面成功渲染之后，倒序触发所有已执行过的拦截器的 **afterCompletion()** 方法\n\n\n\n### 文件上传\n\n在Spring Boot中实现文件上传功能的步骤：\n\n1. 在html文件中配置表单信息\n\n```html\n<form role=\"form\" th:action=\"@{/upload}\" method=\"post\" enctype=\"multipart/form-data\">\n    <div class=\"form-group\">\n        <label for=\"exampleInputEmail1\">邮箱</label>\n        <input type=\"email\" name=\"email\" class=\"form-control\" id=\"exampleInputEmail1\" placeholder=\"Enter email\">\n    </div>\n    <div class=\"form-group\">\n        <label for=\"exampleInputPassword1\">名字</label>\n        <input type=\"password\" name=\"userName\" class=\"form-control\" id=\"exampleInputPassword1\" placeholder=\"Password\">\n    </div>\n    <div class=\"form-group\">\n        <label for=\"exampleInputFile\">头像</label>\n        <input type=\"file\" name=\"headerImg\" id=\"exampleInputFile\">\n    </div>\n    <div class=\"form-group\">\n        <label for=\"exampleInputFile2\">生活照</label>\n        <input type=\"file\" name=\"photos\" id=\"photos\" multiple>\n    </div>\n    <button type=\"submit\" class=\"btn btn-primary\">提交</button>\n</form>\n```\n\n2. 添加相应的处理方法：\n\n```java\n@PostMapping(\"/upload\")\npublic String upload(@RequestParam(\"email\") String email,\n                     @RequestParam(\"userName\") String userName,\n                     @RequestPart(\"headerImg\") MultipartFile headerImg,\n                     @RequestPart(\"photos\") MultipartFile[] photos) throws IOException {\n    log.info(\"上传的信息：email={}, userName={}, headerImg={}, photos={}\",\n            email, userName, headerImg.getSize(), photos.length);\n\n    if (!headerImg.isEmpty()) {\n        String originalFilename = headerImg.getOriginalFilename();\n        headerImg.transferTo(new File(\"D:/cache/\" + originalFilename));\n    }\n\n    if (photos.length > 0){\n       for (MultipartFile photo : photos) {\n           String originalFilename = photo.getOriginalFilename();\n           photo.transferTo(new File(\"D:/cache/\" + originalFilename));\n       }\n    }\n\n    return \"main\";\n}\n```\n\n3. 在配置文件中修改上传文件大小等属性：\n\n```properties\nspring.servlet.multipart.max-file-size=10MB\nspring.servlet.multipart.max-request-size=100MB\n```\n\n上述代码中解析得到的文件类型**MultipartFile**：\n\n![image-20210801214140507](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210801214140507.png)\n\n### 异常处理\n\n默认情况下，Spring Boot提供`/error`处理所有错误的映射。\n\n- 对于机器客户端，它将生成JSON响应，其中包含错误，HTTP状态和异常消息的详细信息。\n- 对于浏览器客户端，响应一个“whitelabel”错误视图，以HTML格式呈现相同的数据\n\n放在静态资源目录下的**error/**目录下的**4xx.html**，**5xx.html**页面会被Spring Boot自动解析，作为错误页面展示在浏览器中：\n\n![image-20210802153307853](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210802153307853.png)\n\n### Web 原生组件注入\n\n#### 方式一：使用 Servlet API 注入\n\n**@ServletComponentScan(basePackages=\"com.zhao.admin\")** ：指定原生Servlet组件的存放路径。\n\n```java\n@ServletComponentScan(basePackages = \"com.zhao.admin\")\n@SpringBootApplication\npublic class SpringbootWebAdminApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(SpringbootWebAdminApplication.class, args);\n    }\n\n}\n```\n\n1. 注入**Servlet**：注入的这些请求直接响应，没有被拦截器所拦截（原理分析见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)）\n\n```java\n@WebServlet(urlPatterns = \"/my\")\npublic class MyServlet extends HttpServlet {\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        resp.getWriter().write(\"This is MyServlet\");\n    }\n}\n```\n\n2. 注入**Filter**：\n\n```java\n@WebFilter(urlPatterns = {\"/css/*\", \"/images/*\"})\npublic class MyFilter implements Filter {\n\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException {\n        // 过滤器初始化\n    }\n\n    @Override\n    public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {\n        // 过滤器工作\n        filterChain.doFilter(servletRequest, servletResponse);\n    }\n\n    @Override\n    public void destroy() {\n        // 过滤器销毁\n    }\n}\n```\n\n3. 注入**Listener**：\n\n```java\n@WebListener\npublic class MyServletContextListener implements ServletContextListener {\n    @Override\n    public void contextInitialized(ServletContextEvent sce) {\n        // 监听到项目初始化完成\n    }\n\n    @Override\n    public void contextDestroyed(ServletContextEvent sce) {\n        // 监听到项目销毁\n    }\n}\n```\n\n#### 方式二：使用 RegistrationBean\n\n在容器中注册的**xxxRegistrationBean**组件都会被配置到Tomcat服务器中，这些组件中配置的**Servlet/Filter/Listener**等Web原生组件都能映射客户端发来的请求。【源码分析见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)】\n\n```java\n@Configuration(proxyBeanMethods = true) // 保证MyServlet组件单实例的，避免myFilter()方法里重复调用myServlet()，产生冗余对象\npublic class MyRegistConfig {\n\n    @Bean\n    public ServletRegistrationBean myServlet(){\n        MyServlet myServlet = new MyServlet();\n        return new ServletRegistrationBean(myServlet,\"/my\",\"/my02\");\n    }\n\n\n    @Bean\n    public FilterRegistrationBean myFilter(){\n        MyFilter myFilter = new MyFilter();\n        // return new FilterRegistrationBean(myFilter,myServlet());\n        FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(myFilter);\n        filterRegistrationBean.setUrlPatterns(Arrays.asList(\"/my\",\"/css/*\"));\n        return filterRegistrationBean;\n    }\n\n    @Bean\n    public ServletListenerRegistrationBean myListener(){\n        MySwervletContextListener mySwervletContextListener = new MySwervletContextListener();\n        return new ServletListenerRegistrationBean(mySwervletContextListener);\n    }\n}\n```\n\n### 内嵌 Servlet 容器\n\n> 内嵌Servlet容器的源码分析见[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n内嵌服务器工作原理：手动调用要启动的服务器的 **start()** 方法开启服务。\n\n#### 切换 Servlet 容器\n\n要想切换服务器，则导入相应的starter场景即可：\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-web</artifactId>\n    <exclusions>\n        <exclusion>\n            <groupId>org.springframework.boot</groupId>\n            <artifactId>spring-boot-starter-tomcat</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-undertow</artifactId>\n</dependency>\n```\n\n#### 定制 Servlet 容器\n\n- 修改配置文件中的 `server.xxx` 属性（最方便）\n- 自定义**ConfigurableServletWebServerFactory**代替**TomcatServletWebServerFactory**，并将其注册到容器中\n- 实现  `WebServerFactoryCustomizer<ConfigurableServletWebServerFactory>` ，把配置文件的值和**ServletWebServerFactory**进行绑定（**xxxxxCustomizer**：定制化器，可以改变xxxx的默认规则）：\n\n```java\n@Component\npublic class MyTomcatWebServerFactoryCustomizer implements WebServerFactoryCustomizer<TomcatServletWebServerFactory> {\n\n    @Override\n    public void customize(TomcatServletWebServerFactory server) {\n        server.addConnectorCustomizers((connector) -> connector.setAsyncTimeout(Duration.ofSeconds(20).toMillis()));\n    }\n\n}\n```\n\n## 数据访问\n\n### 导入 JDBC 场景\n\n在Maven中导入JDBC场景`spring-boot-starter-data-jdbc`：\n\n``` xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-jdbc</artifactId>\n</dependency>\n\n```\n\n导入该场景后，将出现数据源Hikari、JDBC和事务等依赖：\n\n![image-20210804152401123](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210804152401123.png)\n\n导入数据库MySQL驱动的依赖：\n\n```xml\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n</dependency>\n```\n\nSpring Boot提供的MySQL驱动的默认版本：`<mysql.version>8.0.22</mysql.version>`\n\n若想要修改版本，可以：\n\n1. 直接依赖引入具体版本（maven的就近依赖原则）\n2. 重新声明版本（maven的属性的就近优先原则）\n\n```xml\n<properties>\n    <java.version>1.8</java.version>\n    <mysql.version>5.1.49</mysql.version>\n</properties>\n\n<!-- 或者：-->\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.49 </version>\n</dependency>\n```\n\n### 数据源自动配置原理\n\n**DataSourceAutoConfiguration**： 数据源的自动配置类\n\n- 修改**数据源**相关的配置前缀：`\"spring.datasource\"`\n- **数据库连接池**的配置，是容器中**没有自定义的DataSource时**才自动配置的\n- 底层自动配置的数据源是：**HikariDataSource**\n\n![image-20210804153524354](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210804153524354.png)\n\n修改**数据源**的配置项：\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/school?useUnicode=true&characterEncoding=utf8&useSSL=true\n    username: root\n    password: zhaoyuyun\n    driver-class-name: com.mysql.jdbc.Driver\n```\n\n其他数据库相关的自动配置类：\n\n- **DataSourceTransactionManagerAutoConfiguration**： 事务管理器的自动配置\n- **JdbcTemplateAutoConfiguration**： JdbcTemplate的自动配置，可以来对数据库进行crud。容器中有**JdbcTemplate**这个组件，可以修改配置前缀  `\"spring.jdbc\"` 来修改JdbcTemplate的配置。\n- **JndiDataSourceAutoConfiguration**： jndi的自动配置\n- **XADataSourceAutoConfiguration**： 分布式事务相关的\n\n### Druid 数据源\n\nDruid官方github地址：https://github.com/alibaba/druid\n\n#### 基于手动方式引入 Druid 数据源（不常用）\n\n若在容器中配置了自定义的数据源，则不再开启**HikariDataSource**数据源。\n\n引入Druid数据源的依赖：\n\n```xml\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>druid</artifactId>\n    <version>1.1.17</version>\n</dependency>\n```\n\n向容器中注册Druid数据源，并开启监控、防火墙等功能：\n\n```java\n@Configuration\npublic class MyDataSourceConfig {\n\n    // 注册Druid数据源\n    // 将配置文件中以spring.datasource为前缀的属性设置到数据源中\n    @ConfigurationProperties(prefix = \"spring.datasource\")\n    @Bean\n    public DataSource dataSource() throws SQLException {\n        DruidDataSource druidDataSource = new DruidDataSource();\n        // 开启统计监控信息功能与防火墙功能，也可以写在配置文件中\n        druidDataSource.setFilters(\"stat, wall\");\n        return druidDataSource;\n    }\n\n    // 配置Druid的监控页功能\n    @Bean\n    public ServletRegistrationBean statViewServlet() {\n        StatViewServlet statViewServlet = new StatViewServlet();\n        ServletRegistrationBean<StatViewServlet> registrationBean =\n                new ServletRegistrationBean<>(statViewServlet, \"/druid/*\");\n        registrationBean.addInitParameter(\"loginUsername\", \"admin\");\n        registrationBean.addInitParameter(\"loginPassword\", \"123456\");\n        return registrationBean;\n    }\n\n    // WebStatFilter：用于采集web-jdbc关联监控的数据\n    @Bean\n    public FilterRegistrationBean webStatFilter() {\n        WebStatFilter webStatFilter = new WebStatFilter();\n        FilterRegistrationBean<WebStatFilter> filterRegistrationBean = new FilterRegistrationBean<>(webStatFilter);\n        filterRegistrationBean.setUrlPatterns(Arrays.asList(\"/*\"));\n        filterRegistrationBean.addInitParameter(\"exclusions\", \"*.js, *.gif, *.jpg, *.css, *.ico, /druid/*\");\n\n        return null;\n    }\n}\n```\n\n配置文件中设置数据源属性：\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/myDB?useUnicode=true&characterEncoding=utf8&useSSL=true\n    username: root\n    password: zhaoyuyun\n    driver-class-name: com.mysql.jdbc.Driver\n    filters: stat, wall\n    max-active: 12\n```\n\n#### StatViewServlet\n\n**StatViewServlet**的用途包括：\n\n- 提供监控信息展示的html页面\n- 提供监控信息的JSON API\n\n```xml\n<servlet>\n    <servlet-name>DruidStatView</servlet-name>\n    <servlet-class>com.alibaba.druid.support.http.StatViewServlet</servlet-class>\n</servlet>\n<servlet-mapping>\n    <servlet-name>DruidStatView</servlet-name>\n    <url-pattern>/druid/*</url-pattern>\n</servlet-mapping>\n```\n\n#### StatFilter\n\n用于统计监控信息；如SQL监控、URI监控。需要给数据源中配置属性。可以允许多个filter，多个用，分割。例如：\n\n```xml-dtd\n<property name=\"filters\" value=\"stat,slf4j\" />\n```\n\nDruid系统中所有filter：\n\n| 别名          | Filter类名                                              |\n| ------------- | ------------------------------------------------------- |\n| default       | com.alibaba.druid.filter.stat.StatFilter                |\n| stat          | com.alibaba.druid.filter.stat.StatFilter                |\n| mergeStat     | com.alibaba.druid.filter.stat.MergeStatFilter           |\n| encoding      | com.alibaba.druid.filter.encoding.EncodingConvertFilter |\n| log4j         | com.alibaba.druid.filter.logging.Log4jFilter            |\n| log4j2        | com.alibaba.druid.filter.logging.Log4j2Filter           |\n| slf4j         | com.alibaba.druid.filter.logging.Slf4jLogFilter         |\n| commonlogging | com.alibaba.druid.filter.logging.CommonsLogFilter       |\n\n#### 基于官方Starter方式引入Druid数据源（常用）\n\n引入Druid官方提供的starter场景依赖：\n\n```xml\n<dependency>\n    <groupId>com.alibaba</groupId>\n    <artifactId>druid-spring-boot-starter</artifactId>\n    <version>1.1.17</version>\n</dependency>\n```\n\n其向容器中添加了一个Druid数据源自动配置类**DruidDataSourceAutoConfigure**：\n\n![image-20210804202513107](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210804202513107.png)\n\n- 该配置器在Spring Boot自带的数据源自动配置器**DataSourceAutoConfiguration**之前配置，因此不再注册Spring Boot默认的数据源**HikariDataSource**。\n- 该配置器绑定了**DataSourceProperties**和**DruidStatProperties**资源配置类，分别对应资源路径`\"spring.datasource\"`和`\"spring.datasource.druid\"`\n- 该配置器导入了其他相关的配置类，用于开启配置页、防火墙、Web监控等功能\n\n导入的其他相关配置类如下：\n\n- **DruidSpringAopConfiguration.class**（`spring.datasource.druid.aop-patterns`）：监控Spring Bean\n- **DruidStatViewServletConfiguration.class**（`spring.datasource.druid.stat-view-servlet`）：配置监控页：\n-  **DruidWebStatFilterConfiguration.class**（`spring.datasource.druid.web-stat-filter`）：Web监控配置\n- **DruidFilterConfiguration.class**：配置Druid的所有Filters：\n\n```java\nprivate static final String FILTER_STAT_PREFIX = \"spring.datasource.druid.filter.stat\";\nprivate static final String FILTER_CONFIG_PREFIX = \"spring.datasource.druid.filter.config\";\nprivate static final String FILTER_ENCODING_PREFIX = \"spring.datasource.druid.filter.encoding\";\nprivate static final String FILTER_SLF4J_PREFIX = \"spring.datasource.druid.filter.slf4j\";\nprivate static final String FILTER_LOG4J_PREFIX = \"spring.datasource.druid.filter.log4j\";\nprivate static final String FILTER_LOG4J2_PREFIX = \"spring.datasource.druid.filter.log4j2\";\nprivate static final String FILTER_COMMONS_LOG_PREFIX = \"spring.datasource.druid.filter.commons-log\";\nprivate static final String FILTER_WALL_PREFIX = \"spring.datasource.druid.filter.wall\";\n```\n\n配置示例：\n\n```yaml\nspring:\n  datasource:\n    url: jdbc:mysql://localhost:3306/db_account\n    username: root\n    password: 123456\n    driver-class-name: com.mysql.jdbc.Driver\n\n    druid:\n      aop-patterns: com.zhao.admin.*  # 监控SpringBean\n      filters: stat,wall     # 底层开启功能，stat（sql监控），wall（防火墙）\n\n      stat-view-servlet:   # 配置监控页功能\n        enabled: true\n        login-username: admin\n        login-password: admin\n        resetEnable: false\n\n      web-stat-filter:  # 监控web\n        enabled: true\n        urlPattern: /*\n        exclusions: '*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*'\n\n      filter:\n        stat:    # 对上面filters里面的stat的详细配置\n          slow-sql-millis: 1000\n          logSlowSql: true\n          enabled: true\n        wall:\n          enabled: true\n          config:\n            drop-table-allow: false\n```\n\nSpringBoot配置示例：https://github.com/alibaba/druid/tree/master/druid-spring-boot-starter\n\n配置项列表：[https://github.com/alibaba/druid/wiki/DruidDataSource%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7%E5%88%97%E8%A1%A8](https://github.com/alibaba/druid/wiki/DruidDataSource配置属性列表)\n\n### 导入 MyBatis 场景\n\nMyBatis官方链接：https://github.com/mybatis\n\n导入MyBatis的starter场景依赖：\n\n```XML\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.4</version>\n</dependency>\n```\n\n其导入了如下包：\n\n![image-20210805142616006](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805142616006.png)\n\n其中，MyBatis的自动配置器**MybatisAutoConfiguration**会在Spring Boot启动时注册到容器中：\n\n![image-20210805143359047](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805143359047.png)\n\n该类绑定了**MybatisProperties**，对应Spring Boot的配置文件中以`\"mybatis\"`为前缀的属性：\n\n![image-20210805144216362](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805144216362.png)\n\n1. **MybatisAutoConfiguration**向容器中注册了**sqlSessionFactory**，其使用容器中存在的数据源，并且从配置资源类**MybatisProperties**中获取MyBatis的配置属性值：\n\n![image-20210805143832167](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805143832167.png)\n\n2. **MybatisAutoConfiguration**向容器中注册了**SqlSessionTemplate**，其可以执行批量的**SqlSession**：\n\n![image-20210805144629709](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805144629709.png)\n\n![image-20210805144721508](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805144721508.png)\n\n3. **MybatisAutoConfiguration**向容器中注册了**AutoConfiguredMapperScannerRegistrar**，其用于扫描容器中带有 **@Mapper** 注解的组件：\n\n![image-20210805151107546](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805151107546.png)\n\n### 使用 MyBatis\n\n开启MyBatis流程：\n\n- 导入MyBatis官方starter场景： `mybatis-spring-boot-starter`\n- 编写`xxxMapper`接口，并在其上使用 **@Mapper** 注解（也可以使用 **@MapperScan()**  简化）\n- 编写sql映射文件`xxxMapper.xml`（放置在`classpath:mapper/*.xml`下）并绑定`xxxMapper`接口\n- 在`application.yaml`中指定mapper配置文件的位置`mapper-locations`，以及指定全局配置文件的信息\n\n具体步骤如下：\n\n1. 导入MyBatis的starter场景： `mybatis-spring-boot-starter`\n\n```XML\n<dependency>\n    <groupId>org.mybatis.spring.boot</groupId>\n    <artifactId>mybatis-spring-boot-starter</artifactId>\n    <version>2.1.4</version>\n</dependency>\n```\n\n2. 编写`UserMapper`接口，并在其上使用 **@Mapper** 注解（也可以使用 **@MapperScan(\"com.zhao.mapper\")**  简化）\n\n```java\n@Mapper\npublic interface UserMapper {\n\n    // 可以使用注解代替xml里的sql语句\n    @Select(\"select * from user where id = #{id}\")\n    User selectUser(Long id);\n\n    void deleteUser(Long id);\n}\n```\n\n3. 编写sql映射文件`userMapper.xml`（放置在`classpath:mapper/*.xml`下）\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.zhao.admin.mapper.UserMapper\">\n    <select id=\"selectUser\" resultType=\"com.zhao.admin.bean.User\">\n        select * from user where id = #{id}\n    </select>\n\n    <delete id=\"deleteUser\" parameterType=\"long\">\n        delete from user where id = #{id}\n    </delete>\n</mapper>\n```\n\n4. 在`application.yaml`中配置MyBatis：\n\n```yaml\nmybatis:\n  #  config-location: classpath:mybatis/mybatis-config.xml\n  mapper-locations: classpath:mapper/*.xml\n  \n  # 可以不写mybatis-config.xml，所有全局配置文件的配置都放在configuration配置项中即可\n  configuration:\n    map-underscore-to-camel-case: true  \n```\n\n项目结构：\n\n![image-20210805212017625](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805212017625.png)\n\n### MyBatis Plus\n\n导入MyBatis-Plus的starter场景：`mybatis-plus-boot-starter`\n\n```xml\n<dependency>\n    <groupId>com.baomidou</groupId>\n    <artifactId>mybatis-plus-boot-starter</artifactId>\n    <version>3.4.1</version>\n</dependency>\n```\n\n其会向容器中导入**MybatisPlusAutoConfiguration**：\n\n![image-20210805194210051](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805194210051.png)\n\n其对应的配置前缀为`\"mybatis-plus\"`，其会默认扫描`\"classpath*:/mapper/**/*.xml\"`，即类路径下mapper目录下的所有`.xml`文件都会被作为MyBatis的xml进行扫描（开发人员将sql映射文件放置在该目录下即可）：\n\n![image-20210805193856503](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805193856503.png)\n\n使用时，自定义的Mapper接口继承 `BaseMapper<User>` 接口即可自动实现简单功能的CRUD:\n\n```java\n@Mapper\npublic interface UserMapper extends BaseMapper<User> {\n\n}\n```\n\n `BaseMapper<User>` 接口中默认实现了简单CRUD的方法：\n\n![image-20210805213009214](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210805213009214.png)\n\n使用MyBatis Plus提供的`IService`，`ServiceImpl`，减轻Service层开发工作。\n\n``` java\nimport com.zhao.hellomybatisplus.model.User;\nimport com.baomidou.mybatisplus.extension.service.IService;\n\nimport java.util.List;\n\n/**\n *  Service 的CRUD也不用写了\n */\npublic interface UserService extends IService<User> {\n\t//此处故意为空\n}\n```\n\n``` java\nimport com.zhao.hellomybatisplus.model.User;\nimport com.zhao.hellomybatisplus.mapper.UserMapper;\nimport com.zhao.hellomybatisplus.service.UserService;\nimport com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Service;\n\nimport java.util.List;\n\n@Service\npublic class UserServiceImpl extends ServiceImpl<UserMapper,User> implements UserService {\n\t//此处故意为空\n}\n```\n\n## 指标监控\n\n### Spring Boot Actuator\n\n> [官方文档 - Spring Boot Actuator: Production-ready Features](https://docs.spring.io/spring-boot/docs/2.4.2/reference/htmlsingle/#production-ready)\n\n未来每一个微服务在云上部署以后，我们都需要对其进行监控、追踪、审计、控制等。Spring Boot就抽取了Actuator场景，使得我们每个微服务快速引用即可获得生产级别的应用监控、审计等功能。\n\nSpring Boot Actuator1.x与2.x的不同：\n\n![image-20210901160659165](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210901160659165.png)\n\n使用Spring Boot Actuator：\n\n1. 添加Maven依赖：\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-actuator</artifactId>\n</dependency>\n```\n\n该场景启动器常与`spring-boot-starter-web`一起使用，监控web的各种指标。\n\n2. 暴露所有监控信息为HTTP：\n\n```yaml\nmanagement:\n  endpoints:\n    enabled-by-default: true # 暴露所有端点信息\n    web:\n      exposure:\n        include: '*'  # 以web方式暴露\n```\n\n3. 访问`http://localhost:8080/actuator/**`。测试例子：\n- http://localhost:8080/actuator/beans\n- http://localhost:8080/actuator/configprops\n- http://localhost:8080/actuator/metrics\n- http://localhost:8080/actuator/metrics/jvm.gc.pause\n- http://localhost:8080/actuator/metrics/endpointName/detailPath\n  \n\n可视化：https://github.com/codecentric/spring-boot-admin\n\n### Actuator Endpoint\n\n常用断点Endpoint：\n\n| ID                                                       |                             描述                             |\n| :------------------------------------------------------- | :----------------------------------------------------------: |\n| &nbsp;`auditevents`                                      | 暴露当前应用程序的审核事件信息。需要一个`AuditEventRepository组件`。 |\n| &nbsp;`beans `                                           |          显示应用程序中所有Spring Bean的完整列表。           |\n| &nbsp;`caches`                                           |                       暴露可用的缓存。                       |\n| &nbsp;`conditions`                                       |     显示自动配置的所有条件信息，包括匹配或不匹配的原因。     |\n| &nbsp;`configprops`                                      |             显示所有`@ConfigurationProperties`。             |\n| &nbsp;`env`                                              |          暴露Spring的属性`ConfigurableEnvironment`           |\n| &nbsp;`flyway`                                           | 显示已应用的所有Flyway数据库迁移。 需要一个或多个`Flyway`组件。 |\n| &nbsp;`health`                                           |                  显示应用程序运行状况信息。                  |\n| &nbsp;`httptrace`                                        | 显示HTTP跟踪信息（默认情况下，最近100个HTTP请求-响应）。需要一个`HttpTraceRepository`组件。 |\n| &nbsp;`info`                                             |                      显示应用程序信息。                      |\n| <div style=\"width: 120pt\">&nbsp;`integrationgraph`</div> | 显示Spring `integrationgraph` 。需要依赖`spring-integration-core`。 |\n| &nbsp;`loggers`                                          |               显示和修改应用程序中日志的配置。               |\n| &nbsp;`liquibase`                                        | 显示已应用的所有Liquibase数据库迁移。需要一个或多个`Liquibase`组件。 |\n| &nbsp;`metrics`                                          |                显示当前应用程序的“指标”信息。                |\n| &nbsp;`mappings`                                         |             显示所有`@RequestMapping`路径列表。              |\n| &nbsp;`scheduledtasks`                                   |                  显示应用程序中的计划任务。                  |\n| &nbsp;`sessions`                                         | 允许从Spring Session支持的会话存储中检索和删除用户会话。需要使用Spring Session的基于Servlet的Web应用程序。 |\n| &nbsp;`shutdown`                                         |                使应用程序正常关闭。默认禁用。                |\n| &nbsp;`startup`                                          | 显示由`ApplicationStartup`收集的启动步骤数据。需要使用Spring Application进行配置`BufferingApplicationStartup`。 |\n| &nbsp;`threaddump`                                       |                        执行线程转储。                        |\n\n如果应用程序是Web应用程序（Spring MVC，Spring WebFlux或Jersey），则可以使用以下附加端点：\n\n| ID                                                |                             描述                             |\n| ------------------------------------------------- | :----------------------------------------------------------: |\n| &nbsp;`heapdump`                                  |                   返回`hprof`堆转储文件。                    |\n| &nbsp;`jolokia`                                   | 通过HTTP暴露JMX bean（需要引入Jolokia，不适用于WebFlux）。需要引入依赖`jolokia-core`。 |\n| &nbsp;`logfile`                                   | 返回日志文件的内容（如果已设置`logging.file.name`或`logging.file.path`属性）。支持使用HTTP`Range`标头来检索部分日志文件的内容。 |\n| <div style=\"width: 80pt\">&nbsp;`prometheus`</div> | 以Prometheus服务器可以抓取的格式公开指标。需要依赖`micrometer-registry-prometheus`。 |\n\n其中最常用的Endpoint：\n\n- **Health：监控状况**\n- **Metrics：运行时指标**\n- **Loggers：日志记录**\n\n### Health Endpoint\n健康检查端点，我们一般用于在云平台，平台会定时的检查应用的健康状况，我们就需要Health Endpoint可以为平台返回当前应用的一系列组件健康状况的集合。重要的几点：\n\n- health endpoint返回的结果，应该是一系列健康检查后的一个汇总报告。\n- 很多的健康检查默认已经自动配置好了，比如：数据库、redis等。\n- 可以很容易的添加自定义的健康检查机制。\n\n### Metrics Endpoint\n\n提供详细的、层级的、空间指标信息，这些信息可以被pull（主动推送）或者push（被动获取）方式得到：\n\n- 通过Metrics对接多种监控系统。\n- 简化核心Metrics开发。\n- 添加自定义Metrics或者扩展已有Metrics。\n\n![image-20210901155626308](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210901155626308.png)\n\n\n\n### 开启与禁用 Endpoints\n默认所有的Endpoint除过shutdown都是开启的。\n\n需要开启或者禁用某个Endpoint。配置模式为`management.endpoint.<endpointName>.enabled = true`：\n\n```yaml\nmanagement:\n  endpoint:\n    beans:\n      enabled: true\n```\n\n或者禁用所有的Endpoint然后手动开启指定的Endpoint：\n\n```yaml\nmanagement:\n  endpoints:\n    enabled-by-default: false\n  endpoint:\n    beans:\n      enabled: true\n    health:\n      enabled: true\n```\n\n### 暴露 Endpoints\n\n支持的暴露方式：\n\n- HTTP：默认只暴露**health**和**info**。\n- JMX：默认暴露所有Endpoint。（Java Management Extensions（Java管理扩展）的缩写，是一个为应用程序植入管理功能的框架。用户可以在任何Java应用程序中使用这些代理和服务实现管理。）\n- 除过health和info，剩下的Endpoint都应该进行保护访问。如果引入Spring Security，则会默认配置安全访问规则。\n\n| ID                 | JMX  | Web  |\n| ------------------ | ---- | ---- |\n| `auditevents`      | Yes  | No   |\n| `beans`            | Yes  | No   |\n| `caches`           | Yes  | No   |\n| `conditions`       | Yes  | No   |\n| `configprops`      | Yes  | No   |\n| `env`              | Yes  | No   |\n| `flyway`           | Yes  | No   |\n| `health`           | Yes  | Yes  |\n| `heapdump`         | N/A  | No   |\n| `httptrace`        | Yes  | No   |\n| `info`             | Yes  | Yes  |\n| `integrationgraph` | Yes  | No   |\n| `jolokia`          | N/A  | No   |\n| `logfile`          | N/A  | No   |\n| `loggers`          | Yes  | No   |\n| `liquibase`        | Yes  | No   |\n| `metrics`          | Yes  | No   |\n| `mappings`         | Yes  | No   |\n| `prometheus`       | N/A  | No   |\n| `scheduledtasks`   | Yes  | No   |\n| `sessions`         | Yes  | No   |\n| `shutdown`         | Yes  | No   |\n| `startup`          | Yes  | No   |\n| `threaddump`       | Yes  | No   |\n\n### 定制 Endpoint\n\n#### 定制 Health 信息\n\n```yaml\nmanagement:\n    health:\n      enabled: true\n      show-details: always # 总是显示详细信息。可显示每个模块的状态信息\n```\n\n通过实现`HealthIndicator`接口，或继承`MyComHealthIndicator`类。\n\n\n```java\nimport org.springframework.boot.actuate.health.Health;\nimport org.springframework.boot.actuate.health.HealthIndicator;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class MyHealthIndicator implements HealthIndicator {\n\n    @Override\n    public Health health() {\n        int errorCode = check(); // perform some specific health check\n        if (errorCode != 0) {\n            return Health.down().withDetail(\"Error Code\", errorCode).build();\n        }\n        return Health.up().build();\n    }\n\n}\n\n/*     \n构建Health\nHealth build = Health.down()\n                .withDetail(\"msg\", \"error service\")\n                .withDetail(\"code\", \"500\")\n                .withException(new RuntimeException())\n                .build();\n*/\n```\n\n```java\n@Component\npublic class MyComHealthIndicator extends AbstractHealthIndicator {\n\n    /**\n     * 真实的检查方法\n     * @param builder\n     * @throws Exception\n     */\n    @Override\n    protected void doHealthCheck(Health.Builder builder) throws Exception {\n        //mongodb。  获取连接进行测试\n        Map<String,Object> map = new HashMap<>();\n        // 检查完成\n        if(1 == 2){\n//            builder.up(); //健康\n            builder.status(Status.UP);\n            map.put(\"count\",1);\n            map.put(\"ms\",100);\n        }else {\n//            builder.down();\n            builder.status(Status.OUT_OF_SERVICE);\n            map.put(\"err\",\"连接超时\");\n            map.put(\"ms\",3000);\n        }\n\n        builder.withDetail(\"code\",100)\n                .withDetails(map);\n    }\n}\n```\n\n#### 定制 info 信息\n\n方式1：编写配置文件\n\n```yaml\ninfo:\n  appName: boot-admin\n  version: 2.0.1\n  mavenProjectName: @project.artifactId@  #使用@@可以获取maven的pom文件值\n  mavenProjectVersion: @project.version@\n```\n\n方式2：编写`InfoContributor`\n\n```java\nimport java.util.Collections;\n\nimport org.springframework.boot.actuate.info.Info;\nimport org.springframework.boot.actuate.info.InfoContributor;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class ExampleInfoContributor implements InfoContributor {\n\n    @Override\n    public void contribute(Info.Builder builder) {\n        builder.withDetail(\"example\",\n                Collections.singletonMap(\"key\", \"value\"));\n    }\n}\n```\n\nhttp://localhost:8080/actuator/info 会输出以上方式返回的所有info信息\n\n#### 定制Metrics信息\n\n[Spring Boot支持的metrics](https://docs.spring.io/spring-boot/docs/2.4.2/reference/htmlsingle/#production-ready-metrics-meter)\n\n增加定制Metrics：\n\n```java\nclass MyService{\n    Counter counter;\n    public MyService(MeterRegistry meterRegistry){\n         counter = meterRegistry.counter(\"myservice.method.running.counter\");\n    }\n\n    public void hello() {\n        counter.increment();\n    }\n}\n```\n\n```java\n//也可以使用下面的方式\n@Bean\nMeterBinder queueSize(Queue queue) {\n    return (registry) -> Gauge.builder(\"queueSize\", queue::size).register(registry);\n}\n```\n\n#### 定制 Endpoint\n\n```java\n@Component\n@Endpoint(id = \"container\")\npublic class DockerEndpoint {\n\n    @ReadOperation\n    public Map getDockerInfo(){\n        return Collections.singletonMap(\"info\",\"docker started...\");\n    }\n\n    @WriteOperation\n    private void restartDocker(){\n        System.out.println(\"docker restarted....\");\n    }\n}\n```\n\n场景：\n\n- 开发`ReadinessEndpoint`来管理程序是否就绪。\n- 开发`LivenessEndpoint`来管理程序是否存活。\n\n### Boot Admin Server\n\n[官方Github](https://blog.csdn.net/u011863024/article/details/113667946) 和 [官方文档](https://codecentric.github.io/spring-boot-admin/2.3.1/#getting-started)。[开始使用方法](https://codecentric.github.io/spring-boot-admin/2.3.1/#getting-started)\n\n## Profile 环境切换\n\n为了方便多环境适配，Spring Boot简化了profile功能。\n\n- 默认配置文件`application.yaml`任何时候都会加载。\n- 指定环境配置文件`application-{env}.yaml`，`env`通常替代为`test`，\n- 激活指定环境：\n  - 配置文件激活：`spring.profiles.active=prod`\n  - 命令行激活：`java -jar xxx.jar --spring.profiles.active=prod --person.name=haha`（修改配置文件的任意值，**命令行优先**）\n- 默认配置与环境配置同时生效\n- 同名配置项，profile配置优先\n\n### @Profile 条件装配功能\n\n```java\n@Data\n@Component\n@ConfigurationProperties(\"person\") //在配置文件中配置\npublic class Person{\n    private String name;\n    private Integer age;\n}\n```\n\n`application.yaml`：\n\n```yaml\nperson: \n  name: zhangsan\n  age: 8\n```\n\n多环境配置：\n\n```java\npublic interface Person {\n    String getName();\n    Integer getAge();\n}\n\n@Profile(\"test\") // 加载application-test.yaml里的\n@Component\n@ConfigurationProperties(\"person\")\n@Data\npublic class Worker implements Person {\n    private String name;\n    private Integer age;\n}\n\n@Profile(value = {\"prod\",\"default\"}) // 加载application-prod.yaml里的\n@Component\n@ConfigurationProperties(\"person\")\n@Data\npublic class Boss implements Person {\n\n    private String name;\n    private Integer age;\n}\n```\n\n`application-test.yaml`：\n\n```yaml\nperson:\n  name: test-张三\n\nserver:\n  port: 7000\n```\n\n`application-prod.yaml`：\n\n```yaml\nperson:\n  name: prod-张三\n\nserver:\n  port: 8000\n```\n\n`application.properties`：\n\n```properties\n# 激活prod配置文件\nspring.profiles.active=prod\n```\n\n```java\n@Autowired\nprivate Person person;\n\n@GetMapping(\"/\")\npublic String hello(){\n    // 激活了prod，则返回Boss；激活了test，则返回Worker\n    return person.getClass().toString();\n}\n```\n\n**@Profile** 还可以修饰在方法上：\n\n```java\nclass Color {\n}\n\n@Configuration\npublic class MyConfig {\n    @Profile(\"prod\")\n    @Bean\n    public Color red(){\n        return new Color();\n    }\n\n    @Profile(\"test\")\n    @Bean\n    public Color green(){\n        return new Color();\n    }\n}\n```\n\n可以激活一组：\n\n```properties\nspring.profiles.active=production\n\nspring.profiles.group.production[0]=proddb\nspring.profiles.group.production[1]=prodmq\n```\n\n### 配置加载优先级\n\n[官方文档 - Externalized Configuration](https://docs.spring.io/spring-boot/docs/2.4.2/reference/htmlsingle/#boot-features-external-config)\n\n> Spring Boot uses a very particular PropertySource order that is designed to allow sensible overriding of values. Properties are considered in the following order (with values from lower items overriding earlier ones)（1优先级最低，14优先级最高）\n\n- Default properties (specified by setting `SpringApplication.setDefaultProperties`).\n- `@PropertySource` annotations on your `@Configuration` classes. Please note that such property sources are not added to the `Environment` until the application context is being refreshed. This is too late to configure certain properties such as `logging.*` and `spring.main.*` which are read before refresh begins.\n- Config data (such as `application.properties` files)\n- A `RandomValuePropertySource` that has properties only in `random.*`.\n- OS environment variables.\n- Java System properties (`System.getProperties()`).\n- JNDI attributes from `java:comp/env`.\n- `ServletContext` init parameters.\n- `ServletConfig` init parameters.\n- Properties from `SPRING_APPLICATION_JSON` (inline JSON embedded in an environment variable or system property).\n- Command line arguments.\n- `properties` attribute on your tests. Available on `@SpringBootTest` and the test annotations for testing a particular slice of your application.\n- `@TestPropertySource` annotations on your tests.\n- Devtools global settings properties in the `$HOME/.config/spring-boot` directory when devtools is active.\n\n**指定环境变量优先，外部优先，后加载的可以覆盖前面的同名配置项。**\n\n- 外部配置源\n  - Java属性文件\n  - YAML文件\n  - 环境变量\n  - 命令行参数\n- 配置文件查找位置\n  - `classpath` 根路径\n  - `classpath` 根路径下`config`目录\n  - jar包当前目录\n  - jar包当前目录的`config`目录\n  - `/config`子目录的直接子目录\n- 配置文件加载顺序：\n  - 当前jar包内部的`application.properties`和`application.yml`\n  - 当前jar包内部的`application-{profile}.properties` 和 `application-{profile}.yml`\n  - 引用的外部jar包的`application.properties`和`application.yml`\n  - 引用的外部jar包的`application-{profile}.properties`和`application-{profile}.yml`\n\n## 单元测试\n\n### JUnit5 的变化\n\n**Spring Boot 2.2.0 版本开始引入 JUnit 5 作为单元测试默认库**。作为最新版本的JUnit框架，JUnit5与之前版本的JUnit框架有很大的不同。由三个不同子项目的几个不同模块组成：\n\n**JUnit 5 = JUnit Platform + JUnit Jupiter + JUnit Vintage**\n\n- **JUnit Platform**: JUnit Platform是在JVM上启动测试框架的基础，不仅支持JUnit自制的测试引擎，其他测试引擎也都可以接入。\n- **JUnit Jupiter**: JUnit Jupiter提供了JUnit5的新的编程模型，是JUnit5新特性的核心。内部包含了一个**测试引擎**，用于在JUnit Platform上运行。\n- **JUnit Vintage**: 由于JUint已经发展多年，为了照顾老的项目，JUnit Vintage提供了兼容JUnit4.x和JUnit3.x的测试引擎。\n\n![image-20210813193410660](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/image-20210813193410660.png)\n\n注意：**Spring Boot 2.4 以上版本移除了默认对Vintage的依赖。如果需要兼容junit4需要自行引入（不能使用junit4的功能 @Test）**\n\nJUnit 5's Vintage Engine Removed from `spring-boot-starter-test`，如果需要继续兼容junit4需要自行引入vintage：\n\n```xml\n<dependency>\n    <groupId>org.junit.vintage</groupId>\n    <artifactId>junit-vintage-engine</artifactId>\n    <scope>test</scope>\n    <exclusions>\n        <exclusion>\n            <groupId>org.hamcrest</groupId>\n            <artifactId>hamcrest-core</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n```\n\n![img](/images/%E3%80%90SpringBoot%E3%80%91SpringBoot2/1606797616337-e73010e9-9cac-496d-a177-64b677af5a3d.png)\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-test</artifactId>\n    <scope>test</scope>\n</dependency>\n```\n\n现在版本使用 `@SpringBootTest` ：\n\n```java\n@SpringBootTest\nclass Boot05WebAdminApplicationTests {\n    @Test\n    void contextLoads() {\n    }\n}\n```\n\n以前版本使用 `@SpringBootTest + @RunWith(SpringTest.class)`\n\nSpring Boot整合JUnit以后：\n\n- 编写测试方法：`@Test`标注（注意需要使用JUnit5版本的注解）\n- JUnit类具有Spring的功能，`@Autowired`、比如 `@Transactional` 标注测试方法，测试完成后自动回滚\n\nJUnit 5 的 Maven 依赖：\n\n``` xml\n<dependency>\n    <groupId>org.junit.jupiter</groupId>\n    <artifactId>junit-jupiter-api</artifactId>\n    <version>5.3.2</version>\n    <scope>test</scope>\n</dependency>\n```\n\n### JUnit5 常用注解\n\nJUnit5的注解与JUnit4的注解有所变化：https://junit.org/junit5/docs/current/user-guide/#writing-tests-annotations\n\n- **@Test** 表示方法是测试方法。但是与JUnit4的`@Test`不同，他的职责非常单一不能声明任何属性，拓展的测试将会由Jupiter提供额外测试\n- **@ParameterizedTest** 表示方法是参数化测试，下方会有详细介绍\n- **@RepeatedTest** 表示方法可重复执行，下方会有详细介绍\n- **@DisplayName** 为测试类或者测试方法设置展示名称\n- **@BeforeEach** 表示在每个单元测试之前执行\n- **@AfterEach** 表示在每个单元测试之后执行\n- **@BeforeAll** 表示在所有单元测试之前执行\n- **@AfterAll** 表示在所有单元测试之后执行\n- **@Tag** 表示单元测试类别，类似于JUnit4中的 **@Categories**\n- **@Disabled** 表示测试类或测试方法不执行，类似于JUnit4中的 **@Ignore**\n- **@Timeout** 表示测试方法运行如果超过了指定时间将会返回错误\n- **@ExtendWith** 为测试类或测试方法提供扩展类引用\n\n```java\nimport org.junit.jupiter.api.Test; //注意这里使用的是JUnit5里jupiter的Test注解！！\n\npublic class TestDemo {\n    @Test\n    @DisplayName(\"第一次测试\")\n    public void firstTest() {\n        System.out.println(\"hello world\");\n    }\n}\n```\n\n### 断言（Assertions）\n\n断言（Assertions）是测试方法中的核心部分，用来对测试需要满足的条件进行验证。**这些断言方法都是 org.junit.jupiter.api.Assertions 的静态方法**。\n\n断言用于**检查业务逻辑返回的数据是否合理。所有的测试运行结束以后，会有一个详细的测试报告**\n\n#### 简单断言\n\n用来对单个值进行简单的验证。如：\n\n| 方法            | 说明                                 |\n| --------------- | ------------------------------------ |\n| assertEquals    | 判断两个对象或两个原始类型是否相等   |\n| assertNotEquals | 判断两个对象或两个原始类型是否不相等 |\n| assertSame      | 判断两个对象引用是否指向同一个对象   |\n| assertNotSame   | 判断两个对象引用是否指向不同的对象   |\n| assertTrue      | 判断给定的布尔值是否为 true          |\n| assertFalse     | 判断给定的布尔值是否为 false         |\n| assertNull      | 判断给定的对象引用是否为 null        |\n| assertNotNull   | 判断给定的对象引用是否不为 null      |\n\n```java\n@Test\n@DisplayName(\"simple assertion\")\npublic void simple() {\n    assertEquals(3, 1 + 2, \"simple math\");\n    assertNotEquals(3, 1 + 1);\n\n    assertNotSame(new Object(), new Object());\n    Object obj = new Object();\n    assertSame(obj, obj);\n\n    assertFalse(1 > 2);\n    assertTrue(1 < 2);\n\n    assertNull(null);\n    assertNotNull(new Object());\n}\n```\n\n#### 数组断言\n\n通过 **assertArrayEquals()** 方法来判断两个对象或原始类型的数组是否相等\n\n```java\n@Test\n@DisplayName(\"array assertion\")\npublic void array() {\n    assertArrayEquals(new int[]{1, 2}, new int[] {1, 2});\n}\n```\n\n#### 组合断言\n\n`assertAll()` 方法接受多个 `org.junit.jupiter.api.Executable` 函数式接口的实例作为要验证的断言，可以通过 lambda 表达式很容易的提供这些断言\n\n```java\n@Test\n@DisplayName(\"assert all\")\npublic void all() {\n    assertAll(\"Math\",\n              () -> assertEquals(2, 1 + 1),\n              () -> assertTrue(1 > 0)\n             );\n}\n```\n\n#### 异常断言\n\n在JUnit4时期，想要测试方法的异常情况时，需要用 **@Rule** 注解的`ExpectedException`变量，还是比较麻烦的。而JUnit5提供了一种新的断言方式 **Assertions.assertThrows()** ，配合函数式编程就可以进行使用。\n\n```java\n@Test\n@DisplayName(\"异常测试\")\npublic void exceptionTest() {\n    ArithmeticException exception = Assertions.assertThrows(\n        //扔出断言异常\n        ArithmeticException.class, () -> System.out.println(1 % 0));\n}\n```\n\n#### 超时断言\n\nJUnit5还提供了 **Assertions.assertTimeout()** 为测试方法设置了超时时间\n\n```java\n@Test\n@DisplayName(\"超时测试\")\npublic void timeoutTest() {\n    //如果测试方法时间超过1s将会异常\n    Assertions.assertTimeout(Duration.ofMillis(1000), () -> Thread.sleep(500));\n}\n```\n\n#### 快速失败\n\n通过 **fail()** 方法直接使得测试失败\n\n```java\n@Test\n@DisplayName(\"fail\")\npublic void shouldFail() {\n    fail(\"This should fail\");\n}\n```\n\n### 前置条件（Assumptions）\n\nJUnit 5 中的前置条件（**Assumptions【假设】**）类似于断言，不同之处在于**不满足的断言会使得测试方法失败**，而不满足的**前置条件只会使得测试方法的执行终止**。前置条件可以看成是测试方法执行的前提，当该前提不满足时，就没有继续执行的必要。\n\n```java\n@DisplayName(\"前置条件\")\npublic class AssumptionsTest {\n    private final String environment = \"DEV\";\n\n    @Test\n    @DisplayName(\"simple\")\n    public void simpleAssume() {\n        assumeTrue(Objects.equals(this.environment, \"DEV\"));\n        assumeFalse(() -> Objects.equals(this.environment, \"PROD\"));\n    }\n\n    @Test\n    @DisplayName(\"assume then do\")\n    public void assumeThenDo() {\n        assumingThat(\n            Objects.equals(this.environment, \"DEV\"),\n            () -> System.out.println(\"In DEV\")\n        );\n    }\n}\n```\n\n**assumeTrue()** 和 **assumFalse() **确保给定的条件为 true 或 false，不满足条件会使得测试**执行终止（不会失败）**。\n\n **assumingThat()** 的参数是表示条件的布尔值和对应的 `Executable` 接口的实现对象。只有条件满足时，`Executable` 对象才会被执行；当条件不满足时，测试执行并不会终止。\n\n### 嵌套测试\n\nJUnit 5 可以通过 Java 中的内部类和 **@Nested** 注解实现嵌套测试，从而可以更好的把相关的测试方法组织在一起。在内部类中可以使用 **@BeforeEach** 和 **@AfterEach** 注解，而且嵌套的层次没有限制。\n\n```java\n@DisplayName(\"A stack\")\nclass TestingAStackDemo {\n\n    Stack<Object> stack;\n\n    @Test\n    @DisplayName(\"is instantiated with new Stack()\")\n    void isInstantiatedWithNew() {\n        new Stack<>();\n    }\n\n    @Nested\n    @DisplayName(\"when new\")\n    class WhenNew {\n\n        @BeforeEach\n        void createNewStack() {\n            stack = new Stack<>();\n        }\n\n        @Test\n        @DisplayName(\"is empty\")\n        void isEmpty() {\n            assertTrue(stack.isEmpty());\n        }\n\n        @Test\n        @DisplayName(\"throws EmptyStackException when popped\")\n        void throwsExceptionWhenPopped() {\n            assertThrows(EmptyStackException.class, stack::pop);\n        }\n\n        @Test\n        @DisplayName(\"throws EmptyStackException when peeked\")\n        void throwsExceptionWhenPeeked() {\n            assertThrows(EmptyStackException.class, stack::peek);\n        }\n\n        @Nested\n        @DisplayName(\"after pushing an element\")\n        class AfterPushing {\n\n            String anElement = \"an element\";\n\n            @BeforeEach\n            void pushAnElement() {\n                stack.push(anElement);\n            }\n\n            @Test\n            @DisplayName(\"it is no longer empty\")\n            void isNotEmpty() {\n                assertFalse(stack.isEmpty());\n            }\n\n            @Test\n            @DisplayName(\"returns the element when popped and is empty\")\n            void returnElementWhenPopped() {\n                assertEquals(anElement, stack.pop());\n                assertTrue(stack.isEmpty());\n            }\n\n            @Test\n            @DisplayName(\"returns the element when peeked but remains not empty\")\n            void returnElementWhenPeeked() {\n                assertEquals(anElement, stack.peek());\n                assertFalse(stack.isEmpty());\n            }\n        }\n    }\n}\n```\n\n### 参数化测试\n\n参数化测试是JUnit5很重要的一个新特性，它使得用不同的参数多次运行测试成为了可能，也为我们的单元测试带来许多便利。\n\n利用 **@ValueSource** 等注解，指定入参，我们将可以使用不同的参数进行多次单元测试，而不需要每新增一个参数就新增一个单元测试，省去了很多冗余代码。\n\n- **@ValueSource**: 为参数化测试指定入参来源，支持八大基础类以及String类型,Class类型\n- **@NullSource**: 表示为参数化测试提供一个null的入参\n- **@EnumSource**: 表示为参数化测试提供一个枚举入参\n- **@CsvFileSource**：表示读取指定CSV文件内容作为参数化测试入参\n- **@MethodSource**：表示读取指定方法的返回值作为参数化测试入参(注意方法返回需要是一个流)\n\n当然如果参数化测试仅仅只能做到指定普通的入参还达不到让我觉得惊艳的地步。他的强大之处的地方在于他可以支持外部的各类入参。如:CSV，YML，JSON 文件甚至方法的返回值也可以作为入参。只需要去实现**ArgumentsProvider**接口，任何外部文件都可以作为它的入参。\n\n```java\n@ParameterizedTest\n@ValueSource(strings = {\"one\", \"two\", \"three\"})\n@DisplayName(\"参数化测试1\")\npublic void parameterizedTest1(String string) {\n    System.out.println(string);\n    Assertions.assertTrue(StringUtils.isNotBlank(string));\n}\n\n@ParameterizedTest\n@MethodSource(\"method\")    //指定方法名\n@DisplayName(\"方法来源参数\")\npublic void testWithExplicitLocalMethodSource(String name) {\n    System.out.println(name);\n    Assertions.assertNotNull(name);\n}\n\nstatic Stream<String> method() {\n    return Stream.of(\"apple\", \"banana\");\n}\n```\n\n### 迁移指南\n\n在进行迁移的时候需要注意如下变化：\n\n- 注解在 `org.junit.jupiter.api` 包中，断言在 `org.junit.jupiter.api.Assertions` 类中，前置条件在 `org.junit.jupiter.api.Assumptions` 类中。\n- 把 **@Before** 和 **@After** 替换成 **@BeforeEach** 和 **@AfterEach**。\n- 把 **@BeforeClass** 和 **@AfterClass** 替换成 **@BeforeAll** 和 **@AfterAll**。\n- 把 **@Ignore** 替换成 **@Disabled**。\n- 把 **@Category** 替换成 **@Tag**。\n- 把 **@RunWith**、**@Rule** 和 **@ClassRule** 替换成 **@ExtendWith**。\n\n","tags":["Spring","Spring Boot"],"categories":["Spring","Spring Boot"]},{"title":"【Memo】常见问题汇总","url":"/2021/06/28/【Memo】常见问题汇总/","content":"\n## IDEA设置\n\n### 项目字符编码设置\n\n新建项目后，首先设置项目的字符编码为UTF-8：\n\n![image-20210809212949065](/images/%E3%80%90Memo%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/image-20210809212949065.png)\n\n### 设置 Tab 为四个空格\n\n> https://www.cnblogs.com/pcheng/p/12567734.html\n\n阿里巴巴 Java 规范手册规定，使用空格而不是 Tab，原因：\n\n- 在不同的编辑器里Tab的长度可能会不一致。这会导致有Tab的代码，用不同的编辑器打开时，格式可能会乱。\n- 代码压缩时，空格会有更好的压缩率。这里面是信息量的问题，使用了Tab的代码，仍然会有空格，比如代码注释、运算符之间的间隔等等，但使用了空格的代码，是可以没有Tab的。Tab也是一个字符，这就决定了，用Tab的代码虽然不压缩的时候更小，但熵更高，因此压缩率会较差，压缩之后反而更大。\n\n![image-20211114185155293](/images/%E3%80%90Memo%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/image-20211114185155293.png)\n\n### 开启支持注解\n\n![image-20210809213138786](/images/%E3%80%90Memo%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/image-20210809213138786.png)\n\n### 设置Java版本\n\n![image-20210809213305683](/images/%E3%80%90Memo%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/image-20210809213305683.png)\n\n### 将项目的构建和运行操作交给Maven\n\n在不勾选的情况下对项目的构建和运行是 intelliJ idea 去做的，就可能导致构建和运行时无法找到maven仓库中的相关jar包，勾选后在对项目进行构建和运行等操作直接交给了maven。\n\n![image-20210810155531212](/images/%E3%80%90Memo%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/image-20210810155531212.png)\n\n\n\n\n\n## 配置文件\n\n> https://blog.csdn.net/CoderBruis/article/details/80721841\n\nIDEA 的`properties`文件中默认是不会将中文转为ASCII码的。只需要在`File->Settings->File Encodings`里面设置编码的自动转变即可，如图操作：\n\n![img](/images/%E3%80%90Memo%E3%80%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/20180617233755855)","tags":["Memo"],"categories":["Memo"]},{"title":"【Spring】Spring5 AOP 源码分析","url":"/2021/06/28/【Spring】Spring5-AOP源码分析/","content":"\n## AOP原理\n\n本质原理：为每个需要被增强的组件（带有切入点的组件）创建一个代理对象，在需要执行切入点方法时，调用代理对象的相应方法，并在其中按顺序切入通知方法。\n\nAOP使用 **@EnableAspectJAutoProxy**注解通过`@Import`的方式向容器中添加一个**AnnotationAwareAspectJAutoProxyCreator**组件，该组件本质上是一个**后置处理器**，它会随着其他后置处理器一起注册到容器中（在普通bean注册之前）。在普通bean**实例化前**（此时还未实例化，普通的后置处理器在组件调用构造器之后执行），调用该组件的`applyBeanPostProcessorsBeforeInstantiation()`方法把带有Aspect相关的切面类添加到增强器集合中，在bean实例化后（此时才会执行普通的后置处理器内的方法），再调用`applyBeanPostProcessorsAfterInstantiation()`方法为带有切入点的组件（待增强的组件）创建一个**代理对象**（其内含有相应的增强器）。之后在执行该组件**代理对象**的切入点方法时，则使用**CglibAopProxy.intercept()**拦截该方法的执行，并在其中获取满足当前方法的所有**拦截器链**（由增强器包装而成），使用拦截器链的链式机制按顺序执行通知方法与业务代码。\n\nAOP中两个非常重要的组件：**后置处理器**和**拦截器（增强器）**：\n\n- **后置处理器**：拦截组件的创建，为其创建**代理对象**\n- **拦截器（增强器）**：在代理对象执行目标方法时进行拦截，**切入相应的通知方法**\n\n## AOP简易执行流程\n\n注册阶段：\n\n- 配置类开启 ==**@EnableAspectJAutoProxy**== 注解。\n- `@EnableAspectJAutoProxy`注解会注册 ==**AnnotationAwareAspectJAutoProxyCreator**== 组件（通过`@Import(AspectJAutoProxyRegistrar.class)`的方式）。 **AnnotationAwareAspectJAutoProxyCreator**本质上是一个后置处理器（实现了相应接口）\n- 容器刷新（ **refresh()** 方法栈中）：\n  -  ==**registerBeanPostProcessors()**==：创建并注册所有的后置处理器，此时创建了`AnnotationAwareAspectJAutoProxyCreator`组件，在创建时会执行**invokeAwareMethods()**方法，回调地执行其实现的`setBeanFactory()`方法以获取容器中的**BeanFactory**并创建**BeanFactoryAspectJAdvisorsBuilderAdapter**对象。\n  -  ==**finishBeanFactoryInitialization()**==：创建并注册其他**普通单实例组件**（非后置处理器）。`AnnotationAwareAspectJAutoProxyCreator`会**拦截每个组件的创建**。Before（在组件**调用构造器实例化前**调用：若拦截到的组件是切面类，则加入到增强器（advisor）集合中（之后被包装为拦截器）；After（在组件实例化完毕后调用，此时其他普通后置处理器已经完成了相应操作）：若拦截到的组件**需要被增强**（满足切入点表达式的条件），则为该组件创建一个**代理对象**（其内含有相应的增强器），之后执行业务组件的被增强的方法时就会执行该代理对象的相应方法。\n\n执行阶段：\n\n- **代理对象**准备执行**目标方法**（带有切入点的目标方法）时， ==**CglibAopProxy.intercept()**== 会进行拦截，加入增强的通知方法：\n  - 先遍历找到**有效（符合目标方法）**的**拦截器链chain**（之前的增强器包装成拦截器）\n  - 利用**拦截器的链式机制**依次进入每一个拦截器进行执行（每个拦截器都会执行相应的通知方法）\n  - 通过不断回调`CglibMethodInvocation.proceed()`方法**链式地**调用下一个拦截器\n  - 执行效果：前置通知 -> 目标方法 -> 正常返回通知或异常返回通知   -> 后置通知 \n- **代理对象**执行**普通方法**（不带有切入点的目标方法）时， ==**CglibAopProxy.intercept()**== 进行拦截后，因找不到该方法匹配的增强器（因为普通方法没有被切入增强），则直接执行代理对象的普通方法。\n- 没有被增强的普通对象不被拦截。\n\n\n\n<!-- More -->\n\n## @EnableAspectJAutoProxy\n\n要开启AOP自动代理，配置类中需要**添加@EnableAspectJAutoProxy。整个AOP就是从@EnableAspectJAutoProxy注解开始执行的。**\n\n``` java\n@EnableAspectJAutoProxy\n@Configuration\npublic class SpringConfigAOP {\n    // 将业务逻辑类加入到容器中\n    @Bean\n    public MathCalculator calculator(){\n        return new MathCalculator();\n    }\n\n    // 切面类加入到容器中\n    @Bean\n    public LogsAspects logsAspects(){\n        return new LogsAspects();\n    }\n}\n```\n\n`@EnableAspectJAutoProxy`注解：\n\n![image-20210630165506770](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630165506770.png)\n\n## @Import(AspectJAutoProxyRegistrar.class)\n\n`@Import(AspectJAutoProxyRegistrar.class)`表明`@EnableAspectJAutoProxy`注解会向容器中注册**AspectJAutoProxyRegistrar**类。\n\n`AspectJAutoProxyRegistrar`类实现了`ImportBeanDefinitionRegistrar`接口的`registerBeanDefinitions()`方法：\n\n![image-20210630190714343](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630190714343.png)\n\n该方法使用`BeanDefinitionRegistry`类的对象`registry`给容器中**注册**了一个id名称为`internalAutoProxyCreator`的`AnnotationAwareAspectJAutoProxyCreator`组件（注解装配模式的AspectJ自动代理创建器）。注册定义部分的代码：\n\n![image-20210630192408003](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630192408003.png)\n\n**总结**：`@EnableAspectJAutoProxy`注解会向容器中注册了一个`AspectJAutoProxyRegistrar`组件，该组件会向容器中注册一个**AnnotationAwareAspectJAutoProxyCreator**组件，即创建了一个自动代理创建器。**AOP的思想都是通过该组件实现**。\n\n## AnnotationAwareAspectJAutoProxyCreator\n\n`AnnotationAwareAspectJAutoProxyCreator`类实现了两个接口：\n\n- **SmartInstantiationAwareBeanPostProcessor**接口：一种特殊的后置处理器，在每个普通组件**创建前后**（不同于普通后置处理器是在组件创建完成、**初始化前后**）拦截并将该组件的**代理对象注册到容器中**，后续执行该组件的切入点方法时将调用代理对象的相应方法以切入通知方法。它实现的接口方法为postProcessBefore**Instantiation**()，有区别于其他BeanPostProcessor里的postProcessBefore**Initialization**()\n- **BeanFactoryAware**接口：在`AnnotationAwareAspectJAutoProxyCreator`组件被注册到容器中时（每个组件在创建时首先会执行`invokeAwareMethods()`方法，此时会回调`BeanFactoryAware`的接口方法），获取到容器中的组件创建工厂`BeanFactory`，并创建`BeanFactoryAspectJAdvisorsBuilderAdapter`（组件工厂通知构建器的适配器）对象**用于后续为组件创建代理对象**。\n\n![image-20210630193143177](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630193143177.png)\n\n因此需要关心其实现的两个接口方法各有什么功能。\n\n### BeanFactoryAware接口的作用\n\n**作用：获取组件创建工厂BeanFactory**\n\n`AnnotationAwareAspectJAutoProxyCreator`的父类`AspectJAwareAdvisorAutoProxyCreator`（上图红色框所示）重写了`BeanFactoryAware`接口的**setBeanFactory()方法**（`AnnotationAwareAspectJAutoProxyCreator`类本身并没有重写该方法），该方法内调用了**initBeanFactory()方法**（被`AnnotationAwareAspectJAutoProxyCreator`类重写）。\n\n在`AnnotationAwareAspectJAutoProxyCreator`组件被注册到容器中时，容器会执行**invokeAwareMethods()方法**，这是`Aware`接口的回调方法。因为`AnnotationAwareAspectJAutoProxyCreator`实现了`Aware`接口的`setBeanFactory`()方法，因此此时会执行其重写的`setBeanFactory()`方法**获取bean创建工厂BeanFactory**，并创建`BeanFactoryAspectJAdvisorsBuilderAdapter`（组件工厂通知构建器的适配器）对象**用于后续为组件创建代理对象**。\n\n![image-20210704161324229](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704161324229.png)\n\n![image-20210630220411754](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630220411754.png)\n\n### SmartInstantiationAwareBeanPostProcessor接口的作用\n\n**作用：在每个普通组件创建前后进行拦截，并将满足切入点表达式的组件包装后的代理对象注册到容器中**\n\n`SmartInstantiationAwareBeanPostProcessor`接口的postProcessBefore**Instantiation**()方法不同于其他`BeanPostProcessor`里的postProcessBefore**Initialization**()。\n\n`AnnotationAwareAspectJAutoProxyCreator`实现了`SmartInstantiationAwareBeanPostProcessor`接口，会使得其在所有的普通单实例bean**创建前后**能够进行拦截，调用`postProcessBeforeInstantiation()`方法注册每个增强器（切面类），调用`postProcessorsAfterInitialization()`方法将满足切入点表达式的组件包装后的代理对象注册到容器中。**postProcessAfterInitialization()方法中调用wrapIfNecessary()为满足切入点表达式条件的组件包装出代理对象**。\n\n![image-20210703131501253](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703131501253.png)\n\n\n## AOP详细执行流程\n\n### 1. 传入配置类，创建IoC容器\n\n![image-20210630203107349](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630203107349.png)\n\n### 2. refresh()：后续流程均在该方法内执行\n\n==补充IOC容器过程：注册配置类==，调用refresh()方法刷新容器\n\n![image-20210630203127243](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630203127243.png)\n\n### 3. registerBeanPostProcessors()：创建并注册所有后置处理器\n\n在**refresh()方法内**执行`registerBeanPostProcessors()`**创建**并**注册**所有**已定义**的后置处理器，以在后续拦截普通bean的初始化。（步骤3和4中分析均为该方法内的执行逻辑）\n\n![image-20210630203203476](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630203203476.png)\n\n#### 3.1 创建后置处理器实例化对象（只创建，还未注册）\n\n3.1.1 在`registerBeanPostProcessors`()方法内：先获取IoC容器中所有已经定义了的需要实例化的`BeanPostProcessor`组件（此时还没创建对象实例）\n\n![image-20210630203357418](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630203357418.png)\n\n![image-20210630202829082](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630202829082.png)\n\n此时的**org.springframework.aop.config.internalAutoProxyCreator**正是之前在`@Import(AspectJAutoProxyRegistrar.class)`)中使用`BeanDefinitionRegistry`类给容器中添加**定义**的id名称为`internalAutoProxyCreator`的组件。（即之前`BeanDefinitionRegistry`内**定义了**该后置处理器实现类，**但还未创建实例化对象**，步骤3.5处才创建了该组件）\n\n![image-20210630192408003](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630192408003.png)\n\n3.1.2 给容器添加其他`BeanPostProcessor`\n\n![image-20210630204433781](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630204433781.png)\n\n3.1.3 遍历3.1.1中取出的所有`BeanPostProcessor`，并根据其是否实现了`Ordered`接口进行分类\n\n![image-20210630213254910](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630213254910.png)\n\n3.1.4 优先创建实现了`PriorityOrdered`接口的`BeanPostProcessor`\n\n![image-20210630204659073](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630204659073.png)\n\n3.1.5 再创建实现了`Ordered`接口的`BeanPostProcessor`（以下分析均为3.5断点方法`getBean()`中**创建**`AnnotationAwareAspectJAutoProxyCreator`对象的过程）\n\n**AnnotationAwareAspectJAutoProxyCreator类实现了Ordered接口，因此在这一步被创建（创建后再进行注册）**\n\n![image-20210630204914536](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630204914536.png)\n\n以下分析如何**创建**id为`internalAutoProxyCreator`的**AnnotationAwareAspectJAutoProxyCreator**对象【本质为`BeanPostProcessor`对象 】？（注意，此步骤仅创建该对象，还未向容器中注册）\n\n1. 创建bean实例\n2. 调用`populateBean(beanName, mbd, instanceWrapper)` 为bean属性赋值\n3. 调用`initializeBean(beanName, exposedObject, mbd) `为bean初始化\n\n![image-20210629163559536](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210629163559536.png)\n\n`initializeBean()`方法内部依次执行：\n\n- `invokeAwareMethods()`方法（绿色框）：处理Aware接口的回调方法\n- `applyBeanPostProcessorsBeforeInitialization()`方法（红色框）：调用后置处理器\n- `invokeInitMethods()`方法完成**初始化**（黄色框）：执行自定义的初始化方法\n- `applyBeanPostProcessorsAfterInitialization()`方法（红色框）：调用后置处理器\n\n![image-20210630214340913](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630214340913.png)\n\n调用`invokeAwareMethods(beanName, bean)`作用：执行`Aware`接口的回调方法。因为`AnnotationAwareAspectJAutoProxyCreator`类实现了**BeanFactoryAware**接口，因此在这里，执行了该组件的`setBeanFactory()`方法，用于获取bean创建工厂`BeanFactory`。\n\n![image-20210630213635404](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630213635404.png)\n\n4. 此时即调用了`AnnotationAwareAspectJAutoProxyCreator`类父类的`setBeanFactory()`方法（下图红色框），获取了bean创建工厂`BeanFactory`。\n\n![image-20210630220411754](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630220411754.png)\n\n5. 接着执行`this.initBeanFactory((ConfigurableListableBeanFactory)beanFactory);`（上图黄色框）创建了`ReflectiveAspectJAdvisorFactory`（反射的AspectJ增强器工厂）对象和并将其包装成`BeanFactoryAspectJAdvisorsBuilderAdapter`（组件工厂通知构建器的适配器）对象**用于后续为组件创建代理对象**。\n\n![image-20210704164952614](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704164952614.png)\n\n3.1.6 最后再创建和注册没实现优先级接口的`BeanPostProcessor`\n\n![image-20210630204929418](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630204929418.png)\n\n**总结**：经过上述**创建初始化等操作**，此时3.5中getBean()方法执行完毕，获得了每个`BeanPostProcessor`（包括`AnnotationAwareAspectJAutoProxyCreator`）的实例化对象。\n\n3.1步骤仅为 ==**创建后置处理器的过程，此时的后置处理器还未注册到容器中**==。\n\n#### 3.2 创建后的后置处理器注册到BeanFactory中\n\n在创建出`AnnotationAwareAspectJAutoProxyCreator`的实例化对象后执行`registerBeanPostProcessors()`方法将`AnnotationAwareAspectJAutoProxyCreator`组件**注册**到`BeanFactory`中：\n\n![image-20210630204914536](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630204914536.png)\n\n![image-20210630221118378](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630221118378.png)\n\n==3.1和3.2步骤即为**创建和注册AnnotationAwareAspectJAutoProxyCreator组件的过程**。==\n\n### 4. finishBeanFactoryInitialization()：注册普通组件\n\n步骤3中已经注册了所有的`BeanPostProcessor`（黄色框），之后执行`finishBeanFactoryInitialization()`方法（红色框）注册**所有非@Lazy修饰的单实例普通组件**。\n\n![image-20210701153743299](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701153743299.png)\n\n4.1 进入`finishBeanFactoryInitialization()`方法后，首先遍历获取容器中所有的`beanNames`，并依次执行以下方法创建bean对象。方法栈调用：\n\n-  ` -> finishBeanFactoryInitialization(beanFactory)`\n-  `-> beanFactory.preInstantiateSingletons() `\n- `-> getBean(beanName) `\n- `-> doGetBean()`\n- ` -> getSingleton() `\n- `-> createBean()`\n\n![image-20210701163050223](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701163050223.png)\n\n![image-20210701163108692](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701163108692.png)\n\n![image-20210701161459941](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701161459941.png)\n\n![image-20210701161016809](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701161016809.png)\n\n![image-20210701163847923](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701163847923.png)\n\n补充：在调用`getSingleton()`创建单实例bean之前，首先从缓存中查找当前bean是否存在，如果存在，说明这个bean之前已被创建过，可以直接使用，不再需要创建；否则再执行`getSingleton()`方法创建。只要创建好的bean都会被缓存起来。从缓存中查找bean是否存在：\n\n![image-20210701162202790](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701162202790.png)\n\n经过上述方法栈，在执行`getBean(beanName)`方法后创建bean的流程：\n\n4.2 执行`getSingleton(beanName)`方法，从缓存中查找当前bean是否存在，如果存在，说明这个bean之前已被创建过，可以直接使用，不再需要创建；否则再执行`getSingleton()`方法创建。\n\n4.3 进入`createBean()` 方法体：首先执行`resolveBeforeInstantiation() `方法（红色框，指在实例化前**解析**对象） ，该方法试图在此返回一个**包装后的代理对象**：\n\n- 如果能返回代理对象（返回的`bean != null`)就使用（并且不再向下执行创建普通对象）\n- 如果不能返回代理对象（返回的`bean == null`)就向下继续执行`doCreateBean() `方法（黄色框）创建普通对象\n\n![image-20210701180818426](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701180818426.png)\n\n`resolveBeforeInstantiation() `方法体内，在实例化前先后执行**前处理**和**后处理**：\n\n![image-20210701181816332](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701181816332.png)\n\n### 5. applyBeanPostProcessorsBeforeInstantiation() 前处理：将==切面类==添加到增强器（通知方法）集合中==其他作用？==\n\n进入`applyBeanPostProcessorsBeforeInstantiation()`方法，该方法调用`getBeanPostProcessorCache()`方法判断当前容器中是否存在实现了`SmartInstantiationAwareBeanPostProcessor`接口的组件。恰好`AnnotationAwareAspectJAutoProxyCreator`类实现了该接口，因此会调用该类的`postProcessBeforeInstantiation()`方法。（若不存在，则将不再执行后续代码，直接返回null，从而转去创建普通组件）\n\n![image-20210701182427290](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701182427290.png)\n\n![image-20210701182344197](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701182344197.png)\n\n**重点**：\n\n- **BeanPostProcessor**在普通bean对象**创建完成之后，执行初始化方法前后**调用\n- **InstantiationAwareBeanPostProcessor**在普通bean实例**创建之前先进行拦截调用**，尝试使用后置处理器将bean包装成代理对象 \n\n`AnnotationAwareAspectJAutoProxyCreator`实现了`InstantiationAwareBeanPostProcessor`接口，它会在任何bean实例创建之前（此时还没创建对象，也就还没执行普通`BeanPostProcessor`的处理器）先尝试执行`postProcessBeforeInstantiation()`返回对象的。\n\n5.1若`resolveBeforeInstantiation() `方法无法返回代理对象（意味着容器中没有`AnnotationAwareAspectJAutoProxyCreator`组件，即不需要开启AOP，也自然不需要返回代理对象），则程序继续向下执行`doCreateBean() `方法。此时才真正地去创建一个普通单实例bean实例，**该过程和3.5中流程一样**。\n\n![image-20210701171303958](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701171303958.png)\n\n5.2 若存在`AnnotationAwareAspectJAutoProxyCreator`组件，则将执行`postProcessBeforeInstantiation()`方法，该方法用于将所有切面类（带有通知方法的类）添加到增强器（通知方法）集合中。\n\n每个组件都会进入该方法，但我们只关心和AOP相关的组件：自定义的`MathCalculator`（业务逻辑类）和`LogAspect`（切面类）。\n\n![image-20210703101045896](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703101045896.png)\n\n接上文：==这一段作用？==\n\n![image-20210704191747391](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704191747391.png)\n\n5.3 黄色框：判断当前`advisedBeans.cotains(cacheKey)`（保存了所有带有通知方法的bean，又被称为**增强器**）中是否已经包含了当前bean，若包含，则直接返回。\n\n5.4 若不包含，则判断`this.isInfrastructureClass(beanClass`)，即判断当前bean：\n\n- 是否是**基础类型**的`Advice`、`Pointcut`、`Advisor`或`AopInfrastructureBean`接口的实现类。\n- 是否是**切面类型（@Aspect注解修饰的类）**\n\n若符合，说明当前bean是切面类，则执行`advisedBeans.put()`方法将其添加到`advisedBeans`中（包含所有增强器），并向上层返回null。\n\n5.5 判断`this.shouldSkip(beanClass, beanName)`：判断是否需要跳过该bean的处理。\n\n![image-20210703104658589](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703104658589.png)\n\n![image-20210703104753304](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703104753304.png)\n\n获取候选的增强器Advisors（切面里的通知方法），以`ArrayList`方式存储【List\\<Advisor\\> candidateAdvisors】。每一个封装的通知方法增强器是`InstantiationModelAwarePointcutAdvisor`类型，判断每一个增强器是否是`AspectJPointcutAdvisor`类型：若是，返回true；否则继续循环判断其他增强器，若都不是，返回false。\n\n5.6 自定义的`MathCalculator`类经过5.4和5.5的判断均返回`false`，而`LogAspect`切面类因为被`@Aspect`注解修饰，所以会返回`true`，因此被添加到`advisedBeans`中\n\n**总结**：`AnnotationAwareAspectJAutoProxyCreator`类的`postProcessBeforeInstantiation()`方法在组件实例化前调用，目的是**将每个自定义的切面类添加到增强器集合中**。==其他目的？==\n\n==Before里不是特别确定==\n\n### 6. 经过前处理postProcessBeforeInstantiation()后，new一个==MathCalculator对象==\n\n### 7. postProcesAfterInstantiation() 后处理：向容器中注册满足切入点表达式条件的代理对象\n\n![image-20210703131501253](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703131501253.png)\n\n7.1 调用`this.wrapIfNecessary(bean, beanName, cacheKey)`方法：如果需要的话进行**包装**。进入该方法后，调用`this.getAdvicesAndAdvisorsForBean()`以获取**能切入到当前bean的增强器（通知方法）**。将这些增强器存储为`Object[] specificInterceptors`拦截器数组。\n\n![image-20210704200120914](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704200120914.png)\n\n![image-20210703132909220](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703132909220.png)\n\n该方法将遍历所有**候选**的增强器（通知方法），再找到能在当前bean使用的增强器（eligible，有资格的增强器），**即找到哪些通知方法是需要切入到当前bean方法的。**最后给有资格的增强器**排序**（排序是为了后续做切入时按照Before，After，AfterReturning等顺序执行）。\n\n7.2 `this.getAdvicesAndAdvisorsForBean()`方法执行完成后获得了`Object[] specificInterceptors`，里面存有能切入到当前bean的所有增强器（通知方法）。如果当前`specificInterceptors`不为null，则说明当前bean有被增强，那么将当前bean保存到`this.advisedBeans`当中。\n\n7.3 如果当前bean需要被增强，则执行`this.createProxy()`为其创建代理对象：\n\n![image-20210703153159704](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703153159704.png)\n\n接上段：\n\n![image-20210703154315455](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703154315455.png)\n\n该方法内执行流程：\n\n- 创建代理工厂`ProxyFactory`\n- 获取所有增强器（增强方法）并保存到`ProxyFactory`中\n- 使用代理工厂创建代理对象`proxyFactory.getProxy(classLoader)`，其中代理对象有两种，其由Spring自动决定：\n  - `JdkDynamicAopProxy(config)`：jdk动态代理\n  - `ObjenesisCglibAopProxy(config)`：cglib动态代理\n\n在`proxyFactory.getProxy(classLoader)`方法内执行了以下方法返回动态代理对象：\n\n![image-20210703153617812](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703153617812.png)\n\n**总结**：至此`postProcesAfterInstantiation()`方法中的`this.wrapIfNecessary()`方法执行完毕，其为容器中返回当前组件使用cglib增强了的代理对象（若实现了JDK接口，则返回JDK动态代理对象）。之后从容器中获取到的就是**这个组件的代理对象**，执行目标方法的时候，该代理对象就会额外执行通知方法的流程（除原本的业务代码外）。\n\n该代理对象保存了许多详细信息（比如增强器、目标对象等），之后执行代理对象的方法时就会把通知方法一起执行：\n\n![image-20210703163430269](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703163430269.png)\n\n### 8. CglibAopProxy.intercept()：拦截代理对象目标方法的执行\n\n代理对象被注册到容器中后，当执行该bean**被增强的方法**时，AOP代理会执行CglibAopProxy.intercept()方法拦截目标方法的执行：\n\n![image-20210703163932927](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703163932927.png)\n\n8.1 **获取拦截器链**：该方法中执行`ProxyFactory`对象的`getInterceptorsAndDynamicInterceptionAdvice()`方法获取将要执行的**目标方法**的**拦截器链**（拦截器集合，拦截器是由增强器包装后得到的，用于拦截每个目标方法的执行）。具体获得拦截器链的代码——进入该方法：\n\n![image-20210703164925461](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703164925461.png)\n\n![image-20210703191531684](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703191531684.png)\n\n![image-20210703193456012](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703193456012.png)\n\n接上段：\n\n![image-20210703191904882](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703191904882.png)\n\n- 从配置类中获取所有的增强器（一个默认的增强器和其余自定义的增强器）\n- 创建List\\<Object\\> interceptorList 保存拦截器，长度为所有增强器的数量，包含一个默认的`ExposeInvocationInterceptor`拦截器\n- 遍历所有的增强器，将其转为拦截器：`interceptors = registry.getInterceptors(advisor)`\n\n将增强器转为List\\<MethodInterceptor\\>的方式：\n\n- 如果传入的增强器advisor是`MethodInterceptor`，直接加入到集合中\n- 如果不是，则使用适配器`AdvisorAdapter`将增强器转为`MethodInterceptor`\n- 转换完成，返回每个增强器对应的拦截器`MethodInterceptor`\n\n![image-20210703192130240](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703192130240.png)\n\n`AdvisorAdapter`将增强器转为`MethodInterceptor`举例：\n\n![image-20210703192455597](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703192455597.png)\n\n**总结**：经过上述方法栈后，将每个增强器（通知方法）包装成了一个拦截器，返回了一个**拦截器链**（拦截器集合）：\n\n![image-20210703193611280](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703193611280.png)\n\n8.2 得到拦截器链后，判断：\n\n- 如果没有拦截器链（说明**当前目标方法**没有被增强），直接执行目标方法\n- 如果有拦截器链（说明目标方法有被增强），把需要执行的目标对象、目标方法、拦截器链等所有信息传入一个**CglibMethodInvocation**对象，并调用其**proceed()方法**，从而执行带有**通知方法**的业务代码。\n\n接上文获取拦截器链`chain`的代码：\n\n![image-20210703164633170](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703164633170.png)\n\n### 9. CglibMethodInvocation().proceed()方法解析：\n\n进入`CglibMethodInvocation().proceed()`方法后：\n\n- 获取第一个拦截器；\n- 该拦截器执行`invoke`方法（将当前`CglibMethodInvocation`对象传入），该方法会再次地调用`CglibMethodInvocation.proceed()`方法；\n- `currentInterceptorIndex`记录当前拦截器的索引：从-1开始递增，每次执行`procced()`，索引自增一次，即再获取下一个拦截器；\n- 获取第二个拦截器后再次执行`invoke`方法，再次获取第三个拦截器；\n- 重复上述操作，直至获取到最后一个拦截器，执行完其通知方法（此时是第一次调用通知方法，其他拦截器的通知方法还未调用）；\n- 执行完通知方法的拦截器将弹出方法栈，执行后续通知方法；\n\n使用这种**拦截器链**的机制，按顺序调用其余的通知方法和目标方法。\n\n下面按照执行顺序分析流程，假设当前bean对象共有四个自定义的拦截器（`@Before`、`@After`、`@AfterReturnig`、`@AfterThrowing`）和一个默认的拦截器（`ExposeInvocationInterceptor`）：\n\n9.1 首次调用`procced()`方法，当前索引`this.currentInterceptorIndex`为-1，自加1后为0。\n\n![image-20210703224011722](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703224011722.png)\n\n`this.interceptorsAndDynamicMethodMatchers`中按顺序存储了所有拦截器（一个默认和四个自定义）：\n\n![image-20210704115329357](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704115329357.png)\n\n首先取出第一个拦截器，调用其`invoke`方法，将**CglibMethodInvocation**对象作为参数传入：\n\n![image-20210703234254881](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703234254881.png)\n\n调用第一个默认的拦截器：`ExposeInvocationInterceptor`的`invoke`方法，在红色框中调用了`CglibMethodInvocation.proceed()`方法，从而获取了下一个拦截器@**Before**（此时`finally`代码块中的代码，还未执行，需要等到其余的方法栈全部执行完毕后最后执行）。\n\n9.2 ==@Before==：10.1中调用`procced()`获取到第二个拦截器**MethodBeforeAdviceInterceptor**：该拦截器首先执行`advice.before()`，即自定义的**Before**通知方法，再调用`CglibMethodInvocation.proceed()`方法获取下一个拦截器@**After**。注意此时Before通知已经执行。\n\n![image-20210704102922612](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704102922612.png)\n\n9.3 ==@After==：获取到的下一个拦截器是**AspectJAfterAdvice**，该拦截器内将`procced()`方法包装在`try`代码块内。`finally`内的代码块为**After后置通知方法**，此时暂不调用，等待`try`内的`mi.procced()`方法栈执行完再调用。（因为`@After`的执行顺序在`@AfterReturning`和`@AfterThrowing`之后，所以需要等到他们执行完后再调用）执行`mi.procced()`方法获取下一个拦截器@**AfterReturing**。\n\n![image-20210704114113510](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704114113510.png)\n\n9.4 ==@AfterReturning==：进入`mi.procced()`方法内获取了下一个拦截器**AfterReturningAdviceInterceptor**。该拦截器的`invoke`方法内再次调用`mi.procced()`方法获取下一个拦截器**AfterThrowing**。注意此处的代码并没有被`try catch`包裹，意味着后续方法栈出现异常此处无法继续向下正常执行`advice.afterReturning()`通知。\n\n![image-20210704114640043](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704114640043.png)\n\n9.5 ==@AfterThrowing==：进入`mi.procced()`方法内获取了下一个拦截器**AspectJAfterThrowing**。此时再执行`procced()`方法时，因为该组件对应的拦截器**已经全部遍历完**，因此`this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1`判断成立，此时将执行目标对象的**业务代码**。\n\n![image-20210704120009098](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704120009098.png)\n\n同时`procced()`方法包裹在try代码块中，若业务代码中出现异常，则将被后面的`catch`捕获，并执行`invokeAdviceMethod()`将`@AfterThrowing`通知方法执行，**同时抛出了一个异常ex，返回给上一层的@AfterReturing**。上一层的`@AfterReturing`中并没有添加`try catch`代码块，因此若业务代码出现了异常，则将该异常抛给`@AfterReturing`后其无法继续执行后续的**AfterReturing**代码，反而将该异常继续向上抛给`@After`（`@After`内有`try`，可以捕获）。**也就说明@AfterReturing的通知不能在出现异常时执行，@AfterThrowing的通知不能在不出现异常时执行（因为异常通知方法在catch中，只有业务代码出现异常才能执行）**\n\n此时已经遍历完了所有的目标对象，执行目标对象的业务代码：\n\n![image-20210704120832349](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704120832349.png)\n\n执行完业务代码后，当前已经执行了`@Before`前置通知方法、目标对象业务代码，其余的通知方法还未执行。后续的执行顺序：\n\n- 如果业务代码内没有出现异常，则`catch`内的`@AfterThrowing`的通知不会执行，方法栈向上一层返回，返回到`@AfterReturing`，执行其`@AfterReturing`通知方法，执行后再返回到`@After`层执行`@After`通知方法。（此时都没有异常）\n- 如果业务代码内出现异常，则执行`catch`内的`@AfterThrowing`的通知，同时抛出异常`ex`，返回给上一层的`@AfterReturing`，而该层并没有`try catch`，因此不会执行`@AfterReturing`的通知，将此异常继续向上层抛出到`@After`层\n\n9.6 之后回到==@After层==，此处有`try`保证异常不会继续向上抛出，同时不论是否有异常抛出，都会执行`invokeAdviceMethod()`方法执行`@After`后置通知。因此**说明@After通知不论是够有异常，都会在最后执行**\n\n![image-20210704114113510](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704114113510.png)\n\n`@After`通知方法执行完后继续弹栈，此时所有的通知方法都执行完毕，顺序依次为：\n\n- 前置通知（`@Before`）\n- 业务代码\n- 返回通知（`@AfterReturning`）/ 若有异常，此时执行异常通知（`@AfterThrowing`）\n- 后置通知（`@After`）\n\n```\n容器创建完成....\n\n切入点div运行@Before .... 参数列表：{[1, 1]}\ndiv方法执行...\n切入点正常返回@AfterReturning....运行结果：{1}\n切入点结束@After....\n\nProcess finished with exit code 0\n```\n\n补充：Spring4源码中拦截器调用的顺序与Spring5不同，是相反的顺序，但执行效果仍然相同：\n\n![image-20210704122728211](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704122728211.png)\n\n总体思想是链式地执行每个拦截器的`invoke()`方法，在合适的位置执行通知方法，并回调`CglibMethodInvocation.procced()`方法实现链式执行，直到所有的拦截器均执行完毕。\n\n\n\n## AOP原理总结\n\n### 注册阶段\n\n1、配置类开启 ==@**EnableAspectJAutoProxy**== 注解。\n\n2、`@EnableAspectJAutoProxy`注解会注册 ==**AnnotationAwareAspectJAutoProxyCreator**== 组件（通过`@Import(AspectJAutoProxyRegistrar.class)`的方式）。 **AnnotationAwareAspectJAutoProxyCreator**本质上是一个后置处理器（实现了相应接口）\n\n3、容器刷新（ **refresh()** 方法栈中）：\n\n![image-20210630203127243](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210630203127243.png)\n\n![image-20210704212659373](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704212659373.png)\n\n3.1、 ==**registerBeanPostProcessors()**==：创建并注册所有的后置处理器，此时创建了`AnnotationAwareAspectJAutoProxyCreator`组件，在创建时会执行**invokeAwareMethods()**方法，回调地执行其实现的`setBeanFactory()`方法以获取容器中的**BeanFactory**并创建**BeanFactoryAspectJAdvisorsBuilderAdapter**对象。\n\n![image-20210704212412161](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704212412161.png)\n\n3.2、 ==**finishBeanFactoryInitialization()**==：创建并注册其他**普通单实例组件**（非后置处理器）。\n\n`AnnotationAwareAspectJAutoProxyCreator`会**拦截每个组件的创建**，并判断该组件是否需要被代理：\n\n- 若需要被代理（符合切入点表达式），则执行下图红色框创建AOP代理对象，直接返回该代理对象，不再创建普通组件对象\n- 若不需要被代理，则执行下图黄色框创建普通组件对象\n\n![image-20210704212905374](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210704212905374.png)\n\n`resolveBeforeInstantiation() `方法体内，在**实例化普通组件前**先后执行**前处理**和**后处理**：\n\n![image-20210701181816332](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210701181816332.png)\n\n**Before**：若拦截到的组件是切面类，则加入到增强器（advisor）集合中（之后被包装为拦截器）；\n\n![image-20210703101045896](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703101045896.png)\n\n**After**：若拦截到的组件**需要被增强**（满足切入点表达式的条件），则为该组件创建一个**代理对象**（cglib），之后执行业务组件的被增强的方法时就会执行该代理对象的相应方法。\n\n![image-20210703131501253](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703131501253.png)\n\n3.3、若当前组件没有含有切入点表达式（说明不需要被AOP代理），则创建普通组件（下图黄色框）：\n\n![image-20210701180818426](/images/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/image-20210701180818426.png)\n\n\n\n### 执行阶段\n\n**代理对象**准备执行**目标方法**（带有切入点的目标方法）时， ==**CglibAopProxy.intercept()**== 会进行拦截，加入增强的通知方法：\n\n1、 先遍历找到**有效（符合目标方法）**的**拦截器链chain**（之前的增强器包装成拦截器）\n\n![image-20210703163932927](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703163932927.png)\n\n判断拦截器链是否为null，若为null，说明当前方法没有被增强，则直接执行目标方法：\n\n![image-20210703164633170](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703164633170.png)\n\n2、若有被增强，则利用**拦截器的链式机制**依次进入每一个拦截器进行执行（每个拦截器都会执行相应的通知方法）\n\n![image-20210703224011722](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81/image-20210703224011722.png)\n\n3、通过不断回调`CglibMethodInvocation.proceed()`方法**链式地**调用下一个拦截器\n\n4、执行效果：前置通知 -> 目标方法 -> 正常返回通知或异常返回通知   -> 后置通知 \n\n**代理对象**执行**普通方法**（不带有切入点的目标方法）时， ==**CglibAopProxy.intercept()**== 进行拦截后，因找不到该方法匹配的增强器（因为普通方法没有被切入增强），拦截器链为null，则直接执行代理对象的普通方法。\n\n没有被增强的普通对象不被拦截。\n\n","tags":["源码分析","SSM","Spring"],"categories":["源码分析","Spring","SSM"]},{"title":"【Spring】Spring5 源码中常用接口的底层原理","url":"/2021/06/28/【Spring】Spring5-源码中常用接口的底层原理/","content":"\n本文将介绍Spring源码中较为常用的几个接口的底层实现原理：\n\n- ImportBeanDefinitionRegistrar\n- BeanPostProcessor\n- BeanFactoryPostProcessor\n- BeanDefinitionRegistryPostProcessor\n- Aware\n\n## ImportBeanDefinitionRegistrar\n\n`ImportBeanDefinitionRegistrar`接口的实现类用在`@Import`注解中，**用于向IoC容器中自定义注册组件**。\n\n```java\n@Import({MyImportBeanDefinitionRegistrar.class})\npublic class SpringConfig {\n}\n```\n\n`@Import` 注解中可以传入`ImportBeanDefinitionRegistrar`接口的实现类。\n\n![image-20210628212948066](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210628212948066.png)\n\n<!-- More -->\n\n==xxx==通过调用`ImportBeanDefinitionRegistrar`接口实现类的`registerBeanDefinitions()` 方法，可以自定义地给容器中添加组件。方法参数：\n\n- `importingClassMetadata`：当前标注Import注解的类（即SpringConfig类）的所有注解信息\n- `registry`：所有bean对象都通过此对象注册，可以使用该对象给容器中注册一个bean\n\n![image-20210628213321835](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210628213321835.png)\n\n使用方法：把所有要添加到容器中的bean调用`registry.registerBeanDefinition(String beanName, BeanDefinition beanDefinition)`方法手动注册到容器中。该方法需要传入`beanName`和一个实现了**beanDefinition**接口的类的对象（通常使用其实现类**RootBeanDefinition**）\n\n![image-20210628215427638](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210628215427638.png)\n\n使用实例：\n\n![image-20210628220119176](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210628220119176.png)\n\n\n\n## BeanPostProcessor\n\n**BeanPostProcessor**：bean后置处理器。其用于在bean的**初始化前后**进行一些处理工作（此时已经调用了构造函数并使用了set方法为bean赋值）：\n\n- `postProcessBeforeInitialization()`：在初始化方法之前工作\n- `postProcessAfterInitialization()`：在初始化方法之后工作\n\n自定义后置处理器实现`BeanPostProcessor`的方法，并将其注册到容器中。之后所有的bean对象在初始化方法前后都会进入该类的方法中执行相应处理。\n\n```java\n@Component\npublic class MyBeanPostProcessor implements BeanPostProcessor {\n    @Override\n    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {\n        // bean：当前被处理的bean对象\n        System.out.println(\"====> postProcessBeforeInitialization ... \" + beanName + \": \" + bean);\n\n        // 可以对bean进行一些包装\n        return bean;\n    }\n\n    @Override\n    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n        System.out.println(\"====> postProcessAfterInitialization ... \" + beanName + \": \" + bean);\n\n        // 可以对bean进行一些包装\n        return bean;\n    }\n}\n```\n\n### BeanPostProcessor执行流程源码分析\n\n1. 容器调用bean的**构造方法**创建对象\n2. `populateBean()`：容器调用bean的set方法为bean对象的属性赋值（红色框）\n3. `initializeBean()`：容器为bean做初始化操作（黄色框）\n\n方法栈位置：`AbstractAutowireCapableBeanFactory.java`\n\n![image-20210629163559536](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210629163559536.png)\n\n\\=\\=\\=\\=\\=\\=\\> 进入黄色框的`initializeBean()`方法：\n\n- 执行`invokeAwareMethods()`方法（绿色框）\n- 执行`applyBeanPostProcessorsBeforeInitialization()`方法（红色框）\n- 执行`invokeInitMethods()`方法完成初始化（黄色框）\n- 执行`applyBeanPostProcessorsAfterInitialization()`方法（红色框）\n\n![image-20210630214340913](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210630214340913.png)\n\n\\=\\=\\=\\=\\=\\=\\> 进入红色框的`applyBeanPostProcessorsBeforeInitialization()`方法：\n\n遍历得到容器中所有的`BeanPostProcessor`，并一执行`BeanPostProcessor`的`postProcessBeforeInitialization()`方法，将bean对象逐一经过每个`BeanPostProcessor`处理器。一旦返回null，跳出for循环后续不再执行。\n\n![image-20210629164433894](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210629164433894.png)\n\n\n\n## BeanFactoryPostProcessor\n\n**BeanFactoryPostProcessor**：bean工厂后置处理器。调用时机：在**BeanFactory标准初始化之后**调用，此时所有组件的**定义已经加载**，但是组件的**实例还没有被初始化创建**。其作用：**用来定制和修改BeanFactory的内容**。\n\n```java\n@Component\npublic class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor {\n    @Override\n    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {\n        // 可以对beanFactory进行一些修改\n        System.out.println(\"====> postProcessBeanFactory ... bean的数量：\" + beanFactory.getBeanDefinitionCount());\n    }\n}\n```\n\n### BeanFactoryPostProcessor执行流程源码分析\n\n1. 在`refresh()`方法中调用`invokeBeanFactoryPostProcessors()`：\n\n![image-20210705205828372](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210705205828372.png)\n\n2. 在其内的方法栈中先按照类型获取到`postProcessorNames`\n\n![image-20210709100017919](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709100017919.png)\n\n3. 将获取到的：`postProcessorNames`按照优先级排序\n\n![image-20210709100256718](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709100256718.png)\n\n4. 按照优先级次序依次执行\n\n![image-20210709095828532](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709095828532.png)\n\n![image-20210709100124077](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709100124077.png)\n\n上述过程在**初始化创建其他组件之前**执行，在**BeanDefinitionRegistryPostProcessor**之后执行。\n\n## BeanDefinitionRegistryPostProcessor\n\n**BeanDefinitionRegistryPostProcessor**继承自**BeanFactoryPostProcessor**。其在所有bean定义信息**将要被加载，且bean实例还未创建**时执行，因此其在`BeanFactoryPostProcessor`的方法之前执行。作用：**利用传入的BeanDefinitionRegistry给容器中再添加一些组件**。\n\n每个`BeanDefinitionRegistryPostProcessor`接口的实现类都需要实现`postProcessBeanDefinitionRegistry()`方法和`postProcessBeanFactory()`方法，执行顺序：先前者再后者。\n\n```java\n@Component\npublic class MyBeanDefinitionRegistryProcessor implements BeanDefinitionRegistryPostProcessor {\n    @Override\n    public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException {\n        // 首先执行\n        // registry: bean定义信息的保存中心\n        // BeanFactory就是按照BeanDefinitionRegistry中保存的每一个bean定义信息创建bean实例\n        System.out.println(\"====> postProcessBeanDefinitionRegistry ... bean的数量：\" + registry.getBeanDefinitionCount());\n\n        RootBeanDefinition rootBeanDefinition = new RootBeanDefinition(Color.class);\n        // 二者效果相同↑\n        //AbstractBeanDefinition rootBeanDefinition = BeanDefinitionBuilder.rootBeanDefinition(Color.class).getBeanDefinition();\n\n        // 将bean的定义信息保存到BeanDefinitionRegistry中，在后续被BeanFactory获取到定义信息并创建对象\n        registry.registerBeanDefinition(\"newBean\", rootBeanDefinition);\n    }\n\n    @Override\n    public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {\n        // 其次执行\n        // 可以对beanFactory进行一些修改\n        System.out.println(\"====> postProcessBeanFactory ... bean的数量：\" + beanFactory.getBeanDefinitionCount());\n    }\n}\n```\n\n### BeanDefinitionRegistryPostProcessor执行流程源码分析\n\n1. 在`refresh()`方法中调用`invokeBeanFactoryPostProcessors()`：\n\n![image-20210705205828372](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210705205828372.png)\n\n2. 在其内的方法栈中先按照类型获取到`postProcessorNames`\n\n![image-20210709110018151](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709110018151.png)\n\n3. 之后同样按照优先级依次执行`invokeBeanDefinitionRegistryPostProcessors()`（红色框）\n\n![image-20210709110448115](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709110448115.png)\n\n`invokeBeanDefinitionRegistryPostProcessors()`:\n\n![image-20210709110356211](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709110356211.png)\n\n4. 执行完`invokeBeanDefinitionRegistryPostProcessors()`后再执行`invokeBeanFactoryPostProcessors()`（黄色框）\n\n![image-20210709110448115](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709110448115.png)\n\n`invokeBeanFactoryPostProcessors()`:\n\n![image-20210709110615151](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/image-20210709110615151.png)\n\n**注意：上述过程均在BeanFactoryPostProcessor组件的方法执行前执行**。\n\n### 其与BeanFactoryPostProcessor执行时机对比\n\n首先从容器中获取到所有的`BeanDefinitionRegistryPostProcessor`组件，依次触发其`postProcessBeanDefinitionRegistry()`方法，再触发`postProcessBeanFactory()`。\n\n之后再从容器中找到 `BeanFactoryPostProcessor`，并执行其`postProcessBeanFactory()`。\n\n即执行顺序：\n\n- `BeanDefinitionRegistryPostProcessor.postProcessBeanDefinitionRegistry()`\n- `BeanDefinitionRegistryPostProcessor.postProcessBeanFactory()`\n- `BeanFactoryPostProcessor.postProcessBeanFactory()`\n\n\n\n## Aware\n\n```java\n/**\n * A marker superinterface indicating that a bean is eligible to be notified by the\n * Spring container of a particular framework object through a callback-style method.\n * The actual method signature is determined by individual subinterfaces but should\n * typically consist of just one void-returning method that accepts a single argument.\n *\n */\npublic interface Aware {\n\n}\n```\n\nAware接口有若干继承的接口，命名格式为xxxAware：\n\n![image-20210630101718020](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630101718020.png)\n\n开发人员自定义的组件若想使用**Spring底层的一些组件**（如ApplicationContext、BeanFactory等），只需要实现相应的**xxxAware**（如ApplicationContextAware、BeanFactoryAware）接口，这些接口均继承自Aware接口，其特有的方法会以**callback-style**的方式被容器中对应的**xxxAwareProcessor**组件调用。\n\n每个Aware接口实现类都对应了一个xxxAwareProcessor类（如ApplicationContextAware对应ApplicationContextAwareProcessor），该Processor类负责在容器中创建组件后（初始化之前）以**回调的风格**调用xxxAware实现类的特定方法（每个xxxAware实现类都有其特有的方法，功能都不同）。容器在逐一注册bean时，若发现某个bean实现了某个Aware接口，就会在容器中注册相应的xxxAwareProcessor类组件，让其负责回调该bean中实现的xxxAware接口的方法。\n\n例如：**ApplicationContextAware**接口对应了一个**ApplicationContextAwareProcessor**类：\n\n![image-20210630102625001](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630102625001.png)\n\n![image-20210630103554590](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630103554590.png)\n\n若开发人员自定义的某个bean（如下图中BookDao类）实现了`ApplicationContextAware`接口的`setApplicationContext(ApplicationContext applicationContext)`方法，则在容器加载`BookDao`类时，会根据其实现的`ApplicationContextAware`接口动态注册一个`ApplicationContextAwareProcessor`类。\n\n![image-20210630103106864](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630103106864.png)\n\nIoC容器在执行到方法栈`AbstractAutowireCapableBeanFactory.java`时，会遍历得到容器中所有的`BeanPostProcessor`，并一执行`BeanPostProcessor`的`postProcessBeforeInitialization()`方法，将bean对象逐一经过每个`BeanPostProcessor`处理器，此时会调用：\n\n![image-20210629164433894](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210629164433894-1625020601639.png)\n\n`ApplicationContextAwareProcessor`类实现的`postProcessBeforeInitialization()`方法如下：\n\n![image-20210629192447682](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210629192447682.png)\n\n每个bean在进入该方法后都会判断是否符合黄色框中接口的实现类，若符合（代表实现了xxxAware接口），则会执行`invokeAwareInterfaces()`方法，根据其实现的接口类型调用相应的方法设置相应的容器组件（红色框）。\n\n![image-20210630103302320](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630103302320.png) 注意：在创建bean之前调用的invokeAwareMethods()方法（绿色框）内只会调用三个特殊的Aware接口实现类的方法，其他的Aware接口并不会在此执行，只能通过创建相应xxxAwareProcessor的方式回调执行相应方法。\n\n![image-20210630214340913](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630214340913.png)\n\n![image-20210630213635404](/images/%E3%80%90Spring%E3%80%91Spring5%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3/image-20210630213635404.png)","tags":["SSM","Spring"],"categories":["Spring","SSM"]},{"title":"【Spring】Spring5 注解驱动开发","url":"/2021/06/25/【Spring】Spring5-注解驱动开发/","content":"\n![image-20210629094903500](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8/image-20210629094903500.png)\n\n本文将详细介绍Spring5注解驱动开发的细节。其中Spring AOP的源码分析见[【Spring】Spring5 AOP源码分析](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n## IoC容器\n\n导入maven依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-webmvc</artifactId>\n    <version>5.3.5</version>\n</dependency>\n```\n\nIoC容器部分案例汇总：\n\n``` java\n@PropertySource(value = {\"classpath:/person.properties\"}) // 导入外部资源文件\n@Conditional({WindowsCondition.class}) // 满足当前条件，这个类中配置的所有bean注册才能生效\n@ComponentScan(value = \"com.zhao\", excludeFilters = {\n        @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class})\n})\n@ComponentScans(\n        value = {\n                @ComponentScan(value = \"com.zhao\", excludeFilters = {\n                        @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class})\n                }) ,\n                @ComponentScan(value = \"com.zhao\", includeFilters = {\n                        @Filter(type = FilterType.ANNOTATION, classes = {Repository.class}),\n                        @Filter(type = FilterType.ASSIGNABLE_TYPE, classes = {BookService.class}),\n                        @Filter(type = FilterType.CUSTOM, classes = {MyTypeFilter.class})\n                }, useDefaultFilters = false)\n        }\n)\n@Import({User.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})\n@Configuration(proxyBeanMethods = true)\npublic class SpringConfig {\n   \n    @Scope(\"singleton\") // prototype：多实例的，singleton：单实例的\n    @Lazy\n    @Conditional({WindowsCondition.class})\n    @Bean(\"user\")\n    public User user(initMethod = \"init\", destroyMethod = \"destroy\") {\n        return new User(\"zhangsan\", 18);\n    }\n    \n    // 外部无论对配置类中的该组件注册方法调用多少次，获得的都是之前注册在容器中的单实例对象\n    @Bean\n    public UserService userService(@Autowired UserDao userDao) {\n        return new UserService(userDao);\n    }\n    \n    @Bean\n    public StudentFactoryBean studentFactoryBean(){\n        return new StudentFactoryBean();\n    }  \n}\n```\n\n使用`AnnotationConfigApplicationContext`类获取IoC容器中的组件\n\n```java\n@Test\npublic void test() {\n    // 加载配置类 SpringConfig\n    ApplicationContext context\n        = new AnnotationConfigApplicationContext(SpringConfig.class);\n    \n    String[] beanDefinitionNames = context.getBeanDefinitionNames();\n    for (String name : beanDefinitionNames) {\n        System.out.println(name);\n    }\n      \n    User user = context.getBean(User.class);\n    System.out.println(user);\n\n    Object studentFactoryBean = context.getBean(\"studentFactoryBean\");\n    System.out.println(\"bean的类型： \" + studentFactoryBean.getClass()); //返回的是Student类对象\n}\n```\n\n<!-- More -->\n\n### @Configuration\n\n在一个类上添加@Configuration注解，则该类就将作为Spring的配置类，可在其中注册组件。\n\n``` java\n@Configuration()\npublic class SpringConfig {\n    @Bean(\"user\")\n    public User user(initMethod = \"init\", destroyMethod = \"destroy\") {\n        return new User(\"zhangsan\", 18);\n    }\n}\n```\n\n## 组件注册\n\n在Spring IoC容器中注册组件有三种方法\n\n- `@Bean`：编写相应方法返回组件（可用于导入的第三方包中的组件）\n- `@ComponentScan`：包扫描+组件标注注解\n- `@Import`：调用无参构造快速导入组件（可用于导入的第三方包中的组件）\n\n### @Bean：在SpringConfig类里编写相应方法返回组件\n\n方法返回值类型为组件类型，方法名为默认组件id，也可以在`@Bean()`中自定义组件id\n\n``` java\n@Configuration\npublic class SpringConfig {\n    @Bean(\"user\")\n    public User user() {\n        return new User(\"zhangsan\", 18);\n    }\n}\n```\n\n### @ComponentScan：在SpringConfig类上添加包扫描\n\n指定**排除**哪些组件\n\n```java\n@ComponentScan(value = \"com.zhao\", excludeFilters = {\n        @Filter(type = FilterType.ANNOTATION,classes = {Controller.class, Service.class})\n})\n```\n\n指定**包含**哪些组件（注意：需要设置`useDefaultFilters = false`）\n\n``` java\n@ComponentScan(value=\"com.zhao\", includeFilters={\n        @Filter(type= FilterType.ANNOTATION,classes={Controller.class, Service.class})\n}, useDefaultFilters = false)\n```\n\n若想指定多个`@ComponentScan`，可以使用`@ComponentScans`：\n\n``` java\n@ComponentScans(\n        value = {\n                @ComponentScan(value = \"com.zhao\", excludeFilters = {\n                        @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class})\n                }) ,\n                @ComponentScan(value = \"com.zhao\", includeFilters = {\n                        @Filter(type = FilterType.ANNOTATION, classes = {Repository.class}),\n                        @Filter(type = FilterType.ASSIGNABLE_TYPE, classes = {BookService.class}),\n                        @Filter(type = FilterType.CUSTOM, classes = {MyTypeFilter.class})\n                }, useDefaultFilters = false)\n        }\n)\n```\n\n### @Filter：组件注册过滤器\n\n`@Filter`可以指定的类型：\n\n- `FilterType.ANNOTATION`：过滤指定的注解\n- `FilterType.ASSIGNABLE_TYPE`：过滤指定的类\n- `FilterType.CUSTOM`：自定义过滤器类，指定包下的所有类都会经过该过滤器类，并判断是否需要被过滤\n\n`FilterType.CUSTOM`需要传入一个自定义过滤器类`MyTypeFilter`，其需要实现`TypeFilter`接口的方法：\n\n``` java\npublic class MyTypeFilter implements TypeFilter {\n\n    /**\n     * 自定义Filter，每个自定义组件的信息都会被该方法获取，再判断是否过滤掉该组件\n     * @param metadataReader：读取到的当前正在扫描的类的信息\n     * @param metadataReaderFactory：可以获取到其他任何类信息的工厂\n     * @return\n     * @throws IOException\n     */\n    @Override\n    public boolean match(MetadataReader metadataReader, MetadataReaderFactory metadataReaderFactory) throws IOException {\n\n        // 获取当前类的注解信息\n        AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata();\n        // 获取当前扫描的类信息\n        ClassMetadata classMetadata = metadataReader.getClassMetadata();\n        // 获取当前类资源信息（类路径等）\n        Resource resource = metadataReader.getResource();\n\n        String className = classMetadata.getClassName();\n        System.out.println(\"-----> \" + className);\n\n        if (className.contains(\"er\")) {\n            return true;\n        }\n        return false;\n    }\n}\n```\n\n### @Import：快速导入组件 \n\n1. `@Import(xxx.class`)：注册xxx类，id默认是全类名\n2. `@Import(ImportSelector)`：实现`ImportSelector`接口，在其方法中返回需要注册的组件全类名**数组**\n3. `@Import(ImportBeanDefinitionRegistrar)`：实现`ImportBeanDefinitionRegistrar`接口，在其方法中调用`BeanDefinitionRegistry `类对象的`registerBeanDefinition()`方法手动注册组件（**详细源码见【Spring】Spring5源码**）\n\n```java\n@Import({User.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})\npublic class SpringConfig {\n}\n```\n\n`ImportSelector`接口实现类：`MyImportSelector`\n\n``` java\npublic class MyImportSelector implements ImportSelector {\n\n    /**\n     * 该方法返回的全类名将被注册到容器中\n     * @param importingClassMetadata：当前标注Import注解的类（即SpringConfig类）的所有注解信息\n     * @return 返回值就是要导入到容器中的组件全类名，不能返回null\n     */\n    @Override\n    public String[] selectImports(AnnotationMetadata importingClassMetadata) {\n        // 返回要导入到容器中的组件全类名，方法不能返回null\n        return new String[]{\"com.zhao.bean.Student\", \"com.zhao.bean.User\"};\n    }\n}\n```\n\n`ImportBeanDefinitionRegistrar`接口实现类`MyImportBeanDefinitionRegistrar`：\n\n```java\npublic class MyImportBeanDefinitionRegistrar implements ImportBeanDefinitionRegistrar {\n\n    /**\n     * 实现registerBeanDefinitions接口以手动注册bean\n     * @param importingClassMetadata：当前类的注解信息\n     * @param registry：BeanDefinition注册类\n     *                把所有要添加到容器中的bean调用registry.registerBeanDefinition()手动注册类\n     */\n    @Override\n    public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata,\n                                        BeanDefinitionRegistry registry){\n        boolean definition = registry.containsBeanDefinition(\"student\");\n        if (!definition) {\n            // 指定Bean定义信息（bean类型，作用域等）\n            RootBeanDefinition beanDefinition = new RootBeanDefinition(Student.class);\n            // 注册一个bean，指定bean名\n            registry.registerBeanDefinition(\"student\", beanDefinition);\n        }\n    }\n}\n```\n\n### @Scope：设置组件作用域\n\n`@Scope`常用的两种作用域：\n\n- **singleton**：单实例（默认值）。IoC容器**启动时就会**调用方法创建对象到IoC容器中，之后获取就直接从容器中拿（map.get()）。关闭工厂 时，所有的对象都会销毁。\n- **prototype**：多实例。IoC容器启动时**不会**调用方法创建对象到IoC容器中，每次获取的时候才会调用方法创建对象。关闭工厂 ，所有的对象不会销毁。内部的垃圾回收机制会回收。\n\n```java\n@Scope(\"prototype\") \n@Bean(\"user\")\npublic User user() {\n    return new User(\"zhangsan\", 18);\n}\n```\n\n### @Lazy：懒加载\n\n单实例bean默认在容器启动时就创建对象，而使用了@Lazy后，在容器启动时并不会创建对象，而会等到第一次获取bean时才创建对象并初始化。\n\n``` java\n@Lazy\n@Bean(\"user\")\npublic User user() {\n    return new User(\"zhangsan\", 18);\n}\n```\n\n### @Conditional：按照一定条件进行判断，满足条件的给容器中注册bean\n\n**在方法上添加@Conditional**\n\n```java\n@Configuration\npublic class SpringConfig {\n\n    @Conditional({WindowsCondition.class})\n    @Bean(\"user\")\n    public User user() {\n        return new User(\"zhangsan\", 18);\n    }\n\n}\n```\n\n需要实现Condition接口的matches(ConditionContext context, AnnotatedTypeMetadata metadata)方法。当前组件只有满足该条件才会被注册\n\n```java\npublic class WindowsCondition implements Condition {\n\n    /**\n     * 根据条件判断是否注册组件\n     * @param context：判断条件能否使用的上下文（环境）\n     * @param metadata：标记了@Condition注解的注释信息\n     * @return true: 注册  false：不注册\n     */\n    @Override\n    public boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata) {\n        // 获取到ioc使用的工厂\n        ConfigurableListableBeanFactory beanFactory = context.getBeanFactory();\n        // 获取类加载器\n        ClassLoader classLoader = context.getClassLoader();\n        // 获取当前环境信息\n        Environment environment = context.getEnvironment();\n        // 获取到bean定义的注册类，所有bean的定义都在这里注册\n        BeanDefinitionRegistry registry = context.getRegistry();\n\n        String property = environment.getProperty(\"os.name\");\n        return property.contains(\"Windows\");\n    }\n}\n```\n\n**在配置类上添加@Conditional**\n\n满足条件，这个类中配置的所有bean注册才能生效\n\n```java\n@Conditional({WindowsCondition.class})\n@Configuration\npublic class SpringConfig {\n    @Bean(\"user\")\n    public User user() {\n        return new User(\"zhangsan\", 18);\n    }\n}\n```\n\n### 使用FactoryBean注册组件\n\n在`Spring`和其他框架整合时，大量使用`FactoryBean`注册组件。\n\n1. 创建`FactoryBean`接口的实现类`StudentFactoryBean`：\n\n```java\npublic class StudentFactoryBean implements FactoryBean<Student> {\n\n    // 返回一个Student对象，该对象会添加到容器中\n    @Override\n    public Student getObject() throws Exception {\n        return new Student();\n    }\n\n    @Override\n    public Class<?> getObjectType() {\n        return Student.class;\n    }\n\n    @Override\n    public boolean isSingleton() {\n        return false;\n    }\n}\n```\n\n2. 在配置类中声明该工厂类对象\n\n```java\n@Configuration\npublic class SpringConfig {\n\n    @Bean\n    public StudentFactoryBean studentFactoryBean(){\n        return new StudentFactoryBean();\n    }\n}\n```\n\n3. 获取`FactoryBean`调用`getObject()`创建的对象（并非`FactoryBean`组件，而是其内生产的组件）\n\n``` java\nAnnotationConfigApplicationContext  context = new AnnotationConfigApplicationContext(SpringConfig.class);\n\nObject studentFactoryBean = context.getBean(\"studentFactoryBean\");\nSystem.out.println(\"bean的类型： \" + studentFactoryBean.getClass()); //返回的是Student类对象\n```\n\n若想获取`FactoryBean`组件，需要：\n\n``` java\nObject studentFactoryBean = context.getBean(\"&studentFactoryBean\");\n```\n\n### 组件注册小结\n\n组件注册相关注解使用汇总案例：\n\n![image-20210629153052661](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8/image-20210629153052661.png)\n\n``` java\n@PropertySource(value = {\"classpath:/person.properties\"}) // 导入外部资源文件\n@Conditional({WindowsCondition.class}) // 满足当前条件，这个类中配置的所有bean注册才能生效\n@Configuration\n@ComponentScan(value = \"com.zhao\", excludeFilters = {\n        @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class})\n})\n@ComponentScans(\n        value = {\n                @ComponentScan(value = \"com.zhao\", excludeFilters = {\n                        @Filter(type = FilterType.ANNOTATION, classes = {Controller.class, Service.class})\n                }) ,\n                @ComponentScan(value = \"com.zhao\", includeFilters = {\n                        @Filter(type = FilterType.ANNOTATION, classes = {Repository.class}),\n                        @Filter(type = FilterType.ASSIGNABLE_TYPE, classes = {BookService.class}),\n                        @Filter(type = FilterType.CUSTOM, classes = {MyTypeFilter.class})\n                }, useDefaultFilters = false)\n        }\n)\n@Import({User.class, MyImportSelector.class, MyImportBeanDefinitionRegistrar.class})\npublic class SpringConfig {\n    @Scope(\"singleton\") // prototype：多实例的，singleton：单实例的\n    @Lazy\n    @Conditional({WindowsCondition.class})\n    @Bean(\"user\")\n    public User user() {\n        return new User(\"zhangsan\", 18);\n    }\n    \n    @Bean\n    public StudentFactoryBean studentFactoryBean(){\n        return new StudentFactoryBean();\n    }\n}\n```\n\n其中在`@Import`、`@Filter`、`@Conditional`注解中指定的类对象均实现了特定的接口，并会在容器加载时调用这些接口实现类的指定方法，从而使得不同的注解实现不同的效果（注册bean、过滤、判断条件等）。\n\n## 生命周期\n\n生命周期 ：从对象创建到对象销毁的过程。bean 的生命周期有七步 （正常生命周期为五步，而配置后置处理器后为七步）\n\n1. 通过构造器创建 bean 实例（无参数构造）\n2. 为 bean 的属性设置值和对其他 bean 引用（调用 set 方法）\n3. 把 bean 实例传递给**后置处理器**的方法 `postProcessBeforeInitialization`\n4. 调用 bean 的**初始化**的方法（需要在配置初始化方法`init-method`）\n5. 把 bean 实例传递给**后置处理器**的方法 `postProcessAfterInitialization`\n6. bean 可以使用了（对象获取到了）\n7. 当容器关闭时候，调用 bean 的**销毁**方法（需要配置销毁的方法`destroy-method`）\n\n整个生命周期中，3和5由自定义的**后置处理器BeanPostProcessor**实现；4和7由自定义**初始化和销毁方法**实现；其余阶段默认由Spring容器完成。\n\n大致流程：\n\n- constructor构造器执行\n- set方法执行\n- BeanPostProcessor.postProcessBeforeInitialization方法执行\n- init-method执行\n- BeanPostProcessor.postProcessAfterInitialization方法执行\n- destroy-method执行\n\n补充：在开启AOP功能后，容器中会注册一个特殊的后置处理器：**AnnotationAwareAspectJAutoProxyCreator**，该处理器会在每个bean**实例化的前后**进行拦截，将带有切入点的bean包装成代理对象加入到容器中，该过程在上述描述的**1-6步骤前后**执行。\n\n### 自定义初始化和销毁方法\n\nbean的生命周期由容器管理，可以自定义**初始化**和**销毁**方法：\n\n- 方式一：通过`@Bean`注解指定`initMethod`和`destroyMethod`\n- 方式二：通过让bean实现`InitializingBean`定义初始化逻辑和`DisposableBean`定义销毁逻辑\n- 方式三：使用JSR250中`@PostConstruct`和`@PreDestroy`注解\n\n初始化方法在bean对象**创建好并赋值后被调用**，销毁方法在对象被销毁前被调用。\n\n销毁时：\n\n- 单实例：容器关闭时销毁\n- 多实例：容器不会管理这个bean，容器不会调用销毁方法，需要手动调用\n\n#### 方式一：@Bean注解指定initMethod和destroyMethod\n\n```java\n@Configuration\npublic class SpringConfigOfLifeCycle {\n\n    @Bean(initMethod = \"init\", destroyMethod = \"destroy\")\n    public User user(){\n        return new User();\n    }\n}\n```\n\n``` java\n@Component(\"user\")\npublic class User {\n    private String name;\n    private int age;\n\n    public User() {\n        System.out.println(\"======> User constructor ....\");\n    }\n\n    public void init(){\n        System.out.println(\"======> User init ....\");\n    }\n\n    public void destroy(){\n        System.out.println(\"======> User destory ....\");\n    }\n\n}\n```\n\n#### 方式二：bean实现InitializingBean和DisposableBean接口\n\n```java\npublic class Cat implements InitializingBean, DisposableBean {\n\n    public Cat(){\n        System.out.println(\"======> Cat constructor ....\");\n    }\n\n    @Override\n    public void destroy() throws Exception {\n        System.out.println(\"======> Cat destory ....\");\n    }\n\n    @Override\n    public void afterPropertiesSet() throws Exception {\n        System.out.println(\"======> Cat afterPropertiesSet ....\");\n    }\n}\n```\n\n``` java\n@ComponentScan(\"com.zhao.bean\")\n@Configuration\npublic class SpringConfigOfLifeCycle {\n}\n```\n\n#### 方式三：使用JSR250中@PostConstruct和@PreDestroy注解\n\n```java\npublic class Dog {\n    public Dog(){\n        System.out.println(\"=====> Dog constructor ....\");\n    }\n\n    @PostConstruct\n    public void init(){\n        System.out.println(\"=====> Dog init ....\");\n    }\n    \n    @PreDestroy\n    public void destroy(){\n        System.out.println(\"=====> Dog init ....\");\n    }\n}\n```\n\n`@PostConstruct`和`@PreDestroy`的注解信息会被`InitDestroyAnnotationBeanPostProcessor`获取到，并据此执行相应的初始化和销毁方法。\n\n![image-20210629194708129](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629194708129.png)\n\n### 后置处理器 BeanPostProcessor\n\n`BeanPostProcessor`接口用于在bean的**初始化前后**进行一些处理工作：\n\n- `postProcessBeforeInitialization()`：在初始化方法之前工作\n- `postProcessAfterInitialization()`：在初始化方法之后工作\n\n自定义后置处理器实现`BeanPostProcessor`的方法，并将其注册到容器中。之后所有的bean对象在初始化方法前后都会进入该类的方法中执行相应处理。即使一些bean没有自定义初始化方法，也不会影响后置处理器方法的执行。\n\n```java\n@Component\npublic class MyBeanPostProcessor implements BeanPostProcessor {\n    @Override\n    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {\n        // bean：当前被处理的bean对象\n        System.out.println(\"====> postProcessBeforeInitialization ... \" + beanName + \": \" + bean);\n\n        // 可以对bean进行一些包装\n        return bean;\n    }\n\n    @Override\n    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n        System.out.println(\"====> postProcessAfterInitialization ... \" + beanName + \": \" + bean);\n\n        // 可以对bean进行一些包装\n        return bean;\n    }\n}\n```\n\n### BeanPostProcessor 执行流程源码分析\n\n1. 容器调用bean的构造方法创建对象\n2. `populateBean()`：容器调用bean的set方法为bean对象的属性赋值（红色框）\n3. `initializeBean()`：容器为bean做初始化操作（黄色框）\n\n方法栈位置：`AbstractAutowireCapableBeanFactory.java`\n\n![image-20210629163559536](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8/image-20210629163559536.png)\n\n\\=\\=\\=\\=\\=\\=\\> 进入黄色框的`initializeBean()`方法：\n\n- 执行`invokeAwareMethods()`方法（绿色框）\n- 执行`applyBeanPostProcessorsBeforeInitialization()`方法（红色框）\n- 执行`invokeInitMethods()`方法完成初始化（黄色框）\n- 执行`applyBeanPostProcessorsAfterInitialization()`方法（红色框）\n\n![image-20210630214340913](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210630214340913.png)\n\n\\=\\=\\=\\=\\=\\=\\> 进入红色框的`applyBeanPostProcessorsBeforeInitialization()`方法：\n\n遍历得到容器中所有的`BeanPostProcessor`，并一执行`BeanPostProcessor`的`postProcessBeforeInitialization()`方法，将bean对象逐一经过每个`BeanPostProcessor`处理器。一旦返回null，跳出for循环后续不再执行。\n\n![image-20210629164433894](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8/image-20210629164433894.png)\n\n### Spring底层对BeanPostProcessor的应用\n\n使用`BeanPostProcessor`接口的实现类，可以实现：bean赋值、注入其他组件、`@Autowired`属性注入、生命周期注解功能等。\n\n`BeanPostProcessor`接口的实现类\n\n![image-20210629190629663](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629190629663.png)\n\n#### ApplicationContextAwareProcessor\n\n`ApplicationContextAwareProcessor`是`BeanPostProcessor`的一个实现类。其原理同上述自定义的`MyBeanPostProcessor`类一样，都会在如下for循环中被获取到，并执行其实现的`postProcessBeforeInitialization()`方法。\n\n![image-20210629164433894](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629164433894.png)\n\n`ApplicationContextAwareProcessor`类实现的`postProcessBeforeInitialization()`方法如下：\n\n![image-20210629192447682](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629192447682.png)\n\n每个bean在进入该方法后都会判断是否符合黄色框中接口的实现类，若符合，则会执行`invokeAwareInterfaces()`方法，根据其实现的接口类型调用相应的方法设置相应的容器上下文属性。\n\n![image-20210629192653559](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629192653559.png)\n\n#### AutowiredAnnotationBeanPostProcessor\n\n实现@Autowired自动注入功能。在对象创建完后，获取被`@Autowired`注解修饰的属性，从而实现属性注入。\n\n#### BeanValidationPostProcessor\n\n`BeanValidationPostProcessor`常用在JavaWeb中用于**数据校验**。\n\n其类实现的`postProcessBeforeInitialization()`方法如下：\n\n![image-20210629194216136](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629194216136.png)\n\n在其`doValidate()`方法中提供了数据校验的功能。因此可以在bean初始化前后完成校验工作。\n\n![image-20210629194247408](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629194247408.png)\n\n#### InitDestroyAnnotationBeanPostProcessor\n\n`InitDestroyAnnotationBeanPostProcessor`用于获取bean对象的`@PostConstruct`和`@PreDestroy`注解信息，并据此执行相应的初始化和销毁方法。\n\n![image-20210629194708129](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210629194708129.png)\n\n### BeanPostProcessor总结\n\n每个bean对象在被注册到容器的过程中，会在执行`invokeInitMethods()`方法初始化bean之前，执行用户自定义注册的`BeanPostProcessor`实现类和容器默认注册的`BeanPostProcessor`实现类的`postProcessBeforeInitialization()`方法。不同实现类的`postProcessBeforeInitialization()`方法功能不同，可以自定义地为其设置不同的功能，包括输出日志、添加上下文容器、添加环境属性、添加资源解析器等。\n\n若想让某些bean获得上述功能，只需要该类实现`BeanPostProcessor`接口的`postProcessBeforeInitialization()`方法即可。\n\n使用`BeanPostProcessor`接口的实现类，可以实现：bean赋值、注入其他组件、`@Autowired`属性注入、生命周期注解功能等。\n\n\n## 组件属性赋值\n\n### @Value\n\n​\t@Value注解可以赋值的类型：\n\n- 基本数据类型值\n- SpEL：#{}，可以在其中进行数值运算\n- \\${}取出配置文件中的值（在运行环境变量里的值），读取配置文件时需要在配置类上添加注解`@PropertySource`\n\n``` java\n@PropertySource(value = {\"classpath:/person.properties\"})\n@Configuration\npublic class SpringConfigOfPropertyValue {\n\n    @Bean\n    public Person person(){\n        return new Person();\n    }\n}\n```\n\n``` java\n@Component\npublic class Person {\n\n    @Value(\"张三\")\n    private String name;\n\n    @Value(\"#{20-2}\")\n    private Integer age;\n\n    @Value(\"${person.phone}\")\n    private String phone;\n\n    // 省略方法...\n}\n```\n\n## 组件自动装配\n\nSpring利用依赖注入DI，完成对IoC容器中各个组件的依赖关系赋值。\n\n**Spring提供的自动装配注解**：\n\n- `@Autowired`：根据属性**类型**进行自动装配\n- `@Qualifier`：根据属性**名称**进行自动装配\n- `@Primary`：根据设置为**默认首选**的bean进行自动装配\n\nJava规范提供的注解：\n\n- `@Resource`：可以根据类型注入，也可以根据名称注入，但不支持`@Primary`和`@Autowired(required=false)`\n- `@Inject`：功能和`@Autowired`一样，没有`required=false`功能\n\n### @Autowired：按照属性类型自动装配\n\n如果找到多个相同类型的组件，再将**属性的名称**作为组件的id去容器中查找，若找不到指定名称的组件，则程序报错，此时可以添加`required=false`属性使得当前组件即使找不到程序也不会报错。\n\n``` java\n@Service\npublic class UserService {\n\n    //不需要添加set方法\n    @Autowired(required=false)\n    private UserDao userDao;\n    \n    public void add() {\n        System.out.println(\"service add.......\");\n        userDao.add();\n    }\n}\n```\n\n`@Autowired`也可以修饰方法、有参构造器、方法参数上。\n\n有参构造器说明：若组件只有一个有参构造器，这个有参构造器的`@Autowired`可以省略，参数位置的组件仍然能从容器中获取。\n\n``` java\n@Service\npublic class UserService {\n    \n    private UserDao userDao;\n    \n    // 修饰有参构造\n    @Autowired\n    public UserService(UserDao userDao){\n        this.userDao = userDao; \n    }\n    \n    // 修饰方法\n    @Autowired\n    public void setUserDao(UserDao userDao){\n     \tthis.userDao = userDao;   \n    }\n    \n    // 修饰方法参数\n    public UserService(@Autowired UserDao userDao){\n        this.userDao = userDao; \n    }\n    \n    // 修饰方法参数\n    public void setUserDao(@Autowired UserDao userDao){\n     \tthis.userDao = userDao;   \n    }\n}\n```\n\n在配置类中使用`@Autowired`修饰方法参数（可以省略）\n\n``` java\n@Configuration\nclass SpringConfig{\n    @Bean\n    public UserService userService(@Autowired UserDao userDao){\n        return new UserService(userDao);\n    }\n    \n    // 或直接省略@Autowired\n    @Bean\n    public UserService userService(UserDao userDao){\n        return new UserService(userDao);\n    }\n}\n```\n\n### @Qualifier：按照属性名称自动装配\n\n`@Qualifier`：根据对象**名称**进行装配，可以和`@Autowired` 一起使用（目的在于区别同一接口下有多个实现类）\n\n``` java\n@Service\npublic class UserService {\n\n    //不需要添加 set 方法\n    @Autowired\n    @Qualifier(value = \"userDao1\") \n    private UserDao userDao;\n    \n    public void add() {\n        System.out.println(\"service add.......\");\n        userDao.add();\n    }\n}\n```\n\n### @Primary：根据设置为默认首选的bean进行自动装配\n\n被`@Primary`注解修饰的bean会在自动装配时被设置为首选项。但也可以继续使用`@Qualifier`指定需要装配的bean。\n\n``` java\n@Configuration\npublic class SpringConfigOfPropertyValue {\n\n    @Primary()\n    @Bean(\"userDao1\")\n    public UserDao userDao(){\n        return new UserDao();\n    }\n}\n```\n\n``` java\n@Service\npublic class UserService {\n    \n    //@Qualifier(value = \"userDao1\") 不设置时默认注入@Primary()修饰的userDao1\n    @Autowired\n    private UserDao userDao;\n    \n    public void add() {\n        System.out.println(\"service add.......\");\n        userDao.add();\n    }\n}\n```\n\n### @Profile：根据环境动态注册组件\n\n`@Profile`可以指定组件在哪个运行环境下才能被注册到容器中，若不指定则任何环境都能注册这个组件。可用于在开发环境、测试环境和生产环境中动态地注册组件。\n\n加了环境标识的组件，只有当这个环境被激活时才能注册到容器中。默认环境是`default`。没有添加`@Profile`的组件在任何环境下都会被注册。\n\n`@Profile`既可以修饰方法，又可以修饰配置类。\n\n``` java\n@Profile(\"default\")\n@Configuration\npublic class SpringConfigOfPropertyValue {\n\n    @Profile(\"test\")\n    @Bean()\n    public DataSource dataSourceTest(){\n        // .....\n    }\n    \n    @Profile(\"develop\")\n    @Bean()\n    public DataSource dataSourceTest(){\n        // .....\n    }\n}\n```\n\n激活环境的方式：\n\n- 在IDEA中设置`VM arguments：-Dspring.profiles.active=test`\n- 在代码中手动激活环境\n\n``` java\nAnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();\ncontext.getEnvironment().setActiveProfiles(\"test\", \"dev\");\ncontext.register(SpringConfigOfPropertyValue.class);\ncontext.refresh();\n```\n\n## AOP\n\n### AOP 基本概念\n\nAOP（Aspect Oriented Programming）意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。\n\nSpring AOP的源码分析见[【Spring】Spring5 AOP源码分析](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/kuangstudyfffec70f-ce10-4ca2-a71b-dbc535b0e07c.png)\n\n- 面向切面编程（方面），利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得 业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率；\n- 通俗描述：不通过修改源代码方式，在主干功能里面添加新功能。\n- 使用登录例子说明 AOP：\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/20200702135106266.png)\n\n### **AOP 底层原理**\n\nSpring AOP的底层原理分析见[【Spring】Spring5 AOP源码分析](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\nAOP 底层使用**动态代理** ，动态代理有两种情况：\n\n第一种 有接口情况，使用**JDK 动态代理** ；创建**接口实现类代理对象**，增强类的方法\n![在这里插入图片描述](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/20200702135134128.png)\n\n第二种 没有接口情况，使用**CGLIB 动态代理**创建**子类的代理对象**，增强类的方法（该方法不需要实现接口，由CGLIB创建代理对象）\n![在这里插入图片描述](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/2020070213514980.png)\n\n### AOP 术语\n\n\n- 连接点（JointPoint）：类里面哪些方法可以被增强，这些方法称为连接点，每一个方法的每一个位置（开始位置，返回位置，异常位置等）都是一个连接点。\n- **切入点（PointCut）**：切面通知执行的“地点”的定义，实际被真正增强的方法称为切入点。\n- 横切关注点：跨越应用程序多个模块的方法或功能。即是，与我们业务逻辑无关的，但是我们需要关注的部分，就是横切关注点。如日志 , 安全 , 缓存 , 事务等等 ….\n- **切面（Aspect）**：横切关注点被模块化的特殊对象。即，它是一个类。\n- **通知（Advice）**：切面必须要完成的工作。即，它是类中的一个方法。包含前置通知，后置通知，环绕通知 ，异常通知和最终通知。\n- 目标（Target）：被通知的对象。\n- 代理（Proxy）：向目标对象应用通知之后创建的对象。\n\n![image-20210713170252235](/images/%E3%80%90Spring%E3%80%91Spring5-%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/image-20210713170252235.png)\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/kuangstudy7a512991-1651-44b4-afca-d09e12cbbe6f.png)\n\n### AOP 操作\n\n采用**动态代理**的设计模式，在程序运行期间动态地将某段代码切入到指定方法（切入点）指定位置进行运行的编程方式。\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-aspects</artifactId>\n    <version>5.2.12.RELEASE</version>\n</dependency>\n```\n\n定义一个业务逻辑类（`MathCalculator`）。试图在业务逻辑运行的时候将日志进行打印（方法之前，方法运行结束，方法出现异常等）\n\n```java\npublic class MathCalculator {\n    public int div(int i, int j){\n        return i/j;\n    }\n}\n```\n\n定义一个日志切面类（`LogAspects`），在切面类里需要动态感知`MathCalculator.div()`方法运行到什么阶段并执行相应通知方法。通知方法：\n\n- 前置通知（`@Before`）：在切入点（`PointCut`）运行之前运行\n- 后置通知（`@After`）：在切入点运行结束之后运行（无论方法是否正常结束）\n- 返回通知（`@AfterReturning`）：在切入点正常返回之后运行（异常不执行）\n- 异常通知（`@AfterThrowing`）：在切入点出现异常之后运行\n- 环绕通知（`@Around`）：动态代理的方式**手动**推进切入点运行（`joinPoint.procced()`），是最底层的通知，其可以实现上述四个通知效果\n\n**通知方法的执行顺序**：（Spring 5的顺序与Spring 4有所不同）\n\n- 环绕通知（`@Around`）`joinPoint.procced()`方法之前的代码\n- 前置通知（`@Before`）\n- 业务代码\n- 返回通知（`@AfterReturning`）/ 若有异常，此时执行异常通知（`@AfterThrowing`）\n- 后置通知（`@After`）\n- 环绕通知（`@Around`）`joinPoint.procced()`方法以及其之后的代码\n\n多个切面的情况下，先执行前置通知的后执行返回通知和后置通知，后执行前置通知的先执行返回通知和后置通知。类似方法栈先进后出。执行顺序由切面类的字母顺序排序，也可以通过`@Order(1)`设置优先级\n\n### AOP 使用案例\n\n配置类需要**添加@EnableAspectJAutoProxy以开启注解版的AOP自动代理。整个AOP就是从@EnableAspectJAutoProxy注解开始执行的。**（Spring中有很多的`@EnableXXX`注解，其作用是代替xml文件中的一些配置开启某些功能）\n\n```java\n@EnableAspectJAutoProxy\n@Configuration\npublic class SpringConfigAOP {\n    // 将业务逻辑类加入到容器中\n    @Bean\n    public MathCalculator calculator(){\n        return new MathCalculator();\n    }\n\n    // 切面类加入到容器中\n    @Bean\n    public LogsAspects logsAspects(){\n        return new LogsAspects();\n    }\n}\n```\n\n切面类`LogsAspects`\n\n``` java\n@Aspect\n@Order(1)\npublic class LogsAspects {\n\n    // 抽取公共的切入点表达式\n    // 1. 本类可以引用\n    // 2. 其他的切面类也可以引用（需要全类名）\n    @Pointcut(\"execution(* com.zhao.aop.MathCalculator.*(..))\")\n    public void pointCut(){\n    }\n\n    @Before(\"execution(int com.zhao.aop.MathCalculator.div(int, int))\")\n    public void logStart(JoinPoint joinPoint){\n        Object[] args = joinPoint.getArgs(); // 方法参数\n        System.out.println(\"前置通知@Before.... \");\n    }\n\n    @After(\"execution(* com.zhao.aop.MathCalculator.*(..))\")\n    public void logEnd(){\n        System.out.println(\"后置通知@After....\");\n    }\n\n    @AfterReturning(value = \"pointCut()\", returning = \"result\")\n    public void logReturn(Object result){\n        // result: 方法返回值\n        System.out.println(\"返回通知@AfterReturning.... \");\n    }\n\n    @AfterThrowing(value = \"pointCut()\", throwing = \"exception\")\n    public void logException(Exception exception){\n        System.out.println(\"异常通知@AfterThrowing.... \");\n    }\n\n    @Around(\"pointCut()\")\n    public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {\n        System.out.println(\"签名: \" + proceedingJoinPoint.getSignature());\n        Object[] args = proceedingJoinPoint.getArgs();\n\n        try { \n            System.out.println(\"【环绕前置通知】.... \");\n            //执行目标方法proceed\n            Object result = proceedingJoinPoint.proceed(args);\n            System.out.println(\"【环绕返回通知】.... \");\n        } catch (Exception exception){\n            System.out.println(\"【环绕异常通知】.... \");\n        } finally {\n            System.out.println(\"【环绕后置通知】.... \");\n        }\n\n        return result;\n    }\n}\n```\n\n``` java\npublic class AOPTest {\n    AnnotationConfigApplicationContext context;\n\n    @Test\n    public void testOfAop() {\n        context = new AnnotationConfigApplicationContext(SpringConfigAOP.class);\n        System.out.println(\"容器创建完成....\");\n\n        // 必须从容器中获得bean才能启动AOP\n        MathCalculator bean = context.getBean(MathCalculator.class);\n        bean.div(1, 1);\n\n        context.close();\n    }\n}\n```\n\n控制台打印：\n\n``` \n签名: int com.zhao.aop.MathCalculator.div(int,int)\n【环绕前置通知】.... \n前置通知@Before.... \ndiv方法执行...\n返回通知@AfterReturning.... \n后置通知@After....\n【环绕返回通知】.... \n【环绕后置通知】...\n\nProcess finished with exit code 0\n```\n\n## 声明式事务\n\n### 使用案例\n\n1. 导入相关依赖：数据源、数据库驱动、SpringJDBC模块\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-jdbc</artifactId>\n    <version>5.2.12.RELEASE</version>\n</dependency>\n\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.47</version>\n</dependency>\n\n<dependency>\n    <groupId>c3p0</groupId>\n    <artifactId>c3p0</artifactId>\n    <version>0.9.1.2</version>\n</dependency>\n```\n\n2. 配置数据源、**JdbcTemplate**操作数据库(Spring提供的简化数据库操作的工具)\n\n3. 添加 **@EnableTransactionManagement** 注解开启**基于注解的事务管理功能**\n\n4. 配置**事务管理器**来控制事务（事务管理器操作数据源，进行事务管理）\n\n```java\n@EnableTransactionManagement\n@Configuration\npublic class TxConfig {\n\n    // 向容器中注册数据源\n    @Bean\n    public DataSource dataSource() throws PropertyVetoException {\n        ComboPooledDataSource dataSource = new ComboPooledDataSource();\n        dataSource.setUser(\"root\");\n        dataSource.setPassword(\"123456\");\n        dataSource.setDriverClass(\"com.mysql.jdbc.Driver\");\n        dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\");\n        return dataSource;\n    }\n\n    @Bean\n    public JdbcTemplate jdbcTemplate() throws PropertyVetoException {\n        JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource());\n        return jdbcTemplate;\n    }\n\n    // 向容器中注册事务管理器\n    @Bean\n    public PlatformTransactionManager transactionManager() throws PropertyVetoException {\n        return new DataSourceTransactionManager(dataSource());\n    }\n    \n}\n```\n\n5. 在类或方法上添加 **@Transactional()** 注解表明该方法需要添加事务\n\n- 添加到类上，这个类里面所有的方法都添加事务\n- 添加到方法上，只有这个方法添加事务\n\n``` java\n@Transactional()\npublic void add(propagation = Propagation.REQUIRED){\n    update();\n}\n```\n\n### 事务细节参数\n\n- `read-only`：设置事务为只读事务，不需要增删改操作。可以提高查询速度。\n- `timeout`：超时，事务超出指定执行时长后自动终止并回滚。\n- `isolation`：设置隔离级别\n\n运行时异常（非检查异常）发生时默认回滚，编译时异常（检查异常）默认不回滚\n\n- `rollBackFor`：可以让原来默认不回滚的异常回滚\n- `noRollBackFor`：可以让原来默认回滚的异常不回滚\n\n### 声明式事务传播特性\n\n事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。Spring支持7种事务传播行为：\n\n- **propagation_requierd**：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。（如果设置为required，则事务的其他属性继承于大事务）\n- propagation_supports：支持当前事务，如果没有当前事务，就以非事务方法执行。\n- propagation_mandatory：使用当前事务，如果没有当前事务，就抛出异常。\n- **propagation_required_new**：新建事务，如果当前存在事务，把当前事务挂起。\n- propagation_not_supported：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。\n- propagation_never：以非事务方式执行操作，如果当前事务存在则抛出异常。\n- propagation_nested：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作\n\nSpring 默认的事务传播行为是 `PROPAGATION_REQUIRED`，它适合于绝大多数的情况。\n\n假设 ServiveX#methodX() 都工作在事务环境下（即都被 Spring 事务增强了），假设程序中存在如下的调用链：Service1#method1()->Service2#method2()->Service3#method3()，那么这 3 个服务类的 3 个方法通过 Spring 的事务传播机制都工作在同一个事务中。\n\n### 声明式事务原理\n\n**@EnableTransactionManagement** 注解向容器中添加**AutoProxyRegistrar**和**ProxyTransactionManagementConfiguration**组件，二者作用分别为：\n\n- **AutoProxyRegistrar**：类似于AOP中的**AspectJAutoProxyRegistrar**，用于向容器中注册**InfrastructureAdvisorAutoProxyCreator**组件（类似于AOP里的自动代理器，一种后置处理器）来为普通组件进行代理包装，创建**代理对象**\n- **ProxyTransactionManagementConfiguration**：用于注册**事务增强器**，该增强器内设置有事务拦截器，将在代理对象执行目标方法时进行拦截，并调用其`invoke()`方法，**由事务管理器控制事务的提交与回滚**。\n\nSpring事务原理与AOP原理十分相似，都包含有**后置处理器**和**拦截器**思想，在组件创建后包装出代理对象、在代理对象执行目标方法时进行拦截，使用事务管理器控制事务的提交与回滚。\n\n详细的源码分析见文章[【Spring】Spring5 事务源码分析](https://yuyun-zhao.github.io/2021/07/05/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n","tags":["SSM","Spring"],"categories":["Spring","SSM"]},{"title":"【Spring MVC】SSM 整合配置","url":"/2021/06/03/【SpringMVC】SSM整合案例/","content":"\n![img](/images/%E3%80%90SpringMVC%E3%80%91SSM%E6%95%B4%E5%90%88%E6%A1%88%E4%BE%8B/kuangstudyfda8e4e5-ada1-4a2e-b5f5-ef679f7a85e8.png)\n\n## Maven 依赖\n\n``` xml\n<dependencies>\n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-aop</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-core</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-context</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-expression</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-beans</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-web</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-webmvc</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-tx</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.mybatis</groupId>\n        <artifactId>mybatis</artifactId>\n        <version>3.4.5</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>mysql</groupId>\n        <artifactId>mysql-connector-java</artifactId>\n        <version>5.1.6</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-jdbc</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <!--AspectJ 实现Spring AOP-->\n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-aspects</artifactId>\n        <version>5.0.2.RELEASE</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.aspectj</groupId>\n        <artifactId>aspectjweaver</artifactId>\n        <version>1.8.13</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>aopalliance</groupId>\n        <artifactId>aopalliance</artifactId>\n        <version>1.0</version>\n    </dependency>\n    \n    <!--json-->\n    <dependency>\n        <groupId>com.alibaba</groupId>\n        <artifactId>fastjson</artifactId>\n        <version>1.2.60</version>\n    </dependency>\n    \n    <!-- 数据库连接池 -->\n    <dependency>\n        <groupId>com.mchange</groupId>\n        <artifactId>c3p0</artifactId>\n        <version>0.9.2.1</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>com.mchange</groupId>\n        <artifactId>mchange-commons-java</artifactId>\n        <version>0.2.11</version>\n    </dependency>\n    \n    <!--spring整合mybatis包-->\n    <dependency>\n        <groupId>org.mybatis</groupId>\n        <artifactId>mybatis-spring</artifactId>\n        <version>2.0.4</version>\n    </dependency>\n    \n    <!--谷歌图片验证码-->\n    <dependency>\n        <groupId>com.github.penggle</groupId>\n        <artifactId>kaptcha</artifactId>\n        <version>2.3.2</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-core</artifactId>\n        <version>5.3.5</version>\n    </dependency>\n    \n    <!--junit与spring整合-->\n    <dependency>\n        <groupId>org.junit.jupiter</groupId>\n        <artifactId>junit-jupiter-api</artifactId>\n        <version>5.7.1</version>\n        <scope>test</scope>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.springframework</groupId>\n        <artifactId>spring-test</artifactId>\n        <version>5.3.5</version>\n    </dependency>\n    \n    <!--日志-->\n    <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>slf4j-api</artifactId>\n        <version>1.7.21</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>org.slf4j</groupId>\n        <artifactId>slf4j-log4j12</artifactId>\n        <version>1.7.21</version>\n    </dependency>\n    \n    <!--文件上传下载-->\n    <dependency>\n        <groupId>commons-fileupload</groupId>\n        <artifactId>commons-fileupload</artifactId>\n        <version>1.3.1</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>commons-io</groupId>\n        <artifactId>commons-io</artifactId>\n        <version>2.4</version>\n    </dependency>\n    \n    <dependency>\n        <groupId>junit</groupId>\n        <artifactId>junit</artifactId>\n        <version>4.12</version>\n        <scope>test</scope>\n    </dependency>\n</dependencies>\n\n<!--指定maven编译环境-->\n<build>\n    <plugins>\n        <plugin>\n            <artifactId>maven-compiler-plugin</artifactId>\n            <version>3.1</version>\n            <configuration>\n                <source>1.8</source>\n                <target>1.8</target>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n```\n\n为避免资源导出问题可以添加以下代码（使得普通目录下的资源文件也能导出）\n\n``` xml\n<!--静态资源导出问题-->\n<build>\n    <resources>\n        <resource>\n            <directory>src/main/java</directory>\n            <includes>\n                <include>**/*.properties</include>\n                <include>**/*.xml</include>\n            </includes>\n            <filtering>false</filtering>\n        </resource>\n        <resource>\n            <directory>src/main/resources</directory>\n            <includes>\n                <include>**/*.properties</include>\n                <include>**/*.xml</include>\n            </includes>\n            <filtering>false</filtering>\n        </resource>\n    </resources>\n</build>\n```\n\n\n\n## MyBatis 配置\n\n### mybatis-config.xml\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n                PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n                \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n    <settings>\n        <!--设置mybatis输出日志-->\n        <setting name=\"logImpl\" value=\"log4j\"/>\n        <!--开启驼峰命名模式，将数据库字段与实体类进行转换-->\n        <setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/>\n    </settings>\n    \n    <typeAliases>\n        <package name=\"com.zhao.pojo\"/>\n    </typeAliases>\n    \n    <!--\n\t若在Spring中配置SqlSessionFactory时指定了\n\t<property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\">\n\t则此处就不需要指定每一个xml路径\n\t-->\n    <mappers>\n        <mapper resource=\"mapper/BookMapper.xml\"/>\n    </mappers>\n</configuration>\n```\n\n### log4j.properties\n\n``` properties\n# Global logging configuration\nlog4j.rootLogger=ERROR, stdout\n# MyBatis logging configuration...\nlog4j.logger.priv.zwh.mall.dao=DEBUG\n# Console output...\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n\n```\n\n### database.properties\n\n``` properties\njdbc.driver=com.mysql.jdbc.Driver\n# 如果是MySQL8.0+,需要添加 &serverTimezone=Asia/Shanghai\njdbc.url=jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf8&useSSL=false\njdbc.username=root\njdbc.password=123\n```\n\n## Spring 整合 MyBatis\n\n### applicationContext.xml\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd\">\n    \n    <!--指定扫描包-->\n    <context:component-scan base-package=\"com.zhao\"/>\n    \n    <!--关联数据库配置文件-->\n    <context:property-placeholder location=\"classpath:database.properties\"/>\n    \n    <!--配置c3p0数据源-->\n    <bean id=\"pooledDataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\">\n        <!--注入四个数据库原属性-->\n        <!--配置连接池属性-->\n        <property name=\"driverClass\" value=\"${jdbc.driver}\"/>\n        <property name=\"jdbcUrl\" value=\"${jdbc.url}\"/>\n        <property name=\"user\" value=\"${jdbc.username}\"/>\n        <property name=\"password\" value=\"${jdbc.password}\"/>\n    </bean>\n\n    <!--================== 配置和MyBatis的整合=============== -->\n    \n    <!--配置Mybatis工厂，同时指定数据源，并与Mybatis完美整合-->\n    <bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\">\n        <property name=\"dataSource\" ref=\"pooledDataSource\"/>\n        <!-- 指定mybatis全局配置文件的位置 -->\n        <property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/>\n        <!-- 指定mybatis，mapper文件的位置 -->\n        <property name=\"mapperLocations\" value=\"classpath:mapper/*.xml\"></property>\n    </bean>\n    \n    <!-- 配置扫描器，将mybatis接口的实现加入到ioc容器中, mapper代理开发使用Spring自动扫描Mybatis接口并装配（@Mapper） -->\n    <bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\">\n        <!--扫描所有dao接口的实现，加入到ioc容器中 -->\n        <property name=\"basePackage\" value=\"com.zhao.dao\"></property>\n        <property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/>\n    </bean>\n\n    <!-- 配置一个可以执行批量的sqlSession -->\n    <bean id=\"sqlSession\" class=\"org.mybatis.spring.SqlSessionTemplate\">\n        <constructor-arg name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\"></constructor-arg>\n        <constructor-arg name=\"executorType\" value=\"BATCH\"></constructor-arg>\n    </bean>\n    \n    \n    <!-- ===============事务控制的配置 ================-->\n    \n    <bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n        <!-- 控制住数据源 -->\n        <property name=\"dataSource\" ref=\"pooledDataSource\"></property>\n    </bean>\n    \n    <!-- 开启基于注解的事务，使用xml配置形式的事务（必要主要的都是使用配置式） -->\n    <aop:config>\n        <!-- 切入点表达式 -->\n        <aop:pointcut expression=\"execution(* com.atguigu.crud.service..*(..))\" id=\"txPoint\"/>\n        <!-- 配置事务增强 -->\n        <aop:advisor advice-ref=\"txAdvice\" pointcut-ref=\"txPoint\"/>\n    </aop:config>\n\n    <!--配置事务增强，事务如何切入  -->\n    <tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\">\n        <tx:attributes>\n            <!-- 所有方法都是事务方法 -->\n            <tx:method name=\"*\"/>\n            <!--以get开始的所有方法  -->\n            <tx:method name=\"get*\" read-only=\"true\"/>\n        </tx:attributes>\n    </tx:advice>\n    \n</beans>\n```\n\n## Spring MVC 相关配置\n\n### springmvc-servlet.xml\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:p=\"http://www.springframework.org/schema/p\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\nhttp://www.springframework.org/schema/beans/spring-beans.xsd\nhttp://www.springframework.org/schema/context\nhttp://www.springframework.org/schema/context/spring-context.xsd\nhttp://www.springframework.org/schema/mvc\nhttp://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n    \n    <context:component-scan base-package=\"com.zhao.controller\"/>\n    \n    <!--配置视图解析器，方便页面返回-->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\">\n        <property name=\"prefix\" value=\"/WEB-INF/\"></property>\n        <property name=\"suffix\" value=\".jsp\"></property>\n    </bean>\n    \n    <!-- 两个标准配置  -->\n    <!-- 让SpringMVC不处理静态资源，否则静态资源无法找到对应的映射，会报错。将SpringMVC无法处理的请求交给Tomcat默认的Servlet处理 -->\n    <mvc:default-servlet-handler/>\n    \n    <!--\n    支持mvc注解驱动，\n\t1. 映射动态请求\t\n        在Spring中一般采用@RequestMapping注解来完成映射关系\n        要想使@RequestMapping注解生效\n        必须向上下文中注册DefaultAnnotationHandlerMapping\n        和一个AnnotationMethodHandlerAdapter实例\n        这两个实例分别在类级别和方法级别处理。\n        而annotation-driven配置帮助我们自动完成上述两个实例的注入。\n\t2. 支持SpringMVC更高级的一些功能，如JSR303校验，快捷的AJAX\n     -->\n    <mvc:annotation-driven/>\n    \n    <mvc:resources mapping=\"/js/**\" location=\"/js/\"/>\n    <mvc:resources mapping=\"/css/**\" location=\"/css/\"/>\n    <mvc:resources mapping=\"/img/**\" location=\"/img/\"/>\n    \n    <!--\n    defaultEncoding=\"UTF-8\" 是请求的编码格式，默认为iso-8859-1\n    maxUploadSize=\"5400000\" 是允许上传文件的最大值，单位为字节\n    uploadTempDir=\"fileUpload/temp\" 为上传文件的临时路径\n    -->\n    <bean id=\"multipartResolver\" class=\"org.springframework.web.multipart.commons.CommonsMultipartResolver\"\n          p:defaultEncoding=\"UTF-8\" p:maxUploadSize=\"5400000\" p:uploadTempDir=\"/img/\">\n    </bean>\n    \n    <!--拦截器-->\n    <mvc:interceptors>\n        <mvc:interceptor>\n            <mvc:mapping path=\"/root/**\"/>\n            <bean class=\"com.zhao.interceptor.AdminInterceptor\"/>\n        </mvc:interceptor>\n    </mvc:interceptors>\n</beans>\n```\n\n### web.xml\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n\n    <!--加载applicationContext.xml配置文件-->\n    <context-param>\n        <param-name>contextConfigLocation</param-name>\n        <param-value>\n            classpath:applicationContext.xml\n        </param-value>\n    </context-param>\n\n    <listener>\n        <listener-class>\n            org.springframework.web.context.ContextLoaderListener\n        </listener-class>\n    </listener>\n\n    <!--加载springmvc-->\n    <servlet>\n        <servlet-name>dispatcherServlet</servlet-name>\n        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n        <init-param>\n            <param-name>contextConfigLocation</param-name>\n            <param-value>classpath:springmvc-servlet.xml</param-value>\n            <!--若在web.xml同级目录下存在dispatcherServlet-servlet.xml文件则不需在这里显式指定 -->\n        </init-param>\n        <load-on-startup>1</load-on-startup>\n    </servlet>\n    <servlet-mapping>\n        <servlet-name>dispatcherServlet</servlet-name>\n        <url-pattern>/</url-pattern>\n    </servlet-mapping>\n\n    <!-- 字符编码过滤器，一定要放在所有过滤器之前 -->\n    <filter>\n        <filter-name>CharacterEncodingFilter</filter-name>\n        <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n        <init-param>\n            <param-name>encoding</param-name>\n            <param-value>utf-8</param-value>\n        </init-param>\n        <init-param>\n            <!-- 解决响应的乱码问题 -->\n            <param-name>forceRequestEncoding</param-name>\n            <param-value>true</param-value>\n        </init-param>\n    </filter>\n    <filter-mapping>\n        <filter-name>CharacterEncodingFilter</filter-name>\n        <url-pattern>/*</url-pattern>\n    </filter-mapping>\n\n    <!-- 4、使用Rest风格的URI，将页面普通的post请求转为指定的delete或者put请求 -->\n    <filter>\n        <filter-name>HiddenHttpMethodFilter</filter-name>\n        <filter-class>org.springframework.web.filter.HiddenHttpMethodFilter</filter-class>\n    </filter>\n    <filter-mapping>\n        <filter-name>HiddenHttpMethodFilter</filter-name>\n        <url-pattern>/*</url-pattern>\n    </filter-mapping>\n    <filter>\n        <filter-name>HttpPutFormContentFilter</filter-name>\n        <filter-class>org.springframework.web.filter.HttpPutFormContentFilter</filter-class>\n    </filter>\n    <filter-mapping>\n        <filter-name>HttpPutFormContentFilter</filter-name>\n        <url-pattern>/*</url-pattern>\n    </filter-mapping>\n\n</web-app>\n```\n\n## 测试\n\n``` java\n@RunWith(SpringJUnit4ClassRunner.class)\n@ContextConfiguration(\"classpath:applicationContext.xml\")\npublic class TestMain {\n    @Autowired\n    BookMapper bookMapper;\n    \n    @Test\n    public void test1() {\n        List<Books> books = bookMapper.queryAllBook();\n        System.out.println(books);\n    }\n}\n```\n\n``` java\n@Controller\npublic class TestController {\n    @RequestMapping(value = \"/hello\")\n    @ResponseBody\n    public String index() {\n        System.out.println(\"进入controller控制器！\");\n        return \"helloController\";\n    }\n}\n```\n\n\n","tags":["MyBatis","SSM","Spring","Spring MVC"],"categories":["MyBatis","Spring","SSM","Spring MVC"]},{"title":"【前端】AJAX","url":"/2021/06/03/【前端】AJAX/","content":"\n\n## 简介\n\n**AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。**\n\nAJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。**AJAX 不是一种新的编程语言，而是一种用于创建更好更快以及交互性更强的Web应用程序的技术。**\n\n在 2005 年，Google 通过其 Google Suggest 使 AJAX 变得流行起来。Google Suggest能够自动帮你完成搜索单词。Google Suggest 使用 AJAX 创造出动态性极强的 web 界面：当您在谷歌的搜索框输入关键字时，JavaScript 会把这些字符发送到服务器，然后服务器会返回一个搜索建议的列表。\n\n传统的网页(即不用AJAX技术的网页)，想要更新内容或者提交一个表单，都需要重新加载整个网页。而使用AJAX技术的网页，通过在后台服务器进行少量的数据交换，就可以实现异步局部更新。使用AJAX，用户可以创建接近本地桌面应用的直接、高可用、更丰富、更动态的Web用户界面。\n\n## jQuery.ajax\n\n- AJAX的核心是XMLHttpRequest对象(XHR)。XHR为向服务器发送请求和解析服务器响应提供了接口。能够以异步方式从服务器获取新数据。\n- jQuery 提供多个与 AJAX 有关的方法。\n- 通过 jQuery AJAX 方法，您能够使用 HTTP Get 和 HTTP Post 从远程服务器上请求文本、HTML、XML 或 JSON – 同时您能够把这些外部数据直接载入网页的被选元素中。\n- jQuery AJAX本质就是 XMLHttpRequest，对他进行了封装，方便调用！\n\n``` js\njQuery.ajax(...)\n       部分参数：\n              url：请求地址\n             type：请求方式，GET、POST（1.9.0之后用method）\n          headers：请求头\n             data：要发送的数据\n      contentType：即将发送信息至服务器的内容编码类型(默认: \"application/x-www-form-urlencoded; charset=UTF-8\")\n            async：是否异步\n          timeout：设置请求超时时间（毫秒）\n       beforeSend：发送请求前执行的函数(全局)\n         complete：完成之后执行的回调函数(全局)\n          success：成功之后执行的回调函数(全局)\n            error：失败之后执行的回调函数(全局)\n          accepts：通过请求头发送给服务器，告诉服务器当前客户端课接受的数据类型\n         dataType：将服务器端返回的数据转换成指定类型\n            \"xml\": 将服务器端返回的内容转换成xml格式\n           \"text\": 将服务器端返回的内容转换成普通文本格式\n           \"html\": 将服务器端返回的内容转换成普通文本格式，在插入DOM中时，如果包含JavaScript标签，则会尝试去执行。\n         \"script\": 尝试将返回值当作JavaScript去执行，然后再将服务器端返回的内容转换成普通文本格式\n           \"json\": 将服务器端返回的内容转换成相应的JavaScript对象\n          \"jsonp\": JSONP 格式使用 JSONP 形式调用函数时，如 \"myurl?callback=?\" jQuery 将自动替换 ? 为正确的函数名，以执行回调函数\n```\n\najax常用参数：\n\n\n``` js\n$.ajax({\n    url: \"http://www.hzhuti.com\",    //请求的url地址\n    dataType: \"json\",   //返回格式为json\n    async: true, //请求是否异步，默认为异步，这也是ajax重要特性\n    data: { \"id\": \"value\" },    //参数值\n    type: \"GET\",   //请求方式\n    beforeSend: function() {\n        //请求前的处理\n    },\n    success: function(req) {\n        //请求成功时处理\n    },\n    complete: function() {\n        //请求完成的处理\n    },\n    error: function() {\n        //请求出错处理\n    }\n});\n```\n\n<!-- More -->\n\n## 使用案例\n\n配置文件\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        https://www.springframework.org/schema/context/spring-context.xsd\n        http://www.springframework.org/schema/mvc\n        https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n    <!-- 自动扫描指定的包，下面所有注解类交给IOC容器管理 -->\n    <context:component-scan base-package=\"com.zhao.controller\"/>\n    <mvc:default-servlet-handler />\n    <mvc:annotation-driven />\n    <!-- 视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n          id=\"internalResourceViewResolver\">\n        <!-- 前缀 -->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n        <!-- 后缀 -->\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n</beans>\n```\n\n编写一个AjaxController\n\n``` java\n@RestController\npublic class AjaxController {\n    @RequestMapping(\"/a1\")\n    public List<User> ajax1(){\n        List<User> list = new ArrayList<User>();\n        list.add(new User(\"zhangsan1\",3,\"男\"));\n        list.add(new User(\"zhangsan2\",3,\"男\"));\n        list.add(new User(\"zhangsan3\",3,\"男\"));\n        return list; //由于@RestController注解，将list转成json格式返回\n    }\n}\n```\n\n前端页面\n\n``` html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n    <title>Title</title>\n</head>\n<body>\n<input type=\"button\" id=\"btn\" value=\"获取数据\"/>\n<table width=\"80%\" align=\"center\">\n    <tr>\n        <td>姓名</td>\n        <td>年龄</td>\n        <td>性别</td>\n    </tr>\n    <tbody id=\"content\">\n    </tbody>\n</table>\n<script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"></script>\n<script>\n    $(function () {\n        $(\"#btn\").click(function () {\n            $.post(\"${pageContext.request.contextPath}/a2\",function (data) {\n                console.log(data)\n                var html=\"\";\n                for (var i = 0; i <data.length ; i++) {\n                    html+= \"<tr>\" +\n                        \"<td>\" + data[i].name + \"</td>\" +\n                        \"<td>\" + data[i].age + \"</td>\" +\n                        \"<td>\" + data[i].sex + \"</td>\" +\n                        \"</tr>\"\n                }\n                $(\"#content\").html(html);\n            });\n        })\n    })\n</script>\n</body>\n</html>\n```\n\n\n\n","tags":["前端"],"categories":["前端"]},{"title":"【Spring MVC】Spring MVC","url":"/2021/06/03/【SpringMVC】SpringMVC/","content":"\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/kuangstudyfda8e4e5-ada1-4a2e-b5f5-ef679f7a85e8.png)\n\n## 回顾MVC\n\n### 什么是MVC\n\n- MVC是模型(Model)、视图(View)、控制器(Controller)的简写，是一种软件设计规范\n- 是将业务逻辑、数据、显示分离的方法来组织代码\n- MVC主要作用是**降低了视图与业务逻辑间的双向偶合**\n- MVC不是一种设计模式，**MVC是一种架构模式**\n\n**Model（模型）**：数据模型，提供要展示的数据，因此包含数据和行为，可以认为是领域模型或JavaBean组件（包含数据和行为），不过现在一般都分离开来：Value Object（数据Dao） 和 服务层（行为Service）。也就是模型提供了模型数据查询和模型数据的状态更新等功能，包括数据和业务。\n\n**View（视图）**：负责进行模型的展示，一般就是我们见到的用户界面，客户想看到的东西。\n\n**Controller（控制器）**：接收用户请求，委托给模型进行处理（状态改变），处理完毕后把返回的模型数据返回给视图，由视图负责展示。 也就是说控制器做了个调度员的工作。\n\n**最典型的MVC就是JSP + servlet + javabean的模式。**\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/kuangstudy5989b959-a64d-4469-952f-d23699b0bad7.png)\n\n<!-- More -->\n\n### MVC框架要做哪些事\n\n- 将url映射到java类或java类的方法\n- 封装用户提交的数据\n- 处理请求—调用相关的业务处理—封装响应数据\n- 将响应的数据进行渲染 .jsp / html 等表示层数据\n\n**说明：**\n\n 常见的服务器端MVC框架有：Struts、Spring MVC、ASP.NET MVC、Zend Framework、JSF；常见前端MVC框架：vue、angularjs、react、backbone；由MVC演化出了另外一些模式如：MVP、MVVM 等等….\n\n## Spring MVC 简介\n\n### 概述\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/kuangstudyfda8e4e5-ada1-4a2e-b5f5-ef679f7a85e8.png)\n\n**SpringMVC是Spring Framework的一部分，是基于Java实现MVC的轻量级Web框架。**\n\n查看官方文档：https://docs.spring.io/spring/docs/5.2.0.RELEASE/spring-framework-reference/web.html#spring-web\n\nSpringMVC的特点：\n\n1. 轻量级，简单易学\n2. 高效 , 基于请求响应的MVC框架\n3. 与Spring兼容性好，无缝结合\n4. 约定优于配置\n5. 功能强大：RESTful、数据验证、格式化、本地化、主题等\n6. 简洁灵活\n\n### 中心控制器\n\n Spring的web框架围绕**DispatcherServlet**[ 调度Servlet ] 设计。 DispatcherServlet的作用是将请求分发到不同的处理器。从Spring 2.5开始，使用Java 5或者以上版本的用户可以采用基于注解的Controller声明方式。\n\n Spring MVC框架像许多其他MVC框架一样， **以请求为驱动** , **围绕一个中心Servlet分派请求及提供其他功能**，**DispatcherServlet是一个实际的Servlet (它继承自HttpServlet 基类)**。\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/kuangstudyc49f3d6f-e0c6-4228-9bd7-6a40400c3bd4.png)\n\n 当发起请求时被前置的控制器拦截到请求，根据请求参数生成代理请求，找到请求对应的实际控制器，控制器处理请求，创建数据模型，访问数据库，将模型响应给中心控制器，控制器使用模型与视图渲染视图结果，将结果返回给中心控制器，再将结果返回给请求者。\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/kuangstudy00854e07-7eac-476c-a9dd-dcebb7ac0b89.png)\n\n### Spring MVC 执行原理\n\n![img](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/kuangstudy0214fd0a-0df0-4910-a467-5b7d61712868.png)\n\n图为SpringMVC的一个较完整的流程图，实线表示SpringMVC框架提供的技术，不需要开发者实现，虚线表示需要开发者实现。\n\n**简要分析执行流程**\n\nDispatcherServlet表示前置控制器，是整个SpringMVC的控制中心。用户发出请求，DispatcherServlet接收请求并拦截请求。\n\n假设请求的url为 : http://localhost:8080/SpringMVC/hello **该url可拆分成三部分：**\n\n- [http://localhost:8080服务器域名](http://localhost:8080服务器域名/)\n- SpringMVC部署在服务器上的web站点（项目名）\n- hello表示控制器\n\n通过分析，如上url表示为：请求位于服务器localhost:8080上的SpringMVC站点的hello控制器。\n\n- HandlerMapping为处理器映射。DispatcherServlet调用HandlerMapping,HandlerMapping根据请求url查找Handler。\n- HandlerExecution表示具体的Handler,其主要作用是根据url查找控制器，如上url被查找控制器为：hello。\n- HandlerExecution将解析后的信息传递给DispatcherServlet,如解析控制器映射等。\n- HandlerAdapter表示处理器适配器，其按照特定的规则去执行Handler。\n- Handler让具体的Controller执行。\n- Controller将具体的执行信息返回给HandlerAdapter,如ModelAndView。\n- HandlerAdapter将视图逻辑名或模型传递给DispatcherServlet。\n- DispatcherServlet调用视图解析器(ViewResolver)来解析HandlerAdapter传递的逻辑视图名。\n- 视图解析器将解析的逻辑视图名传给DispatcherServlet。\n- DispatcherServlet根据视图解析器解析的视图结果，调用具体的视图。\n- 最终视图呈现给用户。\n\n## Hello Spring MVC\n\n### 配置web.xml\n\n注册DispatcherServlet\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n\n    <!--1.注册DispatcherServlet-->\n    <servlet>\n        <servlet-name>springmvc</servlet-name>\n        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n        <!--关联一个springmvc的配置文件:【servlet-name】-servlet.xml-->\n        <!--如果不指定，默认去找/WEB-INF/xxx-servlet.xml -->\n        <init-param>\n            <param-name>contextConfigLocation</param-name>\n            <param-value>classpath:springmvc-servlet.xml</param-value>\n        </init-param>\n        <!--启动级别-1，在web服务器启动时优先启动，启动顺序，数字越小，启动越早-->\n        <load-on-startup>1</load-on-startup>\n    </servlet>\n\n    <!-- / 匹配所有的请求；（不包括.jsp）-->\n    <!-- /* 匹配所有的请求；（包括.jsp）-->\n    <servlet-mapping>\n        <servlet-name>springmvc</servlet-name>\n        <url-pattern>/</url-pattern>\n    </servlet-mapping>\n\n    <!-- 字符编码过滤器，一定要放在所有过滤器之前 -->\n    <filter>\n        <filter-name>CharacterEncodingFilter</filter-name>\n        <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n        <init-param>\n            <param-name>encoding</param-name>\n            <param-value>utf-8</param-value>\n        </init-param>\n        <init-param>\n            <!-- 解决响应的乱码问题 -->\n            <param-name>forceRequestEncoding</param-name>\n            <param-value>true</param-value>\n        </init-param>\n    </filter>\n    <filter-mapping>\n        <filter-name>CharacterEncodingFilter</filter-name>\n        <url-pattern>/*</url-pattern>\n    </filter-mapping>\n\n\n</web-app>\n```\n\n**注意点**：\n\n- `/ ` 不会匹配 .jsp\n- `/*` 匹配所有的请求，包括 .jsp\n\n`*.jsp` 由Tomcat负责处理，不需要SpringMVC拦截处理。因此常用 `/`\n\n### 原因分析\n\n所有JavaWeb项目里的web.xml都继承自Tomcat的父web.xml，其内配置了一个默认的**DefaultServlet**：\n\n```xml\n<servlet>\n    <servlet-name>defaultServlet</servlet-name>\n    <servlet-class>org.apache.catalina.servlets.DefaultServlet</servlet-class>\n    <init-param>\n        <param-name>readonly</param-name>\n        <param-value>false</param-value>\n    </init-param>\n</servlet>\n<servlet-mapping>\n    <servlet-name>defaultServlet</servlet-name>\n    <url-pattern>/</url-pattern>\n</servlet-mapping>\n```\n**DefaultServlet**是Tomcat用于处理静态资源（除了jsp和servlet之外都是静态资源）的处理器，当**DefaultServlet**判断得知url中访问的是静态资源文件时，就会直接去服务器目录下找该资源是否存在。其配置了`url-pattern：/`\n\n而SpringMVC中我们同样配置了`url-pattern：/`，因此会覆盖Tomcat中的DefaultServlet，使得静态资源不能被Tomcat里的DefaultServlet所处理，只能被我们配置的DispatcherServlet拦截处理。静态资源被DispatcherServlet拦截时会判断哪个方法的`@RequestMapping`是这个静态资源，显然并不能找到，因此无法正常显示。\n\n`*.jsp` 处理问题：Tomcat里的web.xml中配置了对jsp文件的处理，该处理器将处理jsp文件：\n\n``` xml\n<servlet-mapping>\n    <servlet-name>jsp</servlet-name>\n    <url-pattern>*.jsp</url-pattern>\n    <url-pattern>*.jspx</url-pattern>\n</servlet-mapping>\n```\n\n若我们在SpringMVC配置中只添加`url-pattern：/`而没有添加`url-pattern：*.jsp`，则将只覆盖父web.xml里的`url-pattern：/`（处理静态资源），并没有覆盖`url-pattern：*.jsp`。因此这种情况下，遇到jsp文件，则由Tomcat里的默认处理器处理；遇到普通请求，由DispatcherServlet处理；遇到静态资源，因覆盖了Tomcat，则无法处理。\n\n若配置`url-pattern：/*`，则所有请求资源都将被拦截处理。\n\n因此，若想在使用Spring MVC的**DispatcherServlet**的同时仍能处理静态资源，则需要添加：\n\n```xml\n<mvc:default-servlet-handler/>\n```\n\n其能将Spring MVC无法处理的请求交给Tomcat默认的Servlet处理，让Spring MVC不处理静态资源。\n\n### 添加 Spring MVC 配置文件\n\n- 让IoC的注解生效\n- 静态资源过滤 ：HTML，JS ，CSS ，图片，视频 …..\n- MVC的注解驱动\n- 配置视图解析器\n\n在resource目录下添加SpringMVC的配置文件，名称：**springmvc-servlet.xml** : [servletname]-servlet.xml。配置的形式与Spring容器配置基本类似，为了支持基于注解的IoC，设置了自动扫描包的功能，具体配置信息如下：\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        https://www.springframework.org/schema/context/spring-context.xsd\n        http://www.springframework.org/schema/mvc\n        https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n    \n    <!-- 自动扫描包，让指定包下的注解生效,由IoC容器统一管理 -->\n    <context:component-scan base-package=\"com.zhao.controller\"/>\n    \n    <!-- 让SpringMVC不处理静态资源，否则静态资源无法找到对应的映射，会报错。将SpringMVC无法处理的请求交给Tomcat默认的Servlet处理 -->\n    <mvc:default-servlet-handler/>\n    \n    <!--\n    支持mvc注解驱动，\n\t1. 映射动态请求\t\n        在Spring中一般采用@RequestMapping注解来完成映射关系\n        要想使@RequestMapping注解生效\n        必须向上下文中注册DefaultAnnotationHandlerMapping\n        和一个AnnotationMethodHandlerAdapter实例\n        这两个实例分别在类级别和方法级别处理。\n        而annotation-driven配置帮助我们自动完成上述两个实例的注入。\n\t2. 支持SpringMVC更高级的一些功能，如JSR303校验，快捷的AJAX\n     -->\n    <mvc:annotation-driven/>\n    \n    <!-- 视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n          id=\"internalResourceViewResolver\">\n        <!-- 前缀 -->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n        <!-- 后缀 -->\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n</beans>\n```\n\n在视图解析器中我们把所有的视图都存放在/WEB-INF/目录下，这样可以保证视图安全，因为这个目录下的文件，客户端不能直接访问。\n\n`<mvc:default-servlet-handler />`将在SpringMVC上下文中定义一个`DefaultServletHttpRequestHandle`：\n\n- 它会对进入DispatcherSevlet的请求进行筛查，如果发现是没有经过映射的请求，就将该请求交由WEB应用服务器默认的Servlet处理（将SpringMVC无法处理的请求交给Tomcat默认的Servlet处理）\n- 会**过滤静态资源文件**：如果不是静态资源的请求，才由DispatcherServlet继续处理。\n\n### 创建 Controller\n\n编写一个Java控制类： com.zhao.controller.HelloController\n\n``` java\npackage com.zhao.controller;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.ui.Model;\nimport org.springframework.web.bind.annotation.RequestMapping;\n\n@Controller\n@RequestMapping(\"/HelloController\")\npublic class HelloController {\n    //真实访问地址 : 项目名/HelloController/hello\n    @RequestMapping(\"/hello\")\n    public String sayHello(Model model){\n        //向模型中添加属性msg与值，可以在JSP页面中取出并渲染\n        model.addAttribute(\"msg\",\"hello,SpringMVC\");\n        //web-inf/jsp/hello.jsp\n        return \"hello\";\n    }\n}\n```\n\n- `@Controller`是为了让Spring IoC容器初始化时自动扫描到；\n- `@RequestMapping`是为了映射请求路径，这里因为类与方法上都有映射所以访问时应该是`/HelloController/hello`；\n- 方法中声明Model类型的参数是为了把Action中的数据带到视图中；\n- 方法返回的结果是视图的名称`hello`，加上配置文件中的前后缀变成`WEB-INF/jsp/hello.jsp`\n\n### 创建视图层\n\n在WEB-INF/ jsp目录中创建hello.jsp，视图可以直接取出并展示从Controller带回的信息；可以通过EL表示取出Model中存放的值，或者对象；\n\n``` jsp\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n    <title>SpringMVC</title>\n</head>\n<body>\n    ${msg}\n</body>\n</html>\n```\n\n### 小结\n\n实现步骤：\n\n1. 新建一个web项目\n2. 导入相关jar包\n3. 编写web.xml , 注册DispatcherServlet\n4. 编写springmvc配置文件\n5. 创建对应的控制类Controller\n6. 最后完善前端视图和Controller之间的对应\n7. 测试运行调试.\n\n使用SpringMVC必须配置的三大件：\n\n**处理器映射器、处理器适配器、视图解析器**\n\n通常，我们只需要**手动配置视图解析器**，而**处理器映射器**和**处理器适配器**只需要开启**注解驱动**即可，而省去了大段的xml配置\n\n## 常用注解\n\n### 汇总\n\n``` java\n//响应的请求必须为POST，且要带上名为username的参数，不带就报错\n@RequestMapping(value = \"/test\", method = {RequestMethod.POST}, params = {\"username\"})\npublic String test(\n    @RequestParam(value = \"username\", required = false, defaultValue = \"zhangsan\") String username,\n    @RequestHeader(value = \"User-Agent\", required = false, defaultValue = \" \") String userAgent, \n    @CookieValue(\"JSESSIONID\", required = false, defaultValue = \" \") String jid) {\n    // ....\n    return \"success\";\n}\n```\n\n### @RequestMapping\n\n`@RequestMapping`用于请求映射，执行匹配的方法\n\n**method**参数：限定请求方式\n\n``` java\n//映射访问路径,必须是POST请求才能访问到\n@RequestMapping(value = \"/test\", method = {RequestMethod.POST})\npublic String test(Model model){\n    model.addAttribute(\"msg\", \"hello!\");\n    return \"hello\";\n}\n```\n\n**params**参数：解析发送请求里的参数\n\n``` java\n//发送的请求中必须带上名为username的参数，不带就报错\n@RequestMapping(value = \"/test\", params = {\"username\"})\npublic String test(){\n\treturn \"hello\";\n}\n```\n\n**Ant风格路径匹配**\n\n模糊和精确多个匹配情况下，精确匹配优先\n\n- ？：匹配一个字符，0个和多个都不行\n- \\*：匹配任意多个字符，优先级低于?  也可以匹配一层路径。\n- \\*\\*：匹配任意层路径，优先级低于\\*\n\n``` java\n@RequestMapping(\"/test/antTest0?\")\n@RequestMapping(\"/test/antTest0*\")\n@RequestMapping(\"/test/a*/antTest0*\")\n@RequestMapping(\"/test/a/*antTest0*\")\n@RequestMapping(\"/test/**/antTest0\")\n```\n\n### @RequestParam\n\n`@RequestParam`用于获取请求参数。`@RequestParam(\"user\") String username`效果等价于 `username = request.getParameter(\"user\")`\n\n该注解可设置的参数：\n\n``` java\n@RequestMapping(\"/test\")\npublic String test(@RequestParam(\"username\", required=false, defaultValue=\"zhangsan\") String name){\n    System.out.println(name);\n    return \"hello\";\n}\n```\n\n### @RequestHeader\n\n`@RequestHeader`用于获取请求头中的值。`@RequestHeader(\"User-Agent\") String userAgent`效果等价于 `userAgent = request.getHeader(\"User-Agent\")`。\n\n``` java\n@RequestMapping(\"/test\")\npublic String test(@RequestParam(\"username\") String name, @RequestHeader(value = \"User-Agent\", required = false, defaultValue = \" \") String userAgent){\n    System.out.println(userAgent);\n    return \"hello\";\n}\n```\n\n### @CookieValue\n\n`@CookieValue`可用于获取Cookie值\n\n```java\n@RequestMapping(value = \"/test\")\npublic String test(@CookieValue(\"JSESSIONID\", required = false, defaultValue = \" \") String jid) {\n    // ....\n    return \"success\";\n}\n```\n\n\n\n### @PathVariable\n\n`@PathVariable`用于解析RESTful风格中的参数：\n\n```java\n@RequestMapping(\"/commit/{p1}/{p2}\")\npublic String index(@PathVariable(\"p1\") int p1, @PathVariable(\"p2\") int p2, Model model){\n    int result = p1+p2;\n    //Spring MVC会自动实例化一个Model对象用于向视图中传值\n    model.addAttribute(\"msg\", \"结果：\"+result);\n    //返回视图位置\n    return \"hello\";\n}\n```\n## RESTful\n\n### 概念\nREST：Representational State Transfer，直译过来**表现层状态转换**（同一个 URL 可以根据需求被被转换成不同的状态，例如 GET/PUT/POST/DELETE），是目前最流行的一种互联网软件架构。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。\n\n**资源**（Resources）：网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的存在。可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的 URI 。要获取这个资源，访问它的URI就可以，因此 URI 即为每一个资源的独一无二的识别符。\n\n**表现层**（Representation）：把资源具体呈现出来的形式，叫做它的表现层（Representation）。比如，文本可以用 txt 格式表现，也可以用 HTML 格式、XML 格式、JSON 格式表现，甚至可以采用二进制格式。\n\n**状态转化**（State Transfer）：每发出一个请求，就代表了客户端和服务器的一次交互过程。HTTP协议，是一个无状态协议，即所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生“状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是 “表现层状态转化”。具体说，就是 HTTP 协议里面，四个表示操作方式的动词：`GET`、`POST`、`PUT`、`DELETE`。它们分别对应四种基本操作：\n\n- `GET `用来获取资源\n- `POST `用来新建资源\n- `PUT `用来更新资源\n- `DELETE `用来删除资源\n\n满足REST设计风格的程序或接口我们称之为RESTful(从单词字面来看就是一个形容词)。所以RESTful API 就是满足REST架构风格的接口。它不是标准也不是协议，只是一种风格，基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。\n\n### 功能\n\n**传统方式操作资源**：通过不同的参数来实现不同的效果！方法单一，post 和 get\n\n- http://127.0.0.1/item/queryItem.action?id=1 查询，GET\n- http://127.0.0.1/item/saveItem.action 新增，POST\n- http://127.0.0.1/item/updateItem.action 更新，POST\n- http://127.0.0.1/item/deleteItem.action?id=1 删除，GET或POST\n\n**使用RESTful操作资源** ： 可以通过不同的请求方式来实现不同的效果！如下：请求地址一样，但是功能可以不同！\n\n- http://127.0.0.1/item/1 查询，GET\n- http://127.0.0.1/item 新增，POST\n- http://127.0.0.1/item 更新，PUT\n- http://127.0.0.1/item/1 删除，DELETE\n\n### 使用\n\n在SpringMVC中可以使用 `@PathVariable` 注解，让方法参数的值对应绑定到一个URI模板变量上。\n\n```java\n@Controller\npublic class RestFulController {\n    //映射访问路径\n    @RequestMapping(\"/commit/{p1}/{p2}\")\n    public String index(@PathVariable(\"p1\") int p1, @PathVariable(\"p2\") int p2, Model model){\n        int result = p1+p2;\n        //Spring MVC会自动实例化一个Model对象用于向视图中传值\n        model.addAttribute(\"msg\", \"结果：\"+result);\n        //返回视图位置\n        return \"test\";\n    }\n}\n```\n\n**使用method属性指定请求类型**\n\n`@RequestMapping` 注解能够处理 HTTP 请求的方法，约束请求的类型，可以收窄请求范围。指定请求谓词的类型如`GET`, `POST`, `HEAD`, `OPTIONS`, `PUT`, `PATCH`, `DELETE`, `TRACE`等\n\n``` java\n//映射访问路径,必须是POST请求才能访问到\n@RequestMapping(value = \"/hello\", method = {RequestMethod.POST})\npublic String index2(Model model){\n    model.addAttribute(\"msg\", \"hello!\");\n    return \"test\";\n}\n```\n\n**所有的地址栏请求默认都会是 HTTP GET 类型的。**\n\n方法级别的注解变体有如下几个： 组合注解\n\n``` java\n@GetMapping\n@PostMapping\n@PutMapping\n@DeleteMapping\n@PatchMapping\n```\n\n`@GetMapping` 是一个组合注解，它所扮演的是 `@RequestMapping(method = RequestMethod.GET) `的一个快捷方式。\n\n**HiddenHttpMethodFilter**：浏览器 form 表单只支持 `GET` 与 `POST `请求，而`DELETE`、`PUT `等 method 并不支持，Spring3.0 添加了一个过滤器，可以将这些请求转换为标准的 http 方法，使得支持 `GET`、`POST`、`PUT `与`DELETE `请求。使用时需要在web.xml中添加`HiddenHttpMethodFilter`：\n\n``` xml\n<!-- 使用REST风格的URI，将页面的POST请求转换为指定的DELETE或PUT请求 -->\n<filter>\n\t<filter-name>HiddenHttpMethodFilter</filter-name>\n    <filter-class>org.springframework.web.filter.HiddenHttpMethodFilter</filter-class>\n</filter>\n<filter-mapping>\n\t<filter-name>HiddenHttpMethodFilter</filter-name>\n    <url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n\n添加**HiddenHttpMethodFilter**后，若想发送`DELETE`或`PUT`请求，则需要创建一个表单，在表单项中携带一个`_method`参数，这个参数的值可以设置为`DELETE`或`PUT`。\n\n``` html\n<form action=\"commit/1\" method=\"post\">\n    <input name=\"_method\" value=\"DELETE\"/>\n    <input type=\"submit\" value=\"删除1号\"/>\n</form>\n```\n\n**注意**：在Tomcat 8.0以上版本，使用REST风格转发到jsp页面时，因为默认的jsp文件不支持`DELETE`和`PUT`这种请求，因此有异常，无法正常显示。此时需要在jsp文件头添加：`isErrorPage=\"true\"`\n\n```jsp\n<%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\"\n    pageEncoding=\"UTF-8\" isErrorPage=\"true\" %>\n```\n\n**HiddenHttpMethodFilter源码分析**\n\n`HiddenHttpMethodFilter`类里的拦截方法具体如下：\n\n```java\nprotected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException {\n    \n    // 首先获取传入参数 methodParam = _method 里的值，也就是DELETE\n    String paramValue = request.getParameter(this.methodParam);\n    \n    // 判断当前表单是否是POST提交\n    if (\"POST\".equals(request.getMethod()) && StringUtils.hasLength(paramValue)) {\n        // DELETE变成大写\n        String method = paramValue.toUpperCase(Locale.ENGLISH);\n        \n        // 创建包装后的Request类型对象wrapper，该对象的getMethod()方法被重写了，调用时将返回DELETE\n        HttpServletRequest wrapper = new HiddenHttpMethodFilter.HttpMethodRequestWrapper(request, method);\n        \n        // 将包装后的Request传递给了过滤器链，后续调用getMethod()获取到的都是DELETE\n        filterChain.doFilter(wrapper, response);\n    } else {\n        filterChain.doFilter(request, response);\n    }\n\n}\n```\n\nwrapper对象被重写的`getMethod()`方法将直接返回`_method`里的值`DELETE`。并且包装后的wrapper对象被传递到了过滤器链中，从而后续的过滤器在调用此wrapper对象的`getMethod()`时将获取到`DELETE`。\n\n![image-20210715100050957](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/image-20210715100050957.png)\n\n## 结果跳转方式\n\n### ModelAndView\n\n设置ModelAndView对象，根据view的名称和视图解析器跳到指定的页面。\n\n页面 : {视图解析器前缀} + viewName +{视图解析器后缀}\n\n``` xml\n<!-- 视图解析器 -->\n<bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n      id=\"internalResourceViewResolver\">\n    <!-- 前缀 -->\n    <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n    <!-- 后缀 -->\n    <property name=\"suffix\" value=\".jsp\" />\n</bean>\n```\n\n对应的Controller类\n\n``` java\npublic class ControllerTest1 implements Controller {\n    public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception {\n        //返回一个模型视图对象\n        ModelAndView mv = new ModelAndView();\n        mv.addObject(\"msg\",\"ControllerTest1\");\n        mv.setViewName(\"test\");\n        return mv;\n    }\n}\n```\n\n### ServletAPI\n\n通过设置ServletAPI，不需要视图解析器。\n\n- 通过HttpServletResponse进行输出\n- 通过HttpServletResponse实现重定向\n- 通过HttpServletResponse实现转发\n\n``` java\n@Controller\npublic class ResultGo {\n    @RequestMapping(\"/result/t1\")\n    public void test1(HttpServletRequest req, HttpServletResponse rsp) throws IOException {\n        rsp.getWriter().println(\"Hello,Spring BY servlet API\");\n    }\n    \n    @RequestMapping(\"/result/t2\")\n    public void test2(HttpServletRequest req, HttpServletResponse rsp) throws IOException {\n        rsp.sendRedirect(\"/index.jsp\");\n    }\n    \n    @RequestMapping(\"/result/t3\")\n    public void test3(HttpServletRequest req, HttpServletResponse rsp) throws Exception {\n        //转发\n        req.setAttribute(\"msg\",\"/result/t3\");\n        req.getRequestDispatcher(\"/WEB-INF/jsp/test.jsp\").forward(req,rsp);\n    }\n}\n```\n\n### SpringMVC\n\n**通过SpringMVC来实现转发和重定向 - 无需视图解析器；**\n\n测试前，需要将视图解析器注释掉\n\n``` java\n@Controller\npublic class ResultSpringMVC {\n    @RequestMapping(\"/rsm/t1\")\n    public String test1(){\n        //转发\n        return \"/index.jsp\";\n    }\n    \n    @RequestMapping(\"/rsm/t2\")\n    public String test2(){\n        //转发二\n        return \"forward:/index.jsp\";\n    }\n    \n    @RequestMapping(\"/rsm/t3\")\n    public String test3(){\n        //重定向\n        return \"redirect:/index.jsp\";\n    }\n}\n```\n\n**通过SpringMVC来实现转发和重定向 - 有视图解析器；**\n\n重定向不需要视图解析器，本质就是重新请求到一个新地方，所以注意路径问题.\n\n``` java\n@Controller\npublic class ResultSpringMVC2 {\n    @RequestMapping(\"/rsm2/t1\")\n    public String test1(){\n        //转发\n        return \"test\";\n    }\n    \n    @RequestMapping(\"/rsm2/t2\")\n    public String test2(){\n        //重定向\n        return \"redirect:/index.jsp\";\n        //return \"redirect:hello.do\"; //hello.do为另一个请求/\n    }\n}\n```\n\n## 数据处理\n\n### 处理提交数据\n\n**1、提交的域名称和处理方法的参数名一致**\n\n提交数据 : http://localhost:8080/hello?name=zhangsan\n\n``` java\n@RequestMapping(\"/hello\")\npublic String hello(String name){\n    System.out.println(name);\n    return \"hello\";\n}\n```\n\n**2、提交的域名称和处理方法的参数名不一致**\n\n提交数据 : http://localhost:8080/hello?username=zhangsan\n\n使用`@RequestParam(\"username\")`\n\n``` java\n// : username提交的域的名称\n@RequestMapping(\"/hello\")\npublic String hello(@RequestParam(\"username\") String name){\n    System.out.println(name);\n    return \"hello\";\n}\n```\n\n**3、提交的是一个对象**\n\n要求提交的表单域和对象的属性名一致，参数使用对象即可(SpringMVC自动封装)\n\n实体类\n\n```java\npublic class User {\n    private int id;\n    private String name;\n    private int age;\n    \n    //构造\n    //get/set\n    //tostring()\n}\n```\n\n提交数据 : http://localhost:8080/mvc04/user?name=zhangsan&id=1&age=15\n\n处理方法 :\n\n```java\n@RequestMapping(\"/user\")\npublic String user(User user){\n    System.out.println(user);    \n    return \"hello\";\n}\n```\n\n后台输出 : User { id=1, name=’zhangsan’, age=15 }\n\n说明：如果使用对象的话，前端传递的参数名和对象名必须一致，否则就是null。\n\n### 数据显示到前端\n\n**第一种 : 通过ModelAndView**\n\n``` java\npublic class ControllerTest1 implements Controller {\n    public ModelAndView handleRequest(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception {\n        //返回一个模型视图对象\n        ModelAndView mv = new ModelAndView();\n        mv.addObject(\"msg\",\"ControllerTest1\");\n        mv.setViewName(\"test\");\n        return mv;\n    }\n}\n```\n\n**第二种 : 通过ModelMap**\n\n``` java\n@RequestMapping(\"/hello\")\npublic String hello(@RequestParam(\"username\") String name, ModelMap model){\n    //封装要显示到视图中的数据\n    //相当于req.setAttribute(\"name\",name);\n    model.addAttribute(\"name\",name);\n    System.out.println(name);\n    return \"hello\";\n}\n```\n\n**第三种 : 通过Model**\n\n``` java\n@RequestMapping(\"/ct2/hello\")\npublic String hello(@RequestParam(\"username\") String name, Model model){\n    //封装要显示到视图中的数据\n    //相当于req.setAttribute(\"name\",name);\n    model.addAttribute(\"msg\",name);\n    System.out.println(name);\n    return \"test\";\n}\n```\n\n**对比** \n\n- `Model `是一个接口，只有寥寥几个方法只适合用于储存数据，简化了新手对于`Model`对象的操作和理解；\n- `ModelMap `继承了 `LinkedMap `，除了实现了自身的一些方法，同样的继承 `LinkedMap `的方法和特性；\n- `ModelAndView `可以在储存数据的同时，可以进行设置返回的逻辑视图，进行控制展示层的跳转。\n\n可以在方法处传入`Map`、`Model`或`ModelMap`，在这些参数中保存的数据都会放到**请求域（requestScope）**中。使用`Map`，`Model `和`ModelMap`本质上是使用了Spring的**BindingAwareModelMap**在工作，相当于在`BindingAwareModelMap`中保存的数据都会放到请求域中。SpringMVC在运行时拥有唯一的一个`BindingAwareModelMap`对象，各个方法中获取到的`Map/ModelMap`都会被转换成同一个该对象，从而可以做到多个方法中的数据共享。\n\n![image-20210715151056836](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/image-20210715151056836.png)\n\n### @ModelAttribute\n\n被`@ModelAttribute`注解修饰的方法会在所有请求执行前执行，在该方法内可以从数据库获取到pojo对象，如下图中book对象，并将其添加到map中，这样其他请求方法在执行时就能从中获取到该对象。该注解在整合MyBatis后较少使用。\n\n> https://www.bilibili.com/video/BV1d4411g7tv?t=591&p=155\n\n![image-20210715154723475](/images/%E3%80%90SpringMVC%E3%80%91SpringMVC/image-20210715154723475.png)\n\n### 乱码问题\n\nSpringMVC给我们提供了一个过滤器，可以在web.xml中配置。\n\n``` xml\n<filter>\n    <filter-name>encoding</filter-name>\n    <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n    <init-param>\n        <param-name>encoding</param-name>\n        <param-value>utf-8</param-value>\n    </init-param>\n</filter>\n<filter-mapping>\n    <filter-name>encoding</filter-name>\n    <url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n\n注意：<url-pattern>里需要写上/*而非/，否则.jsp文件无法经过该过滤器，因此无法解决.jsp文件的乱码问题。\n\n## Controller 返回 JSON 数据\n\nJSON解析工具：\n\n- jackson\n- fastjson（阿里巴巴）\n\n首先使用jackson，导入jar包：\n\n``` xml\n<!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-core -->\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n    <version>2.9.8</version>\n</dependency>\n```\n\n配置web.xml\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\">\n    <!--1.注册servlet-->\n    <servlet>\n        <servlet-name>SpringMVC</servlet-name>\n        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>\n        <!--通过初始化参数指定SpringMVC配置文件的位置，进行关联-->\n        <init-param>\n            <param-name>contextConfigLocation</param-name>\n            <param-value>classpath:springmvc-servlet.xml</param-value>\n        </init-param>\n        <!-- 启动顺序，数字越小，启动越早 -->\n        <load-on-startup>1</load-on-startup>\n    </servlet>\n    <!--所有请求都会被springmvc拦截 -->\n    <servlet-mapping>\n        <servlet-name>SpringMVC</servlet-name>\n        <url-pattern>/</url-pattern>\n    </servlet-mapping>\n    <filter>\n        <filter-name>encoding</filter-name>\n        <filter-class>org.springframework.web.filter.CharacterEncodingFilter</filter-class>\n        <init-param>\n            <param-name>encoding</param-name>\n            <param-value>utf-8</param-value>\n        </init-param>\n    </filter>\n    <filter-mapping>\n        <filter-name>encoding</filter-name>\n        <url-pattern>/</url-pattern>\n    </filter-mapping>\n</web-app>\n```\n\n配置springmvc-servlet.xml\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        https://www.springframework.org/schema/context/spring-context.xsd\n        http://www.springframework.org/schema/mvc\n        https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n    <!-- 自动扫描指定的包，下面所有注解类交给IOC容器管理 -->\n    <context:component-scan base-package=\"com.zhao.controller\"/>\n    <!-- 视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n          id=\"internalResourceViewResolver\">\n        <!-- 前缀 -->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n        <!-- 后缀 -->\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n</beans>\n```\n\n假设已经存在实体类User，编写一个Controller：\n\n``` java\n@Controller\npublic class UserController {\n    @RequestMapping(value = \"/json1\", produces = \"application/json;charset=utf-8\")\n    @ResponseBody\n    public String json1() throws JsonProcessingException {\n        //创建一个jackson的对象映射器，用来解析数据\n        ObjectMapper mapper = new ObjectMapper();\n        //创建一个对象\n        User user = new User(\"zhangsan\", 3, \"男\");\n        //将我们的对象解析成为json格式\n        String str = mapper.writeValueAsString(user);\n        //由于@ResponseBody注解，这里会将str转成json格式返回；十分方便\n        return str;\n    }\n}\n```\n\n这里使用到注解`@ResponseBody`，其会将return 返回的字符串转为JSON格式\n\n注意：使用JSON时记得处理可能出现的乱码问题，解决方案：在`@RequestMapping`中设置utf-8\n\n``` java\n//produces:指定响应体返回类型和编码\n@RequestMapping(value = \"/json1\",produces = \"application/json;charset=utf-8\")\n```\n\n**乱码统一解决**\n\n上一种方法比较麻烦，如果项目中有许多请求则每一个都要添加。可以通过Spring配置统一指定，这样就不用每次都去处理乱码问题。\n\n 我们可以在springmvc的配置文件上添加一段消息StringHttpMessageConverter转换配置\n\n``` xml\n<mvc:annotation-driven>\n    <mvc:message-converters register-defaults=\"true\">\n        <bean class=\"org.springframework.http.converter.StringHttpMessageConverter\">\n            <constructor-arg value=\"UTF-8\"/>\n        </bean>\n        <bean class=\"org.springframework.http.converter.json.MappingJackson2HttpMessageConverter\">\n            <property name=\"objectMapper\">\n                <bean class=\"org.springframework.http.converter.json.Jackson2ObjectMapperFactoryBean\">\n                    <property name=\"failOnEmptyBeans\" value=\"false\"/>\n                </bean>\n            </property>\n        </bean>\n    </mvc:message-converters>\n</mvc:annotation-driven>\n```\n\n**返回json字符串统一解决**\n\n在类上直接使用 **[@RestController](https://github.com/RestController)** ，这样子，里面所有的方法都只会返回 JSON字符串了，不用再每一个方法都添加[@ResponseBody](https://github.com/ResponseBody) 。在前后端分离开发中，一般都使用 [@RestController](https://github.com/RestController) ，十分便捷。\n\n``` java\n@RestController\npublic class UserController {\n    //produces:指定响应体返回类型和编码\n    @RequestMapping(value = \"/json1\")\n    public String json1() throws JsonProcessingException {\n        //创建一个jackson的对象映射器，用来解析数据\n        ObjectMapper mapper = new ObjectMapper();\n        //创建一个对象\n        User user = new User(\"zhangsan\", 3, \"男\");\n        //将我们的对象解析成为json格式\n        String str = mapper.writeValueAsString(user);\n        //由于@RestController，这里会将str转成json格式返回；十分方便\n        return str;\n    }\n}\n```\n\n### fastJson\n\n fastjson.jar是阿里开发的一款专门用于Java开发的包，可以方便的实现JSON对象与JavaBean对象的转换，实现JavaBean对象与JSON字符串的转换，实现JSON对象与JSON字符串的转换。实现JSON的转换方法很多，最后的实现结果都是一样的。\n\nfastjson 的 pom依赖！\n\n```xml\n<dependency>    \n    <groupId>com.alibaba</groupId>\n    <artifactId>fastjson</artifactId>\n    <version>1.2.60</version>\n</dependency>\n```\n\nfastjson 三个主要的类：\n\n- 【JSONObject 代表 json 对象 】\n  - JSONObject实现了Map接口, 猜想 JSONObject底层操作是由Map实现的。\n  - JSONObject对应JSON对象，通过各种形式的get()方法可以获取JSON对象中的数据，也可利用诸如size()，isEmpty()等方法获取”键：值”对的个数和判断是否为空。其本质是通过实现Map接口并调用接口中的方法完成的。\n\n- 【JSONArray 代表 JSON对象数组】\n  - 内部是有List接口中的方法来完成操作的。\n\n- 【JSON 代表 JSONObject和JSONArray的转化】\n  - JSON类源码分析与使用\n  - 仔细观察这些方法，主要是实现json对象，json对象数组，javabean对象，json字符串之间的相互转化。\n\n**代码测试，新建一个FastJsonDemo 类**\n\n```java\npackage com.zhao.controller;\nimport com.alibaba.fastjson.JSON;\nimport com.alibaba.fastjson.JSONObject;\nimport com.zhao.pojo.User;\nimport java.util.ArrayList;\nimport java.util.List;\npublic class FastJsonDemo {\n    public static void main(String[] args) {\n        //创建一个对象\n        User user1 = new User(\"zhangsan1号\", 3, \"男\");\n        User user2 = new User(\"zhangsan2号\", 3, \"男\");\n        User user3 = new User(\"zhangsan3号\", 3, \"男\");\n        User user4 = new User(\"zhangsan4号\", 3, \"男\");\n        \n        List<User> list = new ArrayList<User>();\n        list.add(user1);\n        list.add(user2);\n        list.add(user3);\n        list.add(user4);\n        \n        System.out.println(\"*******Java对象 转 JSON字符串*******\");\n        String str1 = JSON.toJSONString(list);\n        System.out.println(\"JSON.toJSONString(list)==>\"+str1);\n        \n        String str2 = JSON.toJSONString(user1);\n        System.out.println(\"JSON.toJSONString(user1)==>\"+str2);\n        \n        System.out.println(\"\\n****** JSON字符串 转 Java对象*******\");\n        User jp_user1=JSON.parseObject(str2,User.class);\n        System.out.println(\"JSON.parseObject(str2,User.class)==>\"+jp_user1);\n        \n        System.out.println(\"\\n****** Java对象 转 JSON对象 ******\");\n        JSONObject jsonObject1 = (JSONObject) JSON.toJSON(user2);\n        System.out.println(\"(JSONObject) JSON.toJSON(user2)==>\"+jsonObject1.getString(\"name\"));\n        \n        System.out.println(\"\\n****** JSON对象 转 Java对象 ******\");\n        User to_java_user = JSON.toJavaObject(jsonObject1, User.class);\n        System.out.println(\"JSON.toJavaObject(jsonObject1, User.class)==>\"+to_java_user);\n    }\n}\n```\n\n## AJAX\n\n### 简介\n\n**AJAX = Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）。**\n\nAJAX 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。**AJAX 不是一种新的编程语言，而是一种用于创建更好更快以及交互性更强的Web应用程序的技术。**\n\n在 2005 年，Google 通过其 Google Suggest 使 AJAX 变得流行起来。Google Suggest能够自动帮你完成搜索单词。Google Suggest 使用 AJAX 创造出动态性极强的 web 界面：当您在谷歌的搜索框输入关键字时，JavaScript 会把这些字符发送到服务器，然后服务器会返回一个搜索建议的列表。\n\n传统的网页(即不用AJAX技术的网页)，想要更新内容或者提交一个表单，都需要重新加载整个网页。而使用AJAX技术的网页，通过在后台服务器进行少量的数据交换，就可以实现异步局部更新。使用AJAX，用户可以创建接近本地桌面应用的直接、高可用、更丰富、更动态的Web用户界面。\n\n### jQuery.ajax\n\n- AJAX的核心是XMLHttpRequest对象(XHR)。XHR为向服务器发送请求和解析服务器响应提供了接口。能够以异步方式从服务器获取新数据。\n- jQuery 提供多个与 AJAX 有关的方法。\n- 通过 jQuery AJAX 方法，您能够使用 HTTP Get 和 HTTP Post 从远程服务器上请求文本、HTML、XML 或 JSON – 同时您能够把这些外部数据直接载入网页的被选元素中。\n- jQuery AJAX本质就是 XMLHttpRequest，对他进行了封装，方便调用！\n\n``` js\njQuery.ajax(...)\n       部分参数：\n              url：请求地址\n             type：请求方式，GET、POST（1.9.0之后用method）\n          headers：请求头\n             data：要发送的数据\n      contentType：即将发送信息至服务器的内容编码类型(默认: \"application/x-www-form-urlencoded; charset=UTF-8\")\n            async：是否异步\n          timeout：设置请求超时时间（毫秒）\n       beforeSend：发送请求前执行的函数(全局)\n         complete：完成之后执行的回调函数(全局)\n          success：成功之后执行的回调函数(全局)\n            error：失败之后执行的回调函数(全局)\n          accepts：通过请求头发送给服务器，告诉服务器当前客户端课接受的数据类型\n         dataType：将服务器端返回的数据转换成指定类型\n            \"xml\": 将服务器端返回的内容转换成xml格式\n           \"text\": 将服务器端返回的内容转换成普通文本格式\n           \"html\": 将服务器端返回的内容转换成普通文本格式，在插入DOM中时，如果包含JavaScript标签，则会尝试去执行。\n         \"script\": 尝试将返回值当作JavaScript去执行，然后再将服务器端返回的内容转换成普通文本格式\n           \"json\": 将服务器端返回的内容转换成相应的JavaScript对象\n          \"jsonp\": JSONP 格式使用 JSONP 形式调用函数时，如 \"myurl?callback=?\" jQuery 将自动替换 ? 为正确的函数名，以执行回调函数\n```\n\najax常用参数：\n\n\n``` js\n$.ajax({\n    url: \"http://www.hzhuti.com\",    //请求的url地址\n    dataType: \"json\",   //返回格式为json\n    async: true, //请求是否异步，默认为异步，这也是ajax重要特性\n    data: { \"id\": \"value\" },    //参数值\n    type: \"GET\",   //请求方式\n    beforeSend: function() {\n        //请求前的处理\n    },\n    success: function(result) {\n        //请求成功时处理\n    },\n    complete: function() {\n        //请求完成的处理\n    },\n    error: function() {\n        //请求出错处理\n    }\n});\n```\n\n技巧：`data`属性中若想添加某个表单里的数据时，一个一个获取表单属性值较为繁琐，可以使用jQuery提供的`.serialize()`方法获取完整的表单数据，例如：`data: ${#form}.serialize()`\n\n### 使用案例\n\n配置文件\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:mvc=\"http://www.springframework.org/schema/mvc\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\n        http://www.springframework.org/schema/context\n        https://www.springframework.org/schema/context/spring-context.xsd\n        http://www.springframework.org/schema/mvc\n        https://www.springframework.org/schema/mvc/spring-mvc.xsd\">\n    <!-- 自动扫描指定的包，下面所有注解类交给IOC容器管理 -->\n    <context:component-scan base-package=\"com.zhao.controller\"/>\n    <mvc:default-servlet-handler />\n    <mvc:annotation-driven />\n    <!-- 视图解析器 -->\n    <bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"\n          id=\"internalResourceViewResolver\">\n        <!-- 前缀 -->\n        <property name=\"prefix\" value=\"/WEB-INF/jsp/\" />\n        <!-- 后缀 -->\n        <property name=\"suffix\" value=\".jsp\" />\n    </bean>\n</beans>\n```\n\n编写一个AjaxController\n\n``` java\n\n@RestController\npublic class AjaxController {\n    @RequestMapping(\"/a1\")\n    public List<User> ajax1(){\n        List<User> list = new ArrayList<User>();\n        list.add(new User(\"zhangsan1\",3,\"男\"));\n        list.add(new User(\"zhangsan2\",3,\"男\"));\n        list.add(new User(\"zhangsan3\",3,\"男\"));\n        return list; //由于@RestController注解，将list转成json格式返回\n    }\n}\n```\n\n前端页面\n\n``` html\n<%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %>\n<html>\n<head>\n    <title>Title</title>\n</head>\n<body>\n<input type=\"button\" id=\"btn\" value=\"获取数据\"/>\n<table width=\"80%\" align=\"center\">\n    <tr>\n        <td>姓名</td>\n        <td>年龄</td>\n        <td>性别</td>\n    </tr>\n    <tbody id=\"content\">\n    </tbody>\n</table>\n<script src=\"${pageContext.request.contextPath}/statics/js/jquery-3.1.1.min.js\"></script>\n<script>\n    $(function () {\n        $(\"#btn\").click(function () {\n            $.post(\"${pageContext.request.contextPath}/a2\",function (data) {\n                console.log(data)\n                var html=\"\";\n                for (var i = 0; i <data.length ; i++) {\n                    html+= \"<tr>\" +\n                        \"<td>\" + data[i].name + \"</td>\" +\n                        \"<td>\" + data[i].age + \"</td>\" +\n                        \"<td>\" + data[i].sex + \"</td>\" +\n                        \"</tr>\"\n                }\n                $(\"#content\").html(html);\n            });\n        })\n    })\n</script>\n</body>\n</html>\n```\n\n\n\n\n\n","tags":["SSM","Spring","Spring MVC"],"categories":["Spring","SSM","Spring MVC"]},{"title":"【Spring】Spring5 事务","url":"/2021/05/31/【Spring】Spring5-事务/","content":"\n![img](/images/%E3%80%90Spring%E3%80%91Spring%E4%BA%8B%E5%8A%A1/kuangstudyf90849ac-8a55-459f-846b-6382d38d6a4d.png)\n\n## Spring 事务管理介绍\n\n事务需要添加到 JavaEE 三层结构里面 Service 层（业务逻辑层）。在 Spring 进行事务管理操作有两种方式：编程式事务管理、**声明式事务管理**（推荐使用）：\n\n- **编程式事务**（需要手动调用事务管理器包裹业务代码进行提交回滚）使用`TransactionTemplate`或者直接使用底层的`PlatformTransactionManager`。对于编程式事务管理，Spring推荐使用`TransactionTemplate`。\n- **声明式事务**（只用声明一下注解就可以）是建立在AOP之上的。其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。声明式事务最大的优点就是不需要通过编程的方式管理事务，这样就不需要在业务逻辑代码中掺杂事务管理的代码，只需在配置文件中做相关的事务规则声明(或通过基于`@Transactional`注解的方式)，便可以将事务规则应用到业务逻辑中。\n\n显然声明式事务管理要优于编程式事务管理，这正是Spring倡导的非侵入式的开发方式。声明式事务管理使业务代码不受污染，一个普通的POJO对象，只要加上注解就可以获得完全的事务支持。和编程式事务相比，声明式事务唯一不足地方是，它的最细粒度只能作用到方法级别，无法做到像编程式事务那样可以作用到代码块级别。但是即便有这样的需求，也存在很多变通的方法，比如，可以将需要进行事务管理的代码块独立为方法等等。\n\nSpring事务原理与AOP原理十分相似，其详细的源码分析见[【Spring】Spring5 事务源码分析](https://yuyun-zhao.github.io/2021/07/05/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n## 声明式事务——基于注解方式\n\n1. 导入相关依赖：数据源、数据库驱动、SpringJDBC模块\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-jdbc</artifactId>\n    <version>5.2.12.RELEASE</version>\n</dependency>\n\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.47</version>\n</dependency>\n\n<dependency>\n    <groupId>c3p0</groupId>\n    <artifactId>c3p0</artifactId>\n    <version>0.9.1.2</version>\n</dependency>\n```\n\n2. 配置数据源、**JdbcTemplate**操作数据库(Spring提供的简化数据库操作的工具)\n\n3. 添加 **@EnableTransactionManagement** 注解开启**基于注解的事务管理功能**\n\n4. 配置**事务管理器**来控制事务（事务管理器操作数据源，进行事务管理）\n\n```java\n@EnableTransactionManagement\n@Configuration\npublic class TxConfig {\n\n    // 向容器中注册数据源\n    @Bean\n    public DataSource dataSource() throws PropertyVetoException {\n        ComboPooledDataSource dataSource = new ComboPooledDataSource();\n        dataSource.setUser(\"root\");\n        dataSource.setPassword(\"123456\");\n        dataSource.setDriverClass(\"com.mysql.jdbc.Driver\");\n        dataSource.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\");\n        return dataSource;\n    }\n\n    @Bean\n    public JdbcTemplate jdbcTemplate() throws PropertyVetoException {\n        JdbcTemplate jdbcTemplate = new JdbcTemplate(dataSource());\n        return jdbcTemplate;\n    }\n\n    // 向容器中注册事务管理器\n    @Bean\n    public PlatformTransactionManager transactionManager() throws PropertyVetoException {\n        return new DataSourceTransactionManager(dataSource());\n    }\n    \n}\n```\n\n5. 在类或方法上添加 **@Transactional()** 注解表明该方法需要添加事务\n\n- 添加到类上，这个类里面所有的方法都添加事务\n- 添加到方法上，只有这个方法添加事务\n\n``` java\n@Transactional()\npublic void add(propagation = Propagation.REQUIRED){\n    update();\n}\n```\n\n其中，可以在xml中配置数据库并开启事务管理器：\n\n``` xml\n<!-- 1、在 spring 配置文件，开启事务注解,引入名称空间！-->\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xmlns:aop=\"http://www.springframework.org/schema/aop\"\n       xmlns:tx=\"http://www.springframework.org/schema/tx\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n                           http://www.springframework.org/schema/beans/spring-beans.xsd\n                           http://www.springframework.org/schema/context\n                           http://www.springframework.org/schema/context/spring-context.xsd\n                           http://www.springframework.org/schema/aop\n                           http://www.springframework.org/schema/aop/spring-aop.xsd \n                           http://www.springframework.org/schema/tx\n                           http://www.springframework.org/schema/tx/spring-tx.xsd\">\n\n    <!--2、在 spring 配置文件配置事务管理器-->\n    <!--创建事务管理器-->\n    <bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n        <!--注入数据源-->\n        <property name=\"dataSource\" ref=\"dataSource\"></property>\n    </bean>\n\n    <!--开启事务注解-->\n    <tx:annotation-driven transactionmanager=\"transactionManager\"></tx:annotation-driven>\n\n    <!--3、在 service 类上面（或者 service 类里面方法上面）添加事务注解-->\n```\n\n``` java\n@Transactional()\npublic void add(propagation = Propagation.REQUIRED){\n    //调用update方法\n    update();\n}\n```\n\n## 声明式事务——基于xml方式\n\n在 Spring 配置文件中进行配置：\n\n- 第一步：配置事务管理器\n- 第二步：配置通知\n- 第三步：配置切入点和切面\n\n``` xml\n<!--1 创建事务管理器-->\n<bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\">\n    <!--注入数据源-->\n    <property name=\"dataSource\" ref=\"dataSource\"></property>\n</bean>\n\n<!--2 配置通知-->\n<tx:advice id=\"txadvice\" transaction-manager=\"transactionManager\">\n    <!--配置事务参数-->\n    <tx:attributes>\n        <!--指定哪种规则的方法上面添加事务-->\n        <tx:method name=\"accountMoney\" propagation=\"REQUIRED\"/>\n        <tx:method name=\"account*\"/>\n    </tx:attributes>\n</tx:advice>\n\n<!--3 配置切入点和切面-->\n<aop:config>\n    <!--配置切入点-->\n    <aop:pointcut id=\"pt\" expression=\"execution(*\n                                      com.atguigu.spring5.service.UserService.*(..))\"/>\n    <!--配置切面-->\n    <aop:advisor advice-ref=\"txadvice\" pointcut-ref=\"pt\"/>\n</aop:config>\n```\n\n## 事务细节参数\n\n- `read-only`：设置事务为只读事务，不需要增删改操作。可以提高查询速度。\n- `timeout`：超时，事务超出指定执行时长后自动终止并回滚。\n- `isolation`：设置隔离级别\n\n运行时异常（非检查异常）发生时默认回滚，编译时异常（检查异常）默认不回滚\n\n- `rollBackFor`：可以让原来默认不回滚的异常回滚\n- `noRollBackFor`：可以让原来默认回滚的异常不回滚\n\n## 事务和线程的关系\n\n**当一个新的事务创建时，就会被绑定到当前线程上**。\n\n**TransactionAspectSupport**类中的`ThreadLocal<TransactionInfo>`在当前线程保存了一个事务的信息**TransactionInfo**：\n\n![image-20210818103221467](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210818103221467.png)\n\n该线程会伴随着这个事务整个生命周期，直到事务提交、回滚或挂起（**临时解绑**）时该线程才会取消与该事务的绑定。\n\n同时一个线程只能绑定一个事务，若当前线程原本正绑定的事务还未执行完毕就被新的事务所挂起，则该线程与该事务进行临时解绑，并绑定到新创建的事务上；直到新建的事务提交或回滚后，该线程才会结束与该新建事务的绑定，再次重新绑定之前的事务。\n\n上述过程实现的原理为使用**链表结构**：创建一张`TransactionInfo`链表，将新创建的事务`TransactionInfo`链接到旧的事务`TransactionInfo`的尾部，待新事务执行完毕后再指回旧的事务`TransactionInfo`：\n\n![image-20210818104726262](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210818104726262.png)\n\n![image-20210818105411421](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210818105411421.png)\n\n当新创建的事务结束时恢复旧的事务状态：\n\n![image-20210818105517020](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210818105517020.png)\n\n**什么是事务挂起，如何实现挂起**\n\n对事务的配置在Spring内部会被封装成**TransactionInfo**，线程绑定了事务，自然也绑定了事务相关的**TransactionInfo**。**挂起事务时，把TransactionInfo取出临时存储，等待执行完成后，把之前临时存储的TransactionInfo重新绑定到该线程上**。\n\n**关于事务挂起的举例：（某事务挂起之后，任何操作都不在该事务的控制之下）**\n\n> https://blog.csdn.net/xiaoshuo566/article/details/83929465\n\n例如： 方法A支持事务，方法B不支持事务，即`PROPAGATION_NOT_SUPPORTED`。方法A调用方法B：\n\n- 在方法A开始运行时，系统为它建立Transaction，方法A中对于数据库的处理操作，会在该Transaction的控制之下。\n- 这时，方法A调用方法B，方法A打开的Transaction将挂起，方法B中任何数据库操作，都不在该Transaction的管理之下。\n- 当方法B返回，方法A继续运行，之前的Transaction恢复，后面的数据库操作继续在该Transaction的控制之下提交或回滚。\n\n## 声明式事务传播特性\n\n事务传播行为就是多个事务方法相互调用时，事务如何在这些方法间传播。Spring支持7种事务传播行为：\n\n- **`propagation_required`**（需要事务，有就加入，没有就新建）：如果当前没有事务，就新建一个事务，如果已存在一个事务中，加入到这个事务中，这是最常见的选择。（如果设置为required，则事务的其他属性继承于大事务）好男人。\n- `propagation_supports`（支持事务，有就加入，没有就非事务）：支持当前事务，如果没有当前事务，就以非事务方法执行。懒男人\n- `propagation_mandatory`（强制使用当前事务，有就加入，没有就抛异常）：使用当前事务，如果没有当前事务，就抛出异常。\n\n上述三种类型**都支持当前事务，当前如果有事务就加入。**\n\n- **`propagation_required_new`**（必须新建事务，当前有就抛挂起）：新建事务，如果当前存在事务，把当前事务挂起。挑剔男\n- `propagation_not_supported`（不支持事务，当前有就挂起）：以非事务方式执行操作，如果当前存在事务，就把当前事务**挂起**（**挂起指自己新建一个数据库连接，不再使用之前的数据库连接，在代码中体现为两个方法的connection不相同，详细介绍见上文**）。减肥男\n- `propagation_never`（强制非事务，当前有就抛异常）：以非事务方式执行操作，如果当前事务存在则抛出异常`IllegalTransactionStateException`，该方法内的代码无法运行。神经病\n\n上述三种类型都**不支持当前事务，当前如果有事务，要么挂起，要么抛异常。**\n\n- `propagation_nested`：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与propagation_required类似的操作\n\nSpring 默认的事务传播行为是 `PROPAGATION_REQUIRED`，它适合于绝大多数的情况。\n\n假设 `ServiveX#methodX()` 都工作在事务环境下（即都被 Spring 事务增强了），假设程序中存在如下的调用链：`Service1#method1()->Service2#method2()->Service3#method3()`，那么这 3 个服务类的 3 个方法通过 Spring 的事务传播机制都工作在同一个事务中。\n\n### 示例\n\n``` java\n@Service\npublic class AccountServiceImpl implements AccountService {\n    @Autowired\n    JdbcTemplate jdbcTemplate;\n\n    @Override\n    @Transactional(propagation = Propagation.REQUIRED_NEW)\n    public void addAccount(String name, int initMoney) {\n        String accountId = new SimpleDateFormat(\"yyyyMMddhhmmss\").format(new Date());\n        jdbc.Template.update(\"INSERT INTO `account` (accountName, user, money) VALUES(?,?,?)\", accountId, name, initMoney);\n        int i = 1 / 0; // 制造异常\n    }\n}\n```\n\n```java\n@Transactional(propagation = Propagation.REQUIRED)\npublic void createUser(String name) {\n    jdbc.Template.update(\"INSERT INTO `user` (name) VALUES(?)\", name);\n    accountService.addAccount(name, 10000);\n}\n```\n\n使用过上述案例进行实验，1代表插入成功，2代表插入失败：\n\n![image-20210817144253822](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210817144253822.png)\n\n- 场景1：两个方法都没事务，都是普通方法，因此就算抛出异常，也不影响插入数据\n- 场景2：`createUser()`没有事务，其仍然能插入数据；`addAccount()`有事务，其出现异常不能成功插入数据\n- 场景3：`createUser()`有事务，出现异常后其不能插入数据；`addAccount()`没有声明事务，但其被createUser()调用，仍然会被事务包裹，出现异常不能成功插入数据。**若某个方法包含事务，其调用的其他方法也会包含事务**\n- 场景4：`addAccount()`将`createUser()`的事务挂起，**挂起指自己新建一个数据库连接，不再使用之前的数据库连接，在代码中体现为两个方法的connection不相同，详细介绍见上文**。因此`addAccount()`插入成功（因为没有事务，异常也能插入），`createUser()`插入失败（因为`addAccount()`抛出了异常，被重新恢复的事务所捕获从而插入失败）\n- 场景5：`addAccount()`不支持事务，直接抛出`IllegalTransactionStateException`。所以直接无法运行该方法内插入的语句，所以插入失败；`createUser()`因为有事务，所以捕获到`addAccount()`抛出的异常后回滚，插入失败\n- 场景6：见下文场景分析\n\n场景6详细分析：假设Spring IoC中有组件`AccountServiceImpl`，该组件中的`addAccount()`方法被`@Transactional`注解修饰，代表该方法将开启事务。\n\nSpring容器启动时将使用事务后置处理器**AutoProxyRegistrar**会为该组件创建一个动态代理对象`accountProxy`，该对象将被注入到容器中，其他程序在调用`getBean()`获取该类的对象时，将获取到该类的动态代理对象，而非原始对象。此时在调用该代理对象`accountProxy`的`addAccount()`时，将有事务包裹。\n\n而若不调用该代理对象的`addAccount()`，而是将该方法直接写在本类中，直接调用本类里的该方法，则不会交由Spring事务管理器拦截，此时的方法和普通方法一样。\n\n结论：只有Spring事务代理对象的方法才能被事务拦截器所拦截。直接调用方法无法被拦截（即使该方法被`@Transactional`注解修饰）。\n\n## 编程式事务\n\n编程式事务指需要手动调用事务管理器包裹业务代码进行提交回滚。其需要使用`TransactionTemplate`或者直接使用底层的`PlatformTransactionManager`。对于编程式事务管理，Spring推荐使用`TransactionTemplate`。\n\nSpring事务与JDBC事务的关系：上中下三个框分别代表基于AOP的声明式事务、编程式事务、JDBC事务。其中基于AOP的声明式事务原理见文章[【Spring】Spring5 事务源码分析](https://yuyun-zhao.github.io/2021/07/05/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n编程式事务中的两个重要类：\n\n- **TransactionManager**：事务管理器，用于控制事务的提交和回滚\n- **TransactionStatus**：事务状态，保存了事务的各种状态，例如保存点等；其可创建保存点并利用其回滚到保存点。使用**TransactionManager**创建该对象。\n\n![image-20210818101801840](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210818101801840.png)\n\n编程式事务使用示例：\n\n![image-20210818100033643](/images/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/image-20210818100033643.png)\n\n\n\n可利用**TransactionAspectSupport**获取当前线程方法栈中的事务状态，在不同的事务中该状态对象不同：\n\n```java\nTransactionStatus status = TransactionAspectSupport.currentTransactionStatus();\n```\n\n## 声明式事务原理\n\n**@EnableTransactionManagement** 注解向容器中添加**AutoProxyRegistrar**和**ProxyTransactionManagementConfiguration**组件，二者作用分别为：\n\n- **AutoProxyRegistrar**：类似于AOP中的**AspectJAutoProxyRegistrar**，用于向容器中注册**InfrastructureAdvisorAutoProxyCreator**组件（类似于AOP里的自动代理器，一种后置处理器）来为普通组件进行代理包装，创建**代理对象**\n- **ProxyTransactionManagementConfiguration**：用于注册**事务增强器**，该增强器内设置有事务拦截器，将在代理对象执行目标方法时进行拦截，并调用其`invoke()`方法，**由事务管理器控制事务的提交与回滚**。\n\nSpring事务原理与AOP原理十分相似，都包含有**后置处理器**和**拦截器**思想，在组件创建后包装出代理对象、在代理对象执行目标方法时进行拦截，使用事务管理器控制事务的提交与回滚。\n\n详细的源码分析见文章[【Spring】Spring5 事务源码分析](https://yuyun-zhao.github.io/2021/07/05/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。","tags":["SSM","Spring"],"categories":["Spring","SSM"]},{"title":"【Spring】Spring5 AOP","url":"/2021/05/29/【Spring】Spring5-AOP/","content":"\n![img](/images/%E3%80%90Spring%E3%80%91Spring-AOP/kuangstudyf90849ac-8a55-459f-846b-6382d38d6a4d.png)\n\n## AOP 基本概念\n\nAOP（Aspect Oriented Programming）意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。AOP是OOP的延续，是软件开发中的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生范型。利用AOP可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率。\n\nSpring AOP的源码分析见[【Spring】Spring5 AOP源码分析](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring-AOP/kuangstudyfffec70f-ce10-4ca2-a71b-dbc535b0e07c-1625811781519.png)\n\n- 面向切面编程（方面），利用 AOP 可以对业务逻辑的各个部分进行隔离，从而使得业务逻辑各部分之间的耦合度降低，提高程序的可重用性，同时提高了开发的效率；\n\n- 通俗描述：不通过修改源代码方式，在主干功能里面添加新功能。\n\n- 使用登录例子说明 AOP：\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring-AOP/20200702135106266-1625811781520.png)\n\n## AOP 底层原理\n\nAOP 底层使用**动态代理** ，动态代理有两种情况：\n\n第一种 有接口情况，使用**JDK 动态代理** ；创建**接口实现类代理对象**，增强类的方法\n![在这里插入图片描述](/images/%E3%80%90Spring%E3%80%91Spring-AOP/20200702135134128-1625811781520.png)\n\n第二种 没有接口情况，使用**CGLIB 动态代理**创建**子类的代理对象**，增强类的方法（该方法不需要实现接口，由CGLIB创建代理对象）\n![在这里插入图片描述](/images/%E3%80%90Spring%E3%80%91Spring-AOP/2020070213514980-1625811781520.png)\n\n<!-- More -->\n\n## **AOP JDK 动态代理**\n\n1）使用 JDK 动态代理，使用 `Proxy `类里面的方法创建代理对象：\n\n调用 newProxyInstance 方法，方法有三个参数：\n\n``` java\npublic static Object newProxyInstance(ClassLoader loader,\n                                      Class<?>[] interfaces,\n                                      InvocationHandler h)\n```\n\n- 参数一：类加载器\n- 参数二：增强方法所在的类，这个类实现的接口，支持多个接口\n- 参数三：实现这个接口 `InvocationHandler`，创建代理对象，写增强的部分\n\n2）编写 JDK 动态代理代码\n\n``` java\n//（1）创建接口，定义方法\npublic interface UserDao {\n    public int add(int a,int b);\n    public String update(String id);\n}\n```\n\n``` java\n//（2）创建接口实现类，实现方法\npublic class UserDaoImpl implements UserDao {\n    @Override\n    public int add(int a, int b) {\n        return a+b;\n    }\n    @Override\n    public String update(String id) {\n        return id;\n    }\n}\n```\n\n``` java\n//（3）使用 Proxy 类创建接口代理对象\npublic class JDKProxy {\n    public static void main(String[] args) {\n        //创建接口实现类代理对象\n        Class[] interfaces = {UserDao.class};\n        UserDaoImpl userDao = new UserDaoImpl(); \n        /** 第一参数，类加载器 \n\t第二参数，增强方法所在的类，这个类实现的接口，(支持多个接口)\n\t第三参数，实现这个接口 InvocationHandler，创建代理对象，写增强的部分  */\n        UserDao dao =(UserDao)Proxy.newProxyInstance(JDKProxy.class.getClassLoader(), interfaces,\n                                                     new UserDaoProxy(userDao));\n        int result = dao.add(1, 2);\n        System.out.println(\"result:\"+result);\n    }\n}\n\n//创建代理对象代码\nclass UserDaoProxy implements InvocationHandler {\n    //1 把创建的是谁的代理对象，把谁传递过来\n    //有参数构造传递\n    private Object obj;\n    public UserDaoProxy(Object obj) {\n        this.obj = obj;\n    }\n    //增强的逻辑\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        //方法之前\n        System.out.println(\"方法之前执行....\"+method.getName()+\" :传递的参数...\"+ Arrays.toString(args));\n        //被增强的方法执行\n        Object res = method.invoke(obj, args);\n        //方法之后\n        System.out.println(\"方法之后执行....\"+obj);\n        return res;\n    }\n}\n```\n\n## AOP 术语\n\n\n- 连接点（JointPoint）：类里面哪些方法可以被增强，这些方法称为连接点，每一个方法的每一个位置（开始位置，返回位置，异常位置等）都是一个连接点。\n- **切入点（PointCut）**：切面通知执行的“地点”的定义，实际被真正增强的方法称为切入点。\n- 横切关注点：跨越应用程序多个模块的方法或功能。即是，与我们业务逻辑无关的，但是我们需要关注的部分，就是横切关注点。如日志 , 安全 , 缓存 , 事务等等 ….\n- **切面（Aspect）**：横切关注点被模块化的特殊对象。即，它是一个类。\n- **通知方法（Advice）**：切面必须要完成的工作。即，它是类中的一个方法。包含前置通知，后置通知，环绕通知 ，异常通知和最终通知。\n- 目标（Target）：被通知的对象。\n- 代理（Proxy）：向目标对象应用通知之后创建的对象。\n\n![image-20210713170239284](/images/%E3%80%90Spring%E3%80%91Spring5-AOP/image-20210713170239284.png)\n\n![img](/images/%E3%80%90Spring%E3%80%91Spring-AOP/kuangstudy7a512991-1651-44b4-afca-d09e12cbbe6f-1625811781520.png)\n\n## AOP CGLIB 动态代理\n\nCGLIB是一个功能强大，高性能的**代码生成库**（第三方库，可以由Maven导入）。其被广泛应用于AOP框架（Spring、dynaop）中，用以提供方法拦截操作。它为没有实现接口的类提供代理，为JDK的动态代理提供了很好的补充。通常可以使用Java的动态代理创建代理，但当要代理的类没有实现接口或者为了更好的性能，CGLIB是一个好的选择。CGLIB作为一个开源项目，其代码托管在github，地址为：https://github.com/cglib/cglib\n\n**CGLIB 原理**：动态生成一个要代理类的子类，子类重写要代理的类的所有不是final的方法。在子类中采用**方法拦截**的技术拦截所有父类方法的调用，顺势织入横切逻辑。它比使用java反射的JDK动态代理要快。\n\n**CGLIB 底层**：使用字节码处理框架ASM，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它要求你必须对JVM内部结构包括class文件的格式和指令集都很熟悉。\n\n**CGLIB缺点**：对于final方法，无法进行代理。\n\nSpring 框架一般都是基于 AspectJ 实现 AOP 操作，AspectJ 不是 Spring 组成部分，独立 AOP 框架，一般把 AspectJ 和 Spirng 框架一起使用，进行 AOP 操作。基于 AspectJ 实现 AOP 操作的两种方式：\n\n- 基于注解方式实现\n- 基于 xml 配置文件实现 \n\n### AOP 基于注解开发\n\n采用**动态代理**的设计模式，在程序运行期间动态地将某段代码切入到指定方法（切入点）指定位置进行运行的编程方式。\n\n```xml\n<dependency>\n    <groupId>org.springframework</groupId>\n    <artifactId>spring-aspects</artifactId>\n    <version>5.2.12.RELEASE</version>\n</dependency>\n```\n\n定义一个业务逻辑类（`MathCalculator`）。试图在业务逻辑运行的时候将日志进行打印（方法之前，方法运行结束，方法出现异常等）\n\n```java\npublic class MathCalculator {\n    public int div(int i, int j){\n        return i/j;\n    }\n}\n```\n\n定义一个日志切面类（`LogAspects`），在切面类里需要动态感知`MathCalculator.div()`方法运行到什么阶段并执行相应通知方法。通知方法：\n\n- 前置通知（`@Before`）：在切入点（`PointCut`）运行之前运行\n- 后置通知（`@After`）：在切入点运行结束之后运行（无论方法是否正常结束）\n- 返回通知（`@AfterReturning`）：在切入点正常返回之后运行（异常不执行）\n- 异常通知（`@AfterThrowing`）：在切入点出现异常之后运行\n- 环绕通知（`@Around`）：动态代理的方式**手动**推进切入点运行（`joinPoint.procced()`），是最底层的通知，其可以实现上述四个通知效果\n\n**通知方法的执行顺序**：\n\n- 环绕通知（`@Around`）`joinPoint.procced()`方法之前的代码\n- 前置通知（`@Before`）\n- 业务代码\n- 返回通知（`@AfterReturning`）/ 若有异常，此时执行异常通知（`@AfterThrowing`）\n- 后置通知（`@After`）\n- 环绕通知（`@Around`）`joinPoint.procced()`方法以及其之后的代码\n\n多个切面的情况下，先执行前置通知的后执行返回通知和后置通知，后执行前置通知的先执行返回通知和后置通知。类似方法栈先进后出。执行顺序由切面类的字母顺序排序，也可以通过`@Order(1)`设置优先级\n\n切入点表达式写法：\n\n``` java\n（1）切入点表达式作用：知道对哪个类里面的哪个方法进行增强 \n（2）语法结构： execution([权限修饰符] [返回类型] [类全路径] [方法名称]([参数列表]) )\n（3）例子如下：\n    例 1：对 com.zhao.dao.BookDao 类里面的 add 进行增强\n\t\texecution(* com.zhao.dao.BookDao.add(..))\n \t例 2：对 com.zhao.dao.BookDao 类里面的所有的方法进行增强\n\t\texecution(* com.zhao.dao.BookDao.* (..))\n    例 3：对 com.zhao.dao 包里面所有类，类里面所有方法进行增强\n\t\texecution(* com.zhao.dao.*.* (..))\n```\n\n配置类需要**添加@EnableAspectJAutoProxy以开启注解版的AOP自动代理。整个AOP就是从@EnableAspectJAutoProxy注解开始执行的。**（Spring中有很多的`@EnableXXX`注解，其作用是代替xml文件中的一些配置开启某些功能）\n\n```java\n@EnableAspectJAutoProxy\n@Configuration\npublic class SpringConfigAOP {\n    // 将业务逻辑类加入到容器中\n    @Bean\n    public MathCalculator calculator(){\n        return new MathCalculator();\n    }\n\n    // 切面类加入到容器中\n    @Bean\n    public LogsAspects logsAspects(){\n        return new LogsAspects();\n    }\n}\n```\n\n切面类`LogsAspects`\n\n``` java\n@Aspect\n@Order(1)\npublic class LogsAspects {\n\n    // 抽取公共的切入点表达式\n    // 1. 本类可以引用\n    // 2. 其他的切面类也可以引用（需要全类名）\n    @Pointcut(\"execution(* com.zhao.aop.MathCalculator.*(..))\")\n    public void pointCut(){\n    }\n\n    @Before(\"execution(int com.zhao.aop.MathCalculator.div(int, int))\")\n    public void logStart(JoinPoint joinPoint){\n        Object[] args = joinPoint.getArgs(); // 方法参数\n        System.out.println(\"前置通知@Before.... \");\n    }\n\n    @After(\"execution(* com.zhao.aop.MathCalculator.*(..))\")\n    public void logEnd(){\n        System.out.println(\"后置通知@After....\");\n    }\n\n    @AfterReturning(value = \"pointCut()\", returning = \"result\")\n    public void logReturn(Object result){\n        // result: 方法返回值\n        System.out.println(\"返回通知@AfterReturning.... \");\n    }\n\n    @AfterThrowing(value = \"pointCut()\", throwing = \"exception\")\n    public void logException(Exception exception){\n        System.out.println(\"异常通知@AfterThrowing.... \");\n    }\n\n    @Around(\"pointCut()\")\n    public Object around(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {\n        System.out.println(\"签名: \" + proceedingJoinPoint.getSignature());\n        Object[] args = proceedingJoinPoint.getArgs();\n\n        try { \n            System.out.println(\"【环绕前置通知】.... \");\n            //执行目标方法proceed\n            Object result = proceedingJoinPoint.proceed(args);\n            System.out.println(\"【环绕返回通知】.... \");\n        } catch (Exception exception){\n            System.out.println(\"【环绕异常通知】.... \");\n        } finally {\n            System.out.println(\"【环绕后置通知】.... \");\n        }\n\n        return result;\n    }\n}\n```\n\n``` java\npublic class AOPTest {\n    AnnotationConfigApplicationContext context;\n\n    @Test\n    public void testOfAop() {\n        context = new AnnotationConfigApplicationContext(SpringConfigAOP.class);\n        System.out.println(\"容器创建完成....\");\n\n        // 必须从容器中获得bean才能启动AOP\n        MathCalculator bean = context.getBean(MathCalculator.class);\n        bean.div(1, 1);\n\n        context.close();\n    }\n}\n```\n\n控制台打印：\n\n``` \n签名: int com.zhao.aop.MathCalculator.div(int,int)\n【环绕前置通知】.... \n前置通知@Before.... \ndiv方法执行...\n返回通知@AfterReturning.... \n后置通知@After....\n【环绕返回通知】.... \n【环绕后置通知】...\n\nProcess finished with exit code 0\n```\n\n### AOP 基于xml开发\n\n使用AOP织入，需要导入一个依赖包（和上面的区别？）\n\n``` xml\n<!-- https://mvnrepository.com/artifact/org.aspectj/aspectjweaver -->\n<dependency>\n    <groupId>org.aspectj</groupId>\n    <artifactId>aspectjweaver</artifactId>\n    <version>1.9.4</version>\n</dependency>\n```\n\n#### 方式一：通过 Spring API 实现AOP\n\n第一步：首先编写业务接口和实现类\n\n``` java\npublic interface UserService {\n    public void add();\n    public void delete();\n    public void update();\n    public void search();\n}\n```\n\n``` java\npublic class UserServiceImpl implements UserService{\n    @Override\n    public void add() {\n        System.out.println(\"增加用户\");\n    }\n    @Override\n    public void delete() {\n        System.out.println(\"删除用户\");\n    }\n    @Override\n    public void update() {\n        System.out.println(\"更新用户\");\n    }\n    @Override\n    public void search() {\n        System.out.println(\"查询用户\");\n    }\n}\n```\n\n第二步：然后编写增强类 ：一个前置增强，一个后置增强\n\n``` java\npublic class Log implements MethodBeforeAdvice {\n    //method : 要执行的目标对象的方法\n    //objects : 被调用的方法的参数\n    //Object : 目标对象\n    @Override\n    public void before(Method method, Object[] objects, Object o) throws Throwable {\n        System.out.println( o.getClass().getName() + \"的\" + method.getName() + \"方法被执行了\");\n    }\n}\n```\n\n``` java\npublic class AfterLog implements AfterReturningAdvice {\n    //returnValue 返回值\n    //method被调用的方法\n    //args 被调用的方法的对象的参数\n    //target 被调用的目标对象\n    @Override\n    public void afterReturning(Object returnValue, Method method, Object[] args, Object target) throws Throwable {\n        System.out.println(\"执行了\" + target.getClass().getName()\n                           +\"的\"+method.getName()+\"方法,\"\n                           +\"返回值：\"+returnValue);\n    }\n}\n```\n\n第三步：最后去Spring的文件中注册 , 并实现AOP切入实现 , 注意导入约束\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:aop=\"http://www.springframework.org/schema/aop\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n                           http://www.springframework.org/schema/beans/spring-beans.xsd\n                           http://www.springframework.org/schema/aop\n                           http://www.springframework.org/schema/aop/spring-aop.xsd\">\n    <!--注册bean-->\n    <bean id=\"userService\" class=\"com.zhao.service.UserServiceImpl\"/>\n    <bean id=\"log\" class=\"com.zhao.log.Log\"/>\n    <bean id=\"afterLog\" class=\"com.zhao.log.AfterLog\"/>\n    <!--aop的配置-->\n    <aop:config>\n        <!--切入点  expression:表达式匹配要执行的方法 ..代表该包下的子包也能被扫描到 -->\n        <aop:pointcut id=\"pointcut\" expression=\"execution(* com.zhao.service.UserServiceImpl..*(..))\"/>\n        <!--执行环绕; advice-ref执行方法 . pointcut-ref切入点-->\n        <aop:advisor advice-ref=\"log\" pointcut-ref=\"pointcut\"/>\n        <aop:advisor advice-ref=\"afterLog\" pointcut-ref=\"pointcut\"/>\n    </aop:config>\n</beans>\n```\n\n第四步：测试\n\n``` java\npublic class MyTest {\n    @Test\n    public void test(){\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        UserService userService = (UserService) context.getBean(\"userService\");\n        userService.search();\n    }\n}\n```\n\nSpring的AOP就是将公共的业务 (日志 , 安全等) 和领域业务结合起来 ，当执行领域业务时，将会把公共业务加进来，实现公共业务的重复利用。\n\n#### 方式二：自定义类来实现AOP\n\n目标业务类不变依旧是userServiceImpl\n\n第一步：编写一个切入类\n\n``` java\npublic class DiyPointcut {\n    public void before(){\n        System.out.println(\"---------方法执行前---------\");\n    }\n    public void after(){\n        System.out.println(\"---------方法执行后---------\");\n    }\n}\n```\n\n第二步：在Spring中配置\n\n``` xml\n<!--第二种方式自定义实现-->\n<!--注册bean-->\n<bean id=\"diy\" class=\"com.zhao.config.DiyPointcut\"/>\n<!--aop的配置-->\n<aop:config>\n    <!--第二种方式：使用AOP的标签实现-->\n    <aop:aspect ref=\"diy\">\n        <aop:pointcut id=\"diyPonitcut\" expression=\"execution(* com.zhao.service.UserServiceImpl..*(..))\"/>\n        <aop:before pointcut-ref=\"diyPonitcut\" method=\"before\"/>\n        <aop:after pointcut-ref=\"diyPonitcut\" method=\"after\"/>\n    </aop:aspect>\n</aop:config>\n```\n\n第三步：测试\n\n``` java\npublic class MyTest {\n    @Test\n    public void test(){\n        ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n        UserService userService = (UserService) context.getBean(\"userService\");\n        userService.add();\n    }\n}\n```\n\n## Spring AOP 源码分析\n\nSpring AOP的源码分析见[【Spring】Spring5 AOP源码分析](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)。","tags":["SSM","Spring"],"categories":["Spring","SSM"]},{"title":"【JavaWeb】Servlet","url":"/2021/05/28/【JavaWeb】Servlet/","content":"\n## Servlet\n\nServlet是Sun公司开发动态web的一门技术。Sun在这些API中提供了一个接口：Servlet。开发Servlet程序需要完成两个步骤：\n\n- 编写一个Java类，实现Servlet接口\n- 把开发好的Java类部署到web服务器中\n\n**把实现了Servlet接口的Java程序叫做Servlet**\n\n### HelloServlet\n\nSevlet接口Sun公司提供有两个默认的实现类：HttpServlt，GenericServlet\n\n1. 构建一个普通的Maven项目（不带模板），删掉里面的src目录，这个空的工程就是Maven的主工程。之后在这个项目里建立Module，新建的Module均为Maven父项目的子项目。\n\n2. 关于Maven父子工程的理解：在父项目中会有\n\n   ``` xml\n   <modules>\n       <module>servlet-01</module>\n   </modules>\n   ```\n\n   父项目中的Maven依赖环境Jar包子项目可以直接使用\n\n3. Maven环境优化：修改web.xml（与本地Tomcat中的内容一致）\n\n  ```xml\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee\n                      http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\"\n         metadata-complete=\"true\">\n\n</web-app>\n  ```\n\n4. 编写一个Servlet程序\n   - 编写一个普通类\n   - 实现Servlet接口，这里继承HttpServlet\n\n```java\n   package com.zhao.servlet;\n   \n   import javax.servlet.ServletException;\n   import javax.servlet.http.HttpServlet;\n   import javax.servlet.http.HttpServletRequest;\n   import javax.servlet.http.HttpServletResponse;\n   import java.io.IOException;\n   import java.io.PrintWriter;\n   \n   public class HelloServlet extends HttpServlet {\n       // 由于get或者post只是请求实现的不同方式，可以互相调用，业务逻辑都一样\n       @Override\n       protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n           PrintWriter writer = resp.getWriter();\n           writer.print(\"Hello Servlet\");\n       }\n   \n       @Override\n       protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n           doGet(req, resp);\n       }\n   }\n```\n\n5. 编写Servlet映射：写的Java程序要通过浏览器访问，浏览器需要连接web服务器，所以需要在web服务中注册我们写的Servlet，还需要给他一个浏览器能访问到的路径。\n\n```xml\n<!-- 注册Servlet -->\n<servlet>\n    <servlet-name>HelloServlet</servlet-name>\n    <servlet-class>com.zhao.servlet.HelloServlet</servlet-class>\n</servlet>\n<!-- Servlet的请求路径 -->\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello</url-pattern>\n</servlet-mapping>\n```\n\n6. 配置Tomcat，注意配置项目发布的路径\n7. 启动测试\n\n<!-- More -->\n\n### Servlet原理\n\nServlet是由web服务器调用，web服务器在收到浏览器请求后会调用`service()`方法，该方法会根据请求的类型`GET`或`POST`分发处理，执行相应的`doGet()`或`doPost()`方法。\n\n![image-20210501200459226](/images/%E3%80%90JavaWeb%E3%80%91Servlet/image-20210501200459226.png)\n\n### Mapping问题\n\n1. 一个Servlet可以指定一个映射路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello</url-pattern>\n</servlet-mapping>\n```\n\n2. 一个Servlet可以指定多个映射路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello1</url-pattern>\n</servlet-mapping>\n\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello2</url-pattern>\n</servlet-mapping>\n\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello3</url-pattern>\n</servlet-mapping>\n```\n\n3. 一个Servlet可以指定通用映射路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello/*</url-pattern>\n</servlet-mapping>\n```\n\n4. 默认请求路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/*</url-pattern>\n</servlet-mapping>\n```\n\n优先级问题：\n\n指定了**固有的映射路径优先级最高**，如果找不到匹配的固有映射路径，则就会走默认路径（\\*)\n\n```xml\n<!-- 注册Error Servlet -->\n<servlet>\n    <servlet-name>ErrorServlet</servlet-name>\n    <servlet-class>com.zhao.servlet.ErrorServlet</servlet-class>\n</servlet>\n<!-- ErrorServlet的请求路径 -->\n<servlet-mapping>\n    <servlet-name>ErrorServlet</servlet-name>\n    <url-pattern>/*</url-pattern>\n</servlet-mapping>\n```\n\n### ServletContext\n\n是一个接口，代表Servlet上下文对象，一个工程只有一个ServletContext对象，是一个域对象（这里的域指的是整个web工程）。\n\nweb容器在启动时，他会为每个web程序都创建一个ServletContext对象，他代表了当前的web应用。\n\n作用1：共享数据，即在某个Servlet中保存的数据可以在另一个Servlet中获得。\n\n存入数据的Servlet类，用于保存数据到ServletContext对象中。\n\n```java\npublic class HelloServlet extends HttpServlet {\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        System.out.println(\"hello\");\n        // this.getInitParameter();  初始化参数\n        // this.getServletConfig();  Servlet配置\n        // this.getServletContext(); Servlet上下文\n\n        ServletContext context = this.getServletContext();\n        String username = \"zhangsan\"; // 数据\n\n        // 将一个数据以键值对形式保存在了ServletContext中。\n        context.setAttribute(\"username\", username);\n    }\n}\n```\n\n读入数据的Servlet类，用于从ServletContext对象中读取数据。\n\n```java\npublic class GetServlet extends HttpServlet {\n\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        ServletContext context = this.getServletContext();\n        String username = (String)context.getAttribute(\"username\");\n\n        resp.getWriter().print(username);\n    }\n\n    @Override\n    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        super.doPost(req, resp);\n    }\n}\n```\n\n作用2：获取初始化参数。\n\n```xml\n<!-- 是上下文参数（属于整个web工程） -->\n<context-param>\n  <param-name>url</param-name>\n  <param-value>jdbc:mysql://localhost:3306/mybatis</param-value>\n</context-param>\n```\n\n```java\nServletContext context = this.getServletContext();\n\nString url = context.getInitParameter(\"url\");\nresp.getWriter().print(url);\n```\n\n作用3：请求转发。\n\n访问当前url时，将消息转发给指定的其他url（当前url不会发生变化，重定向会变化）。当前url只充当转发功能。**请求转发不需要添加项目名，只需要/+映射路径**\n\n```java\n// 转发的请求参数\nRequestDispatcher requestDispatcher = context.getRequestDispatcher(\"/servlet01\");\nrequestDispatcher.forward(req, resp); // 调用forward实现请求转发\n```\n\n请求转发的特点：\n\n- 浏览器地址栏没有变化\n- 是一次请求\n- 共享Request域中的数据\n- 可以转发到`WEB-INF`目录下\n- 无法访问项目以外的其他资源（如百度）\n\n作用4：读取资源文件\n\n- 在java目录下新建properties\n- 在resources目录下新建properties\n\n发现都被打包到了同一个路径下：`/WEB-INF/classes`，将这个路径称为classpath。\n\n``` properties\nusername=root\npassword=123456\n```\n\n```java\nInputStream resourceAsStream = this.getServletContext().getResourceAsStream(\"/WEB-INF/classes/db.properties\");\n\nProperties prop = new Properties();\nprop.load(resourceAsStream);\nString user = prop.getProperty(\"username\");\nString password = prop.getProperty(\"password\");\n\nresp.getWriter().print(url + ':' + password);\n```\n\n### HttpServletResponse\n\nweb服务器接收到客户端的HTTP请求，针对这个请求，分别创建一个代表请求的HttpServletRequest对象，代表响应的一个HttpServletResponse对象。\n\n- 如果要获取客户端请求过来的参数，使用HttpServletRequest\n- 如果要给客户端响应一些信息，使用HttpServletResponse\n\n负责向浏览器发送数据的方法：\n\n- `getOutputStream()`\n- `getWriter()`\n\n常见应用：\n\n1. 向浏览器输出消息\n2. 下载文件\n\n``` java\n// 设置让浏览器能够支持附件下载\nrespones.setHeader(\"Content-Disposition\", \"attachment;filename=\"+fileName);\n```\n\n3. 实现重定向\n\n``` java\nresponse.sendRedirect(\"/projectName/url\"); // 重定向到其他url\n```\n\n**重定向和转发的区别**\n\n- 请求转发时，url不会发生变化。（转发在服务器内部完成，不需要加项目名路径，如\"/url\"）\n- 重定向时，url会发生变化。（需要加项目名路径，如\"/projectName/url\")\n\n在前端文件中写跳转链接时，因其不能得知服务器内部的项目结构，因此需要人为指定contextPath（在Servlet程序中不需要再指定当前项目在服务器内的路径）\n\n细节：当用户提交完请求，浏览器会记录下最后一次请求的全部信息。当用户按下功能键F5，就会发起浏览器记录的最后一次请求。在此情况下如果使用请求转发的方式跳转页面，用户按下F5后会再次发起请求，因此这种情况应该使用重定向。\n\n### HttpServletRequest\n\nHttpServletRequest代表客户端的请求，用户通过HTTP协议访问服务器，HTTP协议中的所有消息信息会被封装到HttpServletRequest，通过该类的方法可以获得客户端传来的请求信息。\n\n1. 获取传递的参数\n\n``` java\nString username = request.getParameter(\"username\");\nString[] hobbies = request.getParameterValues(\"hobbies\");\n```\n\n2. 请求转发\n\n``` java\nrequest.getRequestDispatcher(\"/success.jsp\").forward(requset, response);\n```\n\n![image-20210501221519475](/images/%E3%80%90JavaWeb%E3%80%91Servlet/image-20210501221519475.png)\n\n3. 获取请求头中Referer信息（浏览器发起请求时的url），可用于重定向回原地址\n\n```java\nString url = req.getHeader(\"Referer\");\n```\n\n### Web中 / 斜杠的不同意义\n\n在web中，/ 是一种绝对路径：\n\n- / 如果被**浏览器**解析，得到的地址是：http://ip:port/ （指写在静态html代码中，无法被服务器解析，只能被浏览器解析）\n\n``` html\n<a href=\"/\">斜杠</a>\n```\n\n- / 如果被**服务器**解析，得到的地址是：http://ip:port/工程路径\n\n``` \n// 映射\n<url-pattern>/servlet1<url-pattern>\n\n// 获取绝对路径\nservletContext.getRealPath(\"/\");\n\n// 请求转发\nrequest.getRequestDispacther(\"/\");\n```\n\n- 特殊情况：response.senRedirect(\"/\"); 会将斜杠发送给浏览器解析，得到http://ip:port/ \n\n**/WEB-INF/目录下的资源文件，客户端无法直接访问（即不能在浏览器中输入url直接跳转），而只能在servlet程序中跳转**","tags":["JavaWeb"],"categories":["JavaWeb"]},{"title":"【Spring】Spring5 IoC","url":"/2021/05/24/【Spring】Spring5-IoC/","content":"\n![kuangstudyf90849ac-8a55-459f-846b-6382d38d6a4d](/images/%E3%80%90Spring%E3%80%91Spring5-IoC/kuangstudyf90849ac-8a55-459f-846b-6382d38d6a4d.png)\n\n## Spring IoC容器\n\n**1、什么是IoC**\n\n- 把对象创建和对象之间的调用过程，交给Spring进行管理\n- 使用IoC目的：为了降低耦合度\n\n**2、IoC底层**\n\nxml解析、工厂模式、反射\n\n**3、Spring提供的IoC容器实现的两种方式（两个接口）**\n\n- `BeanFactory`接口：IoC容器基本实现是Spring内部接口的使用接口，不提供给开发人员进行使用（加载配置文件时候不会创建对象，在获取对象时才会创建对象。）\n- `ApplicationContext`接口：`BeanFactory`接口的子接口，提供更多更强大的功能，提供给开发人员使用（加载配置文件时候就会把在配置文件对象进行创建）推荐使用！\n\n**4、ApplicationContext接口的实现类**\n\n![image-20210523201040536](/images/%E3%80%90Spring%E3%80%91Spring5-IoC/image-20210523201040536.png)\n\n**5、管理Bean的方式有两种**：\n\n- 基于xml的方式\n- 基于注解的方式\n\n<!-- More -->\n\n## 基于xml方式\n\n### 1、IoC操作Bean管理\n\n Bean管理就是两个操作：\n\n- Spring创建对象；\n- Spring注入属性\n\n### 2、配置文件创建对象\n\n``` xml\n<!--1 配置User对象创建-->\n<bean id=\"user\" class=\"com.zhao.spring5.User\"></bean>\n```\n\n获取类对象\n\n``` JAVA\n@Test\npublic void test(){\n    ApplicationContext context = new ClassPathXmlApplicationContext(\"beans.xml\");\n    //在执行getBean的时候, user已经创建好了, 通过无参构造\n    User user = context.getBean(\"user\", User.class);\n    //User user = (User) context.getBean(\"user\");\n    //调用对象的方法\n    user.show();\n}\n```\n\n### 3、注入属性（DI：依赖注入（注入属性））\n\n==set方式注入==\n\n``` java\n//（1）传统方式： 创建类，定义属性和对应的set方法\npublic class Book {\n        //创建属性\n        private String bname;\n\n        //创建属性对应的set方法\n        public void setBname(String bname) {\n            this.bname = bname;\n        }\n}\n```\n\n``` xml\n<!--（2）spring方式： set方法注入属性-->\n<bean id=\"book\" class=\"com.zhao.spring5.Book\">\n    <!--使用property完成属性注入\n        name：类里面属性名称\n        value：向属性注入的值\n    -->\n    <property name=\"bname\" value=\"Hello\"></property>\n    <property name=\"bauthor\" value=\"World\"></property>\n</bean>\n```\n\n有参构造函数注入\n\n``` java\n//（1）传统方式：创建类，构建有参函数\npublic class Orders {\n    //属性\n    private String oname;\n    private String address;\n    //有参数构造\n    public Orders(String oname,String address) {\n        this.oname = oname;\n        this.address = address;\n    }\n}\n```\n\n``` xml\n<!--（2）spring方式：有参数构造注入属性-->\n<bean id=\"orders\" class=\"com.zhao.spring5.Orders\">\n    <constructor-arg name=\"oname\" value=\"Hello\"></constructor-arg>\n    <constructor-arg name=\"address\" value=\"China！\"></constructor-arg>\n</bean>\n```\n\np名称空间注入\n\n``` xml\n<!--1、添加p名称空间在配置文件头部-->\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:p=\"http://www.springframework.org/schema/p\"   <!--在这里添加一行p-->\n\n<!--2、在bean标签进行属性注入（算是set方式注入的简化操作）-->\n<bean id=\"book\" class=\"com.zhao.spring5.Book\" p:bname=\"very\" p:bauthor=\"good\">\n</bean>\n```\n\n\n### 4、注入空值和特殊符号\n\n``` xml\n<bean id=\"book\" class=\"com.zhao.spring5.Book\">\n    <!--（1）null值-->\n    <property name=\"address\">\n        <null/> <!--属性里边添加一个null标签-->\n    </property>\n\n    <!--（2）特殊符号赋值-->\n    <!--属性值包含特殊符号\n       a 把<>进行转义 &lt; &gt;\n       b 把带特殊符号内容写到CDATA\n      -->\n    <property name=\"address\">\n        <value><![CDATA[<<南京>>]]></value>\n    </property>\n</bean>\n```\n\n### 5、注入属性-外部bean\n\n创建两个类service和dao类\n\n``` java\npublic class UserService {//service类\n\n    //创建UserDao类型属性，生成set方法\n    private UserDao userDao;\n    public void setUserDao(UserDao userDao) {\n        this.userDao = userDao;\n    }\n\n    public void add() {\n        System.out.println(\"service add...............\");\n        userDao.update();//调用dao方法\n    }\n}\n\npublic class UserDaoImpl implements UserDao {//dao类\n\n    @Override\n    public void update() {\n        System.out.println(\"dao update...........\");\n    }\n}\n```\n\n在Spring配置文件中进行配置\n\n``` xml\n<!--1 service和dao对象创建-->\n<bean id=\"userService\" class=\"com.zhao.spring5.service.UserService\">\n    <!--注入userDao对象\n        name属性：类里面属性名称\n        ref属性：创建userDao对象bean标签id值\n    -->\n    <property name=\"userDao\" ref=\"userDaoImpl\"></property>\n</bean>\n<bean id=\"userDaoImpl\" class=\"com.zhao.spring5.dao.UserDaoImpl\"></bean>\n```\n\n### 注入属性-Bean自动装配\n\n在不使用自动装配时需要手动注入每个bean\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans\n        http://www.springframework.org/schema/beans/spring-beans.xsd\">\n    \n    <bean id=\"dog\" class=\"com.zhao.pojo.Dog\"/>\n    <bean id=\"cat\" class=\"com.zhao.pojo.Cat\"/>\n    \n    <bean id=\"user\" class=\"com.zhao.pojo.User\" >\n        <!-- 不使用自动装配时需要手动注入 -->\n        <property name=\"cat\" ref=\"cat\"/>\n        <property name=\"dog\" ref=\"dog\"/>\n        <property name=\"name\" value=\"zhangsan\"/>\n    </bean>\n    \n</beans>\n```\n\n在xml中使用`autowire`设置自动装配：\n\n- `byName`：按照bean名称自动装配\n- `byType`：按照bean类型自动装配\n\n```xml\n<bean id=\"user\" class=\"com.zhao.pojo.User\" autowire=\"byName\">\n    <property name=\"name\" value=\"zhangsan\"/>\n</bean>\n\n<bean id=\"dog\" class=\"com.zhao.pojo.Dog\"/>\n<bean id=\"cat\" class=\"com.zhao.pojo.Cat\"/>\n<bean id=\"user\" class=\"com.zhao.pojo.User\" autowire=\"byType\">\n    <property name=\"name\" value=\"zhangsan\"/>\n</bean>\n```\n\n### 6、注入内部bean和级联赋值\n\n注入属性-内部bean\n\n- 一对多关系：部门和员工一个部门有多个员工，一个员工属于一个部门（部门是一，员工是多）\n- 在实体类之间表示一对多关系，员工表示所属部门，使用对象类型属性进行表示\n- 在spring配置文件中配置\n\n``` java\n//部门类\npublic class Dept {\n    private String dname;\n    public void setDname(String dname) {\n        this.dname = dname;\n    }\n}\n\n//员工类\npublic class Emp {\n    private String ename;\n    private String gender;\n    //员工属于某一个部门，使用对象形式表示\n    private Dept dept;\n    \n    public void setDept(Dept dept) {\n        this.dept = dept;\n    }\n    public void setEname(String ename) {\n        this.ename = ename;\n    }\n    public void setGender(String gender) {\n        this.gender = gender;\n    }\n}\n```\n\n``` xml\n<!--内部bean-->\n<bean id=\"emp\" class=\"com.zhao.spring5.bean.Emp\">\n    <!--设置两个普通属性-->\n    <property name=\"ename\" value=\"Andy\"></property>\n    <property name=\"gender\" value=\"女\"></property>\n    <!--设置对象类型属性-->\n    <property name=\"dept\">\n        <bean id=\"dept\" class=\"com.zhao.spring5.bean.Dept\"><!--内部bean赋值-->\n            <property name=\"dname\" value=\"宣传部门\"></property>\n        </bean>\n    </property>\n</bean>\n```\n\n注入属性-级联赋值\n\n``` xml\n<!--方式一：级联赋值-->\n<bean id=\"emp\" class=\"com.zhao.spring5.bean.Emp\">\n    <!--设置两个普通属性-->\n    <property name=\"ename\" value=\"Andy\"></property>\n    <property name=\"gender\" value=\"女\"></property>\n    <!--级联赋值-->\n    <property name=\"dept\" ref=\"dept\"></property>\n</bean>\n<bean id=\"dept\" class=\"com.zhao.spring5.bean.Dept\">\n    <property name=\"dname\" value=\"公关部门\"></property>\n</bean>\n```\n\n``` java\n//方式二：生成dept的get方法（get方法必须有！！）\npublic Dept getDept() {\n    return dept;\n}\n```\n\n``` xml\n<!--级联赋值-->\n<bean id=\"emp\" class=\"com.zhao.spring5.bean.Emp\">\n    <!--设置两个普通属性-->\n    <property name=\"ename\" value=\"jams\"></property>\n    <property name=\"gender\" value=\"男\"></property>\n    <!--级联赋值-->\n    <property name=\"dept\" ref=\"dept\"></property>\n    <property name=\"dept.dname\" value=\"技术部门\"></property>\n</bean>\n<bean id=\"dept\" class=\"com.zhao.spring5.bean.Dept\">\n</bean>\n```\n\n### 7、IoC 操作 Bean 管理——xml注入集合属性\n\n``` java\n//（1）创建类，定义数组、list、map、set 类型属性，生成对应 set 方法\npublic class Stu {\n    //1 数组类型属性\n    private String[] courses;\n    //2 list集合类型属性\n    private List<String> list;\n    //3 map集合类型属性\n    private Map<String,String> maps;\n    //4 set集合类型属性\n    private Set<String> sets;\n\n    public void setSets(Set<String> sets) {\n        this.sets = sets;\n    }\n    public void setCourses(String[] courses) {\n        this.courses = courses;\n    }\n    public void setList(List<String> list) {\n        this.list = list;\n    }\n    public void setMaps(Map<String, String> maps) {\n        this.maps = maps;\n    }\n}\n```\n\n``` xml\n<!--（2）在 spring 配置文件进行配置-->\n<bean id=\"stu\" class=\"com.zhao.spring5.collectiontype.Stu\">\n    <!--数组类型属性注入-->\n    <property name=\"courses\">\n        <array>\n            <value>java课程</value>\n            <value>数据库课程</value>\n        </array>\n    </property>\n    <!--list类型属性注入-->\n    <property name=\"list\">\n        <list>\n            <value>张三</value>\n            <value>小三</value>\n        </list>\n    </property>\n    <!--map类型属性注入-->\n    <property name=\"maps\">\n        <map>\n            <entry key=\"JAVA\" value=\"java\"></entry>\n            <entry key=\"PHP\" value=\"php\"></entry>\n        </map>\n    </property>\n    <!--set类型属性注入-->\n    <property name=\"sets\">\n        <set>\n            <value>MySQL</value>\n            <value>Redis</value>\n        </set>\n    </property>\n</bean>\n```\n\n### 8、在集合里面设置对象类型值\n\n``` java\n//学生所学多门课程\nprivate List<Course> courseList;//创建集合\npublic void setCourseList(List<Course> courseList) {\n    this.courseList = courseList;\n}\n```\n\n``` xml\n<!--创建多个course对象-->\n<bean id=\"course1\" class=\"com.zhao.spring5.collectiontype.Course\">\n    <property name=\"cname\" value=\"Spring5框架\"></property>\n</bean>\n<bean id=\"course2\" class=\"com.zhao.spring5.collectiontype.Course\">\n    <property name=\"cname\" value=\"MyBatis框架\"></property>\n</bean>\n\n<!--注入list集合类型，值是对象-->\n<property name=\"courseList\">\n    <list>\n        <ref bean=\"course1\"></ref>\n        <ref bean=\"course2\"></ref>\n    </list>\n</property>\n```\n\n``` xml\n<!--第一步：在 spring 配置文件中引入名称空间 util-->\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:util=\"http://www.springframework.org/schema/util\" <!--添加util名称空间-->\nxsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\nhttp://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util.xsd\">  <!--添加util名称空间-->\n\n<!--第二步：使用 util 标签完成 list 集合注入提取-->\n<!--把集合注入部分提取出来-->\n<!--1 提取list集合类型属性注入-->\n<util:list id=\"bookList\">\n    <value>易筋经</value>\n    <value>九阴真经</value>\n    <value>九阳神功</value>\n</util:list>\n\n<!--2 提取list集合类型属性注入使用-->\n<bean id=\"book\" class=\"com.zhao.spring5.collectiontype.Book\" scope=\"prototype\">\n    <property name=\"list\" ref=\"bookList\"></property>\n</bean>\n```\n\n### 9. Bean 作用域\n\n在 Spring 里面，默认情况下，bean 是单实例对象，下面进行作用域设置：\n\n- 在 Spring 配置文件 bean 标签里面有属性（scope）用于设置单实例还是多实例\n- `singleton`：表示是单实例对；`prototype`：表示是多实例对象\n\n``` xml \n<bean id=\"book\" class=\"com.zhao.spring5.collectiontype.Book\" scope=\"prototype\"> <!--设置为多实例-->\n        <property name=\"list\" ref=\"bookList\"></property>\n</bean>\n```\n\n设置 scope 值是 `singleton` 时候，加载 Spring 配置文件时候就会创建实例对象 ；设置 scope 值是 `prototype`时候，不是在加载 Spring 配置文件时候创建对象，而是在调用 `getBean `方法时候才创建实例对象\n\n### 10、Bean 生命周期\n\n生命周期 ：从对象创建到对象销毁的过程。bean 的生命周期有七步 （正常生命周期为五步，而配置后置处理器后为七步）更多细节见[【Spring】Spring5注解驱动开发](https://yuyun-zhao.github.io/2021/06/25/%E3%80%90Spring%E3%80%91Spring5%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/)。\n\n- 通过构造器创建 bean 实例（无参数构造）\n- 为 bean 的属性设置值和对其他 bean 引用（调用 set 方法）\n- 把 bean 实例传递 bean 后置处理器的方法 `postProcessBeforeInitialization`\n- 调用 bean 的初始化的方法（需要在配置文件中配置初始化的方法`init-method`）\n- 把 bean 实例传递 bean 后置处理器的方法 `postProcessAfterInitialization`\n- bean 可以使用了（对象获取到了）\n- 当容器关闭时候，调用 bean 的销毁的方法（需要进行配置销毁的方法` destroy-method`）\n\n``` java\npublic class MyBeanPost implements BeanPostProcessor {//创建后置处理器实现类\n    @Override\n    public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException {\n        System.out.println(\"在初始化之前执行的方法\");\n        return bean;\n    }\n    @Override\n    public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n        System.out.println(\"在初始化之后执行的方法\");\n        return bean;\n    }\n}\n```\n\n### 10. FactoryBean\n\nSpring 有两种类型 bean，一种普通 bean，另外一种工厂 bean（FactoryBean）\n\n- 普通bean：在配置文件中定义 bean 类型就是返回类型\n- 工厂bean：在配置文件定义 bean 类型可以和返回类型不一样。\n  - 第一步：创建类，让这个类作为工厂bean，实现接口`FactoryBean `；\n  - 第二步：实现接口里面的方法，在实现的方法中定义返回的 bean 类型\n\n``` java\npublic class MyBean implements FactoryBean<Course> {\n\n    //定义返回bean\n    @Override\n    public Course getObject() throws Exception {\n        Course course = new Course();\n        course.setCname(\"abc\");\n        return course;\n    }\n}\n```\n\n``` xml\n<bean id=\"myBean\" class=\"com.zhao.spring5.factorybean.MyBean\">\n</bean>\n```\n\n``` java\n@Test\npublic void test() {\n ApplicationContext context =\n new ClassPathXmlApplicationContext(\"bean.xml\");\n Course course = context.getBean(\"myBean\", Course.class);//返回值类型可以不是定义的bean类型！\n System.out.println(course);\n}\n```\n\n### 11. 引入外部属性文件（如Druid）\n\n``` xml\n<beans xmlns=\"http://www.springframework.org/schema/beans\"\n       xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n       xmlns:context=\"http://www.springframework.org/schema/context\"\n       xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\n                           http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"><!--引入context名称空间-->\n\n    <!-- 组件扫描 -->\n    <context:component-scan base-package=\"com.zhao\"></context:component-scan>\n    \n    <!--引入外部属性文件-->\n    <context:property-placeholder location=\"classpath:jdbc.properties\"/>\n\n    <!--配置连接池-->\n    <bean id=\"dataSource\" class=\"com.alibaba.druid.pool.DruidDataSource\">\n        <property name=\"driverClassName\" value=\"${prop.driverClass}\"></property>\n        <property name=\"url\" value=\"${prop.url}\"></property>\n        <property name=\"username\" value=\"${prop.userName}\"></property>\n        <property name=\"password\" value=\"${prop.password}\"></property>\n    </bean>\n\n</beans>\n```\n\n\n## 基于注解方式\n\n基于注解方式的Spring开发详细内容见[【Spring】Spring5 注解驱动开发](https://yuyun-zhao.github.io/2021/06/25/%E3%80%90Spring%E3%80%91Spring5-%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/)。\n\n### 1、什么是注解\n\n- 注解是代码特殊标记，格式：@注解名称(属性名称=属性值, 属性名称=属性值…)\n- 使用注解，注解作用在类上面，方法上面，属性上面\n- 使用注解目的：简化 xml 配置\n\n### 2、Spring 针对 Bean 管理中创建对象提供注解\n\n 下面四个注解功能是一样的，都可以用来创建 bean 实例\n\n- [@Component](https://github.com/Component)\n- [@Controller](https://github.com/Controller)：web层\n- [@Service](https://github.com/Service)：service层\n- [@Repository](https://github.com/Repository)：dao层\n\n### 3、基于注解方式实现对象创建\n\n 第一步 引入依赖 （引入spring-aop jar包）\n\n 第二步 开启组件扫描\n\n``` xml\n<!--开启组件扫描\n 1 如果扫描多个包，多个包使用逗号隔开\n 2 扫描包上层目录 \n-->\n<context:component-scan base-package=\"com.zhao\"></context:component-scan>\n```\n\n第三步 创建类，在类上面添加创建对象注解\n\n``` java\n//在注解里面 value 属性值可以省略不写，\n//默认值是类名称，首字母小写\n//UserService -- userService\n@Component(value = \"userService\") //注解等同于XML配置文件：<bean id=\"userService\" class=\"..\"/>\npublic class UserService {\n    public void add() {\n        System.out.println(\"service add.......\");\n    }\n}\n```\n\n### 4、开启组件扫描细节配置\n\n```xml\n<!--示例 1\n use-default-filters=\"false\" 表示现在不使用默认 filter，自己配置 filter\n context:include-filter ，设置扫描哪些内容\n-->\n<context:component-scan base-package=\"com.zhao\" use-default-filters=\"false\">\n    <context:include-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/><!--代表只扫描Controller注解的类-->\n</context:component-scan>\n\n<!--示例 2\n 下面配置扫描包所有内容\n context:exclude-filter： 设置哪些内容不进行扫描\n-->\n<context:component-scan base-package=\"com.zhao\">\n    <context:exclude-filter type=\"annotation\" expression=\"org.springframework.stereotype.Controller\"/><!--表示Controller注解的类之外一切都进行扫描-->\n</context:component-scan>\n```\n\n### 5、基于注解方式实现属性注入\n\n（1）`@Autowired`：根据属性**类型**进行自动装配:\n\n- 第一步 把 service 和 dao 对象创建，在 service 和 dao 类添加创建对象注解\n- 第二步 在 service 注入 dao 对象，在 service 类添加 dao 类型属性，在属性上面使用注解\n\n``` java\n@Service\npublic class UserService {\n    //定义 dao 类型属性\n    //不需要添加 set 方法\n    //添加注入属性注解\n    @Autowired\n    private UserDao userDao;\n    public void add() {\n        System.out.println(\"service add.......\");\n        userDao.add();\n    }\n}\n\n//Dao实现类\n@Repository\n//@Repository(value = \"userDaoImpl1\")\npublic class UserDaoImpl implements UserDao {\n    @Override\n    public void add() {\n        System.out.println(\"dao add.....\");\n    }\n}\n```\n\n（2）`@Qualifier`：根据对象**名称**进行注入，这个`@Qualifier` 注解的使用，和上面`@Autowired` 一起使用（目的在于区别同一接口下有多个实现类）\n\n``` java\n//定义 dao 类型属性\n//不需要添加 set 方法\n//添加注入属性注解\n@Autowired //根据类型进行注入\n//根据名称进行注入（目的在于区别同一接口下有多个实现类，根据类型就无法选择，从而出错！）\n@Qualifier(value = \"userDaoImpl1\") \nprivate UserDao userDao;\n```\n\n（3）`@Resource`：可以根据类型注入，也可以根据名称注入（它属于javax包下的注解，不推荐使用！）\n\n``` java\n//@Resource //根据类型进行注入\n@Resource(name = \"userDaoImpl1\") //根据名称进行注入\nprivate UserDao userDao;\n```\n\n（4）`@Value`：注入**普通类型属性**\n\n``` java\n@Value(value = \"abc\")\nprivate String name\n```\n\n**总结：若某类型的对象只有一个，则可以使用`@Autowired`注解，此时只会找到唯一的一个对象；但若某类型的对象不止一个，则要使用`@Qualifier`注解，其会根据对象名称去寻找指定的对象。若注入基本类型对象使用`@Value`**。\n\n### 6、作用域\n\n[@scope](https://github.com/scope)\n\n- singleton：默认的，Spring会采用单例模式创建这个对象。关闭工厂 ，所有的对象都会销毁。\n- prototype：多例模式。关闭工厂 ，所有的对象不会销毁。内部的垃圾回收机制会回收\n\n```java\n@Controller(\"user\")\n@Scope(\"prototype\")\npublic class User {\n    @Value(\"秦疆\")    \n    public String name;\n}\n```\n\n### 7、完全注解开发\n\n（1）创建配置类，替代 xml 配置文件\n\n``` java\n@Configuration //作为配置类，替代 xml 配置文件\n@ComponentScan(basePackages = {\"com.zhao\"})\n@Import(SpringConfig2.class)\npublic class SpringConfig {\n    \n    // 注册一个bean，相当于之前的一个bean标签\n    // 方法名称，相当于bean标签里的id属性\n    // 方法返回值，相当于bean标签里的class属性\n    @Bean\n    public User getUser() {\n        return new User();\n    }\n    \n}\n```\n\n（2）编写测试类\n\n``` java\n@Test\npublic void testService2() {\n    //加载配置类\n    ApplicationContext context\n        = new AnnotationConfigApplicationContext(SpringConfig.class);\n    UserService userService = context.getBean(\"userService\",\n                                              UserService.class);\n    System.out.println(userService);\n    userService.add();\n}\n```\n\n## Spring 循环依赖\n\n\n\n\n\nbean仓库只负责存储，不负责创建，创建由beanFactory完成\n\n\n\n``` java\nBeanFactory beanFactory;\nSingletonBeanRegistry beanRegistry;\n\n\n    \n//DefaultListableBeanFactory 同时实现上面两个接口\nDefaultListableBeanFactory factory = new DefaultListableBeanFactory();\nfactory.getSingleton(\"a\"); // 直接去bean仓库里取，若a不存在，不会创建该对象\n\n\n```\n\n双重检测所在getSingleton 有个双重检测\n\n仓库自己将Bean添加，这个过程有双重检测\n\n更集中地控制线程安全性\n\n\n\ngetparent\n\n第一次取自己的，自己没有去取父亲的\n\n父亲还取不到 再创建\n\n该过程见图SPring mvc\n\n\n\n半成品池\n\n\n\n创建a时依赖b, 所以去创建b,但是创建b有依赖a，则先把a放到半成品池里。所以创建b时会从半成品里取a 取出后去创建b并放到单例池singletonFactory里，再回到创建a的过程，a从单例池中取出b，创建完毕后a放到单例池，半成品池里取消a\n\n\n\n直播断了5分钟断在了 半成品和单例里的组件A是否是相同的\n\n\n\na.getB 有值，a是代理对象，能调用方法获取b的值\n\na.b没有值 因为被代理的原始a才有b，直接调代理的aProxy的.b没有值，因为代理对象没必要有b。只用代理方法，不用代理属性值\n\n真实的a里的b属性也是个代理对象。\n\n\n\n工厂池  提前引用 三级缓存\n\n\n\n把工厂ObejectFactory放到工厂池中，后面就获得提前引用\n\n\n\nsingletonFactories是三级工厂\n\n\n\n先去单例池，没有，再去半成品池取，最后去工厂池里找，从工厂池里获取一个工厂，该工厂调用getObject() ，获得提前引用，获取到的是代理对象，将该对象放到二级缓存半成品里，在从工厂里移除这个beanName\n\n为什么有半成品池：提前引用可能有多次，比如a依赖b,c，两个都依赖a，b获得了a的提前引用后将该对象放到二级缓存里，并从工厂池移除该a的代理对象，c之后就不用再创建a了（若不放到二级缓存就会重复提前引用），直接去二级缓存取A。保证动态代理对象A只会被创建一次。\n\n工厂池里存了很多工厂ObjectFactory，这些工厂调用getObject()取得a的动态代理对象singletonObject（提前引用），并将其放到二级缓存里，并从三级里移除该对象以免重复创建\n\n\n\n半成品池在填充属性时（set时）获取的\n\n半成品的目的：不要重复代理\n\n\n\n\n\n对照着图\n\n\n\n\n\n图片\n\n\n\n\n\n什么时候不能解决循环依赖：\n\n- 多例\n- 在构造方法里有依赖\n- 手动关闭了循环依赖功能 `context.setAllowCircularReference(false);`\n\n\n\n\n\n三级缓存（图片里的）\n\nsingletonObjects 单例池\n\n\n\nearlySignletonObejctys是半成品池 二级缓存\n\n\n\n","tags":["SSM","Spring"],"categories":["Spring","SSM"]},{"title":"【MyBatis】MyBatis","url":"/2021/05/15/【MyBatis】MyBatis/","content":"\n## MyBatis简介\n\n![img](/images/%E3%80%90MyBatis%E3%80%91MyBatis/kuangstudyb0b1cef3-3796-4822-bfe8-52a894961853.png)\n\n### 什么是MyBatis\n\n- MyBatis 是一款优秀的**持久层框架**\n- MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集的过程\n- MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 实体类 【Plain Old Java Objects,普通的 Java对象】映射成数据库中的记录。\n- MyBatis 本是apache的一个开源项目ibatis, 2010年这个项目由apache 迁移到了google code，并且改名为MyBatis 。在2013年11月迁移到**Github** .\n- Mybatis官方文档 : http://www.mybatis.org/mybatis-3/zh/index.html\n- GitHub : https://github.com/mybatis/mybatis-3\n\n### 持久化\n\n持久化是将程序数据在持久状态和瞬时状态间转换的机制。\n\n- 即把数据（如内存中的对象）保存到可永久保存的存储设备中（如磁盘）。持久化的主要应用是将内存中的对象存储在数据库中，或者存储在磁盘文件中、XML数据文件中等等。\n- JDBC就是一种持久化机制。文件IO也是一种持久化机制。\n\n### MyBatis的优点\n\n- 简单易学：本身就很小且简单。没有任何第三方依赖，最简单安装只要两个jar文件+配置几个sql映射文件就可以了，易于学习，易于使用，通过文档和源代码，可以比较完全的掌握它的设计思路和实现。\n- 灵活：mybatis不会对应用程序或者数据库的现有设计强加任何影响。 sql写在xml里，便于统一管理和优化。通过sql语句可以满足操作数据库的所有需求。\n- 解除sql与程序代码的耦合：通过提供DAO层，将业务逻辑和数据访问逻辑分离，使系统的设计更清晰，更易维护，更易单元测试。sql和代码的分离，提高了可维护性。\n- 提供xml标签，支持编写动态sql。\n\n<!-- More -->\n\n## Hello MyBatis\n\n**1.  maven中添加依赖**\n\n```xml\n<dependencies>\n    <dependency>\n        <groupId>org.mybatis</groupId>\n        <artifactId>mybatis</artifactId>\n        <version>3.5.3</version>\n    </dependency>\n\n    <dependency>\n        <groupId>mysql</groupId>\n        <artifactId>mysql-connector-java</artifactId>\n        <version>5.1.47</version>\n    </dependency>\n</dependencies>\n\n<!-- 设置路径，保证src中的.xml文件能够被识别，解决静态资源路径问题 -->\n<build>\n    <resources>\n        <resource>\n            <directory>src/main/resources</directory>\n            <includes>\n                <include>**/*.properties</include>\n                <include>**/*.xml</include>\n            </includes>\n            <filtering>true</filtering>\n        </resource>\n        <resource>\n            <directory>src/main/java</directory>\n            <includes>\n                <include>**/*.properties</include>\n                <include>**/*.xml</include>\n            </includes>\n            <filtering>true</filtering>\n        </resource>\n    </resources>\n</build>\n\n```\n\n**2. 配置mybatis-config.xml**\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE configuration\n        PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-config.dtd\">\n<configuration>\n\n    <!-- 引入外部资源文件 -->\n    <properties resource=\"db.properties\"/>\n    \n    <settings>\n        <!-- 开启日志 -->\n        <setting name=\"logImpl\" value=\"STDOUT_LOGGING\"/>\n        <!-- 将数据库字段名按照驼峰命名规定映射为实体类属性名 -->\n        <setting name=\"mapUnderscoreToCamelCase\" value=\"true\"/>\n        <!-- 开启二级缓存 -->\n        <setting name=\"cacheEnabled\" value=\"true\"/>\n    </settings>\n\n    <typeAliases>\n        <!-- 给某个类起别名，在mapper配置文件中可以直接使用别名 -->\n        <typeAlias type=\"com.zhao.pojo.User\" alias=\"user\"/>\n        <!-- 在某个包下扫描所有类，首字母小写后作为其别名 -->\n        <package name=\"com.zhao.pojo\"/>\n    </typeAliases>\n    \n    <environments default=\"development\">\n        <environment id=\"development\">\n            <transactionManager type=\"JDBC\"/>\n            <dataSource type=\"POOLED\">\n                <property name=\"driver\" value=\"${driver}\"/>\n                <property name=\"url\" value=\"${url}\"/>\n                <property name=\"username\" value=\"${username}\"/>\n                <property name=\"password\" value=\"${password}\"/>\n            </dataSource>\n        </environment>\n    </environments>\n\n    <!-- 注册mapper类 -->\n    <mappers>\n        <mapper resource=\"com/zhao/dao/UserMapper.xml\"/>\n    </mappers>\n\n</configuration>\n```\n\ndb.properties\n\n```properties\ndriver=com.mysql.jdbc.Driver\nurl=jdbc:mysql://localhost:3306/smbms?useUnicode=true&characterEncoding=utf8&useSSL=true\nusername=root\npassword=zhaoyuyun\n```\n\n**注意**：在MyBatis的核心配置文件xml中，配置数据库的参数时，url=xxx\\&amp;characterset=xxx需要带上转义符号amp; 但是如果通过db.properties中设置参数时不需要加上转义符，只需要&\n\n**3. 编写MyBatis工具类**\n\n``` java\nimport org.apache.ibatis.io.Resources;\nimport org.apache.ibatis.session.SqlSession;\nimport org.apache.ibatis.session.SqlSessionFactory;\nimport org.apache.ibatis.session.SqlSessionFactoryBuilder;\nimport java.io.IOException;\nimport java.io.InputStream;\n\npublic class MybatisUtils {\n    private static SqlSessionFactory sqlSessionFactory;\n    \n    static {\n        try {\n            String resource = \"mybatis-config.xml\";\n            InputStream inputStream = Resources.getResourceAsStream(resource);\n            sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n    \n    //获取SqlSession连接\n    public static SqlSession getSession(){\n        // 设置自动提交事务\n        return sqlSessionFactory.openSession(true);\n    }\n}\n```\n\n**4. 注册实体类**\n\n``` java\npublic class User {\n    private int id;        //id\n    private String name;   //姓名\n    private String pwd;    //密码\n   \n    //构造,有参,无参\n    //set/get\n    //toString()\n}\n```\n\n**5. 编写Mapper接口类**\n\n``` java\nimport com.zhao.pojo.User;\nimport java.util.List;\npublic interface UserMapper {\n    List<User> selectUser();\n}\n```\n\n**6. 编写Mapper.xml配置文件（配置文件中namespace中的名称为对应Mapper接口或者Dao接口的完整包名，必须一致！）**\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.zhao.dao.UserMapper\">\n    <select id=\"selectUser\" resultType=\"com.zhao.pojo.User\">\n        select * from user\n    </select>\n</mapper>\n```\n\n**7. 测试**\n\n``` java\npublic class MyTest {\n    @Test\n    public void selectUser() {\n        SqlSession session = MybatisUtils.getSession();\n        \n        //方法一:\n        //List<User> users = session.selectList(\"com.zhao.mapper.UserMapper.selectUser\");\n        \n        //方法二:\n        UserMapper mapper = session.getMapper(UserMapper.class);\n        List<User> users = mapper.selectUser();\n        for (User user: users){\n            System.out.println(user);\n        }\n        session.close();\n    }\n}\n```\n\n## MyBatis CRUD\n\n### select\n\n四种语句的通用属性：\n\n- `id`：命名空间中唯一的标识符，接口中的方法名与映射文件中的SQL语句id一一对应\n- `parameterType`：传入SQL语句的参数类型（可以使用万能的Map）\n- `resultType`：SQL语句返回值类型（完整的类名或者别名）\n\n**需求：根据id查询用户**\n\n1. 在UserMapper中添加对应方法（可以使用`@Param`注解给形参名起别名）\n\n   ```java\n   public interface UserMapper { \n       //查询全部用户\n       List<User> selectUser();    \n       //根据id查询用户    \n       User selectUserById(@Param(\"id\") int id);\n   }\n   ```\n\n2. 在UserMapper.xml中添加select语句（MyBatis会将`select * `返回的数据库字段名映射为pojo类对象的属性，即去对应的实体类中查找相应字段名的set方法设值【自动映射】，若属性名与数据库字段名不一致，即找不到对应的set方法，则属性值为null，此时需要使用`ResultMap`）\n\n   ```xml\n   <select id=\"selectUserById\" resultType=\"com.zhao.pojo.User\">\n       select * from user where id = #{id}\n   </select>\n   ```\n\n3. 测试\n\n   ```java\n   @Test\n   public void tsetSelectUserById() { \n       //获取SqlSession连接  \n       SqlSession session = MybatisUtils.getSession();  \n       UserMapper mapper = session.getMapper(UserMapper.class);\n       User user = mapper.selectUserById(1);\n       System.out.println(user);    \n       session.close();\n   }\n   ```\n\n### insert\n\n**需求：给数据库增加一个用户**\n\n1. 在UserMapper接口中添加对应的方法\n\n   ```java\n   //添加一个用户\n   int addUser(User user);\n   ```\n\n2. 在UserMapper.xml中添加insert语句（传入形参是pojo时，SQL语句中的#{}会与类对象的属性变量名判断是否能够对应，不能对应的解析为null）\n\n   ```xml\n   <insert id=\"addUser\" parameterType=\"com.zhao.pojo.User\">     \n       insert into user (id,name,pwd) values (#{id},#{name},#{pwd})\n   </insert>\n   ```\n\n3. 测试\n\n   ```java\n   @Test\n   public void testAddUser() {\n       SqlSession session = MybatisUtils.getSession(); \n       UserMapper mapper = session.getMapper(UserMapper.class);\n       User user = new User(5,\"王五\",\"zxcvbn\");\n       int i = mapper.addUser(user);\n       System.out.println(i);\n       \n       // 提交事务，不写的话不会提交到数据库，除非设置sqlSessionFactory.openSession(true);\n       session.commit();\n       \n       session.close();\n   }\n   ```\n\n**注意：增、删、改操作需要提交事务！设置方法：**\n\n- 每次会话使用完后`session.commit();`\n- 或在工具类中设置`sqlSessionFactory.openSession(true);`\n\n### update\n\n**需求：修改用户的信息**\n\n1. 编写接口方法\n\n   ```java\n   //修改一个用户\n   int updateUser(User user);\n   ```\n\n2. 编写对应的配置文件SQL\n\n   ```xml\n   <update id=\"updateUser\" parameterType=\"com.zhao.pojo.User\">\n       update user set name = #{name},pwd = #{pwd} where id = #{id}\n   </update>\n   ```\n\n3. 测试\n\n   ```java\n   @Test\n   public void testUpdateUser() {\n       SqlSession session = MybatisUtils.getSession();\n       UserMapper mapper = session.getMapper(UserMapper.class);\n       User user = mapper.selectUserById(1);\n       user.setPwd(\"123456\");\n       int i = mapper.updateUser(user);\n       System.out.println(i);\n       session.commit();\n       session.close();\n   }\n   ```\n\n### delete\n\n**需求：根据id删除一个用户**\n\n1. 编写接口方法\n\n   ```java\n   //根据id删除用户\n   int deleteUser(int id);\n   ```\n\n2. 编写对应的配置文件SQL\n\n   ```xml\n   <delete id=\"deleteUser\" parameterType=\"int\">\n       delete from user where id = #{id}\n   </delete>\n   ```\n\n3. 测试\n\n   ```java\n   @Test\n   public void testDeleteUser() {\n       SqlSession session = MybatisUtils.getSession();\n       UserMapper mapper = session.getMapper(UserMapper.class);\n       int i = mapper.deleteUser(5);\n       System.out.println(i);\n       session.commit();\n       session.close();\n   }\n   ```\n\n### 传参时变量名不一致问题\n\n当传入的形参变量名称与SQL语句中的#{}中变量名不一致时，有两种解决方案：\n\n1. 使用`@Param`注解\n\n- 在方法只接受一个参数的情况下，可以不使用[@Param](https://github.com/Param)。\n- 在方法接受多个参数的情况下，建议一定要使用[@Param](https://github.com/Param)注解给参数命名。\n- 如果参数是 JavaBean ， 则不能使用[@Param](https://github.com/Param)。\n- 不使用[@Param](https://github.com/Param)注解时，参数只能有一个，并且是Javabean。\n\n``` java\n//通过密码和名字查询用户\nUser selectUserByNP(@Param(\"uname\") String username, @Param(\"pwd\") String password);\n\n/*\n    <select id=\"selectUserByNP\" resultType=\"com.zhao.pojo.User\">\n      select * from user where name = #{uname} and password = #{pwd}\n    </select>\n*/\n```\n\n2. 使用万能的Map\n\n在接口方法中，参数直接传递Map；\n\n``` java\nUser selectUserByNP2(Map<String,Object> map);\n```\n\n编写SQL语句的时候，需要传递参数类型，参数类型为Map\n\n``` xml\n<select id=\"selectUserByNP2\" parameterType=\"map\" resultType=\"com.zhao.pojo.User\">\n    select * from user where name = #{uname} and password = #{pwd}\n</select>\n```\n\n在使用方法的时候，Map的 key 为 sql中取的值即可，没有顺序要求！\n\n``` java\nMap<String, Object> map = new HashMap<String, Object>();\nmap.put(\"uname\", \"小明\");\nmap.put(\"pwd\", \"123456\");\nUser user = mapper.selectUserByNP2(map);\n```\n\n**小结：**\n\n- 所有的增删改操作都需要提交事务\n- 接口所有的普通参数，尽量都写上[@Param](https://github.com/Param)参数，尤其是多个参数时，必须写上\n- 有时候根据业务的需求，可以考虑使用map传递参数\n- 为了规范操作，在SQL的配置文件中，尽量将Parameter参数和resultType都写上\n\n### \\#与$的区别\n\n- \\#{} 的作用主要是替换预编译语句(PrepareStatement)中的占位符? ，其可以防止SQL注入问题【推荐使用】\n\n  ```sql\n  INSERT INTO user (name) VALUES (#{name});\n  INSERT INTO user (name) VALUES (?);\n  ```\n\n- ${} 的作用是直接进行字符串替换\n\n  ```sql\n  INSERT INTO user (name) VALUES ('${name}');\n  INSERT INTO user (name) VALUES ('zhangsan');\n  ```\n\n## MyBatis配置解析\n\n### 核心配置文件\n\n- mybatis-config.xml 系统核心配置文件\n- MyBatis 的配置文件包含了会深深影响 MyBatis 行为的设置和属性信息。\n- 能配置的内容如下：\n\n```\nconfiguration（配置）\nproperties（属性）\nsettings（设置）\ntypeAliases（类型别名）\ntypeHandlers（类型处理器）\nobjectFactory（对象工厂）\nplugins（插件）\nenvironments（环境配置）\n\tenvironment（环境变量）\n\t\ttransactionManager（事务管理器）\n\t\tdataSource（数据源）\ndatabaseIdProvider（数据库厂商标识）\nmappers（映射器）\n<!-- 注意元素节点的顺序！顺序不对会报错 -->\n```\n\n### environments\n\n```xml\n<environments default=\"development\">\n    <environment id=\"development\">\n        <transactionManager type=\"JDBC|MANAGED\">\n            <property name=\"...\" value=\"...\"/>\n        </transactionManager>\n        <dataSource type=\"UNPOOLED|POOLED|JNDI\">\n            <property name=\"driver\" value=\"${driver}\"/>\n            <property name=\"url\" value=\"${url}\"/>\n            <property name=\"username\" value=\"${username}\"/>\n            <property name=\"password\" value=\"${password}\"/> \n        </dataSource>\n    </environment>\n</environments>\n```\n\n配置MyBatis的多套运行环境，将SQL映射到多个不同的数据库上，必须指定其中一个为默认运行环境（通过default指定）\n\n子元素节点：**environment**\n- 具体的一套环境，通过设置id进行区别，id保证唯一\n- 子元素节点：transactionManager - [ 事务管理器 ]\n  - 详情：[点击查看官方文档](http://www.mybatis.org/mybatis-3/zh/configuration.html#environments)\n  - 这两种事务管理器类型都不需要设置任何属性。\n- 子元素节点：**数据源（dataSource）**\n  - dataSource 元素使用标准的 JDBC 数据源接口来配置 JDBC 连接对象的资源。\n  - 数据源是必须配置的。\n  - 有三种内建的数据源类型\n  - unpooled： 这个数据源的实现只是每次被请求时打开和关闭连接。\n  - **pooled**： 这种数据源的实现利用“池”的概念将 JDBC 连接对象组织起来 , 这是一种使得并发 Web 应用快速响应请求的流行处理方式。\n  - jndi：这个数据源的实现是为了能在如 Spring 或应用服务器这类容器中使用，容器可以集中或在外部配置数据源，然后放置一个 JNDI 上下文的引用。\n  - 数据源也有很多第三方的实现，比如dbcp，c3p0，druid等等….\n\n### mappers\n\n映射器 : 定义映射SQL语句文件。\n\n#### 引入资源方式\n\n```xml\n<!-- 使用相对于类路径的资源引用 -->\n<mappers> \n    <mapper resource=\"org/mybatis/builder/PostMapper.xml\"/>\n</mappers>\n\n<!-- 使用完全限定资源定位符（URL） -->\n<mappers>\n    <mapper url=\"file:///var/mappers/AuthorMapper.xml\"/>\n</mappers>\n\n<!-- 使用映射器接口实现类的完全限定类名需要配置文件名称和接口名称一致，并且位于同一目录下--><mappers>\n    <mapper class=\"org.mybatis.builder.AuthorMapper\"/>\n</mappers>\n\n<!-- 将包内的映射器接口实现全部注册为映射器但是需要配置文件名称和接口名称一致，并且位于同一目录下-->\n<mappers>\n    <package name=\"org.mybatis.builder\"/>\n</mappers>\n```\n\n#### Mapper文件\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"  \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.zhao.mapper.UserMapper\"></mapper>\n```\n\nnamespace中文意思：命名空间，作用如下：\n\n1. namespace和子元素的id联合保证唯一，区别不同的mapper\n2. 绑定DAO接口\n   - namespace的命名必须跟某个接口同名\n   - 接口中的方法与映射文件中sql语句id应该一一对应\n3. namespace命名规则 : 包名+类名\n\n### typeAliases\n\n类型别名是为 Java 类型设置一个短的名字。它只和 XML 配置有关，存在的意义仅在于用来减少类完全限定名的冗余。\n\n```xml\n<!--配置别名,注意顺序-->\n<typeAliases>\n    <typeAlias type=\"com.zhao.pojo.User\" alias=\"User\"/>\n</typeAliases>\n```\n\n当这样配置时，`User`可以用在任何使用`com.zhao.pojo.User`的地方。也可以指定一个包名，MyBatis 会在包名下面搜索需要的 Java Bean，比如:\n\n```xml\n<typeAliases>\n    <package name=\"com.zhao.pojo\"/>\n</typeAliases>\n```\n\n每一个在包 `com.zhao.pojo` 中的 Java Bean，在没有注解的情况下，会使用 Bean 的首字母小写的非限定类名来作为它的别名。\n\n若有注解，则别名为其注解值：\n\n```java\n@Alias(\"user\")\npublic class User {\n    ...\n}\n```\n\n### settings\n\n[设置（settings）](http://www.mybatis.org/mybatis-3/zh/configuration.html#settings)相关\n\n- 懒加载\n- 日志实现\n- 缓存开启关闭\n\n一个配置完整的 settings 元素的示例如下：\n\n```xml\n<settings>  \n    <setting name=\"cacheEnabled\" value=\"true\"/>\n    <setting name=\"lazyLoadingEnabled\" value=\"true\"/>  \n    <setting name=\"multipleResultSetsEnabled\" value=\"true\"/>  \n    <setting name=\"useColumnLabel\" value=\"true\"/>\n    <setting name=\"useGeneratedKeys\" value=\"false\"/>\n    <setting name=\"autoMappingBehavior\" value=\"PARTIAL\"/>\n    <setting name=\"autoMappingUnknownColumnBehavior\" value=\"WARNING\"/>\n    <setting name=\"defaultExecutorType\" value=\"SIMPLE\"/>  \n    <setting name=\"defaultStatementTimeout\" value=\"25\"/> \n    <setting name=\"defaultFetchSize\" value=\"100\"/>\n    <setting name=\"safeRowBoundsEnabled\" value=\"false\"/>  \n    <setting name=\"mapUnderscoreToCamelCase\" value=\"false\"/>  \n    <setting name=\"localCacheScope\" value=\"SESSION\"/>  \n    <setting name=\"jdbcTypeForNull\" value=\"OTHER\"/>\n    <setting name=\"lazyLoadTriggerMethods\" value=\"equals,clone,hashCode,toString\"/>\n</settings>\n```\n\n## ResultMap\n\n**要解决的问题：pojo属性名和数据库字段名不一致**。解决方案：\n\n1. 方案一：为字段名指定别名，别名和java实体类的属性名一致 .\n\n   ```xml\n   <select id=\"selectUserById\" resultType=\"User\">    \n       select id, name, pwd as password from user where id = #{id}\n   </select>\n   ```\n\n**2. 方案二：使用结果集映射->ResultMap** 【推荐】\n\n```xml\n<resultMap id=\"UserMap\" type=\"User\"> \n    <!-- id为主键 -->\n    <id column=\"id\" property=\"id\"/>\n    <!-- column是数据库表的列名 , property是对应实体类的属性名 -->\n    <result column=\"name\" property=\"name\"/>\n    <result column=\"pwd\" property=\"password\"/>\n</resultMap>\n\n<select id=\"selectUserById\" resultMap=\"UserMap\">\n    select id, name, pwd from user where id = #{id}\n</select>\n```\n\n### 自动映射\n\n- `resultMap` 元素是 MyBatis 中最重要最强大的元素。它可以让开发人员从 90% 的 JDBC `ResultSets` 数据提取代码中解放出来。\n- ResultMap 的设计思想是，对于简单的语句根本不需要配置显式的结果映射，而对于复杂一点的语句只需要描述它们的关系就行了。\n\n默认情况没有显式指定 `resultMap`。比如：\n\n```xml\n<select id=\"selectUserById\" resultType=\"map\">\n    select id, name, pwd from user where id = #{id}\n</select>\n```\n\n上述语句只是简单地将所有的列映射到 `HashMap` 的键上，这由 `resultType` 属性指定。虽然在大部分情况下都够用，但是 HashMap 不是一个很好的模型。我们的程序更可能会使用 JavaBean 或 POJO（Plain Old Java Objects，普通老式 Java 对象）作为模型。\n\n### 手动映射\n\n1. 返回值类型为`resultMap`\n\n   ```xml\n   <select id=\"selectUserById\" resultMap=\"UserMap\">\n       select id, name, pwd from user where id = #{id}\n   </select>\n   ```\n\n2. 编写`resultMap`，实现手动映射\n\n   ```xml\n   <resultMap id=\"UserMap\" type=\"User\">\n       <!-- id为主键 -->\n       <id column=\"id\" property=\"id\"/>\n       <!-- column是数据库表的列名, property是对应实体类的属性名 -->\n       <result column=\"name\" property=\"name\"/>\n       <result column=\"pwd\" property=\"password\"/>\n   </resultMap>\n   ```\n\n## 使用注解开发\n\n使用注解开发时不需要再写mapper.xml文件，直接在接口类的方法上添加注解即可。共有四个注解 :\n\n- `@select()`\n- `@update()`\n- `@Insert()`\n- `@delete()`\n\n``` java\n//查询全部用户\n@Select(\"select id,name,pwd password from user\")\npublic List<User> getAllUser();\n```\n\n``` java\n//根据id查询用户\n@Select(\"select * from user where id = #{id}\")\nUser selectUserById(@Param(\"id\") int id);\n```\n\n``` java\n//添加一个用户\n@Insert(\"insert into user (id,name,pwd) values (#{id},#{name},#{pwd})\")\nint addUser(User user);\n```\n\n``` java\n//修改一个用户\n@Update(\"update user set name=#{name},pwd=#{pwd} where id = #{id}\")\nint updateUser(User user);\n```\n\n``` java\n//根据id删除用\n@Delete(\"delete from user where id = #{id}\")\nint deleteUser(@Param(\"id\")int id);\n```\n\n## MyBatis执行流程分析\n\n``` java\n//查询全部用户\n@Select(\"select id,name,pwd password from user\")\npublic List<User> getAllUser();\n```\n\n``` xml\n<!--使用class绑定接口-->\n<mappers>\n    <mapper class=\"com.zhao.mapper.UserMapper\"/>\n</mappers>\n```\n\n``` java\n@Test\npublic void testGetAllUser() {\n    SqlSession session = MybatisUtils.getSession();\n    //本质上利用了jvm的动态代理机制\n    UserMapper mapper = session.getMapper(UserMapper.class);\n    \n●   List<User> users = mapper.getAllUser();\n    for (User user : users){\n        System.out.println(user);\n    }\n    session.close();\n}\n```\n\n利用Debug查看本质\n\n![img](/images/%E3%80%90MyBatis%E3%80%91MyBatis/kuangstudy116bbcb8-3fb6-457d-829b-174782854039.png)\n\n`sqlSession`对象内包含：\n\n- `configuration`：用于加载`mybatis-config.xml`文件中的所有配置信息；\n- `executor`：执行器，用于执行sql语句，含有缓存等信息。\n\n`mapper`对象是指定`Mapper`接口的**动态代理类**，包含：\n\n- `sqlSession`：每个`mapper`都拥有一份`sqlSession`对象，用于执行sql语句；\n- `mapperInterface`：通过反射机制获取`Mapper`接口的全路径名等信息；\n- `methodCache`：方法缓存，包含接口的每个方法和实现。\n\n首先通过反射机制从`session.getMapper(UserMapper.class);`中获取到接口信息，然后动态创建出一个代理类对象`mapper`，其实现了接口的所有方法，使用该代理类执行相应的sql语句。\n\n本质上利用了jvm的动态代理机制\n\n![img](/images/%E3%80%90MyBatis%E3%80%91MyBatis/kuangstudy49f6378c-cff1-46c0-9a2b-aec78e014953.png)\n\nMybatis详细的执行流程\n\n![img](/images/%E3%80%90MyBatis%E3%80%91MyBatis/kuangstudyd3552e34-af83-4ce8-a4ab-45feb0fee43f.png)\n\n## 多对一处理\n\n多对一的理解：多个学生对应一个老师\n\n### 按查询嵌套处理\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<!DOCTYPE mapper\n        PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\n        \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\">\n<mapper namespace=\"com.zhao.mapper.StudentMapper\">\n    <!--\n    需求：获取所有学生及对应老师的信息\n    思路：\n        1. 获取所有学生的信息\n        2. 根据获取的学生信息的老师ID->获取该老师的信息\n        3. 思考问题，这样学生的结果集中应该包含老师，该如何处理呢，数据库中我们一般使用关联查询？\n            1. 做一个结果集映射：StudentTeacher\n            2. StudentTeacher结果集的类型为 Student\n            3. 学生中老师的属性为teacher，对应数据库中为tid。\n               多个 [1,...）学生关联一个老师=> 一对一，一对多\n            4. 查看官网找到：association – 一个复杂类型的关联；使用它来处理关联查询\n    -->\n    <select id=\"getStudents\" resultMap=\"StudentTeacher\">\n      select * from student\n    </select>\n    \n    <resultMap id=\"StudentTeacher\" type=\"Student\">\n        <!--association关联属性  property属性名 javaType属性类型 column在多的一方的表中的列名-->\n        <association property=\"teacher\"  column=\"tid\" javaType=\"Teacher\" select=\"getTeacher\"/>\n    </resultMap>\n    \n    <!--\n    这里传递过来的id，只有一个属性的时候，下面可以写任何值\n    association中column多参数配置：\n        column=\"{key=value,key=value}\"\n        其实就是键值对的形式，key是传给下个sql的取值名称，value是片段一中sql查询的字段名。\n    -->\n    <select id=\"getTeacher\" resultType=\"teacher\">\n        select * from teacher where id = #{id}\n    </select>\n</mapper>\n```\n\n### 按结果嵌套处理\n\n``` xml\n<!--\n按查询结果嵌套处理\n思路：\n    1. 直接查询出结果，进行结果集的映射\n-->\n<select id=\"getStudents2\" resultMap=\"StudentTeacher2\" >\n    select s.id sid, s.name sname, t.name tname\n    from student s, teacher t\n    where s.tid = t.id\n</select>\n\n<resultMap id=\"StudentTeacher2\" type=\"Student\">\n    <id property=\"id\" column=\"sid\"/>\n    <result property=\"name\" column=\"sname\"/>\n    <!--关联对象property 关联对象在Student实体类中的属性-->\n    <association property=\"teacher\" javaType=\"Teacher\">\n        <result property=\"name\" column=\"tname\"/>\n    </association>\n</resultMap>\n```\n\n### 小结\n\n- 按照**查询**进行嵌套处理就像SQL中的子查询\n- 按照**结果**进行嵌套处理就像SQL中的联表查询\n\n## 一对多处理\n\n一对多的理解：一个老师拥有多个学生，即一个老师拥有一群学生（集合）\n\n### 按结果嵌套处理\n\n``` xml\n<mapper namespace=\"com.zhao.mapper.TeacherMapper\">\n    <!--\n    思路:\n        1. 从学生表和老师表中查出学生id，学生姓名，老师姓名\n        2. 对查询出来的操作做结果集映射\n            1. 集合的话，使用collection！\n                JavaType和ofType都是用来指定对象类型的\n                JavaType是用来指定pojo中属性的类型\n                ofType指定的是映射到list集合属性中pojo的类型。\n    -->\n    <select id=\"getTeacher\" resultMap=\"TeacherStudent\">\n        select s.id sid, s.name sname , t.name tname, t.id tid\n        from student s,teacher t\n        where s.tid = t.id and t.id=#{id}\n    </select>\n    \n    <resultMap id=\"TeacherStudent\" type=\"Teacher\">\n        <result  property=\"name\" column=\"tname\"/>\n        <collection property=\"students\" ofType=\"Student\">\n            <result property=\"id\" column=\"sid\" />\n            <result property=\"name\" column=\"sname\" />\n            <result property=\"tid\" column=\"tid\" />\n        </collection>\n    </resultMap>\n</mapper>\n```\n\n### 按查询嵌套处理\n\n``` xml\n<select id=\"getTeacher2\" resultMap=\"TeacherStudent2\">\n  select * from teacher where id = #{id}\n</select>\n\n<resultMap id=\"TeacherStudent2\" type=\"Teacher\">\n    <!--column是一对多的外键 , 写的是一的主键的列名-->\n    <collection property=\"students\" javaType=\"ArrayList\" ofType=\"Student\" column=\"id\" select=\"getStudentByTeacherId\"/>\n</resultMap>\n\n<select id=\"getStudentByTeacherId\" resultType=\"Student\">\n    select * from student where tid = #{id}\n</select>\n```\n\n### 小结\n\n- 关联-association用于一对一和多对一\n- 集合-collection用于一对多的关系\n\nJavaType和ofType都是用来指定对象类型的\n  - JavaType是用来指定pojo中属性的类型\n  - ofType指定的是映射到list集合属性中pojo的类型。\n\n## 动态SQL\n\n[官方文档](http://www.mybatis.org/mybatis-3/zh/dynamic-sql.html)\n\n### 介绍\n\n什么是动态SQL：**动态SQL指的是根据不同的查询条件 , 生成不同的Sql语句.**\n\n```\n官网描述：\nMyBatis 的强大特性之一便是它的动态 SQL。如果你有使用 JDBC 或其它类似框架的经验，你就能体会到根据不同条件拼接 SQL 语句的痛苦。例如拼接时要确保不能忘记添加必要的空格，还要注意去掉列表最后一个列名的逗号。利用动态 SQL 这一特性可以彻底摆脱这种痛苦。    \n虽然在以前使用动态 SQL 并非一件易事，但正是 MyBatis 提供了可以被用在任意 SQL 映射语句中的强大的动态 SQL 语言得以改进这种情形。    \n动态 SQL 元素和 JSTL 或基于类似 XML 的文本处理器相似。在 MyBatis 之前的版本中，有很多元素需要花时间了解。MyBatis 3 大大精简了元素种类，现在只需学习原来一半的元素便可。MyBatis 采用功能强大的基于 OGNL 的表达式来淘汰其它大部分元素。  \n\n-------------------------------\n- if    \n- choose (when, otherwise)\n- trim (where, set)\n- foreach    \n-------------------------------\n```\n\n 我们之前写的 SQL 语句都比较简单，如果有比较复杂的业务，我们需要写复杂的 SQL 语句，往往需要拼接，而拼接 SQL ，稍微不注意，由于引号，空格等缺失可能都会导致错误。\n\n那么怎么去解决这个问题呢？这就要使用 MyBatis 动态SQL，通过 if, choose, when, otherwise, trim, where, set, foreach等标签，可组合成非常灵活的SQL语句，从而在提高 SQL 语句的准确性的同时，也大大提高了开发人员的效率。\n\n### if\n\n**需求：根据作者名字和博客名字来查询博客！如果作者名字为空，那么只根据博客名字查询，反之，则根据作者名来查询**\n\n``` xml\n<!--需求1：\n根据作者名字和博客名字来查询博客！\n如果作者名字为空，那么只根据博客名字查询，反之，则根据作者名来查询\nselect * from blog where title = #{title} and author = #{author}\n-->\n<select id=\"queryBlogIf\" parameterType=\"map\" resultType=\"blog\">\n    select * from blog where\n    <if test=\"title != null\">\n        title = #{title}\n    </if>\n    <if test=\"author != null\">\n        and author = #{author}\n    </if>\n</select>\n```\n\n这样写我们可以看到，如果 author 等于 null，那么查询语句为 select * from user where title=\\#{title}，但是如果title为空呢？那么查询语句为 select * from user where and author=\\#{author}，这是错误的 SQL 语句，如何解决呢？请看下面的 where 语句！\n\n### where\n\n修改上面的SQL语句：\n\n```xml\n<select id=\"queryBlogIf\" parameterType=\"map\" resultType=\"blog\">\n    select * from blog\n    <where>\n        <if test=\"title != null\">\n            title = #{title}\n        </if>\n        <if test=\"author != null\">\n            and author = #{author}\n        </if>\n    </where>\n</select>\n```\n\n这个“where”标签会知道如果它包含的标签中有返回值的话，它就插入一个‘where’。此外，如果标签返回的内容是以 AND 或 OR 开头的，则它会剔除掉。【使用最频繁】\n\n### set\n\n同理，上面的对于查询 SQL 语句包含 where 关键字，如果在进行更新操作的时候，含有 set 关键词，我们怎么处理呢？\n\n``` xml\n<!--注意set是用的逗号隔开-->\n<update id=\"updateBlog\" parameterType=\"map\">\n    update blog\n      <set>\n          <if test=\"title != null\">\n              title = #{title},\n          </if>\n          <if test=\"author != null\">\n              author = #{author}\n          </if>\n      </set>\n    where id = #{id};\n</update>\n```\n\n### choose\n\n有时候，我们不想用到所有的查询条件，只想选择其中的一个，查询条件有一个满足即可，使用 choose 标签可以解决此类问题，类似于 Java 的 switch 语句\n\n``` xml\n<select id=\"queryBlogChoose\" parameterType=\"map\" resultType=\"blog\">\n    select * from blog\n    <where>\n        <choose>\n            <when test=\"title != null\">\n                 title = #{title}\n            </when>\n            <when test=\"author != null\">\n                and author = #{author}\n            </when>\n            <otherwise>\n                and views = #{views}\n            </otherwise>\n        </choose>\n    </where>\n</select>\n```\n\n### SQL片段\n\n有时候可能某个 sql 语句我们用的特别多，为了增加代码的重用性，简化代码，我们需要将这些代码抽取出来，然后使用时直接调用。\n\n**提取SQL片段：**\n\n``` xml\n<sql id=\"if-title-author\">\n    <if test=\"title != null\">\n        title = #{title}\n    </if>\n    <if test=\"author != null\">\n        and author = #{author}\n    </if>\n</sql>\n```\n\n**引用SQL片段：**\n\n``` xml\n<select id=\"queryBlogIf\" parameterType=\"map\" resultType=\"blog\">\n    select * from blog\n    <where>\n        <!-- 引用 sql 片段，如果refid 指定的不在本文件中，那么需要在前面加上 namespace -->\n        <include refid=\"if-title-author\"></include>\n        <!-- 在这里还可以引用其他的 sql 片段 -->\n    </where>\n</select>\n```\n\n注意：\n\n- 最好基于 单表来定义 sql 片段，提高片段的可重用性\n- 在 SQL 片段中不要包括 where\n\n### foreach\n\n``` xml\n<select id=\"queryBlogForeach\" parameterType=\"map\" resultType=\"blog\">\n    select * from blog\n    <where>\n        <!--\n        collection:指定输入对象中的集合属性\n        item:每次遍历生成的对象\n        open:开始遍历时的拼接字符串\n        close:结束时拼接的字符串\n        separator:遍历对象之间需要拼接的字符串\n        select * from blog where 1=1 and (id=1 or id=2 or id=3)\n      -->\n        <foreach collection=\"ids\"  item=\"id\" open=\"and (\" close=\")\" separator=\"or\">\n            id=#{id}\n        </foreach>\n    </where>\n</select>\n```\n\n测试\n\n``` java\n@Test\npublic void testQueryBlogForeach(){\n    SqlSession session = MybatisUtils.getSession();\n    BlogMapper mapper = session.getMapper(BlogMapper.class);\n    \n    HashMap map = new HashMap();\n    List<Integer> ids = new ArrayList<Integer>();\n    ids.add(1);\n    ids.add(2);\n    ids.add(3);\n    \n    map.put(\"ids\",ids);\n    List<Blog> blogs = mapper.queryBlogForeach(map);\n    \n    System.out.println(blogs);\n    session.close();\n}\n```\n\n##  MyBatis缓存\n\n### 简介\n\n什么是缓存 [ Cache ]？\n- 存在内存中的临时数据。\n- 将用户经常查询的数据放在缓存（内存）中，用户去查询数据就不用从磁盘上(关系型数据库数据文件)查询，从缓存中查询，从而提高查询效率，解决了高并发系统的性能问题。\n\n为什么使用缓存？：减少和数据库的交互次数，减少系统开销，提高系统效率。什么样的数据能使用缓存？：经常查询并且不经常改变的数据。\n\n### Mybatis缓存\n\nMyBatis包含一个非常强大的查询缓存特性，它可以非常方便地定制和配置缓存。缓存可以极大的提升查询效率。\n\nMyBatis系统中默认定义了两级缓存：**一级缓存**和**二级缓存**\n\n- 默认情况下，只有一级缓存开启，他是**SqlSession**级别的缓存，也称为本地缓存\n- 二级缓存需要手动开启和配置，他是基于**namespace**级别的缓存\n- 为了提高扩展性，MyBatis定义了缓存接口Cache。我们可以通过实现Cache接口来自定义二级缓存\n- **新的会话查询前会先查找二级缓存中是否有对应数据，若没有再去数据库查找**\n\n### 一级缓存\n\n一级缓存也叫本地缓存：\n\n- 与数据库**同一次会话期间**（SqlSession）查询到的数据会放在本地缓存中。\n- 以后如果需要获取相同的数据，直接从缓存中拿，没必须再去查询数据库；\n\n``` java\n@Test\npublic void testQueryUserById(){\n    SqlSession session = MybatisUtils.getSession();\n    UserMapper mapper = session.getMapper(UserMapper.class);\n    \n    User user1 = mapper.queryUserById(1);\n    System.out.println(user1);\n    \n    User user2 = mapper.queryUserById(1);\n    System.out.println(user2);\n    \n    System.out.println(user1==user2);\n    session.close();\n}\n```\n\n`user1==user2`判断结果为true，即同一个SqlSession中查询到的数据会保存到一级缓存中。**每个sqlSession中的缓存相互独立**\n\n一级缓存失效的情况：\n\n- 两次查询之间执行了增删改操作（因为增删改操作可能会对当前数据产生影响，所以一级缓存清空）\n- 手动清除一级缓存`session.clearCache();`\n\n**一级缓存就是一个map**\n\n### 二级缓存\n\n二级缓存也叫全局缓存，一级缓存作用域太低了，所以诞生了二级缓存。二级缓存是基于**namespace**级别的缓存，一个名称空间，对应一个二级缓存；\n\n工作机制：\n\n- 一个会话查询一条数据，这个数据就会被放在当前会话的一级缓存中；\n- 如果当前会话关闭了，这个会话对应的一级缓存就没了；但是我们想要的是，会话关闭了，一级缓存中的数据被保存到二级缓存中；\n- 新的会话查询信息，就可以从二级缓存中获取内容；\n- 不同的mapper查出的数据会放在自己对应的缓存（map）中\n\n开启二级缓存步骤：\n\n1. 开启全局缓存 【mybatis-config.xml】\n\n```xml\n<setting name=\"cacheEnabled\" value=\"true\"/>\n```\n\n2. 去每个mapper.xml中配置使用二级缓存\n\n``` xml\n<cache eviction=\"FIFO\" flushInterval=\"60000\" size=\"512\" readOnly=\"true\"/>\n<!-- 这个更高级的配置创建了一个 FIFO 缓存，每隔 60 秒刷新，最多可以存储结果对象或列表的 512 个引用，而且返回的对象被认为是只读的，因此对它们进行修改可能会在不同线程中的调用者产生冲突。 -->\n```\n\n3. 代码测试\n\n- 所有的实体类先实现序列化接口\n- 测试\n\n``` java\n@Test\npublic void testQueryUserById(){\n    SqlSession session = MybatisUtils.getSession();\n    SqlSession session2 = MybatisUtils.getSession();\n    \n    UserMapper mapper = session.getMapper(UserMapper.class);\n    UserMapper mapper2 = session2.getMapper(UserMapper.class);\n    User user = mapper.queryUserById(1);\n    \n    System.out.println(user);\n    session.close();\n    \n    User user2 = mapper2.queryUserById(1);\n    \n    System.out.println(user2);\n    System.out.println(user==user2);\n    session2.close();\n}\n```\n\n**结论**\n\n- 只要开启了二级缓存，我们在同一个Mapper中的查询，可以在二级缓存中拿到数据\n- **查出的数据都会被默认先放在一级缓存中**\n- **只有会话提交或者关闭以后，一级缓存中的数据才会转到二级缓存中**\n\n### 缓存原理\n\n新会话创建后本身没有一级缓存，其在查询前会先在二级缓存中查找是否有对应的数据，若没有再去数据库查找\n\n![img](/images/%E3%80%90MyBatis%E3%80%91MyBatis/kuangstudy203221f0-73d7-4d4c-bb81-84b1af9a63db.png)\n\n### EhCache\n\n第三方缓存实现—EhCache：Ehcache是一种广泛使用的java分布式缓存，用于通用缓存。[官方文档](http://www.mybatis.org/ehcache-cache/)\n\n要在应用程序中使用Ehcache，需要引入依赖的jar包\n\n``` xml\n<!-- https://mvnrepository.com/artifact/org.mybatis.caches/mybatis-ehcache -->\n<dependency>\n    <groupId>org.mybatis.caches</groupId>\n    <artifactId>mybatis-ehcache</artifactId>\n    <version>1.1.0</version>\n</dependency>\n```\n\n在mapper.xml中使用对应的缓存即可\n\n``` xml\n<mapper namespace = “org.acme.FooMapper” > \n    <cache type = “org.mybatis.caches.ehcache.EhcacheCache” /> \n</mapper>\n```\n\n编写ehcache.xml文件，如果在`加载时`未找到`/ehcache.xml`资源或出现问题，则将使用默认配置。\n\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ehcache xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:noNamespaceSchemaLocation=\"http://ehcache.org/ehcache.xsd\"\n         updateCheck=\"false\">\n    <!--\n       diskStore：为缓存路径，ehcache分为内存和磁盘两级，此属性定义磁盘的缓存位置。参数解释如下：\n       user.home – 用户主目录\n       user.dir  – 用户当前工作目录\n       java.io.tmpdir – 默认临时文件路径\n     -->\n    <diskStore path=\"./tmpdir/Tmp_EhCache\"/>\n    <defaultCache eternal=\"false\"\n                  maxElementsInMemory=\"10000\"\n                  overflowToDisk=\"false\"\n                  diskPersistent=\"false\"\n                  timeToIdleSeconds=\"1800\"\n                  timeToLiveSeconds=\"259200\"\n                  memoryStoreEvictionPolicy=\"LRU\"/>\n    <cache  name=\"cloud_user\"\n            eternal=\"false\"\n            maxElementsInMemory=\"5000\"\n            overflowToDisk=\"false\"\n            diskPersistent=\"false\"\n            timeToIdleSeconds=\"1800\"\n            timeToLiveSeconds=\"1800\"\n            memoryStoreEvictionPolicy=\"LRU\"/>\n    <!--\n       defaultCache：默认缓存策略，当ehcache找不到定义的缓存时，则使用这个缓存策略。只能定义一个。\n     -->\n    <!--\n      name:缓存名称。\n      maxElementsInMemory:缓存最大数目\n      maxElementsOnDisk：硬盘最大缓存个数。\n      eternal:对象是否永久有效，一但设置了，timeout将不起作用。\n      overflowToDisk:是否保存到磁盘，当系统当机时\n      timeToIdleSeconds:设置对象在失效前的允许闲置时间（单位：秒）。仅当eternal=false对象不是永久有效时使用，可选属性，默认值是0，也就是可闲置时间无穷大。\n      timeToLiveSeconds:设置对象在失效前允许存活时间（单位：秒）。最大时间介于创建时间和失效时间之间。仅当eternal=false对象不是永久有效时使用，默认是0.，也就是对象存活时间无穷大。\n      diskPersistent：是否缓存虚拟机重启期数据 Whether the disk store persists between restarts of the Virtual Machine. The default value is false.\n      diskSpoolBufferSizeMB：这个参数设置DiskStore（磁盘缓存）的缓存区大小。默认是30MB。每个Cache都应该有自己的一个缓冲区。\n      diskExpiryThreadIntervalSeconds：磁盘失效线程运行时间间隔，默认是120秒。\n      memoryStoreEvictionPolicy：当达到maxElementsInMemory限制时，Ehcache将会根据指定的策略去清理内存。默认策略是LRU（最近最少使用）。你可以设置为FIFO（先进先出）或是LFU（较少使用）。\n      clearOnFlush：内存数量最大时是否清除。\n      memoryStoreEvictionPolicy:可选策略有：LRU（最近最少使用，默认策略）、FIFO（先进先出）、LFU（最少访问次数）。\n      FIFO，first in first out，这个是大家最熟的，先进先出。\n      LFU， Less Frequently Used，就是上面例子中使用的策略，直白一点就是讲一直以来最少被使用的。如上面所讲，缓存的元素有一个hit属性，hit值最小的将会被清出缓存。\n      LRU，Least Recently Used，最近最少使用的，缓存的元素有一个时间戳，当缓存容量满了，而又需要腾出地方来缓存新的元素的时候，那么现有缓存元素中时间戳离当前时间最远的元素将被清出缓存。\n   -->\n</ehcache>\n```\n\n​\t\t\n\n","tags":["MyBatis","SSM"],"categories":["MyBatis","SSM"]},{"title":"【Git】常用 Git 命令","url":"/2021/05/15/【Git】常用Git命令/","content":"\n## 基本流程\n\n```bash\ngit init\n\ngit remote add origin 远程仓库地址\n\ngit add .\n\ngit commit -m \"...\"\n\ngit push -u origin master\n\ngit pull origin master\n```\n\n## 在远程分支与本地分支之间建立联系\n\n在本地分支新创建的分支没有与远程分支建立联系，需要使用以下指令建立本地分支与远程分支的联系，之后即可pull\n\n``` bash\ngit checkout -b dev\n\ngit branch --set-upstream-to=origin/dev dev\n\ngit pull origin dev\n```\n\n## 更新远程分支列表\n\n在远程仓库的分支发生变化而本地仓库的分支没有更新时使用\n\n``` bash\ngit remote update origin --prune\ngit fetch --all\n```\n\n\n\n\n\n### 各种疑难杂症解决方案\n\n### Failed to connect to github.com port 443:connection timed out\n\n这种报错很多是因为使用了梯子所导致的代理问题，解决方案：重新设置本地代理的端口号（Clash里代理端口号为7890）\n\n``` bash\ngit config --global http.proxy http://127.0.0.1:7890 \ngit config --global https.proxy http://127.0.0.1:7890\n```\n\n\n\n","tags":["Git"],"categories":["Git"]},{"title":"【JavaWeb】文件上传","url":"/2021/04/28/【JavaWeb】文件上传/","content":"\n## 准备工作\n\napache的开源工具common-fileupload包负责完成文件上传，其依赖于common-io包\n\n``` xml\n<!-- https://mvnrepository.com/artifact/commons-io/commons-io -->\n<dependency>\n    <groupId>commons-io</groupId>\n    <artifactId>commons-io</artifactId>\n    <version>2.6</version>\n</dependency>\n\n<!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload -->\n<dependency>\n    <groupId>commons-fileupload</groupId>\n    <artifactId>commons-fileupload</artifactId>\n    <version>1.3.1</version>\n</dependency>\n```\n\n## 使用类介绍 \n\n文件上传的注意事项：\n\n- 为保证服务器安全，上传文件应该放在外界无法访问的目录下，比如`WEB-INF`目录下（**该目录下的文件只能通过转发和重定向跳转**）\n- 为防止文件覆盖的现象发生，要为上传文件产生一个唯一的文件名（使用uuid或时间戳）\n- 要限制上传文件的最大值\n- 可以限制上传文件的类型，在收到上传文件名时，判断后缀名是否合法\n\n使用类：\n\n- **DiskFileItemFactory**：解析ServletFileUpload对象\n- **ServletFileUpload**：负责处理上传的文件数据，并将表单中每个输入项封装成一个FileItem对象\n- **FileItem**：表单的每个输入项都是一个FileItem对象\n\n<!-- More -->\n\n## 用法示例\n\n``` html\n<html>\n<body>\n<h2>Hello World!</h2>\n\n<%-- 通过表单上传文件\n     get：上传文件大小有限制\n     post：上传文件大小没限制\n--%>\n<form action=\"${pageContext.request.contextPath}/upload.do\" enctype=\"multipart/form-data\" method=\"post\">\n    上传用户：<input type=\"text\" name=\"username\"><br/>\n    <p><input type=\"file\" name=\"file1\"></p>\n    <p><input type=\"file\" name=\"file2\"></p>\n    <p><input type=\"submit\"> | <input type=\"reset\"></p>\n</form>\n\n</body>\n</html>\n```\n\n```java\nif (ServletFileUpload.isMultipartContent(req)) {\n    FileItemFactory fileItemFactory = new DiskFileItemFactory();\n    ServletFileUpload servletFileUpload = new ServletFileUpload(fileItemFactory);\n    try {\n        List<FileItem> list = servletFileUpload.parseRequest(req);\n        \n        for (FileItem fileItem : list) {\n            if (fileItem.isFormField()) {\n            // 普通表单项\n            System.out.println(fileItem.getFieldName());\n            System.out.println(fileItem.getString(\"UTF-8\"));\n            } else {\n                fileItem.write(new File(\"D:\\\\fileItem.getFieldName()\");\n            }\n        } \n    } catch (Exception e) {\n        System.out.println(e);\n    }\n}\n```\n\n\n\n\n\n\n","tags":["JavaWeb"],"categories":["JavaWeb"]},{"title":"【Java】代理模式","url":"/2021/04/25/【Java】动态代理/","content":"\n## 代理模式简介\n\n> https://segmentfault.com/a/1190000011291179\n\n[代理模式](https://link.segmentfault.com/?url=https%3A%2F%2Fzh.wikipedia.org%2Fwiki%2F%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F)是一种设计模式，提供了对目标对象额外的访问方式，即通过代理对象访问目标对象，这样可以在不修改原目标对象的前提下，提供额外的功能操作，扩展目标对象的功能。\n\n简言之，代理模式就是设置一个中间代理来控制访问原目标对象，以达到增强原对象的功能和简化访问方式。\n\n> 代理模式UML类图\n\n![代理模式UML类图](/images/%E3%80%90Java%E3%80%91%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/1460000011291184)\n\n<!-- More -->\n\n## 静态代理\n\n这种代理方式需要**手动创建**代理对象，并且该代理对象和目标对象必须**实现一样的接口**。\n\n优点：可以在不修改目标对象的前提下扩展目标对象的功能。\n\n缺点：\n\n1. 冗余。由于代理对象要实现与目标对象一致的接口，会产生过多的代理类。\n2. 不易维护。一旦接口增加方法，目标对象与代理对象都要进行修改。\n\n示例：\n\n- 接口类： IUserDao\n\n```java\npackage com.proxy;\n\npublic interface IUserDao {\n    public void save();\n}\n```\n\n- 目标对象：UserDao\n\n```java\npackage com.proxy;\n\npublic class UserDao implements IUserDao{\n\n    @Override\n    public void save() {\n        System.out.println(\"保存数据\");\n    }\n}\n```\n\n- 静态代理对象：UserDapProxy **需要实现IUserDao接口！**\n\n```java\npackage com.proxy;\n\npublic class UserDaoProxy implements IUserDao{\n\n    private IUserDao target;\n    public UserDaoProxy(IUserDao target) {\n        this.target = target;\n    }\n    \n    @Override\n    public void save() {\n        System.out.println(\"开启事务\");//扩展了额外功能\n        target.save();\n        System.out.println(\"提交事务\");\n    }\n}\n```\n\n- 测试类：TestProxy\n\n```java\npackage com.proxy;\n\nimport org.junit.Test;\n\npublic class StaticUserProxy {\n    @Test\n    public void testStaticProxy(){\n        //目标对象\n        IUserDao target = new UserDao();\n        //代理对象\n        UserDaoProxy proxy = new UserDaoProxy(target);\n        proxy.save();\n    }\n}\n```\n\n## JDK 动态代理\n\n动态代理利用了[JDK API](https://link.segmentfault.com/?url=http%3A%2F%2Ftool.oschina.net%2Fuploads%2Fapidocs%2Fjdk-zh%2F)，动态地在内存中构建代理对象，从而实现对目标对象的代理功能。动态代理又被称为JDK代理或接口代理。\n\n静态代理与动态代理的区别主要在：\n\n- 静态代理在**编译时就已经实现**，编译完成后代理类是一个实际的class文件\n- 动态代理是**在运行时动态生成的，即编译完成后没有实际的class文件，而是在运行时动态生成类字节码，并加载到JVM中**\n\n**特点：**动态代理对象不需要实现接口，但是要求**目标对象必须实现接口**，否则不能使用动态代理。\n\nJDK中生成代理对象主要涉及的类有\n\n- [java.lang.reflect Proxy](https://link.segmentfault.com/?url=http%3A%2F%2Ftool.oschina.net%2Fuploads%2Fapidocs%2Fjdk-zh%2Fjava%2Flang%2Freflect%2FProxy.html)，主要方法为\n\n```java\nstatic Object newProxyInstance(ClassLoader loader,  //指定当前目标对象使用类加载器\n                               Class<?>[] interfaces,    //目标对象实现的接口的类型\n                               InvocationHandler h      //事件处理器\n                              ) \n    //返回一个指定接口的代理类实例，该接口可以将方法调用指派到指定的调用处理程序。\n```\n\n- [java.lang.reflect InvocationHandler](https://link.segmentfault.com/?url=http%3A%2F%2Ftool.oschina.net%2Fuploads%2Fapidocs%2Fjdk-zh%2Fjava%2Flang%2Freflect%2FInvocationHandler.html)，主要方法为\n\n```java\n// 在代理实例上处理方法调用并返回结果。\nObject invoke(Object proxy, Method method, Object[] args) \n```\n\n示例：\n\n1）使用 JDK 动态代理，使用 `Proxy `类里面的方法创建代理对象：\n\n调用 newProxyInstance 方法，方法有三个参数：\n\n``` java\npublic static Object newProxyInstance(ClassLoader loader,\n                                      Class<?>[] interfaces,\n                                      InvocationHandler h)\n```\n\n- 参数一：类加载器\n- 参数二：增强方法所在的类，这个类实现的接口，支持多个接口\n- 参数三：实现这个接口 `InvocationHandler`，创建代理对象，写增强的部分\n\n2）编写 JDK 动态代理代码\n\n``` java\n//（1）创建接口，定义方法\npublic interface UserDao {\n    public int add(int a,int b);\n    public String update(String id);\n}\n```\n\n``` java\n//（2）创建接口实现类，实现方法\npublic class UserDaoImpl implements UserDao {\n    @Override\n    public int add(int a, int b) {\n        return a+b;\n    }\n    @Override\n    public String update(String id) {\n        return id;\n    }\n}\n```\n\n``` java\n//（3）使用 Proxy 类创建接口代理对象\npublic class JDKProxy {\n    public static void main(String[] args) {\n        //创建接口实现类代理对象\n        Class[] interfaces = {UserDao.class};\n        UserDaoImpl userDao = new UserDaoImpl(); \n        \n        /** 为目标对象生成代理对象\n        第一参数，类加载器 \n        第二参数，增强方法所在的类，这个类实现的接口，(支持多个接口)\n        第三参数，实现这个接口 InvocationHandler，创建代理对象，写增强的部分  */\n        UserDao dao =(UserDao)Proxy.newProxyInstance(JDKProxy.class.getClassLoader(), interfaces,\n                                                     new UserDaoProxy(userDao));\n        int result = dao.add(1, 2);\n        System.out.println(\"result:\"+result);\n    }\n}\n\n//创建代理对象代码\nclass UserDaoProxy implements InvocationHandler {\n    //1 维护一个目标对象，把创建的是谁的代理对象，把谁传递过来\n    //有参数构造传递\n    private Object obj;\n    public UserDaoProxy(Object obj) {\n        this.obj = obj;\n    }\n\n    //增强的逻辑\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        //方法之前\n        System.out.println(\"方法之前执行....\"+method.getName()+\" :传递的参数...\"+ Arrays.toString(args));\n        //被增强的方法执行\n        Object res = method.invoke(obj, args);\n        //方法之后\n        System.out.println(\"方法之后执行....\"+obj);\n        return res;\n    }\n}\n```\n\n\n\n## CGLIB 动态代理\n\n> CGLIB is a powerful, high performance and quality Code Generation Library. It can extend JAVA classes and implement interfaces at runtime.\n\n[CGLIB](https://link.segmentfault.com/?url=https%3A%2F%2Fgithub.com%2Fcglib%2Fcglib) (Code Generation Library )是一个第三方代码生成类库，**运行时在内存中动态生成一个子类对象从而实现对目标对象功能的扩展**。\n\n**cglib特点**\n\n- JDK的动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口。**如果想代理没有实现接口的类，就可以使用CGLIB实现**。\n- CGLIB是一个强大的高性能的代码生成包，它可以在**运行期**扩展Java类与实现Java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和dynaop，为他们提供方法的interception（拦截）。\n- CGLIB包的底层是通过使用一个小而快的**字节码处理框架ASM**，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它需要你对JVM内部结构包括class文件的格式和指令集都很熟悉。\n\nCGLIB与JDK动态代理最大的**区别**就是：\n\n- 使用JDK动态代理的对象必须实现一个或多个接口\n- 使用CGLIB代理的对象则无需实现接口，达到代理类无侵入\n\n使用CGLIB需要引入[cglib的jar包](https://link.segmentfault.com/?url=https%3A%2F%2Frepo1.maven.org%2Fmaven2%2Fcglib%2Fcglib%2F3.2.5%2Fcglib-3.2.5.jar)，如果你已经有`spring-core`的jar包，则无需引入，因为Spring中包含了CGLIB。\n\n- CGLIB的Maven坐标\n\n```xml\n<dependency>\n    <groupId>cglib</groupId>\n    <artifactId>cglib</artifactId>\n    <version>3.2.5</version>\n</dependency>\n```\n\n> 举例：保存用户功能的动态代理实现\n\n- 目标对象：UserDao\n\n```java\npackage com.cglib;\n\npublic class UserDao{\n\n    public void save() {\n        System.out.println(\"保存数据\");\n    }\n}\n```\n\n- 代理对象：ProxyFactory\n\n```java\npackage com.cglib;\n\nimport java.lang.reflect.Method;\n\nimport net.sf.cglib.proxy.Enhancer;\nimport net.sf.cglib.proxy.MethodInterceptor;\nimport net.sf.cglib.proxy.MethodProxy;\n\npublic class ProxyFactory implements MethodInterceptor{\n\n    private Object target;//维护一个目标对象\n    public ProxyFactory(Object target) {\n        this.target = target;\n    }\n\n    //为目标对象生成代理对象\n    public Object getProxyInstance() {\n        //工具类\n        Enhancer en = new Enhancer();\n        //设置父类\n        en.setSuperclass(target.getClass());\n        //设置回调函数\n        en.setCallback(this);\n        //创建子类对象代理\n        return en.create();\n    }\n\n    @Override\n    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable {\n        System.out.println(\"开启事务\");\n        // 执行目标对象的方法\n        Object returnValue = method.invoke(target, args);\n        System.out.println(\"关闭事务\");\n        return null;\n    }\n}\n```\n\n- 测试类：TestProxy\n\n```java\npackage com.cglib;\n\nimport org.junit.Test;\n\npublic class TestProxy {\n\n    @Test\n    public void testCglibProxy(){\n        //目标对象\n        UserDao target = new UserDao();\n        System.out.println(target.getClass());\n        //代理对象\n        UserDao proxy = (UserDao) new ProxyFactory(target).getProxyInstance();\n        System.out.println(proxy.getClass());\n        //执行代理对象方法\n        proxy.save();\n    }\n}\n```\n\n- 输出结果\n\n```bash\nclass com.cglib.UserDao\nclass com.cglib.UserDao$$EnhancerByCGLIB$$552188b6\n开启事务\n保存数据\n关闭事务\n```\n\n## 总结\n\n1. 静态代理实现较简单，只要代理对象对目标对象进行包装，即可实现增强功能，但静态代理只能为一个目标对象服务，如果目标对象过多，则会产生很多代理类。\n2. JDK动态代理需要目标对象实现业务接口，代理类只需实现`InvocationHandler`接口。\n3. 动态代理生成的类为 `class com.sun.proxy.\\$Proxy4`，cglib代理生成的类为`class com.cglib.UserDao\\$\\$EnhancerByCGLIB\\$\\$552188b6`。\n4. 静态代理在编译时产生class字节码文件，可以直接使用，效率高。\n5. JDK动态代理必须实现`InvocationHandler`接口，通过反射代理方法，比较消耗系统性能，但可以减少代理类的数量，使用更灵活。\n6. CGLIB代理无需实现接口，通过生成类字节码实现代理，比反射稍快，不存在性能问题，但CGLIB会继承目标对象，需要重写方法，所以目标对象不能为`final`类。","tags":["Java"],"categories":["Java"]},{"title":"【Spring】Spring 汇总","url":"/2021/04/23/【Spring】Spring5-汇总/","content":"\n![img](/images/%E3%80%90Spring%E3%80%91Spring5%E6%B1%87%E6%80%BB/kuangstudyf90849ac-8a55-459f-846b-6382d38d6a4d.png)\n\n## Spring 内容汇总\n\n### 源码分析\n\n[【Spring】Spring5 IoC 源码分析](https://yuyun-zhao.github.io/2021/07/14/%E3%80%90Spring%E3%80%91Spring5-IoC%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n[【Spring】Spring5 AOP 源码分析](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-AOP%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n[【Spring】Spring5 事务源码分析](https://yuyun-zhao.github.io/2021/07/05/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n[【Spring MVC】Spring MVC 源码分析](https://yuyun-zhao.github.io/2021/07/13/%E3%80%90SpringMVC%E3%80%91SpringMVC-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/\t)\n\n[【Spring Boot】Spring Boot2 源码分析](https://yuyun-zhao.github.io/2021/07/12/%E3%80%90SpringBoot%E3%80%91SpringBoot2-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/)\n\n[【Spring】Spring5 源码中常用接口的底层原理](https://yuyun-zhao.github.io/2021/06/28/%E3%80%90Spring%E3%80%91Spring5-%E6%BA%90%E7%A0%81%E4%B8%AD%E5%B8%B8%E7%94%A8%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/)\n\n### 学习笔记\n\n[【Spring】Spring5 IoC](https://yuyun-zhao.github.io/2021/05/24/%E3%80%90Spring%E3%80%91Spring5-IoC/)\n\n[【Spring】Spring5 AOP](https://yuyun-zhao.github.io/2021/05/29/%E3%80%90Spring%E3%80%91Spring5-AOP/)\n\n[【Spring】Spring5 事务](https://yuyun-zhao.github.io/2021/05/31/%E3%80%90Spring%E3%80%91Spring5-%E4%BA%8B%E5%8A%A1/)\n\n[【Spring】Spring5 注解驱动开发](https://yuyun-zhao.github.io/2021/06/25/%E3%80%90Spring%E3%80%91Spring5-%E6%B3%A8%E8%A7%A3%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%91/)\n\n[【Spring MVC】Spring MVC](https://yuyun-zhao.github.io/2021/06/03/%E3%80%90SpringMVC%E3%80%91SpringMVC/)\n\n[【Spring MVC】SSM整合案例](https://yuyun-zhao.github.io/2021/06/03/%E3%80%90SpringMVC%E3%80%91SSM%E6%95%B4%E5%90%88%E6%A1%88%E4%BE%8B/)\n\n[【Spring Boot】Spring Boot2](https://yuyun-zhao.github.io/2021/06/30/%E3%80%90SpringBoot%E3%80%91SpringBoot2/)\n\n\n\n","tags":["SSM","Spring"],"categories":["Spring","SSM"]},{"title":"【JavaWeb】JavaWeb 基础","url":"/2021/04/16/【JavaWeb】JavaWeb/","content":"\n## JavaWeb\n\nJavaWeb是指所有通过Java语言编写的，可以通过浏览器访问的程序的总称。JavaWeb是基于请求和响应开发的。\n\n- 请求：客户端给服务器发送数据，Request\n- 响应：服务器给客户端传回数据，Response\n\nJavaWeb三大组件：Servlet程序、Filter过滤器、Listener监听器\n\n## HTTP\n\nHTTP：超文本传输协议。是一个简单的请求-响应协议，通常运行在TCP之上，端口号：80。HTTPS相比HTTP更为安全。HTTP两个时代：\n\n- HTTP1.0：客户端与web服务器连接后，只能获得一个web资源。\n- HTTP2.0：客户端与web服务器连接后，可以获得多个web资源。\n\n### HTTP请求\n\n**请求行**：\n\n- 请求行中的请求方式：`GET`或`POST`\n- 请求方式：`GET`、`POST`、`HEAD`、`DELETE`、`PUT`\n  - `GET`：请求能够携带的参数比较少，大小有限制，会在浏览器的URL地址栏显示数据内容，不安全，但高效\n  - `POST`：请求能够携带的参数没有限制，大小没有限制，不会在浏览器的URL地址栏显示数据内容，安全，但不高效\n\n**GET请求**\n\n![image-20210501214204632](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210501214204632.png)\n\n**POST请求**\n\n![image-20210501214745892](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210501214745892.png)\n\n### HTTP 响应\n\n响应状态码：\n\n- 101：转换协议（例如HTTP协议转换成WebSocket协议）\n- 200：请求响应成功\n- 3xx：请求与重定向\n- 4xx：找不到资源（404 资源不存在），都是客户端的错误（比如输入错误的地址）\n- 5xx：服务器代码错误（500），网关错误（502）\n\n![image-20210501215225830](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210501215225830.png)\n\n### URL 和 URI\n\nURI：资源识别符；URL：比 URI 多了一个定位功能，就是用定位的方式实现的 URI。**URL 是 URI 的子集**。\n\n在 Web 领域上，假设所有的 Html 文档都有唯一的编号，记作 html:xxxxx，xxxxx 是一串数字，即Html 文档的身份证号码，这个能唯一标识一个 Html 文档，那么这个号码就是一个 URI。\n\n而 URL 则通过描述是哪个主机上哪个路径上的文件来唯一确定一个资源，也就是定位的方式来实现的 URI。\n\n<!-- More -->\n\n## Tomcat\n\n**Tomcat**是由Apache软件基金会属下[Jakarta项目](https://zh.wikipedia.org/wiki/Jakarta项目)开发的[Servlet](https://zh.wikipedia.org/wiki/Servlet)容器，按照[Sun Microsystems](https://zh.wikipedia.org/wiki/Sun_Microsystems)提供的技术规范，实现了对[Servlet](https://zh.wikipedia.org/wiki/Servlet)和[JavaServer Page](https://zh.wikipedia.org/wiki/JavaServer_Page)（[JSP](https://zh.wikipedia.org/wiki/JSP)）的支持，并提供了作为Web服务器的一些特有功能，如Tomcat管理和控制平台、安全局管理和Tomcat阀等。由于Tomcat本身也内含了[HTTP](https://zh.wikipedia.org/wiki/HTTP)[服务器](https://zh.wikipedia.org/wiki/服务器)，因此也可以视作单独的[Web服务器](https://zh.wikipedia.org/wiki/Web服务器)。Tomcat提供了一个Jasper[编译器](https://zh.wikipedia.org/wiki/编译器)用以将JSP编译成对应的Servlet。\n\n在官网安装Tomcat 9.0.45版本压缩包，解压到本地即可，无需配置环境变量。在构建Servlet项目时，在IDEA中指定Tomcat根目录即可使用Tomcat。\n\n## Maven\n\n### Maven项目架构管理工具\n\n用于方便导入jar包。核心思想：约定大于配置。有约束，不要去违反。Maven会规定好如何去编写Java代码，必须按照这个规范组织结构。\n\n修改为Maven阿里云镜像：\n\n``` xml\n<mirror>\n    <id>nexus-aliyun</id>\n    <mirrorOf>*</mirrorOf>\n    <name>Nexus aliyun</name>\n    <url>http://maven.aliyun.com/nexus/content/groups/public</url>\n</mirror>\n```\n\n修改本地仓库的位置：`localRepository`\n\n``` xml\n<localRepository>D:\\Environment\\apache-maven-3.8.1\\maven-repo</localRepository>\n```\n\n### Maven仓库\n\nMaven repository：https://mvnrepository.com/\n\n### Maven约定\n\n创建JavaWeb项目时，webapp目录创建在src/main目录下才能够自动导入maven配置文件中添加的包，否则需要在项目结构中手动导入包。\n\n## Servlet\n\nServlet是Sun公司开发动态web的一门技术。Sun在这些API中提供了一个接口：Servlet。开发Servlet程序需要完成两个步骤：\n\n- 编写一个Java类，实现Servlet接口\n- 把开发好的Java类部署到web服务器中\n\n**把实现了Servlet接口的Java程序叫做Servlet**\n\n### HelloServlet\n\nSevlet接口Sun公司提供有两个默认的实现类：HttpServlt，GenericServlet\n\n1. 构建一个普通的Maven项目（不带模板），删掉里面的src目录，这个空的工程就是Maven的主工程。之后在这个项目里建立Module，新建的Module均为Maven父项目的子项目。\n\n2. 关于Maven父子工程的理解：在父项目中会有\n\n   ``` xml\n<modules>\n       <module>servlet-01</module>\n   </modules>\n   ```\n   \n   父项目中的Maven依赖环境Jar包子项目可以直接使用\n\n3. Maven环境优化：修改web.xml（与本地Tomcat中的内容一致）\n\n  ```xml\n<web-app xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\"\n         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n         xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee\n                      http://xmlns.jcp.org/xml/ns/javaee/web-app_4_0.xsd\"\n         version=\"4.0\"\n         metadata-complete=\"true\">\n\n</web-app>\n  ```\n\n4. 编写一个Servlet程序\n   - 编写一个普通类\n   -  实现Servlet接口，这里继承HttpServlet\n   \n```java\n   package com.zhao.servlet;\n   \n   import javax.servlet.ServletException;\n   import javax.servlet.http.HttpServlet;\n   import javax.servlet.http.HttpServletRequest;\n   import javax.servlet.http.HttpServletResponse;\n   import java.io.IOException;\n   import java.io.PrintWriter;\n   \n   public class HelloServlet extends HttpServlet {\n       // 由于get或者post只是请求实现的不同方式，可以互相调用，业务逻辑都一样\n       @Override\n       protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n           PrintWriter writer = resp.getWriter();\n           writer.print(\"Hello Servlet\");\n       }\n   \n       @Override\n       protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n           doGet(req, resp);\n       }\n   }\n```\n\n5. 编写Servlet映射：写的Java程序要通过浏览器访问，浏览器需要连接web服务器，所以需要在web服务中注册我们写的Servlet，还需要给他一个浏览器能访问到的路径。\n\n```xml\n<!-- 注册Servlet -->\n<servlet>\n    <servlet-name>HelloServlet</servlet-name>\n    <servlet-class>com.zhao.servlet.HelloServlet</servlet-class>\n</servlet>\n<!-- Servlet的请求路径 -->\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello</url-pattern>\n</servlet-mapping>\n```\n\n6. 配置Tomcat，注意配置项目发布的路径\n7. 启动测试\n\n### Servlet原理\n\nServlet是由web服务器调用，web服务器在收到浏览器请求后会调用`service()`方法，该方法会根据请求的类型`GET`或`POST`分发处理，执行相应的`doGet()`或`doPost()`方法。\n\n![image-20210501200459226](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210501200459226.png)\n\n### Mapping问题\n\n1. 一个Servlet可以指定一个映射路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello</url-pattern>\n</servlet-mapping>\n```\n\n2. 一个Servlet可以指定多个映射路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello1</url-pattern>\n</servlet-mapping>\n\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello2</url-pattern>\n</servlet-mapping>\n\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello3</url-pattern>\n</servlet-mapping>\n```\n\n3. 一个Servlet可以指定通用映射路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/hello/*</url-pattern>\n</servlet-mapping>\n```\n\n4. 默认请求路径\n\n```xml\n<servlet-mapping>\n    <servlet-name>HelloServlet</servlet-name>\n    <url-pattern>/*</url-pattern>\n</servlet-mapping>\n```\n\n优先级问题：\n\n指定了**固有的映射路径优先级最高**，如果找不到匹配的固有映射路径，则就会走默认路径（\\*)\n\n```xml\n<!-- 注册Error Servlet -->\n<servlet>\n    <servlet-name>ErrorServlet</servlet-name>\n    <servlet-class>com.zhao.servlet.ErrorServlet</servlet-class>\n</servlet>\n<!-- ErrorServlet的请求路径 -->\n<servlet-mapping>\n    <servlet-name>ErrorServlet</servlet-name>\n    <url-pattern>/*</url-pattern>\n</servlet-mapping>\n```\n\n### ServletContext\n\n是一个接口，代表Servlet上下文对象，一个工程只有一个ServletContext对象，是一个域对象（这里的域指的是整个web工程）。\n\nweb容器在启动时，他会为每个web程序都创建一个ServletContext对象，他代表了当前的web应用。\n\n作用1：共享数据，即在某个Servlet中保存的数据可以在另一个Servlet中获得。\n\n存入数据的Servlet类，用于保存数据到ServletContext对象中。\n\n```java\npublic class HelloServlet extends HttpServlet {\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        System.out.println(\"hello\");\n        // this.getInitParameter();  初始化参数\n        // this.getServletConfig();  Servlet配置\n        // this.getServletContext(); Servlet上下文\n\n        ServletContext context = this.getServletContext();\n        String username = \"zhangsan\"; // 数据\n\n        // 将一个数据以键值对形式保存在了ServletContext中。\n        context.setAttribute(\"username\", username);\n    }\n}\n```\n\n读入数据的Servlet类，用于从ServletContext对象中读取数据。\n\n```java\npublic class GetServlet extends HttpServlet {\n\n    @Override\n    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        ServletContext context = this.getServletContext();\n        String username = (String)context.getAttribute(\"username\");\n\n        resp.getWriter().print(username);\n    }\n\n    @Override\n    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {\n        super.doPost(req, resp);\n    }\n}\n```\n\n作用2：获取初始化参数。\n\n```xml\n<!-- 是上下文参数（属于整个web工程） -->\n<context-param>\n  <param-name>url</param-name>\n  <param-value>jdbc:mysql://localhost:3306/mybatis</param-value>\n</context-param>\n```\n\n```java\nServletContext context = this.getServletContext();\n\nString url = context.getInitParameter(\"url\");\nresp.getWriter().print(url);\n```\n\n作用3：请求转发。\n\n访问当前url时，将消息转发给指定的其他url（当前url不会发生变化，重定向会变化）。当前url只充当转发功能。**请求转发不需要添加项目名，只需要/+映射路径**\n\n```java\n// 转发的请求参数\nRequestDispatcher requestDispatcher = context.getRequestDispatcher(\"/servlet01\");\nrequestDispatcher.forward(req, resp); // 调用forward实现请求转发\n```\n\n请求转发的特点：\n\n- 浏览器地址栏没有变化\n- 是一次请求\n- 共享Request域中的数据\n- 可以转发到`WEB-INF`目录下\n- 无法访问项目以外的其他资源（如百度）\n\n作用4：读取资源文件\n\n- 在java目录下新建properties\n- 在resources目录下新建properties\n\n发现都被打包到了同一个路径下：`/WEB-INF/classes`，将这个路径称为classpath。\n\n**classpath**：`src/main/`下的`java`目录和`resources`目录下的文件会被合并到`/WEB-INF/classes`下，将该路径称为classpath\n\n``` properties\nusername=root\npassword=123456\n```\n\n```java\nInputStream resourceAsStream = this.getServletContext().getResourceAsStream(\"/WEB-INF/classes/db.properties\");\n\nProperties prop = new Properties();\nprop.load(resourceAsStream);\nString user = prop.getProperty(\"username\");\nString password = prop.getProperty(\"password\");\n\nresp.getWriter().print(url + ':' + password);\n```\n\n### HttpServletResponse\n\nweb服务器接收到客户端的HTTP请求，针对这个请求，分别创建一个代表请求的HttpServletRequest对象，代表响应的一个HttpServletResponse对象。\n\n- 如果要获取客户端请求过来的参数，使用HttpServletRequest\n- 如果要给客户端响应一些信息，使用HttpServletResponse\n\n负责向浏览器发送数据的方法：\n\n- `getOutputStream()`\n- `getWriter()`\n\n常见应用：\n\n1. 向浏览器输出消息\n2. 下载文件\n\n``` java\n// 设置让浏览器能够支持附件下载\nrespones.setHeader(\"Content-Disposition\", \"attachment;filename=\"+fileName);\n```\n\n3. 实现重定向\n\n``` java\nresponse.sendRedirect(\"/projectName/url\"); // 重定向到其他url\n```\n\n**重定向和转发的区别**\n\n- 请求转发时，url不会发生变化。（转发在服务器内部完成，不需要加项目名路径，如\"/工程名\"）\n- 重定向时，url会发生变化。（需要加项目名路径，如\"/projectName/url\")\n- 请求转发是服务器级别的，可以访问/WEB-INF/下的资源\n- 重定向是浏览器级别的，无法访问/WEB-INF/下的资源\n- 请求转发会将斜杠\"/\"发送给服务器解析，得到http://ip:port/工程名\n- 重定向会将斜杠\"/\"发送给浏览器解析，得到http://ip:port/ \n\n在前端文件中写跳转链接时，因其不能得知服务器内部的项目结构，因此需要人为指定contextPath（在Servlet程序中不需要再指定当前项目在服务器内的路径）\n\n细节：当用户提交完请求，浏览器会记录下最后一次请求的全部信息。当用户按下功能键F5，就会发起浏览器记录的最后一次请求。在此情况下如果使用请求转发的方式跳转页面，用户按下F5后会再次发起请求，因此这种情况应该使用重定向。\n\n### HttpServletRequest\n\nHttpServletRequest代表客户端的请求，用户通过HTTP协议访问服务器，HTTP协议中的所有消息信息会被封装到HttpServletRequest，通过该类的方法可以获得客户端传来的请求信息。\n\n1. 获取传递的参数\n\n``` java\nString username = request.getParameter(\"username\");\nString[] hobbies = request.getParameterValues(\"hobbies\");\n```\n\n2. 请求转发\n\n``` java\nrequest.getRequestDispatcher(\"/success.jsp\").forward(requset, response);\n```\n\n![image-20210501221519475](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210501221519475.png)\n\n3. 获取请求头中Referer信息（浏览器发起请求时的url），可用于重定向回原地址\n\n```java\nString url = req.getHeader(\"Referer\");\n```\n\n### Web中 / 斜杠的不同意义\n\n- 浏览器内代表所有资源：`/**`\n- 服务器内代表所有资源：`/`\n\n在Web中，/ 是一种**绝对路径**：\n\n- / 如果被**浏览器**解析，得到的地址是：`http://ip:port/` （指写在静态html代码中，无法被服务器解析，只能被浏览器解析）\n\n``` html\n<a href=\"/\">斜杠</a>\n```\n\n- / 如果被**服务器**解析，得到的地址是：`http://ip:port/工程路径/`\n\n``` java\n// 映射\n<url-pattern>/servlet1<url-pattern>\n\n// 获取绝对路径\nservletContext.getRealPath(\"/\");\n\n// 请求转发\nrequest.getRequestDispacther(\"/\");\n```\n\n- 特殊情况：`response.sendRedirect(\"/\"); `会将斜杠发送给浏览器解析，得到`http://ip:port/` ，因此需要再加上工程名`response.sendRedirect(\"/projectName/xxx\");`\n\n**/WEB-INF/目录下的资源文件，客户端无法直接访问（即不能在浏览器中输入url直接跳转），而只能在servlet程序中跳转**\n\n**在IDEA中，\"/\"代表的项目文件路径为\"`target/项目名-1.0-SNAPSHOT/`\"**\n\n在Web应用的前端程序（.jsp）中：\n\n- 不以 / 开始的相对路径找资源时以**当前资源的路径为基准**，容易出现问题（不推荐使用）\n- 以 / 开始的相对路径找资源时以`http://ip:port/`为基准，不包含**当前项目名称路径**，因此需要在资源前加上`${pageContext.request.contextPath}/`以使程序能找到\"`target/项目名-1.0-SNAPSHOT/`\"下的资源文件。例如若想在.jsp文件中引入css文件的路径，需要写 `href=\"${pageContext.request.contextPath}/css/style.css\"`\n\n![image-20210604105603326](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210604105603326.png)\n\n## Cookie Session\n\n会话：用户打开一个浏览器，访问了一些web资源，关闭浏览器，这个过程可以称为一个会话。\n\n有状态会话：浏览器能够保存客户端信息的会话。\n\n### 保存会话\n\n**Cookie**：客户端技术（请求，响应），服务器给客户端创建Cookie。是服务器通知客户端保存键值对的一种技术，客户端有了Cookie后，每次请求都会发送给服务器，每个Cookie的大小不能超过4kb\n\n**Session**：服务器技术，可以保存用户的会话信息。可以把信息和数据放在session中\n\n### Cookie\n\n服务器创建Cookie\n\n![image-20210505095556020](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210505095556020.png)\n\n服务器获取客户端的Cookie\n\n![image-20210505100507884](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210505100507884.png)\n\n1. 从请求中拿到Cookie信息\n2. 服务器响应给客户端Cookie\n\n``` java\nCookie[] cookies = req.getCookies(); // 获得cookies\n\ncookie.getName(); // 获得cookie中的Key\ncookie.getValue(); // 获得cookie中的Value\n\nnew Cookie(\"keyName\", value); // 新建一个Cookie\n\ncookie.setMaxAge(24*60*60); // 设置cookie的有效期，不设置默认关闭浏览器时删除\nresp.addCookie(cookie); // 响应给客户端一个cookie\n```\n\n删除Cookie的方法：\n\n-  不设置有效期，关闭浏览器（关闭Session），自动失效；\n- 设置有效期，时间为0。\n\nCookie有效路径Path的设置：通过设置path路径可以过滤掉不符合路径的Cookie。\n\n### Session\n\n服务器会给每一个用户（浏览器）创建一个Session对象。一个Session独占一个浏览器，只要浏览器没关，这个Session就一直存在。用户登录之后，整个网站都可以访问到用户信息。\n\nSession技术，底层是基于Cookie技术实现的：每次创建出的Session对象都会保存成一个Cookie对象传给浏览器保存（该Cookie对象的生命周期为Session级别，即关闭浏览器后销毁）。\n\n![image-20210506103813937](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210506103813937.png)\n\nSession和Cookie的区别：\n\n- Cookie是把用户的数据写给用户的浏览器，浏览器保存（可以保存多个）\n- Session是把用户的浏览器写到用户独占的Session中，服务器保存（保存重要的信息，减少资源的浪费）\n- Session对象由服务器创建\n\n使用场景：\n\n- 保存一个登录用户的信息\n- 购物车信息\n- 在整个网站中经常用到的数据\n\n``` java\n// 在session中存入信息\nHttpSession session = req.getSession();\nsession.setAttribute(\"name\", \"zhangsan\");\nString sessionId = session.getId();\n\n// 从session中获取信息\nHttpSession session = req.getSession();\nString name = session.getAttribute(\"name\");\n\n// 注销session\nsession.removeAttribute(\"name\");\nsession.invalidate();\n```\n\nSession销毁方法：\n\n1. 手动销毁：\n\n``` java\ngetSession().invalidate();\n```\n\n2. 自动销毁：设置会话自动过期：web.xml配置\n\n``` xml\n<session-config>\n    <!-- 15分钟后过期 -->\n\t<session-timeout>15</session-timeout>\n</session-config>\n```\n\n## JSP\n\nJava Server Pages：Java服务器端页面，也和Servlet一样，用于动态web技术。JSP页面中可以嵌入Java代码，为用户提供动态数据。其主要用于代替Servlet程序回传html页面的数据。\n\n### JSP原理\n\n浏览器向服务器发送请求，不管访问什么资源，其实都是在访问Servlet。在Tomcat部署网页后，会为每个JSP文件生成对应的Java代码（放在work目录下），即**JSP最终会被转换成Java源码**，**JSP本质上就是一个Servlet**。\n\n在JSP页面中，Java代码会原封还不动的输出，html代码会进行转换：\n\n``` java\nout.write(\"<html>\\r\\n\");\n```\n\n![image-20210423133239836](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210423133239836.png)\n\n### JSP基础语法\n\n**JSP表达式**：将结果输出到客户端\n\n```jsp\n<%-- JSP表达式\n<%= new java.util.Date()%>\n```\n\n**JSP脚本片段**：代码片段会被生成到_jspService方法中作为Java代码的一部分。\n\n```jsp\n<%-- jsp脚本片段 --%>\n<%\n    int sum = 0;\n    for (int i = 1; i <= 100; i++) {\n        sum += i;\n    }\n    out.println(\"<h1>sum=\"+sum+\"</h1>\");\n%>\n```\n\n**JSP声明**：会被编译到JSP生成的Java的类中，作为属性或方法声明。\n\n```jsp\n<%!\n    static {\n        System.out.println(\"Loading Servlet!\");\n    }\n\n    private int globalVar = 0;\n\n    public void testFunction(){\n        System.out.println(\"进入了test方法\");\n    }\n%>\n```\n\n### JSP指令\n\n静态包含：`<%@ include file=\"common/header.jsp\" %>`\n\n特点：静态包含不会翻译被包含的jsp页面，其实是把被包含的jsp页面的代码拷贝到包含的位置执行输出，两个页面的作用域会冲突。\n\n动态包含：`< jsp:include page=\" \" ></jsp:include>`\n\n特点：动态包含会被包含的jsp页面翻译成java代码，两个页面的作用域不会冲突。\n\n``` jsp\n<%@ page args... %>\n\n<%--@ include ：静态包含，会将两个页面合而为一，在这里定义的变量不能重复，作用域冲突--%>\n<%@ include file=\"common/header.jsp\" %>\n<h1>\n    网页主体\n</h1>\n<%@ include file=\"common/footer.jsp\" %>\n\n<%-- JSP标签\n    jsp:include 拼接两个页面，本质还是三个网页，在这里定义的变量可以重复，作用域不冲突\n< jsp:include page=\"common/header.jsp\" />\n<h1>\n    网页主体\n</h1>\n< jsp:include page=\"common/footer.jsp\" />\n```\n\n### 九大内置对象\n\n- PageContext\n- Request\n- Response\n- Session\n- Application【ServletContext】\n- Config【ServletConfig】\n- out\n- page\n- exception\n\n四个能够保存数据信息的对象：\n\n- PageContext：保存的数据只在一个页面中有效\n- Request：保存的数据只在一次请求中有效，请求转发会携带这个数据\n- Session：保存的数据只在一次会话中有效，从打开服务器到关闭服务器\n- Application【ServletContext】：保存的数据只在服务器中有效，从打开服务器到关闭服务器\n\n```jsp\n<%\n   pageContext.setAttribute(\"name1\", \"zhangsan1\");  // 保存的数据只在一个页面中有效\n   request.setAttribute(\"name2\", \"zhangsan2\");      // 保存的数据只在一次请求中有效，请求转发会携带这个数据\n   session.setAttribute(\"name3\", \"zhangsan3\");      // 保存的数据只在一次会话中有效，从打开服务器到关闭服务器\n   application.setAttribute(\"name4\", \"zhangsan4\");  // 保存的数据只在服务器中有效，从打开服务器到关闭服务器\n%>\n\n<%\n   String name1 = (String) pageContext.getAttribute(\"name1\");\n   String name2 = (String) pageContext.findAttribute(\"name2\");\n   String name3 = (String) pageContext.findAttribute(\"name3\");\n   String name4 = (String) pageContext.findAttribute(\"name4\");\n\n   request.setAttribute(\"name2\", \"zhangsan2\");\n   session.setAttribute(\"name3\", \"zhangsan3\");\n   application.setAttribute(\"name4\", \"zhangsan4\");\n%>\n```\n\n### out和response.getWriter()区别\n\n![image-20210502203944192](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210502203944192.png)\n\n### JSP标签、JSTL标签、EL表达式\n\n```xml\n<dependency>\n  <groupId>javax.servlet.jsp.jstl</groupId>\n  <artifactId>jstl-api</artifactId>\n  <version>1.2</version>\n</dependency>\n<dependency>\n  <groupId>taglibs</groupId>\n  <artifactId>standard</artifactId>\n  <version>1.1.2</version>\n</dependency>\n```\n\n**EL（Expression Language）表达式**：`${}`\n\n- 获取数据：`${username}`\n- 执行运算：`${param.username==\"zhangsan\"}`\n- 获取web开发的常用对象：`${param.username}`\n\n**JSP标签**\n\n``` jsp\n<jsp:forward page=\"/jsptag2.jsp\">\n\t<jsp:param name=\"name\", value=\"zhangsan\"></jsp:param>\n    <jsp:param name=\"age\", value=\"3\"></jsp:param>\n</jsp:forward>\n```\n\n**JSTL表达式**\n\nJSTL标签库的使用就是为了弥补HTML标签的不足，它自定义了许多标签，可以供我们使用 ，标签的功能和Java代码一样。\n\n- **核心标签**\n- 格式化标签\n- SQL标签\n- XML标签\n\n**JSTL标签库使用步骤：**\n\n1. 引入对应的taglib才能使用JSTL标签\n\n``` jsp\n<%@ taglib prefix=\"c\" uri=:http://java.sun.com/jsp/jstl/core\" %>\n```\n\n2. 在Tomcat也需要引入JSTL的包，否则无法解析JSTL库\n3. 使用其中的方法\n\n``` jsp\n<c:if test=\"${param.username == 'admin'}\" var=\"isAdmin\" >\n\t<c:out value=\"管理员欢迎您\"></c:out>\n</c:if>\n```\n\n``` jsp\n<c:forEach var=\"people\" items=\"${list}\" begin=\"1\" end=\"3\" step=\"1\">\n\t<c:out value=\"&{people}\"/> <br>\n</c:forEach>\n```\n\n### JavaBean\n\nJavaBean有特定的写法：\n\n- 必须有一个无参构造\n- 属性必须私有化\n- 必须有get/set方法\n\n一般用来和数据库的字段做映射。\n\n ORM：对象关系映射：\n\n- 数据库中的表——>Java中的类\n- 数据库中的字段——>Java中的类的属性\n- 数据库中的行数据——>Java中的类的对象\n\n## MVC三层架构\n\n**MVC：Model View Controller**\n\n**Controller(Servlet)**：专注于处理请求以及控制视图跳转\n\n- 接受用户的请求\n- 响应给客户端内容（交给业务层处理，接受业务层返回的数据）\n- 重定向或转发（视图跳转）\n\n**View（JSP）**：专注于显示网页与数据\n\n- 展示网页界面\n- 提供用户操作，为Controller提供请求\n\n**Model（数据库）**：\n\n- 存储数据\n\n![MVC (1)](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/MVC%20(1).png)\n\nModel\n\n- 业务处理：业务逻辑（Servce）\n- 数据持久层：CRUD（Dao）\n\nView\n\n- 展示数据\n- 提供链接发起Servlet请求（a，form，img...）\n\nController\n\n- 接受用户的请求（req：请求参数，Session信息）\n- 交给业务层处理对应的代码，接受业务层返回的结果\n- 控制视图的跳转\n\n## Filter\n\n---\n\n面试题：Filter 和 Interceptor 几乎拥有相同的功能，二者有何区别？\n\n- Filter 是 Servlet 定义的原生组件，好处是可以脱离 Spring 应用也能使用；其工作时机早于 Interceptor（待确定），在请求映射前执行\n- Interceptor 是 Spring 定义的接口，可以使用 Spring 的自动装配等功能\n\n---\n\nFilter：过滤器，用来过滤网站的数据。\n\n- 处理中文乱码\n- 登录验证\n\n![image-20210507213832192](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210507213832192.png)\n\nFilter的先后执行顺序由Filter类在web.xml中定义的顺序有关\n\n匹配方式：\n\n- 精确匹配：精确到具体的文件名\n- 目录匹配：匹配到指定目录下的所有文件：/admin/*\n- 后缀名匹配：匹配到指定后缀名的文件：*.html（不能以/开头）\n\n1. 实现`Filter`类的功能（处理中文乱码）\n\n```java\npackage com.zhao.filter;\n\nimport javax.servlet.*;\nimport java.io.IOException;\n\npublic class CharacterEncodingFilter implements Filter {\n\n    // 初始化：web服务器启动时就初始化，随时等待过滤对象出现\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException {\n        System.out.println(\"CharacterEncodingFilter初始化\");\n    }\n\n    // Chain：链\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException {\n        request.setCharacterEncoding(\"utf-8\");\n        response.setCharacterEncoding(\"utf-8\");\n        response.setContentType(\"text/html;charset=UTF-8\");\n\n        System.out.println(\"CharacterEncodingFilter初始化执行前\");\n        chain.doFilter(request, response); // 让请求继续写，如果不写，程序到这里就被拦截停止\n        System.out.println(\"CharacterEncodingFilter初始化执行后\");\n    }\n\n    //  销毁：web服务器关闭的时候，过滤会销毁\n    @Override\n    public void destroy() {\n        System.out.println(\"CharacterEncodingFilter销毁\");\n    }\n}\n```\n\n2. 在web.xml中配置Filter\n\n```xml\n<!-- 注册Filter -->\n<filter>\n    <filter-name>Filter</filter-name>\n    <filter-class>com.zhao.filter.CharacterEncodingFilter</filter-class>\n</filter>\n<!-- Filter的请求路径 -->\n<filter-mapping>\n    <filter-name>Filter</filter-name>\n    <!-- 指定url下的任何请求都会经过这个过滤器  -->\n    <url-pattern>/hello</url-pattern>\n    <!-- 若想任意url下的请求都可以经过这个过滤器，则写/* 其会拦截jsp文件，否则无法过滤jsp文件里= -->\n    <url-pattern>/*</url-pattern>\n</filter-mapping>\n```\n\nFilter的使用场景之一（事务）：在Filter中捕获Service层的异常\n\n![image-20210509102119700](/images/%E3%80%90JavaWeb%E3%80%91JavaWeb/image-20210509102119700.png)\n\n## Listener\n\nListener：监听器\n\n1. 实现监听器的接口\n\n```java\npackage com.zhao.listener;\n\nimport javax.servlet.ServletContext;\nimport javax.servlet.http.HttpSessionEvent;\nimport javax.servlet.http.HttpSessionListener;\n\npublic class OnlineCountListener implements HttpSessionListener {\n\n    // 一旦创建Session就会触发一次这个方法\n    @Override\n    public void sessionCreated(HttpSessionEvent se) {\n        ServletContext servletContext = se.getSession().getServletContext();\n        Integer onlineCount = (Integer) servletContext.getAttribute(\"OnlineCount\");\n\n        if (onlineCount == null) {\n            onlineCount = new Integer(1);\n        } else {\n            int count = onlineCount.intValue();\n            onlineCount = new Integer(count+1);\n        }\n\n        servletContext.setAttribute(\"OnlineCount\", onlineCount);\n    }\n\n    // 销毁Session监听\n    // 一旦销毁Session就会触发一次这个方法\n    @Override\n    public void sessionDestroyed(HttpSessionEvent se) {\n        ServletContext servletContext = se.getSession().getServletContext();\n        Integer onlineCount = (Integer) servletContext.getAttribute(\"OnlineCount\");\n\n        if (onlineCount == null) {\n            onlineCount = new Integer(0);\n        } else {\n            int count = onlineCount.intValue();\n            onlineCount = new Integer(count-1);\n        }\n\n        servletContext.setAttribute(\"OnlineCount\", onlineCount);\n    }\n}\n```\n\n2. 在web.xml中配置Listener\n\n```xml\n<listener>\n    <listener-class>com.zhao.listener.OnlineCountListener</listener-class>\n</listener>\n```","tags":["JavaWeb"],"categories":["JavaWeb"]},{"title":"【前端】JavaScript","url":"/2021/04/14/【前端】JavaScript/","content":"\n## JavaScript\n\nJavaScript是一门世界上最流行的脚本语言。**ECMAScript**可以理解为是JavaScript的一个标准\n\n### 引入JavaScript\n\n1. 内部标签\n\n``` html\n<!--Script标签内，写JavaScript代码-->\n<script>\n   ....\n</script>\n```\n\n2. 外部引入\n\n``` html\n<script src=\"js/helloworld.js\"></script>\n```\n\n### 基本语法\n\n``` html\n<!--Script标签内，写JavaScript代码-->\n<script>\n    // alert('hello world');\n    var score = 1;\n    if (score > 60){\n        alert(true);\n    } else {\n        alert(false);\n    }\n    // console.log() 在浏览器的控制台打印变量\n\n</script>\n```\n\n### 严格检查格式\n\n`'use strict';` 严格检查模式，必须写在JavaScript第一行，防止JavaScript不严谨的语法误用。（前提:IDEA需要设置支持ES6语法）\n\n<!-- More -->\n\n## 数据类型\n\nJavaScript数据类型包括：数值、文本、图形、音频、视频。\n\n所有变量类型都是`var / let`\n\n``` java\nvar num;\nlet num; //（推荐）局部变量建议使用let定义\n```\n\n### number\n\nJavaScript不区分小数和整数\n\n``` javascript\n123      // 整数\n123.1    // 浮点数\n1.123e4  // 科学计数法\nNaN      // not a number\n```\n\n### 字符串\n\n``` javascript\nvar str1 = 'abc';\nvar str2 = \"abc\";\nvar str3 = `abc ${str1}`;\n```\n\n### 比较运算符\n\n``` javascript\n=    // 赋值\n==   // 等于（类型不一样，值一样，也会判断为true）\n===  // 绝对等于（类型一样，值一样，才会判断为true）\n```\n\n注意：\n\n- `NaN===NaN`，这个与所有数值都不相等，包括自己\n- 只能通过`isNaN(NaN)`判断是否为`NaN`\n\n### null和undefined\n\n- null：空\n- undefined：未定义\n\n### 数组\n\n``` javascript\nvar arr = [1,2,3,4,5,'hello',null,true];\n```\n\n取数组下标如果越界了，则返回`undefined`。\n\n常用方法：\n\n- indexOf()：获取某元素对应的索引\n- slice()：截取Array的一部分，返回一个新数组\n- push()：向尾部压入一个数据\n- pop()：弹出尾部的一个元素\n- unshift()：向头部压入数据\n- shift()：弹出头部的第一个数据\n- sort()：排序\n- reverse()：元素反转\n- concat()：连接数组\n- join()：打印使用特定字符串连接后的数组\n\n### 对象\n\n对象是大括号，数组是中括号。每个属性之间使用逗号隔开，最后一个不需要\n\n``` javascript\nvar person = {\n    name: \"zhangsan\",\n    age: 13,\n    tags:['js', 'java', 'web']\n}\n\n// 查看某属性对应的值\nperson.name\n> \"zhangsan\"\n\n// 删除属性\ndelete person.name\n> true\n\n// 赋值\nperson.name = \"lisi\"\n\n// 动态添加\nperson.newAttribute = \"new attribute\"\n\n// 判断某属性是否在这个对象中 xxx in xxx\n'name' in person\n> true\nperson.hasOwnProperty('toString')\n> true\n\n// 判断一个属性是否是这个对象自身拥有的 hasOwnProperty()\nperson.hasOwnProperty('toString')\n> false\nperson.hasOwnProperty('name')\n> true\n```\n\n### Map和Set\n\n> Map：可重复的键值对集合\n\n``` javascript\nvar map = new Map([['tom', 100], ['jack', 90]]);\nvar name = map.get('tom');\nmap.set('admin', 123456);\nmap.delete('tom');\nconsole.log(name);\n```\n\n> Set：无序不重复的集合\n\n``` javascript\nvar set = new Set([1,3,3,2,2]);\nset.add(4);\nset.delete(1);\nconsole.log(set.has(3));\n```\n\n### iterator\n\n遍历数组\n\n``` javascript\n// in：取索引\nvar arr = [3, 4, 5];\nfor (var x in arr) {\n    console.log(x);\n}\n> 0 1 2\n\n// of：取元素值\nvar arr = [3, 4, 5];\nfor (let x of arr) {\n    console.log(x);\n}\n> 3 4 5\n```\n\n遍历Map\n\n``` javascript\nvar map = new Map([['tom', 100], ['jack', 90]]);\nfor (let x of map){\n    console.log(x);\n}\n```\n\n遍历Set\n\n``` javascript\nvar set = new Set([5, 6, 7]);\nfor (let x of set){\n    console.log(x);\n}\n```\n\n## 函数\n\n### 定义函数\n\n> 定义方式一\n\n``` javascript\nfunction abs(x) {\n    if (x >= 0) {\n        return x;\n    } else {\n        return -x;\n    }\n}\n```\n\n> 定义方式二\n\n``` javascript\nvar abs = function(x){\n    if (x >= 0) {\n        return x;\n    } else {\n        return -x;\n    }\n}\n```\n\n`function(x){....}`是一个匿名函数。但是可以把结果赋值给`abs`，通过`abs`就可以调用函数。\n\n> 调用函数\n\n``` javascript\nabs(10);\nabs(-10);\n```\n\n参数问题：JavaScript可以传任意个参数，也可以不传参数（返回`undefined`）。假设不传入参数，需要手动判断：\n\n``` javascript\nvar abs = function(x){\n    // 手动抛出异常\n    if (typeof x !== 'number') {\n        throw 'not a number';\n    }\n    if (x >= 0) {\n        return x;\n    } else {\n        return -x;\n    }\n}\n```\n\n> arguments\n\n代表传递进来的所有参数，是一个数组。\n\n``` javascript\nvar abs = function(x){\n\n    console.log(\"x=>\" + x);\n    \n    for (let i = 0; i < arguments.length; i++){\n    \tconsole.log(arguments[i]);    \n    }\n    \n    if (x >= 0) {\n        return x;\n    } else {\n        return -x;\n    }\n}\n```\n\n> rest\n\nES6引入的新特性，获取除了已经定义的参数外的所有参数 \n\n``` javascript\nfunction test(a, b, ...rest) {\n    console.log(\"a=>\" + a);\n    console.log(\"b=>\" + b);\n    console.log(rest); \n}\n```\n\n### 变量的作用域\n\n在JavaScript中，var定义变量实际是有作用域的。假设在**函数体中**声明，则在**函数体外**不可以使用。内部函数可以访问外部函数的成员变量，反之不行。\n\n``` javascript\nfunction test() {\n    var x = 1;\n}\n\nx = x + 2; // Uncaught Reference \n```\n\n> 提升变量的作用域\n\nJavaScript执行引擎会先定义所有全局变量，然后按顺序赋值。\n\n> 全局变量\n\n放在函数外面的变量都是全局变量。默认所有的全局变量，都会自动绑定在window对象上.\n\n``` javascript\nvar x = 'xxx';\nalert(x);\nalert(window.x);\n```\n\nJavaScript实际上只有一个全局作用域（`window`对象），任何变量（函数也可以视为变量），假设没有在函数作用范围内找到，就会向外查找，如果在全局作用域（`windows`对象中）都没找到，报错`ReferenceError`\n\n> 规范\n\n由于所有的全局变量都会绑定到`window`上，如果不同的js文件，使用了相同的全局变量，就会发生冲突。为避免冲突，可使用自定义唯一全局变量。\n\n``` javascript\n// 唯一全局变量\nvar MyApp = {};\n\n// 定义全局变量\nMyApp.name = \"zhangsan\";\nMyApp.add = function (a, b) {\n    return a + b;\n}\n```\n\n将自己的代码全部放入自定义的唯一空间名中，降低全局命名冲突的问题\n\n> 局部作用域 let\n\nES6 `let`关键字，解决局部作用域冲突问题\n\n> 常量 const\n\nES6 `const`关键字\n\n``` javascript\nconst PI = '3.14';\n```\n\n### 方法\n\n> 定义方法\n\n方法就是把函数放在对象的里面，对象只有两个东西：属性和方法\n\n``` javascript\nvar person = {\n    name: \"zhangsan\";\n    birth: 2020;\n    age: function() {\n        // 今年-出生的年\n        let now = new Date().getFullYear();\n        return now - this.birth;\n    }\n}\n\nperson.name;\nperson.age();\n```\n\n## 内部对象\n\n### JSON\n\nJSON（JavaScript Object Notation）是一种轻量级的数据交换格式。在JavaScript中一切即为对象，任何js支持的类型都可以用JSON表示。格式：\n\n- 对象用`{ }`\n- 数组用`[ ]`\n- 所有的键值对用`key: value`\n\nJSON字符串和JS对象的转换：\n\n``` javascript\nvar user = {\n    name: \"zhangsan\",\n    age: 3\n}\n\n// 对象转化为json字符串\nvar jsonUser = JSON.stringify(user);\n\n// json字符串转换为对象\nvar obj = JSON.parse('{\"name\": \"zhangsan\", \"age\": 3});\n```\n\n## 面向对象编程\n\n- 类：模板，原型对象\n- 对象：具体的实例\n\n> 原型对象\n\n语法：`childObj.__proto__ = parentObj`。子对象的原型是父对象，可获得父对象的方法。\n\n> class继承\n\n`class`关键字，是在ES6引入的。\n\n1. 定义一个类，包含属性和方法\n\n``` javascript\nclass Student {\n    constructor(name) {\n        this.name = name;\n    }\n    \n    hello() {\n        alert('hello');\n    }\n}\n\n// 创建对象\nvar xiaoming = new Student(\"xiaoming\");\nxiaoming.hello();\n```\n\n2. 继承\n\n``` javascript\nclass PrimaryStudent extends Student {\n    constructor(name, grade) {\n        super(name);\n        this.grade = grade;\n    }\n    \n    myGrade() {\n        alert(\".....\");\n    }\n}\n\nvar xiaoming = new Student(\"xiaoming\");\nvar xiaohong = new PrimaryStudent(\"xiaohong\", 3);\n\nxiaohong.myGrade();\n```\n\n> 原型链\n\n__ proto __：Object()的原型对象还是Object()对象。\n\n## 操作BOM对象\n\nBOM：浏览器对象模型。\n\n> window\n\n`window`代表浏览器窗口。\n\n> Navigator\n\n`Navigator`封装了浏览器的信息。\n\n> screen\n\n`screen`代表屏幕属性。\n\n> location\n\n`location`代表当前界面的URL信息。\n\n``` javascript\nhost: \"www.baidu.com\"\nhref:\"http://www.baidu.com/\"\nprotocol:\"https:\"\nreload:f reload() 刷新网页\n\n// 设置新的地址，网页会跳转到指定为地址\nlocation.assign('https://xxxxx') \n```\n\n> document\n\n`document`代表当前页面\n\n``` javascript\ndocument.title // 当前页面的标题\n```\n\n获取具体的文档树节点\n\n``` javascript\ndocument.getElementById('id');\n```\n\n获取cookie\n\n``` javascript\ndocument.cookie\n```\n\n> history\n\n``` javascript\nhistory.back()    // 后退\nhistory.forward() // 前进\n```\n\n## 操作DOM对象\n\nDOM：文档对象模型。浏览器网页就是一个DOM属性结构。\n\n- 更新：更新DOM节点\n- 遍历：遍历得到DOM节点\n- 删除：删除DOM节点\n- 添加：添加新DOM节点\n\n> 获得DOM节点\n\n``` javascript\nvar h1 = document.getElementsByTagName('h1');\nvar p1 = document.getElementsById('p1');\nvar p2 = document.getElementsByClassName('p2');\nvar father = document.getElementsByTagName('father');\n\nvar children = father.children;\n```\n\n> 更新DOM节点\n\n``` html\n<div id='id1'> </div>\n\t\n<script>\n\tvar id1 = document.getElementsById('id1');\t\n</script>\n```\n\n操作文本\n\n``` javascript\nid1.innerText = '456' // 修改文本的值\nid1.innerHTML = '<strong>123</strong>'\n```\n\n操作JS\n\n``` javascript\nid1.style.color = 'red';\nid1.style.fontSize = '20px';\n```\n\n> 删除节点\n\n步骤：获取父节点 ——> 通过父节点删除自己\n\n``` javascript\nvar self = document.getElementById('p1');\nvar father = p1.parentElement;\nfather.removeChild(self);\n```\n\n> 插入节点：appendChild\n\n``` javascript\nvar js = document.getElementById('js');\nvar list = document.getElementById('list');\nlist.appendChild(js);\n```\n\n> 插入节点：insert\n\n``` javascript\n// 要包含的节点.insertBefore(newNode, targetNode)\nlist.insertBefore(js, ee);\n```\n\n ## 操作表单\n\n> 表单：form DOM树\n\n- 文本框 text\n- 下拉框 select\n- 单选框 radio\n- 多选框 checkbox\n- 隐藏域 hidden\n- 密码框 password\n\n表单的作用：提交信息\n\n> 获得要提交的信息\n\n``` html\n<form action=\"post\">\n    <p>\n        <span>用户名：</span>  <input type=\"text\" id=\"username\">\n    </p>\n    \n    <!-- 多选框的值，就是定义好的value-->\n    <p>\n        <span>性别：</span>\n        <input type=\"radio\" name=\"sex\" value=\"man\" id=\"boy\"> 男\n        <input type=\"radio\" name=\"sex\" value=\"woman\" id=\"girl\"> 女\n    </p>\n    \n</form>\n\n<script>\n    var input_text = document.getElementById('username');\n    var boy_radio = document.getElementById('boy');\n    var girl_radio = document.getElementById('girl');\n    \n    // 得到输入框的值\n    input_text.value;\n    //修改输入框的值\n    input_text.value = '123'\n    \n    boy_radio.checked; // 查看是否被选中\n    girl_radio.checked = true; // 设置被选中\n</script>\n```\n\n## 事件\n\n### 静态注册事件\n\n在html标签中直接添加事件的响应函数，并在js文件中定义函数内容，这样既可在触发html标签事件时执行相应的响应函数。\n\n``` html\n<script type=\"text/javascript\">\n\tfunction onclickFun() {\n        ...\n    }\n</script>\n\n<button onclick=\"onclickFun();\">\n```\n\n### 动态注册事件\n\n网页加载后就注册好事件。这样每次检测到事件被触发就会执行响应函数\n\n``` javascript\nwindow.onload = function() {\n    var btnObj = document.getElementById(\"btn01\");\n    btnObj.onclick = function() {\n    ...\n    }\n}\n\n```\n\n## JQuery\n\njQuery库，里面存在大量的JavaScript函数，用于简化开发。\n\n**jQuery的本质**：jQuery对象是DOM对象的数组 + jQuery提供的一系列功能函数。其会将查询到的符合条件的DOM对象封装成一个数组存放并附加一些功能函数。 \n\njQuery对象和DOM对象互相转换：\n\n- DOM转jQuery：var \\$obj= \\$(DOM对象)\n- jQuery转DOM：var dom = \\$obj[下标]\n\n公式：**$(选择器).事件(响应函数)**\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Title</title>\n    \n    <!-- 导入jQuery -->\n    <script src=\"lib/jquery-3.6.0.js\"></script>\n</head>\n<body>\n\n<!--\n公式：$(selector).action()\nselector就是css的选择器\n-->\n\n<a href=\"\" id=\"test-jquery\">点我</a>\n\n<script>\n    document.getElementById('id');\n    $('#test-jquery').click(function(){\n        alert('hello, jQuery');\n    })\n</script>\n\n</body>\n</html>\n```\n\n### 选择器\n\n``` javascript\n$('p').click(); // 标签选择器\n$('#id1').click(); // id选择器\n$('.class1').click(); // class选择器\n```\n\n### 事件\n\n- 鼠标事件\n- 键盘事件\n- 其他事件\n\n``` html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Title</title>\n    <script src=\"lib/jquery-3.6.0.js\"></script>\n    <style>\n        #divMove{\n            width: 500px;\n            height: 500px;\n            border: 1px solid red;\n        }\n    </style>\n</head>\n<body>\n\n<!--\n公式：$(selector).action()\nselector就是css的选择器\n-->\nmouse: <span id=\"mouseMove\"></span>\n<div id=\"divMove\">\n    在这里移动鼠标试试\n</div>\n\n<script>\n    document.getElementById('id');\n    $('#test-jquery').click(function(){\n        alert('hello, jQuery');\n    })\n\n    // 当网页元素加载完毕之后响应事件\n    $(function(){\n        $('#divMove').mousemove(function (e) {\n            $('#mouseMove').text(' x: '+e.pageX + '  y: '+e.pageY)\n        });\n    })\n\n</script>\n\n</body>\n</html>\n```\n\n### 操作DOM\n\n节点文本操作\n\n```javascript\n// 获得值\n$('#test-ul li[name=cpp]').text();\n$('#test-ul').html();\n\n// 设置值\n$('#test-ul li[name=cpp]').text('c');\n$('#test-ul').html('xxx');\n```\n\ncss操作\n\n```javascript\n$('#test-ul li[name=cpp]').css(\"color:red\");\n```\n\n元素的显示和隐藏。本质：`display: none`\n\n``` javascript\n$('#test-ul li[name=cpp]').show()\n$('#test-ul li[name=cpp]').hide()\n```\n\n","tags":["前端"],"categories":["前端"]},{"title":"【Java】单元测试","url":"/2021/04/13/【Java】单元测试/","content":"\n## JUnit5 的变化\n\n**Spring Boot 2.2.0 版本开始引入 JUnit 5 作为单元测试默认库**。作为最新版本的JUnit框架，JUnit5与之前版本的JUnit框架有很大的不同。由三个不同子项目的几个不同模块组成：\n\n**JUnit 5 = JUnit Platform + JUnit Jupiter + JUnit Vintage**\n\n- **JUnit Platform**: JUnit Platform是在JVM上启动测试框架的基础，不仅支持JUnit自制的测试引擎，其他测试引擎也都可以接入。\n- **JUnit Jupiter**: JUnit Jupiter提供了JUnit5的新的编程模型，是JUnit5新特性的核心。内部包含了一个**测试引擎**，用于在JUnit Platform上运行。\n- **JUnit Vintage**: 由于JUint已经发展多年，为了照顾老的项目，JUnit Vintage提供了兼容JUnit4.x和JUnit3.x的测试引擎。\n\n![image-20210813193410660](/images/%E3%80%90Java%E3%80%91%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/image-20210813193410660-1628855815225.png)\n\n注意：**Spring Boot 2.4 以上版本移除了默认对Vintage的依赖。如果需要兼容junit4需要自行引入（不能使用junit4的功能 @Test）**\n\nJUnit 5’s Vintage Engine Removed from `spring-boot-starter-test`，如果需要继续兼容junit4需要自行引入vintage：\n\n```xml\n<dependency>\n    <groupId>org.junit.vintage</groupId>\n    <artifactId>junit-vintage-engine</artifactId>\n    <scope>test</scope>\n    <exclusions>\n        <exclusion>\n            <groupId>org.hamcrest</groupId>\n            <artifactId>hamcrest-core</artifactId>\n        </exclusion>\n    </exclusions>\n</dependency>\n```\n\n![img](/images/%E3%80%90Java%E3%80%91%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/1606797616337-e73010e9-9cac-496d-a177-64b677af5a3d-1628855815226.png)\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-test</artifactId>\n    <scope>test</scope>\n</dependency>\n```\n\n现在版本使用 `@SpringBootTest` ：\n\n```java\n@SpringBootTest\nclass Boot05WebAdminApplicationTests {\n    @Test\n    void contextLoads() {\n    }\n}\n```\n\n以前版本使用 `@SpringBootTest + @RunWith(SpringTest.class)`\n\nSpring Boot整合JUnit以后：\n\n- 编写测试方法：`@Test`标注（注意需要使用JUnit5版本的注解）\n- JUnit类具有Spring的功能，`@Autowired`、比如 `@Transactional` 标注测试方法，测试完成后自动回滚\n\n## JUnit5常用注解\n\nJUnit5的注解与JUnit4的注解有所变化：https://junit.org/junit5/docs/current/user-guide/#writing-tests-annotations\n\n- **@Test** 表示方法是测试方法。但是与JUnit4的`@Test`不同，他的职责非常单一不能声明任何属性，拓展的测试将会由Jupiter提供额外测试\n- **@ParameterizedTest** 表示方法是参数化测试，下方会有详细介绍\n- **@RepeatedTest** 表示方法可重复执行，下方会有详细介绍\n- **@DisplayName** 为测试类或者测试方法设置展示名称\n- **@BeforeEach** 表示在每个单元测试之前执行\n- **@AfterEach** 表示在每个单元测试之后执行\n- **@BeforeAll** 表示在所有单元测试之前执行\n- **@AfterAll** 表示在所有单元测试之后执行\n- **@Tag** 表示单元测试类别，类似于JUnit4中的 **@Categories**\n- **@Disabled** 表示测试类或测试方法不执行，类似于JUnit4中的 **@Ignore**\n- **@Timeout** 表示测试方法运行如果超过了指定时间将会返回错误\n- **@ExtendWith** 为测试类或测试方法提供扩展类引用\n\n```java\nimport org.junit.jupiter.api.Test; //注意这里使用的是JUnit5里jupiter的Test注解！！\n\npublic class TestDemo {\n    @Test\n    @DisplayName(\"第一次测试\")\n    public void firstTest() {\n        System.out.println(\"hello world\");\n    }\n}\n```\n\n## 断言（Assertions）\n\n断言（Assertions）是测试方法中的核心部分，用来对测试需要满足的条件进行验证。**这些断言方法都是 org.junit.jupiter.api.Assertions 的静态方法**。\n\n断言用于**检查业务逻辑返回的数据是否合理。所有的测试运行结束以后，会有一个详细的测试报告**\n\n### 简单断言\n\n用来对单个值进行简单的验证。如：\n\n| 方法            | 说明                                 |\n| --------------- | ------------------------------------ |\n| assertEquals    | 判断两个对象或两个原始类型是否相等   |\n| assertNotEquals | 判断两个对象或两个原始类型是否不相等 |\n| assertSame      | 判断两个对象引用是否指向同一个对象   |\n| assertNotSame   | 判断两个对象引用是否指向不同的对象   |\n| assertTrue      | 判断给定的布尔值是否为 true          |\n| assertFalse     | 判断给定的布尔值是否为 false         |\n| assertNull      | 判断给定的对象引用是否为 null        |\n| assertNotNull   | 判断给定的对象引用是否不为 null      |\n\n```java\n@Test\n@DisplayName(\"simple assertion\")\npublic void simple() {\n    assertEquals(3, 1 + 2, \"simple math\");\n    assertNotEquals(3, 1 + 1);\n\n    assertNotSame(new Object(), new Object());\n    Object obj = new Object();\n    assertSame(obj, obj);\n\n    assertFalse(1 > 2);\n    assertTrue(1 < 2);\n\n    assertNull(null);\n    assertNotNull(new Object());\n}\n```\n\n### 数组断言\n\n通过 **assertArrayEquals()** 方法来判断两个对象或原始类型的数组是否相等\n\n```java\n@Test\n@DisplayName(\"array assertion\")\npublic void array() {\n    assertArrayEquals(new int[]{1, 2}, new int[] {1, 2});\n}\n```\n\n### 组合断言\n\n`assertAll()` 方法接受多个 `org.junit.jupiter.api.Executable` 函数式接口的实例作为要验证的断言，可以通过 lambda 表达式很容易的提供这些断言\n\n```java\n@Test\n@DisplayName(\"assert all\")\npublic void all() {\n    assertAll(\"Math\",\n              () -> assertEquals(2, 1 + 1),\n              () -> assertTrue(1 > 0)\n             );\n}\n```\n\n### 异常断言\n\n在JUnit4时期，想要测试方法的异常情况时，需要用**@Rule**注解的`ExpectedException`变量，还是比较麻烦的。而JUnit5提供了一种新的断言方式 **Assertions.assertThrows()** ，配合函数式编程就可以进行使用。\n\n```java\n@Test\n@DisplayName(\"异常测试\")\npublic void exceptionTest() {\n    ArithmeticException exception = Assertions.assertThrows(\n        //扔出断言异常\n        ArithmeticException.class, () -> System.out.println(1 % 0));\n}\n```\n\n### 超时断言\n\nJUnit5还提供了 **Assertions.assertTimeout()** 为测试方法设置了超时时间\n\n```java\n@Test\n@DisplayName(\"超时测试\")\npublic void timeoutTest() {\n    //如果测试方法时间超过1s将会异常\n    Assertions.assertTimeout(Duration.ofMillis(1000), () -> Thread.sleep(500));\n}\n```\n\n### 快速失败\n\n通过 **fail()** 方法直接使得测试失败\n\n```java\n@Test\n@DisplayName(\"fail\")\npublic void shouldFail() {\n    fail(\"This should fail\");\n}\n```\n\n## 前置条件（Assumptions）\n\nJUnit 5 中的前置条件（**Assumptions【假设】**）类似于断言，不同之处在于**不满足的断言会使得测试方法失败**，而不满足的**前置条件只会使得测试方法的执行终止**。前置条件可以看成是测试方法执行的前提，当该前提不满足时，就没有继续执行的必要。\n\n```java\n@DisplayName(\"前置条件\")\npublic class AssumptionsTest {\n    private final String environment = \"DEV\";\n\n    @Test\n    @DisplayName(\"simple\")\n    public void simpleAssume() {\n        assumeTrue(Objects.equals(this.environment, \"DEV\"));\n        assumeFalse(() -> Objects.equals(this.environment, \"PROD\"));\n    }\n\n    @Test\n    @DisplayName(\"assume then do\")\n    public void assumeThenDo() {\n        assumingThat(\n            Objects.equals(this.environment, \"DEV\"),\n            () -> System.out.println(\"In DEV\")\n        );\n    }\n}\n```\n\n**assumeTrue()** 和 **assumFalse() **确保给定的条件为 true 或 false，不满足条件会使得测试**执行终止（不会失败）**。\n\n **assumingThat()** 的参数是表示条件的布尔值和对应的 `Executable` 接口的实现对象。只有条件满足时，`Executable` 对象才会被执行；当条件不满足时，测试执行并不会终止。\n\n## 嵌套测试\n\nJUnit 5 可以通过 Java 中的内部类和 **@Nested** 注解实现嵌套测试，从而可以更好的把相关的测试方法组织在一起。在内部类中可以使用 **@BeforeEach** 和 **@AfterEach** 注解，而且嵌套的层次没有限制。\n\n```java\n@DisplayName(\"A stack\")\nclass TestingAStackDemo {\n\n    Stack<Object> stack;\n\n    @Test\n    @DisplayName(\"is instantiated with new Stack()\")\n    void isInstantiatedWithNew() {\n        new Stack<>();\n    }\n\n    @Nested\n    @DisplayName(\"when new\")\n    class WhenNew {\n\n        @BeforeEach\n        void createNewStack() {\n            stack = new Stack<>();\n        }\n\n        @Test\n        @DisplayName(\"is empty\")\n        void isEmpty() {\n            assertTrue(stack.isEmpty());\n        }\n\n        @Test\n        @DisplayName(\"throws EmptyStackException when popped\")\n        void throwsExceptionWhenPopped() {\n            assertThrows(EmptyStackException.class, stack::pop);\n        }\n\n        @Test\n        @DisplayName(\"throws EmptyStackException when peeked\")\n        void throwsExceptionWhenPeeked() {\n            assertThrows(EmptyStackException.class, stack::peek);\n        }\n\n        @Nested\n        @DisplayName(\"after pushing an element\")\n        class AfterPushing {\n\n            String anElement = \"an element\";\n\n            @BeforeEach\n            void pushAnElement() {\n                stack.push(anElement);\n            }\n\n            @Test\n            @DisplayName(\"it is no longer empty\")\n            void isNotEmpty() {\n                assertFalse(stack.isEmpty());\n            }\n\n            @Test\n            @DisplayName(\"returns the element when popped and is empty\")\n            void returnElementWhenPopped() {\n                assertEquals(anElement, stack.pop());\n                assertTrue(stack.isEmpty());\n            }\n\n            @Test\n            @DisplayName(\"returns the element when peeked but remains not empty\")\n            void returnElementWhenPeeked() {\n                assertEquals(anElement, stack.peek());\n                assertFalse(stack.isEmpty());\n            }\n        }\n    }\n}\n```\n\n## 参数化测试\n\n参数化测试是JUnit5很重要的一个新特性，它使得用不同的参数多次运行测试成为了可能，也为我们的单元测试带来许多便利。\n\n利用 **@ValueSource** 等注解，指定入参，我们将可以使用不同的参数进行多次单元测试，而不需要每新增一个参数就新增一个单元测试，省去了很多冗余代码。\n\n- **@ValueSource**: 为参数化测试指定入参来源，支持八大基础类以及String类型,Class类型\n- **@NullSource**: 表示为参数化测试提供一个null的入参\n- **@EnumSource**: 表示为参数化测试提供一个枚举入参\n- **@CsvFileSource**：表示读取指定CSV文件内容作为参数化测试入参\n- **@MethodSource**：表示读取指定方法的返回值作为参数化测试入参(注意方法返回需要是一个流)\n\n当然如果参数化测试仅仅只能做到指定普通的入参还达不到让我觉得惊艳的地步。他的强大之处的地方在于他可以支持外部的各类入参。如:CSV，YML，JSON 文件甚至方法的返回值也可以作为入参。只需要去实现**ArgumentsProvider**接口，任何外部文件都可以作为它的入参。\n\n```java\n@ParameterizedTest\n@ValueSource(strings = {\"one\", \"two\", \"three\"})\n@DisplayName(\"参数化测试1\")\npublic void parameterizedTest1(String string) {\n    System.out.println(string);\n    Assertions.assertTrue(StringUtils.isNotBlank(string));\n}\n\n@ParameterizedTest\n@MethodSource(\"method\")    //指定方法名\n@DisplayName(\"方法来源参数\")\npublic void testWithExplicitLocalMethodSource(String name) {\n    System.out.println(name);\n    Assertions.assertNotNull(name);\n}\n\nstatic Stream<String> method() {\n    return Stream.of(\"apple\", \"banana\");\n}\n```\n\n## 迁移指南\n\n在进行迁移的时候需要注意如下变化：\n\n- 注解在 `org.junit.jupiter.api` 包中，断言在 `org.junit.jupiter.api.Assertions` 类中，前置条件在 `org.junit.jupiter.api.Assumptions` 类中。\n- 把 **@Before** 和 **@After** 替换成 **@BeforeEach** 和 **@AfterEach**。\n- 把 **@BeforeClass** 和 **@AfterClass** 替换成 **@BeforeAll** 和 **@AfterAll**。\n- 把 **@Ignore** 替换成 **@Disabled**。\n- 把 **@Category** 替换成 **@Tag**。\n- 把 **@RunWith**、**@Rule** 和 **@ClassRule** 替换成 **@ExtendWith**。\n\n","tags":["Java"],"categories":["Java"]},{"title":"【前端】HTML5 + CSS3","url":"/2021/04/10/【前端】HTML5/","content":"\n## HTML\n\n### HTML\n\n**Hyper Text Markup Language**（超文本标记语言）\n\n### W3C标准\n\n**W3C：World Wide Web Consortium**（万维网联盟），成立于1994年，是Web技术领域最权威和最具影响力的国际**中立性技术标准结构**。\n\nW3C标准包括：\n\n- **结构**化标准语言（HTML、XML）\n- **表现**标准语言（CSS）\n- **行为**标准（DOM、ECMAScript）\n\n\n\n<!-- More -->\n\n## CSS\n\n**Cascading Style Sheet**层叠级联样式表 。用于美化页面，可以设置字体、颜色、编剧、高度、宽度、背景图片、网页定位、网页浮动等。\n\n导入CSS文件\n\n``` html\n<link href=\"css/style.css\" rel = \"stylesheet\" type=\"text/css\"/>\n```\n\n### 基本选择器\n\n> 作用：选择页面上某一个或者某一类元素\n\n- 标签选择器：选中一类标签。`标签{}`\n- 类`class`选择器：选中所有class属性一致的标签，可以跨标签。`.类名{}`\n- `id`选择器：全局唯一，不可重复。`#id名{}`\n\n选择器优先级不遵循就近原则，是固定的：**id选择器 > class选择器 > 标签选择器**\n\n``` html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Title</title>\n\n    <style>\n        /*标签选择器*/\n        h1{\n            color: deepskyblue;\n        }\n\n        /*id选择器，id必须唯一*/\n        #id1{\n            color: antiquewhite;\n        }\n\n        /*类选择器*/\n        .style1{\n            color: darkorange;\n        }\n    </style>\n\n</head>\n<body>\n\n<h1 id = \"id1\"> 标题1 </h1>\n<h1 class = \"style1\"> 标题2 </h1>\n<h1 class = \"style1\"> 标题3 </h1>\n<h1> 标题4 </h1>\n\n</body>\n</html>\n```\n\n### 层次选择器\n\n- 后代选择器\n- 子选择器\n- 相邻兄弟选择器\n- 通用选择器\n\n``` html\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Title</title>\n\n    <style>\n        /*后代选择器*/\n        body p{\n            background: red;\n        }\n\n        /*子选择器*/\n        body>p{\n            background: green;\n        }\n\n        /*相邻兄弟选择器，只有一个，并且相邻向下*/\n        .active + p{\n            background: yellow;\n        }\n\n        /*通用兄弟选择器，当前选中元素的向下所有兄弟元素*/\n        .active~p{\n            background: darkorange;\n        }\n\n    </style>\n\n</head>\n<body>\n\n<p> p0 </p>\n<p class=\"active\"> p01 </p>\n<p class=\"active\"> p1 </p>\n<p> p2 </p>\n<p> p3 </p>\n<p class=\"active\"> p11 </p>\n<ul>\n    <li>\n        <p> p4 </p>\n    </li>\n    <li>\n        <p> p5 </p>\n    </li>\n    <li>\n        <p> p6 </p>\n    </li>\n</ul>\n\n</body>\n</html>\n```\n\n### 属性选择器\n\n> id 和 class的结合\n\n- `=`：完全相等\n- `*=`：包含等于\n- `^=`：以xxx开头\n- `$=`：以xxx结尾\n\n","tags":["前端"],"categories":["前端"]},{"title":"【MySQL】MySQL 事务","url":"/2021/04/02/【MySQL】MySQL事务/","content":"\n![image-20210913132511709](/images/%E3%80%90MySQL%E3%80%91MySQL%E4%BA%8B%E5%8A%A1/image-20210913132511709.png)\n\n## 事务原则\n\nTCL: Transaction Control Language 事务控制语言。\n\n 事务（Transaction）：事务由单独单元的一个或一组sql语句组成，在这个单元中，每个MySQL语句是相互依赖的，这个执行单元 ==**要么全部执行，要么全部不执行**==\n\n-  SQL语句1正在执行：A给B转账200     A：1000  ——> 200   B：200\n-  SQL语句2正在执行：B收到A的钱        B：800    ——>            B：400 \n\n将一组SQL放在一个批次中去执行。上述两条语句组成一组来执行，要么都成功，要么都失败，否则钱会凭空消失。\n\n> 事务原则：ACID原则——原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability)；脏读，幻读，不可重复读\n\n**1. 原子性（Atomicity）**\n\n原子性是指**事务是一个不可分割的工作单位**，事务中的操作**要么都执行，要么都不执行**，没有中间状态。对于事务在执行中发生错误，所有的操作都会被回滚，整个事务就像从没被执行过一样。\n\n**2. 一致性（Consistency）**\n\n事务必须使数据库从一个一致性状态变换到另一个一致性状态。保证数据库一致性是指当事务完成时，必须使所有数据都具有一致的状态。（例如A给B转账前后，数据库中二者余额之和相等，转账前为一个一致性状态，转账后也为一个一致性状态）。\n\n**3. 隔离性（Isolation）**\n\n隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他数据是隔离的，并发执行的各个事务之间不能互相干扰。\n\n**4. 持久性（Durability）**\n\n持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n\n其中，原子性和持久性靠**undo和redo日志**来实现，隔离性通过线程的控制来实现\n\n## 事务隔离级别\n\n> 参考链接：https://cloud.tencent.com/developer/article/1450773\n\n对于同时运行的多个事务，当这些事务访问数据库中相同的数据时，如果没有采取必要的隔离机制，就会导致各种并发问题：\n\n**1. 脏读（读取未提交数据）：**\n\n指一个事务读取了另一个事务未提交的数据。例如，两个事务T1和T2，T1读取了已经被T2更新但是**还没有被提交**的字段，之后，若T2回滚，T1读取到的内容就是临时且无效的。\n\n**2. 不可重复读（前后多次读取，数据内容不一致）：**\n\n指在一个事务内读取表中的某一行数据，过段时间，该字段数据被另一事务修改，此时第一个事务**再读时读取结果不同**。例如，两个事务T1和T2，T1读取了一个字段，然后T2**更新**了该字段，之后，T1再此读取同一字段时，值就不同了。\n\n**3. 幻读（前后多次读取，数据总量不一致）：**\n\n事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据。（类似班级里刚才看还是一个人，再看变成两个人，就像产生了幻觉）\n\n**不可重复读和幻读的区别:**\n\n(1) 不可重复读是读取了其他事务更改的数据，**针对UPDATE操作**\n\n解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。\n\n(2) 幻读是读取了其他事务新增的数据，**针对INSERT和DELETE操作**\n\n解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据。\n\n**MySQL的JDBC中，默认开启事务，此时每一句sql语句都会在一个单独的事务中执行，例如两次查询语句都会在不同的事务中执行，执行完该语句都会立刻提交。**\n\nMySQL支持4种事务隔离级别，默认级别为 ==**REPEATABLE READ**==\n\n- **READ UNCOMMITTED（读未提交数据）**：允许事务读取未被其他事务提交的变更。脏读、不可重复读和幻读都可能出现 \n- **READ COMMITTED（读已提交数据）**：只允许事务读取已经被其他事务提交的变更。可以避免脏读，但不可重复读和幻读仍然可能出现 \n- **REPEATABLE READ（可重复读）**：确保事务可以多次从一个字段中读取相同的值，在这个事务持续期间，禁止其他事务对这个字段进行更新。**此时即使其他事务修改某字段并COMMIT，本事务查询时仍是原先值**。可以避免脏读和不可重复读，但幻读仍然可能出现，**即其他事务若插入了新的行，本事务查询时也会多出这些行，导致看起来像幻觉一样，每次读取的数据总量不同**\n- **SERIALIZABLE（串行化）**：确保事务可以从一个表中读取相同的行，在这个事务持续期间，禁止其他事务对该表执行插入，更新和删除操作。所有并发问题都可以避免，但性能十分低下。在某个事务读取时，其他事务阻塞，无法对该表进行操作。**该级别下无法进行并发**\n\n查看隔离级别：\n\n``` sql\nSELECT @@TX_ISOLATION           --（8.0以前） \nSELECT @@TRANSACTION_ISOLATION  --（8.0以后）\n```\n\n设置**当前**MySQL连接的隔离级别：\n\n**SET ==SESSION== TRANSACTION ISOLATION LEVEL ==READ COMMITTED==**\n\n设置**全局**MySQL连接的隔离级别：\n\n**SET ==GLOBAL== TRANSACTION ISOLATION LEVEL ==READ COMMITTED==**\n\n## undo 和 redo 日志\n\n> http://www.zhdba.com/mysqlops/2012/04/06/innodb-log1/\n\n在数据库系统中，既有存放数据的文件，也有存放日志的文件。在内存中既有日志缓存 log buffer，也有磁盘文件 log file。MySQL中的日志文件，有这么两种与事务有关：**undo日志**与**redo日志**。\n\n### undo 日志\n\n> https://www.bilibili.com/video/BV1n7411R7WQ?p=6&spm_id_from=333.1007.top_right_bar_window_history.content.click\n\nundo日志的原理：为了满足事务的原子性，在操作任何数据之前，首先将数据备份到 undo log。然后进行数据的修改。如果出现了错误或者用户执行了 ROLLBACK 语句，系统可以利用 undo log 中的备份将数据恢复到事务开始之前的状态。并且数据库写入数据到磁盘之前，会把**数据先缓存在内存**中，事务提交时才会写入磁盘中。\n\n> 用undo日志实现原子性的简化过程\n\n 假设有A、B两个数据，值分别为1,2。\n\n- A. 事务开始.\n- B. 记录A=1到 undo log.\n- C. 修改A=3.\n- D. 记录B=2到 undo log.\n- E. 修改B=4.\n- F. 将 undo log 写到磁盘。\n- G. 将数据写到磁盘。\n- H. 事务提交\n\n**1. 如何保证持久性？**\n\n事务提交前，会把修改后的数据保存到磁盘，也就是说只要事务提交了，数据肯定持久化了。\n\n**2. 如何保证原子性？**\n\n- 每次对数据库修改，都会把修改前数据记录在 undo log，那么需要回滚时，可以读取 undo log，恢复数据。\n- 若系统在G和H之间崩溃，此时事务并未提交，需要回滚。而 undo log 已经被持久化，可以根据 undo log 来恢复数据\n- 若系统在G之前崩溃，此时数据并未持久化到硬盘，依然保持在事务之前的状态\n\n**缺陷**：每个事务提交前将数据和 undo log 写入磁盘，这样会导致大量的磁盘IO，因此性能很低。\n\n如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即 **redo log**。\n\n### redo日志\n\n和 undo log 相反，redo log 记录的是**新数据**的备份。在事务提交前，只要将 redo log 持久化即可，不需要将数据库中的数据持久化，减少了IO的次数。 \n\n> undo + redo 事务的简化过程\n\n 假设有A、B两个数据，值分别为1,2\n\n- A. 事务开始.\n- B. 记录 A=1 到 undo log buffer.\n- C. 修改 A=3.\n- D. 记录 A=3 到 redo log buffer.\n- E. 记录 B=2 到 undo log buffer\n- F. 修改 B=4.\n- G. 记录 B=4 到 redo log buffer.\n- H. 将 undo log 写入磁盘\n- I. 将 redo log 写入磁盘\n- J. 事务提交\n\n**1. 如何保证原子性？**\n\n如果在事务提交前故障，通过 undo log 日志恢复数据。如果 undo log 都还没写入，那么数据就尚未持久化，无需回滚\n\n**2. 如何保证持久化？**\n\n注意，这里并没有出现数据的持久化。因为数据已经写入 redo log，而 redo log 持久化到了硬盘，因此只要到了步骤`I`以后，事务是可以提交的。\n\n**3. 内存中的数据库数据何时持久化到磁盘？**\n\n因为 redo log 已经持久化，因此数据库数据写入磁盘与否影响不大，不过为了避免出现脏数据（内存中与磁盘不一致），事务提交后也会将内存数据刷入磁盘（也可以按照固设定的频率刷新内存数据到磁盘中）。\n\n**4. redo log 何时写入磁盘？**\n\nredo log 会在事务提交之前，或者 redo log buffer满了的时候写入磁盘\n\n这里存在两个问题：\n\n**问题1**：之前是写 undo 和数据库数据到硬盘，现在是写 undo 和 redo 到磁盘，似乎没有减少IO次数\n\n- 数据库数据写入是**随机IO**，性能很差\n- redo log 在初始化时会开辟一段**连续的空间**，写入是**顺序IO**，性能很好\n- 实际上 undo log 并不是直接写入磁盘，而是先写入到 redo log buffer 中，当 redo log 持久化时，undo log 就同时持久化到硬盘了。\n\n因此事务提交前，只需要对 redo log 持久化即可。另外，redo log 并不是写入一次就持久化一次， redo log 在内存中也有自己的缓冲池：`redo log buffer`。每次写 redo log 都是写入到 buffer，在提交时一次性持久化到磁盘，减少IO次数。\n\n**问题2**：redo log 数据是写入内存buffer中，当buffer满或者事务提交时，将 buffer 数据写入磁盘。redo log 中记录的数据，有可能包含尚未提交事务，如果此时数据库崩溃，那么如何完成数据恢复？\n\n数据恢复有两种策略：\n\n- 恢复时，只重做已经提交了的事务\n- 恢复时，重做所有事务包括未提交的事务和回滚了的事务。然后通过 undo log 回滚那些未提交的事务\n\nInnodb 引擎采用的是第二种方案，因此 undo log 要在 redo log 前持久化\n\n**总结**：\n\n- undo log 记录**更新前**的数据，用于保证事务**原子性**\n- redo log 记录**更新后**的数据，用于保证事务的**持久性**\n- redo log 有自己的内存buffer，先写入到 buffer，事务提交时写入磁盘\n- redo log 持久化之后，意味着事务是**可提交**的\n\n## 悲观锁和乐观锁\n\n参考链接：https://cloud.tencent.com/developer/article/1450773\n\n### 悲观锁\n\n![image-20210912202607757](/images/%E3%80%90MySQL%E3%80%91MySQL%E4%BA%8B%E5%8A%A1/image-20210912202607757.png)\n\n正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。\n\n悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机 制，也无法保证外部系统不会修改数据）。\n\n在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。\n\n每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。**传统的关系型数据库里边就用到了很多这种锁机制**，比如**行锁**，**表锁**等，**读锁**，**写锁**等，都是在做操作之前先上锁。\n\n### 乐观锁\n\n![image-20210912202630691](/images/%E3%80%90MySQL%E3%80%91MySQL%E4%BA%8B%E5%8A%A1/image-20210912202630691.png)\n\n相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据**版本**（ Version ）记录机制实现。\n\n何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。\n\n此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，**如果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据**。\n\n每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用**版本号**等机制。**乐观锁适用于多读的应用类型，这样可以提高吞吐量**。Redis就是利用这种check-and-set机制实现事务的。\n\n## 执行事务顺序\n\n1. 关闭自动提交：`SET autocommit = 0`\n2. 开启一个事务：`START TRANSACTION`\n   - 提交（执行成功）：`COMMIT` ，获得新的数据库\n   - 回滚（执行失败）：`ROLLBACK`，返回原先数据库\n3. 开启自动提交：`SET autocommit = 1`\n\n``` sql\n-- MySQL是默认开启事务自动提交的\nSET autocommit = 0;   -- 关闭\nSET autocommit = 1;\t  -- 开启（默认）\n\n-- 手动处理事务\nSET autocommit = 0;   -- 关闭自动提交\n\n-- 事务开启\nSTART TRANSACTION;    -- 标记一个事务的开始，从这个之后的sql都在同一个事务内\n\nINSERT xx;\nINSERT xx;\n\n-- 提交：持久化（成功）\nCOMMIT;\n\n-- 回滚：回到原来的样子（失败）\nROLLBACK;\n\n-- 事务结束\nSET autocommit = 1; -- 开启自动提交\n\nSAVEPOINT 保存点名称a;              -- 设置一个事务的保存点\nROLLBACK TO 保存点名称a;            -- 回滚到保存点 \nRELEASE SAVEPOINT 保存点名称;       -- 撤销保存点 \n```\n\n测试案例：\n\n``` sql\n-- 模拟转账\nSET autocommit = 0;  -- 关闭自动提交\n\nSTART TRANSACTION;    -- 开启一个事务\n\nUPDATE `account` SET `money`=`money` - 500 WHERE `name` = 'zhangsan';\nUPDATE `account` SET `money`=`money` + 500 WHERE `name` = 'lisi';\n\nCOMMIT;    -- 提交事务，执行后数据库内容才会修改\nROLLBACK;  -- 回滚，数据库内容不会修改\n\nSET autocommit = 1;  -- 恢复默认值\n```\n\n### DELETE 和 TRUNCATE 在事务中的区别\n\n- `DELETE`在事务提交前使用，若回滚，则数据会恢复\n- `TRUNCATE`事务提交前使用，若回滚，则数据依旧不会恢复","tags":["MySQL"],"categories":["MySQL"]},{"title":"【MySQL】JDBC","url":"/2021/04/01/【MySQL】JDBC/","content":"\n## JDBC简介\n\n> JDBC概念：https://www.jianshu.com/p/e71990336319\n>\n> 参考视频：https://www.bilibili.com/video/BV1eJ411c7rf?p=1\n\nJDBC（Java Data Base Connectivity，java数据库连接）是一个**独立于特定数据库管理系统、通用的SQL数据库存取和操作的公共接口**（一组API）。，定义了用来访问数据库的标准Java类库，（**java.sql,javax.sql**）使用这些类库可以以一种**标准**的方法、方便地访问数据库资源。\n\n普通应用程序无法直接和数据库进行通讯连接，需要借助**数据库驱动**和数据库连接。**SUN**公司为了简化开发人员对数据库的统一操作，提供了一个Java操作数据库的规范，俗称JDBC。这些规范由具体的厂商去做，开发人员**只需要调用接口**即可连接数据库进行开发。\n\nJDBC为访问不同的数据库提供了一种**统一的途径**，为开发者屏蔽了一些细节问题。JDBC的目标是使Java程序员使用JDBC可以连接任何**提供了JDBC驱动程序**的数据库系统，这样就使得程序员无需对特定的数据库系统的特点有过多的了解，从而大大简化和加快了开发过程。\n\n应用程序 ——>  JDBC  ——> MySQL驱动 /Oracle驱动 ——> MySQL数据库/Oracle数据库\n\n![image-20210517213554324](/images/%E3%80%90MySQL%E3%80%91JDBC/image-20210517213554324.png)\n\n数据库应用厂商实现JDBC的接口。开发人员不需要关注每种数据库的具体实现。\n\n> **JDBC是sun公司提供一套用于数据库操作的接口，java程序员只需要面向这套接口编程即可。**\n>\n> **不同的数据库厂商，需要针对这套接口，提供不同实现。不同的实现的集合，即为不同数据库的驱动。\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t————面向接口编程**\n\n## 1、JDBC使用概览\n\nJDBC使用步骤：\n\n- 加载驱动：`Class.forName(\"com.mysql.jdbc.Driver\");`\n- 连接数据库：`DriverManager.getConnection(url, username, password);`\n- 创建执行sql语句的对象：`Statement statement = connection.createStatement();` \n- 获得返回的结果集：`ResultSet resultSet = statement.executeQuery(sql);`\n- 释放连接：`resultSet.close();`\n\n![image-20210709164526603](/images/%E3%80%90MySQL%E3%80%91JDBC/image-20210709164526603.png)\n\n<!-- more -->\n\n``` java\npackage com.yuyunzhao.test;\n\nimport java.sql.*;\n\npublic class JdbcTest {\n    public static void main(String[] args) throws ClassNotFoundException, SQLException {\n\n        // 1. 加载驱动\n        Class.forName(\"com.mysql.jdbc.Driver\");\n\n        /* useUnicode=true：设置使用Unicode编码，支持中文\n        *  characterEncoding=utf8：设置字符集为utf-8\n        *  userSSL=true：安全连接\n        */\n        // 2. 设置用户信息和url\n        // url: jdbc:mysql(主协议:子协议)://localhost(ip):3306(端口号)/school(数据库)\n        String url = \"jdbc:mysql://localhost:3306/school?useUnicode=true&characterEncoding=utf8&useSSL=true\";\n        String username = \"root\";\n        String password = \"zhaoyuyun\";\n\n        // 3. 连接成功，Connection代表数据库对象\n        Connection connection = DriverManager.getConnection(url, username, password);\n\n        // 4. 创建执行SQL的对象\n        Statement statement = connection.createStatement();\n\n        String sql = \"SELECT * FROM `student`\";\n\n        // 5. 执行sql语句，返回的结果集中封装了全部查询结果\n        ResultSet resultSet = statement.executeQuery(sql);\n\n        while (resultSet.next()){\n            System.out.println(\"studentno = \" +  resultSet.getInt(\"studentno\"));\n            System.out.println(\"sex = \" +  resultSet.getInt(\"sex\"));\n            System.out.println(\"======================================== \");\n        }\n\n        resultSet.close();\n        statement.close();\n        connection.close();\n    }\n}\n```\n\n其中：`url: jdbc:mysql(主协议:子协议)://localhost(ip):3306(端口号)/school(数据库)`\n\n注意：通常不用显式调用 **DriverManager **类的  **registerDriver() ** 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类**都包含了静态代码块**，在这个静态代码块中，会调用  **DriverManager.registerDriver() ** 方法来注册自身的一个实例。下图是MySQL的Driver实现类的源码：\n\n![image-20210709171009159](/images/%E3%80%90MySQL%E3%80%91JDBC/image-20210709171009159.png)\n\n### 1.1 Statement对象\n\nJDBC中的Statement对象用于向数据库发送SQL语句，想完成对数据库的增删改查，只需要通过这个对象向数据库发送增删改查语句即可。\n\nStatement对象的executeUpdate方法，用于向数据库发送增、删、改的sql语句，executeUpdate执行完后，将会返回一个整数（即增删改语句导致了数据库几行数据发生了变化)。\n\nStatement.executeQuery方法用于向数据库发送查询语句，executeQuery方法返回代表查询结果的ResultSet对象。\n\n#### 1.1.1 executeUpdate方法\n\n> CRUD操作-create\n\n使用executeUpdate(String sql)方法完成数据添加操作：\n\n``` java\nStatement st = conn.createStatement();\nString sql = \"insert into user(...) values(...)\";\nint num = st.executeUpdate(sql);\nif (num > 0){\n\tSystem.out.println(\"插入成功\");\n}\n```\n\n> CRUD操作-delete\n\n使用executeUpdate(String sql)方法完成数据删除操作：\n\n``` java\nStatement st = conn.createStatement();\nString sql = \"delete from user where id=1\";\nint num = st.executeUpdate(sql);\nif (num > 0){\n\tSystem.out.println(\"删除成功\");\n}\n```\n\n> CRUD操作-update\n\n使用executeUpdate(String sql)方法完成数据修改操作：\n\n``` java\nStatement st = conn.createStatement();\nString sql = \"update user set name= '' where name=''\";\nint num = st.executeUpdate(sql);\nif (num > 0){\n\tSystem.out.println(\"修改成功\");\n}\n```\n\n#### 1.1.2 executeQuery方法\n\n> CRUD操作-read\n\n使用executeQuery(String sql)方法完成数据查询操作：\n\n``` java\nStatement st = conn.createStatement();\nString sql = \"select * from user where id=1\";\nResultSet rs = st.executeQuery(sql);\nif (rs.next()){\n\t// 根据获取列的数据类型，分别调用rs的相应方法映射到java对象中\n}\n```\n\n> SQL注入的问题\n\nsql存在漏洞，会被攻击导致数据泄漏。例如，在sql语句中加入\" xxx or 1=1\"的字段，就会导致原先的判断条件失效，从而造成数据泄漏。\n\n### 1.2 PreparedStatement对象\n\n**PreparedStatement接口是Statement的子接口，它表示一条预编译过的SQL语句，其能最大可能地提高性能：**\n\n- PreparedStatement对象可以防止SQL注入，效率更高。其会预编译SQL语句，并通过传参的形式设置参数值。\n- DBServer会对预编译语句提供性能优化。因为预编译语句有可能被重复调用，所以语句在被DBServer的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码即可；\n- 在statement语句中，即使是相同操作但是因为数据内容不一样，所以整个语句本身不能匹配，没有缓存语句的意义，事实是没有数据库会对普通语句变异后的执行代码缓存。这样每执行一次都要对传入的语句编译一次。\n\n\n``` java\nString sql = \"inset into users(`id`, `name`, `password`) values(?, ?, ?)\";\nPreparedStatment st = connection.prepareStatement(sql);\nst.setInt(1, 4);\nst.setString(2, 'zhangsan');\nst.setString(3, '123456');\n```\n\nPreparedStatement防止SQL注入的本质：把传进来的参数当做字符，假设其中存在转义字符，就直接忽略，‘’引号会被直接转义。\n\n### 1.3 JDBC使用事务\n\n要么都执行，要么都不执行。\n\n> ACID原则\n\n**1. 原子性(Atomicity)**\n\n原子性是指**事务是一个不可分割的工作单位**，事务中的操作**要么都执行，要么都不执行**。\n\n**2. 一致性(Consistency)**\n\n事务必须使数据库从一个一致性状态变换到另一个一致性状态。（例如A给B转账前后，数据库中二者余额之和相等，转账前为一个一致性状态，转账后也为一个一致性状态）。\n\n**3. 隔离性(Isolation)**\n\n隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他数据是隔离的，并发执行的各个事务之间不能互相干扰。\n\n**4. 持久性(Durability)**\n\n持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n\n> 代码实现\n\n1. 开启事务：`connection.setAutoCommit(false);` \n2. 一组业务执行完毕，提交事务：`connection.commit();`\n3. 在`catch`中显式定义回滚语句，但**默认失败后就回滚**：`connection.rollback();`\n\n若不调用`close()`就退出程序，则默认进行回滚。\n\n**MySQL的JDBC中，默认开启事务，此时每一句sql语句都会在一个单独的事务中执行，例如两次查询语句都会在不同的事务中执行，执行完该语句都会立刻提交。**\n\n``` java\npackage com.yuyunzhao.transaction;\n\nimport java.sql.*;\n\npublic class TestTransaction2 {\n    public static void main(String[] args) throws ClassNotFoundException, SQLException {\n\n        // 加载驱动\n        Class.forName(\"com.mysql.jdbc.Driver\");\n\n        /* useUnicode=true：设置使用Unicode编码，支持中文\n         *  characterEncoding=utf8：设置字符集为utf-8\n         *  userSSL=true：安全连接\n         */\n        // 设置用户信息和url\n        String url = \"jdbc:mysql://localhost:3306/shop?useUnicode=true&characterEncoding=utf8&useSSL=true\";\n        String username = \"root\";\n        String password = \"zhaoyuyun\";\n\n        Connection connection = null;\n        PreparedStatement st = null;\n\n        try {\n\n            // 连接成功，Connection代表数据库对象\n            connection = DriverManager.getConnection(url, username, password);\n\n            // 关闭数据库的自动提交，自动会开启事务\n            connection.setAutoCommit(false);\n\n            String sql1 = \"update `account` set `money` = `money` - 100 where `name` = 'A'\";\n            st = connection.prepareStatement(sql1);\n            st.executeUpdate();\n\n            // 模拟报错\n            int x = 1/0;\n\n            String sql2 = \"update `account` set `money` = `money` + 100 where `name` = 'B'\";\n            st = connection.prepareStatement(sql2);\n            st.executeUpdate();\n\n            // 业务完毕，提交事务\n            connection.commit();\n            System.out.println(\"成功\");\n\n        }catch(Exception e){\n            // 如果上述事务执行过程中异常，则回滚\n            // 默认会回滚\n            System.out.println(\"失败\");\n            try{\n                connection.rollback(); // 如果失败则回滚事务\n            } catch (SQLException e1){\n                e1.printStackTrace();\n            }\n            e.printStackTrace();\n        } finally {\n            st.close();\n            connection.close();\n        }\n\n    }\n}\n```\n\n## 2、获取数据库连接\n\n### 2.1 要素一：Driver接口实现类\n\n#### 2.1.1 Driver接口介绍\n\n- java.sql.Driver 接口是所有 JDBC 驱动程序需要实现的接口。这个接口是提供给数据库厂商使用的，不同数据库厂商提供不同的实现。\n\n- 在程序中不需要直接去访问实现了 Driver 接口的类，而是由驱动程序管理器类(java.sql.DriverManager)去调用这些Driver实现。\n  - Oracle的驱动：**oracle.jdbc.driver.OracleDriver**\n  - mySql的驱动： **com.mysql.jdbc.Driver**\n\n![1555576157618](/images/%E3%80%90MySQL%E3%80%91JDBC/1555576157618.png)\n\n![1555576170074](/images/%E3%80%90MySQL%E3%80%91JDBC/1555576170074.png)\n\n- 将上述jar包拷贝到Java工程的一个目录中，习惯上新建一个lib文件夹。\n\n ![1566134718955](/images/%E3%80%90MySQL%E3%80%91JDBC/1566134718955.png)\n\n在驱动jar上右键-->Build Path-->Add to Build Path\n\n ![1566134781682](/images/%E3%80%90MySQL%E3%80%91JDBC/1566134781682.png)\n\n注意：如果是Dynamic Web Project（动态的web项目）话，则是把驱动jar放到WebContent（有的开发工具叫WebRoot）目录中的WEB-INF目录中的lib目录下即可\n\n ![1566135290460](/images/%E3%80%90MySQL%E3%80%91JDBC/1566135290460.png)\n\n#### 2.1.2 加载与注册JDBC驱动\n\n- 加载驱动：加载 JDBC 驱动需调用 Class 类的静态方法 forName()，向其传递要加载的 JDBC 驱动的类名\n\n  - **Class.forName(“com.mysql.jdbc.Driver”);**\n\n- 注册驱动：DriverManager 类是驱动程序管理器类，负责管理驱动程序\n\n  - **使用DriverManager.registerDriver(com.mysql.jdbc.Driver)来注册驱动**\n\n  - 通常不用显式调用 DriverManager 类的 registerDriver() 方法来注册驱动程序类的实例，因为 Driver 接口的驱动程序类**都**包含了静态代码块，在这个静态代码块中，会调用 DriverManager.registerDriver() 方法来注册自身的一个实例。下图是MySQL的Driver实现类的源码：\n\n    ![1566136831283](/images/%E3%80%90MySQL%E3%80%91JDBC/1566136831283.png)\n\n### 2.2 要素二：URL\n\n- JDBC URL 用于标识一个被注册的驱动程序，驱动程序管理器通过这个 URL 选择正确的驱动程序，从而建立到数据库的连接。\n\n- JDBC URL的标准由三部分组成，各部分间用冒号分隔。 \n\n  - **jdbc:子协议:子名称**\n  - **协议**：JDBC URL中的协议总是jdbc \n  - **子协议**：子协议用于标识一个数据库驱动程序\n  - **子名称**：一种标识数据库的方法。子名称可以依不同的子协议而变化，用子名称的目的是为了**定位数据库**提供足够的信息。包含**主机名**(对应服务端的ip地址)**，端口号，数据库名**\n\n- 举例：\n\n  ![1555576477107](/images/%E3%80%90MySQL%E3%80%91JDBC/1555576477107.png)\n\n- **几种常用数据库的 JDBC URL**\n\n  - MySQL的连接URL编写方式：\n\n    - jdbc:mysql://主机名称:mysql服务端口号/数据库名称?参数=值&参数=值\n    - jdbc:mysql://localhost:3306/atguigu\n    - jdbc:mysql://localhost:3306/atguigu**?useUnicode=true&characterEncoding=utf8**（如果JDBC程序与服务器端的字符集不一致，会导致乱码，那么可以通过参数指定服务器端的字符集）\n    - jdbc:mysql://localhost:3306/atguigu?user=root&password=123456\n\n  - Oracle 9i的连接URL编写方式：\n\n    - jdbc:oracle:thin:@主机名称:oracle服务端口号:数据库名称\n    - jdbc:oracle:thin:@localhost:1521:atguigu\n\n  - SQLServer的连接URL编写方式：\n\n    - jdbc:sqlserver://主机名称:sqlserver服务端口号:DatabaseName=数据库名称\n\n    - jdbc:sqlserver://localhost:1433:DatabaseName=atguigu\n\n### 2.3 要素三：用户名和密码\n\n- user,password可以用“属性名=属性值”方式告诉数据库\n- 可以调用 DriverManager 类的 getConnection() 方法建立到数据库的连接\n\n### 2.4 数据库连接方式举例\n\n#### 2.4.1 连接方式一\n\n```java\n\t@Test\n    public void testConnection1() {\n        try {\n            //1.提供java.sql.Driver接口实现类的对象\n            Driver driver = null;\n            driver = new com.mysql.jdbc.Driver();\n\n            //2.提供url，指明具体操作的数据\n            String url = \"jdbc:mysql://localhost:3306/test\";\n\n            //3.提供Properties的对象，指明用户名和密码\n            Properties info = new Properties();\n            info.setProperty(\"user\", \"root\");\n            info.setProperty(\"password\", \"abc123\");\n\n            //4.调用driver的connect()，获取连接\n            Connection conn = driver.connect(url, info);\n            System.out.println(conn);\n        } catch (SQLException e) {\n            e.printStackTrace();\n        }\n    }\n```\n\n> 说明：上述代码中显式出现了第三方数据库的API\n\n#### 2.4.2 连接方式二\n\n```java\n\t@Test\n    public void testConnection2() {\n        try {\n            //1.实例化Driver\n            String className = \"com.mysql.jdbc.Driver\";\n            Class clazz = Class.forName(className);\n            Driver driver = (Driver) clazz.newInstance();\n\n            //2.提供url，指明具体操作的数据\n            String url = \"jdbc:mysql://localhost:3306/test\";\n\n            //3.提供Properties的对象，指明用户名和密码\n            Properties info = new Properties();\n            info.setProperty(\"user\", \"root\");\n            info.setProperty(\"password\", \"abc123\");\n\n            //4.调用driver的connect()，获取连接\n            Connection conn = driver.connect(url, info);\n            System.out.println(conn);\n\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n    }\n```\n\n> 说明：相较于方式一，这里使用反射实例化Driver，不在代码中体现第三方数据库的API。体现了面向接口编程思想。\n\n#### 2.4.3 连接方式三\n\n```java\n\t@Test\n    public void testConnection3() {\n        try {\n            //1.数据库连接的4个基本要素：\n            String url = \"jdbc:mysql://localhost:3306/test\";\n            String user = \"root\";\n            String password = \"abc123\";\n            String driverName = \"com.mysql.jdbc.Driver\";\n\n            //2.实例化Driver\n            Class clazz = Class.forName(driverName);\n            Driver driver = (Driver) clazz.newInstance();\n            //3.注册驱动\n            DriverManager.registerDriver(driver);\n            //4.获取连接\n            Connection conn = DriverManager.getConnection(url, user, password);\n            System.out.println(conn);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\n    }\n```\n\n> 说明：使用DriverManager实现数据库的连接。体会获取连接必要的4个基本要素。\n\n#### 2.4.4 连接方式四\n\n```java\n\t@Test\n    public void testConnection4() {\n        try {\n            //1.数据库连接的4个基本要素：\n            String url = \"jdbc:mysql://localhost:3306/test\";\n            String user = \"root\";\n            String password = \"abc123\";\n            String driverName = \"com.mysql.jdbc.Driver\";\n\n            //2.加载驱动 （①实例化Driver ②注册驱动）\n            Class.forName(driverName);\n\n\n            //Driver driver = (Driver) clazz.newInstance();\n            //3.注册驱动\n            //DriverManager.registerDriver(driver);\n            /*\n            可以注释掉上述代码的原因，是因为在mysql的Driver类中声明有：\n            static {\n                try {\n                    DriverManager.registerDriver(new Driver());\n                } catch (SQLException var1) {\n                    throw new RuntimeException(\"Can't register driver!\");\n                }\n            }\n\n             */\n\n\n            //3.获取连接\n            Connection conn = DriverManager.getConnection(url, user, password);\n            System.out.println(conn);\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\n    }\n```\n\n> 说明：不必显式的注册驱动了。因为在DriverManager的源码中已经存在静态代码块，实现了驱动的注册。\n\n#### 2.4.5 连接方式五(最终版)\n\n```java\n\t@Test\n    public  void testConnection5() throws Exception {\n    \t//1.加载配置文件\n        InputStream is = ConnectionTest.class.getClassLoader().getResourceAsStream(\"jdbc.properties\");\n        Properties pros = new Properties();\n        pros.load(is);\n        \n        //2.读取配置信息\n        String user = pros.getProperty(\"user\");\n        String password = pros.getProperty(\"password\");\n        String url = pros.getProperty(\"url\");\n        String driverClass = pros.getProperty(\"driverClass\");\n\n        //3.加载驱动\n        Class.forName(driverClass);\n\n        //4.获取连接\n        Connection conn = DriverManager.getConnection(url,user,password);\n        System.out.println(conn);\n\n    }\n```\n\n其中，配置文件声明在工程的src目录下：【jdbc.properties】\n\n```properties\nuser=root\npassword=abc123\nurl=jdbc:mysql://localhost:3306/test\ndriverClass=com.mysql.jdbc.Driver\n```\n\n> 说明：使用配置文件的方式保存配置信息，在代码中加载配置文件\n>\n> **使用配置文件的好处：**\n>\n> ①实现了代码和数据的分离，如果需要修改配置信息，直接在配置文件中修改，不需要深入代码\n>\n> ②如果修改了配置信息，省去重新编译的过程。\n\n## 3、使用PreparedStatement实现CRUD操作\n\n### 3.1 操作和访问数据库\n\n- 数据库连接被用于向数据库服务器发送命令和 SQL 语句，并接受数据库服务器返回的结果。其实一个数据库连接就是一个Socket连接。\n\n- 在 java.sql 包中有 3 个接口分别定义了对数据库的调用的不同方式：\n\n  - Statement：用于执行静态 SQL 语句并返回它所生成结果的对象。 \n  - PrepatedStatement：SQL 语句被预编译并存储在此对象中，可以使用此对象多次高效地执行该语句。\n  - CallableStatement：用于执行 SQL 存储过程\n\n  ![1566573842140](/images/%E3%80%90MySQL%E3%80%91JDBC/1566573842140.png)\n\n### 3.2 使用Statement操作数据表的弊端\n\n- 通过调用 Connection 对象的 createStatement() 方法创建该对象。该对象用于执行静态的 SQL 语句，并且返回执行结果。\n\n- Statement 接口中定义了下列方法用于执行 SQL 语句：\n\n  ```sql\n  int excuteUpdate(String sql)：执行更新操作INSERT、UPDATE、DELETE\n  ResultSet executeQuery(String sql)：执行查询操作SELECT\n  ```\n\n- 但是使用Statement操作数据表存在弊端：\n\n  - **问题一：存在拼串操作，繁琐**\n  - **问题二：存在SQL注入问题**\n\n- SQL 注入是利用某些系统没有对用户输入的数据进行充分的检查，而在用户输入数据中注入非法的 SQL 语句段或命令(如：SELECT user, password FROM user_table WHERE user='a' OR 1 = ' AND password = ' OR '1' = '1') ，从而利用系统的 SQL 引擎完成恶意行为的做法。\n\n- 对于 Java 而言，要防范 SQL 注入，只要用 PreparedStatement(从Statement扩展而来) 取代 Statement 就可以了。\n\n- 代码演示：\n\n```java\npublic class StatementTest {\n\n\t// 使用Statement的弊端：需要拼写sql语句，并且存在SQL注入的问题\n\t@Test\n\tpublic void testLogin() {\n\t\tScanner scan = new Scanner(System.in);\n\n\t\tSystem.out.print(\"用户名：\");\n\t\tString userName = scan.nextLine();\n\t\tSystem.out.print(\"密   码：\");\n\t\tString password = scan.nextLine();\n\n\t\t// SELECT user,password FROM user_table WHERE USER = '1' or ' AND PASSWORD = '='1' or '1' = '1';\n\t\tString sql = \"SELECT user,password FROM user_table WHERE USER = '\" + userName + \"' AND PASSWORD = '\" + password\n\t\t\t\t+ \"'\";\n\t\tUser user = get(sql, User.class);\n\t\tif (user != null) {\n\t\t\tSystem.out.println(\"登陆成功!\");\n\t\t} else {\n\t\t\tSystem.out.println(\"用户名或密码错误！\");\n\t\t}\n\t}\n\n\t// 使用Statement实现对数据表的查询操作\n\tpublic <T> T get(String sql, Class<T> clazz) {\n\t\tT t = null;\n\n\t\tConnection conn = null;\n\t\tStatement st = null;\n\t\tResultSet rs = null;\n\t\ttry {\n\t\t\t// 1.加载配置文件\n\t\t\tInputStream is = StatementTest.class.getClassLoader().getResourceAsStream(\"jdbc.properties\");\n\t\t\tProperties pros = new Properties();\n\t\t\tpros.load(is);\n\n\t\t\t// 2.读取配置信息\n\t\t\tString user = pros.getProperty(\"user\");\n\t\t\tString password = pros.getProperty(\"password\");\n\t\t\tString url = pros.getProperty(\"url\");\n\t\t\tString driverClass = pros.getProperty(\"driverClass\");\n\n\t\t\t// 3.加载驱动\n\t\t\tClass.forName(driverClass);\n\n\t\t\t// 4.获取连接\n\t\t\tconn = DriverManager.getConnection(url, user, password);\n\n\t\t\tst = conn.createStatement();\n\n\t\t\trs = st.executeQuery(sql);\n\n\t\t\t// 获取结果集的元数据\n\t\t\tResultSetMetaData rsmd = rs.getMetaData();\n\n\t\t\t// 获取结果集的列数\n\t\t\tint columnCount = rsmd.getColumnCount();\n\n\t\t\tif (rs.next()) {\n\n\t\t\t\tt = clazz.newInstance();\n\n\t\t\t\tfor (int i = 0; i < columnCount; i++) {\n\t\t\t\t\t// //1. 获取列的名称\n\t\t\t\t\t// String columnName = rsmd.getColumnName(i+1);\n\n\t\t\t\t\t// 1. 获取列的别名\n\t\t\t\t\tString columnName = rsmd.getColumnLabel(i + 1);\n\n\t\t\t\t\t// 2. 根据列名获取对应数据表中的数据\n\t\t\t\t\tObject columnVal = rs.getObject(columnName);\n\n\t\t\t\t\t// 3. 将数据表中得到的数据，封装进对象\n\t\t\t\t\tField field = clazz.getDeclaredField(columnName);\n\t\t\t\t\tfield.setAccessible(true);\n\t\t\t\t\tfield.set(t, columnVal);\n\t\t\t\t}\n\t\t\t\treturn t;\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\t// 关闭资源\n\t\t\tif (rs != null) {\n\t\t\t\ttry {\n\t\t\t\t\trs.close();\n\t\t\t\t} catch (SQLException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (st != null) {\n\t\t\t\ttry {\n\t\t\t\t\tst.close();\n\t\t\t\t} catch (SQLException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (conn != null) {\n\t\t\t\ttry {\n\t\t\t\t\tconn.close();\n\t\t\t\t} catch (SQLException e) {\n\t\t\t\t\te.printStackTrace();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn null;\n\t}\n}\n```\n\n综上：\n\n![1566569819744](/images/%E3%80%90MySQL%E3%80%91JDBC/1566569819744.png)\n\n### 3.3 PreparedStatement的使用\n\n#### 3.3.1 PreparedStatement介绍\n\n- 可以通过调用 Connection 对象的 **preparedStatement(String sql)** 方法获取 PreparedStatement 对象\n\n- **PreparedStatement 接口是 Statement 的子接口，它表示一条预编译过的 SQL 语句**\n\n- PreparedStatement 对象所代表的 SQL 语句中的参数用问号(?)来表示，调用 PreparedStatement 对象的 setXxx() 方法来设置这些参数. setXxx() 方法有两个参数，第一个参数是要设置的 SQL 语句中的参数的索引(从 1 开始)，第二个是设置的 SQL 语句中的参数的值\n\n#### 3.3.2 PreparedStatement vs Statement\n\n- 代码的可读性和可维护性。\n\n- **PreparedStatement 能最大可能提高性能：**\n  - DBServer会对**预编译**语句提供性能优化。因为预编译语句有可能被重复调用，所以<u>语句在被DBServer的编译器编译后的执行代码被缓存下来，那么下次调用时只要是相同的预编译语句就不需要编译，只要将参数直接传入编译过的语句执行代码中就会得到执行。</u>\n  - 在statement语句中,即使是相同操作但因为数据内容不一样,所以整个语句本身不能匹配,没有缓存语句的意义.事实是没有数据库会对普通语句编译后的执行代码缓存。这样<u>每执行一次都要对传入的语句编译一次。</u>\n  - (语法检查，语义检查，翻译成二进制命令，缓存)\n\n- PreparedStatement 可以防止 SQL 注入 \n\n#### 3.3.3 Java与SQL对应数据类型转换表\n\n| Java类型           | SQL类型                  |\n| ------------------ | ------------------------ |\n| boolean            | BIT                      |\n| byte               | TINYINT                  |\n| short              | SMALLINT                 |\n| int                | INTEGER                  |\n| long               | BIGINT                   |\n| String             | CHAR,VARCHAR,LONGVARCHAR |\n| byte   array       | BINARY  ,    VAR BINARY  |\n| java.sql.Date      | DATE                     |\n| java.sql.Time      | TIME                     |\n| java.sql.Timestamp | TIMESTAMP                |\n\n#### 3.3.4 使用PreparedStatement实现增、删、改操作\n\n```java\n\t//通用的增、删、改操作（体现一：增、删、改 ； 体现二：针对于不同的表）\n\tpublic void update(String sql,Object ... args){\n\t\tConnection conn = null;\n\t\tPreparedStatement ps = null;\n\t\ttry {\n\t\t\t//1.获取数据库的连接\n\t\t\tconn = JDBCUtils.getConnection();\n\t\t\t\n\t\t\t//2.获取PreparedStatement的实例 (或：预编译sql语句)\n\t\t\tps = conn.prepareStatement(sql);\n\t\t\t//3.填充占位符\n\t\t\tfor(int i = 0;i < args.length;i++){\n\t\t\t\tps.setObject(i + 1, args[i]);\n\t\t\t}\n\t\t\t\n\t\t\t//4.执行sql语句\n\t\t\tps.execute();\n\t\t} catch (Exception e) {\n\t\t\t\n\t\t\te.printStackTrace();\n\t\t}finally{\n\t\t\t//5.关闭资源\n\t\t\tJDBCUtils.closeResource(conn, ps);\n\t\t\t\n\t\t}\n\t}\n```\n\n\n\n#### 3.3.5 使用PreparedStatement实现查询操作\n\n```java\n\t// 通用的针对于不同表的查询:返回一个对象 (version 1.0)\n\tpublic <T> T getInstance(Class<T> clazz, String sql, Object... args) {\n\n\t\tConnection conn = null;\n\t\tPreparedStatement ps = null;\n\t\tResultSet rs = null;\n\t\ttry {\n\t\t\t// 1.获取数据库连接\n\t\t\tconn = JDBCUtils.getConnection();\n\n\t\t\t// 2.预编译sql语句，得到PreparedStatement对象\n\t\t\tps = conn.prepareStatement(sql);\n\n\t\t\t// 3.填充占位符\n\t\t\tfor (int i = 0; i < args.length; i++) {\n\t\t\t\tps.setObject(i + 1, args[i]);\n\t\t\t}\n\n\t\t\t// 4.执行executeQuery(),得到结果集：ResultSet\n\t\t\trs = ps.executeQuery();\n\n\t\t\t// 5.得到结果集的元数据：ResultSetMetaData\n\t\t\tResultSetMetaData rsmd = rs.getMetaData();\n\n\t\t\t// 6.1通过ResultSetMetaData得到columnCount,columnLabel；通过ResultSet得到列值\n\t\t\tint columnCount = rsmd.getColumnCount();\n\t\t\tif (rs.next()) {\n\t\t\t\tT t = clazz.newInstance();\n\t\t\t\tfor (int i = 0; i < columnCount; i++) {// 遍历每一个列\n\n\t\t\t\t\t// 获取列值\n\t\t\t\t\tObject columnVal = rs.getObject(i + 1);\n\t\t\t\t\t// 获取列的别名:列的别名，使用类的属性名充当\n\t\t\t\t\tString columnLabel = rsmd.getColumnLabel(i + 1);\n\t\t\t\t\t// 6.2使用反射，给对象的相应属性赋值\n\t\t\t\t\tField field = clazz.getDeclaredField(columnLabel);\n\t\t\t\t\tfield.setAccessible(true);\n\t\t\t\t\tfield.set(t, columnVal);\n\n\t\t\t\t}\n\n\t\t\t\treturn t;\n\n\t\t\t}\n\t\t} catch (Exception e) {\n\n\t\t\te.printStackTrace();\n\t\t} finally {\n\t\t\t// 7.关闭资源\n\t\t\tJDBCUtils.closeResource(conn, ps, rs);\n\t\t}\n\n\t\treturn null;\n\n\t}\n```\n\n> 说明：使用PreparedStatement实现的查询操作可以替换Statement实现的查询操作，解决Statement拼串和SQL注入问题。\n\n### 3.4 ResultSet与ResultSetMetaData\n\n#### 3.4.1 ResultSet\n\n- 查询需要调用PreparedStatement 的 executeQuery() 方法，查询结果是一个ResultSet 对象\n\n- ResultSet 对象以逻辑表格的形式封装了执行数据库操作的结果集，ResultSet 接口由数据库厂商提供实现\n\n- ResultSet 返回的实际上就是一张数据表。有一个指针指向数据表的第一条记录的前面。\n\n- ResultSet 对象维护了一个指向当前数据行的**游标**，初始的时候，游标在第一行之前，可以通过 ResultSet 对象的 next() 方法移动到下一行。调用 next()方法检测下一行是否有效。若有效，该方法返回 true，且指针下移。相当于Iterator对象的 hasNext() 和 next() 方法的结合体。\n\n- 当指针指向一行时, 可以通过调用 getXxx(int index) 或 getXxx(int columnName) 获取每一列的值。\n\n  - 例如: getInt(1), getString(\"name\")\n  - **注意：Java与数据库交互涉及到的相关Java API中的索引都从1开始。**\n\n- ResultSet 接口的常用方法：\n\n  - boolean next()\n\n  - getString()\n  - …\n\n  ![1555580152530](/images/%E3%80%90MySQL%E3%80%91JDBC/1555580152530.png)\n\n#### 3.4.2 ResultSetMetaData\n\n- 可用于获取关于 ResultSet 对象中列的类型和属性信息的对象\n\n- ResultSetMetaData meta = rs.getMetaData();\n  - **getColumnName**(int column)：获取指定列的名称\n  - **getColumnLabel**(int column)：获取指定列的别名\n  - **getColumnCount**()：返回当前 ResultSet 对象中的列数。 \n\n  - getColumnTypeName(int column)：检索指定列的数据库特定的类型名称。 \n  - getColumnDisplaySize(int column)：指示指定列的最大标准宽度，以字符为单位。 \n  - **isNullable**(int column)：指示指定列中的值是否可以为 null。 \n\n  - isAutoIncrement(int column)：指示是否自动为指定列进行编号，这样这些列仍然是只读的。 \n\n![1555579494691](/images/%E3%80%90MySQL%E3%80%91JDBC/1555579494691.png)\n\n**问题1：得到结果集后, 如何知道该结果集中有哪些列 ？ 列名是什么？**\n\n​     需要使用一个描述 ResultSet 的对象， 即 ResultSetMetaData\n\n**问题2：关于ResultSetMetaData**\n\n1. **如何获取 ResultSetMetaData**： 调用 ResultSet 的 getMetaData() 方法即可\n2. **获取 ResultSet 中有多少列**：调用 ResultSetMetaData 的 getColumnCount() 方法\n3. **获取 ResultSet 每一列的列的别名是什么**：调用 ResultSetMetaData 的getColumnLabel() 方法\n\n![1555579816884](/images/%E3%80%90MySQL%E3%80%91JDBC/1555579816884.png)\n\n### 3.5 资源的释放\n\n- 释放ResultSet, Statement,Connection。\n- 数据库连接（Connection）是非常稀有的资源，用完后必须马上释放，如果Connection不能及时正确的关闭将导致系统宕机。Connection的使用原则是**尽量晚创建，尽量早的释放。**\n- 可以在finally中关闭，保证及时其他代码出现异常，资源也一定能被关闭。\n\n\n\n### 3.6 JDBC API小结\n\n- 两种思想\n\n  - 面向接口编程的思想\n\n  - ORM思想(object relational mapping)\n    - 一个数据表对应一个java类\n    - 表中的一条记录对应java类的一个对象\n    - 表中的一个字段对应java类的一个属性\n\n  > sql是需要结合列名和表的属性名来写。注意起别名。\n\n- 两种技术\n\n  - JDBC结果集的元数据：ResultSetMetaData\n    - 获取列数：getColumnCount()\n    - 获取列的别名：getColumnLabel()\n  - 通过反射，创建指定类的对象，获取指定的属性并赋值\n\n## 4、操作BLOB类型字段\n\n### 4.1 MySQL BLOB类型\n\n- MySQL中，BLOB是一个二进制大型对象，是一个可以存储大量数据的容器，它能容纳不同大小的数据。\n- 插入BLOB类型的数据必须使用PreparedStatement，因为BLOB类型的数据无法使用字符串拼接写的。\n\n- MySQL的四种BLOB类型(除了在存储的最大信息量上不同外，他们是等同的)\n\n![1555581069798](/images/%E3%80%90MySQL%E3%80%91JDBC/1555581069798.png)\n\n- 实际使用中根据需要存入的数据大小定义不同的BLOB类型。\n- 需要注意的是：如果存储的文件过大，数据库的性能会下降。\n- 如果在指定了相关的Blob类型以后，还报错：xxx too large，那么在mysql的安装目录下，找my.ini文件加上如下的配置参数： **max_allowed_packet=16M**。同时注意：修改了my.ini文件之后，需要重新启动mysql服务。\n\n### 4.2 向数据表中插入大数据类型\n\n```java\n//获取连接\nConnection conn = JDBCUtils.getConnection();\n\t\t\nString sql = \"insert into customers(name,email,birth,photo)values(?,?,?,?)\";\nPreparedStatement ps = conn.prepareStatement(sql);\n\n// 填充占位符\nps.setString(1, \"徐海强\");\nps.setString(2, \"xhq@126.com\");\nps.setDate(3, new Date(new java.util.Date().getTime()));\n// 操作Blob类型的变量\nFileInputStream fis = new FileInputStream(\"xhq.png\");\nps.setBlob(4, fis);\n//执行\nps.execute();\n\t\t\nfis.close();\nJDBCUtils.closeResource(conn, ps);\n\n```\n\n\n\n### 4.3 修改数据表中的Blob类型字段\n\n```java\nConnection conn = JDBCUtils.getConnection();\nString sql = \"update customers set photo = ? where id = ?\";\nPreparedStatement ps = conn.prepareStatement(sql);\n\n// 填充占位符\n// 操作Blob类型的变量\nFileInputStream fis = new FileInputStream(\"coffee.png\");\nps.setBlob(1, fis);\nps.setInt(2, 25);\n\nps.execute();\n\nfis.close();\nJDBCUtils.closeResource(conn, ps);\n```\n\n\n\n### 4.4 从数据表中读取大数据类型\n\n```java\nString sql = \"SELECT id, name, email, birth, photo FROM customer WHERE id = ?\";\nconn = getConnection();\nps = conn.prepareStatement(sql);\nps.setInt(1, 8);\nrs = ps.executeQuery();\nif(rs.next()){\n\tInteger id = rs.getInt(1);\n    String name = rs.getString(2);\n\tString email = rs.getString(3);\n    Date birth = rs.getDate(4);\n\tCustomer cust = new Customer(id, name, email, birth);\n    System.out.println(cust); \n    //读取Blob类型的字段\n\tBlob photo = rs.getBlob(5);\n\tInputStream is = photo.getBinaryStream();\n\tOutputStream os = new FileOutputStream(\"c.jpg\");\n\tbyte [] buffer = new byte[1024];\n\tint len = 0;\n\twhile((len = is.read(buffer)) != -1){\n\t\tos.write(buffer, 0, len);\n\t}\n    JDBCUtils.closeResource(conn, ps, rs);\n\t\t\n\tif(is != null){\n\t\tis.close();\n\t}\n\t\t\n\tif(os !=  null){\n\t\tos.close();\n\t}\n    \n}\n\n```\n\n\n\n## 5、批量插入\n\n### 5.1 批量执行SQL语句\n\n当需要成批插入或者更新记录时，可以采用Java的批量**更新**机制，这一机制允许多条语句一次性提交给数据库批量处理。通常情况下比单独提交处理更有效率\n\nJDBC的批量处理语句包括下面三个方法：\n\n- **addBatch(String)：添加需要批量处理的SQL语句或是参数；**\n- **executeBatch()：执行批量处理语句；**\n- **clearBatch():清空缓存的数据**\n\n通常我们会遇到两种批量执行SQL语句的情况：\n\n- 多条SQL语句的批量处理；\n- 一个SQL语句的批量传参；\n\n\n\n### 5.2 高效的批量插入\n\n举例：向数据表中插入20000条数据\n\n- 数据库中提供一个goods表。创建如下：\n\n```sql\nCREATE TABLE goods(\nid INT PRIMARY KEY AUTO_INCREMENT,\nNAME VARCHAR(20)\n);\n```\n\n\n\n#### 5.2.1 实现层次一：使用Statement\n\n```java\nConnection conn = JDBCUtils.getConnection();\nStatement st = conn.createStatement();\nfor(int i = 1;i <= 20000;i++){\n\tString sql = \"insert into goods(name) values('name_' + \"+ i +\")\";\n\tst.executeUpdate(sql);\n}\n```\n\n\n\n#### 5.2.2 实现层次二：使用PreparedStatement\n\n```java\nlong start = System.currentTimeMillis();\n\t\t\nConnection conn = JDBCUtils.getConnection();\n\t\t\nString sql = \"insert into goods(name)values(?)\";\nPreparedStatement ps = conn.prepareStatement(sql);\nfor(int i = 1;i <= 20000;i++){\n\tps.setString(1, \"name_\" + i);\n\tps.executeUpdate();\n}\n\t\t\nlong end = System.currentTimeMillis();\nSystem.out.println(\"花费的时间为：\" + (end - start));//82340\n\t\t\n\t\t\nJDBCUtils.closeResource(conn, ps);\n```\n\n#### 5.2.3 实现层次三\n\n```java\n/*\n * 修改1： 使用 addBatch() / executeBatch() / clearBatch()\n * 修改2：mysql服务器默认是关闭批处理的，我们需要通过一个参数，让mysql开启批处理的支持。\n * \t\t ?rewriteBatchedStatements=true 写在配置文件的url后面\n * 修改3：使用更新的mysql 驱动：mysql-connector-java-5.1.37-bin.jar\n * \n */\n@Test\npublic void testInsert1() throws Exception{\n\tlong start = System.currentTimeMillis();\n\t\t\n\tConnection conn = JDBCUtils.getConnection();\n\t\t\n\tString sql = \"insert into goods(name)values(?)\";\n\tPreparedStatement ps = conn.prepareStatement(sql);\n\t\t\n\tfor(int i = 1;i <= 1000000;i++){\n\t\tps.setString(1, \"name_\" + i);\n\t\t\t\n\t\t//1.“攒”sql\n\t\tps.addBatch();\n\t\tif(i % 500 == 0){\n\t\t\t//2.执行\n\t\t\tps.executeBatch();\n\t\t\t//3.清空\n\t\t\tps.clearBatch();\n\t\t}\n\t}\n\t\t\n\tlong end = System.currentTimeMillis();\n\tSystem.out.println(\"花费的时间为：\" + (end - start));//20000条：625                                                                         //1000000条:14733  \n\t\t\n\tJDBCUtils.closeResource(conn, ps);\n}\n```\n\n#### 5.2.4 实现层次四\n\n```java\n/*\n* 层次四：在层次三的基础上操作\n* 使用Connection 的 setAutoCommit(false)  /  commit()\n*/\n@Test\npublic void testInsert2() throws Exception{\n\tlong start = System.currentTimeMillis();\n\t\t\n\tConnection conn = JDBCUtils.getConnection();\n\t\t\n\t//1.设置为不自动提交数据\n\tconn.setAutoCommit(false);\n\t\t\n\tString sql = \"insert into goods(name)values(?)\";\n\tPreparedStatement ps = conn.prepareStatement(sql);\n\t\t\n\tfor(int i = 1;i <= 1000000;i++){\n\t\tps.setString(1, \"name_\" + i);\n\t\t\t\n\t\t//1.“攒”sql\n\t\tps.addBatch();\n\t\t\t\n\t\tif(i % 500 == 0){\n\t\t\t//2.执行\n\t\t\tps.executeBatch();\n\t\t\t//3.清空\n\t\t\tps.clearBatch();\n\t\t}\n\t}\n\t\t\n\t//2.提交数据\n\tconn.commit();\n\t\t\n\tlong end = System.currentTimeMillis();\n\tSystem.out.println(\"花费的时间为：\" + (end - start));//1000000条:4978 \n\t\t\n\tJDBCUtils.closeResource(conn, ps);\n}\n```\n\n## 6、 数据库事务\n\n### 6.1 数据库事务介绍\n\n- **事务：一组逻辑操作单元,使数据从一种状态变换到另一种状态。**\n\n- **事务处理（事务操作）：**保证所有事务都作为一个工作单元来执行，即使出现了故障，都不能改变这种执行方式。当在一个事务中执行多个操作时，要么所有的事务都**被提交(commit)**，那么这些修改就永久地保存下来；要么数据库管理系统将放弃所作的所有修改，整个事务**回滚(rollback)**到最初状态。\n\n- 为确保数据库中数据的**一致性**，数据的操纵应当是离散的成组的逻辑单元：当它全部完成时，数据的一致性可以保持，而当这个单元中的一部分操作失败，整个事务应全部视为错误，所有从起始点以后的操作应全部回退到开始状态。 \n\n### 6.2 JDBC事务处理\n\n- 数据一旦提交，就不可回滚。\n\n- 数据什么时候意味着提交？\n\n  - **当一个连接对象被创建时，默认情况下是自动提交事务**：每次执行一个 SQL 语句时，如果执行成功，就会向数据库自动提交，而不能回滚。\n  - **关闭数据库连接，数据就会自动的提交。**如果多个操作，每个操作使用的是自己单独的连接，则无法保证事务。即同一个事务的多个操作必须在同一个连接下。\n\n- **JDBC程序中为了让多个 SQL 语句作为一个事务执行：**\n\n  - 调用 Connection 对象的 **setAutoCommit(false);** 以取消自动提交事务\n  - 在所有的 SQL 语句都成功执行后，调用 **commit();** 方法提交事务\n  - 在出现异常时，调用 **rollback();** 方法回滚事务\n\n  > 若此时 Connection 没有被关闭，还可能被重复使用，则需要恢复其自动提交状态 setAutoCommit(true)。尤其是在使用数据库连接池技术时，执行close()方法前，建议恢复自动提交状态。\n\n【案例：用户AA向用户BB转账100】\n\n```java\npublic void testJDBCTransaction() {\n\tConnection conn = null;\n\ttry {\n\t\t// 1.获取数据库连接\n\t\tconn = JDBCUtils.getConnection();\n\t\t// 2.开启事务\n\t\tconn.setAutoCommit(false);\n\t\t// 3.进行数据库操作\n\t\tString sql1 = \"update user_table set balance = balance - 100 where user = ?\";\n\t\tupdate(conn, sql1, \"AA\");\n\n\t\t// 模拟网络异常\n\t\t//System.out.println(10 / 0);\n\n\t\tString sql2 = \"update user_table set balance = balance + 100 where user = ?\";\n\t\tupdate(conn, sql2, \"BB\");\n\t\t// 4.若没有异常，则提交事务\n\t\tconn.commit();\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\t// 5.若有异常，则回滚事务\n\t\ttry {\n\t\t\tconn.rollback();\n\t\t} catch (SQLException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\n    } finally {\n        try {\n\t\t\t//6.恢复每次DML操作的自动提交功能\n\t\t\tconn.setAutoCommit(true);\n\t\t} catch (SQLException e) {\n\t\t\te.printStackTrace();\n\t\t}\n        //7.关闭连接\n\t\tJDBCUtils.closeResource(conn, null, null); \n    }  \n}\n\n```\n\n其中，对数据库操作的方法为：\n\n```java\n//使用事务以后的通用的增删改操作（version 2.0）\npublic void update(Connection conn ,String sql, Object... args) {\n\tPreparedStatement ps = null;\n\ttry {\n\t\t// 1.获取PreparedStatement的实例 (或：预编译sql语句)\n\t\tps = conn.prepareStatement(sql);\n\t\t// 2.填充占位符\n\t\tfor (int i = 0; i < args.length; i++) {\n\t\t\tps.setObject(i + 1, args[i]);\n\t\t}\n\t\t// 3.执行sql语句\n\t\tps.execute();\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t} finally {\n\t\t// 4.关闭资源\n\t\tJDBCUtils.closeResource(null, ps);\n\n\t}\n}\n```\n\n### 6.3 事务的ACID属性    \n\n1. **原子性（Atomicity）**\n   原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。 \n\n2. **一致性（Consistency）**\n   事务必须使数据库从一个一致性状态变换到另外一个一致性状态。\n\n3. **隔离性（Isolation）**\n   事务的隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。\n\n4. **持久性（Durability）**\n   持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n\n#### 6.3.1 数据库的并发问题\n\n- 对于同时运行的多个事务, 当这些事务访问数据库中相同的数据时, 如果没有采取必要的隔离机制, 就会导致各种并发问题:\n  - **脏读**: 对于两个事务 T1, T2, T1 读取了已经被 T2 更新但还**没有被提交**的字段。之后, 若 T2 回滚, T1读取的内容就是临时且无效的。\n  - **不可重复读**: 对于两个事务T1, T2, T1 读取了一个字段, 然后 T2 **更新**了该字段。之后, T1再次读取同一个字段, 值就不同了。\n  - **幻读**: 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中**插入**了一些新的行。之后, 如果 T1 再次读取同一个表, 就会多出几行。\n\n- **数据库事务的隔离性**: 数据库系统必须具有隔离并发运行各个事务的能力, 使它们不会相互影响, 避免各种并发问题。\n\n- 一个事务与其他事务隔离的程度称为隔离级别。数据库规定了多种事务隔离级别, 不同隔离级别对应不同的干扰程度, **隔离级别越高, 数据一致性就越好, 但并发性越弱。**\n\n#### 6.3.2 四种隔离级别\n\n- 数据库提供的4种事务隔离级别：\n\n  ![1555586275271](/images/%E3%80%90MySQL%E3%80%91JDBC/1555586275271.png)\n\n- Oracle 支持的 2 种事务隔离级别：**READ COMMITED**, SERIALIZABLE。 Oracle 默认的事务隔离级别为: **READ COMMITED** 。\n\n\n- Mysql 支持 4 种事务隔离级别。Mysql 默认的事务隔离级别为: **REPEATABLE READ。**\n\n\n#### 6.3.3 在MySql中设置隔离级别\n\n- 每启动一个 mysql 程序, 就会获得一个单独的数据库连接. 每个数据库连接都有一个全局变量 @@tx_isolation, 表示当前的事务隔离级别。\n\n- 查看当前的隔离级别: \n\n  ```mysql\n  SELECT @@tx_isolation;\n  ```\n\n- 设置当前 mySQL 连接的隔离级别:  \n\n  ```mysql\n  set  transaction isolation level read committed;\n  ```\n\n- 设置数据库系统的全局的隔离级别:\n\n  ```mysql\n  set global transaction isolation level read committed;\n  ```\n\n- 补充操作：\n\n  - 创建mysql数据库用户：\n\n    ```mysql\n    create user tom identified by 'abc123';\n    ```\n\n  - 授予权限\n\n    ```mysql\n    #授予通过网络方式登录的tom用户，对所有库所有表的全部权限，密码设为abc123.\n    grant all privileges on *.* to tom@'%'  identified by 'abc123'; \n    \n     #给tom用户使用本地命令行方式，授予atguigudb这个库下的所有表的插删改查的权限。\n    grant select,insert,delete,update on atguigudb.* to tom@localhost identified by 'abc123'; \n    \n    ```\n\n\n## 7、DAO及相关实现类\n\n- DAO：Data Access Object访问数据信息的类和接口，包括了对数据的CRUD（Create、Retrival、Update、Delete），而不包含任何业务相关的信息。有时也称作：BaseDAO\n- 作用：为了实现功能的模块化，更有利于代码的维护和升级。\n- 下面是尚硅谷JavaWeb阶段书城项目中DAO使用的体现：\n\n![1566726681515](/images/%E3%80%90MySQL%E3%80%91JDBC/1566726681515-1625822622017.png)\n\n- 层次结构：\n\n![1566745811244](/images/%E3%80%90MySQL%E3%80%91JDBC/1566745811244-1625822622017.png)\n\n### 【BaseDAO.java】\n\n```java\npackage com.atguigu.bookstore.dao;\n\nimport java.lang.reflect.ParameterizedType;\nimport java.lang.reflect.Type;\nimport java.sql.Connection;\nimport java.sql.SQLException;\nimport java.util.List;\n\nimport org.apache.commons.dbutils.QueryRunner;\nimport org.apache.commons.dbutils.handlers.BeanHandler;\nimport org.apache.commons.dbutils.handlers.BeanListHandler;\nimport org.apache.commons.dbutils.handlers.ScalarHandler;\n\n\n/**\n * 定义一个用来被继承的对数据库进行基本操作的Dao\n * \n * @author HanYanBing\n *\n * @param <T>\n */\npublic abstract class BaseDao<T> {\n\tprivate QueryRunner queryRunner = new QueryRunner();\n\t// 定义一个变量来接收泛型的类型\n\tprivate Class<T> type;\n\n\t// 获取T的Class对象，获取泛型的类型，泛型是在被子类继承时才确定\n\tpublic BaseDao() {\n\t\t// 获取子类的类型\n\t\tClass clazz = this.getClass();\n\t\t// 获取父类的类型\n\t\t// getGenericSuperclass()用来获取当前类的父类的类型\n\t\t// ParameterizedType表示的是带泛型的类型\n\t\tParameterizedType parameterizedType = (ParameterizedType) clazz.getGenericSuperclass();\n\t\t// 获取具体的泛型类型 getActualTypeArguments获取具体的泛型的类型\n\t\t// 这个方法会返回一个Type的数组\n\t\tType[] types = parameterizedType.getActualTypeArguments();\n\t\t// 获取具体的泛型的类型·\n\t\tthis.type = (Class<T>) types[0];\n\t}\n\n\t/**\n\t * 通用的增删改操作\n\t * \n\t * @param sql\n\t * @param params\n\t * @return\n\t */\n\tpublic int update(Connection conn,String sql, Object... params) {\n\t\tint count = 0;\n\t\ttry {\n\t\t\tcount = queryRunner.update(conn, sql, params);\n\t\t} catch (SQLException e) {\n\t\t\te.printStackTrace();\n\t\t} \n\t\treturn count;\n\t}\n\n\t/**\n\t * 获取一个对象\n\t * \n\t * @param sql\n\t * @param params\n\t * @return\n\t */\n\tpublic T getBean(Connection conn,String sql, Object... params) {\n\t\tT t = null;\n\t\ttry {\n\t\t\tt = queryRunner.query(conn, sql, new BeanHandler<T>(type), params);\n\t\t} catch (SQLException e) {\n\t\t\te.printStackTrace();\n\t\t} \n\t\treturn t;\n\t}\n\n\t/**\n\t * 获取所有对象\n\t * \n\t * @param sql\n\t * @param params\n\t * @return\n\t */\n\tpublic List<T> getBeanList(Connection conn,String sql, Object... params) {\n\t\tList<T> list = null;\n\t\ttry {\n\t\t\tlist = queryRunner.query(conn, sql, new BeanListHandler<T>(type), params);\n\t\t} catch (SQLException e) {\n\t\t\te.printStackTrace();\n\t\t} \n\t\treturn list;\n\t}\n\n\t/**\n\t * 获取一个但一值得方法，专门用来执行像 select count(*)...这样的sql语句\n\t * \n\t * @param sql\n\t * @param params\n\t * @return\n\t */\n\tpublic Object getValue(Connection conn,String sql, Object... params) {\n\t\tObject count = null;\n\t\ttry {\n\t\t\t// 调用queryRunner的query方法获取一个单一的值\n\t\t\tcount = queryRunner.query(conn, sql, new ScalarHandler<>(), params);\n\t\t} catch (SQLException e) {\n\t\t\te.printStackTrace();\n\t\t} \n\t\treturn count;\n\t}\n}\n```\n\n### 【BookDAO.java】\n\n```java\npackage com.atguigu.bookstore.dao;\n\nimport java.sql.Connection;\nimport java.util.List;\n\nimport com.atguigu.bookstore.beans.Book;\nimport com.atguigu.bookstore.beans.Page;\n\npublic interface BookDao {\n\n\t/**\n\t * 从数据库中查询出所有的记录\n\t * \n\t * @return\n\t */\n\tList<Book> getBooks(Connection conn);\n\n\t/**\n\t * 向数据库中插入一条记录\n\t * \n\t * @param book\n\t */\n\tvoid saveBook(Connection conn,Book book);\n\n\t/**\n\t * 从数据库中根据图书的id删除一条记录\n\t * \n\t * @param bookId\n\t */\n\tvoid deleteBookById(Connection conn,String bookId);\n\n\t/**\n\t * 根据图书的id从数据库中查询出一条记录\n\t * \n\t * @param bookId\n\t * @return\n\t */\n\tBook getBookById(Connection conn,String bookId);\n\n\t/**\n\t * 根据图书的id从数据库中更新一条记录\n\t * \n\t * @param book\n\t */\n\tvoid updateBook(Connection conn,Book book);\n\n\t/**\n\t * 获取带分页的图书信息\n\t * \n\t * @param page：是只包含了用户输入的pageNo属性的page对象\n\t * @return 返回的Page对象是包含了所有属性的Page对象\n\t */\n\tPage<Book> getPageBooks(Connection conn,Page<Book> page);\n\n\t/**\n\t * 获取带分页和价格范围的图书信息\n\t * \n\t * @param page：是只包含了用户输入的pageNo属性的page对象\n\t * @return 返回的Page对象是包含了所有属性的Page对象\n\t */\n\tPage<Book> getPageBooksByPrice(Connection conn,Page<Book> page, double minPrice, double maxPrice);\n\n}\n```\n\n### 【UserDAO.java】\n\n```java\npackage com.atguigu.bookstore.dao;\n\nimport java.sql.Connection;\n\nimport com.atguigu.bookstore.beans.User;\n\npublic interface UserDao {\n\n\t/**\n\t * 根据User对象中的用户名和密码从数据库中获取一条记录\n\t * \n\t * @param user\n\t * @return User 数据库中有记录 null 数据库中无此记录\n\t */\n\tUser getUser(Connection conn,User user);\n\n\t/**\n\t * 根据User对象中的用户名从数据库中获取一条记录\n\t * \n\t * @param user\n\t * @return true 数据库中有记录 false 数据库中无此记录\n\t */\n\tboolean checkUsername(Connection conn,User user);\n\n\t/**\n\t * 向数据库中插入User对象\n\t * \n\t * @param user\n\t */\n\tvoid saveUser(Connection conn,User user);\n}\n```\n\n### 【BookDaoImpl.java】\n\n```java\npackage com.atguigu.bookstore.dao.impl;\n\nimport java.sql.Connection;\nimport java.util.List;\n\nimport com.atguigu.bookstore.beans.Book;\nimport com.atguigu.bookstore.beans.Page;\nimport com.atguigu.bookstore.dao.BaseDao;\nimport com.atguigu.bookstore.dao.BookDao;\n\npublic class BookDaoImpl extends BaseDao<Book> implements BookDao {\n\n\t@Override\n\tpublic List<Book> getBooks(Connection conn) {\n\t\t// 调用BaseDao中得到一个List的方法\n\t\tList<Book> beanList = null;\n\t\t// 写sql语句\n\t\tString sql = \"select id,title,author,price,sales,stock,img_path imgPath from books\";\n\t\tbeanList = getBeanList(conn,sql);\n\t\treturn beanList;\n\t}\n\n\t@Override\n\tpublic void saveBook(Connection conn,Book book) {\n\t\t// 写sql语句\n\t\tString sql = \"insert into books(title,author,price,sales,stock,img_path) values(?,?,?,?,?,?)\";\n\t\t// 调用BaseDao中通用的增删改的方法\n\t\tupdate(conn,sql, book.getTitle(), book.getAuthor(), book.getPrice(), book.getSales(), book.getStock(),book.getImgPath());\n\t}\n\n\t@Override\n\tpublic void deleteBookById(Connection conn,String bookId) {\n\t\t// 写sql语句\n\t\tString sql = \"DELETE FROM books WHERE id = ?\";\n\t\t// 调用BaseDao中通用增删改的方法\n\t\tupdate(conn,sql, bookId);\n\t\t\t\n\t}\n\n\t@Override\n\tpublic Book getBookById(Connection conn,String bookId) {\n\t\t// 调用BaseDao中获取一个对象的方法\n\t\tBook book = null;\n\t\t// 写sql语句\n\t\tString sql = \"select id,title,author,price,sales,stock,img_path imgPath from books where id = ?\";\n\t\tbook = getBean(conn,sql, bookId);\n\t\treturn book;\n\t}\n\n\t@Override\n\tpublic void updateBook(Connection conn,Book book) {\n\t\t// 写sql语句\n\t\tString sql = \"update books set title = ? , author = ? , price = ? , sales = ? , stock = ? where id = ?\";\n\t\t// 调用BaseDao中通用的增删改的方法\n\t\tupdate(conn,sql, book.getTitle(), book.getAuthor(), book.getPrice(), book.getSales(), book.getStock(), book.getId());\n\t}\n\n\t@Override\n\tpublic Page<Book> getPageBooks(Connection conn,Page<Book> page) {\n\t\t// 获取数据库中图书的总记录数\n\t\tString sql = \"select count(*) from books\";\n\t\t// 调用BaseDao中获取一个单一值的方法\n\t\tlong totalRecord = (long) getValue(conn,sql);\n\t\t// 将总记录数设置都page对象中\n\t\tpage.setTotalRecord((int) totalRecord);\n\n\t\t// 获取当前页中的记录存放的List\n\t\tString sql2 = \"select id,title,author,price,sales,stock,img_path imgPath from books limit ?,?\";\n\t\t// 调用BaseDao中获取一个集合的方法\n\t\tList<Book> beanList = getBeanList(conn,sql2, (page.getPageNo() - 1) * Page.PAGE_SIZE, Page.PAGE_SIZE);\n\t\t// 将这个List设置到page对象中\n\t\tpage.setList(beanList);\n\t\treturn page;\n\t}\n\n\t@Override\n\tpublic Page<Book> getPageBooksByPrice(Connection conn,Page<Book> page, double minPrice, double maxPrice) {\n\t\t// 获取数据库中图书的总记录数\n\t\tString sql = \"select count(*) from books where price between ? and ?\";\n\t\t// 调用BaseDao中获取一个单一值的方法\n\t\tlong totalRecord = (long) getValue(conn,sql,minPrice,maxPrice);\n\t\t// 将总记录数设置都page对象中\n\t\tpage.setTotalRecord((int) totalRecord);\n\n\t\t// 获取当前页中的记录存放的List\n\t\tString sql2 = \"select id,title,author,price,sales,stock,img_path imgPath from books where price between ? and ? limit ?,?\";\n\t\t// 调用BaseDao中获取一个集合的方法\n\t\tList<Book> beanList = getBeanList(conn,sql2, minPrice , maxPrice , (page.getPageNo() - 1) * Page.PAGE_SIZE, Page.PAGE_SIZE);\n\t\t// 将这个List设置到page对象中\n\t\tpage.setList(beanList);\n\t\t\n\t\treturn page;\n\t}\n\n}\n```\n\n### 【UserDaoImpl.java】\n\n```java\npackage com.atguigu.bookstore.dao.impl;\n\nimport java.sql.Connection;\n\nimport com.atguigu.bookstore.beans.User;\nimport com.atguigu.bookstore.dao.BaseDao;\nimport com.atguigu.bookstore.dao.UserDao;\n\npublic class UserDaoImpl extends BaseDao<User> implements UserDao {\n\n\t@Override\n\tpublic User getUser(Connection conn,User user) {\n\t\t// 调用BaseDao中获取一个对象的方法\n\t\tUser bean = null;\n\t\t// 写sql语句\n\t\tString sql = \"select id,username,password,email from users where username = ? and password = ?\";\n\t\tbean = getBean(conn,sql, user.getUsername(), user.getPassword());\n\t\treturn bean;\n\t}\n\n\t@Override\n\tpublic boolean checkUsername(Connection conn,User user) {\n\t\t// 调用BaseDao中获取一个对象的方法\n\t\tUser bean = null;\n\t\t// 写sql语句\n\t\tString sql = \"select id,username,password,email from users where username = ?\";\n\t\tbean = getBean(conn,sql, user.getUsername());\n\t\treturn bean != null;\n\t}\n\n\t@Override\n\tpublic void saveUser(Connection conn,User user) {\n\t\t//写sql语句\n\t\tString sql = \"insert into users(username,password,email) values(?,?,?)\";\n\t\t//调用BaseDao中通用的增删改的方法\n\t\tupdate(conn,sql, user.getUsername(),user.getPassword(),user.getEmail());\n\t}\n\n}\n```\n\n### 【Book.java】\n\n```java\npackage com.atguigu.bookstore.beans;\n/**\n * 图书类\n * @author songhongkang\n *\n */\npublic class Book {\n\n\tprivate Integer id;\n\tprivate String title; // 书名\n\tprivate String author; // 作者\n\tprivate double price; // 价格\n\tprivate Integer sales; // 销量\n\tprivate Integer stock; // 库存\n\tprivate String imgPath = \"static/img/default.jpg\"; // 封面图片的路径\n\t//构造器，get()，set()，toString()方法略\n}\n```\n\n### 【Page.java】\n\n```java\npackage com.atguigu.bookstore.beans;\n\nimport java.util.List;\n/**\n * 页码类\n * @author songhongkang\n *\n */\npublic class Page<T> {\n\n\tprivate List<T> list; // 每页查到的记录存放的集合\n\tpublic static final int PAGE_SIZE = 4; // 每页显示的记录数\n\tprivate int pageNo; // 当前页\n//\tprivate int totalPageNo; // 总页数，通过计算得到\n\tprivate int totalRecord; // 总记录数，通过查询数据库得到\n\n```\n\n### 【User.java】\n\n```java\npackage com.atguigu.bookstore.beans;\n/**\n * 用户类\n * @author songhongkang\n *\n */\npublic class User {\n\n\tprivate Integer id;\n\tprivate String username;\n\tprivate String password;\n\tprivate String email;\n\n```\n\n## 8、数据库连接池\n\n### 8.1 JDBC数据库连接池的必要性\n\n- 在使用开发基于数据库的web程序时，传统的模式基本是按以下步骤：　　\n  - **在主程序（如servlet、beans）中建立数据库连接**\n  - **进行sql操作**\n  - **断开数据库连接**\n\n- 这种模式开发，存在的问题:\n  - 普通的JDBC数据库连接使用 DriverManager 来获取，每次向数据库建立连接的时候都要将 Connection 加载到内存中，再验证用户名和密码(得花费0.05s～1s的时间)。需要数据库连接的时候，就向数据库要求一个，执行完成后再断开连接。这样的方式将会消耗大量的资源和时间。**数据库的连接资源并没有得到很好的重复利用。**若同时有几百人甚至几千人在线，频繁的进行数据库连接操作将占用很多的系统资源，严重的甚至会造成服务器的崩溃。\n  - **对于每一次数据库连接，使用完后都得断开。**否则，如果程序出现异常而未能关闭，将会导致数据库系统中的内存泄漏，最终将导致重启数据库。（回忆：何为Java的内存泄漏？）\n  - **这种开发不能控制被创建的连接对象数**，系统资源会被毫无顾及的分配出去，如连接过多，也可能导致内存泄漏，服务器崩溃。 \n\n### 8.2 数据库连接池技术\n\n- 为解决传统开发中的数据库连接问题，可以采用数据库连接池技术。\n- **数据库连接池的基本思想**：就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。\n\n- **数据库连接池**负责分配、管理和释放数据库连接，它**允许应用程序重复使用一个现有的数据库连接，而不是重新建立一个**。\n- 数据库连接池在初始化时将创建一定数量的数据库连接放到连接池中，这些数据库连接的数量是由**最小数据库连接数来设定**的。无论这些数据库连接是否被使用，连接池都将一直保证至少拥有这么多的连接数量。连接池的**最大数据库连接数量**限定了这个连接池能占有的最大连接数，当应用程序向连接池请求的连接数超过最大连接数量时，这些请求将被加入到等待队列中。\n\n![1555593464033](/images/%E3%80%90MySQL%E3%80%91JDBC/1555593464033.png)\n\n- **工作原理：**\n\n![1555593598606](/images/%E3%80%90MySQL%E3%80%91JDBC/1555593598606.png)\n\n- **数据库连接池技术的优点**\n\n  **1. 资源重用**\n\n  由于数据库连接得以重用，避免了频繁创建，释放连接引起的大量性能开销。在减少系统消耗的基础上，另一方面也增加了系统运行环境的平稳性。\n\n  **2. 更快的系统反应速度**\n\n  数据库连接池在初始化过程中，往往已经创建了若干数据库连接置于连接池中备用。此时连接的初始化工作均已完成。对于业务请求处理而言，直接利用现有可用连接，避免了数据库连接初始化和释放过程的时间开销，从而减少了系统的响应时间\n\n  **3. 新的资源分配手段**\n\n  对于多应用共享同一数据库的系统而言，可在应用层通过数据库连接池的配置，实现某一应用最大可用数据库连接数的限制，避免某一应用独占所有的数据库资源\n\n  **4. 统一的连接管理，避免数据库连接泄漏**\n\n  在较为完善的数据库连接池实现中，可根据预先的占用超时设定，强制回收被占用连接，从而避免了常规数据库连接操作中可能出现的资源泄露\n\n\n### 8.3 多种开源的数据库连接池\n\n- JDBC 的数据库连接池使用 javax.sql.DataSource 来表示，DataSource 只是一个接口，该接口通常由服务器(Weblogic, WebSphere, Tomcat)提供实现，也有一些开源组织提供实现：\n  - **DBCP** 是Apache提供的数据库连接池。tomcat 服务器自带dbcp数据库连接池。**速度相对c3p0较快**，但因自身存在BUG，Hibernate3已不再提供支持。\n  - **C3P0** 是一个开源组织提供的一个数据库连接池，**速度相对较慢，稳定性还可以。**hibernate官方推荐使用\n  - **Proxool** 是sourceforge下的一个开源项目数据库连接池，有监控连接池状态的功能，**稳定性较c3p0差一点**\n  - **BoneCP** 是一个开源组织提供的数据库连接池，速度快\n  - **Druid** 是阿里提供的数据库连接池，据说是集DBCP 、C3P0 、Proxool 优点于一身的数据库连接池，但是速度不确定是否有BoneCP快\n- DataSource 通常被称为数据源，它包含连接池和连接池管理两个部分，习惯上也经常把 DataSource 称为连接池\n- **DataSource用来取代DriverManager来获取Connection，获取速度快，同时可以大幅度提高数据库访问速度。**\n- 特别注意：\n  - 数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此**整个应用只需要一个数据源即可。**\n  - 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但conn.close()并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。\n\n#### 8.3.1 C3P0数据库连接池\n\n- 获取连接方式一\n\n```java\n//使用C3P0数据库连接池的方式，获取数据库的连接：不推荐\npublic static Connection getConnection1() throws Exception{\n\tComboPooledDataSource cpds = new ComboPooledDataSource();\n\tcpds.setDriverClass(\"com.mysql.jdbc.Driver\"); \n\tcpds.setJdbcUrl(\"jdbc:mysql://localhost:3306/test\");\n\tcpds.setUser(\"root\");\n\tcpds.setPassword(\"abc123\");\n\t\t\n//\tcpds.setMaxPoolSize(100);\n\t\n\tConnection conn = cpds.getConnection();\n\treturn conn;\n}\n```\n\n\n\n- 获取连接方式二\n\n```java\n//使用C3P0数据库连接池的配置文件方式，获取数据库的连接：推荐\nprivate static DataSource cpds = new ComboPooledDataSource(\"helloc3p0\");\npublic static Connection getConnection2() throws SQLException{\n\tConnection conn = cpds.getConnection();\n\treturn conn;\n}\n```\n\n其中，src下的配置文件为：【c3p0-config.xml】\n\n```xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<c3p0-config>\n\t<named-config name=\"helloc3p0\">\n\t\t<!-- 获取连接的4个基本信息 -->\n\t\t<property name=\"user\">root</property>\n\t\t<property name=\"password\">abc123</property>\n\t\t<property name=\"jdbcUrl\">jdbc:mysql:///test</property>\n\t\t<property name=\"driverClass\">com.mysql.jdbc.Driver</property>\n\t\t\n\t\t<!-- 涉及到数据库连接池的管理的相关属性的设置 -->\n\t\t<!-- 若数据库中连接数不足时, 一次向数据库服务器申请多少个连接 -->\n\t\t<property name=\"acquireIncrement\">5</property>\n\t\t<!-- 初始化数据库连接池时连接的数量 -->\n\t\t<property name=\"initialPoolSize\">5</property>\n\t\t<!-- 数据库连接池中的最小的数据库连接数 -->\n\t\t<property name=\"minPoolSize\">5</property>\n\t\t<!-- 数据库连接池中的最大的数据库连接数 -->\n\t\t<property name=\"maxPoolSize\">10</property>\n\t\t<!-- C3P0 数据库连接池可以维护的 Statement 的个数 -->\n\t\t<property name=\"maxStatements\">20</property>\n\t\t<!-- 每个连接同时可以使用的 Statement 对象的个数 -->\n\t\t<property name=\"maxStatementsPerConnection\">5</property>\n\n\t</named-config>\n</c3p0-config>\n```\n\n\n\n#### 8.3.2 DBCP数据库连接池\n\n- DBCP 是 Apache 软件基金组织下的开源连接池实现，该连接池依赖该组织下的另一个开源系统：Common-pool。如需使用该连接池实现，应在系统中增加如下两个 jar 文件：\n  - Commons-dbcp.jar：连接池的实现\n  - Commons-pool.jar：连接池实现的依赖库\n- **Tomcat 的连接池正是采用该连接池来实现的。**该数据库连接池既可以与应用服务器整合使用，也可由应用程序独立使用。\n- 数据源和数据库连接不同，数据源无需创建多个，它是产生数据库连接的工厂，因此整个应用只需要一个数据源即可。\n- 当数据库访问结束后，程序还是像以前一样关闭数据库连接：conn.close(); 但上面的代码并没有关闭数据库的物理连接，它仅仅把数据库连接释放，归还给了数据库连接池。\n- 配置属性说明\n\n| 属性                       | 默认值 | 说明                                                         |\n| -------------------------- | ------ | ------------------------------------------------------------ |\n| initialSize                | 0      | 连接池启动时创建的初始化连接数量                             |\n| maxActive                  | 8      | 连接池中可同时连接的最大的连接数                             |\n| maxIdle                    | 8      | 连接池中最大的空闲的连接数，超过的空闲连接将被释放，如果设置为负数表示不限制 |\n| minIdle                    | 0      | 连接池中最小的空闲的连接数，低于这个数量会被创建新的连接。该参数越接近maxIdle，性能越好，因为连接的创建和销毁，都是需要消耗资源的；但是不能太大。 |\n| maxWait                    | 无限制 | 最大等待时间，当没有可用连接时，连接池等待连接释放的最大时间，超过该时间限制会抛出异常，如果设置-1表示无限等待 |\n| poolPreparedStatements     | false  | 开启池的Statement是否prepared                                |\n| maxOpenPreparedStatements  | 无限制 | 开启池的prepared 后的同时最大连接数                          |\n| minEvictableIdleTimeMillis |        | 连接池中连接，在时间段内一直空闲， 被逐出连接池的时间        |\n| removeAbandonedTimeout     | 300    | 超过时间限制，回收没有用(废弃)的连接                         |\n| removeAbandoned            | false  | 超过removeAbandonedTimeout时间后，是否进 行没用连接（废弃）的回收 |\n\n\n\n- 获取连接方式一：\n\n```java\npublic static Connection getConnection3() throws Exception {\n\tBasicDataSource source = new BasicDataSource();\n\t\t\n\tsource.setDriverClassName(\"com.mysql.jdbc.Driver\");\n\tsource.setUrl(\"jdbc:mysql:///test\");\n\tsource.setUsername(\"root\");\n\tsource.setPassword(\"abc123\");\n\t\t\n\t//\n\tsource.setInitialSize(10);\n\t\t\n\tConnection conn = source.getConnection();\n\treturn conn;\n}\n```\n\n- 获取连接方式二：\n\n```java\n//使用dbcp数据库连接池的配置文件方式，获取数据库的连接：推荐\nprivate static DataSource source = null;\nstatic{\n\ttry {\n\t\tProperties pros = new Properties();\n\t\t\n\t\tInputStream is = DBCPTest.class.getClassLoader().getResourceAsStream(\"dbcp.properties\");\n\t\t\t\n\t\tpros.load(is);\n\t\t//根据提供的BasicDataSourceFactory创建对应的DataSource对象\n\t\tsource = BasicDataSourceFactory.createDataSource(pros);\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\t\t\n}\npublic static Connection getConnection4() throws Exception {\n\t\t\n\tConnection conn = source.getConnection();\n\t\n\treturn conn;\n}\n```\n\n其中，src下的配置文件为：【dbcp.properties】\n\n```properties\ndriverClassName=com.mysql.jdbc.Driver\nurl=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true&useServerPrepStmts=false\nusername=root\npassword=abc123\n\ninitialSize=10\n#...\n```\n\n\n\n#### 8.3.3 Druid（德鲁伊）数据库连接池\n\nDruid是阿里巴巴开源平台上一个数据库连接池实现，它结合了C3P0、DBCP、Proxool等DB池的优点，同时加入了日志监控，可以很好的监控DB池连接和SQL的执行情况，可以说是针对监控而生的DB连接池，**可以说是目前最好的连接池之一。**\n\n```java\npackage com.atguigu.druid;\n\nimport java.sql.Connection;\nimport java.util.Properties;\n\nimport javax.sql.DataSource;\n\nimport com.alibaba.druid.pool.DruidDataSourceFactory;\n\npublic class TestDruid {\n\tpublic static void main(String[] args) throws Exception {\n\t\tProperties pro = new Properties();\t\t pro.load(TestDruid.class.getClassLoader().getResourceAsStream(\"druid.properties\"));\n\t\tDataSource ds = DruidDataSourceFactory.createDataSource(pro);\n\t\tConnection conn = ds.getConnection();\n\t\tSystem.out.println(conn);\n\t}\n}\n\n```\n\n其中，src下的配置文件为：【druid.properties】\n\n```java\nurl=jdbc:mysql://localhost:3306/test?rewriteBatchedStatements=true\nusername=root\npassword=123456\ndriverClassName=com.mysql.jdbc.Driver\n\ninitialSize=10\nmaxActive=20\nmaxWait=1000\nfilters=wall\n```\n\n- 详细配置参数：\n\n| **配置**                      | **缺省** | **说明**                                                     |\n| ----------------------------- | -------- | ------------------------------------------------------------ |\n| name                          |          | 配置这个属性的意义在于，如果存在多个数据源，监控的时候可以通过名字来区分开来。   如果没有配置，将会生成一个名字，格式是：”DataSource-” +   System.identityHashCode(this) |\n| url                           |          | 连接数据库的url，不同数据库不一样。例如：mysql :   jdbc:mysql://10.20.153.104:3306/druid2      oracle :   jdbc:oracle:thin:@10.20.149.85:1521:ocnauto |\n| username                      |          | 连接数据库的用户名                                           |\n| password                      |          | 连接数据库的密码。如果你不希望密码直接写在配置文件中，可以使用ConfigFilter。详细看这里：<https://github.com/alibaba/druid/wiki/%E4%BD%BF%E7%94%A8ConfigFilter> |\n| driverClassName               |          | 根据url自动识别   这一项可配可不配，如果不配置druid会根据url自动识别dbType，然后选择相应的driverClassName(建议配置下) |\n| initialSize                   | 0        | 初始化时建立物理连接的个数。初始化发生在显示调用init方法，或者第一次getConnection时 |\n| maxActive                     | 8        | 最大连接池数量                                               |\n| maxIdle                       | 8        | 已经不再使用，配置了也没效果                                 |\n| minIdle                       |          | 最小连接池数量                                               |\n| maxWait                       |          | 获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。 |\n| poolPreparedStatements        | false    | 是否缓存preparedStatement，也就是PSCache。PSCache对支持游标的数据库性能提升巨大，比如说oracle。在mysql下建议关闭。 |\n| maxOpenPreparedStatements     | -1       | 要启用PSCache，必须配置大于0，当大于0时，poolPreparedStatements自动触发修改为true。在Druid中，不会存在Oracle下PSCache占用内存过多的问题，可以把这个数值配置大一些，比如说100 |\n| validationQuery               |          | 用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。 |\n| testOnBorrow                  | true     | 申请连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能。 |\n| testOnReturn                  | false    | 归还连接时执行validationQuery检测连接是否有效，做了这个配置会降低性能 |\n| testWhileIdle                 | false    | 建议配置为true，不影响性能，并且保证安全性。申请连接的时候检测，如果空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效。 |\n| timeBetweenEvictionRunsMillis |          | 有两个含义： 1)Destroy线程会检测连接的间隔时间2)testWhileIdle的判断依据，详细看testWhileIdle属性的说明 |\n| numTestsPerEvictionRun        |          | 不再使用，一个DruidDataSource只支持一个EvictionRun           |\n| minEvictableIdleTimeMillis    |          |                                                              |\n| connectionInitSqls            |          | 物理连接初始化的时候执行的sql                                |\n| exceptionSorter               |          | 根据dbType自动识别   当数据库抛出一些不可恢复的异常时，抛弃连接 |\n| filters                       |          | 属性类型是字符串，通过别名的方式配置扩展插件，常用的插件有：   监控统计用的filter:stat日志用的filter:log4j防御sql注入的filter:wall |\n| proxyFilters                  |          | 类型是List，如果同时配置了filters和proxyFilters，是组合关系，并非替换关系 |\n\n\n\n## 9、Apache-DBUtils实现CRUD操作\n\n### 9.1 Apache-DBUtils简介\n\n- commons-dbutils 是 Apache 组织提供的一个开源 JDBC工具类库，它是对JDBC的简单封装，学习成本极低，并且使用dbutils能极大简化jdbc编码的工作量，同时也不会影响程序的性能。\n\n- API介绍：\n  - org.apache.commons.dbutils.QueryRunner\n  - org.apache.commons.dbutils.ResultSetHandler\n  - 工具类：org.apache.commons.dbutils.DbUtils   \n- API包说明：\n\n![1555595163263](/images/%E3%80%90MySQL%E3%80%91JDBC/1555595163263.png)\n\n![1555595198644](/images/%E3%80%90MySQL%E3%80%91JDBC/1555595198644.png)\n\n\n\n\n\n### 9.2 主要API的使用\n\n#### 9.2.1 DbUtils\n\n- DbUtils ：提供如关闭连接、装载JDBC驱动程序等常规工作的工具类，里面的所有方法都是静态的。主要方法如下：\n  - **public static void close(…) throws java.sql.SQLException**：　DbUtils类提供了三个重载的关闭方法。这些方法检查所提供的参数是不是NULL，如果不是的话，它们就关闭Connection、Statement和ResultSet。\n  - public static void closeQuietly(…): 这一类方法不仅能在Connection、Statement和ResultSet为NULL情况下避免关闭，还能隐藏一些在程序中抛出的SQLEeception。\n  - public static void commitAndClose(Connection conn)throws SQLException： 用来提交连接的事务，然后关闭连接\n  - public static void commitAndCloseQuietly(Connection conn)： 用来提交连接，然后关闭连接，并且在关闭连接时不抛出SQL异常。 \n  - public static void rollback(Connection conn)throws SQLException：允许conn为null，因为方法内部做了判断\n  - public static void rollbackAndClose(Connection conn)throws SQLException\n  - rollbackAndCloseQuietly(Connection)\n  - public static boolean loadDriver(java.lang.String driverClassName)：这一方装载并注册JDBC驱动程序，如果成功就返回true。使用该方法，你不需要捕捉这个异常ClassNotFoundException。\n\n#### 9.2.2 QueryRunner类\n\n- **该类简单化了SQL查询，它与ResultSetHandler组合在一起使用可以完成大部分的数据库操作，能够大大减少编码量。**\n\n- QueryRunner类提供了两个构造器：\n  - 默认的构造器\n  - 需要一个 javax.sql.DataSource 来作参数的构造器\n\n- QueryRunner类的主要方法：\n  - **更新**\n    - public int update(Connection conn, String sql, Object... params) throws SQLException:用来执行一个更新（插入、更新或删除）操作。\n    - ......\n  - **插入**\n    - public <T> T insert(Connection conn,String sql,ResultSetHandler<T> rsh, Object... params) throws SQLException：只支持INSERT语句，其中 rsh - The handler used to create the result object from the ResultSet of auto-generated keys.  返回值: An object generated by the handler.即自动生成的键值\n    - ....\n  - **批处理**\n    - public int[] batch(Connection conn,String sql,Object[][] params)throws SQLException： INSERT, UPDATE, or DELETE语句\n    - public <T> T insertBatch(Connection conn,String sql,ResultSetHandler<T> rsh,Object[][] params)throws SQLException：只支持INSERT语句\n    - .....\n  - **查询**\n    - public Object query(Connection conn, String sql, ResultSetHandler rsh,Object... params) throws SQLException：执行一个查询操作，在这个查询中，对象数组中的每个元素值被用来作为查询语句的置换参数。该方法会自行处理 PreparedStatement 和 ResultSet 的创建和关闭。\n    - ...... \n\n- 测试\n\n```java\n// 测试添加\n@Test\npublic void testInsert() throws Exception {\n\tQueryRunner runner = new QueryRunner();\n\tConnection conn = JDBCUtils.getConnection3();\n\tString sql = \"insert into customers(name,email,birth)values(?,?,?)\";\n\tint count = runner.update(conn, sql, \"何成飞\", \"he@qq.com\", \"1992-09-08\");\n\n\tSystem.out.println(\"添加了\" + count + \"条记录\");\n\t\t\n\tJDBCUtils.closeResource(conn, null);\n\n}\n```\n\n```java\n// 测试删除\n@Test\npublic void testDelete() throws Exception {\n\tQueryRunner runner = new QueryRunner();\n\tConnection conn = JDBCUtils.getConnection3();\n\tString sql = \"delete from customers where id < ?\";\n\tint count = runner.update(conn, sql,3);\n\n\tSystem.out.println(\"删除了\" + count + \"条记录\");\n\t\t\n\tJDBCUtils.closeResource(conn, null);\n\n}\n```\n\n\n\n#### 9.2.3 ResultSetHandler接口及实现类\n\n- 该接口用于处理 java.sql.ResultSet，将数据按要求转换为另一种形式。\n\n- ResultSetHandler 接口提供了一个单独的方法：Object handle (java.sql.ResultSet .rs)。\n\n- 接口的主要实现类：\n\n  - ArrayHandler：把结果集中的第一行数据转成对象数组。\n\n  - ArrayListHandler：把结果集中的每一行数据都转成一个数组，再存放到List中。\n\n  - **BeanHandler：**将结果集中的第一行数据封装到一个对应的JavaBean实例中。\n\n  - **BeanListHandler：**将结果集中的每一行数据都封装到一个对应的JavaBean实例中，存放到List里。\n\n  - ColumnListHandler：将结果集中某一列的数据存放到List中。\n\n  - KeyedHandler(name)：将结果集中的每一行数据都封装到一个Map里，再把这些map再存到一个map里，其key为指定的key。\n\n  - **MapHandler：**将结果集中的第一行数据封装到一个Map里，key是列名，value就是对应的值。\n\n  - **MapListHandler：**将结果集中的每一行数据都封装到一个Map里，然后再存放到List\n\n  - **ScalarHandler：**查询单个值对象\n\n    \n\n- 测试\n\n```java\n/*\n * 测试查询:查询一条记录\n * \n * 使用ResultSetHandler的实现类：BeanHandler\n */\n@Test\npublic void testQueryInstance() throws Exception{\n\tQueryRunner runner = new QueryRunner();\n\n\tConnection conn = JDBCUtils.getConnection3();\n\t\t\n\tString sql = \"select id,name,email,birth from customers where id = ?\";\n\t\t\n\t//\n\tBeanHandler<Customer> handler = new BeanHandler<>(Customer.class);\n\tCustomer customer = runner.query(conn, sql, handler, 23);\n\tSystem.out.println(customer);\t\n\tJDBCUtils.closeResource(conn, null);\n}\n```\n\n```java\n/*\n * 测试查询:查询多条记录构成的集合\n * \n * 使用ResultSetHandler的实现类：BeanListHandler\n */\n@Test\npublic void testQueryList() throws Exception{\n\tQueryRunner runner = new QueryRunner();\n\n\tConnection conn = JDBCUtils.getConnection3();\n\t\t\n\tString sql = \"select id,name,email,birth from customers where id < ?\";\n\t\t\n\t//\n\tBeanListHandler<Customer> handler = new BeanListHandler<>(Customer.class);\n\tList<Customer> list = runner.query(conn, sql, handler, 23);\n\tlist.forEach(System.out::println);\n\t\t\n\tJDBCUtils.closeResource(conn, null);\n}\n```\n\n```java\n/*\n * 自定义ResultSetHandler的实现类\n */\n@Test\npublic void testQueryInstance1() throws Exception{\n\tQueryRunner runner = new QueryRunner();\n\n\tConnection conn = JDBCUtils.getConnection3();\n\t\t\n\tString sql = \"select id,name,email,birth from customers where id = ?\";\n\t\t\n\tResultSetHandler<Customer> handler = new ResultSetHandler<Customer>() {\n\n\t\t@Override\n\t\tpublic Customer handle(ResultSet rs) throws SQLException {\n\t\t\tSystem.out.println(\"handle\");\n//\t\t\treturn new Customer(1,\"Tom\",\"tom@126.com\",new Date(123323432L));\n\t\t\t\t\n\t\t\tif(rs.next()){\n\t\t\t\tint id = rs.getInt(\"id\");\n\t\t\t\tString name = rs.getString(\"name\");\n\t\t\t\tString email = rs.getString(\"email\");\n\t\t\t\tDate birth = rs.getDate(\"birth\");\n\t\t\t\t\t\n\t\t\t\treturn new Customer(id, name, email, birth);\n\t\t\t}\n\t\t\treturn null;\n\t\t\t\t\n\t\t}\n\t};\n\t\t\n\tCustomer customer = runner.query(conn, sql, handler, 23);\n\t\t\n\tSystem.out.println(customer);\n\t\t\n\tJDBCUtils.closeResource(conn, null);\n}\n```\n\n```java\n/*\n * 如何查询类似于最大的，最小的，平均的，总和，个数相关的数据，\n * 使用ScalarHandler\n * \n */\n@Test\npublic void testQueryValue() throws Exception{\n\tQueryRunner runner = new QueryRunner();\n\n\tConnection conn = JDBCUtils.getConnection3();\n\t\t\n\t//测试一：\n//\tString sql = \"select count(*) from customers where id < ?\";\n//\tScalarHandler handler = new ScalarHandler();\n//\tlong count = (long) runner.query(conn, sql, handler, 20);\n//\tSystem.out.println(count);\n\t\t\n\t//测试二：\n\tString sql = \"select max(birth) from customers\";\n\tScalarHandler handler = new ScalarHandler();\n\tDate birth = (Date) runner.query(conn, sql, handler);\n\tSystem.out.println(birth);\n\t\t\n\tJDBCUtils.closeResource(conn, null);\n}\n```\n\n## JDBC总结\n\n```java\n总结\n@Test\npublic void testUpdateWithTx() {\n\t\t\n\tConnection conn = null;\n\ttry {\n\t\t//1.获取连接的操作（\n\t\t//① 手写的连接：JDBCUtils.getConnection();\n\t\t//② 使用数据库连接池：C3P0;DBCP;Druid\n\t\t//2.对数据表进行一系列CRUD操作\n\t\t//① 使用PreparedStatement实现通用的增删改、查询操作（version 1.0 \\ version 2.0)\n//version2.0的增删改public void update(Connection conn,String sql,Object ... args){}\n//version2.0的查询 public <T> T getInstance(Connection conn,Class<T> clazz,String sql,Object ... args){}\n\t\t//② 使用dbutils提供的jar包中提供的QueryRunner类\n\t\t\t\n\t\t//提交数据\n\t\tconn.commit();\n\t\t\t\n\t\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\t\t\n\t\t\t\n\t\ttry {\n\t\t\t//回滚数据\n\t\t\tconn.rollback();\n\t\t} catch (SQLException e1) {\n\t\t\te1.printStackTrace();\n\t\t}\n\t\t\t\n\t}finally{\n\t\t//3.关闭连接等操作\n\t\t//① JDBCUtils.closeResource();\n\t\t//② 使用dbutils提供的jar包中提供的DbUtils类提供了关闭的相关操作\n\t\t\t\n\t}\n}\n```\n\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"【MySQL】MySQL 基础","url":"/2021/03/29/【MySQL】MySQL基础/","content":"\n![image-20210913132511709](/images/%E3%80%90MySQL%E3%80%91MySQL%E5%9F%BA%E7%A1%80/image-20210913132511709.png)\n\n## 1. 初识 MySQL\n\n- **DB**：DataBase，数据库，实际上在硬盘上以文件的形式存在     \n- **SQL**：Structured Query Language，结构化查询语言，是一门标准通用的语言，标准sql适用于所有的数据库产品，SQL语句在执行时，内部会先进行编译，然后再执行。（SQL语句的编译由DBMS完成）\n- **DBMS**： DataBase Management System，数据库管理系统，如MySQL，Oracle，DB2等，用来管理DB（用来管理数据库中的数据）\n\n**DBMS负责执行sql语句，其通过执行sql语句来操作DB中的数据。**\n\n### 1.1 启动 MySQL 服务\n\n命令行启动MySQL服务（管理员模式）\n\n``` bash\nnet start mysql\n```\n\n### 1.2 连接数据库\n\n命令行连接数据库（管理员模式）\n\n``` sql\nmysql -u root -p xxxxx  -- 连接数据库\n```\n\n### 1.3 SQL 命令\n\n更改用户密码并刷新权限（sql语句需要以;结尾）\n\n``` sql\nUPDATE mysql.user SET authentication_string=password('123456')\nWHERE user='root' AND Host='localhost'; -- 更改用户密码\n\nFLUSH PRIVILEGES; -- 刷新权限\n```\n\n<!-- more -->\n\n基本命令\n\n```sql\nSHOW DATABASES; -- 查询所有数据库\nUSE xxx; -- 切换数据库 use 数据库名\n\nSHOW TABLES; -- 查看数据库中所有的表\nDESCRIBE student; -- 显示数据库中所有的表的信息\n\nCREATE DATABASE westos; -- 创建一个数据库\n\nEXIT; -- 退出连接\n\n-- 单行注释\n/* 多行注释\nhello \nMySQL\n*/\n```\n\n### 1.4 数据库语言分类\n\n- **DDL： Database Definition Language** 数据库定义语言。用于对**表的结构**进行增删改：CREATE  DROP ALTER\n- **DML：Data Manipulation Language**  数据库操纵语言。用于对**表的数据**进行增删改：INSERT DELETE UPDATE \n- **DQL：Data Query Language** 数据库查询语言。用于查询表中的数据，基本结构是由SELECT子句，FROM子句，WHERE子句组成的查询块：\n- **DCL：Data Control Language** 数据库控制语言。用来授予或回收访问数据库的某种特权：GRANT REVOKE \n- **TCL：Transaction Control Language** 事务控制语言。控制数据库操纵事务发生的时间及效果，对数据库实行监视等：COMMIT ROLLBACK\n\n## 2. 数据库基础\n\n### 2.1 操作数据库\n\n操作数据库 ——> 操作数据库中的表 ——> 操作数据库中表的数据\n\n==**MySQL关键字不区分大小写**==\n\n以下关键字属于MySQL命令，并非SQL语句，只有在MySQL中才能使用\n\n1. 创建数据库\n\n``` sql\nCREATE DATABASE [IF NOT EXISTS] school;\n```\n\n2. 删除数据库\n\n``` sql\nDROP DATABASE [IF EXISTS] school;\n```\n\n3. 使用数据库\n\n``` sql\n-- 如果表名或者字符段名是一个特殊字符，需要带上 ` `\nUSE `school`;\n```\n\n4. 查看数据库\n\n``` sql\nSHOW DATABASES;  -- 查看所有数据库\n```\n\n### 2.2 数据库的列类型\n\n> 数值\n\n- tinyint：\t   十分小的数据 ，        1个字节\n- smallint：     较小的数据  ，           2个字节\n- mediumint：中等大小的数据，     3个字节\n- **int：              标准的整数 ，          4个字节**\n- bigint：          较大的数据 ，            8个字节\n- float：            浮点数，                     4个字节\n- double：        浮点数，                     8个字节\n- decimal：      字符串形式的浮点数，  金融计算时，一般使用decimal\n\n其中浮点型数据创建时可以指定保留位数。例如double(M, D)代表小数点后保留D位小数，M代表整数部位+小数部位的总长度，如果超出范围，则插入临界值。M和D可以省略，如果是decimal，则默认M=10，D=0；如果是float和double，则会根据插入的数值的精度来决定精度。\n\n> 字符串\n\n- char：       **固定大小**字符串 0~255（在内存中分配固定长度存储数据）\n- **varchar： 可变长度字符串 0~65535，类比Java中String（按照实际字符串大小在内存中分配空间）**  \n- tinytext： 微型文本  2^8 - 1\n- text：        文本串     2 ^16 - 1  保存大文本\n\nchar(M)表示最大长度不能超过M，其中M可以省略，默认为1；**varchar(M)的M不可以省略**。\n\n> 时间日期\n\n类比java.util.Date\n\n- date：  YYYY-MM-DD    日期格式\n- time ：  HH:mm::ss         时间格式\n- **datetime：    YYYY-MM-DD HH:mm::ss     最常用的时间格式**\n- **timestamp：  时间戳，1970.01.01到现在的毫秒数**\n- year： 年份表示\n\n> 大对象\n\n- BLOB：Binary Large Object 二进制大对象（存储图片、视频等流媒体信息）对应Java中的Object\n- CLOB：Character Large Object 字符大对象（存储较大文本，比如可以存储4G的字符串）对应Java中的Object\n\n> NULL\n\n- 没有值，未知\n- ==**注意，不要使用NULL进行运算，NULL和任何数参与运算，计算结果都为NULL**==\n- 想避免NULL对运算结果产生影响，则使用`IFNULL`空处理函数：`IFNULL(XXX, 0)`\n\n### 2.3 存储引擎\n\n> **存储引擎是对一张表而言**，而非对数据库而言，不同的表可以有不同的存储引擎（可以在 CREATE 语句中指定存储引擎类型）\n\n存储引擎即一张表在数据库中的存储方式。\n\n|              | MyISAM                 | InnoDB                         |\n| ------------ | ---------------------- | ------------------------------ |\n| 事务支持     | 不支持（最新版支持）   | 支持                           |\n| 数据行表锁   | 不支持行锁，只支持表锁 | 支持行锁                       |\n| 外键约束     | 不支持                 | 支持                           |\n| 全文索引     | 支持                   | 不支持（最新版支持）           |\n| 表空间的大小 | 较小                   | 较大，约为2倍                  |\n| 缓存         | 只缓存索引             | 不仅缓存索引，还要缓存真实数据 |\n| 关注点       | 性能                   | 事务                           |\n\n- **MyISAM**：**可被转换为压缩、只读表来节省空间**。节约空间，速度较快\n- **InnoDB**：安全性高，支持**事务**的处理，多表多用户操作，在MySQL服务器**崩溃后提供自动恢复**，支持级联删除和更新\n- **MEMORY**：查询速度**最快**，**表数据和索引**被存储在**内存**中，不支持事务，数据容易丢失。不能包含TEXT或BLOB字段\n\n> 在物理空间存在的位置\n\n所有数据库文件都存在data目录下，一个文件夹就是一个数据库，本质还是文件的存储。MySQL引擎在物理文件上的区别：\n\n- InnoDB：\n  - `*.frm`  表结构的定义文件\n  - `*.ibd` 数据和索引共同存储在一个文件中\n- MyISAM：\n  - `*.frm`  表结构的定义文件\n  - `*.MYD` 数据文件（data）\n  - `*.MYI`  索引文件（index）\n\n> 其中，InnDB 采用聚集（聚数）索引（索引和真实数据存储在一起），MyISAM 采用非聚集（稀疏）索引（索引和真实数据分开存储），这才导致了二者在磁盘上存储文件类型的区别。\n\n三种存储引擎的适用条件：\n\n- MyISAM：适用于大量的数据读而少量数据更新的混合操作，另一种适用情形是使用压缩的只读表\n- InnoDB：适用于查询中包含较多的数据更新操作，其行级锁机制和多版本的支持为数据读取和更新的混合操作提供了良好的并发机制\n- MEMORY：适用于存储非永久需要的数据，或者是能够从基于磁盘的表中重新生成的数据\n\n### 2.4 数据表的类型\n\n> 设置数据库表的字符集编码\n\n``` sql\nCHARSET=utf8\n```\n\n不设置的话，会是MySQL默认的字符集编码Latin1（不支持中文）。\n\n可以在my.ini中配置默认的编码：\n\n``` sql\ncharacter-set-server=utf8\n```\n\n### 2.5 约束\n\n在创建表时，可以给表的字段添加相应的约束，从而保证表中数据的合法性、有效性和完整性。\n\n- 非空约束（NOT NULL）：约束的字段不能为NULL\n- 唯一约束（UNIQUE）：约束的字段不能重复\n- 主键约束（PRIMARY KEY）：约束的字段既不能为NULL，也不能重复（简称PK）\n- 外键约束（FOREIGN KEY)：用于限制两个表的关系，约束的字段的值必须来自于主表的关联列的值（简称FK）\n- 无符号约束（UNSIGNED）：约束该字段为无符号\n- 零填充约束（ZEROFILL）：限制该字段0填充\n- 自增约束（AUTO_INCREMENT）：限制该字段自增\n- 默认值约束（DEFAULT）：设置该字段的默认值\n\n> 唯一性约束（UNIQUE）\n\n**UNIQUE**：唯一性约束修饰的字段具有唯一性，不能重复，但可以设置为NULL。\n\n若给两列同时加UNIQUE，则为表级约束，联合起来不重复即可。若在列后面直接加UNIQUE，则为列级约束，该列数据不能有重复。\n\n> 主键（PRIMARY KEY）\n\n**PRIMARY KEY**：主键值是这行数据在这张表中的唯一标识（第一范式要求每张表必须有主键）。\n\n一张表的主键约束只能有一个，可以是单一主键（推荐）或复合主键（不推荐，违反三范式）。主键值最好是和业务没有关系的自然数。在字段后添加AUTO_INCREMENT设置主键值自增\n\n>  外键（FOREIGN KEY）\n\n**FOREIGN KEY**：用于减少表的冗余，将一张表拆成两张表。\n\n外键引用的父表的字段必须是唯一的（UNIQUE），一般情况都是子表外键引用父表主键\n\n> 无符号约束（UNSIGNED）\n\n- 无符号的整数\n- 声明了该列不能声明为负数\n\n>  零填充约束（ZEROFILL）\n\n- 0填充的\n- 不足的位数，使用0填充。zerofill设置为3时，5——005\n\n>  自增约束（AUTO_INCREMENT）\n\n- 自动在上一条记录的基础上+1（默认）\n- 通常用来设计唯一的主键，例如Index，必须是整数类型\n- 可以自定义设置主键自增的起始值和步长\n\n> 默认值约束（DEFAULT）\n\n- 设置默认的值\n- 例如若sex设置默认值为男，如果不指定该列的值，则会设置为默认值\n\n增加外键约束的方式：\n\n> 方式一：在创建表的时候，增加约束（比较麻烦）\n\n``` sql\nCREATE TABLE `grade`(\n\t`gradeid` INT(10) NOT NULL AUTO_INCREMENT COMMENT '年级id',\n\t`gradename` VARCHAR(50) NOT NULL COMMENT '年级名称',\n\tPRIMARY KEY (`gradeid`)\n)ENGINE=INNODB DEFAULT CHARSET=utf8;\n\n-- 学生表的gradeid字段要去引用年级表的gradeid\n-- 定义外键KEY\n-- 给这个外键添加约束（执行引用） reference 引用\nCREATE TABLE IF NOT EXISTS `student`(\n\t`id` INT(4) NOT NULL AUTO_INCREMENT  COMMENT '学号',\n\t`name` VARCHAR(30) NOT NULL DEFAULT '匿名' COMMENT '姓名',\n\t`pwd` VARCHAR(20) NOT NULL DEFAULT '123456' COMMENT '密码',\n\t`sex` VARCHAR(2) NOT NULL DEFAULT '女' COMMENT '性别',\n\t`birthday` DATETIME DEFAULT NULL COMMENT '出生日期',\n\t`gradeid` INT(10) NOT NULL COMMENT '学生年级',\n\t`address` VARCHAR(100) DEFAULT NULL COMMENT '家庭住址',\n\t`email` VARCHAR(50) DEFAULT NULL COMMENT '邮箱',\n\t CONSTRAINT pk PRIMARY KEY(`id`), \n     CONSTRAINT uq UNIQUE(`name`), \n\t KEY `FK_gradeid`(`gradeid`),\n\t CONSTRAINT `FK_gradid` FOREIGN KEY (`gradeid`) REFERENCES `grade`(`gradeid`)\n)ENGINE=INNODB DEFAULT CHARSET=utf8;\n```\n\n删除有外键关系的表时，必须先删除引用别人的表（从表），再删除被引用的表（主表）\n\n> 方式二：创建表成功后，添加外键约束\n\n``` sql\nCREATE TABLE `grade`(\n\t`gradeid` INT(10) NOT NULL AUTO_INCREMENT COMMENT '年级id',\n\t`gradename` VARCHAR(50) NOT NULL COMMENT '年级名称',\n\tPRIMARY KEY (`gradeid`)\n)ENGINE=INNODB DEFAULT CHARSET=utf8;\n\nCREATE TABLE IF NOT EXISTS `student`(\n\t`id` INT(4) NOT NULL AUTO_INCREMENT  COMMENT '学号',\n\t`name` VARCHAR(30) NOT NULL DEFAULT '匿名' COMMENT '姓名',\n\t`pwd` VARCHAR(20) NOT NULL DEFAULT '123456' COMMENT '密码',\n\t`sex` VARCHAR(2) NOT NULL DEFAULT '女' COMMENT '性别',\n\t`birthday` DATETIME DEFAULT NULL COMMENT '出生日期',\n\t`gradeid` INT(10) NOT NULL COMMENT '学生年级',\n\t`address` VARCHAR(100) DEFAULT NULL COMMENT '家庭住址',\n\t`email` VARCHAR(50) DEFAULT NULL COMMENT '邮箱',\n\tPRIMARY KEY(`id`)\n)ENGINE=INNODB DEFAULT CHARSET=utf8;\n\n-- ALTER TABLE 表 ADD CONSTRAINT 约束名 FOREIGN KEY(作为外键的列) REFERENCES 哪个表（哪个字段)\nALTER TABLE `student` ADD CONSTRAINT `FK_gradeid` FOREIGN KEY(`gradeid`) REFERENCES `grade`(`gradeid`);\n```\n\n以上操作都是``物理外键``，数据库级别的外键，不建议使用（避免数据库过多造成困扰）\n\n- 数据库就是单纯的表，只用来存数据，只有行（数据）和列（字段）\n- 想使用多张表的数据，想使用外键时，使用程序实现\n\n**主键约束（PRIMARY KEY）和唯一约束（UNIQUE）对比：**\n\n|              | 保证唯一性 | 是否允许为空 | 一个表可以有几个 | 是否允许组合 |\n| ------------ | ---------- | ------------ | ---------------- | ------------ |\n| **主键约束** | √          | ×            | 最多有一个       | √            |\n| **唯一约束** | √          | √            | 可以有多个       | √            |\n\n**列级约束和表级约束对比**\n\n|              | 位置         | 支持的约束类型                 | 是否可以起约束名     |\n| ------------ | ------------ | ------------------------------ | -------------------- |\n| **列级约束** | 列的后面     | 语法都支持，但外键没有效果     | 不可以               |\n| **表级约束** | 所有列的下面 | 默认和非空约束不支持，其他支持 | 可以（主键没有效果） |\n\n\n\n## 3.  数据库定义语言（DDL）\n\n### 3.1 创建表（CREATE）\n\n```sql\n-- 注意点 英文括号()，表的名称和字段尽量使用``\n-- 字符串使用单引号''括起来\n-- 所有语句后面加,（最后一句不用加）\n-- PRIMAY KEY 一张表的主键约束只能有一个。单一主键或复合主键（不推荐，因为违反三范式）\nCREATE TABLE IF NOT EXISTS `student`(\n\t`id` INT(4) UNSIGNED NOT NULL AUTO_INCREMENT  COMMENT '学号',\n\t`name` VARCHAR(30) NOT NULL DEFAULT '匿名' COMMENT '姓名',\n\t`pwd` VARCHAR(20) NOT NULL DEFAULT '123456' COMMENT '密码',\n\t`sex` VARCHAR(2) NOT NULL DEFAULT '女' COMMENT '性别',\n\t`birthday` DATETIME DEFAULT NULL COMMENT '出生日期',\n\t`address` VARCHAR(100) DEFAULT NULL COMMENT '家庭住址',\n\t`email` VARCHAR(50) DEFAULT NULL COMMENT '邮箱',\n\tPRIMARY KEY(`id`)\n)ENGINE=INNODB DEFAULT CHARSET=utf8;\n```\n\n一般格式：\n\n```  sql\nCREATE TABLE [IF NOT EXISTS] `表名`(\n    `字段名` 列类型 [约束] [索引] [注释],\n    `字段名` 列类型 [约束] [索引] [注释],\n    ...\n    `字段名` 列类型 [约束] [索引] [注释],\n    PRIMARY KEY(`字段名`)\n)[表类型][注释][字符集设置];\n```\n\n约束位置处可以添加：\n\n- `UNSIGNED`：限制该字段为无符号\n- `ZEROFILL`：该字段0填充\n- `AUTO_INCREMENT`：该字段自增\n- `DEFAULT` ：设置该字段的默认值\n- `NOT NULL`：限制该字段不能为NULL\n- `UNIQUE`：限制该字段不能重复\n- `PRIMARY KEY`：约束该字段既不能为NULL，也不能重复\n- `FOREIGN KEY`：约束该字段的值必须来自于主表的关联列的值（外键约束在列级约束处无效果）\n\n常用命令：\n\n``` sql\nSHOW CREATE DATABASE `school`; -- 查看创建数据库的语句\nSHOW CREATE TABLE `student`;   -- 查看创建student数据表的语句，使用Navicat生成表后，可以使用该命令查看创建表的语句\nDESC `student`;                -- 显示表的结构\n```\n\n复制表：\n\n``` sql\n-- 复制表的结构+数据\nCREATE TABLE `student_2`\nSELECT * FROM `student`;\n\n-- 只复制表的结构\nCREATE TABLE `student_2` LIKE `student`;\n```\n\n### 3.2 修改表（ALTER）\n\n> 修改表的结构\n\n``` sql\n-- 修改表名：ALTER TABLE 旧表名 RENAME AS 新表名\nALTER TABLE test RENAME AS teacher1;\n\n-- 增加表的字段：ALTER TABLE 表名 ADD 字段名 列属性\nALTER TABLE teacher1 ADD age INT(11);\n\n-- 修改表的字段（修改字段类型以及约束，字段重命名）\n-- ALTER TABLE 表名 MODIFY 字段名 列属性[]\nALTER TABLE teacher1 MODIFY age VARCHAR(11); -- 修改字段类型以及约束\n-- ALTER TABLE 表名 CHANGE 旧字段名 新字段名\nALTER TABLE teacher1 CHANGE age age1 INT(1); -- 字段重命名\n```\n\n> 删除表的结构\n\n``` sql\n-- 删除表的字段：ALTER TABLE 表名 DROP 字段名\nALTER TABLE teacher1 DROP age1;\n```\n\n注意点：\n\n- 字段名使用``包裹\n- 注释用-- 或/**/\n- sql关键字大小写不敏感\n\n### 3.3 删除表（DROP）\n\n``` sql\nDROP TABLE IF EXISTS t_student;\n```\n\n## 4. 数据库操纵语言（DML）\n\n### 4.1 添加数据（INSERT）\n\n语法：==**INSERT INTO 表名(字段名1, 字段名2) VALUES ('值11','值12'), ('值21','值22')**==\n\n``` sql\n-- 插入一个数据的一个字段时\n-- INSERT INTO `表名`(`字段名1`) VALUES ('值1')\nINSERT INTO `student`(`name`) VALUES ('zhangsan');\n\n-- 插入一个数据的多个字段时\n-- INSERT INTO `表名`(`字段名1`, `字段名2`) VALUES ('值1', '值2')\nINSERT INTO `student`(`name`, `pwd`) VALUES ('zhangsan', 'aaaaaa');\n\n-- 插入多个数据的多个字段时\n-- INSERT INTO `表名`(`字段名1`, `字段名2`) VALUES ('值11', '值12'), ('值21', '值22')\nINSERT INTO `student`(`name`, `pwd`) VALUES ('zhangsan', 'aaaaaa'), ('lisi', 'bbbbbb');\n```\n\n注意事项：\n\n1. 字段和字段使用英文逗号隔开\n2. 表后括号内的字段可以省略，但是后面的值必须与字段名一一对应\n3. 可以同时插入多条数据，此时VALUES后面的值使用逗号隔开`VALUES(), (), ()...`\n\n### 4.2 修改数据（UPDATE）\n\n语法：==**UPDATE 表名 SET  字段名1=value, [字段名2=value2, ...] WHERE [条件]**==\n\n条件：WHERE子句，运算符\n\n``` sql\n--  修改学员名字，带了条件\nUPDATE `student` SET `name`='wangwu' WHERE `id`=1;\n\n-- 不指定条件的情况下，会改动所有的表\nUPDATE `student` SET `name`='wangwu';\n\n-- 修改多个属性\nUPDATE `student` SET `name`='zhaoliu', `email`='1234567@qq.com' \nWHERE `id`=1;\n\n-- 通过多个条件定位数据，无上限\nUPDATE `student` SET `name`='zhaoliu' \nWHERE `name`='wangwu' AND `sex`='女';\t\n\n-- 修改多张表的记录\nUPDATE `student1` s1 \nJOIN `student2` s2\nON s1.`id` = s2.`id`\nSET `name`='zhaoliu' \nWHERE `name`='wangwu'\n```\n\n| 操作符              | 含义           | 范围            | 结果   |\n| :------------------ | -------------- | --------------- | ------ |\n| =                   | 等于           | 5=6             | false  |\n| <=>                 | 安全等于       | 5<=>NULL        | false  |\n| <> 或 !=            | 不等于         | 5<>6            | true   |\n| >，>=               | 大于，大于等于 | 5>6, 5>=6       | false  |\n| <，<=               | 小于，小于等于 | 5<6, 5<=6       | true   |\n| BETWEEN ... AND ... | 闭区间[]       | BETWEEN 2 AND 5 | [2, 5] |\n| AND                 | &&             | 5>1 AND 1>2     | false  |\n| OR                  | \\|\\|           | 5>1 OR 1>2      | true   |\n\n注意：\n\n- 字段名是数据库的列，尽量带上``\n- 筛选的条件如果没有指定，则会修改所有的列\n- value是一个具体的值，也可以是一个变量（时间变量）\n- 多个设置的属性之间使用英文逗号隔开\n- **安全等于<=>可以判断某字段数值是否等于NULL，而普通等于=无法判断是否为NULL**\n\n### 4.3 删除数据（DELETE）\n\n语法：==**DELETE  FROM 表名 [WHERE 条件]**==\n\n作用：**用于删除小表，删除后可以回滚，删除速度较慢**\n\n``` sql\n-- 删除数据 （避免这样写，会全部删除）\nDELETE FROM `student`;\n\n-- 删除指定数据\nDELETE FROM `student` WHERE `id`=1;\n\n-- 联表删除数据\n-- 将userid为Bbiri的user表和my_employees表的记录删除\nDELETE u, e \nFROM users u\nJOIN my_employees e\nON u.`userid` = r.`Userid`\nWHERE u.`userid` = 'Bbiri';\n```\n\n> TRUNCATE 命令  \n\n作用：**用于删除大表，表被截断，不可回滚，永久消失，删除速度较快**。完全清空一个数据库表，表的结构和索引约束不会变。\n\n``` sql\n-- 清空表\nTRUNCATE TABLE `student`;\n```\n\n> TRUNCATE与DELETE区别\n\n- 相同点：都能删除数据，都不会删除表结构\n- 不同点：\n  - TRUNCATE：**删除后不可回滚，永久丢失，删除速度较快**。重新设置自增列，**自增会归零**，不会影响事务，其后不能加`WHERE`过滤\n  - DELETE：**删除后可以回滚，删除速度较慢。**不影响自增列，删除后**自增不归零**\n\n``` sql\nDELETE FROM `test`;    -- 不会影响自增\nTRUNCATE TABLE `test`; -- 自增会归零\n```\n\n了解即可： `DELETE删除的问题`\n\n重启数据库时：\n\n- InnoDB，自增列会从1开始（存在内存当中，断电即失）\n- MyISAM，继续从上一个自增量开始（存在文件中，不会丢失）\n\n## 5. 数据库查询语言（DQL）\n\n### 5.1 DQL\n\nDQL：Data Query Language，数据库查询语言\n\n- 所有的查询操作都使用SELECT\n- 数据库中最核心的语言\n- 使用频率最高\n\n**SELECT完整语法：**\n\n``` sql\nSELECT[ALL | DISTINCT | DISTINCTROW | TOP]\n{* | talbe.* | [table.]field1[AS alias1][,[table.]field2[AS alias2][,…]]} -- 字段\nFROM tableexpression[,…]  -- 从哪张表（主表）查询\n[LEFT | RIGHT | INNER JOIN externaldatabase]  -- 联合查询\n[ON …]          -- 联合查询的等值判断\n[WHERE …]       -- 条件过滤：可以是具体的值，也可以是子查询语句\n[GROUP BY …]    -- 分组：通过某个字段进行分组\n[HAVING …]  \t-- 过滤分组后信息：条件和WHERE相似，只是位置必须在GROUP BY之后\n[ORDER BY …]\t-- 排序：通过某个字段排序\n[LIMIT ]        -- 分页：指定查询记录从哪条，显示多少条\n```\n\n==**SELECT语句执行顺序：**==\n\n`SELECT `在`HAVING`之后执行，因此分组函数不能在`WHERE`中使用\n\n``` sql\nSELECT            -- 7\nFROM              -- 1\n[JOIN  …]         -- 2\n[ON    …]         -- 3\n[WHERE …]         -- 4\n[GROUP BY …]      -- 5\n[HAVING …]        -- 6\n[ORDER BY …]      -- 8\n[LIMIT ]          -- 9\n```\n\n### 5.2 指定查询字段（SELECT）\n\n语法：==**SELECT 字段，... FROM 表**==\n\n> 有时列的名字不是那么见名知意，此时可以其别名，使用AS ：字段名 AS 别名 或  表名 AS 别名\n\n``` sql\n-- 查询全部学生 SELECT 字段 FROM 表\nSELECT * FROM `student`;\n\n-- 查询指定字段\nSELECT `StudentNo`, `StudentName` FROM `student`;\n\n-- 别名，给结果起个名字。可以给字段其别名，也可以给表名起别名\nSELECT `StudentNo` AS 学号, `StudentName` AS 学生姓名 FROM `student` AS s;\n\n-- 函数 CONCAT(a, b)，将连接后字符串显示\nSELECT CONCAT('姓名： ', StudentName) AS 新名字 FROM `student`;\n```\n\n> 去重 DISTINCT\n\n作用：去除SELECT查询出来的结果中重复的数据，重复数据只显示一条\n\n``` sql\n-- 查询一下有哪些同学参加了考试\nSELECT * FROM result;            -- 查询全部的考试成绩\nSELECT `StudentNo` FROM result;  -- 查询有哪些同学参加了考试\n\n-- 发现重复数据，去重\nSELECT DISTINCT `StudentNo` FROM result;\n```\n\n> 数据库的列（表达式）\n\n``` sql\nSELECT VERSION();                   -- 查询系统版本（函数）\nSELECT 100*3-1 AS 计算结果;          -- 用来计算（表达式）\nSELECT @@AUTO_INCREMENT_INCREMENT;  -- 查询自增的步长（变量）\n\n-- 学员考试成绩+1分查看\nSELECT `StudentNo`, `StudentResult`+1 AS '提分后' FROM result;\n```\n\n数据库中的表达式：文本值，列，NULL，函数，计算表达式，系统变量...\n\n语法：==**SELECT 表达式  FROM 表**==\n\n### 5.3 条件子句（WHERE）\n\n作用：检索数据中`符合条件`的值\n\n搜索的条件由一个或多个表达式组成，结果为布尔值\n\n> 逻辑运算符\n\n| 运算符      | 语法                 | 描述                           |\n| ----------- | -------------------- | ------------------------------ |\n| AND  &&     | a AND b   a && b     | 逻辑与，两个都为真，结果为真   |\n| OR     \\|\\| | a OR b      a \\|\\| b | 逻辑或，其中一个为真，结果为真 |\n| NOT   !     | NOT a       ! a      | 逻辑非，真变假，假变真         |\n\n``` sql\n-- && AND \nSELECT `StudentNo`, `StudentResult` FROM result\nWHERE `StudentResult`>=95 && `StudentResult`<=100;\nWHERE `StudentResult`>=95 AND `StudentResult`<=100;\n\n-- 区间\nSELECT `StudentNo`, `StudentResult` FROM result\nWHERE `StudentResult` BETWEEN 95 AND 100;\n\n-- != NOT\nSELECT `StudentNo`, `StudentResult` FROM result \nWHERE `StudentNo` != 1000;\nWHERE NOT `StudentNo` = 1000;\n```\n\n> 模糊查询：比较运算符\n\n| 运算符      | 语法                 | 描述                                             |\n| ----------- | -------------------- | ------------------------------------------------ |\n| IS NULL     | a IS NULL            | 如果操作符a为NULL，结果为真                      |\n| IS NOT NULL | a IS NOT NULL        | 如果操作符a为NOT NULL，结果为真                  |\n| BETWEEN     | a BETWEEN b and c    | 若a在b和c之间，结果为真                          |\n| **LIKE**    | a   b                | SQL匹配，如果a匹配b，结果为真                    |\n| **IN**      | a IN (a1, a2, a3...) | 假设a在a1，或者a2...其中的某一个值中，则结果为真 |\n\n``` sql\n-- ======================= 模糊查询 =========================\n-- 查询姓张的同学\n-- LIKE结合 %(代表任意个字符)  _(表示一个字符)\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE StudentName LIKE '张%';\n\n-- 查询姓张的同学，'张'后只有一个字的\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE StudentName LIKE '张_';\n\n-- 查询姓张的同学，'张'后只有两个字的\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE StudentName LIKE '张__';\n-- 若想匹配下划线'_'，则使用转义'\\_'的方式才能查询到带有_的数据\n\n-- 查询名字中间有伟的字的同学 %伟%\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE StudentName LIKE '%伟%';\n\n-- ======================= IN =========================\n-- 查询1000,1001号学员\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE StudentNo IN (1000, 1001);\n\n-- 查询在北京的学生\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE `Address` IN ('北京朝阳');\n\n-- ======================= NULL/NOT NULL ======================= \n-- 查询地址为空的学生，即等于 NULL 或 ''\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE address = '' OR adress IS NULL;\n\n-- 查询有出生日期的同学，即不为空\nSELECT `StudentNo`, `StudentName` FROM \t`student` \nWHERE `BornDate` IS NOT NULL;\n```\n\n注意：使用`LIKE`时，若想匹配下划线_，则使用转义的方式。\n\n### 5.4 连接查询（JOIN )\n\n1. 按照年代分类：\n   - SQL92（旧的语法）\n   - SQL99（新的语法）\n\n2. 按照表的连接方式分类：\n   - 内连接（包括等值连接、非等值连接、自连接）\n   - 外连接（包括左外连接，右外连接）\n   - 全连接\n\n笛卡尔积现象：当两张表进行连接查询时，没有任何条件进行限制，最终的查询结果条数是两张表记录条数的乘积。（例如第一张表有7条数据，第二张表有8条数据，则不加条件限制时，查询出56条数据）避免笛卡尔积现象的方法：使用ON关键字加条件进行过滤。**但避免笛卡尔积现象并不会减少记录的匹配次数，数据库在匹配数据时仍然是搜索了56次，但是只滤过剩下了符合条件的数据**\n\n\n语法：==**FROM 要查询的表 INNER/RIGHT/LEFT JOIN 要连接的表 ON 交叉条件**==\n\n![七种SQL Joins 文氏图解](/images/%E3%80%90MySQL%E3%80%91MySQL%E5%9F%BA%E7%A1%80/02.png)\n\n> MySQL 不支持 FULL OUTER JOIN\n\n- **INNER JOIN**：内连接，又叫等值连接，只返回两个表中连接字段相等的行数据\n- **LEFT JOIN**：左连接，从左表中返回所有值，即使右表中没有匹配（没匹配上的数据显示NULL）\n- **RIGHT JOIN**：右连接，从右表中返回所有值，即使左表中没有匹配（没匹配上的数据显示NULL）\n\n数据库在通过JOIN连接两张或多张表来返回记录时，都会生成一张中间的临时表，然后再将这张临时表返回给用户，或与下一层的表进行连接。\n\n在使用LEFT JOIN 时，ON和WHERE条件的区别如下：\n\n- ON条件是在生成临时表时使用的条件，它不管ON中的条件是否为真，都会返回左边表中的记录。（为真的部分返回数值，为假的部分返回NULL）\n- WHERE条件是在临时表生成好后，再对临时表进行过滤的条件。\n\n**ON用于判断哪个字段在两个表中相等，从而连接两个表，WHERE则是在连接后生成的临时表的基础上进行过滤**。\n\n在使用INNER JOIN 时，ON和WHERE条件产生的效果相同。\n\n``` sql\n-- =========================== 连接查询 JOIN ==========================\n-- 查询参加了考试的同学（学号，姓名，科目编号，分数）\nSELECT * FROM `student`;\nSELECT * FROM `result`;\n\t\n/* 思路\n1. 分析需求，分析查询的表来自哪些表\n2. 确定使用哪种连接查询 7种\n确定交叉点（这两个表中哪个数据是相同的）\n判断的条件：student表中的StudenNo = result表中的 StudentNo\n*/\n\n-- INNER JOIN 内连接，取二者共有的行，交集\nSELECT s.`StudentNo`, `StudentName`, `SubjectNo`, `StudentResult`\nFROM `student` AS s\nINNER JOIN result AS r\nWHERE s.`StudentNo` = r.`StudentNo`;\n\n-- LEFT JOIN：左连接。以左表为主表，展示左表所有的数据、右表符合ON条件的数据、以及右表不符合条件的数据（这些不符合的数据显示为空）\nSELECT s.`StudentNo`, `StudentName`, `SubjectNo`, `StudentResult`\nFROM `student` AS s\nLEFT JOIN result AS r\nON s.`StudentNo` = r.`StudentNo`;\n\n-- RIGHT JOIN：右连接，以右表为主表，展示右表所有的数据、左表符合ON条件的数据、以及左表不符合条件的数据（这些不符合的数据显示为空）\nSELECT s.`StudentNo`, `StudentName`, `SubjectNo`, `StudentResult`\nFROM `student` AS s\nRIGHT JOIN result AS r\nON s.`StudentNo` = r.`StudentNo`;\n\n-- 查询缺考的同学\n-- 增加WHERE，对查询结果进行筛选过滤\nSELECT s.`StudentNo`, `StudentName`, `SubjectNo`, `StudentResult`\nFROM `student` AS s\nLEFT JOIN result AS r\nON s.`StudentNo` = r.`StudentNo`\nWHERE `StudentResult` IS NULL;\n\n-- =========================== 多张表连接查询 ===========================\n-- 查询参加了考试的同学信息：学号，学生姓名，科目名，分数\nSELECT s.`StudentNo`, `StudentName`, `SubjectName`, `StudentResult`\nFROM student AS s\nRIGHT JOIN result As r\nON r.`StudentNo` = s.`StudentNo`\nINNER JOIN `subject` AS sub\nON r.SubjectNo = sub.SubjectName;\n\n-- 格式：\n-- SELECT 要查询哪些数据 \n-- FROM 要查询的表 \n-- XXX JOIN 要连接的表 \n-- ON 交叉条件\n-- 假设存在一种多张表查询，先查询两张表，然后再查询另一张表\n\n-- FROM a LEFT JOIN b  a为基准\n-- FROM a RIGHT JOIN b  b为基准\n```\n\n> 自连接\n\n==**自己的表和自己的表连接，核心：一张表拆为两张一样的表即可**==\n\n**原表**\n\n| categoryid | pid  | categoryName |\n| ---------- | ---- | ------------ |\n| 2          | 1    | 信息技术     |\n| 3          | 1    | 软件开发     |\n| 4          | 3    | 数据库       |\n| 5          | 1    | 美术设计     |\n| 6          | 3    | Web开发      |\n| 7          | 5    | PS技术       |\n| 8          | 2    | 办公信息     |\n\n> 拆成父类表和子类表\n\n**父类**\n\n| categoryid | categoryName |\n| ---------- | ------------ |\n| 2          | 信息技术     |\n| 3          | 软件开发     |\n| 5          | 美术设计     |\n\n**子类**\n\n| pid  | categoryid | categoryName |\n| ---- | ---------- | ------------ |\n| 3    | 4          | 数据库       |\n| 2    | 8          | 办公信息     |\n| 3    | 6          | Web开发      |\n| 5    | 7          | PS技术       |\n\n操作：查询父类对应的子类关系\n\n| 父类     | 子类     |\n| -------- | -------- |\n| 信息技术 | 办公信息 |\n| 软件开发 | 数据库   |\n| 软件开发 | Web开发  |\n| 美术设计 | PS技术   |\n\n``` sql\n-- 查询父子信息： 把一张表选定为两张一样的表\nSELECT a.`categoryName` AS  '父栏目', b.`categoryNAME` AS '子栏目'\nFROM `category` AS a, `category` AS b\nWHERE a.`categoryid` = b.`pid`;\n```\n\n### 5.5 分组和过滤（GROUP BY  / HAVING）\n\n语法：==**GROUP BY  ....   HAVING ....**==\n\n- `GROUP BY`：按照某个字段或者某些字段进行分组，**可以进行多个字段分组**\n- `HAVING`：必须放在`GROUP BY`后，对**分组后的结果**进行过滤\n\n`GROUP BY`语句在`WHERE`语句之后执行。\n\n==**若某个语句中没有显式GROUP BY，则编译时会在最后添加缺省的GROUP BY**==\n\n``` sql\n-- 查询不同课程的平均分，最高分，最低分，平均分大于80分\n-- 核心：根据不同的课程分组\nSELECT ANY_VALUE(subjectName), AVG(StudentResult) AS 平均分, MAX(StudentResult) AS 最高分, MIN(StudentResult) AS 最低分\nFROM result r\nINNER JOIN `subject` sub\nON r.`subjectNo` = sub.`subjectNo`\nGROUP BY r.SubjectNo -- 通过什么字段分组\nHAVING 平均分 > 80;\n\n-- 找出每个部门不同工作岗位的最高薪资\n-- 多字段分组\nSELECT deptno, job, MAX(sal) \nFROM emp\nGROUP BY \ndeptno, job;  -- 按照部门和岗位分组，先部门，后岗位，多字段分组\n```\n\n**当一条SQL语句有GROUP BY时，只允许SELECT查询==参加分组==的字段和==分组函数==**。\n\n注意：**在SELECT中使用到分组函数或使用GROUP BY关键字时，需要使用ANY_VALUE()修饰普通字段，其会选择被分到同一组的数据里第一条数据的指定列值作为返回数据，即只返回一个值**。\n\n**因为分组函数或使用GROUP BY关键字在使用时会从多条匹配到的数据中取出某一个作为返回结果（例如MAX()，只取了最大的数据），此时，没有被分组函数修饰的字段将匹配到多条数据，因此必须从中选出某一条作为返回结果，ANY_VALUE()即从中返回了第一条数据**。\n\n为提高效率，可先使用WHERE进行筛选，再在其基础上使用GROUP BY分组。若先GROUP BY，再HAVING，则效率低于前者。如果能在GROUP BY前使用WHERE过滤，则最好先使用WHERE。\n\n### 5.6 排序（ORDER BY ）\n\n语法：==**ORDER BY 字段名 DESC/ASC**==\n\n- 升序ASC\n- 降序DESC\n\n注意：当指定多个字段进行排序时，越靠前的字段越起主导地位，后面的字段只会在前面的字段排序相等的情况下才会启用。例如`ORDER BY XXX DESC, YYY ASC `，先按照XXX进行降序排列，再在其基础上，对XXX相等的数据进行升序排列。\n\n\n``` sql\n-- ======================== 分页LIMIT 排序ORDER BY =========================\n-- 排序：升序ASC，降序DESC\n-- ORDER BY 通过哪个字段排序，怎么拍\n-- 查询的结果根据成绩降序排序\nSELECT s.`StudentNo`, `StudentName`, `SubjectName`, `StudentResult`\nFROM `student` AS s\nINNER JOIN `result` AS r\nON s.`StudentNo` = r.`StudentNo`\nINNER JOIN `subject` AS sub\nON r.`SubjectNo` = sub.`SubjectNo`\nORDER BY StudentResult DESC;\n```\n\n### 5.7 分页（LIMIT）\n\n语法：==**LIMIT 查询起始值，pagesize**==\n\n``` sql\n-- 分页：缓解数据库压力，给人更好的体验\n-- 网页应用：当前，总的页数，页面大小\n-- LIMIT 0, 5   1~5       \n-- LIMIT 6, 5   6~10     \n-- 第一页 LIMIT 0, 5\n-- 第二页 LIMIT 5, 5\n-- 第三页 LIMIT 10, 5\n-- 第N页 LIMIT  (N-1)* pageSize, pageSize\n-- [PageSize: 页面大小, (N-1)*PageSize：起始值, N: 当前页]\n\nSELECT s.`StudentNo`, `StudentName`, `SubjectName`, `StudentResult`\nFROM `student` AS s\nINNER JOIN `result` AS r\nON s.`StudentNo` = r.`StudentNo`\nINNER JOIN `subject` AS sub\nON r.`SubjectNo` = sub.`SubjectNo`\nORDER BY StudentResult DESC\nLIMIT 0,5;\n```\n\n### 5.8 子查询\n\n目标：WHERE（不使用固定值，而使用计算出来的值）\n\n本质：==**在WHERE语句中嵌套一个子查询语句**==\n\n``` sql\n-- 查询数据库结构-1的所有考试结果（学号，科目编号，成绩），降序排列\n-- 方式一：使用连接查询\nSELECT `StudentNo`, r.`SubjectNo`, `StudentResult`\nFROM `result` AS r\nINNER JOIN `subject` AS sub\nON r.`SubjectNo` = sub.`SubjectNo`\nWHERE `SubjectName` = '数据库结构-1'\nORDER BY  `StudentResult` DESC;\n\n-- 方式二：使用子查询（由里及外）\nSELECT `StudentNo`, r.`SubjectNo`, `StudentResult`\nFROM `result` AS r\nWHERE `SubjectNo` = ANY(\n\t\t\tSELECT `SubjectNo` \n\t\t\tFROM `subject` \n\t\t\tWHERE `SubjectName` = '数据库结构-1'\n)\nORDER BY `StudentResult` DESC;\n\n-- 查询数据库结构-1的学生的学号\nSELECT `SubjectNo` FROM `subject` WHERE `SubjectName` = '数据库结构-1';\n\n-- 分数不小于80分的学生的学号和姓名\nSELECT `StudentNo`, `StudentName`\nFROM `student` \nWHERE `StudentNo` = ANY(\n\t\t\tSELECT `StudentNo` \n\t\t\tFROM `result`\n\t\t\tWHERE `StudentResult` >= 80\n);\n\n-- 或\nSELECT `StudentNo`, `StudentName`\nFROM `student` \nWHERE `StudentNo` IN (\n\t\t\tSELECT `StudentNo` \n\t\t\tFROM `result`\n\t\t\tWHERE `StudentResult` >= 80\n);\n```\n\n### 5.9 合并查询结果（UNION）\n\n语法：==**SELECT XXXXX  UNION SELECT XXXXX**==\n\n作用：用于将两个SELECT语句查询到的结果合并成一张表（行数据拼接起来），可以把两个**不相干的表**中的数据拼接起来显示（例如要查询的结果来自于多张表，并且这些表之间没有直接的连接关系）。\n\n要求：\n\n- 前后两个查询结果的列数必须一致\n- 多条查询语句的查询的每一列的类型和顺序最好一致\n- `UNION`关键字默认去重，如果使用`UNION ALL`可以包含重复项\n\n## 6. MySQL函数\n\n### 6.1 普通函数\n\n``` sql\n-- 数学运算 \nSELECT ABS(-8);       -- 绝对值\nSELECT CEILING(9.4);  -- 向上取整\nSELECT FLOOR(9.4);    -- 向下取整\nSELECT RAND();        -- 随机数\nSELECT SIGN(-2);      -- 判断一个数的符号 0返回0，负数返回-1，整数返回1\n\n-- +号运算\nSELECT 100 + 90;         -- 两个操作数都为数值型，则做加法运算\nSELECT '123' + 90；      -- 其中一方为字符型，试图将字符型数值转换为数值型，\n                         -- 如果转换成功，则继续做加法，如果转换失败，则将字符型数值转换成0\nSELECT NULL + 10;        -- 只要其中一方为NULL，则结果为NULL\n\n-- 字符串函数\nSELECT CHAR_LENGTH('helloworld');          -- 字符串长度\nSELECT CONCAT('Hello', ' World');          -- 拼接字符串\nSELECT INSERT('hello world', 1, 2, 'He');  -- 从某个位置开始替换某个字符串\nSELECT LOWER('HELLOWORLD');                -- 变小写字母\nSELECT UPPER('helloworld');                -- 变大写字母\nSELECT INSTR('hello world', 'h');          -- 返回第一次出现的字符串的位置，找不到返回0\nSELECT REPLACE('hello world', 'world', 'mysql');   -- 替换\nSELECT SUBSTR('hello world', 4, 6);        -- 返回指定的子字符串（源字符串，截取的位置，截取的长度）从第4个字符开始取，取6个字符长度\nSELECT REVERSE('hello world');             -- 反转\nSELECT TRIM('   HELLO   ');                -- 将字符串前后的空格去掉\nSELECT TRIM('a' FROM 'aaaHELLOaaa');       -- 将字符串前后的指定字符'a'去掉\n\nSELECT REPLACE(studentName, '周', '邹') FROM student\nWHERE studentName LIKE '周%';\n\n-- 时间和日期函数（记住）\nSELECT CURRENT_DATE();  -- 获取当前时间\nSELECT CURDATE();       -- 获取当前日期\nSELECT NOW();           -- 获取当前时间\nSELECT LOCALTIME();     -- 本地时间\nSELECT SYSDATE();       -- 本地时间\n\nSELECT YEAR(NOW());\nSELECT MONTH(NOW());\nSELECT DAY(NOW());\nSELECT HOUR(NOW());\nSELECT MINUTE(NOW());\nSELECT SECOND(NOW());\n\n-- 系统\nSELECT SYSTEM_USER();\nSELECT USER();\nSELECT VERSION();\n\n-- 空处理函数，将xxx为NULL的值设置为0\nIFNULL(xxx, 0)\n```\n\n### 6.2 分组函数\n\n分组函数都是对**某一组**数据进行操作的。 其也被称为聚合函数、多行处理函数：输入多行，最终输出一行结果。\n\n- **分组函数自动忽略NULL，无需添加WHERE条件语句判断数据是否为NULL**\n- **分组函数不能直接使用在WHERE子句当中，因为WHERE语句在GROUP BY语句之前执行，而分组函数必须在分完组才能执行（即必须在GROUP BY语句之后执行）**\n- **分组函数一般都会和GROUP BY联合使用，其在GROUP BY语句执行后才执行**\n\n例如：`SELECT ename, sal FROM emp WHERE sal > AVG(sal); `有语法错误，因为分组函数不能在WHERE子句中使用。修改办法：使用子查询语句`SELECT ename, sal FROM emp WHERE sal > (SELECT AVG(sal) FROM emp); `\n\n| 函数名称 | 描述   |\n| -------- | ------ |\n| COUNT()  | 计数   |\n| SUM()    | 求和   |\n| AVG()    | 平均值 |\n| MAX()    | 最大值 |\n| MIN()    | 最小值 |\n\n``` sql\nSELECT COUNT(`StudentName`) FROM student;  -- COUNT(字段)，指定查询某列，会忽略所有的NULL值\nSELECT COUNT(*) FROM student;  -- COUNT(*)，不会忽略NULL值\nSELECT COUNT(1) FROM result;   -- COUNT(1)，不会忽略NULL值，效果同COUNT(*)，本质是在表中加了一列全是1的数据，然后统计1的个数，本质还是COUNT(*)\n\t\t\t\nSELECT SUM(`studentResult`) AS 总分 FROM result;\nSELECT AVG(`studentResult`) AS 平均分 FROM result;\nSELECT MAX(`studentResult`) AS 最高分 FROM result;\nSELECT MIN(`studentResult`) AS 最低分 FROM result;\n```\n\n注意：==**count(\\*)和count(某字段)的区别：**==\n\n- `count(*)`：和字段内容没关系，会查询所有包含NULL在内的行数（统计总记录条数）\n- `count(某字段)`：和字段内容有关系，会查询除了NULL值以外的行数（忽略NULL值）\n\n分组函数在`GROUP BY`**之后**使用，用于统计分组后同一组内数据的最大/小值、平均值和总数。\n\n### 6.3 数据库级别的MD5加密（扩展）\n\nMD5：Message-Digest Algorithm，信息摘要算法。\n\nMD5主要增强算法复杂度和不可逆性。MD5破解网站的原理：背后有一个字典，一一查询匹配MD5加密后的值与加密前的值，看能否找到匹配。\n\n``` sql\n-- ====================== 测试MD5 加密 ======================\nCREATE TABLE `testmd5`(\n\t`id` INT(4) NOT NULL,\n\t`name` VARCHAR(20) NOT NULL,\n\t`pwd` VARCHAR(50) NOT NULL,\n\tPRIMARY KEY(`id`)\n)ENGINE=INNODB DEFAULT CHARSET=utf8;\n\n-- 明文密码\nINSERT INTO `testmd5` VALUES(1, 'zhangsan', '123456'), (2, 'lisi', '123456'), (3, 'wangwu', '123456');\n\n-- 加密\nUPDATE `testmd5` SET pwd=MD5(pwd) WHERE id=1;\nUPDATE `testmd5` SET pwd=MD5(pwd);\n\n-- 插入数据时加密\nINSERT INTO `testmd5` VALUES(4, 'zhaoliu', MD5('123456'));\n\n-- 如何校验：将用户传递进来的密码进行md5加密，然后对比加密后的值\nSELECT * FROM testmd5 WHERE `name`='zhaoliu' AND pwd=(MD5('123456'));\n```\n\n## 7. 事务\n\n### 7.1 什么是事务\n\nTCL: Transaction Control Language 事务控制语言。\n\n 事务（Transaction）：事务由单独单元的一个或一组sql语句组成，在这个单元中，每个MySQL语句是相互依赖的，这个执行单元 ==**要么全部执行，要么全部不执行**==\n\n-  SQL语句1正在执行：A给B转账200     A：1000  ——> 200   B：200\n-  SQL语句2正在执行：B收到A的钱        B：800    ——>            B：400 \n\n将一组SQL放在一个批次中去执行。上述两条语句组成一组来执行，要么都成功，要么都失败，否则钱会凭空消失。\n\n### 7.2 事务原则\n\n> 事务原则：ACID原则——原子性(Atomicity)、一致性(Consistency)、隔离性(Isolation)、持久性(Durability)；脏读，幻读，不可重复读\n\n**1. 原子性（Atomicity）**\n\n原子性是指**事务是一个不可分割的工作单位**，事务中的操作**要么都执行，要么都不执行**，没有中间状态。对于事务在执行中发生错误，所有的操作都会被回滚，整个事务就像从没被执行过一样。\n\n**2. 一致性（Consistency）**\n\n事务必须使数据库从一个一致性状态变换到另一个一致性状态。保证数据库一致性是指当事务完成时，必须使所有数据都具有一致的状态。（例如A给B转账前后，数据库中二者余额之和相等，转账前为一个一致性状态，转账后也为一个一致性状态）。\n\n**3. 隔离性（Isolation）**\n\n隔离性是指一个事务的执行不能被其他事务干扰，即一个事务内部的操作及使用的数据对并发的其他数据是隔离的，并发执行的各个事务之间不能互相干扰。\n\n**4. 持久性（Durability）**\n\n持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响。\n\n其中，原子性和持久性靠**undo和redo日志**来实现，隔离性通过线程的控制来实现\n\n### 7.3 事务隔离级别\n\n> 参考链接：https://cloud.tencent.com/developer/article/1450773\n\n对于同时运行的多个事务，当这些事务访问数据库中相同的数据时，如果没有采取必要的隔离机制，就会导致各种并发问题：\n\n**1. 脏读（读取未提交数据）：**\n\n指一个事务读取了另一个事务未提交的数据。例如，两个事务T1和T2，T1读取了已经被T2更新但是**还没有被提交**的字段，之后，若T2回滚，T1读取到的内容就是临时且无效的。\n\n**2. 不可重复读（前后多次读取，数据内容不一致）：**\n\n指在一个事务内读取表中的某一行数据，过段时间，该字段数据被另一事务修改，此时第一个事务**再读时读取结果不同**。例如，两个事务T1和T2，T1读取了一个字段，然后T2**更新**了该字段，之后，T1再此读取同一字段时，值就不同了。\n\n**3. 幻读（前后多次读取，数据总量不一致）：**\n\n事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据。（类似班级里刚才看还是一个人，再看变成两个人，就像产生了幻觉）\n\n**不可重复读和幻读的区别:**\n\n(1) 不可重复读是读取了其他事务更改的数据，**针对UPDATE操作**\n\n解决：使用行级锁，锁定该行，事务A多次读取操作完成后才释放该锁，这个时候才允许其他事务更改刚才的数据。\n\n(2) 幻读是读取了其他事务新增的数据，**针对INSERT和DELETE操作**\n\n解决：使用表级锁，锁定整张表，事务A多次读取数据总量之后才释放该锁，这个时候才允许其他事务新增数据。\n\n**MySQL的JDBC中，默认开启事务，此时每一句sql语句都会在一个单独的事务中执行，例如两次查询语句都会在不同的事务中执行，执行完该语句都会立刻提交。**\n\nMySQL支持4种事务隔离级别，默认级别为 ==**REPEATABLE READ**==\n\n- **READ UNCOMMITTED（读未提交数据）**：允许事务读取未被其他事务提交的变更。脏读、不可重复读和幻读都可能出现 \n- **READ COMMITTED（读已提交数据）**：只允许事务读取已经被其他事务提交的变更。可以避免脏读，但不可重复读和幻读仍然可能出现 \n- **REPEATABLE READ（可重复读）**：确保事务可以多次从一个字段中读取相同的值，在这个事务持续期间，禁止其他事务对这个字段进行更新。**此时即使其他事务修改某字段并COMMIT，本事务查询时仍是原先值**。可以避免脏读和不可重复读，但幻读仍然可能出现，**即其他事务若插入了新的行，本事务查询时也会多出这些行，导致看起来像幻觉一样，每次读取的数据总量不同**\n- **SERIALIZABLE（串行化）**：确保事务可以从一个表中读取相同的行，在这个事务持续期间，禁止其他事务对该表执行插入，更新和删除操作。所有并发问题都可以避免，但性能十分低下。在某个事务读取时，其他事务阻塞，无法对该表进行操作。**该级别下无法进行并发**\n\n查看隔离级别：\n\n``` sql\nSELECT @@TX_ISOLATION           --（8.0以前） \nSELECT @@TRANSACTION_ISOLATION  --（8.0以后）\n```\n\n设置**当前**MySQL连接的隔离级别：\n\n**SET ==SESSION== TRANSACTION ISOLATION LEVEL ==READ COMMITTED==**\n\n设置**全局**MySQL连接的隔离级别：\n\n**SET ==GLOBAL== TRANSACTION ISOLATION LEVEL ==READ COMMITTED==**\n\n### 7.4 undo 和 redo 日志\n\n> http://www.zhdba.com/mysqlops/2012/04/06/innodb-log1/\n\n在数据库系统中，既有存放数据的文件，也有存放日志的文件。在内存中既有日志缓存 log buffer，也有磁盘文件 log file。MySQL中的日志文件，有这么两种与事务有关：**undo日志**与**redo日志**。\n\n### 7.4.1 undo 日志\n\n> https://www.bilibili.com/video/BV1n7411R7WQ?p=6&spm_id_from=333.1007.top_right_bar_window_history.content.click\n\nundo日志的原理：为了满足事务的原子性，在操作任何数据之前，首先将数据备份到 undo log。然后进行数据的修改。如果出现了错误或者用户执行了 ROLLBACK 语句，系统可以利用 undo log 中的备份将数据恢复到事务开始之前的状态。并且数据库写入数据到磁盘之前，会把**数据先缓存在内存**中，事务提交时才会写入磁盘中。\n\n> 用undo日志实现原子性的简化过程\n\n 假设有A、B两个数据，值分别为1,2。\n\n- A. 事务开始.\n- B. 记录A=1到 undo log.\n- C. 修改A=3.\n- D. 记录B=2到 undo log.\n- E. 修改B=4.\n- F. 将 undo log 写到磁盘。\n- G. 将数据写到磁盘。\n- H. 事务提交\n\n**1. 如何保证持久性？**\n\n事务提交前，会把修改后的数据保存到磁盘，也就是说只要事务提交了，数据肯定持久化了。\n\n**2. 如何保证原子性？**\n\n- 每次对数据库修改，都会把修改前数据记录在 undo log，那么需要回滚时，可以读取 undo log，恢复数据。\n- 若系统在G和H之间崩溃，此时事务并未提交，需要回滚。而 undo log 已经被持久化，可以根据 undo log 来恢复数据\n- 若系统在G之前崩溃，此时数据并未持久化到硬盘，依然保持在事务之前的状态\n\n**缺陷**：每个事务提交前将数据和 undo log 写入磁盘，这样会导致大量的磁盘IO，因此性能很低。\n\n如果能够将数据缓存一段时间，就能减少IO提高性能。但是这样就会丧失事务的持久性。因此引入了另外一种机制来实现持久化，即 **redo log**。\n\n### 7.4.2 redo日志\n\n和 undo log 相反，redo log 记录的是**新数据**的备份。在事务提交前，只要将 redo log 持久化即可，不需要将数据库中的数据持久化，减少了IO的次数。 \n\n> undo + redo 事务的简化过程\n\n 假设有A、B两个数据，值分别为1,2\n\n- A. 事务开始.\n- B. 记录 A=1 到 undo log buffer.\n- C. 修改 A=3.\n- D. 记录 A=3 到 redo log buffer.\n- E. 记录 B=2 到 undo log buffer\n- F. 修改 B=4.\n- G. 记录 B=4 到 redo log buffer.\n- H. 将 undo log 写入磁盘\n- I. 将 redo log 写入磁盘\n- J. 事务提交\n\n**1. 如何保证原子性？**\n\n如果在事务提交前故障，通过 undo log 日志恢复数据。如果 undo log 都还没写入，那么数据就尚未持久化，无需回滚\n\n**2. 如何保证持久化？**\n\n注意，这里并没有出现数据的持久化。因为数据已经写入 redo log，而 redo log 持久化到了硬盘，因此只要到了步骤`I`以后，事务是可以提交的。\n\n**3. 内存中的数据库数据何时持久化到磁盘？**\n\n因为 redo log 已经持久化，因此数据库数据写入磁盘与否影响不大，不过为了避免出现脏数据（内存中与磁盘不一致），事务提交后也会将内存数据刷入磁盘（也可以按照固设定的频率刷新内存数据到磁盘中）。\n\n**4. redo log 何时写入磁盘？**\n\nredo log 会在事务提交之前，或者 redo log buffer满了的时候写入磁盘\n\n这里存在两个问题：\n\n**问题1**：之前是写 undo 和数据库数据到硬盘，现在是写 undo 和 redo 到磁盘，似乎没有减少IO次数\n\n- 数据库数据写入是**随机IO**，性能很差\n- redo log 在初始化时会开辟一段**连续的空间**，写入是**顺序IO**，性能很好\n- 实际上 undo log 并不是直接写入磁盘，而是先写入到 redo log buffer 中，当 redo log 持久化时，undo log 就同时持久化到硬盘了。\n\n因此事务提交前，只需要对 redo log 持久化即可。另外，redo log 并不是写入一次就持久化一次， redo log 在内存中也有自己的缓冲池：`redo log buffer`。每次写 redo log 都是写入到 buffer，在提交时一次性持久化到磁盘，减少IO次数。\n\n**问题2**：redo log 数据是写入内存buffer中，当buffer满或者事务提交时，将 buffer 数据写入磁盘。redo log 中记录的数据，有可能包含尚未提交事务，如果此时数据库崩溃，那么如何完成数据恢复？\n\n数据恢复有两种策略：\n\n- 恢复时，只重做已经提交了的事务\n- 恢复时，重做所有事务包括未提交的事务和回滚了的事务。然后通过 undo log 回滚那些未提交的事务\n\nInnodb 引擎采用的是第二种方案，因此 undo log 要在 redo log 前持久化\n\n**总结**：\n\n- undo log 记录**更新前**的数据，用于保证事务**原子性**\n- redo log 记录**更新后**的数据，用于保证事务的**持久性**\n- redo log 有自己的内存buffer，先写入到 buffer，事务提交时写入磁盘\n- redo log 持久化之后，意味着事务是**可提交**的\n\n\n\n### 7.5 悲观锁和乐观锁\n\n参考链接：https://cloud.tencent.com/developer/article/1450773\n\n>  悲观锁\n\n正如其名，它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度，因此，在整个数据处理过程中，将数据处 于锁定状态。\n\n悲观锁的实现，往往依靠数据库提供的锁机制（也只有数据库层提供的锁机制才能真正保证数据访问的排他性，否则，即使在本系统中实现了加锁机 制，也无法保证外部系统不会修改数据）。\n\n在悲观锁的情况下，为了保证事务的隔离性，就需要一致性锁定读。读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。\n\n> 乐观锁\n\n相对悲观锁而言，乐观锁机制采取了更加宽松的加锁机制。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。但随之而来的就是数据库性能的大量开销，特别是对长事务而言，这样的开销往往无法承受。\n\n而乐观锁机制在一定程度上解决了这个问题。乐观锁，大多是基于数据版本（ Version ）记录机制实现。\n\n何谓数据版本？即为数据增加一个版本标识，在基于数据库表的版本解决方案中，一般是通过为数据库表增加一个 “version” 字段来实现。读取出数据时，将此版本号一同读出，之后更新时，对此版本号加一。\n\n此时，将提交数据的版本数据与数据库表对应记录的当前版本信息进行比对，如 果提交的数据版本号大于数据库表当前版本号，则予以更新，否则认为是过期数据。\n\n### 7.6 执行事务顺序\n\n1. 关闭自动提交：`SET autocommit = 0`\n2. 开启一个事务：`START TRANSACTION`\n   - 提交（执行成功）：`COMMIT` ，获得新的数据库\n   - 回滚（执行失败）：`ROLLBACK`，返回原先数据库\n3. 开启自动提交：`SET autocommit = 1`\n\n``` sql\n-- MySQL是默认开启事务自动提交的\nSET autocommit = 0;   -- 关闭\nSET autocommit = 1;\t  -- 开启（默认）\n\n-- 手动处理事务\nSET autocommit = 0;   -- 关闭自动提交\n\n-- 事务开启\nSTART TRANSACTION;    -- 标记一个事务的开始，从这个之后的sql都在同一个事务内\n\nINSERT xx;\nINSERT xx;\n\n-- 提交：持久化（成功）\nCOMMIT;\n\n-- 回滚：回到原来的样子（失败）\nROLLBACK;\n\n-- 事务结束\nSET autocommit = 1; -- 开启自动提交\n\nSAVEPOINT 保存点名称a;              -- 设置一个事务的保存点\nROLLBACK TO 保存点名称a;            -- 回滚到保存点 \nRELEASE SAVEPOINT 保存点名称;       -- 撤销保存点 \n```\n\n测试案例：\n\n``` sql\n-- 模拟转账\nSET autocommit = 0;  -- 关闭自动提交\n\nSTART TRANSACTION;    -- 开启一个事务\n\nUPDATE `account` SET `money`=`money` - 500 WHERE `name` = 'zhangsan';\nUPDATE `account` SET `money`=`money` + 500 WHERE `name` = 'lisi';\n\nCOMMIT;    -- 提交事务，执行后数据库内容才会修改\nROLLBACK;  -- 回滚，数据库内容不会修改\n\nSET autocommit = 1;  -- 恢复默认值\n```\n\n### 7.7 DELETE 和 TRUNCATE 在事务中的区别\n\n- `DELETE`在事务提交前使用，若回滚，则数据会恢复\n- `TRUNCATE`事务提交前使用，若回滚，则数据依旧不会恢复\n\n## 8. 视图\n\n> 视图（VIEW）：一种虚拟存在的表。站在不同的角度去看待同一份数据\n\n视图是一种虚拟存在的表，行和列的数据来自定义视图的查询中使用的表，并且是在使用视图时**动态生成的**，**只保存了SQL逻辑，不保存查询结果**。视图使用时可以像操纵表一样操纵表中的数据。\n\n### 8.1 操作视图\n\n> 创建视图\n\n语法：==**CREATE VIEW 视图名 AS DQL语句（SELECT ... FROM ...)**== \n\n``` sql\nCREATE VIEW emp_view \nAS \nSELECT * FROM emp; -- CREATE后只能是DQL语句\n```\n\n> 删除视图\n\n语法：==**DROP VIEW 视图名**==\n\n``` sql\nDROP VIEW emp_view;\n```\n\n> 修改视图\n\n语法：==**ALTER  VIEW  视图名**==\n\n``` sql\nCREATE OR REPLACE VIEW emp_view  -- 如果存在则替换\nAS \nSELECT * FROM emp; \n\nALTER VIEW emp_view\nAS\nSELECT * FROM emp;\n```\n\n> 更新视图\n\n语法同操作表时一模一样\n\n``` sql\nUPDATE emp_view SET sal = 1000 WHERE dname = 'ACCOUNTING';\n```\n\n**视图的更新性和视图中查询的定义有关系，以下类型的视图时不能更新的：**\n\n- 包含以下关键字的SQL语句：分组函数、`DISTINCT`、`GROUP BY`、`HAVING`、`UNION`或`UNION ALL`\n- 常量视图\n- `SELECT`中包含子查询\n- `JOIN`\n- `FROM`一个不能更新的视图 \n- `WHERE`子句的子查询引用了`FROM`子句中的表\n\n### 8.2 视图的作用\n\n视图的特点：通过对视图的操作会影响到原表数据。可以**面向视图对象**进行增删改查，**对视图对象的增删改查将会导致原表被操作**。\n\n视图的作用：假设有一条非常复杂的SQL语句，而这条SQL语句需要在不同的位置上反复使用。每次使用这条SQL语句的时候都需要重新编写（很麻烦），这时可以把这条复杂的SQL语句以视图对象的形式新建。在需要编写这条SQL语句的位置直接使用视图对象，可以大大简化开发，并且有利于后期的维护，因为修改时只需要修改一个视图对象所映射的SQL语句。\n\n### 8.3 视图和表的区别\n\n|          | 创建语法       | 是否占用实际物理空间 | 使用         |\n| -------- | -------------- | -------------------- | ------------ |\n| **视图** | `CREATE VIEW`  | 只是保存了SQL逻辑    | 主要用来查询 |\n| **表**   | `CREATE TABLE` | 保存了实际数据       | 增删改查     |\n\n## 9. 变量\n\nMySQL中变量类型：\n\n- **系统变量**：\n  - **全局变量**：针对数据库全局有效。服务器每次启动将为所有的全局变量赋初值，针对所有的会话（连接）有效，但是不能跨重启（数据库重启后之前设置的值会恢复）\n  - **会话变量**：仅针对某次会话（连接）有效\n- 自定义变量：\n  - **用户变量**：在当前会话中有效，同与会话变量的作用域\n  - **局部变量**：仅仅在定义它的`BEGIN END`中有效\n\n|              | 作用域        | 定义和使用的地方            | 语法                                                    |\n| ------------ | ------------- | --------------------------- | ------------------------------------------------------- |\n| **用户变量** | 当前会话      | 会话中的任何地方            | `SET @a = 0;`必须加@符号，不用限定类型                  |\n| **局部变量** | `BEGIN END`中 | `BEGIN END`中，且为第一句话 | `DECLARE a INT DEFAULT 0;`一般不用加@符号，需要限定类型 |\n\n## 10. 存储过程和函数\n\n存储过程：一组预编译好的SQL语句的集合，可以理解成批处理语句（类似于Java中的函数）。\n\n- 提高代码的重用性\n- 简化操作\n- 减少了编译次数并且减少了和数据库服务器的连接次数，提高了效率\n\n### 10.1 存储过程的语法\n\n> 创建存储过程\n\n``` sql\nCREATE PROCEDURE 存储过程名（参数列表）\nBEGIN\n\t存储过程体（一组合法的SQL语句）\nEND\n```\n\n参数列表包含三部分：参数模式、参数名和参数类型。其中参数模式包含：\n\n- `IN`：该参数可以作为输入，也就是该参数需要调用方传入值\n- `OUT` ：该参数可以作为输出，也就是该参数可以作为返回值\n- `INOUT`：该参数既可以作为输入又可以作为输出，也就是该参数既需要传入值，又可以返回值\n\n如果存储过程体仅仅只有一句话，则`BEGIN END`可以省略。存储过程体中的每句SQL语句的结尾要求必须加分号。存储过程的结尾可以使用`DELIMITER`重新设置。\n\n> 调用存储方法\n\n``` sql\nCALL 存储过程名（实参列表）；\n```\n\n> 删除存储过程\n\n``` sql\nDROP PROCEDURE 存储过程名;\n```\n\n> 查看存储过程的信息\n\n``` sql\nSHOW CREATE PROCEDURE 存储过程名;\n```\n\n### 10.2 创建和调用存储过程\n\n> 空参列表\n\n``` sql\nSELECT * FROM `admin`;\n\nDELIMITER $\nCREATE PROCEDURE myp1()\nBEGIN\n\tINSERT INTO `admin`(`username`, `password`) \n\tVALUES('zhangsan', '123456');\nEND $\n\n-- 调用\nCALL myp1() $\n```\n\n> 带IN模式参数的存储过程\n\n``` sql\nCREATE PROCEDURE myp2(IN `name` VARCHAR(20))\nBEGIN\n\tSELECT `userid`\n\tFROM `student`\n\tWHERE `username` = `name`;\nEND $\n\n-- 调用\nCALL myp2('zhangsan')$\n```\n\n``` sql\nCREATE PROCEDURE myp3(IN `name` VARCHAR(20), IN `password` VARCHAR(20))\nBEGIN\n\tDECLARE `result` INT DEFAULT 0; -- 声明局部变量并初始化\n    \n\tSELECT COUNT(*) INTO result     -- 将查询结果赋值给变量\n\tFROM `admin`\n\tWHERE `admin`.`username` = `name`\n\tAND `admin`.`password` = `password`;\n\t\n\tSELECT IF(`result` > 0, '成功', '失败')  -- 变量使用\nEND $\n\n-- 调用\nCALL myp3('zhangsan', '123456')$\n```\n\n> 带OUT模式的存储过程\n\n``` sql\nCREATE PROCEDURE myp4(IN beautyName VARCHAR(20), OUT boyName VARCHAR(20))\nBEGIN\n\tSELECT bo.boyName INTO boyName\n\tFROM boys bo\n\tINNER JOIN beauty b \n\tON bo.id = b.boyfriend_id\n\tWHERE b.name = beautyName;\nEND $\n\n-- 创建用户变量并调用存储过程\nSET @bName $\nCALL myp5('zhangsan', @bName)$\n```\n\n> 带INOUT模式的存储过程\n\n``` sql\nCREATE PROCEDURE myp5(INOUT a INT, INOUT b INT)\nBEGIN\n\tSET a = a * 2;\n\tSET b = b * 2;\nEND $\n\nSET @m = 10$\nSET @n = 20$\nCALL myp5(@m, @n)$\n```\n\n### 10.3 函数的语法\n\n存储过程和函数的区别：\n\n- 存储过程：可以有0个返回，也可以有多个返回，适合做批量插入、批量更新\n- 函数：有且只有一个返回，适合做处理数据后返回一个结果\n\n> 创建函数\n\n``` sql\nCREATE FUNCTION 函数名(参数列表) RETURNS 返回类型\nBEGIN\n\t函数体\nEND\n```\n\n- 参数列表包含：参数名、参数类型。\n- 函数体：肯定会有`RETURN`语句。如果`RETURN`语句没有放在函数体的最后也不会报错，但不建议\n- 当函数体中只有一句话，可以省略`BEGIN END`\n- 使用`DELIMITER`语句设置结束标记\n\n> 调用函数\n\n``` sql\nSELECT 函数名(列表参数)\n```\n\n> 查看函数\n\n``` sql\nSHOW CREATE FUNCTION myf1;\n```\n\n> 删除函数\n\n``` sql\nDROP FUNCTION myf1;\n```\n\n### 10.4 创建和调用函数\n\n> 无参数，有返回\n\n``` sql\nCREATE FUNCTION myf1() RETURNS INT\nBEGIN\n\tDECLARE c INT DEFAULT 0;  -- 定义局部变量\n\t\n\tSELECT COUNT(*) INTO c    -- 给c赋值\n\tFROM employees;\n\t\n\tRETURN c;                 -- 返回值\nEND $\n\nSELECT myf1()$\n```\n\n> 有参数，有返回\n\n``` sql\nCREATE FUNCTION myf2(empName VARCHAR(20)) RETURNS DOUBLE\nBEGIN\n\tSET @sal = 0;             -- 定义用户变量\n\t\n\tSELECT salary INTO @sal   -- 赋值\n\tFROM employees\n\tWHERE last_name = empName;\n\t\n\tRETURN @sal;\nEND $\n\nSELECT myf2('king') $\n```\n\n### 10.5 应用场景：批量插入数据脚本\n\n#### 环境准备\n\n> 1、建表SQL。\n\n```mysql\n/* 1.dept表 */\nCREATE TABLE `dept` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `deptno` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '部门id',\n  `dname` varchar(20) NOT NULL DEFAULT '' COMMENT '部门名字',\n  `loc` varchar(13) NOT NULL DEFAULT '' COMMENT '部门地址',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='部门表'\n\n/* 2.emp表 */\nCREATE TABLE `emp` (\n  `id` int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键',\n  `empno` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '员工编号',\n  `ename` varchar(20) NOT NULL DEFAULT '' COMMENT '员工名字',\n  `job` varchar(9) NOT NULL DEFAULT '' COMMENT '职位',\n  `mgr` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '上级编号',\n  `hiredata` date NOT NULL COMMENT '入职时间',\n  `sal` decimal(7,2) NOT NULL COMMENT '薪水',\n  `comm` decimal(7,2) NOT NULL COMMENT '分红',\n  `deptno` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '部门id',\n  PRIMARY KEY (`id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='员工表'\n```\n\n> 2、由于开启过慢查询日志，开启了`bin-log`，我们就必须为`function`指定一个参数，否则使用函数会报错。\n\n```shell\n# 在mysql中设置 \n# log_bin_trust_function_creators 默认是关闭的 需要手动开启\nmysql> SHOW VARIABLES LIKE 'log_bin_trust_function_creators';\n+---------------------------------+-------+\n| Variable_name                   | Value |\n+---------------------------------+-------+\n| log_bin_trust_function_creators | OFF   |\n+---------------------------------+-------+\n1 row in set (0.00 sec)\n\nmysql> SET GLOBAL log_bin_trust_function_creators=1;\nQuery OK, 0 rows affected (0.00 sec)\n```\n\n上述修改方式MySQL重启后会失败，在`my.cnf`配置文件下修改永久有效。\n\n```shell\n[mysqld]\nlog_bin_trust_function_creators=ON\n```\n\n#### 创建函数\n\n```mysql\n# 1、函数：随机产生字符串\nDELIMITER $$\nCREATE FUNCTION rand_string(n INT) RETURNS VARCHAR(255)\nBEGIN\n    DECLARE chars_str VARCHAR(100) DEFAULT 'abcdefghijklmnopqrstuvwsyzABCDEFGHIJKLMNOPQRSTUVWXYZ';\n    DECLARE return_str VARCHAR(255) DEFAULT '';\n    DECLARE i INT DEFAULT 0;\n    WHILE i < n DO\n    SET return_str = CONCAT(return_str,SUBSTRING(chars_str,FLOOR(1+RAND()*52),1));\n    SET i = i + 1;\n    END WHILE;\n    RETURN return_str;\nEND $$\n\n# 2、函数：随机产生部门编号\nDELIMITER $$\nCREATE FUNCTION rand_num() RETURNS INT(5)\nBEGIN\n    DECLARE i INT DEFAULT 0;\n    SET i = FLOOR(100 + RAND() * 10);\n    RETURN i;\nEND $$\n```\n\n#### 创建存储过程\n\n```mysql\n# 1、函数：向dept表批量插入\nDELIMITER $$\nCREATE PROCEDURE insert_dept(IN START INT(10),IN max_num INT(10))\nBEGIN\nDECLARE i INT DEFAULT 0;\n    SET autocommit = 0;\n    REPEAT\n    SET i = i + 1;\n    INSERT INTO dept(deptno,dname,loc) VALUES((START + i),rand_string(10),rand_string(8));\n    UNTIL i = max_num\n    END REPEAT;\n    COMMIT;\nEND $$\n\n# 2、函数：向emp表批量插入\nDELIMITER $$\nCREATE PROCEDURE insert_emp(IN START INT(10),IN max_num INT(10))\nBEGIN\nDECLARE i INT DEFAULT 0;\n    SET autocommit = 0;\n    REPEAT\n    SET i = i + 1;\n    INSERT INTO emp(empno,ename,job,mgr,hiredata,sal,comm,deptno) VALUES((START + i),rand_string(6),'SALESMAN',0001,CURDATE(),2000,400,rand_num());\n    UNTIL i = max_num\n    END REPEAT;\n    COMMIT;\nEND $$\n```\n\n#### 调用存储过程\n\n```mysql\n# 1、调用存储过程向dept表插入10个部门。\nDELIMITER ;\nCALL insert_dept(100,10);\n\n# 2、调用存储过程向emp表插入50万条数据。\nDELIMITER ;\nCALL insert_emp(100001,500000);\n```\n\n\n\n## 11. 权限管理和备份\n\n### 11.1 权限管理\n\n> SQL命令\n\n用户表：mysql.user（存储用户信息）\n\n本质：修改权限，添加用户等操作本质上是对这张表进行增删改查\n\n``` sql\n-- 创建用户： CREATE USER 用户名 IDENTIFIED BY '密码'\nCREATE USER zhangsan IDENTIFIED BY '123456';\n\n-- 修改密码（修改当前用户密码）\nSET PASSWORD = PASSWORD('111111');\n\n-- 修改密码（修改指定用户密码）\nSET PASSWORD FOR zhangsan = PASSWORD('111111');\n\n-- 重命名： RENAME USER 原名 TO 新名\nRENAME USER zhangsan TO zhangsanfeng;\n\n-- 用户授权： ALL PRIVILEGES 全部权限 TO 库.表\n-- ALL PRIVILEGES 除了给别人授权，其他都权限都有\nGRANT ALL PRIVILEGES ON *.* TO zhangsan;\n\n-- 查询权限\nSHOW GRANTS FOR zhangsan -- 查看指定用户的权限\nSHOW GRANTS FOR root@localhost\n\n-- 撤销权限： REVOKE 哪些权限 ON 在哪个库 FROM 给谁撤销\nREVOKE ALL PRIVILEGES ON *.* FROM zhangsan;\n\n-- 删除用户\nDROP USER zhangsan;\n```\n\n### 11.2 MySQL备份\n\n为什么要备份：\n\n- 保证重要的数据不丢失\n- 数据转移\n\nMySQL数据库备份的方式：\n\n- 直接拷贝物理文件，data目录\n- 在Navicat工具中手动导出\n- 使用命令行：mysqldump\n\n``` bash\n# =================================  导出 ===============================\n# mysqldump -h 主机 -u 用户名 -p 密码 数据库 表名 > 物理磁盘位置/文件名\nmysqldump -hlocalhost -uroot -p123456 schoool student > D:/student.sql\n\n# mysqldump -h 主机 -u 用户名 -p 密码 数据库 > 物理磁盘位置/文件名\nmysqldump -hlocalhost -uroot -p123456 schoool > D:/school.sql\n\n# =================================  导入 ===============================\n# 在登入的情况下，切换到指定数据库\nmysql -uroot -p123456\nmysql> USE school;\nmysql> source D:/student.sql # 或 source D:/school.sql\n```\n\n## 12. 数据库设计的三大范式\n\n### 12.1 为什么需要设计\n\n当数据库交复杂时，就需要设计\n\n**糟糕的数据库设计：**\n\n- 数据冗余，浪费空间\n- 数据库插入和删除都会麻烦/异常（屏蔽使用物理外键）\n- 程序的性能差\n\n**良好的数据库设计：**\n\n- 节省内存空间\n- 保证数据库的完整性\n- 方便开发系统\n\n**软件开发中，关于数据库的设计：**\n\n- 分析需求，分析业务和需要处理的数据库需求\n- 概要设计：设计关系图 E-R图\n\n**设计数据库的步骤：（个人博客）**\n\n- 收集信息，分析需求\n  - 用户表（用户登录注销，用户的个人信息，写博客，创建分类）\n  - 分类表（文章分类，谁创建的）\n  - 文章表（文章的信息）\n  - 评论表（评论的信息）\n  - 友链表（友链信息）\n  - 自定义表（系统信息，某个关键的字，或者一些主字段） 表中两列：key  | value\n- 标识实体（把需求落地到每个字段）\n- 标识实体之间的关系\n  - 写博客：user --> blog\n  - 创建分类：user --> category\n  - 关注：user --> user\n  - 友链：links\n  - 评论：user --> user --> blog\n\n### 12.2 三大范式\n\n> 三大范式：设计表的依据，按照这个三范式设计的表不会出现数据冗余 https://www.bilibili.com/video/BV1fx411X7BD?p=74\n\n**1. 第一范式（1NF）：原子性**\n\n任何一张表都应该有**主键**，并且每一个字段**原子性不可再分**，即每一列的信息不可再分\n\n**2. 第二范式（2NF）：不可部分依赖**\n\n前提：必须满足第一范式。所有非主键字段**完全依赖**主键，不能产生**部分依赖**。即每一列都只和主键相关，而不能只与主键的一部分相关（主要针对**联合主键**而言），例如，某表中有联合主键，某些非主键字段只依赖联合主键中的其中一个，不依赖于另一个，就产生了冗余\n\n**多对多，三张表，关系表两个外键。**若遇到不符合第二范式的表时，将一张**多对多**关系的表拆成**三张表**：\n\n- 两个表分别存储独立的信息，每个表有一个主键\n- 一张关系表，关系表里有两个外键，分别引用两个独立表\n\n**3. 第三范式（3NF）：不可传递依赖**\n\n前提：必须满足第一范式和第二范式。所有非主键字段**直接依赖**主键，不能产生**传递依赖**。\n\n**一对多，两张表，多的表加外键。**若遇到不符合第二范式的表时，将一张**一对多**关系的表拆成**两张表**：\n\n- 一张内容少的表，存储会产生传递依赖的信息\n- 另一张内容多的表加外键，引用第一张表\n\n**规范性和性能的问题：在实际的开发中，以满足客户的需求位置，有时候会拿冗余换执行速度**\n\n- 考虑商业化的需求和目标，数据库的性能更加重要\n- 在规范性能问题的时候，需要适当考虑一下规范性\n- 故意给某些表增加一些冗余的字段（从多表查询边单表查询）\n- 故意增加一些计算列（从大数据量降低为小数据量的查询：索引）\n\n","tags":["MySQL"],"categories":["MySQL"]},{"title":"【Java】稀疏矩阵","url":"/2021/03/27/【Java】稀疏矩阵/","content":"\n```java\npublic class SparesArray {\n    public static void main(String[] args) {\n        // 创建一个二维数组 11*11  0：没有旗子， 1：黑棋， 2：白棋\n        int[][] array1 = new int[11][11];\n        array1[1][2] = 1;\n        array1[2][3] = 2;\n\n        System.out.println(\"输出原始的矩阵\");\n\n        for (int[] ints : array1){\n            for (int anInt : ints){\n                System.out.print(anInt + \"\\t\");\n            }\n            System.out.println();\n        }\n\n        // 转换为稀疏数组\n        // 1. 获取有效值的个数\n        int sum = 0;\n        for (int i = 0; i < 11; i++){\n            for (int j = 0; j < 11; j++) {\n                if (array1[i][j] != 0) {\n                    sum++;\n                }\n            }\n        }\n        System.out.println(\"有效值个数：\" + sum);\n\n        // 2. 创建一个稀疏数组的数组\n        int[][] array2 = new int[sum+1][3];\n        array2[0][0] = 11;\n        array2[0][1] = 11;\n        array2[0][2] = sum;\n\n        // 遍历二维数组，将非零值放入稀疏数组\n        int count = 0;\n        for (int i = 0; i < array1.length; i++){\n            for (int j = 0; j < array1[i].length; j++) {\n                if (array1[i][j] != 0){\n                    count++;\n                    array2[count][0] = i;\n                    array2[count][1] = j;\n                    array2[count][2] = array1[i][j];\n                }\n            }\n        }\n\n        System.out.println(\"稀疏数组\");\n        for (int i = 0; i < array2.length; i++){\n            System.out.println(array2[i][0] + \"\\t\" + array2[i][1] + \"\\t\" + array2[i][2]);\n        }\n\n        // ===============================================================\n        // 稀疏数组还原\n        System.out.println(\"还原\");\n\n        // 1. 读取稀疏数组\n        int[][] array3 = new int[array2[0][0]][array2[0][1]];\n\n        // 2. 给其中元素还原它的值\n        for (int i = 1; i < array2.length; i++){\n            array3[array2[i][0]][array2[i][1]] = array2[i][2];\n        }\n\n        // 3. 打印\n        for (int[] ints : array3){\n            for (int anInt : ints){\n                System.out.print(anInt + \"\\t\");\n            }\n            System.out.println();\n        }\n\n    }\n}\n```","tags":["Java"],"categories":["Java"]},{"title":"【Java】Stream API","url":"/2021/03/26/【Java】Stream-API/","content":"\n## Stream API\n\nJava8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一个则是 Stream API。 Stream API ( `java.util.stream`) 把真正的**函数式编程风格**引入到Java中。这是目前为止对Java类库最好的补充，因为Stream API可以极大提供Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。\n\nStream 是 Java8 中处理**集合**的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的**查找**、**过滤**和**映射数据**等操作。 使用 Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。 也可以使用 Stream API 来并行执行操作。简言之，Stream API 提供了一种高效且易于使用的处理数据的方式。\n\nStream 是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。 “集合讲的是数据，Stream讲的是计算！” 注意：\n\n- Stream 自己**不会存储元素**。\n- Stream **不会改变源对象**。相反，他们会返回一个持有结果的新Stream。\n- Stream 操作是**延迟执行**的。这意味着他们会等到需要结果的时候才执行。\n\n### 为什么要是用 Stream API\n\n实际开发中，项目中多数数据源都来自于Mysql，Oracle等。但现在数据源可以更多了，有MongDB，Radis 等，而这些 NoSQL 的数据就需要 Java 层面去处理。 \n\nStream 和 Collection 集合的区别：Collection 是一种**静态的内存数据结构**，而 Stream 是有关**计算**的。前者是主要**面向内存**，存储在内存中， 后者主要是**面向 CPU**，通过 CPU 实现计算。\n\n### Stream 的使用流程\n\n![image-20210626155810489](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626155810489.png)\n\n使用流程的注意点：\n- 一个中间操作链，对数据源的数据进行处理\n- 一旦执行终止操作，就执行中间操作链，并产生结果。之后，不会再被使用\n\n### 创建 Stream 的方式\n\n#### 方式一：通过集合\n\n![image-20210626160117139](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160117139.png)\n\n``` java\n//创建Stream方式一：通过集合\n@Test\npublic void test1(){\n    List<Employee> employees = EmployeeData.getEmployees();\n\n    //default Stream<E> stream() : 返回一个顺序流\n    Stream<Employee> stream = employees.stream();\n\n    //default Stream<E> parallelStream() : 返回一个并行流\n    Stream<Employee> parallelStream = employees.parallelStream();\n}\n```\n\n#### 方式二：通过数组\n\n![image-20210626160210175](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160210175.png)\n\n``` java\n//创建Stream方式二：通过数组\n@Test\npublic void test2(){\n    int[] arr = new int[]{1,2,3,4,5,6};\n    //调用Arrays类的static <T> Stream<T> stream(T[] array): 返回一个流\n    IntStream stream = Arrays.stream(arr);\n\n    Employee e1 = new Employee(1001,\"Tom\");\n    Employee e2 = new Employee(1002,\"Jerry\");\n    Employee[] arr1 = new Employee[]{e1,e2};\n    Stream<Employee> stream1 = Arrays.stream(arr1);\n}\n```\n\n#### 方式三：通过 Stream 的 of()\n\n![image-20210626160255007](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160255007.png)\n\n``` java\n//创建Stream方式三：通过Stream的of()\n@Test\npublic void test3(){\n    Stream<Integer> stream = Stream.of(1, 2, 3, 4, 5, 6);\n}\n```\n\n#### 方式四：创建无限流\n\n![image-20210626160338594](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160338594.png)\n\n``` java\n//创建Stream方式四：创建无限流\n@Test\npublic void test4(){\n    //迭代\n    //public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f)\n    //遍历前10个偶数\n    Stream.iterate(0, t -> t + 2).limit(10).forEach(System.out::println);\n\n    //生成\n    //public static<T> Stream<T> generate(Supplier<T> s)\n    Stream.generate(Math::random).limit(10).forEach(System.out::println);\n}\n```\n\n总结四种方式：\n\n``` java\n//创建Stream方式一：通过集合\n@Test\npublic void test1(){\n    List<Employee> employees = EmployeeData.getEmployees();\n\n    //default Stream<E> stream() : 返回一个顺序流\n    Stream<Employee> stream = employees.stream();\n\n    //default Stream<E> parallelStream() : 返回一个并行流\n    Stream<Employee> parallelStream = employees.parallelStream();\n}\n\n//创建Stream方式二：通过数组\n@Test\npublic void test2(){\n    int[] arr = new int[]{1,2,3,4,5,6};\n    //调用Arrays类的static <T> Stream<T> stream(T[] array): 返回一个流\n    IntStream stream = Arrays.stream(arr);\n\n    Employee e1 = new Employee(1001,\"Tom\");\n    Employee e2 = new Employee(1002,\"Jerry\");\n    Employee[] arr1 = new Employee[]{e1,e2};\n    Stream<Employee> stream1 = Arrays.stream(arr1);\n}\n\n//创建Stream方式三：通过Stream的of()\n@Test\npublic void test3(){\n    Stream<Integer> stream = Stream.of(1, 2, 3, 4, 5, 6);\n}\n\n//创建Stream方式四：创建无限流\n@Test\npublic void test4(){\n    //迭代\n    //public static<T> Stream<T> iterate(final T seed, final UnaryOperator<T> f)\n    //遍历前10个偶数\n    Stream.iterate(0, t -> t + 2).limit(10).forEach(System.out::println);\n\n    //生成\n    //public static<T> Stream<T> generate(Supplier<T> s)\n    Stream.generate(Math::random).limit(10).forEach(System.out::println);\n}\n```\n\n### Stream 中间操作\n\n多个中间操作可以连接起来形成一个流水线，除非流水线上触发终止操作，否则中间操作不会执行任何的处理！而在终止操作时一次性全部处理，称为“惰性求值”。\n\n![image-20210626160546946](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160546946.png)\n\n![image-20210626160550965](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160550965.png)\n\n![image-20210626160554806](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160554806.png)\n\n``` java\npublic class StreamAPITest1 {\n\n    //1-筛选与切片\n    @Test\n    public void test1(){\n        List<Employee> list = EmployeeData.getEmployees();\n        // filter(Predicate p)——接收 Lambda ， 从流中排除某些元素。\n        Stream<Employee> stream = list.stream();\n        //练习：查询员工表中薪资大于7000的员工信息\n        stream.filter(e -> e.getSalary() > 7000).forEach(System.out::println);\n\n        System.out.println();\n        //limit(n)——截断流，使其元素不超过给定数量。\n        list.stream().limit(3).forEach(System.out::println);\n        System.out.println();\n\n        //skip(n) —— 跳过元素，返回一个扔掉了前 n 个元素的流。若流中元素不足 n 个，则返回一个空流。与 limit(n) 互补\n        list.stream().skip(3).forEach(System.out::println);\n\n        System.out.println();\n        //distinct()——筛选，通过流所生成元素的 hashCode() 和 equals() 去除重复元素\n\n        list.add(new Employee(1010,\"刘强东\",40,8000));\n        list.add(new Employee(1010,\"刘强东\",41,8000));\n        list.add(new Employee(1010,\"刘强东\",40,8000));\n        list.add(new Employee(1010,\"刘强东\",40,8000));\n        list.add(new Employee(1010,\"刘强东\",40,8000));\n\n        //System.out.println(list);\n\n        list.stream().distinct().forEach(System.out::println);\n    }\n\n    //映射\n    @Test\n    public void test2(){\n        //map(Function f)——接收一个函数作为参数，将元素转换成其他形式或提取信息，该函数会被应用到每个元素上，并将其映射成一个新的元素。\n        List<String> list = Arrays.asList(\"aa\", \"bb\", \"cc\", \"dd\");\n        list.stream().map(str -> str.toUpperCase()).forEach(System.out::println);\n\n        //练习1：获取员工姓名长度大于3的员工的姓名。\n        List<Employee> employees = EmployeeData.getEmployees();\n        Stream<String> namesStream = employees.stream().map(Employee::getName);\n        namesStream.filter(name -> name.length() > 3).forEach(System.out::println);\n        System.out.println();\n        //练习2：\n        Stream<Stream<Character>> streamStream = list.stream().map(StreamAPITest1::fromStringToStream);\n        streamStream.forEach(s ->{\n            s.forEach(System.out::println);\n        });\n        System.out.println();\n        //flatMap(Function f)——接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流。\n        Stream<Character> characterStream = list.stream().flatMap(StreamAPITest1::fromStringToStream);\n        characterStream.forEach(System.out::println);\n\n    }\n\n    //将字符串中的多个字符构成的集合转换为对应的Stream的实例\n    public static Stream<Character> fromStringToStream(String str){//aa\n        ArrayList<Character> list = new ArrayList<>();\n        for(Character c : str.toCharArray()){\n            list.add(c);\n        }\n        return list.stream();\n    }\n\n    @Test\n    public void test3(){\n        ArrayList list1 = new ArrayList();\n        list1.add(1);\n        list1.add(2);\n        list1.add(3);\n\n        ArrayList list2 = new ArrayList();\n        list2.add(4);\n        list2.add(5);\n        list2.add(6);\n\n        //list1.add(list2);\n        list1.addAll(list2);\n        System.out.println(list1);\n    }\n\n    //3-排序\n    @Test\n    public void test4(){\n        //sorted()——自然排序\n        List<Integer> list = Arrays.asList(12, 43, 65, 34, 87, 0, -98, 7);\n        list.stream().sorted().forEach(System.out::println);\n        //抛异常，原因:Employee没有实现Comparable接口\n        //List<Employee> employees = EmployeeData.getEmployees();\n        //employees.stream().sorted().forEach(System.out::println);\n        \n        //sorted(Comparator com)——定制排序\n\n        List<Employee> employees = EmployeeData.getEmployees();\n        employees.stream().sorted( (e1,e2) -> {\n\n            int ageValue = Integer.compare(e1.getAge(),e2.getAge());\n            if(ageValue != 0){\n                return ageValue;\n            }else{\n                return -Double.compare(e1.getSalary(),e2.getSalary());\n            }\n\n        }).forEach(System.out::println);\n    }\n}\n```\n\n### Stream 终止操作\n\n终端操作会从流的流水线生成结果。其结果可以是任何不是流的值，例如：`List`、`Integer`，甚至是 `void `。流进行了终止操作后，不能再次使用。\n\n![image-20210626160640867](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160640867.png)\n\n![image-20210626160645113](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160645113.png)\n\n![image-20210626160649435](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160649435.png)\n\n![image-20210626160653025](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160653025.png)\n\nCollector需要使用Collectors提供实例。\n\n![image-20210626160700820](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626160700820.png)\n\n``` java\npublic class StreamAPITest2 {\n\n    //1-匹配与查找\n    @Test\n    public void test1(){\n        List<Employee> employees = EmployeeData.getEmployees();\n\n        //allMatch(Predicate p)——检查是否匹配所有元素。\n        //练习：是否所有的员工的年龄都大于18\n        boolean allMatch = employees.stream().allMatch(e -> e.getAge() > 18);\n        System.out.println(allMatch);\n\n        //anyMatch(Predicate p)——检查是否至少匹配一个元素。\n        //练习：是否存在员工的工资大于 10000\n        boolean anyMatch = employees.stream().anyMatch(e -> e.getSalary() > 10000);\n        System.out.println(anyMatch);\n\n        //noneMatch(Predicate p)——检查是否没有匹配的元素。\n        //练习：是否存在员工姓“雷”\n        boolean noneMatch = employees.stream().noneMatch(e -> e.getName().startsWith(\"雷\"));\n        System.out.println(noneMatch);\n        //findFirst——返回第一个元素\n        Optional<Employee> employee = employees.stream().findFirst();\n        System.out.println(employee);\n        //findAny——返回当前流中的任意元素\n        Optional<Employee> employee1 = employees.parallelStream().findAny();\n        System.out.println(employee1);\n    }\n\n    @Test\n    public void test2(){\n        List<Employee> employees = EmployeeData.getEmployees();\n        // count——返回流中元素的总个数\n        long count = employees.stream().filter(e -> e.getSalary() > 5000).count();\n        System.out.println(count);\n        //max(Comparator c)——返回流中最大值\n        //练习：返回最高的工资：\n        Stream<Double> salaryStream = employees.stream().map(e -> e.getSalary());\n        Optional<Double> maxSalary = salaryStream.max(Double::compare);\n        System.out.println(maxSalary);\n        //min(Comparator c)——返回流中最小值\n        //练习：返回最低工资的员工\n        Optional<Employee> employee = employees.stream().min((e1, e2) -> Double.compare(e1.getSalary(), e2.getSalary()));\n        System.out.println(employee);\n        System.out.println();\n        //forEach(Consumer c)——内部迭代\n        employees.stream().forEach(System.out::println);\n\n        //使用集合的遍历操作\n        employees.forEach(System.out::println);\n    }\n\n    //2-归约\n    @Test\n    public void test3(){\n        //reduce(T identity, BinaryOperator)——可以将流中元素反复结合起来，得到一个值。返回 T\n        //练习1：计算1-10的自然数的和\n        List<Integer> list = Arrays.asList(1,2,3,4,5,6,7,8,9,10);\n        Integer sum = list.stream().reduce(0, Integer::sum);\n        System.out.println(sum);\n\n        //reduce(BinaryOperator) ——可以将流中元素反复结合起来，得到一个值。返回 Optional<T>\n        //练习2：计算公司所有员工工资的总和\n        List<Employee> employees = EmployeeData.getEmployees();\n        Stream<Double> salaryStream = employees.stream().map(Employee::getSalary);\n        //Optional<Double> sumMoney = salaryStream.reduce(Double::sum);\n        Optional<Double> sumMoney = salaryStream.reduce((d1,d2) -> d1 + d2);\n        System.out.println(sumMoney.get());\n    }\n\n    //3-收集\n    @Test\n    public void test4(){\n        //collect(Collector c)——将流转换为其他形式。接收一个 Collector接口的实现，用于给Stream中元素做汇总的方法\n        //练习1：查找工资大于6000的员工，结果返回为一个List或Set\n        List<Employee> employees = EmployeeData.getEmployees();\n        List<Employee> employeeList = employees.stream().filter(e -> e.getSalary() > 6000).collect(Collectors.toList());\n\n        employeeList.forEach(System.out::println);\n        System.out.println();\n        Set<Employee> employeeSet = employees.stream().filter(e -> e.getSalary() > 6000).collect(Collectors.toSet());\n\n        employeeSet.forEach(System.out::println);\n    }\n}\n```\n\n## Optional 类\n\nOptional 类：为了解决java中的空指针问题而生。\n\n到目前为止，臭名昭著的空指针异常是导致Java应用程序失败的最常见原因。 以前，为了解决空指针异常，Google公司著名的Guava项目引入了Optional类，Guava通过使用检查空值的方式来防止代码污染，它鼓励程序员写更干净的代 码。受到Google Guava的启发，Optional类已经成为Java 8类库的一部分。 \n\nOptional 类(`java.util.Optional`) 是一个容器类，它可以保存类型T的值，代表这个值存在。或者仅仅保存 null，表示这个值不存在。原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。 \n\nOptional类的 Javadoc 描述如下：这是一个可以为 null 的容器对象。如果值存在则`isPresent()`方法会返回true，调用`get()`方法会返回该对象。\n\n![image-20210626162456425](/images/%E3%80%90Java%E3%80%91Stream-API/image-20210626162456425.png)\n\n\n\n使用举例：\n\n``` java\n@Test\npublic void test1(){\n    //empty():创建的Optional对象内部的value = null\n    Optional<Object> op1 = Optional.empty();\n    if(!op1.isPresent()){//Optional封装的数据是否包含数据\n        System.out.println(\"数据为空\");\n\n    }\n    System.out.println(op1);\n    System.out.println(op1.isPresent());\n    //如果Optional封装的数据value为空，则get()报错。否则，value不为空时，返回value.\n    //System.out.println(op1.get());\n\n}\n\n@Test\npublic void test2(){\n    String str = \"hello\";\n    //str = null;\n    //of(T t):封装数据t生成Optional对象。要求t非空，否则报错。\n    Optional<String> op1 = Optional.of(str);\n    //get()通常与of()方法搭配使用。用于获取内部的封装的数据value\n    String str1 = op1.get();\n    System.out.println(str1);\n\n}\n\n@Test\npublic void test3(){\n    String str = \"beijing\";\n    str = null;\n    //ofNullable(T t) ：封装数据t赋给Optional内部的value。不要求t非空\n    Optional<String> op1 = Optional.ofNullable(str);\n    //orElse(T t1):如果Optional内部的value非空，则返回此value值。如果\n    //value为空，则返回t1.\n    String str2 = op1.orElse(\"shanghai\");\n\n    System.out.println(str2);//\n}\n```\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】Lambda 表达式","url":"/2021/03/26/【Java】Lambda表达式/","content":"\n## Lambda 表达式\n\nLambda 是一个匿名函数，我们可以把 Lambda 表达式理解为是一段可以传递的代码（将代码像数据一样进行传递）。使用它可以写出更简洁、更灵活的代码。作为一种更紧凑的代码风格，使Java的语言表达能力得到了提升、\n\n从匿名内部类到 Lambda 的转换举例1：\n\n匿名内部类形式：\n\n```java\nRunnable r1 = new Runnable() {\n    @Override\n    public void run() {\n        System.out.println(\"我爱北京天安门\");\n    }\n};\nr1.run();\n```\n\nLambda 表达式形式：\n\n\n``` java\nRunnable r2 = () -> System.out.println(\"我爱北京故宫\");\nr2.run();\n```\n\n从匿名内部类到Lambda 的转换举例2：\n\n匿名内部类形式：\n\n``` java\nComparator<Integer> com1 = new Comparator<Integer>() {\n    @Override\n    public int compare(Integer o1, Integer o2) {\n        return Integer.compare(o1,o2);\n    }\n};\nint compare1 = com1.compare(12,21);\n```\n\nLambda 表达式形式：\n\n``` java\nComparator<Integer> com2 = (o1,o2) -> Integer.compare(o1,o2);\nint compare2 = com2.compare(32,21);\n```\n\n方法引用形式：\n\n``` java\nComparator<Integer> com3 = Integer :: compare;\nint compare3 = com3.compare(32,21);\n```\n\n### 语法\n\nLambda 表达式：在Java 8语言中引入的一种新的语法元素和操作符。这个操作符为 “->” ， 该操作符被称为 Lambda 操作符或箭头操作符。它将 Lambda 分为两个部分： \n\n- 左侧：指定了 Lambda 表达式需要的参数列表 \n- 右侧：指定了 Lambda体 ，是抽象方法的实现逻辑，也即 Lambda 表达式要执行的功能。\n\n### 六种使用方式\n\n![image-20210626150542844](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626150542844.png)\n\n![image-20210626150547722](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626150547722.png)\n\n总结六种情况：\n\n- 左边：lambda 形参列表的参数类型可以省略(类型推断)；如果 lambda 形参列表只一个参数，其一对()也可以省略\n- 右边：lambda 体应该使用一对{}包裹；如果 lambda 体只一条执行语句（可能是`return`语句，省略这一对{}和`return`关键字）\n\n### 类型推断\n\n上述 Lambda 表达式中的参数类型都是由编译器推断得出的。Lambda 表达式中无需指定类型，程序依然可以编译，这是因为 javac 根据程序的上下文，在后台推断出了参数的类型。Lambda 表达式的类型依赖于上下文环境，是由编译器推断出来的。这就是所谓的“类型推断”。\n\n![image-20210626150920181](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626150920181.png)\n\n## 函数式接口\n\n### 定义\n\n只包含**一个抽象方法的接口**，称为**函数式接口**。 \n\n- 可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda 表达式抛出一个受检异常(即：非运行时异常)，那么该异常需要在目标接口的抽象方法上进行声明）。 \n- 可以在一个接口上使用` @FunctionalInterface` 注解，这样可以检查它是否是一个函数式接口。\n- 同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。 \n- 在`java.util.function`包下定义了Java 8 的丰富的函数式接口\n\n### 如何理解函数式接口\n\nJava从诞生日起就是一直倡导“一切皆对象”，在Java里面面向对象(OOP) 编程是一切。但是随着python、scala等语言的兴起和新技术的挑战，Java不得不做出调整以便支持更加广泛的技术要求，也即java不但可以支持OOP还 可以支持OOF（面向函数编程） \n\n在函数式编程语言当中，函数被当做一等公民对待。在将函数作为一等公民的编程语言中，Lambda表达式的类型是函数。但是在Java8中，有所不同。在 Java8中，Lambda表达式是对象，而不是函数，它们必须依附于一类特别的 对象类型——函数式接口。 \n\n简单的说，在Java8中，**Lambda表达式就是一个函数式接口的实例**。这就是 Lambda表达式和函数式接口的关系。也就是说，只要一个对象是函数式接口的实例，那么该对象就可以用 Lambda 表达式来表示。 \n\n所以以前用**匿名实现类**表示的现在都可以用 Lambda 表达式来写。\n\n**Lambda表达式的本质：作为函数式接口的实例**\n\n函数式接口举例：\n\n![image-20210626151346747](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626151346747.png)\n\n![image-20210626151503858](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626151503858.png)\n\n### Java 内置四大核心函数式接口\n\n![image-20210626153213826](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626153213826.png)\n\n### 其他函数式接口\n\n![image-20210626153330040](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626153330040.png)\n\n## 方法引用\n\n方法引用可以看做是 Lambda 表达式深层次的表达。换句话说，**方法引用就是Lambda表达式**，也就是函数式接口的一个实例，通过方法的名字来指向一个方法。\n\n- 当要传递给 Lambda 体的操作，已经有实现的方法了，可以使用方法引用。\n- 要求：实现接口的抽象方法的参数列表和返回值类型，必须与方法引用的方法的参数列表和返回值类型保持一致。\n- 格式：使用操作符 “::” 将类(或对象) 与方法名分隔开来。 \n- 如下三种主要使用情况： \n  - 情况一：对象::实例方法名 \n  - 情况二：类::静态方法名 \n  - 情况三：类::实例方法名\n\n要求接口中的抽象方法的形参列表和返回值类型与方法引用的方法的形参列表和返回值类型相同！（针对于情况1和情况2）当函数式接口方法的第一个参数是需要引用方法的调用者，并且第二个参数是需要引用方法的参数(或无参数)时：`ClassName::methodName`（针对于情况3）\n\n![image-20210626153934414](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626153934414.png)\n\n![image-20210626154023663](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626154023663.png)\n\n使用举例：\n\n``` java\n// 情况一：对象 :: 实例方法\n//Consumer中的void accept(T t)\n//PrintStream中的void println(T t)\n@Test\npublic void test1() {\n    Consumer<String> con1 = str -> System.out.println(str);\n    con1.accept(\"北京\");\n\n    System.out.println(\"*******************\");\n    PrintStream ps = System.out;\n    Consumer<String> con2 = ps::println;\n    con2.accept(\"beijing\");\n}\n\n//Supplier中的T get()\n//Employee中的String getName()\n@Test\npublic void test2() {\n    Employee emp = new Employee(1001,\"Tom\",23,5600);\n\n    Supplier<String> sup1 = () -> emp.getName();\n    System.out.println(sup1.get());\n\n    System.out.println(\"*******************\");\n    Supplier<String> sup2 = emp::getName;\n    System.out.println(sup2.get());\n\n}\n\n// 情况二：类 :: 静态方法\n//Comparator中的int compare(T t1,T t2)\n//Integer中的int compare(T t1,T t2)\n@Test\npublic void test3() {\n    Comparator<Integer> com1 = (t1,t2) -> Integer.compare(t1,t2);\n    System.out.println(com1.compare(12,21));\n\n    System.out.println(\"*******************\");\n\n    Comparator<Integer> com2 = Integer::compare;\n    System.out.println(com2.compare(12,3));\n\n}\n\n//Function中的R apply(T t)\n//Math中的Long round(Double d)\n@Test\npublic void test4() {\n    Function<Double,Long> func = new Function<Double, Long>() {\n        @Override\n        public Long apply(Double d) {\n            return Math.round(d);\n        }\n    };\n\n    System.out.println(\"*******************\");\n\n    Function<Double,Long> func1 = d -> Math.round(d);\n    System.out.println(func1.apply(12.3));\n\n    System.out.println(\"*******************\");\n\n    Function<Double,Long> func2 = Math::round;\n    System.out.println(func2.apply(12.6));\n}\n\n// 情况：类 :: 实例方法  (难度)\n// Comparator中的int comapre(T t1,T t2)\n// String中的int t1.compareTo(t2)\n@Test\npublic void test5() {\n    Comparator<String> com1 = (s1,s2) -> s1.compareTo(s2);\n    System.out.println(com1.compare(\"abc\",\"abd\"));\n\n    System.out.println(\"*******************\");\n\n    Comparator<String> com2 = String :: compareTo;\n    System.out.println(com2.compare(\"abd\",\"abm\"));\n}\n\n//BiPredicate中的boolean test(T t1, T t2);\n//String中的boolean t1.equals(t2)\n@Test\npublic void test6() {\n    BiPredicate<String,String> pre1 = (s1,s2) -> s1.equals(s2);\n    System.out.println(pre1.test(\"abc\",\"abc\"));\n\n    System.out.println(\"*******************\");\n    BiPredicate<String,String> pre2 = String :: equals;\n    System.out.println(pre2.test(\"abc\",\"abd\"));\n}\n\n// Function中的R apply(T t)\n// Employee中的String getName();\n@Test\npublic void test7() {\n    Employee employee = new Employee(1001, \"Jerry\", 23, 6000);\n\n    Function<Employee,String> func1 = e -> e.getName();\n    System.out.println(func1.apply(employee));\n\n    System.out.println(\"*******************\");\n\n    Function<Employee,String> func2 = Employee::getName;\n    System.out.println(func2.apply(employee));\n\n}\n```\n\n\n\n\n\n\n\n### 构造器引用\n\n![image-20210626154608885](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626154608885.png)\n\n使用举例：\n\n``` java\n//Supplier中的T get()\n//Employee的空参构造器：Employee()\n@Test\npublic void test1(){\n\n    Supplier<Employee> sup = new Supplier<Employee>() {\n        @Override\n        public Employee get() {\n            return new Employee();\n        }\n    };\n    System.out.println(\"*******************\");\n\n    Supplier<Employee>  sup1 = () -> new Employee();\n    System.out.println(sup1.get());\n\n    System.out.println(\"*******************\");\n\n    Supplier<Employee>  sup2 = Employee :: new;\n    System.out.println(sup2.get());\n}\n\n//Function中的R apply(T t)\n@Test\npublic void test2(){\n    Function<Integer,Employee> func1 = id -> new Employee(id);\n    Employee employee = func1.apply(1001);\n    System.out.println(employee);\n\n    System.out.println(\"*******************\");\n\n    Function<Integer,Employee> func2 = Employee :: new;\n    Employee employee1 = func2.apply(1002);\n    System.out.println(employee1);\n\n}\n\n//BiFunction中的R apply(T t,U u)\n@Test\npublic void test3(){\n    BiFunction<Integer,String,Employee> func1 = (id,name) -> new Employee(id,name);\n    System.out.println(func1.apply(1001,\"Tom\"));\n\n    System.out.println(\"*******************\");\n\n    BiFunction<Integer,String,Employee> func2 = Employee :: new;\n    System.out.println(func2.apply(1002,\"Tom\"));\n\n}\n```\n\n\n\n### 数组引用\n\n![image-20210626154622412](/images/%E3%80%90Java%E3%80%91Lambda%E8%A1%A8%E8%BE%BE%E5%BC%8F/image-20210626154622412.png)\n\n使用举例：\n\n``` java\n//Function中的R apply(T t)\n@Test\npublic void test4(){\n    Function<Integer,String[]> func1 = length -> new String[length];\n    String[] arr1 = func1.apply(5);\n    System.out.println(Arrays.toString(arr1));\n\n    System.out.println(\"*******************\");\n\n    Function<Integer,String[]> func2 = String[] :: new;\n    String[] arr2 = func2.apply(10);\n    System.out.println(Arrays.toString(arr2));\n}\n```\n\n​\t","tags":["Java"],"categories":["Java"]},{"title":"【Java】网络编程","url":"/2021/03/25/【Java】网络编程/","content":"\n## InetAddress\n\n``` java\npublic static void main(String[] args) {\n\n    try {\n        //File file = new File(\"hello.txt\");\n        InetAddress inet1 = InetAddress.getByName(\"192.168.10.14\");\n\n        System.out.println(inet1);\n\n        InetAddress inet2 = InetAddress.getByName(\"www.baidu.com\");\n        System.out.println(inet2);\n\n        InetAddress inet3 = InetAddress.getByName(\"127.0.0.1\");\n        System.out.println(inet3);\n\n        //获取本地ip\n        InetAddress inet4 = InetAddress.getLocalHost();\n        System.out.println(inet4);\n\n        //getHostName()\n        System.out.println(inet2.getHostName());\n        //getHostAddress()\n        System.out.println(inet2.getHostAddress());\n\n    } catch (UnknownHostException e) {\n        e.printStackTrace();\n    }\n}\n```\n\n## TCP Socket\n\n``` java\npublic class TCPTest1 {\n\n    //客户端\n    @Test\n    public void client()  {\n        Socket socket = null;\n        OutputStream os = null;\n        try {\n            //1.创建Socket对象，指明服务器端的ip和端口号\n            InetAddress inet = InetAddress.getByName(\"192.168.14.100\");\n            socket = new Socket(inet,8899);\n            //2.获取一个输出流，用于输出数据\n            os = socket.getOutputStream();\n            //3.写出数据的操作\n            os.write(\"你好，我是客户端mm\".getBytes());\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //4.资源的关闭\n            if(os != null){\n                try {\n                    os.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n            if(socket != null){\n                try {\n                    socket.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n        }\n\n\n\n    }\n    //服务端\n    @Test\n    public void server()  {\n\n        ServerSocket ss = null;\n        Socket socket = null;\n        InputStream is = null;\n        ByteArrayOutputStream baos = null;\n        try {\n            //1.创建服务器端的ServerSocket，指明自己的端口号\n            ss = new ServerSocket(8899);\n            //2.调用accept()表示接收来自于客户端的socket\n            socket = ss.accept();\n            //3.获取输入流\n            is = socket.getInputStream();\n\n            //不建议这样写，可能会有乱码\n            //        byte[] buffer = new byte[1024];\n            //        int len;\n            //        while((len = is.read(buffer)) != -1){\n            //            String str = new String(buffer,0,len);\n            //            System.out.print(str);\n            //        }\n            //4.读取输入流中的数据\n            baos = new ByteArrayOutputStream();\n            byte[] buffer = new byte[5];\n            int len;\n            while((len = is.read(buffer)) != -1){\n                baos.write(buffer,0,len);\n            }\n\n            System.out.println(baos.toString());\n\n            System.out.println(\"收到了来自于：\" + socket.getInetAddress().getHostAddress() + \"的数据\");\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if(baos != null){\n                //5.关闭资源\n                try {\n                    baos.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(is != null){\n                try {\n                    is.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(socket != null){\n                try {\n                    socket.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(ss != null){\n                try {\n                    ss.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n}\n\n```\n\n``` java\npublic class TCPTest2 {\n\n    /*\n        这里涉及到的异常，应该使用try-catch-finally处理\n    */\n    @Test\n    public void client() throws IOException {\n        //1.\n        Socket socket = new Socket(InetAddress.getByName(\"127.0.0.1\"),9090);\n        //2.\n        OutputStream os = socket.getOutputStream();\n        //3.\n        FileInputStream fis = new FileInputStream(new File(\"beauty.jpg\"));\n        //4.\n        byte[] buffer = new byte[1024];\n        int len;\n        while((len = fis.read(buffer)) != -1){\n            os.write(buffer,0,len);\n        }\n        //关闭数据的输出\n        socket.shutdownOutput();\n\n        //5.接收来自于服务器端的数据，并显示到控制台上\n        InputStream is = socket.getInputStream();\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        byte[] bufferr = new byte[20];\n        int len1;\n        while((len1 = is.read(buffer)) != -1){\n            baos.write(buffer,0,len1);\n        }\n\n        System.out.println(baos.toString());\n\n        //6.\n        fis.close();\n        os.close();\n        socket.close();\n        baos.close();\n    }\n\n    /*\n    这里涉及到的异常，应该使用try-catch-finally处理\n     */\n    @Test\n    public void server() throws IOException {\n        //1.\n        ServerSocket ss = new ServerSocket(9090);\n        //2.\n        Socket socket = ss.accept();\n        //3.\n        InputStream is = socket.getInputStream();\n        //4.\n        FileOutputStream fos = new FileOutputStream(new File(\"beauty.jpg\"));\n        //5.\n        byte[] buffer = new byte[1024];\n        int len;\n        while((len = is.read(buffer)) != -1){\n            fos.write(buffer,0,len);\n        }\n\n        System.out.println(\"图片传输完成\");\n\n        //6.服务器端给予客户端反馈\n        OutputStream os = socket.getOutputStream();\n        os.write(\"你好！\".getBytes());\n\n        //7.\n        fos.close();\n        is.close();\n        socket.close();\n        ss.close();\n        os.close();\n\n    }\n}\n\n```\n\n## UDP DatagramSocket\n\n``` java\npublic class UDPTest {\n\n    //发送端\n    @Test\n    public void sender() throws IOException {\n\n        DatagramSocket socket = new DatagramSocket();\n\n        String str = \"我是UDP方式发送的导弹\";\n        byte[] data = str.getBytes();\n        InetAddress inet = InetAddress.getLocalHost();\n        DatagramPacket packet = new DatagramPacket(data,0,data.length,inet,9090);\n\n        socket.send(packet);\n\n        socket.close();\n\n    }\n    //接收端\n    @Test\n    public void receiver() throws IOException {\n\n        DatagramSocket socket = new DatagramSocket(9090);\n\n        byte[] buffer = new byte[100];\n        DatagramPacket packet = new DatagramPacket(buffer,0,buffer.length);\n\n        socket.receive(packet);\n\n        System.out.println(new String(packet.getData(),0,packet.getLength()));\n\n        socket.close();\n    }\n}\n```\n\n## URL\n\nURL:统一资源定位符，对应着互联网的某一资源地址。\n\n格式：http://localhost:8080/examples/beauty.jpg?username=Tom\n\n协议  主机名  端口号 资源地址  参数列表\n\n``` java\npublic class URLTest {\n\n    public static void main(String[] args) {\n        try {\n            URL url = new URL(\"http://localhost:8080/examples/beauty.jpg?username=Tom\");\n//            public String getProtocol(  )     获取该URL的协议名\n            System.out.println(url.getProtocol());\n//            public String getHost(  )           获取该URL的主机名\n            System.out.println(url.getHost());\n//            public String getPort(  )            获取该URL的端口号\n            System.out.println(url.getPort());\n//            public String getPath(  )           获取该URL的文件路径\n            System.out.println(url.getPath());\n//            public String getFile(  )             获取该URL的文件名\n            System.out.println(url.getFile());\n//            public String getQuery(   )        获取该URL的查询名\n            System.out.println(url.getQuery());\n        } catch (MalformedURLException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】反射","url":"/2021/03/23/【Java】反射/","content":"\n## 反射概述\n\nReflection（反射）是被视为**动态语言**的关键，反射机制允许程序在执行期借助于Reflection API取得任何类的内部信息，并能直接操作意对象部属性及方法。\n\n**框架 = 反射 + 注解 + 设计模式**\n\n加载完类之后，在**堆内存的方法区**中就产生了一个`Class`类型的对象（一个类只有一个`Class`对象），这个对象就包含了**完整的类的结构信息**。我们可以通过这个对象看到类的结构。这个对象就像一面镜子，透过这个镜子看到类的结构，所以，我们形象的称之为：反射。\n\n![image-20210623202252209](/images/%E3%80%90Java%E3%80%91%E5%8F%8D%E5%B0%84/image-20210623202252209.png)\n\n### 动态语言 vs 静态语言\n\n**动态语言**是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。主要动态语言：`Object-C`、`C#`、`JavaScript`、`PHP`、`Python`、`Erlang`。 \n\n**静态语言**与动态语言相对应的，运行时**结构不可变**的语言就是静态语言。如`Java`、`C`、` C++`。\n\nJava不是动态语言，但Java可以称之为“**准动态**语言”。即Java有一定的动态性，我们可以利用反射机制、字节码操作获得类似动态语言的特性。 Java的动态性让编程的时候更加灵活。\n\n### 反射相关类\n\n- `java.lang.Class`：反射的源头\n- `java.lang.reflect.Method`\n- `java.lang.reflect.Field`\n- `java.lang.reflect.Constructor`\n\n### 反射优点和缺点\n\n优点：可以动态地创建和使用对象（也是框架底层核心）\n\n缺点：使用反射基本是解释执行，对执行速度有影响\n\n<!-- More -->\n\n## Class类的理解\n\n类的加载过程：程序经过`javac.ex`e命令以后，会生成一个或多个字节码文件(.class结尾)。接着我们使用`java.exe`命令对某个字节码文件进行解释运行。相当于将某个字节码文件加载到内存中。此过程就称为类的加载。加载到内存中的类，我们就称为运行时类，此运行时类，就作为`Class`的一个实例。\n\n换句话说，**Class的实例就对应着一个运行时类，其包含该运行时类的完整结构信息**。\n\n加载到内存中的运行时类，会缓存一定的时间。在此时间之内，我们可以通过不同的方式来获取此运行时类，**得到的是同一个Class对象**。\n\n## 获取Class实例的几种方式\n\n``` java\n//方式一：调用运行时类的属性：.class\nClass clazz1 = Person.class;\nSystem.out.println(clazz1);\n\n//方式二：通过运行时类的对象,调用getClass()\nPerson p1 = new Person();\nClass clazz2 = p1.getClass();\nSystem.out.println(clazz2);\n\n//方式三：调用Class的静态方法：forName(String classPath)，常用\nclazz3 = Class.forName(\"java.lang.String\");\nSystem.out.println(clazz3);\n\n//方式四：使用类的加载器：ClassLoader  (了解)\nClassLoader classLoader = ReflectionTest.class.getClassLoader();\nClass clazz4 = classLoader.loadClass(\"com.zhao.java.Person\");\nSystem.out.println(clazz4);\n```\n\n补充：`ClassLoader`类的使用：使用Classloader加载src目录下的配置文件\n\n```java    \n@Test\npublic void test() throws Exception {\n    Properties pros =  new Properties();\n\n    //读取配置文件的方式一：\n    此时的文件默认在当前的module下，与src同级。\n    FileInputStream fis = new FileInputStream(\"jdbc.properties\");\n    FileInputStream fis = new FileInputStream(\"src\\\\jdbc1.properties\");\n    pros.load(fis);\n\n    //读取配置文件的方式二：使用ClassLoader\n    //配置文件默认识别为：当前module的src下\n    ClassLoader classLoader = ClassLoaderTest.class.getClassLoader();\n    InputStream is = classLoader.getResourceAsStream(\"jdbc1.properties\");\n    pros.load(is);\n\n    String user = pros.getProperty(\"user\");\n    String password = pros.getProperty(\"password\");\n    System.out.println(\"user = \" + user + \",password = \" + password);\n}\n```\n\n\n\n## 反射应用一：创建运行时类的对象\n\n代码举例\n\n``` java\nClass<Person> clazz = Person.class;\nPerson obj = clazz.newInstance();\nSystem.out.println(obj);\n```\n\n说明`newInstance():`调用此方法，创建对应的运行时类的对象。**内部调用了运行时类的空参的构造器。**\n\n要想此方法正常的创建运行时类的对象，要求：\n\n- 运行时类必须提供**空参**的构造器\n- 空参的构造器的**访问权限**得够。通常，设置为public。\n\n在javabean中要求提供一个public的空参构造器。原因：\n\n- 便于通过反射，创建运行时类的对象\n- 便于子类继承此运行时类时，子类默认调用super()时能保证父类有默认构造器\n\n## 反射应用二：获取运行时类的完整结构\n\n通过反射，可以获取对应的运行时类中所有的属性、方法、构造器、父类、接口、父类的泛型、包、注解、异常等。\n\n``` java\n@Test\npublic void test1(){\n    Class clazz = Person.class;\n\n    //获取属性结构\n    //getFields():获取当前运行时类及其父类中声明为public访问权限的属性\n    Field[] fields = clazz.getFields();\n    for(Field f : fields){\n        System.out.println(f);\n    }\n    System.out.println();\n\n    //getDeclaredFields():获取当前运行时类中声明的所属性。（不包含父类中声明的属性）\n    Field[] declaredFields = clazz.getDeclaredFields();\n    for(Field f : declaredFields){\n        System.out.println(f);\n    }\n}\n\n@Test\npublic void test1(){\n    Class clazz = Person.class;\n\n    //getMethods():获取当前运行时类及其所父类中声明为public权限的方法\n    Method[] methods = clazz.getMethods();\n    for(Method m : methods){\n        System.out.println(m);\n    }\n    System.out.println();\n    \n    //getDeclaredMethods():获取当前运行时类中声明的所方法。（不包含父类中声明的方法\n    Method[] declaredMethods = clazz.getDeclaredMethods();\n    for(Method m : declaredMethods){\n        System.out.println(m);\n    }\n}\n\n/*\n  获取构造器结构\n*/\n@Test\npublic void test1(){\n    Class clazz = Person.class;\n    \n    //getConstructors():获取当前运行时类中声明为public的构造器\n    Constructor[] constructors = clazz.getConstructors();\n    for(Constructor c : constructors){\n        System.out.println(c);\n    }\n    System.out.println();\n    \n    //getDeclaredConstructors():获取当前运行时类中声明的所的构造器\n    Constructor[] declaredConstructors = clazz.getDeclaredConstructors();\n    for(Constructor c : declaredConstructors){\n        System.out.println(c);\n    }\n\n}\n\n/*\n  获取运行时类的父类\n*/\n@Test\npublic void test2(){\n    Class clazz = Person.class;\n\n    Class superclass = clazz.getSuperclass();\n    System.out.println(superclass);\n}\n\n/*\n  获取运行时类的带泛型的父类\n*/\n@Test\npublic void test3(){\n    Class clazz = Person.class;\n\n    Type genericSuperclass = clazz.getGenericSuperclass();\n    System.out.println(genericSuperclass);\n}\n\n/*\n  获取运行时类的带泛型的父类的泛型\n*/\n@Test\npublic void test4(){\n    Class clazz = Person.class;\n\n    Type genericSuperclass = clazz.getGenericSuperclass();\n    ParameterizedType paramType = (ParameterizedType) genericSuperclass;\n    \n    //获取泛型类型\n    Type[] actualTypeArguments = paramType.getActualTypeArguments();\n    //System.out.println(actualTypeArguments[0].getTypeName());\n    System.out.println(((Class)actualTypeArguments[0]).getName());\n}\n\n/*\n  获取运行时类实现的接口\n*/\n@Test\npublic void test5(){\n    Class clazz = Person.class;\n\n    Class[] interfaces = clazz.getInterfaces();\n    for(Class c : interfaces){\n        System.out.println(c);\n    }\n    System.out.println();\n    \n    //获取运行时类的父类实现的接口\n    Class[] interfaces1 = clazz.getSuperclass().getInterfaces();\n    for(Class c : interfaces1){\n        System.out.println(c);\n    }\n\n}\n/*\n  获取运行时类所在的包\n*/\n@Test\npublic void test6(){\n    Class clazz = Person.class;\n\n    Package pack = clazz.getPackage();\n    System.out.println(pack);\n}\n\n/*\n  获取运行时类声明的注解\n*/\n@Test\npublic void test7(){\n    Class clazz = Person.class;\n\n    Annotation[] annotations = clazz.getAnnotations();\n    for(Annotation annos : annotations){\n        System.out.println(annos);\n    }\n}\n```\n\n## 反射应用三：调用运行时类的指定结构\n\n``` java\n@Test\npublic void testField1() throws Exception {\n    Class clazz = Person.class;\n\n    //创建运行时类的对象\n    Person p = (Person) clazz.newInstance();\n\n    //1. getDeclaredField(String fieldName):获取运行时类中指定变量名的属性\n    Field name = clazz.getDeclaredField(\"name\");\n\n    //2.保证当前属性是可访问的\n    name.setAccessible(true);\n    //3.获取、设置指定对象的此属性值\n    name.set(p,\"Tom\");\n\n    System.out.println(name.get(p));\n}\n```\n\n调用指定的方法：\n``` java\n@Test\npublic void testMethod() throws Exception {\n    Class clazz = Person.class;\n\n    //创建运行时类的对象\n    Person p = (Person) clazz.newInstance();\n\n    /*\n      1.获取指定的某个方法\n      getDeclaredMethod():参数1 ：指明获取的方法的名称  参数2：指明获取的方法的形参列表\n    */\n    Method show = clazz.getDeclaredMethod(\"show\", String.class);\n    //2.保证当前方法是可访问的\n    show.setAccessible(true);\n\n    /*\n      3. 调用方法的invoke():参数1：方法的调用者  参数2：给方法形参赋值的实参\n      invoke()的返回值即为对应类中调用的方法的返回值。\n    */\n    Object returnValue = show.invoke(p,\"CHN\"); //String nation = p.show(\"CHN\");\n    System.out.println(returnValue);\n\n    System.out.println(\"*************如何调用静态方法*****************\");\n\n    // private static void showDesc()\n\n    Method showDesc = clazz.getDeclaredMethod(\"showDesc\");\n    showDesc.setAccessible(true);\n    //如果调用的运行时类中的方法没返回值，则此invoke()返回null\n    //Object returnVal = showDesc.invoke(null);\n    Object returnVal = showDesc.invoke(Person.class);\n    System.out.println(returnVal);//null\n}\n```\n\n调用指定的构造器：\n\n``` java\n@Test\npublic void testConstructor() throws Exception {\n    Class clazz = Person.class;\n\n    //private Person(String name)\n    /*\n    1.获取指定的构造器\n    getDeclaredConstructor():参数：指明构造器的参数列表\n     */\n    Constructor constructor = clazz.getDeclaredConstructor(String.class);\n\n    //2.保证此构造器是可访问的\n    constructor.setAccessible(true);\n\n    //3.调用此构造器创建运行时类的对象\n    Person per = (Person) constructor.newInstance(\"Tom\");\n    System.out.println(per);\n\n}\n```\n\n## 反射应用四：动态代理\n\n### 代理模式的原理 \n使用一个代理将对象包装起来,，然后用该代理对象取代原始对象。任何对原始对象的调用都要通过代理。代理对象决定是否以及何时将方法调用转到原始对象上。 \n\n### 静态代理\n\n举例：实现Runnable接口的方法创建多线程。\n\n``` java\nClass MyThread implements Runnable{} //相当于被代理类\nClass Thread implements Runnable{} //相当于代理类\n\nmain(){\n\tMyThread t = new MyThread();\n\tThread thread = new Thread(t);\n\tthread.start();//启动线程；调用线程的run()\n}\n```\n\n### 静态代理的缺点\n\n- 代理类和目标对象的类都是在**编译期间**确定下来，不利于程序的扩展；\n- **每一个代理类只能为一个接口服务**，这样一来程序开发中必然产生过多的代理。\n\n### 动态代理的特点\n\n动态代理是指客户通过代理类来调用其它对象的方法，并且是在**程序运行时**根据需要**动态**创建目标类的代理对象。\n\n### 动态代理的实现\n\n需要解决的两个主要问题：\n\n- 问题一：如何根据加载到内存中的被代理类，动态的创建一个代理类及其对象。 \n  （通过`Proxy.newProxyInstance()`实现）\n- 问题二：当通过代理类的对象调用方法a时，如何动态的去调用被代理类中的同名方法a。\n  （通过`InvocationHandler`接口的实现类及其方法`invoke()`）\n\n代码实现：\n\n``` java\ninterface Human{\n    String getBelief();\n    void eat(String food);\n}\n\n//被代理类\nclass SuperMan implements Human{\n    @Override\n    public String getBelief() {\n        return \"I believe I can fly!\";\n    }\n\n    @Override\n    public void eat(String food) {\n        System.out.println(\"我喜欢吃\" + food);\n    }\n}\n\nclass HumanUtil{\n    public void method1(){\n        System.out.println(\"====================通用方法一====================\");\n    }\n\n    public void method2(){\n        System.out.println(\"====================通用方法二====================\");\n    }\n}\n\nclass ProxyFactory{\n    //调用此方法，返回一个代理类的对象。解决问题一\n    public static Object getProxyInstance(Object obj){//obj:被代理类的对象\n        MyInvocationHandler handler = new MyInvocationHandler();\n        handler.bind(obj);\n        return Proxy.newProxyInstance(obj.getClass().getClassLoader(),obj.getClass().getInterfaces(),handler);\n    }\n}\n\nclass MyInvocationHandler implements InvocationHandler{\n    private Object obj;//需要使用被代理类的对象进行赋值\n    public void bind(Object obj){\n        this.obj = obj;\n    }\n\n    //当我们通过代理类的对象，调用方法a时，就会自动的调用如下的方法：invoke()\n    //将被代理类要执行的方法a的功能就声明在invoke()中\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        HumanUtil util = new HumanUtil();\n        util.method1();\n\n        //method:即为代理类对象调用的方法，此方法也就作为了被代理类对象要调用的方法\n        //obj:被代理类的对象\n        Object returnValue = method.invoke(obj,args);\n        \n        util.method2();\n\n        //上述方法的返回值就作为当前类中的invoke()的返回值。\n        return returnValue;\n    }\n}\n\npublic class ProxyTest {\n\n    public static void main(String[] args) {\n        SuperMan superMan = new SuperMan();\n        //proxyInstance:代理类的对象\n        Human proxyInstance = (Human) ProxyFactory.getProxyInstance(superMan);\n        //当通过代理类对象调用方法时，会自动的调用被代理类中同名的方法\n        String belief = proxyInstance.getBelief();\n        System.out.println(belief);\n        proxyInstance.eat(\"四川麻辣烫\");\n\n        System.out.println(\"*****************************\");\n\n        NikeClothFactory nikeClothFactory = new NikeClothFactory();\n        ClothFactory proxyClothFactory = (ClothFactory) ProxyFactory.getProxyInstance(nikeClothFactory);\n        proxyClothFactory.produceCloth();\n    }\n}\n```\n\n动态代理其他应用：\n\nMyBatis中`sqlSession`返回的每个`mapper`对象都是一个代理类。\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】IO 流","url":"/2021/03/18/【Java】IO流/","content":"\n## File类\n\n`java.io.File`类：文件和文件目录路径的抽象表示形式，与平台无关\n\n- File 能新建、删除、重命名文件和目录，但 File不能访问文件内容本身。 如果需要访问文件内容本身，则需要使用输入/输出流。\n- 想要在Java程序中表示一个真实存在的文件或目录，那么必须有一个File对象，但是Java程序中的一个File对象，可能没有一个真实存在的文件或目录。 \n-  File对象可以作为参数传递给流的构造器，指明读取或写入的\"终点\"。\n\nJava路径：\n\n- 相对路径：相较于某个路径下，指明的路径。在某个Module下代码内的相对路径默认相对于当前Module\n- 绝对路径：包含盘符在内的文件或文件目录的路径\n\n<!-- More -->\n\n``` java\npublic class FileTest {\n    /*\n    1.如何创建File类的实例\n        File(String filePath)\n        File(String parentPath,String childPath)\n        File(File parentFile,String childPath)\n\n    2.\n    相对路径：相较于某个路径下，指明的路径。\n    绝对路径：包含盘符在内的文件或文件目录的路径\n\n    3.路径分隔符\n     windows:\\\\\n     unix:/\n     */\n    @Test\n    public void test1(){\n        //构造器1\n        File file1 = new File(\"hello.txt\");//相对于当前module\n        File file2 =  new File(\"D:\\\\workspace_idea1\\\\JavaSenior\\\\day08\\\\he.txt\");\n\n        System.out.println(file1);\n        System.out.println(file2);\n\n        //构造器2：\n        File file3 = new File(\"D:\\\\workspace_idea1\",\"JavaSenior\");\n        System.out.println(file3);\n\n        //构造器3：\n        File file4 = new File(file3,\"hi.txt\");\n        System.out.println(file4);\n    }\n\n    /*\n    public String getAbsolutePath()：获取绝对路径\n    public String getPath() ：获取路径\n    public String getName() ：获取名称\n    public String getParent()：获取上层文件目录路径。若无，返回null\n    public long length() ：获取文件长度（即：字节数）。不能获取目录的长度。\n    public long lastModified() ：获取最后一次的修改时间，毫秒值\n\n    如下的两个方法适用于文件目录：\n    public String[] list() ：获取指定目录下的所有文件或者文件目录的名称数组\n    public File[] listFiles() ：获取指定目录下的所有文件或者文件目录的File数组\n     */\n    @Test\n    public void test2(){\n        File file1 = new File(\"hello.txt\");\n        File file2 = new File(\"d:\\\\io\\\\hi.txt\");\n\n        System.out.println(file1.getAbsolutePath());\n        System.out.println(file1.getPath());\n        System.out.println(file1.getName());\n        System.out.println(file1.getParent());\n        System.out.println(file1.length());\n        System.out.println(new Date(file1.lastModified()));\n\n        System.out.println();\n\n        System.out.println(file2.getAbsolutePath());\n        System.out.println(file2.getPath());\n        System.out.println(file2.getName());\n        System.out.println(file2.getParent());\n        System.out.println(file2.length());\n        System.out.println(file2.lastModified());\n    }\n    \n    @Test\n    public void test3(){\n        File file = new File(\"D:\\\\workspace_idea1\\\\JavaSenior\");\n\n        String[] list = file.list();\n        for(String s : list){\n            System.out.println(s);\n        }\n\n        System.out.println();\n\n        File[] files = file.listFiles();\n        for(File f : files){\n            System.out.println(f);\n        }\n    }\n    \n    /*\n    public boolean renameTo(File dest):把文件重命名为指定的文件路径\n     比如：file1.renameTo(file2)为例：\n        要想保证返回true,需要file1在硬盘中是存在的，且file2不能在硬盘中存在。\n     */\n    @Test\n    public void test4(){\n        File file1 = new File(\"hello.txt\");\n        File file2 = new File(\"D:\\\\io\\\\hi.txt\");\n\n        boolean renameTo = file2.renameTo(file1);\n        System.out.println(renameTo);\n\n    }\n    \n    /*\n    public boolean isDirectory()：判断是否是文件目录\n    public boolean isFile() ：判断是否是文件\n    public boolean exists() ：判断是否存在\n    public boolean canRead() ：判断是否可读\n    public boolean canWrite() ：判断是否可写\n    public boolean isHidden() ：判断是否隐藏\n     */\n    @Test\n    public void test5(){\n        File file1 = new File(\"hello.txt\");\n        file1 = new File(\"hello1.txt\");\n\n        System.out.println(file1.isDirectory());\n        System.out.println(file1.isFile());\n        System.out.println(file1.exists());\n        System.out.println(file1.canRead());\n        System.out.println(file1.canWrite());\n        System.out.println(file1.isHidden());\n\n        System.out.println();\n\n        File file2 = new File(\"d:\\\\io\");\n        file2 = new File(\"d:\\\\io1\");\n        System.out.println(file2.isDirectory());\n        System.out.println(file2.isFile());\n        System.out.println(file2.exists());\n        System.out.println(file2.canRead());\n        System.out.println(file2.canWrite());\n        System.out.println(file2.isHidden());\n\n    }\n    \n    /*\n    创建硬盘中对应的文件或文件目录\n    \tpublic boolean createNewFile() ：创建文件。若文件存在，则不创建，返回false\n    \tpublic boolean mkdir() ：创建文件目录。如果此文件目录存在，就不创建了。如果此文件目录的上层目录不存在，也不创建。\n    \tpublic boolean mkdirs() ：创建文件目录。如果此文件目录存在，就不创建了。如果上层文件目录不存在，一并创建\n    \n    删除磁盘中的文件或文件目录\n    \tpublic boolean delete()：删除文件或者文件夹\n    删除注意事项：Java中的删除不走回收站。\n     */\n    @Test\n    public void test6() throws IOException {\n        File file1 = new File(\"hi.txt\");\n        if(!file1.exists()){\n            //文件的创建\n            file1.createNewFile();\n            System.out.println(\"创建成功\");\n        }else{//文件存在\n            file1.delete();\n            System.out.println(\"删除成功\");\n        }\n\n\n    }\n    \n    @Test\n    public void test7(){\n        //文件目录的创建\n        File file1 = new File(\"d:\\\\io\\\\io1\\\\io3\");\n\n        boolean mkdir = file1.mkdir();\n        if(mkdir){\n            System.out.println(\"创建成功1\");\n        }\n\n        File file2 = new File(\"d:\\\\io\\\\io1\\\\io4\");\n\n        boolean mkdir1 = file2.mkdirs();\n        if(mkdir1){\n            System.out.println(\"创建成功2\");\n        }\n        //要想删除成功，io4文件目录下不能有子目录或文件\n        File file3 = new File(\"D:\\\\io\\\\io1\\\\io4\");\n        file3 = new File(\"D:\\\\io\\\\io1\");\n        System.out.println(file3.delete());\n    }\n}\n```\n\n## IO流原理及流的分类\n\n### IO流原理\n\n- I/O是Input/Output的缩写， I/O技术是非常实用的技术，用于处理设备之间的数据传输。如读/写文件，网络通讯等。\n-  Java程序中，对于数据的输入/输出操作以“流(stream)” 的方式进行。 \n- java.io包下提供了各种“流”类和接口，用以获取不同种类的数据，并通过标准的方法输入或输出数据。\n\n### 流的分类\n\n- 按操作数据单位不同分为：字节流(8 bit)，字符流(16 bit) \n- 按数据流的流向不同分为：输入流，输出流 \n- 按流的角色的不同分为：节点流，处理流\n\n![image-20210624132238499](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624132238499.png)\n\nIO流类型示意图\n\n![image-20210624132519552](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624132519552.png)\n\n### 节点流和处理流\n\n**节点流**：直接从数据源或目的地读写数据。\n\n![image-20210624132703272](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624132703272.png)\n\n**处理流**：不直接连接到数据源或目的地，而是“连接”在已存在的流（节点流或处理流）之上，通过对数据的处理为程序提供更为强大的读写功能。\n\n![image-20210624132713974](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624132713974.png)\n\n### IO流体系\n\n![image-20210624132602926](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624132602926.png)\n\n| 抽象基类         | 节点流（或文件流）                              | 缓冲流（处理流的一种）                                       |\n| ---------------- | ----------------------------------------------- | ------------------------------------------------------------ |\n| **InputStream**  | **FileInputStream** read(byte[] buffer)         | **BufferedInputStream** read(byte[] buffer)                  |\n| **OutputStream** | **FileOutputStream** write(byte[] buffer,0,len) | **BufferedOutputStream** write(byte[] buffer,0,len) / flush() |\n| **Reader**       | **FileReader** read(char[] cbuf)                | **BufferedReader** read(char[] cbuf) / readLine()            |\n| **Writer**       | **FileWriter** write(char[] cbuf,0,len)         | **BufferedWriter** write(char[] cbuf,0,len) / flush()        |\n\n- 对于文本文件(.txt,.java,.c,.cpp)，使用字符流处理\n- 对于非文本文件(.jpg,.mp3,.mp4,.avi,.doc,.ppt,...)，使用字节流处理\n\n## FileReader和FileWriter\n\n\n``` java\npublic class FileReaderWriterTest {\n\n    public static void main(String[] args) {\n        File file = new File(\"hello.txt\");//相较于当前工程\n        System.out.println(file.getAbsolutePath());\n\n        File file1 = new File(\"day09\\\\hello.txt\");\n        System.out.println(file1.getAbsolutePath());\n    }\n\n    /*\n    将day09下的hello.txt文件内容读入程序中，并输出到控制台\n\n    说明点：\n    1. read()的理解：返回读入的一个字符。如果达到文件末尾，返回-1\n    2. 异常的处理：为了保证流资源一定可以执行关闭操作。需要使用try-catch-finally处理\n    3. 读入的文件一定要存在，否则就会报FileNotFoundException。\n\n     */\n    @Test\n    public void testFileReader(){\n        FileReader fr = null;\n        try {\n            //1.实例化File类的对象，指明要操作的文件\n            File file = new File(\"hello.txt\");//相较于当前Module\n            //2.提供具体的流\n            fr = new FileReader(file);\n\n            //3.数据的读入\n            //read():返回读入的一个字符。如果达到文件末尾，返回-1\n            //方式一：\n//        int data = fr.read();\n//        while(data != -1){\n//            System.out.print((char)data);\n//            data = fr.read();\n//        }\n\n            //方式二：语法上针对于方式一的修改\n            int data;\n            while((data = fr.read()) != -1){\n                System.out.print((char)data);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //4.流的关闭操作\n//            try {\n//                if(fr != null)\n//                    fr.close();\n//            } catch (IOException e) {\n//                e.printStackTrace();\n//            }\n            //或\n            if(fr != null){\n                try {\n                    fr.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n\n    }\n\n    //对read()操作升级：使用read的重载方法\n    @Test\n    public void testFileReader1()  {\n        FileReader fr = null;\n        try {\n            //1.File类的实例化\n            File file = new File(\"hello.txt\");\n\n            //2.FileReader流的实例化\n            fr = new FileReader(file);\n\n            //3.读入的操作\n            //read(char[] cbuf):返回每次读入cbuf数组中的字符的个数。如果达到文件末尾，返回-1\n            char[] cbuf = new char[5];\n            int len;\n            while((len = fr.read(cbuf)) != -1){\n                //方式一：\n                //错误的写法\n//                for(int i = 0;i < cbuf.length;i++){\n//                    System.out.print(cbuf[i]);\n//                }\n                //正确的写法\n//                for(int i = 0;i < len;i++){\n//                    System.out.print(cbuf[i]);\n//                }\n                //方式二：\n                //错误的写法,对应着方式一的错误的写法\n//                String str = new String(cbuf);\n//                System.out.print(str);\n                //正确的写法\n                String str = new String(cbuf,0,len);\n                System.out.print(str);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if(fr != null){\n                //4.资源的关闭\n                try {\n                    fr.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n        }\n\n    }\n    /*\n    从内存中写出数据到硬盘的文件里。\n\n    说明：\n    1. 输出操作，对应的File可以不存在的。并不会报异常\n    2.\n         File对应的硬盘中的文件如果不存在，在输出的过程中，会自动创建此文件。\n         File对应的硬盘中的文件如果存在：\n                如果流使用的构造器是：FileWriter(file,false) / FileWriter(file):对原有文件的覆盖\n                如果流使用的构造器是：FileWriter(file,true):不会对原有文件覆盖，而是在原有文件基础上追加内容\n\n     */\n    @Test\n    public void testFileWriter() {\n        FileWriter fw = null;\n        try {\n            //1.提供File类的对象，指明写出到的文件\n            File file = new File(\"hello1.txt\");\n\n            //2.提供FileWriter的对象，用于数据的写出\n            fw = new FileWriter(file,false);\n\n            //3.写出的操作\n            fw.write(\"I have a dream!\\n\");\n            fw.write(\"you need to have a dream!\");\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //4.流资源的关闭\n            if(fw != null){\n\n                try {\n                    fw.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n\n    @Test\n    public void testFileReaderFileWriter() {\n        FileReader fr = null;\n        FileWriter fw = null;\n        try {\n            //1.创建File类的对象，指明读入和写出的文件\n            File srcFile = new File(\"hello.txt\");\n            File destFile = new File(\"hello2.txt\");\n\n            //不能使用字符流来处理图片等字节数据\n//            File srcFile = new File(\"爱情与友情.jpg\");\n//            File destFile = new File(\"爱情与友情1.jpg\");\n\n\n            //2.创建输入流和输出流的对象\n            fr = new FileReader(srcFile);\n            fw = new FileWriter(destFile);\n\n\n            //3.数据的读入和写出操作\n            char[] cbuf = new char[5];\n            int len;//记录每次读入到cbuf数组中的字符的个数\n            while((len = fr.read(cbuf)) != -1){\n                //每次写出len个字符\n                fw.write(cbuf,0,len);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //4.关闭流资源\n            //方式一：\n//            try {\n//                if(fw != null)\n//                    fw.close();\n//            } catch (IOException e) {\n//                e.printStackTrace();\n//            }finally{\n//                try {\n//                    if(fr != null)\n//                        fr.close();\n//                } catch (IOException e) {\n//                    e.printStackTrace();\n//                }\n//            }\n            //方式二：\n            try {\n                if(fw != null)\n                    fw.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n\n            try {\n                if(fr != null)\n                    fr.close();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n## FileInputStream和FileOutputStream\n\n``` java\npublic class FileInputOutputStreamTest {\n\n    //使用字节流FileInputStream处理文本文件，可能出现乱码。\n    @Test\n    public void testFileInputStream() {\n        FileInputStream fis = null;\n        try {\n            //1. 造文件\n            File file = new File(\"hello.txt\");\n\n            //2.造流\n            fis = new FileInputStream(file);\n\n            //3.读数据\n            byte[] buffer = new byte[5];\n            int len;//记录每次读取的字节的个数\n            while((len = fis.read(buffer)) != -1){\n\n                String str = new String(buffer,0,len);\n                System.out.print(str);\n\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if(fis != null){\n                //4.关闭资源\n                try {\n                    fis.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n\n    /*\n    实现对图片的复制操作\n     */\n    @Test\n    public void testFileInputOutputStream()  {\n        FileInputStream fis = null;\n        FileOutputStream fos = null;\n        try {\n            //\n            File srcFile = new File(\"爱情与友情.jpg\");\n            File destFile = new File(\"爱情与友情2.jpg\");\n\n            //\n            fis = new FileInputStream(srcFile);\n            fos = new FileOutputStream(destFile);\n\n            //复制的过程\n            byte[] buffer = new byte[5];\n            int len;\n            while((len = fis.read(buffer)) != -1){\n                fos.write(buffer,0,len);\n            }\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if(fos != null){\n                //\n                try {\n                    fos.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(fis != null){\n                try {\n                    fis.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n        }\n\n    }\n\n    //指定路径下文件的复制\n    public void copyFile(String srcPath,String destPath){\n        FileInputStream fis = null;\n        FileOutputStream fos = null;\n        try {\n            //\n            File srcFile = new File(srcPath);\n            File destFile = new File(destPath);\n\n            //\n            fis = new FileInputStream(srcFile);\n            fos = new FileOutputStream(destFile);\n\n            //复制的过程\n            byte[] buffer = new byte[1024];\n            int len;\n            while((len = fis.read(buffer)) != -1){\n                fos.write(buffer,0,len);\n            }\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if(fos != null){\n                //\n                try {\n                    fos.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(fis != null){\n                try {\n                    fis.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n        }\n    }\n\n}\n```\n\n## 缓冲流\n\n处理流，就是“套接”在已有的流的基础上。缓冲流能提高读写速度，原因：内部提供了一个**缓冲区**，读写时先将内存中的数据存放在缓冲区内，当缓冲区内容满了再统一对硬盘进行读写，节省了大量向硬盘读写所耗费的时间。\n\n- `BufferedInputStream`\n- `BufferedOutputStream`\n- `BufferedReader`\n- `BufferedWriter`\n\n**创建缓冲流时，需要将对应的节点流对象作为构造器参数传入。**关闭外部流（缓冲流）后，其内部流（节点流）会自动关闭，不需要再`close`。\n\n![image-20210624140207933](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624140207933.png)\n\n``` java\npublic class BufferedTest {\n\n    /*\n    实现非文本文件的复制\n     */\n    @Test\n    public void BufferedStreamTest() throws FileNotFoundException {\n        BufferedInputStream bis = null;\n        BufferedOutputStream bos = null;\n\n        try {\n            //1.造文件\n            File srcFile = new File(\"爱情与友情.jpg\");\n            File destFile = new File(\"爱情与友情3.jpg\");\n            //2.造流\n            //2.1 造节点流\n            FileInputStream fis = new FileInputStream((srcFile));\n            FileOutputStream fos = new FileOutputStream(destFile);\n            //2.2 造缓冲流\n            bis = new BufferedInputStream(fis);\n            bos = new BufferedOutputStream(fos);\n\n            //3.复制的细节：读取、写入\n            byte[] buffer = new byte[10];\n            int len;\n            while((len = bis.read(buffer)) != -1){\n                bos.write(buffer,0,len);\n//                bos.flush();//刷新缓冲区\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //4.资源关闭\n            //要求：先关闭外层的流，再关闭内层的流\n            if(bos != null){\n                try {\n                    bos.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n            if(bis != null){\n                try {\n                    bis.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n            //说明：关闭外层流的同时，内层流也会自动的进行关闭。关于内层流的关闭，我们可以省略.\n//        fos.close();\n//        fis.close();\n        }\n    }\n\n    //实现文件复制的方法\n    public void copyFileWithBuffered(String srcPath,String destPath){\n        BufferedInputStream bis = null;\n        BufferedOutputStream bos = null;\n\n        try {\n            //1.造文件\n            File srcFile = new File(srcPath);\n            File destFile = new File(destPath);\n            //2.造流\n            //2.1 造节点流\n            FileInputStream fis = new FileInputStream((srcFile));\n            FileOutputStream fos = new FileOutputStream(destFile);\n            //2.2 造缓冲流\n            bis = new BufferedInputStream(fis);\n            bos = new BufferedOutputStream(fos);\n\n            //3.复制的细节：读取、写入\n            byte[] buffer = new byte[1024];\n            int len;\n            while((len = bis.read(buffer)) != -1){\n                bos.write(buffer,0,len);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //4.资源关闭\n            //要求：先关闭外层的流，再关闭内层的流\n            if(bos != null){\n                try {\n                    bos.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n            if(bis != null){\n                try {\n                    bis.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n            //说明：关闭外层流的同时，内层流也会自动的进行关闭。关于内层流的关闭，我们可以省略.\n//        fos.close();\n//        fis.close();\n        }\n    }\n\n    @Test\n    public void testCopyFileWithBuffered(){\n        long start = System.currentTimeMillis();\n\n        String srcPath = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\01-视频.avi\";\n        String destPath = \"C:\\\\Users\\\\Administrator\\\\Desktop\\\\03-视频.avi\";\n\n        copyFileWithBuffered(srcPath,destPath);\n\n        long end = System.currentTimeMillis();\n\n        System.out.println(\"复制操作花费的时间为：\" + (end - start));//618 - 176\n    }\n\n\n    /*\n    使用BufferedReader和BufferedWriter实现文本文件的复制\n     */\n    @Test\n    public void testBufferedReaderBufferedWriter(){\n        BufferedReader br = null;\n        BufferedWriter bw = null;\n        try {\n            //创建文件和相应的流\n            br = new BufferedReader(new FileReader(new File(\"dbcp.txt\")));\n            bw = new BufferedWriter(new FileWriter(new File(\"dbcp1.txt\")));\n\n            //读写操作\n            //方式一：使用char[]数组\n//            char[] cbuf = new char[1024];\n//            int len;\n//            while((len = br.read(cbuf)) != -1){\n//                bw.write(cbuf,0,len);\n//    //            bw.flush();\n//            }\n\n            //方式二：使用String\n            String data;\n            while((data = br.readLine()) != null){\n                //方法一：\n//                bw.write(data + \"\\n\");//data中不包含换行符\n                //方法二：\n                bw.write(data);//data中不包含换行符\n                bw.newLine();//提供换行的操作\n            }\n\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //关闭资源\n            if(bw != null){\n\n                try {\n                    bw.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n            if(br != null){\n                try {\n                    br.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n}\n```\n\n## 转换流\n\n转换流：属于**字符流**。因为其后缀为`Reader`和`Writer`。\n\n- `InputStreamReader`：将一个字节输入流转换为字符输入流\n- `OutputStreamWriter`：将一个字符输出流转换为字节输出流\n\n作用：提供字节流与字符流之间的转换。可指定使用不同的字符集编码方式读取同一段文本数据。\n\n- 解码：字节、字节数组 ---> 字符数组、字符串\n- 编码：字符数组、字符串 ---> 字节、字节数组\n\n![image-20210624140145352](/images/%E3%80%90Java%E3%80%91IO%E6%B5%81/image-20210624140145352.png)\n\n### 字符集\n- ASCII：美国标准信息交换码。用一个字节的7位可以表示。\n- ISO8859-1：拉丁码表（欧洲码表）。用一个字节的8位表示。\n- GB2312：中国的中文编码表。多两个字节编码所有字符\n- GBK：中国的中文编码表升级，融合了更多的中文文字符号。最多两个字节编码\n- Unicode：国际标准码，融合了目前人类使用的所有字符。为每个字符分配唯一的字符码。所有的文字都用两个字节来表示。\n- UTF-8：变长的编码方式，可用1-4个字节来表示一个字符。\n\n``` java\npublic class InputStreamReaderTest {\n\n    /*\n    此时处理异常的话，仍然应该使用try-catch-finally\n    综合使用InputStreamReader和OutputStreamWriter\n     */\n    @Test\n    public void test() throws Exception {\n        //1.造文件、造流\n        File file1 = new File(\"dbcp.txt\");\n        File file2 = new File(\"dbcp_gbk.txt\");\n\n        FileInputStream fis = new FileInputStream(file1);\n        FileOutputStream fos = new FileOutputStream(file2);\n\n        InputStreamReader isr = new InputStreamReader(fis,\"utf-8\");\n        OutputStreamWriter osw = new OutputStreamWriter(fos,\"gbk\");\n\n        //2.读写过程\n        char[] cbuf = new char[20];\n        int len;\n        while((len = isr.read(cbuf)) != -1){\n            osw.write(cbuf,0,len);\n        }\n\n        //3.关闭资源\n        isr.close();\n        osw.close();\n    }\n}\n```\n\n## 序列化\n\n**序列化机制：**\n\n- 对象序列化机制允许把**内存**中的Java对象转换成**平台无关的二进制流**，从而允许把这种二进制流持久地保存在**磁盘**上，或通过**网络**将这种二进制流传输到另一个网络节点。\n- 当其它程序获取了这种二进制流，就可以恢复成原来的Java对象（反序列化）\n\nJava的序列化机制是通过在运行时判断类的`serialVersionUID`来验证版本一致性的。在进行反序列化时，JVM会把传来的字节流中的`serialVersionUID`与本地相应实体类的`serialVersionUID`进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常。(`InvalidCastException`)\n\n若不提供`serialVersionUID`，则JVM会为该类生成一个默认的`serialVersionUID`，这样的缺陷在于，若后续该类进行了改动，重新编译出的class文件将会拥有另一个默认的`serialVersionUID`，二者不会相同，此时将不再能进行反序列化。\n\n谈谈你对`java.io.Serializable`接口的理解，我们知道它用于序列化， 是**空方法接口**，还有其它认识吗？\n\n`Serializable`接口是给JVM参考的，JVM看到该接口后，会为该类自动生成一个**序列化版本号**：`serialVersionUID`，其用于唯一标识该对象在数据源中的位置。\n\n实现了`Serializable`接口的对象，可将它们转换成一系列字节，并可在以后完全恢复回原来的样子。**这一过程亦可通过网络进行。这意味着序列化机制能自动补偿操作系统间的差异**。换句话说，可以先在Windows机器上创建一个对象，对其序列化，然后通过网络发给一台Unix机器，然后在那里准确无误地重新“装配”。不必关心数据在不同机器上如何表示，也不必关心字节的顺序或者其他任何细节。由于大部分作为参数的类如`String`、`Integer`等都实现了` java.io.Serializable`的接口，也可以利用多态的性质，作为参数使接口更灵活。\n\n## 对象流\n\n`ObjectInputStream`和`OjbectOutputSteam`\n\n作用：用于存储和读取基本数据类型数据或对象的处理流。它的强大之处就是可以把Java中的对象写入到数据源中，也能把对象从数据源中还原回来。\n\n要想一个java对象是**可序列化**的，需要满足的要求：\n\n- 需要实现接口：`Serializable`\n- 当前类提供一个全局常量：`serialVersionUID`，其用于唯一标识该对象在数据源中的位置\n- 除了当前类需要实现`Serializable`接口之外，还必须保证其内部所有属性也必须是可序列化的。（默认情况下，基本数据类型可序列化）\n\n补充：`ObjectOutputStream`和`ObjectInputStream`不能序列化`static`和`transient`（表示游离，不参与序列化）修饰的成员变量。可以一次序列化多个对象（用集合存放多个对象一起传给`ObjectOutputStream`）\n\n``` java\npublic class ObjectInputOutputStreamTest {\n\n    /*\n    序列化过程：将内存中的java对象保存到磁盘中或通过网络传输出去\n    使用ObjectOutputStream实现\n     */\n    @Test\n    public void testObjectOutputStream(){\n        ObjectOutputStream oos = null;\n\n        try {\n            //1.\n            oos = new ObjectOutputStream(new FileOutputStream(\"object.dat\"));\n            //2.\n            oos.writeObject(new String(\"我爱北京天安门\"));\n            oos.flush();//每write一个对象就要刷新一次\n\n            oos.writeObject(new Person(\"王铭\",23));\n            oos.flush();\n\n            oos.writeObject(new Person(\"张学良\",23,1001,new Account(5000)));\n            oos.flush();\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            if(oos != null){\n                //3.\n                try {\n                    oos.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n        }\n\n    }\n\n    /*\n    反序列化：将磁盘文件中的对象还原为内存中的一个java对象\n    使用ObjectInputStream来实现\n     */\n    @Test\n    public void testObjectInputStream(){\n        ObjectInputStream ois = null;\n        try {\n            ois = new ObjectInputStream(new FileInputStream(\"object.dat\"));\n\n            Object obj = ois.readObject();\n            String str = (String) obj;\n\n            Person p = (Person) ois.readObject();\n            Person p1 = (Person) ois.readObject();\n\n            System.out.println(str);\n            System.out.println(p);\n            System.out.println(p1);\n\n        } catch (IOException e) {\n            e.printStackTrace();\n        } catch (ClassNotFoundException e) {\n            e.printStackTrace();\n        } finally {\n            if(ois != null){\n                try {\n                    ois.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n\n    }\n}\n```\n\n## RandomAccessFile\n\n- `RandomAccessFile`直接继承于`java.lang.Object`类，实现了`DataInput`和`DataOutput`接口\n- `RandomAccessFile`既可以作为一个输入流，又可以作为一个输出流\n\n如果`RandomAccessFile`作为输出流时，写出到的文件如果不存在，则在执行过程中自动创建。如果写出到的文件存在，则会对原有文件内容进行覆盖。（默认情况下，从头覆盖）可以通过相关的操作，实现`RandomAccessFile`“插入”数据的效果。\n\n``` java\npublic class RandomAccessFileTest {\n\n    @Test\n    public void test1() {\n\n        RandomAccessFile raf1 = null;\n        RandomAccessFile raf2 = null;\n        try {\n            //1.\n            raf1 = new RandomAccessFile(new File(\"爱情与友情.jpg\"),\"r\");\n            raf2 = new RandomAccessFile(new File(\"爱情与友情1.jpg\"),\"rw\");\n            //2.\n            byte[] buffer = new byte[1024];\n            int len;\n            while((len = raf1.read(buffer)) != -1){\n                raf2.write(buffer,0,len);\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        } finally {\n            //3.\n            if(raf1 != null){\n                try {\n                    raf1.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n\n            }\n            if(raf2 != null){\n                try {\n                    raf2.close();\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }\n    }\n\n    @Test\n    public void test2() throws IOException {\n        RandomAccessFile raf1 = new RandomAccessFile(\"hello.txt\",\"rw\");\n\n        raf1.seek(3);//将指针调到角标为3的位置\n        raf1.write(\"xyz\".getBytes());//\n        raf1.close();\n    }\n    \n    /*\n    使用RandomAccessFile实现数据的插入效果\n     */\n    @Test\n    public void test3() throws IOException {\n\n        RandomAccessFile raf1 = new RandomAccessFile(\"hello.txt\",\"rw\");\n\n        raf1.seek(3);//将指针调到角标为3的位置\n        //保存指针3后面的所有数据到StringBuilder中\n        StringBuilder builder = new StringBuilder((int) new File(\"hello.txt\").length());\n        byte[] buffer = new byte[20];\n        int len;\n        while((len = raf1.read(buffer)) != -1){\n            builder.append(new String(buffer,0,len)) ;\n        }\n        //调回指针，写入“xyz”\n        raf1.seek(3);\n        raf1.write(\"xyz\".getBytes());\n\n        //将StringBuilder中的数据写入到文件中\n        raf1.write(builder.toString().getBytes());\n\n        raf1.close();\n\n        //思考：将StringBuilder替换为ByteArrayOutputStream\n    }\n}\n```\n\n\n\n## 其他流\n\n- 标准的输入、输出流：System.in、System.out\n- 打印流：PrintStream、PrintWriter\n- 数据流：DataInputStream、DataOutputStream。作用：用于读取或写出基本数据类型的变量或字符串\n\n### 打印流\n\n``` java\n@Test\npublic void test2() {\n    PrintStream ps = null;\n    try {\n        FileOutputStream fos = new FileOutputStream(new File(\"D:\\\\IO\\\\text.txt\"));\n        // 创建打印输出流,设置为自动刷新模式(写入换行符或字节 '\\n' 时都会刷新输出缓冲区)\n        ps = new PrintStream(fos, true);\n        if (ps != null) {// 把标准输出流(控制台输出)改成文件\n            System.setOut(ps);\n        }\n\n        for (int i = 0; i <= 255; i++) { // 输出ASCII字符\n            System.out.print((char) i);\n            if (i % 50 == 0) { // 每50个数据一行\n                System.out.println(); // 换行\n            }\n        }\n    } catch (FileNotFoundException e) {\n        e.printStackTrace();\n    } finally {\n        if (ps != null) {\n            ps.close();\n        }\n    }\n\n}\n```\n\n### 数据流\n\n  将文件中存储的基本数据类型变量和字符串读取到内存中，保存在变量中。 注意点：读取不同类型的数据的顺序要与当初写入文件时，保存的数据的顺序一致！\n\n将内存中的字符串、基本数据类型的变量写出到文件中：\n\n``` java\n@Test\npublic void test3() throws IOException {\n    //1.\n    DataOutputStream dos = new DataOutputStream(new FileOutputStream(\"data.txt\"));\n\n    //2.\n    dos.writeUTF(\"张三\");\n    dos.flush();//刷新操作，将内存中的数据写入文件\n    dos.writeInt(23);\n    dos.flush();\n    dos.writeBoolean(true);\n    dos.flush();\n    //3.\n    dos.close();\n}\n\n@Test\npublic void test4() throws IOException {\n    //1.\n    DataInputStream dis = new DataInputStream(new FileInputStream(\"data.txt\"));\n    //2.\n    String name = dis.readUTF();\n    int age = dis.readInt();\n    boolean isMale = dis.readBoolean();\n\n    System.out.println(\"name = \" + name);\n    System.out.println(\"age = \" + age);\n    System.out.println(\"isMale = \" + isMale);\n\n    //3.\n    dis.close();\n}\n```","tags":["Java"],"categories":["Java"]},{"title":"【Java】集合","url":"/2021/03/16/【Java】集合/","content":"\n## 集合框架的概述\n\n集合、数组都是对多个数据进行存储操作的结构，简称Java容器。\n\n### Java 数组\n\n数组在存储多个数据方面的特点：\n\n- 一旦初始化以后，其长度就确定了。\n- 数组一旦定义好，其元素的类型也就确定了。我们也就只能操作指定类型的数据了。比如：`String[] arr;int[] arr1;Object[] arr2;`\n\n 数组在存储多个数据方面的缺点：\n\n- 一旦初始化以后，其长度就不可修改。\n- 数组中提供的方法非常有限，对于添加、删除、插入数据等操作，非常不便，同时效率不高。\n- 获取数组中实际元素的个数的需求，数组没有现成的属性或方法可用\n\n数组存储数据的特点：**有序、可重复。对于无序、不可重复的需求，不能满足。**\n\n### Java 集合\n\nJava集合类可以用于存储数量不等的多个对象 ，还可用于保存具有映射关系的关联数组。其可分为 `Collection`和`Map`两种体系。\n\n- `Collection`接口：**单列**集合，用来存储一个一个的对象\n  - `List`接口：存储**有序的、可重复的**数据。包含`ArrayList`、`LinkedList`、`Vector      `\n  - `Set`接口：存储**无序的、不可重复的**数据。包含`HashSet`、`LinkedHashSet`、`TreeSet`\n- `Map`接口：**双列**集合，用来存储一对(key-value)一对的数据。包含`HashMap`、`LinkedHashMap`、`TreeMap`、`Hashtable`、`Properties`\n\n**Collection接口继承树**\n\n![image-20210617161218475](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210617161218475.png)\n\n**Map接口继承树**\n\n![image-20210617161305507](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210617161305507.png)\n\n<!-- More -->\n\n## Collection 接口\n\n向`Collection`接口的实现类的对象中添加数据obj时，要求obj所在类要重写`equals()`方法。\n\nCollection接口常用方法：\n\n``` java\npublic class CollectionTest {\n\n    @Test\n    public void test1(){\n        Collection coll = new ArrayList();\n\n        //add(Object e):将元素e添加到集合coll中\n        coll.add(\"AA\");\n        coll.add(\"BB\");\n        coll.add(123);//自动装箱\n        coll.add(new Date());\n\n        //size():获取添加的元素的个数\n        System.out.println(coll.size());//4\n\n        //addAll(Collection coll1):将coll1集合中的元素添加到当前的集合中\n        Collection coll1 = new ArrayList();\n        coll1.add(456);\n        coll1.add(\"CC\");\n        coll.addAll(coll1);\n\n        System.out.println(coll.size());//6\n        System.out.println(coll);\n\n        //clear():清空集合元素\n        coll.clear();\n\n        //isEmpty():判断当前集合是否为空\n        System.out.println(coll.isEmpty());\n\n    }\n\n}\n```\n\n向`Collection`接口的实现类的对象中添加数据obj时，要求obj所在类要重写`equals()`方法。\n\n``` java\npublic class CollectionTest {\n\n    @Test\n    public void test1(){\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n        coll.add(new String(\"Tom\"));\n        coll.add(false);\n        \n        //1.contains(Object obj):判断当前集合中是否包含obj\n        //我们在判断时会调用obj对象所在类的equals()。\n        boolean contains = coll.contains(123);\n        System.out.println(contains);\n        System.out.println(coll.contains(new String(\"Tom\")));\n\n        //2.containsAll(Collection coll1):判断形参coll1中的所有元素是否都存在于当前集合中。\n        Collection coll1 = Arrays.asList(123,4567);\n        System.out.println(coll.containsAll(coll1));\n    }\n\n    @Test\n    public void test2(){\n        //3.remove(Object obj):从当前集合中移除obj元素。\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n        coll.add(new Person(\"Jerry\",20));\n\n        coll.remove(123);\n        System.out.println(coll);\n\n        coll.remove(new Person(\"Jerry\",20));\n        System.out.println(coll);\n\n        //4. removeAll(Collection coll1):差集：从当前集合中移除coll1中所有的元素。\n        Collection coll1 = Arrays.asList(123,456);\n        coll.removeAll(coll1);\n        System.out.println(coll);\n    }\n\n    @Test\n    public void test3(){\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n        coll.add(new Person(\"Jerry\",20));\n        coll.add(new String(\"Tom\"));\n        coll.add(false);\n\n        //5.retainAll(Collection coll1):交集：获取当前集合和coll1集合的交集，并返回给当前集合\n//        Collection coll1 = Arrays.asList(123,456,789);\n//        coll.retainAll(coll1);\n//        System.out.println(coll);\n\n        //6.equals(Object obj):要想返回true，需要当前集合和形参集合的元素都相同。\n        Collection coll1 = new ArrayList();\n        coll1.add(456);\n        coll1.add(123);\n        coll1.add(new Person(\"Jerry\",20));\n        coll1.add(new String(\"Tom\"));\n        coll1.add(false);\n\n        System.out.println(coll.equals(coll1));\n    }\n\n    @Test\n    public void test4(){\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n\n        //7.hashCode():返回当前对象的哈希值\n        System.out.println(coll.hashCode());\n\n        //8.集合 --->数组：toArray()\n        Object[] arr = coll.toArray();\n        for(int i = 0;i < arr.length;i++){\n            System.out.println(arr[i]);\n        }\n\n        //拓展：数组 --->集合:调用Arrays类的静态方法asList()\n        List<String> list = Arrays.asList(new String[]{\"AA\", \"BB\", \"CC\"});\n        System.out.println(list);\n\n        List arr1 = Arrays.asList(new int[]{123, 456});\n        System.out.println(arr1.size());//1\n\n        List arr2 = Arrays.asList(new Integer[]{123, 456});\n        System.out.println(arr2.size());//2\n\n        //9.iterator():返回Iterator接口的实例，用于遍历集合元素。放在IteratorTest.java中测试\n    }\n}\n```\n\n集合元素的遍历操作，使用迭代器`Iterator`接口。获取方法：`collection.iterator();`\n\n- 内部的方法：`hasNext() `和 `next()`\n- 集合对象每次调用`iterator()`方法都得到一个全新的迭代器对象，默认游标都在集合的第一个元素之前。\n- 内部定义了`remove()`，可以在遍历的时候，删除集合中的元素。此方法不同于集合直接调用`remove()`。\n\n``` java\npublic class IteratorTest {\n\n    @Test\n    public void test1(){\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n        coll.add(new Person(\"Jerry\",20));\n\n        Iterator iterator = coll.iterator();\n\n        //hasNext():判断是否还有下一个元素\n        while(iterator.hasNext()){\n            //next():①指针下移 ②将下移以后集合位置上的元素返回\n            System.out.println(iterator.next());\n        }\n\n    }\n\n    @Test\n    public void test2(){\n\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n        coll.add(new Person(\"Jerry\",20));\n        coll.add(new String(\"Tom\"));\n        coll.add(false);\n\n        //错误方式一：\n//        Iterator iterator = coll.iterator();\n//        while((iterator.next()) != null){\n//            System.out.println(iterator.next());\n//        }\n\n        //错误方式二：\n        //集合对象每次调用iterator()方法都得到一个全新的迭代器对象，默认游标都在集合的第一个元素之前。\n        while (coll.iterator().hasNext()){\n            System.out.println(coll.iterator().next());\n        }\n    }\n\n    //测试Iterator中的remove()\n    //如果还未调用next()或在上一次调用 next 方法之后已经调用了 remove 方法，\n    // 再调用remove都会报IllegalStateException。\n    @Test\n    public void test3(){\n        Collection coll = new ArrayList();\n        coll.add(123);\n        coll.add(456);\n        coll.add(new Person(\"Jerry\",20));\n        coll.add(new String(\"Tom\"));\n        coll.add(false);\n\n        //删除集合中\"Tom\"\n        Iterator iterator = coll.iterator();\n        while (iterator.hasNext()){\n//            iterator.remove();\n            Object obj = iterator.next();\n            if(\"Tom\".equals(obj)){\n                iterator.remove();\n//                iterator.remove();\n            }\n\n        }\n        //遍历集合\n        iterator = coll.iterator();\n        while (iterator.hasNext()){\n            System.out.println(iterator.next());\n        }\n    }\n}\n```\n\n调用`next()`方法时，先将`iterator`的指针下移，再将下移后位置上的元素返回。\n\n增强for循环：\n\n``` java\n//for(集合元素的类型 局部变量 : 集合对象)\n//内部仍然调用了迭代器。\nfor(Object obj : coll){\n    System.out.println(obj);\n}\n```\n\n## List 接口\n\nList接口：存储有序的、可重复的数据。是一种“动态”数组。能够替换原有的数组。其实现类有三种：\n\n- **ArrayList**：作为`List`接口的**主要实现类**；**线程不安全的（可使用Collections工具类返回线程安全的`ArrayList`），效率高**；底层使用`Object[] elementData`**数组**存储；数组长度动态扩容时每次扩容1.5倍。\n- **LinkedList**：对于**频繁的插入、删除操作**，使用此类效率比`ArrayList`高；底层使用**双向链表**存储。\n- **Vector**：作为`List`接口的**古老**实现类；**线程安全的，效率低**；底层使用`Object[] elementData`**数组**存储；数组长度动态扩容时每次扩容2倍。不常使用\n\nList接口中的常用方法\n\n``` java\nvoid add(int index, Object ele) //在index位置插入ele元素\nboolean addAll(int index, Collection eles) //从index位置开始将eles中的所有元素添加进来\nObject get(int index) //获取指定index位置的元素\nint indexOf(Object obj) //返回obj在集合中首次出现的位置\nint lastIndexOf(Object obj) //返回obj在当前集合中末次出现的位置\nObject remove(int index) //移除指定index位置的元素，并返回此元素\nObject set(int index, Object ele) //设置指定index位置的元素为ele\nList subList(int fromIndex, int toIndex) //返回从fromIndex到toIndex位置的子集合\n```\n\n总结：\n\n- 增：add(Object obj) \n- 删：remove(int index) / remove(Object obj)\n- 改：set(int index, Object ele)\n- 查：get(int index)\n- 插：add(int index, Object ele)\n- 长度：size() \n- 遍历：\n  - Iterator迭代器方式\n  - 增强for循环\n  - 普通的循环\n\n注意：remove方法有两个重载，一个是删除指定索引位置，一个是删除指定对象\n\n### ArrayList\n\n`ArrayList`的源码分析\n\n jdk 7情况下：\n\n``` java\nArrayList list = new ArrayList();//底层创建了长度是10的Object[]数组elementData\nlist.add(123);//elementData[0] = new Integer(123);\n...\nlist.add(11);//如果此次的添加导致底层elementData数组容量不够，则扩容1.5倍。\n```\n\n默认情况下，扩容为原来的容量的1.5倍，**同时需要将原有数组中的数据复制到新的数组中**。**结论：建议开发中使用带参的构造器：ArrayList list = new ArrayList(int capacity);**\n\njdk 8中`ArrayList`的变化：\n\n ```java\nArrayList list = new ArrayList();//底层Object[] elementData初始化为{}.并没有创建长度为10的数组\nlist.add(123);//第一次调用add()时，底层才创建了长度10的数组，并将数据123添加到elementData[0]\n...\n ```\n\n后续的添加和扩容操作与jdk 7无异。\n\n小结：jdk 7中的ArrayList的对象的创建类似于单例的**饿汉式**，而jdk 8中的`ArrayList`的对象的创建类似于单例的**懒汉式**，延迟了数组的创建，节省内存。\n\n### LinkedList\n\n`LinkedList`的源码分析：\n\n```` java\nLinkedList list = new LinkedList(); //内部声明了Node类型的first和last属性，默认值为null\nlist.add(123);//将123封装到Node中，创建了Node对象。\n````\n\n其中，Node定义为：体现了LinkedList的双向链表的说法\n\n``` java\nprivate static class Node<E> {\n    E item;\n    Node<E> next;\n    Node<E> prev;\n\n    Node(Node<E> prev, E element, Node<E> next) {\n        this.item = element;\n        this.next = next;\n        this.prev = prev;\n    }\n}\n```\n\n### Vector\n\n`Vector`的源码分析：jdk7和jdk8中通过`Vector()`构造器创建对象时，底层都创建了长度为10的数组。在扩容方面，默认扩容为原来的数组长度的2倍。\n\n**问：ArrayList、LinkedList、Vector三者的异同？**\n\n- 同：三个类都是实现了`List`接口，存储数据的特点相同：存储**有序的、可重复的**数据\n- 异：\n  - `ArrayList`和`Vector`区别：`ArrayList`效率高，线程不安全，`Vector`效率低，线程安全；数组长度动态扩容倍数不同；\n  - `ArrayList`和`LinkedList`的区别：`ArrayList`使用**数组**结构存储，`LinkedList`使用**双向链表**结构存储；`LinkedList`适用于频繁插入删除数据，`Array`适用于频繁查询某个位置数据；\n\n## Set 接口\n\nSet接口：存储无序的、不可重复的数据。`Set`接口中没有额外定义新的方法，使用的都是`Collection`中声明过的方法。其实现类有三个：\n\n- **HashSet**：作为`Set`接口的**主要实现类**；**线程不安全的（可使用Collections工具类返回线程安全的`HashSet`**；可以存储`null`值；遍历时无法按照添加时的顺序遍历（`HashSet`底层是通过`HashMap`实现的，HashSet中的值就是`HashMap`中的key）\n  - **LinkedHashSet**：作为`HashSet`的子类；遍历其内部数据时，**可以按照添加的顺序遍历**。对于频繁的**遍历**操作，`LinkedHashSet`效率高于`HashSet`。\n- **TreeSet**：可以按照添加对象的指定属性，进行排序。\n\n使用要求：向`Set`(主要指：`HashSet`、`LinkedHashSet`)中添加的数据，**其所在的类一定要重写hashCode()和equals()方法**。并且重写的`hashCode()`和`equals()`尽可能保持一致性：相等的对象必须具有相等的hashCode 值。重写两个方法的小技巧：对象中用作 `equals() `方法比较的 `Field`，都应该用来计算 hashCode 值。\n\n---\n\n> https://cloud.tencent.com/developer/article/1622192\n\n- OpenJDK默认的`hashCode(`)方法实现和对象内存地址无关，在版本6和7中，它是随机生成的数字，在版本8中，它是**基于线程状态的数字**。（[AZUL-ZING](https://www.azul.com/products/zing/virtual-machine/)的hashcode是基于地址的）\n- 在Hotspot中，hash值会存在对象头中。\n- `hashCode()`方法和`System.identityHashCode()`会让对象不能使用偏向锁，所以如果想使用偏向锁，那就最好重写hashCode方法。\n\n---\n\n### HashSet\n\n `HashSet`底层：数组+链表的结构（`HashSet `本质上是 `HashMap`）。\n\n- **无序性**：不等于随机性。存储的数据在底层数组中并非按照数组索引的顺序添加，而是根据数据的哈希值决定的。\n- **不可重复性**：保证添加的元素按照`equals()`判断时，不能返回true。即：相同的元素只能添加一个。\n\n添加元素的过程：\n\n- 向`HashSet`中添加元素a，首先调用元素a所在类的`hashCode`()方法，计算元素a的哈希值，此哈希值接着通过某种算法计算出在`HashSet`底层数组中的存放位置（即为：索引位置）；\n- 判断数组此位置上是否已经有元素：如果此位置上没有其他元素，则元素a添加成功。（情况1）\n- 如果此位置上有其他元素b(或以链表形式存在的多个元素），则比较元素a与元素b的hash值：\n  - 如果hash值不相同，则元素a添加成功。（情况2）\n  - 如果hash值相同，进而需要调用元素a所在类的`equals()`方法：`equals()`返回true，元素a添加失败；`equals()`返回false，则元素a添加成功。（情况3）\n\n对于添加成功的情况2和情况3而言：元素a与已经存在指定索引位置上数据以**链表**的方式存储。jdk 7：元素a放到数组中，指向原来的元素。jdk 8：原来的元素在数组中，指向元素a\n\n![image-20210617201737187](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210617201737187.png)\n\n``` java\n@Test\npublic void test1(){\n    Set set = new HashSet();\n    set.add(456);\n    set.add(123);\n    set.add(123);\n    set.add(\"AA\");\n    set.add(\"CC\");\n    set.add(new User(\"Tom\",12));\n    set.add(new User(\"Tom\",12));\n    set.add(129);\n\n    Iterator iterator = set.iterator();\n    while(iterator.hasNext()){\n        System.out.println(iterator.next());\n    }\n}\n```\n\n**`HashSet `本质上是 `HashMap`**：\n\n`HashSet `的 `add()` 方法调用的就是 `HashMap `的 `put()` 方法，`add()` 方法传入的值就是 `HashMap `里的 `key`，`value `为一个共用的 `Object` 常量 `PRESENT`（不放 `null `是因为 `remove()` 时要判断是否为空）：\n\n![image-20210918132643499](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210918132643499.png)\n\n![image-20210918132711870](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210918132711870.png)\n\n### LinkedHashSet\n\n`LinkedHashSet`作为`HashSet`的子类，在添加数据的同时，每个数据还维护了两个引用，记录此数据前一个数据和后一个数据（类似于双向链表结构）。优点：对于频繁的遍历操作，`LinkedHashSet`效率高于`HashSet`。\n![image-20210617202602059](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210617202602059.png)\n\n``` java\n@Test\npublic void test2(){\n    Set set = new LinkedHashSet();\n    set.add(456);\n    set.add(123);\n    set.add(123);\n    set.add(\"AA\");\n    set.add(\"CC\");\n    set.add(new User(\"Tom\",12));\n    set.add(new User(\"Tom\",12));\n    set.add(129);\n\n    Iterator iterator = set.iterator();\n    while(iterator.hasNext()){\n        System.out.println(iterator.next());\n    }\n}\n```\n\n### TreeSet\n\n`TreeSet `是 `SortedSet `接口的实现类，`TreeSet `可以确保集合元素处于排序状态。`TreeSet`底层使用**红黑树**结构存储数据。特点：有序，查询速度比List快。\n\n向`TreeSet`中添加的数据，要求是**相同类**的对象。两种排序方式：自然排序（实现`Comparable`接口）和定制排序（`Comparator`）。自然排序中，比较两个对象是否相同的标准为：`compareTo()`返回0，不再使用`equals()`。定制排序中，比较两个对象是否相同的标准为：`compare()`返回0，不再使用`equals()`。\n\n``` java\n@Test\npublic void test2(){\n    Comparator com = new Comparator() {\n        //按照年龄从小到大排列\n        @Override\n        public int compare(Object o1, Object o2) {\n            if(o1 instanceof User && o2 instanceof User){\n                User u1 = (User)o1;\n                User u2 = (User)o2;\n                return Integer.compare(u1.getAge(),u2.getAge());\n            }else{\n                throw new RuntimeException(\"输入的数据类型不匹配\");\n            }\n        }\n    };\n\n    // 构造函数传入Comparator类的对象后将不再使用原先的compareTo方法判断\n    TreeSet set = new TreeSet(com);\n    set.add(new User(\"Tom\",12));\n    set.add(new User(\"Jerry\",32));\n    set.add(new User(\"Jim\",2));\n    set.add(new User(\"Mike\",65));\n    set.add(new User(\"Mary\",33));\n    set.add(new User(\"Jack\",33));\n    set.add(new User(\"Jack\",56));\n\n    Iterator iterator = set.iterator();\n    while(iterator.hasNext()){\n        System.out.println(iterator.next());\n    }\n}\n```\n\n**List和Set插入数据时判断是否重复的方法：**\n\n- List：遍历每个元素，调用其`equals()`方法判断是否相等。效率较低。\n- Set：计算插入数据的哈希值，判断是否已经存在该哈希值，不存在说明没有重复；若存在则调用`equals()`方法判断是否相等。效率较高。\n\n### Set 的使用\n\nList实现类对象和Set实现类对象可以相互转换，用于过滤List中重复的元素\n\n```java\n//练习：在List内去除重复数字值，要求尽量简单\n//方法：将List对象赋给Set对象，其会过滤掉重复的元素，再将其转回List\npublic static List duplicateList(List list) {\n    HashSet set = new HashSet();\n    set.addAll(list);\n    return new ArrayList(set);\n}\n\n@Test\npublic void test2(){\n    List list = new ArrayList();\n    list.add(new Integer(1));\n    list.add(new Integer(2));\n    list.add(new Integer(2));\n    list.add(new Integer(4));\n    list.add(new Integer(4));\n    List list2 = duplicateList(list);\n    for (Object integer : list2) {\n        System.out.println(integer);\n    }\n}\n```\n\n考察Set接口的底层原理：\n\n\n``` java\n@Test\npublic void test3(){\n    HashSet set = new HashSet();\n    Person p1 = new Person(1001,\"AA\");\n    Person p2 = new Person(1002,\"BB\");\n\n    set.add(p1);\n    set.add(p2);\n    System.out.println(set);\n\n    p1.name = \"CC\";\n    set.remove(p1);\n    System.out.println(set);\n    set.add(new Person(1001,\"CC\"));\n    System.out.println(set);\n    set.add(new Person(1001,\"AA\"));\n    System.out.println(set);\n}\n```\n\n ## Map 接口\n\n> 详解：https://imlql.cn/post/cbc5672a.html\n\n`Map`：双列数据，存储key-value对的数据\n\n- `HashMap`：作为Map的主要实现类；**线程不安全的（可使用Collections工具类返回线程安全的`HashMap`），效率高**；可以存储null的key和value；不可以按照添加的顺序实现遍历（`HashSet`底层是通过`HashMap`实现的，`HashSet`中的值就是`HashMap`中的key）\n  - `LinkedHashMap`：继承自`HashMap`，保证在遍历map元素时，**可以按照添加的顺序实现遍历**。原因：在原有的HashMap底层结构基础上，添加了一对指针，指向前一个和后一个元素。对于频繁的遍历操作，此类执行效率高于`HashMap`\n- `TreeMap`：保证按照添加的key-value对进行排序，实现排序遍历。此时考虑key的自然排序或定制排序。底层使用**红黑树**\n- `Hashtable`：作为古老的实现类；**线程安全的，效率低**；不能存储null的key和value；其他实现细节和`HashMap`一致\n  - `Properties`：常用来处理配置文件。key和value都是`String`类型\n\n`HashMap`的底层：数组+链表 （jdk7及之前）；数组+链表+红黑树 （jdk 8）\n\n问：\n\n1. `HashMap`的底层实现原理？\n2. `HashMap `和 `Hashtable`的异同？\n   - HashMap是线程不安全的，效率高，可以存储null的key和value\n   - Hashtable是线程安全的，效率低，不可以存储null的key和value\n3. `CurrentHashMap `与 `Hashtable`的异同？\n\n### Map 结构的理解：\n\n`Map`中的key：**无序的、不可重复的**，使用`Set`存储所有的key。key所在的类要重写`equals()`和`hashCode() `方法（以HashMap为例）\n\n`Map`中的value：**无序的、可重复的**，使用`Collection`存储所有的value。value所在的类要重写`equals()`方法。\n\n一个键值对：key-value构成了一个`Entry`对象。`Map`中的`Entry`：**无序的、不可重复的**，使用`Set`存储所有的`Entry`\n\njdk 8.0 后是Node ，只记 Node\n\n### HashMap 的底层实现原理\n\n> https://www.bilibili.com/video/BV1Kb411W75N?p=552\n\n`HashMap `底层是： `Node `类型的数组 + `Node `类型的单向链表 + 红黑树（jdk1.8）\n\n以jdk7为例说明：\n\n``` java\nHashMap map = new HashMap();\n```\n\n在实例化以后，底层创建了长度是16的一维数组`Entry[] table`。经过执行过多次put()方法...\n\n``` java\nmap.put(key1,value1);\n```\n\n首先，调用key1所在类的`hashCode()`计算key1哈希值，此哈希值经过某种算法计算以后（一些位运算操作），得到在`Entry`数组中的存放位置。如果此位置上的数据为空，此时的key1-value1添加成功。 ---- 情况1\n\n如果此位置上的数据不为空(意味着此位置上存在一个或多个数据(以**链表**形式存在))，比较key1和已经存在的一个或多个数据的哈希值：\n\n- 如果key1的哈希值与已经存在的数据的哈希值都不相同，此时key1-value1添加成功。---- 情况2\n- 如果key1的哈希值和已经存在的某一个数据(key2-value2)的哈希值相同，继续比较：调用key1所在类的`equals(key2)`方法，比较：\n  - 如果`equals()`返回false：此时key1-value1添加成功。----情况3\n  - 如果`equals()`返回true：使用value1替换value2。\n\n补充：关于情况2和情况3：此时key1-value1和原来的数据以**链表**的方式存储。\n\n在不断的添加过程中，会涉及到扩容问题，当超出临界值(且要存放的位置非空)时，扩容。默认的扩容方式：扩容为原来容量的2倍，并将原有的数据复制过来。\n\n![image-20210625091437538](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210625091437538.png)\n\n**jdk 8 相较于 jdk 7 在底层实现方面的不同：**\n\n1. `new HashMap();` 底层没有立刻创建一个长度为16的数组\n2. jdk 8底层的数组是：`Node[]`，而非`Entry[]`\n3. 首次调用`put()`方法时，底层创建长度为16的数组\n4. jdk7底层结构只有：数组+链表。jdk8中底层结构：数组+链表+**红黑树**。\n   - 形成链表时，七上八下（jdk7:新的元素指向旧的元素。jdk8：旧的元素指向新的元素）\n   - 当数组的某一个索引位置上的元素以链表形式存在的数据个数 > 8 且当前数组的长度 > 64时，此时此索引位置上的所数据改为使用红黑树存储（若数组长度 < 64，则数组扩容，不改用红黑树）。\n\n![image-20210625091347684](/images/%E3%80%90Java%E3%80%91%E9%9B%86%E5%90%88/image-20210625091347684.png)\n\n`HashMap` 内重要常量（背诵）：\n\n- `DEFAULT_INITIAL_CAPACITY `: `HashMap`的默认容量，**16**\n- `DEFAULT_LOAD_FACTOR`：`HashMap`的默认加载因子：**0.75**\n- `threshold`：扩容的临界值，等于容量*填充因子：`16 * 0.75 => 12`，大于该值时扩容\n- `TREEIFY_THRESHOLD`：`Bucket`中链表长度大于该默认值，转化为红黑树：8\n- `MIN_TREEIFY_CAPACITY`：桶中的`Node`被树化时最小的hash表容量：64\n\n问：负载因子值的大小，对HashMap有什么影响？\n\n- 负载因子的大小决定了HashMap的数据密度。 \n- 负载因子越大密度越大，发生碰撞的几率越高，数组中的链表越容易长, 造成查询或插入时的比较次数增多，性能会下降。 \n- 负载因子越小，就越容易触发扩容，数据密度也越小，意味着发生碰撞的几率越小，数组中的链表也就越短，查询和插入时比较的次数也越小，性能会更高。但是会浪费一定的内容空间。而且经常扩容也会影响性能，建议初始化预设大一点的空间。 \n- 按照其他语言的参考及研究经验，会考虑将负载因子设置为0.7~0.75，此时平均检索长度接近于常数。\n\n### LinkedHashMap 的底层实现原理\n\n继承自`HashMap`。修改了`Entry`的内容，增加了两个Entry类型对象代表链表结构中当前对象指向的前后对象。\n\n``` java\nstatic class Entry<K,V> extends HashMap.Node<K,V> {\n    Entry<K,V> before, after;//能够记录添加的元素的先后顺序\n    Entry(int hash, K key, V value, Node<K,V> next) {\n        super(hash, key, value, next);\n    }\n}\n```\n\n### HashMap 常用方法\n\n``` java\npublic class MapTest {\n\n    /*\n \t元视图操作的方法：\n \tSet keySet()：返回所有key构成的Set集合\n \tCollection values()：返回所有value构成的Collection集合\n \tSet entrySet()：返回所有key-value对构成的Set集合\n     */\n\n    @Test\n    public void test5(){\n        Map map = new HashMap();\n        map.put(\"AA\",123);\n        map.put(45,1234);\n        map.put(\"BB\",56);\n\n        //遍历所有的key集：keySet()\n        Set set = map.keySet();\n            Iterator iterator = set.iterator();\n            while(iterator.hasNext()){\n                System.out.println(iterator.next());\n        }\n        System.out.println();\n        \n        //遍历所有的value集：values()\n        Collection values = map.values();\n        for(Object obj : values){\n            System.out.println(obj);\n        }\n        System.out.println();\n        \n        //遍历所有的key-value\n        //方式一：entrySet()\n        Set entrySet = map.entrySet();\n        Iterator iterator1 = entrySet.iterator();\n        while (iterator1.hasNext()){\n            Object obj = iterator1.next();\n            //entrySet集合中的元素都是entry\n            Map.Entry entry = (Map.Entry) obj;\n            System.out.println(entry.getKey() + \"---->\" + entry.getValue());\n\n        }\n        System.out.println();\n        \n        //方式二：\n        Set keySet = map.keySet();\n        Iterator iterator2 = keySet.iterator();\n        while(iterator2.hasNext()){\n            Object key = iterator2.next();\n            Object value = map.get(key);\n            System.out.println(key + \"=====\" + value);\n        }\n    }\n\n\n    /*\n \t元素查询的操作：\n \tObject get(Object key)：获取指定key对应的value\n \tboolean containsKey(Object key)：是否包含指定的key\n \tboolean containsValue(Object value)：是否包含指定的value\n \tint size()：返回map中key-value对的个数\n \tboolean isEmpty()：判断当前map是否为空\n \tboolean equals(Object obj)：判断当前map和参数对象obj是否相等\n     */\n    @Test\n    public void test4(){\n        Map map = new HashMap();\n        map.put(\"AA\",123);\n        map.put(45,123);\n        map.put(\"BB\",56);\n        // Object get(Object key)\n        System.out.println(map.get(45));\n        //containsKey(Object key)\n        boolean isExist = map.containsKey(\"BB\");\n        System.out.println(isExist);\n\n        isExist = map.containsValue(123);\n        System.out.println(isExist);\n\n        map.clear();\n\n        System.out.println(map.isEmpty());\n    }\n\n    /*\n\t添加、删除、修改操作：\n \tObject put(Object key,Object value)：将指定key-value添加到(或修改)当前map对象中\n \tvoid putAll(Map m):将m中的所有key-value对存放到当前map中\n \tObject remove(Object key)：移除指定key的key-value对，并返回value\n \tvoid clear()：清空当前map中的所有数据\n     */\n    @Test\n    public void test3(){\n        Map map = new HashMap();\n        //添加\n        map.put(\"AA\",123);\n        map.put(45,123);\n        map.put(\"BB\",56);\n        //修改\n        map.put(\"AA\",87);\n\n        System.out.println(map);\n\n        Map map1 = new HashMap();\n        map1.put(\"CC\",123);\n        map1.put(\"DD\",123);\n\n        map.putAll(map1);\n\n        System.out.println(map);\n\n        //remove(Object key)\n        Object value = map.remove(\"CC\");\n        System.out.println(value);\n        System.out.println(map);\n\n        //clear()\n        map.clear();//与map = null操作不同\n        System.out.println(map.size());\n        System.out.println(map);\n    }\n\n    @Test\n    public void test2(){\n        Map map = new HashMap();\n        map = new LinkedHashMap();\n        map.put(123,\"AA\");\n        map.put(345,\"BB\");\n        map.put(12,\"CC\");\n\n        System.out.println(map);\n    }\n\n\n    @Test\n    public void test1(){\n        Map map = new HashMap();\n//        map = new Hashtable();\n        map.put(null,123);\n\n    }\n}\n\n```\n\n### TreeMap\n\n向TreeMap中添加key-value，要求key必须是由同一个类创建的对象。因为要**按照key进行排序**：自然排序 、定制排序。\n\n``` java\npublic class TreeMapTest {\n    //自然排序\n    @Test\n    public void test1(){\n        TreeMap map = new TreeMap();\n        User u1 = new User(\"Tom\",23);\n        User u2 = new User(\"Jerry\",32);\n        User u3 = new User(\"Jack\",20);\n        User u4 = new User(\"Rose\",18);\n\n        map.put(u1,98);\n        map.put(u2,89);\n        map.put(u3,76);\n        map.put(u4,100);\n\n        Set entrySet = map.entrySet();\n        Iterator iterator1 = entrySet.iterator();\n        while (iterator1.hasNext()){\n            Object obj = iterator1.next();\n            Map.Entry entry = (Map.Entry) obj;\n            System.out.println(entry.getKey() + \"---->\" + entry.getValue());\n        }\n    }\n\n    //定制排序\n    @Test\n    public void test2(){\n        TreeMap map = new TreeMap(new Comparator() {\n            @Override\n            public int compare(Object o1, Object o2) {\n                if(o1 instanceof User && o2 instanceof User){\n                    User u1 = (User)o1;\n                    User u2 = (User)o2;\n                    return Integer.compare(u1.getAge(),u2.getAge());\n                }\n                throw new RuntimeException(\"输入的类型不匹配！\");\n            }\n        });\n        User u1 = new User(\"Tom\",23);\n        User u2 = new User(\"Jerry\",32);\n        User u3 = new User(\"Jack\",20);\n        User u4 = new User(\"Rose\",18);\n\n        map.put(u1,98);\n        map.put(u2,89);\n        map.put(u3,76);\n        map.put(u4,100);\n\n        Set entrySet = map.entrySet();\n        Iterator iterator1 = entrySet.iterator();\n        while (iterator1.hasNext()){\n            Object obj = iterator1.next();\n            Map.Entry entry = (Map.Entry) obj;\n            System.out.println(entry.getKey() + \"---->\" + entry.getValue());\n        }\n    }\n}\n```\n\n## Collections 工具类\n\n`Collections` 是一个操作 `Set`、`List` 和 `Map` 等集合的工具类（操作数组的工具类：`Arrays`）\n\n`Collections` 中提供了一系列静态的方法对集合元素进行排序、查询和修改等操作， 还提供了对集合对象设置不可变、对集合对象实现同步控制等方法。\n\n其提供的线程安全功能是通过 `synchronized` 方式加锁，其效率不高，也不常用。通常使用 JUC 包下的 **CopyOnWriteArrayList** 类实现集合类的线程安全功能。\n\n排序操作：（均为`static`方法） \n\n- `reverse(List)`：反转`List`中元素的顺序 \n- `shuffle(List)`：对`List`集合元素进行随机排序 \n- `sort(List)`：根据元素的自然顺序对指定`List`集合元素按升序排序 \n- `sort(List，Comparator)`：根据指定的`Comparator`产生的顺序对`List`集合元素进行排序\n- `swap(List，int， int)`：将指定`List`集合中的 i 处元素和 j 处元素进行交换\n\n查找、替换\n\n- `Object max(Collection)`：根据元素的自然顺序，返回给定集合中的最大元素\n- `Object max(Collection，Comparator)`：根据 `Comparator `指定的顺序，返回给定集合中的最大元素\n- `Object min(Collection)`：根据元素的自然顺序，返回给定集合中的最小元素\n- `Object min(Collection，Comparator) `：根据 `Comparator `指定的顺序，返回给定集合中的最小元素\n- `int frequency(Collection，Object)`：返回指定集合中指定元素的出现次数 \n- `void copy(List dest,List src)`：将`src`中的内容复制到`dest`中 \n- `boolean replaceAll(List list，Object oldVal，Object newVal)`：使用新值替换 `List `对象的所有旧值\n\n**同步控制**：`Collections`类中提供了多个 `synchronizedXxx()` 方法，该方法可使将指定集合包装成**线程同步**的集合，从而可以解决多线程并发访问集合时的线程安全问题。使用 `synchronizedXxx()` 方法，将返回一个新的集合类对象，其各个方法都添加了同步代码块：\n\n``` java\npublic int hashCode() {\n    synchronized (mutex) {return list.hashCode();}\n}\n\npublic E get(int index) {\n    synchronized (mutex) {return list.get(index);}\n}\n\npublic void add(int index, E element) {\n    synchronized (mutex) {list.add(index, element);}\n}\npublic E remove(int index) {\n    synchronized (mutex) {return list.remove(index);}\n}\n```\n\n\n\n``` java\npublic class CollectionsTest {\n    @Test\n    public void test2(){\n        List list = new ArrayList();\n        list.add(123);\n        list.add(43);\n        list.add(765);\n        list.add(-97);\n        list.add(0);\n\n        //报异常：IndexOutOfBoundsException(\"Source does not fit in dest\")\n//        List dest = new ArrayList();\n//        Collections.copy(dest,list);\n        //正确的：\n        List dest = Arrays.asList(new Object[list.size()]);\n        System.out.println(dest.size());//list.size();\n        Collections.copy(dest,list);\n\n        System.out.println(dest);\n\n        /*\n        Collections 类中提供了多个 synchronizedXxx() 方法，\n        该方法可使将指定集合包装成线程同步的集合，从而可以解决\n        多线程并发访问集合时的线程安全问题\n         */\n        //返回的list1即为线程安全的List\n        List list1 = Collections.synchronizedList(list);\n    }\n\n    @Test\n    public void test1(){\n        List list = new ArrayList();\n        list.add(123);\n        list.add(43);\n        list.add(765);\n        list.add(765);\n        list.add(765);\n        list.add(-97);\n        list.add(0);\n        System.out.println(list);\n\n//        Collections.reverse(list);\n//        Collections.shuffle(list);\n//        Collections.sort(list);\n//        Collections.swap(list,1,2);\n        int frequency = Collections.frequency(list, 123);\n\n        System.out.println(list);\n        System.out.println(frequency);\n    }\n}\n```\n\n问：`Collection` 和 `Collections` 的区别？\n\n- `Collection`：集合中的一种接口，其实现类有`ArrayList`，`LinkedArrayList`等。\n- `Collections`：集合工具类，用于对集合进行排序、查找等操作。\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】String","url":"/2021/03/16/【Java】String/","content":"\n## String 的基本特性\n\nString：字符串，使用一对 `\"\"` 引起来表示。Java 程序中的所有字符串**字面值**（如`\"abc\"`）都作为此类的实例实现。\n\n```java\nString s1 = \"hello\";                // 字面量的定义方式\nString s2 =  new String(\"hello\");   // new 对象的方式\n```\n\n- `String`是一个**final**类，代表**不可变**的**字符序列**，其不可被继承。\n- 字符串是**常量**，用双引号引起来表示。它们的值在创建之后**不能更改**。\n- `String`对象的字符内容是存储在一个**字符数组常量**`final char value[]`中的。\n- `String`实现了`Serializable`接口：表示字符串是支持**序列化**的。实现了`Comparable`接口：表示`String`可以**比较大小**。\n\n![img](/images/%E3%80%90Java%E3%80%91String/image-20210625102721429-1633660803855.png)\n\n### String 的不可变性\n\nString：代表**不可变的字符序列**。简称：不可变性。\n\n1. 当对字符串重新赋值时，需要**重新指定内存区域赋值**，不能使用原有的value进行赋值。\n2. 当对现有的字符串进行连接操作时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值。\n3. 当调用`String`的`replace()`方法修改指定字符或字符串时，也需要重新指定内存区域赋值，不能使用原有的value进行赋值。\n4. 通过**字面量**（如`\"abc\"`）的方式（**区别于new**）给一个字符串赋值，此时的字符串值声明在**字符串常量池**中\n5. 字符串常量池中是**不会存储相同内容**的字符串的。\n\n![img](/images/%E3%80%90Java%E3%80%91String/image-20210625102749139-1633660803855.png)\n\n<!-- More -->\n\n代码\n\n```java\n@Test\npublic void test1(){\n    String s1 = \"abc\"; //字面量的定义方式\n    String s2 = \"abc\";\n    s1 = \"hello\";\n\n    System.out.println(s1 == s2);//比较s1和s2的地址值 false\n    System.out.println(s1);//hello\n    System.out.println(s2);//abc\n\n    System.out.println(\"*****************\");\n\n    String s3 = \"abc\";\n    s3 += \"def\";\n    System.out.println(s3);//abcdef\n    System.out.println(s2);//abc\n\n    System.out.println(\"*****************\");\n\n    String s4 = \"abc\";\n    String s5 = s4.replace('a', 'm');\n    System.out.println(s4);//abc\n    System.out.println(s5);//mbc\n}\n```\n\n### String 的实例化方式\n\n- 方式一：通过**字面量**定义的方式 `String str1 = \"abc\";`，此对象存储在字符串常量池中\n- 方式二：通过**new + 构造器**的方式 `String str2 = new String(\"abc\");`，此时创建两个对象，一个 String 对象 `\"abc \"` 存储在字符串常量池中，另一个 `str2` 存储在普通堆空间中\n\n二者区别：\n\n- 下图中的两个橙色块代表两个 String 对象\n- 直接用字面量形式创建的对象 `str1` 存在于**字符串常量池**中，其内维护了一份唯一的字符串数据 `char[] value = \"abc\"`\n- 用 new 的方式创建的 String 对象存在于**堆区**中，和上一种方式的对象是不同的\n\n二者的联系在于普通堆区内的 String 对象内部维护的 `char[] value` 数组其实指向的是常量池中的 String 对象内部维护的 `char[] value`，即同一个字符串数据只存在一份于字符串常量池中，普通堆区的 String 对象只是引用了该数据\n\n![image-20210625103416513](/images/%E3%80%90Java%E3%80%91String/image-20210625103416513-1633660803855.png)\n\n---\n\n问：`String str = new String(\"abc\");`方式创建对象，在内存中创建了几个对象？\n\n答：两个。一个 `String` 对象 `\"abc \"` 存储在字符串常量池中（在常量池的 `Hashtable` 结构中），另一个 `str` 存储在普通堆空间中。\n\n注意这个 `str` 内部的 `char[]` 数组的地址就是在字符串常量池中 `\"abc\"` 对象的 `char[]` 数组地址，即在普通堆区 new 出来的多个 String 对象，他们如果内容相同，那么内部的 `char[]` 数组的地址就是同一个地址（指向存储在字符串常量池中的真正数据 `\"abc \"` ），本身不会再去创建新的` char[]` 数据了，而是共享常量池中的同一份 ` char[]`。\n\n同时，在普通堆内存空间中存在的 String 对象 `str` 是会被 GC 的，但是在字符串常量池中的匿名 `String` 对象 `\"abc \"` 不会被轻易 GC，只有当所有引用该对象内的 `char[] value` 的 String 对象都不存在了才会被回收。 \n\n---\n\n我们也可以从字节码角度分析这两种创建方式的差异：\n\n```java\npublic static void main(String[] args) {\n    String a = \"a\";\n    String b = new String(\"b\");\n}\n```\n\n![image-20211013151732410](/images/%E3%80%90Java%E3%80%91String/image-20211013151732410.png)\n\n- `0  ldc #2 <a>`：从字符串常量池中加载` \"a\"` 这个字符串到操作数栈中\n- `2  asrore_1`：将操作数栈中存储的 `\"a\"` 保存到局部变量表中索引位置为1的位置（即赋值给对象 a）\n- `3  new #3 <java/lang/String>`：new 一个 String 对象（即 b 对象，但此时还未初始化，对象属性只是初始值）放到操作数栈中\n- `6  dup`：将 new 的 String 对象复制一份同样放到操作数栈中\n- `7  ldc #4 <b>`：从字符串常量池中加载 `\"b\"` 这个字符串到操作数栈中\n- `9  invokespecial #5 <java/lang/String.<init>>`：调用 String 类的 `<init>` 方法（包含构造器），将 6 中复制出的 String 和 7 中载入的 \"b\" 字符串弹栈，传入到该方法中，从而真正地完成了一个 String 类型对象（此时已经做了初始化）的创建和初始化，将该对象放回到操作数栈中\n- `12  astore_2`：将 9 中初始化完毕的 String 对象存储到局部变量表中索引位置为1的位置（即赋值给对象 b）\n- `13  return`：方法返回\n\n从上述流程中可以看出：\n\n- 字面量形式的对象在程序启动加载阶段就已经被创建好放到了字符串常量池中，而不是等到执行该方法时才创建\n- 字面量形式没有再 new 一个对象，而是把字符串常量池里已经存在的对象的地址赋给了引用对象 a\n\n### 字符串对象存储方式\n\n下图中堆区value指向 `\"javaEE\"` 的红色箭头代表每个对象内的 `char[] value` 都是共享的常量池中的唯一一份 `char[] value`（它同样存储在一个 String 对象中）：\n\n![image-20210625103432649](/images/%E3%80%90Java%E3%80%91String/image-20210625103432649-1633660803855.png)\n\n![image-20210625103730602](/images/%E3%80%90Java%E3%80%91String/image-20210625103730602-1633660803855.png)\n\n字符串的特性：\n\n![image-20210625103806711](/images/%E3%80%90Java%E3%80%91String/image-20210625103806711-1633660803856.png)\n\n结论：\n\n- 常量与常量的拼接结果在常量池。且常量池中不会存在相同内容的常量。\n- **只要其中有一个是变量，结果就在堆中**。原理是底层创建了一个 `StringBuilder` 对象，将字符串拼接完毕后返回了一个存储在堆中的 `String` 类型对象\n- 如果拼接的结果调用`intern()`方法，返回值就在常量池中。\n\n测试代码：\n\n```java\n@Test\npublic void test2(){\n    //通过字面量定义的方式：此时的s1和s2的数据javaEE声明在方法区中的字符串常量池中。\n    String s1 = \"javaEE\";\n    String s2 = \"javaEE\";\n    //通过new + 构造器的方式:此时的s3和s4保存的地址值，是数据在堆空间中开辟空间以后对应的地址值。\n    String s3 = new String(\"javaEE\");\n    String s4 = new String(\"javaEE\");\n\n    System.out.println(s1 == s2);//true\n    System.out.println(s1 == s3);//false\n    System.out.println(s1 == s4);//false\n    System.out.println(s3 == s4);//false\n\n    System.out.println(\"***********************\");\n    Person p1 = new Person(\"Tom\",12);\n    Person p2 = new Person(\"Tom\",12);\n\n    System.out.println(p1.name.equals(p2.name));//true\n    System.out.println(p1.name == p2.name);//true\n\n    p1.name = \"Jerry\";\n    System.out.println(p2.name);//Tom\n}\n\n@Test\npublic void test3(){\n    String s1 = \"javaEE\";\n    String s2 = \"hadoop\";\n\n    String s3 = \"javaEEhadoop\";\n    String s4 = \"javaEE\" + \"hadoop\";\n    String s5 = s1 + \"hadoop\";\n    String s6 = \"javaEE\" + s2;\n    String s7 = s1 + s2;\n\n    System.out.println(s3 == s4);//true\n    System.out.println(s3 == s5);//false\n    System.out.println(s3 == s6);//false\n    System.out.println(s3 == s7);//false\n    System.out.println(s5 == s6);//false\n    System.out.println(s5 == s7);//false\n    System.out.println(s6 == s7);//false\n\n    String s8 = s6.intern();//返回值得到的s8使用的常量值中已经存在的“javaEEhadoop”\n    System.out.println(s3 == s8);//true\n\n}\n\n/*\n    结论：\n    1.常量与常量的拼接结果在常量池。且常量池中不会存在相同内容的常量。\n    2.只要其中有一个是变量，结果就在堆中。\n    3.如果拼接的结果调用intern()方法，返回值就在常量池中\n*/\n@Test\npublic void test4(){\n    String s1 = \"javaEEhadoop\";\n    String s2 = \"javaEE\";\n    String s3 = s2 + \"hadoop\";\n    System.out.println(s1 == s3);//false\n\n    final String s4 = \"javaEE\";//s4:常量\n    String s5 = s4 + \"hadoop\";\n    System.out.println(s1 == s5);//true\n\n}\n```\n\n面试题\n\n```java\npublic class StringExer {\n    String str = new String(\"good\");\n    char [] ch = {'t','e','s','t'};\n\n    public void change(String str, char[] ch) {\n        str = \"test ok\";\n        ch[0] = 'b';\n    }\n\n    public static void main(String[] args) {\n        StringExer ex = new StringExer();\n        ex.change(ex.str, ex.ch);\n        System.out.println(ex.str);\n        System.out.println(ex.ch);\n    }\n}\n```\n\n输出结果\n\n```\ngood\nbest\n```\n\n原因：\n\n- `ex.str`传入`change()`方法后，在栈中创建了一个局部变量`str`，其同样指向字符串常量池中的`\"good\"`匿名对象，此时`str = \"test ok\"`执行后，将在字符串常量池中新建一个匿名字符串对象 `\"test ok\"`，并且被局部变量 `str` 所指向，但`ex.str`的内容保持不变（仍然指向字符串常量 `\"good\"`）；\n- `ex.ch`传入`change()`方法后，在栈中创建了局部变量`ch[]`，其同样指向`ex.ch`数组，但修改`ch[0]`会导致`ex.ch`的内容同样被修改。\n\n二者的区别在于：`String`类对象和`char[]`数组对象作为形参传入时都是引用类型，修改形参时原本对象也应该被修改，但`String`类的不可变性导致修改形参时在常量池中创建了新的字符串内容，因此原本对象内容没有改变，但`char`数组并无此特性，因此会被修改。\n\n\n\n### String 的底层结构\n\n**字符串常量池是不会存储相同内容的字符串的**\n\nString 的 String Pool（字符串常量池）是一个固定大小的`Hashtable`，默认值大小长度是1009。如果放进String Pool的String对象非常多，就会造成Hash冲突严重，从而导致链表会很长，而链表长了后直接会造成的影响就是当调用`String.intern()`方法时去常量池中查找是否已经存在某个字符串时性能会大幅下降。\n\n使用`-XX:StringTablesize`可设置StringTable的长度\n\n- 在JDK 6中`StringTable`是固定的，就是1009的长度，所以如果常量池中的字符串过多就会导致效率下降很快，`StringTablesize`设置没有要求\n- 在JDK 7中，`StringTable`的长度默认值是60013，`StringTablesize`设置没有要求\n- 在JDK 8中，`StringTable`的长度默认值是60013，`StringTable`可以设置的最小值为1009\n\n\n\n### 为什么 JDK 9 改变了 String 结构\n\n> **官方文档**：http://openjdk.java.net/jeps/254\n\n**为什么改为 byte[] 存储？**\n\nString类的当前实现将字符存储在char[]数组中，每个字符使用两个字节(16位)。\n\n从许多不同的应用程序收集的数据表明，**字符串是堆使用的主要组成部分**，而且大多数字符串对象**只包含拉丁字符**（Latin-1）。这些字符只需要一个字节的存储空间，**因此这些字符串对象的内部char数组中有一半的空间将不会使用，产生了大量浪费。**\n\n之前 String 类使用 UTF-16 的 `char[]` 数组存储，JDK 9改为 `byte[]` 数组 外加一个**编码标识存储**。该编码表示如果你的字符是ISO-8859-1或者Latin-1，那么只需要一个字节存。如果你是其它字符集，比如UTF-8，你仍然用两个字节存\n\n结论：在 JDK 9 之后，String再也不用 `char[]` 来存储了，改成了 `byte []` 加上编码标记，节约了一些空间。\n\n```java\n// 之前\nprivate final char value[];\n// 之后\nprivate final byte[] value\n```\n\n同时基于String的数据结构，例如`StringBuffer`和`StringBuilder`也同样做了修改。\n\n\n\n## String 的内存分配\n\n在Java语言中有8种基本数据类型和一种比较特殊的类型String。这些类型为了使它们在运行过程中速度更快、更节省内存，都提供了一种常量池的概念。\n\n常量池就类似一个Java系统级别提供的缓存。8种基本数据类型的常量池都是系统协调的，String类型的常量池比较特殊。它的主要使用方法有两种：\n\n- 直接使用双引号声明出来的字面量String对象会直接存储在常量池中。比如：`String info=\"hello\";`\n- 如果不是用双引号声明的String对象，可以使用String提供的`intern()`方法将对象存储在常量池中。这个后面重点谈\n\n存放位置调整：\n\n- Java 6及以前，字符串常量池存放在**永久代**\n- Java 7后oracle的工程师对字符串池的逻辑做了很大的改变，即将字符串常量池的位置调整到Java**堆内**\n\n>所有的字符串都保存在堆（Heap）中，和其他普通对象一样，这样可以让你在进行调优应用时仅需要调整堆大小就可以了。\n>\n>字符串常量池概念原本使用得比较多，但是这个改动使得我们有足够的理由让我们重新考虑在Java 7中使用String.intern（）。\n\nJava 8 元空间，字符串常量在堆区：\n\n![image-20200711093546398](/images/%E3%80%90Java%E3%80%91String/image-20200711093546398.png)\n\n![image-20200711093558709](/images/%E3%80%90Java%E3%80%91String/image-20200711093558709.png)\n\n### 为什么 StringTable 从永久代调整到堆中\n\n为什么要调整位置？\n\n- 永久代的默认空间大小比较小\n- 永久代垃圾回收频率低，大量的字符串无法及时回收，容易进行Full GC产生STW或者容易产生`OOM：PermGen Space`\n- 堆中空间足够大，字符串可被及时回收\n\n在JDK 7中，interned字符串不再在Java堆的永久代中分配，而是在Java堆的主要部分（称为年轻代和年老代）中分配，与应用程序创建的其他对象一起分配。\n\n此更改将导致驻留在主Java堆中的数据更多，驻留在永久生成中的数据更少，因此可能需要调整堆大小。\n\n## String 的基本操作\n\nJava语言规范里要求完全相同的字符串字面量，应该包含同样的Unicode字符序列（包含同一份码点序列的常量），并且必须是指向同一个String类实例。\n\n``` java\n//官方示例代码\nclass Memory {\n    public static void main(String[] args) {//line 1\n        int i = 1;//line 2\n        Object obj = new Object();//line 3\n        Memory mem = new Memory();//line 4\n        mem.foo(obj);//line 5\n    }//line 9\n\n    private void foo(Object param) {//line 6\n        String str = param.toString();//line 7\n        System.out.println(str);\n    }//line 8\n}\n```\n\n分析运行时内存（`foo()` 方法是实例方法，其实图中少了一个 `this` 局部变量）\n\n![img](/images/%E3%80%90Java%E3%80%91String/0010.png)\n\n\n\n\n\n## 字符串拼接操作\n\n- 常量与常量的拼接结果在常量池，原理是**编译期优化**\n- 常量池中不会存在相同内容的变量\n- **只要其中有一个是变量，结果就在堆中**。变量拼接的原理是使用 `StringBuilder`\n- 如果拼接的结果调用 `intern()` 方法，则**主动将常量池中还没有的字符串对象放入池中，并返回此对象地址**\n\n### 字符串常量间的拼接\n\n字符串常量与常量的拼接结果在常量池，原理是**编译期优化**\n\n```java\n@Test\npublic void test1() {\n  String s1 = \"a\" + \"b\" + \"c\"; //编译期优化：等同于\"abc\"\n  String s2 = \"abc\"; //\"abc\"一定是放在字符串常量池中，将此地址赋给s2\n  /*\n         * 最终.java编译成.class,再执行.class\n         * String s1 = \"abc\";\n         * String s2 = \"abc\"\n         */\n  System.out.println(s1 == s2); //true\n  System.out.println(s1.equals(s2)); //true\n}\n```\n\n从字节码指令看出：编译器做了优化，将 `\"a\" + \"b\" + \"c\"` 优化成了 `\"abc\"`\n\n```\n0 ldc #2 <abc>   <--------  这里直接载入的是 \"abc\" \n2 astore_1\n3 ldc #2 <abc>\n5 astore_2\n6 getstatic #3 <java/lang/System.out>\n9 aload_1\n10 aload_2\n11 if_acmpne 18 (+7)\n14 iconst_1\n15 goto 19 (+4)\n18 iconst_0\n19 invokevirtual #4 <java/io/PrintStream.println>\n22 getstatic #3 <java/lang/System.out>\n25 aload_1\n26 aload_2\n27 invokevirtual #5 <java/lang/String.equals>\n30 invokevirtual #4 <java/io/PrintStream.println>\n33 return\n```\n\n### 字符串变量间的拼接\n\n- 拼接前后，**只要其中有一个是变量，结果就在堆中**\n- 调用 `intern()` 方法，则主动将字符串对象存入字符串常量池中，并将其地址返回\n\n```java\n@Test\npublic void test2(){\n  String s1 = \"javaEE\";\n  String s2 = \"hadoop\";\n\n  String s3 = \"javaEEhadoop\";\n  String s4 = \"javaEE\" + \"hadoop\";//编译期优化\n  //如果拼接符号的前后出现了变量，则相当于在堆空间中new String()，具体的内容为拼接的结果：javaEEhadoop\n  String s5 = s1 + \"hadoop\";\n  String s6 = \"javaEE\" + s2;\n  String s7 = s1 + s2;\n\n  System.out.println(s3 == s4);//true\n  System.out.println(s3 == s5);//false\n  System.out.println(s3 == s6);//false\n  System.out.println(s3 == s7);//false\n  System.out.println(s5 == s6);//false\n  System.out.println(s5 == s7);//false\n  System.out.println(s6 == s7);//false\n  \n  //intern():判断字符串常量池中是否存在javaEEhadoop值，如果存在，则返回常量池中javaEEhadoop的地址；\n  //如果字符串常量池中不存在javaEEhadoop，则在常量池中加载一份javaEEhadoop，并返回次对象的地址。\n  String s8 = s6.intern();\n  System.out.println(s3 == s8);//true\n}\n```\n\n底层原理：字符串变量间的拼接操作的**底层其实使用了 `StringBuilder`**\n\n![image-20200711102231129](/images/%E3%80%90Java%E3%80%91String/image-20200711102231129.png)\n\n`s1 + s2` 的执行细节：\n\n- `StringBuilder s = new StringBuilder();`\n- `s.append(s1);`\n- `s.append(s2);`\n- `s.toString();`  -> 类似于`new String(\"ab\");`\n\n在JDK 5之后，使用的是 `StringBuilder`，在JDK5之前使用的是 `StringBuffer`\n\n| String                                                       | StringBuffer                                                 | StringBuilder    |\n| ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------- |\n| String的值是不可变的，这就导致每次对String的操作都会生成新的String对象，不仅效率低下，而且浪费大量优先的内存空间 | StringBuffer是可变类，和线程安全的字符串操作类，任何对它指向的字符串的操作都不会产生新的对象。每个StringBuffer对象都有一定的缓冲区容量，当字符串大小没有超过容量时，不会分配新的容量，当字符串大小超过容量时，会自动增加容量 | 可变类，速度更快 |\n| 不可变                                                       | 可变                                                         | 可变             |\n|                                                              | 线程安全                                                     | 线程不安全       |\n|                                                              | 多线程操作字符串                                             | 单线程操作字符串 |\n\n注意，我们左右两边如果是变量的话，就是需要`new StringBuilder`进行拼接，但是如果使用的是 `final` 修饰，则是从常量池中获取。\n\n所以说拼接符号左右两边都是字符串常量或常量引用，则仍然使用编译器优化。也就是说被 `final` 修饰的变量，将会变成常量。\n\n在开发中，能够使用 `final` 的时候，建议使用上\n\n```java\npublic static void test4() {\n    final String s1 = \"a\";\n    final String s2 = \"b\";\n    String s3 = \"ab\";\n    String s4 = s1 + s2;\n    System.out.println(s3 == s4);\n}\n```\n\n运行结果\n\n```\ntrue\n```\n\n### 拼接操作和 append() 性能对比\n\n```java\n    public static void method1(int highLevel) {\n        String src = \"\";\n        for (int i = 0; i < highLevel; i++) {\n            src += \"a\"; // 每次循环都会创建一个StringBuilder对象\n        }\n    }\n\n    public static void method2(int highLevel) {\n        StringBuilder sb = new StringBuilder();\n        for (int i = 0; i < highLevel; i++) {\n            sb.append(\"a\");\n        }\n    }\n```\n\n方法1耗费的时间：4005ms，方法2消耗时间：7ms\n\n结论：通过 `StringBuilder` 的 `append()` 方式添加字符串的效率，要远远高于 String 的字符串拼接方法\n\n `StringBuilder` 的 `append()` 方式，自始至终只创建一个 `StringBuilder` 的对象\n\n而使用String的字符串拼接方式：\n\n- 还需要创建很多 `StringBuilder` 对象和调用 `toString()` 时候创建的 String 对象\n- 内存中由于创建了较多的 `StringBuilder` 和 String 对象，内存占用过大，如果进行GC那么将会耗费更多的时间\n\n改进的空间：\n\n- 在实际开发中，如果基本确定要前前后后添加的字符串长度不高于某个限定值highLevel的情况下，建议使用构造器实例化：\n- `StringBuilder s = new StringBuilder(highLevel);  // new char[highLevel]`\n- 这样可以避免频繁扩容\n\n## intern() 的使用\n\n> intern()：将字符串对象放到字符串常量池的**内部**\n\n```java\npublic native String intern();\n```\n\n`intern()` 是一个 native方法，调用的是底层C的方法\n\n字符串池最初是空的，由String类私有地维护。在调用 `intern()` 方法时，如果池中已经包含了由 `equals(object)` 方法确定的与该字符串对象相等的字符串，**则返回池中的字符串对象的地址**。否则，**该字符串对象将被添加到池中，并返回对该字符串对象的引用。**\n\n如果不是用双引号声明的String对象，可以使用String提供的 `intern()` 方法：`intern()` 方法会从字符串常量池中查询当前字符串是否存在，若不存在就会将当前字符串放入常量池中（好处是可以减少堆中存放的大量冗余字符串对象），并将常量池中该对象的地址返回给引用对象。\n\n比如：\n\n```\nString myInfo = new string(\"hello\").intern();\n```\n\n也就是说，如果在任意字符串上调用 `String.intern()` 方法，**那么其返回结果所指向的那个类实例，必须和直接以常量形式出现的字符串实例完全相同**。因此，下列表达式的值必定是true\n\n```java\n(\"a\"+\"b\"+\"c\").intern（）==\"abc\"\n```\n\n通俗点讲，**`intern()` 就是确保字符串在内存里只有一份拷贝，这样可以节约内存空间，加快字符串操作任务的执行速度**。注意，这个值会被存放在字符串内部池（String Intern Pool）\n\n### intern() 的空间效率测试\n\n我们通过测试一下，使用了 `intern()` 和不使用的时候，其实相差还挺多的\n\n```java\npublic class StringIntern2 {\n    static final int MAX_COUNT = 1000 * 10000;\n    static final String[] arr = new String[MAX_COUNT];\n\n    public static void main(String[] args) {\n        Integer [] data = new Integer[]{1,2,3,4,5,6,7,8,9,10};\n        long start = System.currentTimeMillis();\n        for (int i = 0; i < MAX_COUNT; i++) {\n            arr[i] = new String(String.valueOf(data[i%data.length])).intern();\n        }\n        long end = System.currentTimeMillis();\n        System.out.println(\"花费的时间为：\" + (end - start));\n\n        try {\n            Thread.sleep(1000000);\n        } catch (Exception e) {\n            e.getStackTrace();\n        }\n    }\n}\n```\n\n**结论**：对于程序中大量使用存在的字符串时，尤其存在很多已经重复的字符串时，**使用 `intern()` 方法能够节省内存空间**，因为其将冗余的对象都GC，只在常量池里保存一份字符串数据。\n\n大的网站平台，需要内存中存储大量的字符串。比如社交网站，很多人都存储：北京市、海淀区等信息。这时候如果字符串都调用 `intern()` 方法，就会很明显降低内存的大小。\n\n## String 相关的面试题\n\n### new String(\"ab\") 会创建几个对象\n\n```java\n/**\n * 题目：\n * new String(\"ab\")会创建几个对象？看字节码，就知道是两个。\n *     一个对象是：new关键字在堆空间创建的\n *     另一个对象是：字符串常量池中的对象\"ab\"。 字节码指令：ldc\n *\n */\npublic class StringNewTest {\n    public static void main(String[] args) {\n        String str = new String(\"ab\");\n    }\n}\n```\n\n我们转换成字节码来查看\n\n```\n 0 new #2 <java/lang/String>\n 3 dup\n 4 ldc #3 <ab>\n 6 invokespecial #4 <java/lang/String.<init>>\n 9 astore_1\n10 return\n```\n\n这里面就是两个对象\n\n- 一个对象是：new关键字在堆空间中创建\n- 另一个对象：字符串常量池中的对象\n\n### new String(\"a\") + new String(\"b\") 会创建几个对象\n\n```java\n/**\n * 思考：\n * new String(\"a\") + new String(\"b\")呢？\n *  对象1： new StringBuilder()\n *  对象2： new String(\"a\")\n *  对象3： 常量池中的\"a\"\n *  对象4： new String(\"b\")\n *  对象5： 常量池中的\"b\"\n *\n *  深入剖析： StringBuilder的toString():\n *       对象6 ：new String(\"ab\")\n *       强调一下，toString()的调用，在字符串常量池中，没有生成\"ab\"\n *\n */\npublic class StringNewTest {\n    public static void main(String[] args) {\n        String str = new String(\"a\") + new String(\"b\");\n    }\n}\n```\n\n字节码文件为\n\n```\n 0 new #2 <java/lang/StringBuilder>\n 3 dup\n 4 invokespecial #3 <java/lang/StringBuilder.<init>>\n 7 new #4 <java/lang/String>\n10 dup\n11 ldc #5 <a>\n13 invokespecial #6 <java/lang/String.<init>>\n16 invokevirtual #7 <java/lang/StringBuilder.append>\n19 new #4 <java/lang/String>\n22 dup\n23 ldc #8 <b>\n25 invokespecial #6 <java/lang/String.<init>>\n28 invokevirtual #7 <java/lang/StringBuilder.append>\n31 invokevirtual #9 <java/lang/StringBuilder.toString>\n34 astore_1\n35 return\n```\n\n我们创建了6个对象\n\n- 对象1：new StringBuilder()\n- 对象2：new String(\"a\")\n- 对象3：常量池的 a\n- 对象4：new String(\"b\")\n- 对象5：常量池的 b\n- 对象6：toString中会创建一个 new String(\"ab\")\n  - 调用toString方法，不会在常量池中生成ab\n\n字节码指令分析：\n\n1. `0 new #2 <java/lang/StringBuilder>` ：拼接字符串会创建一个 `StringBuilder` 对象\n2. `7 new #4 <java/lang/String>` ：创建 String 对象，对应于 `new String(\"a\")`\n3. `11 ldc #5 <a>` ：在字符串常量池中放入 `\"a\"`（如果之前字符串常量池中没有 `\"a\"` 的话）\n4. `19 new #4 <java/lang/String>` ：创建 String 对象，对应于 `new String(\"b\")`\n5. `23 ldc #8 <b>` ：在字符串常量池中放入 `\"b\"`（如果之前字符串常量池中没有 `\"b\"` 的话）\n6. `31 invokevirtual #9 <java/lang/StringBuilder.toString>` ：调用 `StringBuilder` 的 `toString() `方法，会生成一个 String 对象\n\n但是需要注意，`StringBuilder` 的 `toString() `方法是直接将其内维护的 `char[] value`数组内的元素通过构造器赋值给新建的 String 对象，而并没有以字面量的形式出现这个拼接后的字符串，因此不会在字符串常量池中创建 `\"ab\"` 对象，只有通过 `intern()` 方法才会将该对象存储到常量池中。\n\n![img](/images/%E3%80%90Java%E3%80%91String/0012.png)\n\n### intern() 相关的面试题\n\n```java\n/**\n * 如何保证变量s指向的是字符串常量池中的数据呢？\n * 有两种方式：\n * 方式一： String s = \"shkstart\"; // 字面量定义的方式\n * 方式二： 调用intern()\n *         String s = new String(\"shkstart\").intern();\n *         String s = new StringBuilder(\"shkstart\").toString().intern();\n *\n */\npublic class \tStringIntern {\n  public static void main(String[] args) {\n\n    String s = new String(\"1\");\n    s.intern();//调用此方法之前，字符串常量池中已经存在了\"1\"\n    String s2 = \"1\";\n    System.out.println(s == s2);//jdk6：false   jdk7/8：false\n\n    /*\n         1、s3变量记录的地址为：new String(\"11\")\n         2、经过上面的分析，我们已经知道执行完pos_1的代码，在堆中有了一个new String(\"11\")\n         这样的String对象。但是在字符串常量池中没有\"11\"\n         3、接着执行s3.intern()，在字符串常量池中生成\"11\"\n           3-1、在JDK6的版本中，字符串常量池还在永久代，所以直接在永久代生成\"11\",也就有了新的地址\n           3-2、而在JDK7的后续版本中，字符串常量池被移动到了堆中，此时堆里已经有new String（\"11\"）了\n           出于节省空间的目的，直接将堆中的那个字符串的引用地址储存在字符串常量池中。没错，字符串常量池中存的是new String(\"11\")在堆中的地址\n         4、所以在JDK7后续版本中，s3和s4指向的完全是同一个地址。\n         */\n    String s3 = new String(\"1\") + new String(\"1\");//pos_1\n    s3.intern();\n\n    String s4 = \"11\";//s4变量记录的地址：使用的是上一行代码代码执行时，在常量池中生成的\"11\"的地址\n    System.out.println(s3 == s4);//jdk6：false  jdk7/8：true\n  }\n}\n```\n\n解释的已经比较清楚了，下面看一下内存图\n\n**内存分析**\n\nJDK 6 ：正常眼光判断即可\n\n- `new String()` 即在堆中\n- `str.intern()` 则把字符串放入常量池中\n\n因为 JDK 6 中字符串常量池存储在永久代，其不在堆中，因此就是单纯的将字符串放到常量池中（不像 JDK 7 后的操作，将引用保存在常量池里）\n\n![img](/images/%E3%80%90Java%E3%80%91String/0013.png)\n\nJDK 7 及后续版本，**注意大坑**：因为字符串常量池移动到了堆区，因此为了节省空间，就不再常量池里拷贝一份字符串副本了，而是直接创建一个对象引用已经存在于堆区中的字符串对象（后续再引用该常量池里的对象时，其地址直接等于了存在于堆区的对象）\n\n![img](/images/%E3%80%90Java%E3%80%91String/0014.png)\n\n#### 面试题的拓展\n\n```java\n/**\n * StringIntern.java中练习的拓展：\n *\n */\npublic class StringIntern1 {\n  public static void main(String[] args) {\n    //执行完下一行代码以后，字符串常量池中，是否存在\"11\"呢？答案：不存在！！\n    String s3 = new String(\"1\") + new String(\"1\");//new String(\"11\")\n    //在字符串常量池中生成对象\"11\"，代码顺序换一下，实打实的在字符串常量池里有一个\"11\"对象\n    String s4 = \"11\";  \n    String s5 = s3.intern();\n\n    // s3 是堆中的 \"ab\" ，s4 是字符串常量池中的 \"ab\"\n    System.out.println(s3 == s4);//false\n\n    // s5 是从字符串常量池中取回来的引用，当然和 s4 相等\n    System.out.println(s5 == s4);//true\n  }\n}\n```\n\n### intern() 方法的练习\n\n**练习 1**\n\n```java\npublic class StringExer1 {\n  public static void main(String[] args) {\n\n    String s = new String(\"a\") + new String(\"b\");//new String(\"ab\")\n    //在上一行代码执行完以后，字符串常量池中并没有\"ab\"\n    /*\n\t\t1、jdk6中：在字符串常量池（此时在永久代）中创建一个字符串\"ab\"\n        2、jdk8中：字符串常量池（此时在堆中）中没有创建字符串\"ab\",而是创建一个引用，指向new String(\"ab\")，\t\t  将此引用返回\n        3、详解看上面\n\t\t*/\n    String s2 = s.intern();\n\n    System.out.println(s2 == \"ab\"); // jdk6:true  jdk8:true\n    System.out.println(s == \"ab\");  // jdk6:false  jdk8:true\n  }\n}\n```\n\n**JDK 6**\n\n[![image-20201116113423492](/images/%E3%80%90Java%E3%80%91String/0015.png)](https://cdn.jsdelivr.net/gh/youthlql/lqlp@v1.1.0/JVM/chapter_009/0015.png)\n\n**JDK 7/8**\n\n![image-20200711151326909](/images/%E3%80%90Java%E3%80%91String/image-20200711151326909.png)\n\n**练习 2**\n\n```java\npublic class StringExer1 {\n  public static void main(String[] args) {\n    // 相比于 练习1 多了这一行\n    String x = \"ab\";\n    String s = new String(\"a\") + new String(\"b\");//new String(\"ab\")\n\n    String s2 = s.intern();\n\n    System.out.println(s2 == \"ab\"); // jdk6:true  jdk8:true\n    System.out.println(s == \"ab\");  // jdk6:false  jdk8:false\n  }\n}\n```\n\n这种情况下，因为已经使用字面量的形式将 `\"ab\"` 添加到了常量池中，所以后续的 `intern()` 就不会再像 练习1 一样指向 `s` 了\n\n![image-20200711151433277](/images/%E3%80%90Java%E3%80%91String/image-20200711151433277.png)\n\n**练习 3**\n\n```java\npublic class StringExer2 {\n  public static void main(String[] args) {\n    String s1 = new String(\"ab\");//执行完以后，会在字符串常量池中会生成\"ab\"\n\n    // 注意没有返回值时，s1指向的仍然不变\n    // 只有intern()方法的返回值才会指向常量池里的地址，调用者自身不会改变地址\n    s1.intern();\n    String s2 = \"ab\";\n    System.out.println(s1 == s2); // false\n  }\n}\n```\n\n**练习 4**\n\n```java\npublic class StringExer2 {\n  // 对象内存地址可以使用System.identityHashCode(object)方法获取\n  public static void main(String[] args) {\n    String s1 = new String(\"a\") + new String(\"b\");//执行完以后，不会在字符串常量池中会生成\"ab\"\n    System.out.println(System.identityHashCode(s1));\n    \n    // 注意，上面拼接的方式没有在常量池中创建字符串\n    // 因此这里会在常量池里创建对象引用 s1\n    s1.intern();\n    System.out.println(System.identityHashCode(s1));\n    \n    String s2 = \"ab\";\n    System.out.println(System.identityHashCode(s2));\n    System.out.println(s1 == s2); // true\n  }\n}\n```\n\n输出结果：\n\n```\n1836019240\n1836019240\n1836019240\ntrue\n```\n\n## String 使用陷阱\n\n- `String s1 = \"a\"; `说明：在字符串常量池中创建了一个字面量为`\"a\"`的字符串。\n- `s1 = s1 + \"b\"; `说明：实际上原来的`\"a\"`字符串对象已经丢弃了，现在在堆空间中产生了一个字符串`s1+\"b\"`（也就是`\"ab\"`)。如果多次执行这些改变串内容的操作，会**导致大量副本字符串对象存留在内存中，降低效率**。如果这样的操作放到循环中，会极大影响程序的性能。\n- `String s2 = \"ab\"; `说明：直接在字符串常量池中创建一个字面量为`\"ab\"`的字符串。\n- `String s3 = \"a\" + \"b\"; `说明：s3指向字符串常量池中已经创建的`\"ab\"`的字符串（编译期间优化时就将这行代码替换成了 `String s3 = \"ab\"`）。\n- `String s4 = s1.intern(); `说明：堆空间的s1对象在调用`intern()`之后，会将常量池中已经存在的`\"ab\"`字符串的地址赋值给s4。\n\n![image-20210625105035027](/images/%E3%80%90Java%E3%80%91String/image-20210625105035027.png)\n\n面试题：\n\n![image-20210625105058682](/images/%E3%80%90Java%E3%80%91String/image-20210625105058682.png)\n\n结果：输出 good and best。原因：\n\n- `ex.str`传入`change()`方法后，在栈中创建了一个局部变量`str`，其同样指向`ex.str`所指向的字符串常量\"good\"，此时`str = \"test ok\"`执行后，局部变量str所指向的字符串常量变为\"test ok\"，但`ex.str`的内容保持不变（仍然指向字符串常量\"good\"）；\n- `ex.ch`传入`change()`方法后，在栈中创建了局部变量`ch[]`，其同样指向`ex.ch`数组，但修改`ch[0]`会导致`ex.ch`的内容同样被修改。\n\n二者的区别在于：`String`类对象和`char`数组对象作为形参传入时都是引用类型，修改形参时原本对象也应该被修改，但`String`类的不可变性导致修改形参时在常量池中创建了新的字符串内容，因此原本对象内容没有改变，但`char`数组并无此特性，因此会被修改。\n\n## String 常用方法\n\n- `int length()`：返回字符串的长度： return value.length\n- `char charAt(int index)`： 返回某索引处的字符return value[index]\n- `boolean isEmpty()`：判断是否是空字符串：return value.length == 0\n- `String toLowerCase()`：使用默认语言环境，将 String 中的所有字符转换为小写\n- `String toUpperCase()`：使用默认语言环境，将 String 中的所有字符转换为大写\n- `String trim()`：返回字符串的副本，忽略前导空白和尾部空白 \n- `boolean equals(Object obj)`：比较字符串的内容是否相同 \n- `boolean equalsIgnoreCase(String anotherString)`：与equals方法类似，忽略大小写 \n- `String concat(String str)`：将指定字符串连接到此字符串的结尾。 等价于用“+” \n- `int compareTo(String anotherString)`：比较两个字符串的大小 \n- `String substring(int beginIndex)`：返回一个新的字符串，它是此字符串的从 beginIndex开始截取到最后的一个子字符串。 \n- `String substring(int beginIndex, int endIndex)` ：返回一个新字符串，它是此字符串从beginIndex开始截取到endIndex(不包含)的一个子字符串。\n- `boolean endsWith(String suffix)`：测试此字符串是否以指定的后缀结束\n- `boolean startsWith(String prefix)`：测试此字符串是否以指定的前缀开始\n- `boolean startsWith(String prefix, int toffset)`：测试此字符串从指定索引开始的子字符串是否以指定前缀开始\n- `boolean contains(CharSequence s)`：当且仅当此字符串包含指定的 char 值序列时，返回 true\n\n### 索引\n\n- `int indexOf(String str)`：返回指定子字符串在此字符串中第一次出现处的索引\n- `int indexOf(String str, int fromIndex)`：返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始\n- `int lastIndexOf(String str)`：返回指定子字符串在此字符串中最右边出现处的索引\n- `int lastIndexOf(String str, int fromIndex)`：返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索\n\n注：`indexOf`和`lastIndexOf`方法如果未找到都是返回-1\n\n### 替换\n\n- `String replace(char oldChar, char newChar)`：返回一个新的字符串，它是通过用 `newChar `替换此字符串中出现的所有 `oldChar `得到的。\n- `String replace(CharSequence target, CharSequence replacement)`：使用指定的字面值替换序列替换此字符串所有匹配字面值目标序列的子字符串。\n- `String replaceAll(String regex, String replacement)`：使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。\n- `String replaceFirst(String regex, String replacement)`：使用给定的 replacement 替换此字符串匹配给定的正则表达式的第一个子字符串。\n\n### 匹配\n\n- `boolean matches(String regex)`：告知此字符串是否匹配给定的正则表达式。\n\n### 切片\n\n- `String[] split(String regex)`：根据给定正则表达式的匹配拆分此字符串。\n- `String[] split(String regex, int limit)`：根据匹配给定的正则表达式来拆分此字符串，最多不超过limit个，如果超过了，剩下的全部都放到最后一个元素中。\n\n``` java\npublic class StringMethodTest {\n\n    /*\n    替换：\n    String replace(char oldChar, char newChar)：返回一个新的字符串，它是通过用 newChar 替换此字符串中出现的所有 oldChar 得到的。\n    String replace(CharSequence target, CharSequence replacement)：使用指定的字面值替换序列替换此字符串所有匹配字面值目标序列的子字符串。\n    String replaceAll(String regex, String replacement)：使用给定的 replacement 替换此字符串所有匹配给定的正则表达式的子字符串。\n    String replaceFirst(String regex, String replacement)：使用给定的 replacement 替换此字符串匹配给定的正则表达式的第一个子字符串。\n    匹配:\n    boolean matches(String regex)：告知此字符串是否匹配给定的正则表达式。\n    切片：\n    String[] split(String regex)：根据给定正则表达式的匹配拆分此字符串。\n    String[] split(String regex, int limit)：根据匹配给定的正则表达式来拆分此字符串，最多不超过limit个，如果超过了，剩下的全部都放到最后一个元素中。\n    */\n    @Test\n    public void test4(){\n        String str1 = \"北京教育北京\";\n        String str2 = str1.replace('北', '东');\n\n        System.out.println(str1);\n        System.out.println(str2);\n\n        String str3 = str1.replace(\"北京\", \"上海\");\n        System.out.println(str3);\n\n        System.out.println(\"*************************\");\n        String str = \"12hello34world5java7891mysql456\";\n        //把字符串中的数字替换成,，如果结果中开头和结尾有，的话去掉\n        String string = str.replaceAll(\"\\\\d+\", \",\").replaceAll(\"^,|,$\", \"\");\n        System.out.println(string);\n\n        System.out.println(\"*************************\");\n        str = \"12345\";\n        //判断str字符串中是否全部有数字组成，即有1-n个数字组成\n        boolean matches = str.matches(\"\\\\d+\");\n        System.out.println(matches);\n        String tel = \"0571-4534289\";\n        //判断这是否是一个杭州的固定电话\n        boolean result = tel.matches(\"0571-\\\\d{7,8}\");\n        System.out.println(result);\n\n        System.out.println(\"*************************\");\n        str = \"hello|world|java\";\n        String[] strs = str.split(\"\\\\|\");\n        for (int i = 0; i < strs.length; i++) {\n            System.out.println(strs[i]);\n        }\n        System.out.println();\n        str2 = \"hello.world.java\";\n        String[] strs2 = str2.split(\"\\\\.\");\n        for (int i = 0; i < strs2.length; i++) {\n            System.out.println(strs2[i]);\n        }\n    }\n\n    /*\n    boolean endsWith(String suffix)：测试此字符串是否以指定的后缀结束\n    boolean startsWith(String prefix)：测试此字符串是否以指定的前缀开始\n    boolean startsWith(String prefix, int toffset)：测试此字符串从指定索引开始的子字符串是否以指定前缀开始\n    boolean contains(CharSequence s)：当且仅当此字符串包含指定的 char 值序列时，返回 true\n    int indexOf(String str)：返回指定子字符串在此字符串中第一次出现处的索引\n    int indexOf(String str, int fromIndex)：返回指定子字符串在此字符串中第一次出现处的索引，从指定的索引开始\n    int lastIndexOf(String str)：返回指定子字符串在此字符串中最右边出现处的索引\n    int lastIndexOf(String str, int fromIndex)：返回指定子字符串在此字符串中最后一次出现处的索引，从指定的索引开始反向搜索\n    注：indexOf和lastIndexOf方法如果未找到都是返回-1\n     */\n    @Test\n    public void test3(){\n        String str1 = \"hellowworld\";\n        boolean b1 = str1.endsWith(\"rld\");\n        System.out.println(b1);\n\n        boolean b2 = str1.startsWith(\"He\");\n        System.out.println(b2);\n\n        boolean b3 = str1.startsWith(\"ll\",2);\n        System.out.println(b3);\n\n        String str2 = \"wor\";\n        System.out.println(str1.contains(str2));\n\n        System.out.println(str1.indexOf(\"lol\"));\n\n        System.out.println(str1.indexOf(\"lo\",5));\n\n        String str3 = \"hellorworld\";\n\n        System.out.println(str3.lastIndexOf(\"or\"));\n        System.out.println(str3.lastIndexOf(\"or\",6));\n\n        //什么情况下，indexOf(str)和lastIndexOf(str)返回值相同？\n        //情况一：存在唯一的一个str。情况二：不存在str\n    }\n\n\n    /*\n    int length()：返回字符串的长度： return value.length\n    char charAt(int index)： 返回某索引处的字符return value[index]\n    boolean isEmpty()：判断是否是空字符串：return value.length == 0\n    String toLowerCase()：使用默认语言环境，将 String 中的所有字符转换为小写\n    String toUpperCase()：使用默认语言环境，将 String 中的所有字符转换为大写\n    String trim()：返回字符串的副本，忽略前导空白和尾部空白\n    boolean equals(Object obj)：比较字符串的内容是否相同\n    boolean equalsIgnoreCase(String anotherString)：与equals方法类似，忽略大小写\n    String concat(String str)：将指定字符串连接到此字符串的结尾。 等价于用“+”\n    int compareTo(String anotherString)：比较两个字符串的大小\n    String substring(int beginIndex)：返回一个新的字符串，它是此字符串的从beginIndex开始截取到最后的一个子字符串。\n    String substring(int beginIndex, int endIndex) ：返回一个新字符串，它是此字符串从beginIndex开始截取到endIndex(不包含)的一个子字符串。\n     */\n    @Test\n    public void test2() {\n        String s1 = \"HelloWorld\";\n        String s2 = \"helloworld\";\n        System.out.println(s1.equals(s2));\n        System.out.println(s1.equalsIgnoreCase(s2));\n\n        String s3 = \"abc\";\n        String s4 = s3.concat(\"def\");\n        System.out.println(s4);\n\n        String s5 = \"abc\";\n        String s6 = new String(\"abe\");\n        System.out.println(s5.compareTo(s6));//涉及到字符串排序\n\n        String s7 = \"北京尚硅谷教育\";\n        String s8 = s7.substring(2);\n        System.out.println(s7);\n        System.out.println(s8);\n\n        String s9 = s7.substring(2, 5);\n        System.out.println(s9);\n    }\n\n    @Test\n    public void test1() {\n        String s1 = \"HelloWorld\";\n        System.out.println(s1.length());\n        System.out.println(s1.charAt(0));\n        System.out.println(s1.charAt(9));\n//        System.out.println(s1.charAt(10));\n//        s1 = \"\";\n        System.out.println(s1.isEmpty());\n\n        String s2 = s1.toLowerCase();\n        System.out.println(s1);//s1不可变的，仍然为原来的字符串\n        System.out.println(s2);//改成小写以后的字符串\n\n        String s3 = \"   he  llo   world   \";\n        String s4 = s3.trim();\n        System.out.println(\"-----\" + s3 + \"-----\");\n        System.out.println(\"-----\" + s4 + \"-----\");\n    }\n}\n```\n\n## String 与其他数据类型转换\n\n### String 与基本数据类型转换\n\n- 字符串 ——> 基本数据类型、包装类 \n  - `Integer`包装类的`public static int parseInt(String s)`：可以将由“数字”字符组成的字符串转换为整型。 \n  - 类似地，使用`java.lang`包中的`Byte`、`Short`、`Long`、`Float`、`Double`类调相应的类方法可以将由“数字”字符组成的字符串，转化为相应的基本数据类型。 \n- 基本数据类型、包装类 ——> 字符串 \n  - 调用`String`类的`public static String valueOf(int n)`可将int型转换为字符串 \n  - `valueOf(byte b)`、`valueOf(long l)`、`valueOf(float f)`、`valueOf(double d)`、`valueOf(boolean b)`可由参数的相应类型到字符串的转换\n\n``` java\n// 字符串 ——> 基本数据类型、包装类 \nint num = Integer.parseInt(\"123\");\n\n// 基本数据类型、包装类 ——> 字符串 \nString str1 = String.valueOf(123);\n\n// 测试\nString str2 = num + \"\";\nSystem.out.println(str1 == str2); //false 有String变量参与的运算都会new新的对象\n```\n\n### String 与字符数组 char[] 转换\n\n- 字符数组`char[]` ——> 字符串\n  - `String `类的构造器：`String(char[]) 和 String(char[]，int offset，int length) `分别用字符数组中的全部字符和部分字符创建字符串对象。\n- 字符串 ——> 字符数组`char[]`\n  - `public char[] toCharArray()`：将字符串中的全部字符存放在一个字符数组中的方法。\n  - `public void getChars(int srcBegin, int srcEnd, char[] dst, int dstBegin)`：提供了将指定索引范围内的字符串存放到数组中的方法。\n\n``` java\n// 字符数组char[] ——> 字符串\nchar[] arr = new char[]{'h','e','l','l','o'};\nString str1 = new String(arr);\n\n// 字符串 ——> 字符数组char[]\nString str2 = \"abc123\";  \nchar[] charArray = str1.toCharArray();\n```\n\n### String 与字节数组转换\n\n- 字节数组 ——> 字符串\n  - `String(byte[])`：通过使用平台的默认字符集解码指定的 byte 数组，构造一个新的 `String`。\n  - `String(byte[]，int offset，int length) `：用指定的字节数组的一部分， 即从数组起始位置offset开始取length个字节构造一个字符串对象。 \n- 字符串  ——> 字节数组\n  - `public byte[] getBytes()` ：使用平台的默认字符集将此 `String `编码为 byte 序列，并将结果存储到一个新的 byte 数组中。\n  - `public byte[] getBytes(String charsetName)` ：使用指定的字符集将此 `String `编码到 byte 序列，并将结果存储到新的 byte 数组。\n\n``` java\n// 字节数组 ——> 字符串\nString str2 = new String(bytes);//使用默认的字符集，进行解码。\nSystem.out.println(str2);\n\nString str3 = new String(gbks);\nSystem.out.println(str3);//出现乱码。原因：编码集和解码集不一致！\n\nString str4 = new String(gbks, \"gbk\");\nSystem.out.println(str4);//没有出现乱码。原因：编码集和解码集一致！\n\n// 字符串  ——> 字节数组\nString str1 = \"abc123中国\";\nbyte[] bytes = str1.getBytes(); //使用默认的字符集，进行编码。\nSystem.out.println(Arrays.toString(bytes));\n\nbyte[] gbks = str1.getBytes(\"gbk\");//使用gbk字符集进行编码。\nSystem.out.println(Arrays.toString(gbks));\n\n```\n\n## StringBuffer 和 StringBuilder\n\n### StringBuffer\n\n `java.lang.StringBuffer`代表**可变**的字符序列，JDK1.0中声明，可以对字符串内容进行增删，此时**不会产生新的对象**。很多方法与`String`相同。作为参数传递时，方法内部可以改变值。\n\n![image-20210625131148661](/images/%E3%80%90Java%E3%80%91String/image-20210625131148661.png)\n\n`StringBuffer`类不同于`String`，其对象必须使用构造器生成。有三个构造器：\n\n- `StringBuffer()`：初始容量为16的字符串缓冲区\n- `StringBuffer(int size)`：构造指定容量的字符串缓冲区\n- `StringBuffer(String str)`：将内容初始化为指定字符串内容\n\n![image-20210625131436828](/images/%E3%80%90Java%E3%80%91String/image-20210625131436828.png)\n\n### StringBuffer 的常用方法\n\n- `StringBuffer append(xxx)`：提供了很多的append()方法，用于进行字符串拼接\n- `StringBuffer delete(int start,int end)`：删除指定位置的内容\n- `StringBuffer replace(int start, int end, String str)`：把[start,end)位置替换为str\n- `StringBuffer insert(int offset, xxx)`：在指定位置插入xxx\n- `StringBuffer reverse()` ：把当前字符序列逆转\n- `public int indexOf(String str)`\n- `public String substring(int start,int end)`:返回一个从start开始到end索引结束的左闭右开区间的子字符串\n- `public int length()`\n- `public char charAt(int n )`\n- `public void setCharAt(int n ,char ch)`\n\n当`append`和`insert`时，如果原来value数组长度不够，可扩容\n\n总结：\n\n-  增：`append(xxx)`\n-  删：`delete(int start,int end)`\n-  改：`setCharAt(int n ,char ch) / replace(int start, int end, String str)`\n-  查：`charAt(int n )`\n-  插：`insert(int offset, xxx)`\n-  长度：`length()`\n-  *遍历：`for() + charAt() / toString()`\n\n``` java\n@Test\npublic void test2(){\n    StringBuffer s1 = new StringBuffer(\"abc\");\n    s1.append(1);\n    s1.append('1');\n    System.out.println(s1);\n    // s1.delete(2,4);\n    //s1.replace(2,4,\"hello\");\n    //s1.insert(2,false);\n    //s1.reverse();\n    String s2 = s1.substring(1, 3);\n    System.out.println(s1);\n    System.out.println(s1.length());\n    System.out.println(s2);\n}\n```\n\n### StringBuilder\n\n`StringBuilder `和 `StringBuffer `非常类似，均代表**可变**的字符序列，而且提供相关功能的方法也一样。\n\n### String、StringBuffer、StringBuilder 三者的异同\n\n- `String`:**不可变**的字符序列；底层使用**final** char[]存储\n- `StringBuffer`:**可变**的字符序列；**线程安全的，效率低**；底层使用char[]存储\n- `StringBuilder`:**可变**的字符序列；jdk5.0新增的，**线程不安全的，效率高**；底层使用char[]存储\n\n对比String、StringBuffer、StringBuilder三者的效率：**从高到低排列：StringBuilder > StringBuffer > String**\n\n注意：作为参数传递时，方法内部String不会改变其值，StringBuffer和StringBuilder会改变其值（因为其内的`char[] value`不是`final`的）。\n\n **源码分析：**\n\n``` java\nString str = new String();//char[] value = new char[0];\nString str1 = new String(\"abc\");//char[] value = new char[]{'a','b','c'};\n\nStringBuffer sb1 = new StringBuffer();//char[] value = new char[16];底层创建了一个长度是16的数组。\nSystem.out.println(sb1.length());//0\nsb1.append('a');//value[0] = 'a';\nsb1.append('b');//value[1] = 'b';\n\nStringBuffer sb2 = new StringBuffer(\"abc\");//char[] value = new char[\"abc\".length() + 16];\n```\n\n- 问题1. `System.out.println(sb2.length()); ` 答：3\n- 问题2. 扩容问题：如果要添加的数据底层数组盛不下了，那就需要扩容底层的数组。默认情况下，扩容为原来容量的**2倍 + 2**，**同时将原有数组中的元素复制到新的数组中**。\n\n 开发中建议使用：`StringBuffer(int capacity)` 或` StringBuilder(int capacity)`。提前将容量设置好，以免扩容时复制元素造成时间浪费。\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】Java 常用类","url":"/2021/03/15/【Java】Java常用类/","content":"\n## 日期时间类\n\n### JDK 8 之前的日期时间类\n\n- `System`类中`currentTimeMillis()`\n- `java.util.Date`和子类`java.sql.Date`\n- `SimpleDateFormat`\n- `Calendar`\n\n``` java\npublic class DateTimeTest {\n    \n    //1.System类中的currentTimeMillis()\n    @Test\n    public void test1(){\n        long time = System.currentTimeMillis();\n        //返回当前时间与1970年1月1日0时0分0秒之间以毫秒为单位的时间差。\n        //称为时间戳\n        System.out.println(time);\n    }\n    \n    /*\n    java.util.Date类\n           |---java.sql.Date类\n\n    1.两个构造器的使用\n        >构造器一：Date()：创建一个对应当前时间的Date对象\n        >构造器二：创建指定毫秒数的Date对象\n    2.两个方法的使用\n        >toString():显示当前的年、月、日、时、分、秒\n        >getTime():获取当前Date对象对应的毫秒数。（时间戳）\n\n    3. java.sql.Date对应着数据库中的日期类型的变量\n        >如何实例化\n        >如何将java.util.Date对象转换为java.sql.Date对象\n     */\n    @Test\n    public void test2(){\n        //构造器一：Date()：创建一个对应当前时间的Date对象\n        Date date1 = new Date();\n        System.out.println(date1.toString());//Sat Feb 16 16:35:31 GMT+08:00 2019\n\n        System.out.println(date1.getTime());//1550306204104\n\n        //构造器二：创建指定毫秒数的Date对象\n        Date date2 = new Date(155030620410L);\n        System.out.println(date2.toString());\n\n        //创建java.sql.Date对象\n        java.sql.Date date3 = new java.sql.Date(35235325345L);\n        System.out.println(date3);//1971-02-13\n\n        //如何将java.util.Date对象转换为java.sql.Date对象\n        //情况一：\n        // Date date4 = new java.sql.Date(2343243242323L);\n        // java.sql.Date date5 = (java.sql.Date) date4;\n        //情况二：\n        Date date6 = new Date();\n        java.sql.Date date7 = new java.sql.Date(date6.getTime());\n    }\n}\n```\n\n<!-- More -->\n\n```java\nimport org.junit.Test;\n\nimport java.text.ParseException;\nimport java.text.SimpleDateFormat;\nimport java.util.Calendar;\nimport java.util.Date;\n\n/**\n * jdk 8之前的日期时间的API测试\n * 1. System类中currentTimeMillis();\n * 2. java.util.Date和子类java.sql.Date\n * 3. SimpleDateFormat\n * 4. Calendar\n */\npublic class DateTimeTest {\n    /*\n    SimpleDateFormat的使用：SimpleDateFormat对日期Date类的格式化和解析\n\n    1.两个操作：\n    1.1 格式化：日期 --->字符串\n    1.2 解析：格式化的逆过程，字符串 ---> 日期\n\n    2.SimpleDateFormat的实例化\n\n     */\n    @Test\n    public void testSimpleDateFormat() throws ParseException {\n        //实例化SimpleDateFormat:使用默认的构造器\n        SimpleDateFormat sdf = new SimpleDateFormat();\n\n        //格式化：日期 --->字符串\n        Date date = new Date();\n        System.out.println(date);\n\n        String format = sdf.format(date);\n        System.out.println(format);\n\n        //解析：格式化的逆过程，字符串 ---> 日期\n        String str = \"19-12-18 上午11:43\";\n        Date date1 = sdf.parse(str);\n        System.out.println(date1);\n\n        //*************按照指定的方式格式化和解析：调用带参的构造器*****************\n//        SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyyy.MMMMM.dd GGG hh:mm aaa\");\n        SimpleDateFormat sdf1 = new SimpleDateFormat(\"yyyy-MM-dd hh:mm:ss\");\n        //格式化\n        String format1 = sdf1.format(date);\n        System.out.println(format1);//2019-02-18 11:48:27\n        //解析:要求字符串必须是符合SimpleDateFormat识别的格式(通过构造器参数体现),\n        //否则，抛异常\n        Date date2 = sdf1.parse(\"2020-02-18 11:48:27\");\n        System.out.println(date2);\n    }\n\n\n    /*\n    Calendar日历类(抽象类）的使用\n     */\n    @Test\n    public void testCalendar(){\n        //1.实例化\n        //方式一：创建其子类（GregorianCalendar）的对象\n        //方式二：调用其静态方法getInstance()\n        Calendar calendar = Calendar.getInstance();\n//        System.out.println(calendar.getClass());\n\n        //2.常用方法\n        //get()\n        int days = calendar.get(Calendar.DAY_OF_MONTH);\n        System.out.println(days);\n        System.out.println(calendar.get(Calendar.DAY_OF_YEAR));\n\n        //set()\n        //calendar可变性\n        calendar.set(Calendar.DAY_OF_MONTH,22);\n        days = calendar.get(Calendar.DAY_OF_MONTH);\n        System.out.println(days);\n\n        //add()\n        calendar.add(Calendar.DAY_OF_MONTH,-3);\n        days = calendar.get(Calendar.DAY_OF_MONTH);\n        System.out.println(days);\n\n        //getTime():日历类---> Date\n        Date date = calendar.getTime();\n        System.out.println(date);\n\n        //setTime():Date ---> 日历类\n        Date date1 = new Date();\n        calendar.setTime(date1);\n        days = calendar.get(Calendar.DAY_OF_MONTH);\n        System.out.println(days);\n    }\n}\n\n```\n\n### JDK 8 中新时间类\n\n- `LocalDate`\n- `LocalTime`\n- `LocalDateTime`（常用）\n- `DateTimeFormatter`（类似`SimpleTimeFormat`）\n\n``` java\nimport org.junit.Test;\n\nimport java.time.*;\nimport java.time.format.DateTimeFormatter;\nimport java.time.format.FormatStyle;\nimport java.time.temporal.TemporalAccessor;\nimport java.util.Date;\n\n/**\n * jdk 8中日期时间API的测试\n */\npublic class JDK8DateTimeTest {\n\n    @Test\n    public void testDate(){\n        //偏移量\n        Date date1 = new Date(2020 - 1900,9 - 1,8);\n        System.out.println(date1);//Tue Sep 08 00:00:00 GMT+08:00 2020\n    }\n\n    /*\n    LocalDate、LocalTime、LocalDateTime 的使用\n    说明：\n        1.LocalDateTime相较于LocalDate、LocalTime，使用频率要高\n        2.类似于Calendar\n     */\n    @Test\n    public void test1(){\n        //now():获取当前的日期、时间、日期+时间\n        LocalDate localDate = LocalDate.now();\n        LocalTime localTime = LocalTime.now();\n        LocalDateTime localDateTime = LocalDateTime.now();\n\n        System.out.println(localDate);\n        System.out.println(localTime);\n        System.out.println(localDateTime);\n\n        //of():设置指定的年、月、日、时、分、秒。没有偏移量\n        LocalDateTime localDateTime1 = LocalDateTime.of(2020, 10, 6, 13, 23, 43);\n        System.out.println(localDateTime1);\n\n\n        //getXxx()：获取相关的属性\n        System.out.println(localDateTime.getDayOfMonth());\n        System.out.println(localDateTime.getDayOfWeek());\n        System.out.println(localDateTime.getMonth());\n        System.out.println(localDateTime.getMonthValue());\n        System.out.println(localDateTime.getMinute());\n\n        //体现不可变性\n        //withXxx():设置相关的属性\n        LocalDate localDate1 = localDate.withDayOfMonth(22);\n        System.out.println(localDate);\n        System.out.println(localDate1);\n\n\n        LocalDateTime localDateTime2 = localDateTime.withHour(4);\n        System.out.println(localDateTime);\n        System.out.println(localDateTime2);\n\n        //不可变性\n        LocalDateTime localDateTime3 = localDateTime.plusMonths(3);\n        System.out.println(localDateTime);\n        System.out.println(localDateTime3);\n\n        LocalDateTime localDateTime4 = localDateTime.minusDays(6);\n        System.out.println(localDateTime);\n        System.out.println(localDateTime4);\n    }\n\n    /*\n    Instant的使用\n    类似于 java.util.Date类\n     */\n    @Test\n    public void test2(){\n        //now():获取本初子午线对应的标准时间\n        Instant instant = Instant.now();\n        System.out.println(instant);//2019-02-18T07:29:41.719Z\n\n        //添加时间的偏移量\n        OffsetDateTime offsetDateTime = instant.atOffset(ZoneOffset.ofHours(8));\n        System.out.println(offsetDateTime);//2019-02-18T15:32:50.611+08:00\n\n        //toEpochMilli():获取自1970年1月1日0时0分0秒（UTC）开始的毫秒数  ---> Date类的getTime()\n        long milli = instant.toEpochMilli();\n        System.out.println(milli);\n\n        //ofEpochMilli():通过给定的毫秒数，获取Instant实例  -->Date(long millis)\n        Instant instant1 = Instant.ofEpochMilli(1550475314878L);\n        System.out.println(instant1);\n    }\n\n    /*\n    DateTimeFormatter:格式化或解析日期、时间\n    类似于SimpleDateFormat\n     */\n\n    @Test\n    public void test3(){\n//        方式一：预定义的标准格式。如：ISO_LOCAL_DATE_TIME;ISO_LOCAL_DATE;ISO_LOCAL_TIME\n        DateTimeFormatter formatter = DateTimeFormatter.ISO_LOCAL_DATE_TIME;\n        //格式化:日期-->字符串\n        LocalDateTime localDateTime = LocalDateTime.now();\n        String str1 = formatter.format(localDateTime);\n        System.out.println(localDateTime);\n        System.out.println(str1);//2019-02-18T15:42:18.797\n\n        //解析：字符串 -->日期\n        TemporalAccessor parse = formatter.parse(\"2019-02-18T15:42:18.797\");\n        System.out.println(parse);\n\n//        方式二：\n//        本地化相关的格式。如：ofLocalizedDateTime()\n//        FormatStyle.LONG / FormatStyle.MEDIUM / FormatStyle.SHORT :适用于LocalDateTime\n        DateTimeFormatter formatter1 = DateTimeFormatter.ofLocalizedDateTime(FormatStyle.LONG);\n        //格式化\n        String str2 = formatter1.format(localDateTime);\n        System.out.println(str2);//2019年2月18日 下午03时47分16秒\n\n\n//      本地化相关的格式。如：ofLocalizedDate()\n//      FormatStyle.FULL / FormatStyle.LONG / FormatStyle.MEDIUM / FormatStyle.SHORT : 适用于LocalDate\n        DateTimeFormatter formatter2 = DateTimeFormatter.ofLocalizedDate(FormatStyle.MEDIUM);\n        //格式化\n        String str3 = formatter2.format(LocalDate.now());\n        System.out.println(str3);//2019-2-18\n\n\n//       重点： 方式三：自定义的格式。如：ofPattern(“yyyy-MM-dd hh:mm:ss”)\n        DateTimeFormatter formatter3 = DateTimeFormatter.ofPattern(\"yyyy-MM-dd hh:mm:ss\");\n        //格式化\n        String str4 = formatter3.format(LocalDateTime.now());\n        System.out.println(str4);//2019-02-18 03:52:09\n\n        //解析\n        TemporalAccessor accessor = formatter3.parse(\"2019-02-18 03:52:09\");\n        System.out.println(accessor);\n\n    }\n}\n\n```\n\n## 比较器\n\n- 自然排序：`Comparable`接口，让类本身修改代码以实现排序\n- 定制排序：`Comparator`接口\n\n### Comparable\n\n像String、包装类等实现了`Comparable`接口，重写了`compareTo(obj)`方法，给出了比较两个对象大小的方式。重写`compareTo(obj)`的规则：\n\n- 如果当前对象this大于形参对象obj，则返回正整数\n- 如果当前对象this小于形参对象obj，则返回负整数\n- 如果当前对象this等于形参对象obj，则返回零。\n\n对于自定义类来说，如果需要排序，我们可以让自定义类实现`Comparable`接口，重写`compareTo(obj)`方法。在`compareTo(obj)`方法中指明如何排序。\n\n```java\n@Override\npublic int compareTo(Object o) {\n    if(o instanceof xxx){\n        // TODO: 比较大小\n    }\n    throw new RuntimeException(\"传入的数据类型不一致！\");\n}\n```\n\n### Comparator\n\n当元素的类型没有实现`Comparable`接口而又不方便修改代码，或者实现了`Comparable`接口的排序规则不适合当前的操作，那么可以考虑使用 `Comparator `的对象来排序。重写 `Comparator `对象的`compare(Object o1, Object o2`)方法，比较o1和o2的大小：\n\n- 如果方法返回正整数，则表示o1大于o2；\n- 如果返回0，表示相等；\n- 返回负整数，表示o1小于o2。\n\n``` java\n@Test\npublic void test(){\n    String[] arr = new String[]{\"AA\",\"CC\",\"KK\",\"MM\",\"GG\",\"JJ\",\"DD\"};\n    Arrays.sort(arr,new Comparator(){\n        //按照字符串从大到小的顺序排列\n        @Override\n        public int compare(Object o1, Object o2) {\n            if(o1 instanceof String && o2 instanceof  String){\n                String s1 = (String) o1;\n                String s2 = (String) o2;\n                return -s1.compareTo(s2);\n            }\n            throw new RuntimeException(\"输入的数据类型不一致\");\n        }\n    });\n    System.out.println(Arrays.toString(arr));\n}\n```\n\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】多线程","url":"/2021/03/14/【Java】多线程/","content":"\n## 基本概念\n\n>  进程（Process） 是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。 在当代面向线程设计的计算机结构中，进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。是计算机中的程序关于某数据集合上的一次运行活动，是系统进行资源分配和调度的基本单位，是操作系统结构的基础。程序是指令、数据及其组织形式的描述，进程是程序的实体。\n>\n> 线程（thread） 是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务。\n\n- 进程：指在系统中正在运行的一个应用程序；程序一旦运行就是一个进程；进程——**资源分配的最小单位**\n- 线程：系统分配处理器时间资源的基本单元，或者说进程之内独立执行的一个单元执行流；线程——**程序执行的最小单位**\n\n举例解释进程与线程：\n\n- IDEA 这个应用程序启动后就是一个单独的进程\n- IDEA 里的各种语法提示、错误报警等功能都是一个个线程并发运行\n\n并发和并行的区别：\n\n- 并行：同一个**时间点**多个线程**一起**执行\n- 并发：同一个**时间段**多个线程**交替**执行\n\n\n\n## 创建多线程\n\n创建多线程有四种方式：\n\n- 继承`Thread`类\n- 实现`Runnable`接口\n- 实现`Callable`接口\n- 使用线程池\n\n### 方式一：继承 Thread 类\n\n1. 创建一个继承于`Thread`类的子类\n2. 重写`Thread`类的`run()` --> 将此线程执行的操作声明在`run()`中\n3. 创建`Thread`类的子类的对象\n4. 通过此对象调用`start()`\n\n``` java\n//1. 创建一个继承于Thread类的子类\nclass MyThread extends Thread {\n    //2. 重写Thread类的run()\n    @Override\n    public void run() {\n        for (int i = 0; i < 100; i++) {\n            if(i % 2 == 0){\n                System.out.println(Thread.currentThread().getName() + \":\" + i);\n            }\n        }\n    }\n}\n\npublic class ThreadTest {\n    public static void main(String[] args) {\n        //3. 创建Thread类的子类的对象\n        MyThread t1 = new MyThread();\n\n        //4.通过此对象调用start():①启动当前线程 ② 调用当前线程的run()\n        t1.start();\n        \n        //问题一：我们不能通过直接调用run()的方式启动线程。\n        // t1.run();\n        //问题二：再启动一个线程，遍历100以内的偶数。不可以还让已经start()的线程去执行。会报IllegalThreadStateException\n        // t1.start();\n        \n        //我们需要重新创建一个线程的对象\n        MyThread t2 = new MyThread();\n        t2.start();\n\n        //如下操作仍然是在main线程中执行的。\n        for (int i = 0; i < 100; i++) {\n            if(i % 2 == 0){\n                System.out.println(Thread.currentThread().getName() + \":\" + i + \"***********main()************\");\n            }\n        }\n    }\n\n}\n```\n\n`start()` 方法底层是调用 `native` 修饰的 `start0()` 方法，其调用的并非JVM中的Java程序，而是本地的C语言程序执行线程任务，因此调用 `t1.start()` 方法时该线程并不一定立即执行，其执行时机由CPU决定。\n\n### 方式二：实现 Runnable 接口\n\n1. 创建一个实现了`Runnable`接口的类\n2. 实现类去实现`Runnable`中的抽象方法：`run()`\n3. 创建实现类的对象\n4. 将此对象作为参数传递到`Thread`类的构造器中，创建`Thread`类的对象\n5. 通过Thread类的对象调用`start()`\n\n``` java\n//1. 创建一个实现了Runnable接口的类\nclass MyThread implements Runnable{\n\n    //2. 实现类去实现Runnable中的抽象方法：run()\n    @Override\n    public void run() {\n        for (int i = 0; i < 100; i++) {\n            if(i % 2 == 0){\n                System.out.println(Thread.currentThread().getName() + \":\" + i);\n            }\n        }\n    }\n}\n\npublic class ThreadTest {\n    public static void main(String[] args) {\n        //3. 创建实现类的对象\n        MyThread mThread = new MyThread();\n        //4. 将此对象作为参数传递到Thread类的构造器中，创建Thread类的对象\n        Thread t1 = new Thread(myThread);\n        t1.setName(\"线程1\");\n        //5. 通过Thread类的对象调用start():① 启动线程 ②调用当前线程的run()-->调用了Runnable类型的target的run()\n        t1.start();\n\n        //再启动一个线程，遍历100以内的偶数\n        Thread t2 = new Thread(myThread);\n        t2.setName(\"线程2\");\n        t2.start();\n    }\n\n}\n```\n\n**重点：Thread类实现了Runnable接口，该方法本质上使用了静态代理的设计模式**：Thread类实现了Runnable接口中的run()方法，调用Thread的run()方法时，会调用在构造器中传入的自定义类的run()方法，因此是一种静态代理的设计模式\n\n```java\n// 构造方法\npublic Thread(Runnable target) {\n    init(null, target, \"Thread-\" + nextThreadNum(), 0);\n}\n\n// Thread类的run()方法，其中target时构造方法中传入的自定义类\n@Override\npublic void run() {\n    if (target != null) {\n        target.run();\n    }\n} \n```\n\n``` java\nClass MyThread implements Runnable{} //相当于被代理类\nClass Thread implements Runnable{}   //相当于代理类\n\nmain(){\n\tMyThread t = new MyThread();   //创建被代理类对象\n\tThread thread = new Thread(t); //创建代理类，执行start方法时会调用接口的run()方法\n\tthread.start(); //启动线程；调用线程的run()\n}\n```\n\n比较创建线程的两种方式。开发中优先选择：实现`Runnable`接口的方式。原因：\n\n1. 实现的方式没有类的单继承性的局限性\n2. 实现的方式更适合来处理多个线程有**共享数据**的情况。\n\n相同点：两种方式都需要重写`run()`，将线程要执行的逻辑声明在`run()`中。\n\n<!-- More -->\n\n### 方式三：实现 Callable 接口\n\n和`Runnable`相比，`Callable`功能更强大：\n\n- 相比`run()`方法，`call()` 方法**可以有返回值**\n- 方法**可以抛出异常**\n- 支持泛型的返回值\n- 需要借助`FutureTask`类，比如获取返回结果\n\n其中：\n\n- 第一次调用 `FutureTask`  的 `get()` 方法时，线程会一直阻塞直到任务结束然后获取结果；\n- 第二次调用 `FutureTask`  的 `get()` 方法时，将不会再次运行线程，而是直接返回结果。\n\n```java\npackage multiThread;\n\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.ExecutionException;\nimport java.util.concurrent.FutureTask;\n\n// 1. 创建一个实现Callable的实现类\nclass NumThread implements Callable{\n\n    // 2. 实现call方法，将此线程需要执行的操作声明在call()中\n    @Override\n    public Object call() throws Exception {\n        int sum = 0;\n        for (int i = 1; i <= 100; i++){\n            System.out.println(i);\n            sum += i;\n        }\n\n        return sum;\n    }\n}\n\npublic class CallableTest {\n    public static void main(String[] args) {\n        // 3. 创建Callable接口实现类的对象\n        NumThread numThread = new NumThread();\n\n        // 4. 将此Callable接口的实现类的对象传递到FutureTask构造器中\n        FutureTask futureTask = new FutureTask(numThread);\n\n        // 5. 将FutureTask类对象作为参数传递到Thread类的构造器中，创建对象并调用start()\n        new Thread(futureTask).start();\n\n        // 6. 获取Callable中call方法的返回值\n        while (!futureTask.isDone()) {\n            // 等待\n        }\n        \t\n        try {\n            // get()方法一直阻塞直到任务结束然后获取结果\n            Object sum = futureTask.get();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        } catch (ExecutionException e) {\n            e.printStackTrace();\n        }\n\n    }\n\n}\n```\n\n### 方式四：使用线程池\n\n经常创建和销毁、使用量特别大的资源，比如并发情况下线程对性能影响很大。思路： 提前创建好多个线程，放入池中使用时直接获取，使用完放回池中。可以避免频繁创建销毁、实现重复利用。好处：\n\n- 提高响应速度 （减少了创建新线程的时间）\n- 降低资源消耗 （重复利用线程池中，不需要每次都创建）\n- 便于线程管理\n  - `corePoolSize`：核心池的大小\n  - `maximumPoolSize`：最大线程数\n  - `keepAliveTime`：线程没有任务时最多保持长间后会 终止\n\n```java\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\n//创建并使用多线程的第四种方法：使用线程池\nclass MyThread implements Runnable {\n\n   @Override\n   public void run() {\n      for (int i = 1; i <= 100; i++) {\n         System.out.println(Thread.currentThread().getName() + \":\" + i);\n      }\n   }\n\n}\n\npublic class ThreadPool {\n   public static void main(String[] args) {\n      // 1.调用Executors的newFixedThreadPool(),返回指定线程数量的ExecutorService\n      ExecutorService pool = Executors.newFixedThreadPool(10);\n       \n      // 2.将Runnable实现类的对象作为形参传递给ExecutorService的submit()方法中，开启线程并执行相关的run()\n      pool.execute(new MyThread());\n     \n      // pool.submit(Callable callable);\n       \n      // 3.结束线程的使用\n      pool.shutdown();\n       \n      // 设置线程池属性\n      ThreadPoolExecutor service1 = (ThreadPoolExecutor)service;\n      service1.setCorePoolSize(15);\n    \n   }\n}\n```\n\n## Thread 类中常用方法\n\n`Thread`中的常用方法：\n\n- `start()`:启动当前线程；调用当前线程的`run()`\n- `run()`: 通常需要重写Thread类中的此方法，将创建的线程要执行的操作声明在此方法中\n- `currentThread()`:静态方法，返回执行当前代码的线程\n- `getName()`:获取当前线程的名字\n- `setName()`:设置当前线程的名字\n- `yield()`:释放当前cpu的执行权，释放后所有线程重新竞争cpu执行权\n- `join()`:在线程a中调用线程b的`join()`，此时线程a就进入阻塞状态，直到线程b完全执行完以后，线程a才结束阻塞状态。\n- `stop()`:已过时。当执行此方法时，强制结束当前线程。\n- `sleep(long millitime)`:让当前线程“睡眠”指定的millitime毫秒。在指定的millitime毫秒时间内，当前线程是阻塞状态。\n- `isAlive()`:判断当前线程是否存活\n\n线程的优先级：\n\n- `MAX_PRIORITY`：10\n- `MIN_PRIORITY`：1\n- `NORM_PRIORITY`：5  -->默认优先级\n\n如何获取和设置当前线程的优先级：\n\n- `getPriority()`:获取线程的优先级\n- `setPriority(int p)`:设置线程的优先级\n\n说明：高优先级的线程要抢占低优先级线程cpu的执行权。但是只是从概率上讲，高优先级的线程高概率的情况下被执行。并不意味着只有当高优先级的线程执行完以后，低优先级的线程才执行。\n\n## 线程的生命周期\n\n![image-20210615154527649](/images/%E3%80%90Java%E3%80%91%E5%A4%9A%E7%BA%BF%E7%A8%8B/image-20210615154527649.png)\n\n线程的五种状态：\n\n- 新建\n- 就绪\n- 运行\n- 阻塞\n- 死亡\n\n![image-20210918094212914](/images/%E3%80%90Java%E3%80%91%E5%A4%9A%E7%BA%BF%E7%A8%8B/image-20210918094212914.png)\n\n## 解决线程安全问题\n\n### 方式一：同步代码块\n\n```java\nsynchronized(同步监视器){\n    // 需要被同步的代码\n}\n```\n\n操作同步代码时，只能有一个线程参与，其他线程等待。相当于是一个单线程的过程，效率低（局限性）。说明：\n\n1. 操作共享数据的代码，即为需要被同步的代码。不能包含代码多了，也不能包含代码少了。\n2. 共享数据：多个线程共同操作的变量。\n3. 同步监视器，俗称：**锁**。**任何一个类的对象，都可以充当锁**。\n\n要求：**多个线程必须要共用同一把锁（同步监视器）**：\n\n- 在实现`Runnable`接口创建多线程的方式中，我们可以考虑使用`this`充当同步监视器。因为`Runnable`类对象被多个`Thread`类对象所共享，所以多个线程共用同一把锁。\n- 在继承`Thread`类创建多线程的方式中，因为多个线程类对象本身不能共享数据，因此需要设置一个`static`修饰的对象作为锁，或使用反射方式`xxx.class`作为锁。\n\n实现Runnable接口例子：\n\n```java\nclass Window1 implements Runnable{\n    private int ticket = 100;\n\n    @Override\n    public void run() {\n        while(true){\n            synchronized (this){ //此时的this:唯一的Window1的对象，也可以用其他任意类对象作为锁\n                if (ticket > 0) {\n                    try {\n                        Thread.sleep(100);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n\n                    System.out.println(Thread.currentThread().getName() + \":卖票，票号为：\" + ticket);\n                    ticket--;\n                } else {\n                    break;\n                }\n            }\n        }\n    }\n}\n\npublic class WindowTest1 {\n    public static void main(String[] args) {\n        Window1 w = new Window1();\n\n        Thread t1 = new Thread(w);\n        Thread t2 = new Thread(w);\n        Thread t3 = new Thread(w);\n\n        t1.setName(\"窗口1\");\n        t2.setName(\"窗口2\");\n        t3.setName(\"窗口3\");\n\n        t1.start();\n        t2.start();\n        t3.start();\n    }\n\n}\n```\n\n若使用继承`Thread`类的方式，需要在类中设置一个`static`对象作为锁，或使用反射方式`Window1.class`。\n\n### 方式二：同步方法\n\n同步方法仍然涉及到同步监视器，只是不需要显示声明：\n\n- 非静态的同步方法（适用于实现`Runnable`接口），同步监视器是：`this`\n- 静态的同步方法（适用于继承`Thread`类），同步监视器是：当前类本身\n\n非静态的同步方法（适用于实现`Runnable`接口）：\n\n```java\nclass Window2 implements Runnable {\n    private int ticket = 100;\n\n    @Override\n    public void run() {\n        while (true) {\n            // 在while循环内加锁\n            show();\n        }\n    }\n\n    private synchronized void show(){ //同步监视器：this\n            if (ticket > 0) {\n                try {\n                    Thread.sleep(100);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n                System.out.println(Thread.currentThread().getName() + \":卖票，票号为：\" + ticket);\n                ticket--;\n            }\n    }\n}\n```\n\n静态的同步方法（适用于继承`Thread`类）：\n\n```java\nclass Window3 extends Thread {\n    private static int ticket = 100;\n\n    @Override\n    public void run() {\n        while (true) {\n            show();\n        }\n    }\n    \n    private static synchronized void show(){ //同步监视器：Window3.class\n\n        if (ticket > 0) {\n            try {\n                Thread.sleep(100);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n\n            System.out.println(Thread.currentThread().getName() + \"：卖票，票号为：\" + ticket);\n            ticket--;\n        }\n    }\n}\n```\n\n### 方式三：Lock 锁\n\n解决线程安全问题的方式三：Lock锁  --- JDK5.0新增\n\n`synchronized`与`Lock`的区别：\n\n- **原始构成**：`sync`是JVM层面的，底层通过`monitorenter`和`monitorexit`来实现的。`Lock`是JDK API层面的。（`sync`一个`enter`会有两个`exit`，一个是正常退出，一个是异常退出）\n- **使用方法**：`sync`不需要手动释放锁（若发生异常也会自动释放），而`Lock`需要手动释放`unlock()`（通常写在finally代码块中防止发生异常无法释放同步监视器）\n- **是否可中断**：`sync`不可中断，除非抛出异常或者正常运行完成。`Lock`是可中断的，通过调用`interrupt()`方法。\n- **是否为公平锁**：`sync`只能是非公平锁，而`Lock`既能是公平锁，又能是非公平锁。\n- **绑定多个条件**：`sync`不能，只能随机唤醒。而`Lock`可以通过`Condition`来绑定多个条件，精确唤醒。\n\n在高并发场景下，`Lock` 的性能远优于 `synchronized`。\n\n优先使用顺序：`Lock `——> 同步代码块（已经进入了方法体，分配了相应资源）——> 同步方法（在方法体之外）\n\n```java\nclass Window implements Runnable{\n    private int ticket = 100;\n    \n    //1.实例化ReentrantLock\n    private ReentrantLock lock = new ReentrantLock();\n\n    @Override\n    public void run() {\n        while(true){\n            try{\n                //2.调用锁定方法lock()\n                lock.lock();\n\n                if(ticket > 0){\n                    try {\n                        Thread.sleep(100);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    System.out.println(Thread.currentThread().getName() + \"：售票，票号为：\" + ticket);\n                    ticket--;\n                }else{\n                    break;\n                }\n            }finally {\n                //3.调用解锁方法：unlock()\n                lock.unlock();\n            }\n\n        }\n    }\n}\n```\n\n死锁的理解：不同的线程分别占用对方需要的同步资源不放弃，都在等待对方放弃自己需要的同步资源，就形成了线程的死锁。出现死锁后，不会出现异常，不会出现提示，只是所有的线程都处于阻塞状态，无法继续。\n\n## synchronized 原理\n\nSynchronized的重入的实现机理：每个锁对象拥有一个锁计数器和一个指向持有该锁的线程的指针。\n\n当执行monitorenter时，如果目标锁对象的计数器为零，那么说明它没有被其他线程所持有，Java虚拟机会将该锁对象的持有线程设置为当前线程，并且将其计数器加1。\n\n在目标锁对象的计数器不为零的情况下，如果锁对象的持有线程是当前线程，那么Java虚拟机可以将其计数器加1，否则需要等待，直至持有线程释放该锁。\n\n当执行monitorexit时，Java虚拟机则需将锁对象的计数器减1。计数器为零代表锁已被释放。\n\n> synchronized(obj)，放obj的目的是，将修改该对象的对象头Header里的锁状态的值，将其由0设置为1，这样其他线程想进入代码块内，就会发现其值为1，就会阻塞等待。同时是可重入的，同一个线程递归调用同一段 syn 不会阻塞，可以直接进入，可能锁状态里有保存了线程的引用值，能判断哪个线程持有的锁。\n\n\n## synchronized 多种使用情况\n\n`synchronized` 实现同步的基础：Java中的每一个对象都可以作为锁。具体表现为以下3种形式：\n\n- 对于普通同步方法，锁是当前**实例对象**。\n- 对于静态同步方法，锁是当前类的 **`Class` 类模板**。\n- 对于同步方法块，锁是 `synchonized` 括号里配置的对象\n\n### 情况一：普通同步方法 + 调用同一个对象\n\n一个对象中的各个**普通同步方法**都是**互斥的**，一个普通同步方法上的 `synchronized `锁**的是当前类的实例对象而不仅仅是锁当前方法**，同一时间**只能有一个线程**访问该类**实例对象**里的**某一个普通同步方法**，而不能有多个线程同时访问**同一个对象**的多个普通同步方法（但是可以同时访问他的普通非同步方法）。注意此时描述的是多个线程调用**同一个对象**里的多个普通同步方法。\n\n举例：手机资源类中有很多不同功能的普通同步资源（普通同步方法），且该手机只有一部（一个实例对象），那么一旦某人（某线程）抢到了该手机（实例对象），那么不管他用的是哪个普通同步资源（哪个普通同步方法），其他人（其他线程）都无法再使用该手机（实例对象）里的任何普通同步资源（普通同步方法），则其他人（其他线程）可以同时听这部手机里的歌（普通非同步资源）\n\n**结论**：普通同步方法上的 `synchronized `锁的是**当前实例对象**，而不仅仅是当前方法，但要注意的是，普通非同步方法并不会被锁，其仍然能正常调用。\n\n### 情况二：普通同步方法 + 调用不同的对象\n\n对比情况一，如果多个线程调用的是不同对象的普通同步方法，则并不会互斥，因为普通同步方法上的锁只所当前实例对象，不同的实例对象上的锁不同，当然不会互斥。\n\n### 情况三：普通同步方法 + 普通非同步方法\n\n当调用的是普通方法（没有加`synchronized `的方法）时，并不受锁的影响。\n\n### 情况四：静态同步方法 + 调用不同对象\n\n静态同步方法**锁的是整个类模板**，该类的所有实例对象都不能同时访问静态同步方法。但是同一个对象的静态同步方法和普通同步方法不互斥，两个线程可以同时访问静态同步方法和普通同步方法。因为两个方法锁一个锁当前类模板，一个锁当前对象，所以并不互斥。\n\n### 情况五：静态同步方法 + 普通同步方法\n\n同一个对象的静态同步方法和普通同步方法不互斥，两个线程可以同时访问静态同步方法和普通同步方法。因为两个方法锁一个锁当前类模板，一个锁当前对象，所以并不互斥。\n\n\n\n> 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。也就是说**如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方法必须等待获取锁的方法释放锁后才能获取锁**，可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁，所以毋须等待该实例对象，已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。所有的静态同步方法用的也是同一把锁——类对象本身，这两把锁是两个不同的对象，所以静态同步方法与非静态同步方法之间是不会有竞态条件的。\n>\n> 但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同步方法之间，只要它们是同一个类的实例对象，都会互斥\n\n\n\n## 线程安全的懒汉式单例模式\n\n```java\nclass Bank{\n    private Bank(){}\n    private static Bank instance = null;\n\n    public static Bank getInstance(){\n        //方式一：效率稍差\n        /*\n        synchronized (Bank.class) {\n            if(instance == null){\n                instance = new Bank();\n            }\n            return instance;\n        }*/\n        \n        //方式二：效率更高，如果实例对象已经非空，说明已经造好了对象，不需要再进入同步代码块内\n        //DCL（Double Check Lock 双端检锁机制）\n        if(instance == null){\n            synchronized (Bank.class) {\n                if(instance == null){\n                    instance = new Bank();\n                }\n            }\n        }\n        return instance;\n    }\n}\n```\n\n### 可能存在的问题\n\n注意，双端检锁机制不一定线程安全，原因是指令重排序的存在，加入`volatile`可以禁止指令重排序。指令重排序只会保证串行语义的执行的一致性（单线程），并不会关心多线程间的语义一致性。\n\n代码中 `instance = new Bank()` 语句实际的执行顺序为：\n\n1. `memory = allocate()`：为对象开辟一块内存空间\n2. `instance(memory)`：初始化该对象，为其成员属性赋值\n3. `instance = memory`：设置`instance`指向刚才分配的内存地址，此时 `instance != null`\n\n正常顺序是1 -> 3 -> 2。但由于指令重排序，可能某个线程在new对象的时候，重新排序后是1 -> 3 -> 2。即先给该对象引用赋了地址，但还未为该变量进行初始化（还未实例化对象）。\n\n这就导致了可能该对象还未初始化时，另一个线程就抢到CPU执行权并判断 ` if(instance == null)`，此时发现`instance`的值已经不为空了（因为已经开辟并分配了地址），其将被直接返回，那么获取到的对象就是`null`值了。\n\n> 该情况不会导致重复new对象，只是有可能返回null值。\n\n解决方案：\n\n1. 采用方式一，在整个方法上加锁。缺点是并发效率低\n2. 为`instance`对象添加`volatile`关键字，禁止指令重排序。\n\n``` java\nclass Bank{\n    private Bank(){}\n    private volatile static Bank instance = null;\n\n    public static Bank getInstance(){\n        // DCL（Double Check Lock 双端检锁机制）\n        if(instance == null){\n            synchronized (Bank.class) {\n                if(instance == null){\n                    instance = new Bank();\n                }\n            }\n        }\n        return instance;\n    }\n}\n```\n\n\n\n## 线程间的通信\n\n### wait()、notify()、notigyAll()\n\n涉及到的三个方法：\n\n- `wait()`：一旦执行此方法，当前线程就进入阻塞状态，**并释放同步监视器**\n- `notify()`：一旦执行此方法，就会唤醒被wait的一个线程，如果有多个线程被wait，就唤醒优先级高的线程\n- `notifyAll()`：一旦执行此方法，就会唤醒所有被wait的线程\n\n注意：\n\n- `wait()`，`notify()`，`notifyAll()`这三个方法必须使用在**同步代码块或同步方法中**；\n- 三者的调用者必须是同步代码块或同步方法中的同步监视器，否则会出现`IllegalMonitorStateException`异常；\n- `wait()`，`notify()`，`notifyAll()`这三个方法是定义在`java.lang.Object`类中。\n\n**虚假唤醒**问题：`wait()` 方法的特点是“在哪里睡就在哪里醒”。如果`wait()`方法不使用在 while 循环中，则当其被其他线程唤醒后，程序会继续向下执行。因此某些业务条件下需要将 `wait()` 放在 while 循环中，防止其被别人唤醒后，在不满足跳出阻塞条件的情况下继续向下执行。\n\n例子：\n\n```java\npackage multiThread;\n\n/**\n * 线程通信的例子：使用两个线程交替打印1-100\n * \n * 涉及到三个方法：\n *  wait()：一旦执行此方法，当前线程就进入阻塞状态，**并释放同步监视器**\n *  notify()：一旦执行此方法，就会唤醒被wait的一个线程，如果有多个线程被wait，就唤醒优先级高的线程\n *  notifyAll()：一旦执行此方法，就会唤醒所有被wait的线程\n *\n */\nclass Number implements Runnable {\n    private int number = 1;\n\n    @Override\n    public void run() {\n        while(true) {\n            synchronized (this) {\n                // 唤醒其他所有线程，哪怕唤醒后，因为当前资源已经被锁，唤醒后的线程也进不来\n                notifyAll();\n\n                if (number < 100){\n                    try {\n                        Thread.sleep(10);\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                    System.out.println(Thread.currentThread().getName() + \":\" + number);\n                    number++;\n\n                    try {\n                        // 使得调用wait()方法的线程进入阻塞状态，同时释放锁\n                        wait();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }else {\n                    break;\n                }\n            }\n        }\n    }\n}\n\npublic class MultiThreadingTest {\n    public static void main(String[] args) {\n        Number number = new Number();\n\n        Thread t1 = new Thread(number);\n        Thread t2 = new Thread(number);\n\n        t1.setName(\"线程1\");\n        t2.setName(\"线程2\");\n\n        t1.start();\n        t2.start();\n    }\n}\n```\n\n**sleep() 和 wait() 的异同**：\n\n- 相同点：一旦执行方法，都可以使得当前线程进入阻塞状态\n- 不同点：\n  - 两个方法声明的位置不同：`Thread`类声明`sleep()`，`Object`类中声明`wait()`\n  - 调用的要求不同：`sleep()`可以在任何需要的场景下调用，`wait()`必须在同步代码块或同步方法中调用\n  - 关于是否释放同步监视器：如果两个方法都是用在同步代码块或同步方法中，`sleep()`不会释放锁，`wait()`会释放锁\n\n### lock.newCondition()\n\n除了可以使用 `Objetct` 类中的 `wait()` 等方法外，还可以使用 `Lock` 接口提供的 `Condition` 接口进行线程通信，其好处是可以使用 `condition.signal()` **唤醒指定的线程（精准唤醒）**：\n\n``` java\nCondition condition01 = lock.newCondition();\nCondition condition02 = lock.newCondition();\n\n// 唤醒其他所有线程\ncondition01.signalAll();\n\n// condition01 线程睡眠等待\ncondition01.await();\n\n// ---------------------------------------\n// 唤醒指定线程 condition02\ncondition02.signal();\n```\n\n\n\n\n\n\n\n## 集合线程安全\n\n### ArrayList 线程不安全\n\n`ArrayList` 是线程不安全的，并发条件下对 `ArrayList` 的 `add()` 操作会导致异常发生。\n\n**解决方案一**：使用 `Vector` 集合（较为古老，不常用）\n\n `Vector` 是 `List` 接口的**古老**实现类，其特点是**线程安全的，效率低**，不太常用（底层是 `synchronized` 加锁方式的效率都比较低，因为不论是读还是写都会阻塞，而读操作没必要加锁）\n\n**解决方案二**：使用 `Collections` 工具类（不常用）\n\nCollections 是一个操作 `Set`、`List` 和 `Map` 等集合的工具类（操作数组的工具类：Arrays）。Collections 中提供了一系列静态的方法对集合元素进行排序、查询和修改等操作， 还提供了对集合对象设置不可变、对集合对象实现同步控制等方法。\n\n其提供的线程安全功能是通过 `synchronized` 方式加锁，其效率不高，也不常用。\n\n``` java\nList<String> list = Collections.synchronizedList(new ArrayList<>());\n```\n\n**解决方案三**：使用 JUC 包下的 **CopyOnWriteArrayList** 类（常用）\n\n它相当于线程安全的 `ArrayList`。和 `ArrayList` 一样，它是个**可变数组**；但是和 `ArrayList` 不同的是，它具有以下特性：\n1. 它最适合于具有以下特征的应用程序：List 大小通常保持很小，**只读操作远多于可变操作**，需要在遍历期间防止线程间的冲突。\n2. 它是**线程安全的**。\n3. 因为通常需要复制整个基础数组，所以可变操作（`add()`、`set() `和 `remove()` 等等）的开销很大。\n4. 迭代器支持 `hasNext()`, `next()` 等不可变操作，但不支持可变` remove()` 等操作。\n5. 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。\n\n`CopyOnWriteArrayList` 不使用独占锁，而是使用**写时复制技术**，将读写分离。读操作不加锁，写操作才加锁。\n\n写时复制思路：当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，**再将原容器的引用指向新的容器**。这样**读和写的是不同的容器**，因此实现了读写分离，写时不耽误并发读。\n\n`add()` 方法源码：\n\n![image-20210916205340151](/images/%E3%80%90Java%E3%80%91%E5%A4%9A%E7%BA%BF%E7%A8%8B/image-20210916205340151.png)\n\n拷贝时使用的是 `Arrays` 工具类的 `copyOf()` 方法\n\n\n\n**总结**：`Vector` 读写时都上锁，因此性能较差，不能同时读和写。但 **CopyOnWriteArrayList** 可以在读的时候进行写，效率较高。 \n\n\n\n### HashSet 线程不安全\n\n解决方案：使用 **CopyOnWriteArraySet** \n\n![image-20210923215559576](/images/%E3%80%90Java%E3%80%91%E5%A4%9A%E7%BA%BF%E7%A8%8B/image-20210923215559576.png)\n\n### HashMap 线程不安全\n\n解决方案：使用 **ConcurrentHashMap** \n\n具体如何保证线程安全？\n\n\n\nHashTable\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Java】基本数据类型","url":"/2021/03/12/【Java】基本数据类型/","content":"\n## Java 数据类型\n\n基本数据类型：\n\n- 整型：`byte \\ short \\ int \\ long`\n- 浮点型：`float \\ double`\n- 字符型：`char`\n- 布尔型：`boolean`\n\n引用数据类型：\n\n- 类（`class`）\n- 接口（`interfac`）\n- 数组（`array`）\n\n### 容量\n\n- 整型：`byte`（1字节=8bit） \\ `short`（2字节）\\ `int`（4字节）\\ `long`（8字节）\n- 浮点型：`float`（4字节） \\ `double`（8字节）\n- 字符型：`char`（1字符=2字节）\n\n**注意：定义long型变量，必须以\"l\"或\"L\"结尾；定义float类型变量时，变量要以\"f\"或\"F\"结尾**\n\n**整型常量默认为int类型，浮点类型常量默认为double类型。**\n\n### 自动类型提升\n\n自动类型提升：当容量小的数据类型的变量与容量大的数据类型的变量做运算时，结果自动提升为容量大的数据类型。\n\n`byte 、char 、short --> int --> long --> float --> double`\n\n**特别的：当byte、char、short三种类型的变量做运算时，结果为int型**\n\n `float`和`double`类型的变量相加时，结果为`double`类型。\n\n### 强制类型转换\n\n强制类型转换：从容量大的类型转换成容量小的类型。它是自动类型提升运算的**逆运算**。其中容量大小指的是，表示数的范围的大小。比如：`float`容量要大于`long`的容量\n\n### 注意事项\n\n1. 情况1：编译不出错，因为右边的123456默认是`int`类型，转给`long`类型时为自动类型提升（小转大，不出错）\n\n``` java\nlong num  = 123456;\n```\n\n2. 情况2：编译出错——过大的整数。因为右边的数默认为int类型，但因为该数字过大超过了`int`类型的范围，所以会报错。此时需要再其后面加上`\"l\"`或`\"L\"`。\n\n``` java\nlong num = 12345678987654321;\n\n// 正确：\nlong num = 12345678987654321L;\n```\n\n3. 情况3：编译出错——不兼容的类型：从`double`转换到`float`可能会有损失。因为右边的12.3默认为`double`类型，不能直接转换，需要加上强制类型转换`(float)12.3`。此时需要再其后面加上`\"f\"`或`\"F\"`。\n\n``` java\nfloat f1 = 12.3;\n\n// 正确\nfloat f1 = (float)12.3;\nfloat f1 = 12.3F;\n```\n\n4. 情况4：编译出错——不兼容的类型：从int转换到byte可能会有损失。因为此时的 1 默认是int类型，不能直接转换，需要加上强制类型转换。\n\n``` java\nbyte b = 12;\nbyte b1 = b + 1;\n```\n\n### 进制转换\n\n> 二进制转十进制细节：https://www.bilibili.com/video/BV1Kb411W75N?t=470&p=64\n\n计算机底层使用**补码**的方式存储数据\n\n### 基本数据类型使用示例\n\n```java\nclass VariableTest {\n    public static void main(String[] args) {\n        //1. 整型：byte(1字节=8bit) \\ short(2字节) \\ int(4字节) \\ long(8字节)\n        //① byte范围：-128 ~ 127\n        //\n        byte b1 = 12;\n        byte b2 = -128;\n        //b2 = 128;//编译不通过\n        System.out.println(b1);\n        System.out.println(b2);\n        // ② 声明long型变量，必须以\"l\"或\"L\"结尾\n        // ③ 通常，定义整型变量时，使用int型。\n        short s1 = 128;\n        int i1 = 1234;\n        long l1 = 3414234324L;\n        System.out.println(l1);\n\n        //2. 浮点型：float(4字节) \\ double(8字节)\n        //① 浮点型，表示带小数点的数值\n        //② float表示数值的范围比long还大\n\n        double d1 = 123.3;\n        System.out.println(d1 + 1);\n        //③ 定义float类型变量时，变量要以\"f\"或\"F\"结尾\n        float f1 = 12.3F;\n        System.out.println(f1);\n        //④ 通常，定义浮点型变量时，使用double型。\n\n        //3. 字符型：char （1字符=2字节)\n        //① 定义char型变量，通常使用一对'',内部只能写一个字符\n        char c1 = 'a';\n        //编译不通过\n        //c1 = 'AB';\n        System.out.println(c1);\n\n        char c2 = '1';\n        char c3 = '中';\n        char c4 = 'ス';\n        System.out.println(c2);\n        System.out.println(c3);\n        System.out.println(c4);\n\n        //② 表示方式：1.声明一个字符 2.转义字符 3.直接使用 Unicode 值来表示字符型常量\n        char c5 = '\\n';//换行符\n        c5 = '\\t';//制表符\n        System.out.print(\"hello\" + c5);\n        System.out.println(\"world\");\n\n        char c6 = '\\u0043';\n        System.out.println(c6);\n\n        //4.布尔型：boolean\n        //① 只能取两个值之一：true 、 false\n        //② 常常在条件判断、循环结构中使用\n        boolean bb1 = true;\n        System.out.println(bb1);\n    }\n}\n```\n\n### 整数类型扩展\n\n整数进制：\n\n- 二进制：0b10，对应对应十进制2\n- 十进制：10\n- 八进制：010，对应十进制8\n- 十六进制：0x10，对应十进制16\n\n多个不同整数类型的变量相加时，若其中有一个long类型，则相加结果为long；否则都为int类型。\n\n## 浮点数类型扩展\n\n浮点数`float`类型占32字节，`double`类型占64字节，其位数有限、是离散的、有舍入误差的，因此容易出现数值溢出的情况。两个浮点数可能很接近但不严格相等。`float`和`double`类型的变量相加时，结果为`double`类型。\n\n使用浮点数时应注意，银行业务中不能使用float和double类型，要使用BigDecimal类进行判断。\n\n``` java\n// 理论上f和d应该相等\nfloat f = 0.1f;\ndouble d = 1.0 / 10; \n\n// 但是结果输出false\nSystem.out.println(f == d);\n\nfloat f1 = 2158452165841256123584f;\nfloat f2 = f1 + 1;\n\n// 结果输出true\nSystem.out.println(f1 == f2);\n```\n\n\n## 字符类型\n\n编码类型：Unicode  2字节，范围0-65536\n\n转义字符：\n\n- \\t  制表符\n- \\n  换行\n\n\n\n\n\n\n\n\n","tags":["Java"],"categories":["Java"]},{"title":"【OpenCV】OpenCV 读取摄像头数据","url":"/2021/03/10/【OpenCV】OpenCV读取摄像头数据/","content":"\n通过cv::VideoCapture类读取外接设备视频流（摄像头或外接读卡器获取到的视频流）\n\n```c++\ncv::VideoCapture capture(0);\n\nif (!capture.isOpened())\n{\n    printf(\"could not open camera...\\n\");\n    return -1;\n}\ncv::namedWindow(\"capture\", WINDOW_AUTOSIZE);\n\ncv::Mat frame;\nint index = 0;\n\nwhile (true) \n{\n    if (!capture.read(frame)) \n        break;\n    \n    cv::imshow(\"capture\", frame);\n    char c = waitKey(1);\n    \n    if (c >= 49) {\n    index = c - 49;\n    }\n    if (c == 27) {\n    break;\n    }\n}\n\ncapture.release();\n```\n\n","tags":["C++","OpenCV"],"categories":["C++","OpenCV"]},{"title":"【Qt】基于 Qt 显示 OpenCV 的 Mat 数据","url":"/2021/03/10/【Qt】基于Qt显示OpenCV的Mat数据/","content":"\n## 读取图片\n\n使用`QFileDialog::getOpenFileName`函数获取文件名：\n\n```c++\nQString filename = QFileDialog::getOpenFileName(this,tr(\"Open Image\"),\"\",tr(\"Image File(*.bmp *.jpg *.jpeg *.png)\"));\nQTextCodec *code = QTextCodec::codecForName(\"gb18030\");\nstd::string img_name = code->fromUnicode(filename).data();\n```\n\n使用`cv::imread`函数读取图片：\n\n```c++\nimage_mat = cv::imread(img_name);\n\nif(!image_mat.data)\n{\n    QMessageBox msg_box;\n    msg_box.setText(tr(\"Image data is null\"));\n    msg_box.exec();\n}\nelse\n{\n    //TODO: xxxx\n}\n```\n\n<!-- more -->\n\n## cv::Mat转换为QImage\n\n将`cv::Mat`类对象转换为`QImage`类对象。注意事项：\n\n1. cv::Mat类通道顺序为BGR，QImgae类为RGB，因此需要先使用`cv::cvtColor`做色彩转换。\n\n2. 需要判断Mat对象的通道数，单通道和三通道处理方式略有不同：\n\n- 三通道RGB图片：`QImage::Format_RGB888`\n- 单通道图片：`QImage::Format_Indexed8`\n\n```c++\ncv::Mat rgbMat;\nQImage img;\n\nif (image_mat.channels() == 3)\n{\n    cv::cvtColor(mat, rgbMat, CV_BGR2RGB); \n    img = QImage((const uchar*)(rgbMat.data), rgbMat.cols, rgbMat.rows, rgbMat.cols * rgbMat.channels(), QImage::Format_RGB888);\n} else {\n    img = QImage((const uchar*)(mat.data), mat.cols, mat.rows, mat.cols * mat.channels(), QImage::Format_Indexed8);\n}\n```\n\n## QLabel显示图片\n\n在Qt Designer中创建一个`QLabel`类对象img_label，并根据需求设置其长宽大小，最后通过`setPixmap`函数设置QImage数据。\n\n调整图片大小时有两种设置方式：\n\n- 图片尺寸调整到QLabel实际尺寸：`setScaledContents(true)`\n- QLabel尺寸调整到图片实际尺寸：resize()\n\n```c++\nthis->ui->img_label->clear();\nthis->ui->img_label->setPixmap(QPixmap::fromImage(img));\nthis->ui->img_label->setScaledContents(true);\n//this->ui->img_label->resize(this->ui->img_label->pixmap()->size());\n```\n\n\n\n## 完整代码\n\n```c++\nQString filename = QFileDialog::getOpenFileName(this,tr(\"Open Image\"),\"\",tr(\"Image File(*.bmp *.jpg *.jpeg *.png)\"));\nQTextCodec *code = QTextCodec::codecForName(\"gb18030\");\nstd::string img_name = code->fromUnicode(filename).data();\n\nimage_mat = cv::imread(img_name);\n\nif(!image_mat.data)\n{\n    QMessageBox msg_box;\n    msg_box.setText(tr(\"Image data is null\"));\n    msg_box.exec();\n}\nelse\n{\n    cv::Mat rgbMat;\n    QImage img;\n\n    if (image_mat.channels() == 3)\n    {\n        cv::cvtColor(mat, rgbMat, CV_BGR2RGB); \n        img = QImage((const uchar*)(rgbMat.data), rgbMat.cols, rgbMat.rows, rgbMat.cols * rgbMat.channels(), QImage::Format_RGB888);\n    } else {\n        img = QImage((const uchar*)(mat.data), mat.cols, mat.rows, mat.cols * mat.channels(), QImage::Format_Indexed8);\n    }\n    \n\tthis->ui->img_label->clear();\n    this->ui->img_label->setPixmap(QPixmap::fromImage(img));\n    this->ui->img_label->setScaledContents(true);\n    //this->ui->img_label->resize(this->ui->img_label->pixmap()->size());\n}\n```\n\n","tags":["C++","OpenCV","Qt"],"categories":["C++","OpenCV","Qt"]},{"title":"计算机网络原理","url":"/2021/03/01/【计算机网络】计算机网络原理/","content":"\n## 计算机网络分层结构\n\n- OSI参考模型：7层\n- TCP/IP参考模型：4层\n\n一台主机的每一张网卡都拥有一个固定的物理地址（MAC地址）。两台主机在进行通讯时，交换机通过MAC地址确定传输目标对象，从而通过网线将数据包传输给目标主机。\n\n<!-- more -->\n\n## 数据传输过程\n\n\n\n一台主机A想与另一台主机B通讯时，需要首先知道对方的**MAC地址**（每张网卡有一个MAC地址），其先在缓存文件中寻找有没有这个MAC地址对应的设备，若没有，则通过**ARP协议**在子网内广播一个信号，判断哪台设备的ip地址是B的ip地址。目标设备B发现A要找的ip地址是自己时，就会返回给对方自己的MAC地址，并储存在交换机（不确定）中，此时A即知道了B的ip地址和MAC地址，即可进行通讯；\n\n\n\n## 创建虚拟机时三种网络连接方式\n\n**桥接模式**：在主机上创建一个与主机ip地址（192.168.0.20）位于同一网段下的虚拟机ip地址（192.168.0.30），其内的虚拟机操作系统可以与外界其他操作系统通信，但会占用真实的ip地址（192.168.0.xxx）\n\n**NAT模式**(Network Address Translation，网络地址转换)：在主机上创建另一个网段的ip地址（192.168.100.200），虚拟机中的ip地址（192.168.100.50）与这个ip地址处于同一网段下，不再占用主机上真实的ip地址（192.168.0.40）。这种方式可以避免虚拟机的ip地址占用真实的ip地址（192.168.0.xxx）。\n\n**主机模式**：创建的虚拟机操作系统是独立的主机，不能访问外网。\n\n![image-20210721095121364](/images/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%8E%9F%E7%90%86/image-20210721095121364.png)","tags":["计算机网络"],"categories":["计算机网络"]},{"title":"【C++】C++ 实现ping功能","url":"/2021/02/12/【C】C-实现ping功能/","content":"\n## 目的\n\n使用C++实现ping功能，用于在进行TCP/IP通讯前测试是否能与目标主机通讯。\n\n## 原理\n\nping 命令是基于ICMP 协议来工作的，「ICMP」全称为Internet 控制报文协议( Internet Control Message Protocol)。基于ICMP协议向目标IP发送ICMP响应请求报文，目标主机收到这个报文之后，会向源IP回复一个ICMP响应应答报文。\n\n## C++实现\n\n构建ICMPPing类实现上述功能。\n\n- icmp_ping.h：\n\n```c++\n#ifndef ICMPPING_H\n#define ICMPPING_H\n\n#include <Winsock2.h>\n#include <iphlpapi.h> \n\n#pragma comment(lib,\"Iphlpapi.lib\")\n#pragma comment(lib,\"Ws2_32.lib\")\n\nclass ICMPPing\n{\nprivate:\n\ttypedef HANDLE(WINAPI* ICMPCREATEFILE)(VOID);\n\ttypedef BOOL(WINAPI* ICMPCLOSEHANDLE)(HANDLE);\n\ttypedef DWORD(WINAPI* ICMPSENDECHO)(HANDLE, DWORD, LPVOID, WORD, PIP_OPTION_INFORMATION, LPVOID, DWORD, DWORD);\nprivate:\n\tICMPPing();\npublic:\n\t~ICMPPing();\n\tstatic ICMPPing* GetInstance();\n\t// init ICMP function, return true for success, or for error\n\tBOOL Init();\n\t// ping host, return true for connect success, or for timeout\n\tBOOL Ping(const char* host);\nprivate:\n\tstatic ICMPPing* icmp_ping_;\n\t// pointer of function\n\tICMPCREATEFILE pIcmpCreateFile_;\n\tICMPCLOSEHANDLE pIcmpCloseHandle_;\n\tICMPSENDECHO pIcmpSendEcho_;\n};\n\n#endif\n```\n\n<!-- more -->\n\n- icmp_ping.cpp：\n\n```c++\n#include \"icmp_ping.h\"\n\nICMPPing* ICMPPing::icmp_ping_ = NULL;\n\nICMPPing::ICMPPing()\n    : pIcmpCreateFile_(NULL),\n    pIcmpCloseHandle_(NULL),\n    pIcmpSendEcho_(NULL)\n{\n}\n\nICMPPing::~ICMPPing()\n{\n    delete icmp_ping_;\n}\n\nICMPPing* ICMPPing::GetInstance()\n{\n    if (icmp_ping_ == NULL)\n        icmp_ping_ = new ICMPPing;\n\n    return icmp_ping_;\n}\n\nBOOL ICMPPing::Init()\n{\n    HINSTANCE hIcmp = LoadLibrary(\"ICMP.DLL\");\n    if (hIcmp == NULL)\n    {\n        return false;\n    }\n    pIcmpCreateFile_ = (ICMPCREATEFILE)GetProcAddress(hIcmp, \"IcmpCreateFile\");\n    pIcmpCloseHandle_ = (ICMPCLOSEHANDLE)GetProcAddress(hIcmp, \"IcmpCloseHandle\");\n    pIcmpSendEcho_ = (ICMPSENDECHO)GetProcAddress(hIcmp, \"IcmpSendEcho\");\n    if ((pIcmpCreateFile_ == NULL) || (pIcmpCloseHandle_ == NULL) || (pIcmpSendEcho_ == NULL))\n        return false;\n    return true;\n}\n\nBOOL ICMPPing::Ping(const char* host)\n{\n    DWORD timeOut = 1000;  \n    ULONG hAddr = inet_addr(host);  \n    if (hAddr == INADDR_NONE)\n    {\n        hostent* hp = gethostbyname(host);   \n        if (hp)\n            memcpy(&hAddr, hp->h_addr_list, hp->h_length); \n        else\n        {\n            return false;\n        }\n    }\n    HANDLE hIp = pIcmpCreateFile_();\n    IP_OPTION_INFORMATION ipoi;\n    memset(&ipoi, 0, sizeof(IP_OPTION_INFORMATION));\n    ipoi.Ttl = 128;  \n\n    unsigned char pSend[36];  \n    memset(pSend, 'E', 32);\n\n    int repSize = sizeof(ICMP_ECHO_REPLY) + 32;\n    unsigned char pReply[100]; \n    ICMP_ECHO_REPLY* pEchoReply = (ICMP_ECHO_REPLY*)pReply;\n\n    DWORD nPackets = pIcmpSendEcho_(hIp, hAddr, pSend, 32, &ipoi, pReply, repSize, timeOut);   \n\n    if (pEchoReply->Status != 0)\n    {\n        pIcmpCloseHandle_(hIp);\n        return false;\n    }\n\n    pIcmpCloseHandle_(hIp);\n    return true;\n}\n\n```\n\n该类使用单例模式，在主程序中使用时，通过调用`GetInstance()`函数返回类指针对象；之后通过`Init()`函数进行初始化，并判断返回值是否为false；最后调用`Ping()`函数验证是否能和目标主机进行通讯。\n\n```c++\n#include \"icmp_ping.h\"\n#include <iostream>\n\nint main()\n{\n    ICMPPing* icmp_ping = ICMPPing::GetInstance();\n\n    if (!icmp_ping->Init())\n        std::cout << \"init error!\" << std::endl;\n\n    if (icmp_ping->Ping(\"192.168.0.12\")){\n        std::cout << \"ping success!\" << std::endl;\n    } else{\n        std::cout << \"ping fail!\" << std::endl;\n    }\n\n    return 0;\n}\n```\n\n## 注意\n\n若该类同时与其他包含有<Windows.h>的文件放在同一项目下编译时，会报重定义的错误，这是因为<Windows.h>中包含了<Winsock.h>头文件，而本类包含了<Winsock2.h>文件，因此会有重定义。解决方案：\n\n在项目属性  ——>  C/C++  ———>  预处理器  -------> 预处理器定义\n\n增加如下定义\n\n`WIN32_LEAN_AND_MEAN`\n\n## 致谢\n\n>  代码参考自http://www.cnblogs.com/guoyz1314/p/3527340.html\n\n","tags":["计算机网络","C++"],"categories":["计算机网络","C++"]},{"title":"【Java】Java 基础语法","url":"/2021/02/11/【Java】Java基础语法/","content":"\n## Java 数据类型\n\n基本数据类型：\n\n- 整型：`byte \\ short \\ int \\ long`\n- 浮点型：`float \\ double`\n- 字符型：`char`\n- 布尔型：`boolean`\n\n引用数据类型：\n\n- 类（`class`）\n- 接口（`interfac`）\n- 数组（`array`）\n\n### 容量\n\n- 整型：`byte`（1字节=8bit） \\ `short`（2字节）\\ `int`（4字节）\\ `long`（8字节）\n- 浮点型：`float`（4字节） \\ `double`（8字节）\n- 字符型：`char`（1字符=2字节）\n\n**注意：定义long型变量，必须以\"l\"或\"L\"结尾；定义float类型变量时，变量要以\"f\"或\"F\"结尾**\n\n**整型常量默认为int类型，浮点类型常量默认为double类型。**\n\n### 自动类型提升\n\n自动类型提升：当容量小的数据类型的变量与容量大的数据类型的变量做运算时，结果自动提升为容量大的数据类型。\n\n`byte 、char 、short --> int --> long --> float --> double`\n\n**特别的：当byte、char、short三种类型的变量做运算时，结果为int型**\n\n `float`和`double`类型的变量相加时，结果为`double`类型。\n\n### 强制类型转换\n\n强制类型转换：从容量大的类型转换成容量小的类型。它是自动类型提升运算的**逆运算**。其中容量大小指的是，表示数的范围的大小。比如：`float`容量要大于`long`的容量\n\n### 注意事项\n\n1. 情况1：编译不出错，因为右边的123456默认是`int`类型，转给`long`类型时为自动类型提升（小转大，不出错）\n\n``` java\nlong num  = 123456;\n```\n\n2. 情况2：编译出错——过大的整数。因为右边的数默认为int类型，但因为该数字过大超过了`int`类型的范围，所以会报错。此时需要再其后面加上`\"l\"`或`\"L\"`。\n\n``` java\nlong num = 12345678987654321;\n\n// 正确：\nlong num = 12345678987654321L;\n```\n\n3. 情况3：编译出错——不兼容的类型：从`double`转换到`float`可能会有损失。因为右边的12.3默认为`double`类型，不能直接转换，需要加上强制类型转换`(float)12.3`。此时需要再其后面加上`\"f\"`或`\"F\"`。\n\n``` java\nfloat f1 = 12.3;\n\n// 正确\nfloat f1 = (float)12.3;\nfloat f1 = 12.3F;\n```\n\n4. 情况4：编译出错——不兼容的类型：从int转换到byte可能会有损失。因为此时的 1 默认是int类型，不能直接转换，需要加上强制类型转换。\n\n``` java\nbyte b = 12;\nbyte b1 = b + 1;\n```\n\n### 进制转换\n\n> 二进制转十进制细节：https://www.bilibili.com/video/BV1Kb411W75N?t=470&p=64\n\n计算机底层使用**补码**的方式存储数据\n\n### 基本数据类型使用示例\n\n```java\nclass VariableTest {\n    public static void main(String[] args) {\n        //1. 整型：byte(1字节=8bit) \\ short(2字节) \\ int(4字节) \\ long(8字节)\n        //① byte范围：-128 ~ 127\n        //\n        byte b1 = 12;\n        byte b2 = -128;\n        //b2 = 128;//编译不通过\n        System.out.println(b1);\n        System.out.println(b2);\n        // ② 声明long型变量，必须以\"l\"或\"L\"结尾\n        // ③ 通常，定义整型变量时，使用int型。\n        short s1 = 128;\n        int i1 = 1234;\n        long l1 = 3414234324L;\n        System.out.println(l1);\n\n        //2. 浮点型：float(4字节) \\ double(8字节)\n        //① 浮点型，表示带小数点的数值\n        //② float表示数值的范围比long还大\n\n        double d1 = 123.3;\n        System.out.println(d1 + 1);\n        //③ 定义float类型变量时，变量要以\"f\"或\"F\"结尾\n        float f1 = 12.3F;\n        System.out.println(f1);\n        //④ 通常，定义浮点型变量时，使用double型。\n\n        //3. 字符型：char （1字符=2字节)\n        //① 定义char型变量，通常使用一对'',内部只能写一个字符\n        char c1 = 'a';\n        //编译不通过\n        //c1 = 'AB';\n        System.out.println(c1);\n\n        char c2 = '1';\n        char c3 = '中';\n        char c4 = 'ス';\n        System.out.println(c2);\n        System.out.println(c3);\n        System.out.println(c4);\n\n        //② 表示方式：1.声明一个字符 2.转义字符 3.直接使用 Unicode 值来表示字符型常量\n        char c5 = '\\n';//换行符\n        c5 = '\\t';//制表符\n        System.out.print(\"hello\" + c5);\n        System.out.println(\"world\");\n\n        char c6 = '\\u0043';\n        System.out.println(c6);\n\n        //4.布尔型：boolean\n        //① 只能取两个值之一：true 、 false\n        //② 常常在条件判断、循环结构中使用\n        boolean bb1 = true;\n        System.out.println(bb1);\n    }\n}\n```\n\n## 数组\n\n### 数组默认初始值\n\n- `int[]`类型：0\n- `double[]`类型：0.0\n- `String[]`类型：null\n\n### 数组元素的默认初始化值\n\n针对于初始化方式一：比如：`int[][] arr = new int[4][3];`\n\n- 外层元素的初始化值为：地址值\n- 内层元素的初始化值为：与一维数组初始化情况相同\n\n针对于初始化方式二：比如：`int[][] arr = new int[4][];`\n\n- 外层元素的初始化值为：null\n- 内层元素的初始化值为：不能调用，否则报错。\n\n``` java\npublic class ArrayTest {\n    public static void main(String[] args) {\n\n        int[][] arr = new int[4][3];\n        System.out.println(arr[0]);//[I@15db9742 \n        System.out.println(arr[0][0]);//0\n\n        System.out.println(arr);//[[I@6d06d69c\n\n        System.out.println(\"*****************\");\n        float[][] arr1 = new float[4][3];\n        System.out.println(arr1[0]);//地址值\n        System.out.println(arr1[0][0]);//0.0\n\n        System.out.println(\"*****************\");\n\n        String[][] arr2 = new String[4][2];\n        System.out.println(arr2[1]);//地址值\n        System.out.println(arr2[1][1]);//null\n\n        System.out.println(\"*****************\");\n        double[][] arr3 = new double[4][];\n        System.out.println(arr3[1]);//null\n        //System.out.println(arr3[1][0]);//报错\n\n    }\n}\n```\n\n### 数组的内存解析\n\n1. 一维数组\n\n> https://www.bilibili.com/video/BV1Kb411W75N?p=152\n\n![image-20210710163256394](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210710163256394.png)\n\n2. 二维数组\n\n> https://www.bilibili.com/video/BV1Kb411W75N?p=153\n\n![image-20210710164551679](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210710164551679.png)\n\n### 注意点\n\n`System.out.println`对`char[]`数组的重载方法是**打印其内容**，其他类型数组**打印的是地址值**\n\n``` java\nint[] arr = new int[]{1,2,3};\nSystem.out.println(arr); // 地址值\n\nchar[] arr1 = new char[]{'1','2','3'};\nSystem.out.println(arr1); // \"123\"\n```\n\n## 包装类\n\n基本数据类型、包装类和String类间的转化：\n\n![image-20210711100436651](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711100436651.png)\n\n### 面试题\n\n``` java\npublic class InterviewTest {\n\n\t@Test\n\tpublic void test1() {\n\t\tObject o1 = true ? new Integer(1) : new Double(2.0);\n\t\tSystem.out.println(o1);// 1.0 因为三元运算符在编译期间就会将 : 左右的类型进行统一，即将int类型提升为double类型的对象\n\t}\n\n\t@Test\n\tpublic void test2() {\n\t\tObject o2;\n\t\tif (true)\n\t\t\to2 = new Integer(1);\n\t\telse\n\t\t\to2 = new Double(2.0);\n\t\tSystem.out.println(o2); // 1 这里不需要同一类型\n\t}\n\n\t@Test\n\tpublic void test2() {\n\t\tInteger i = new Integer(1);\n\t\tInteger j = new Integer(1);\n\t\tSystem.out.println(i == j);//false\n\t\t\n\t\t//Integer内部定义了IntegerCache结构，IntegerCache中定义了Integer[],\n\t\t//保存了从-128~127范围的整数。如果我们使用自动装箱的方式，给Integer赋值的范围在\n\t\t//-128~127范围内时，可以直接使用数组中的元素，不用再去new了。目的：提高效率\n\t\t\n\t\tInteger m = 1;\n\t\tInteger n = 1;\n\t\tSystem.out.println(m == n); //true\n\n\t\tInteger x = 128;//相当于new了一个Integer对象\n\t\tInteger y = 128;//相当于new了一个Integer对象\n\t\tSystem.out.println(x == y);//false\n\t}\n}\n```\n\n`Integer`内部定义了**IntegerCache**子类，其在`static`代码块中，随着`Integer`类的加载而加载，`IntegerCache`中定义了`Integer[]`数组，保存了从**-128~127**范围的整数。如果我们使用自动装箱的方式，给`Integer`赋值的范围在`-128~127`范围内时，可以直接从该`Integer[]`数组中获取相应的`Integer`对象，不用再去new了，因此两次获取到的对象相等。目的：提高效率。\n\n![image-20210711101552184](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711101552184.png)\n\n## 面向对象\n\n### 理解 “万事万物皆对象”\n\n- 在Java语言范畴中，我们将功能、结构等封装到类中，通过类的实例，来调用具体的功能结构。\n  - Scanner、String等\n  - 文件File等\n- 涉及到Java语言与前端html、后端的数据库交互时，前后端的结构在Java层次交互时，都体现为类、对象\n\n### 方法参数的值传递机制\n\n- 如果变量是**基本**数据类型，此时赋值的是变量所保存的**数据值**。\n- 如果变量是**引用**数据类型，此时赋值的是变量所保存的数据的**地址值**。\n\n``` java\npublic class ValueTransferTest {\n    public static void main(String[] args) {\n        System.out.println(\"***********基本数据类型：****************\");\n        int m = 10;\n        int n = m;\n        System.out.println(\"m = \" + m + \", n = \" + n);\n\n        n = 20;\n        System.out.println(\"m = \" + m + \", n = \" + n);\n\n        System.out.println(\"***********引用数据类型：****************\");\n\n        Order o1 = new Order();\n        o1.orderId = 1001;\n\n        Order o2 = o1;//赋值以后，o1和o2的地址值相同，都指向了堆空间中同一个对象实体。\n\n        System.out.println(\"o1.orderId = \" + o1.orderId + \",o2.orderId = \" +o2.orderId); // 都是1001\n\n        o2.orderId = 1002;\n\n        System.out.println(\"o1.orderId = \" + o1.orderId + \",o2.orderId = \" +o2.orderId); // 都是1002\n    }\n}\n\nclass Order{\n    int orderId;\n}\n```\n\n![方法参数传递机制1](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92%E6%9C%BA%E5%88%B61.png)\n\n![方法参数传递机制2](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/%E6%96%B9%E6%B3%95%E5%8F%82%E6%95%B0%E4%BC%A0%E9%80%92%E6%9C%BA%E5%88%B62.png)\n\n### 对象的内存解析\n\n![对象的内存解析](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90.png)\n\n![对象数组的内存解析](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/%E5%AF%B9%E8%B1%A1%E6%95%B0%E7%BB%84%E7%9A%84%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90.png)\n\n### 封装性\n\n隐藏对象内部的复杂性，只对外公开简单的接口。便于外界调用，从而提高系统的可扩展性、可维护性。通俗地讲，**把该隐藏的隐藏起来，该暴露的暴露出来，这就是封装性的设计思想**\n\n程序设计追求“高内聚，低耦合”：\n\n- 高内聚：类的内部数据操作细节自己完成，不允许外部干涉；\n- 低耦合 ：仅对外暴露少量的方法用于使用 。\n\n封装性解决结构的可见性问题。其体现在：\n\n- 将属性私有化（`private`），避免外界用户通过“对象.属性”的方式获取对象的属性值，提供公共的（`public`）方法获取（`getXxx`）和设置（`setXxx`）该属性的值\n- 不对外暴露私有方法\n- 单例模式\n\n四种权限修饰符：\n\n![image-20210710200928296](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210710200928296.png)\n\n### 继承性\n\n继承性：子类可以继承父类的方法和属性（Java只能单继承，但可以实现多个接口）。继承性的优点：\n\n- 减少了代码的冗余，提高代码的复用性\n- 便于功能的扩展\n- 为多态性提供了前提\n\n继承性的体现：一旦子类A继承父类B后，子类A就获取了父类B中声明的**所有**属性和方法。**特别的，父类中声明为private的属性或方法，子类继承后，仍然能够拥有。只是因为封装性的影响（封装性将私有属性隐藏起来，不允许其他对象访问），使得子类不能直接调用父类的这些private属性和方法。（只拥有，却不能访问）**\n\n继承的特点：\n\n- 一个类可以被多个子类继承。\n- Java中类的单继承性：一个类只能有一个父类\n- 子父类是相对的概念。\n- 子类直接继承的父类，称为：直接父类。间接继承的父类称为：间接父类\n- 子类继承父类以后，就获取了直接父类以及所有间接父类中声明的属性和方法\n\n### 重写（override/overwrite）\n\n定义：在子类中可以根据需要对从父类中继承来的方法进行改造，也称为方法的**重置**、**覆盖**。在程序执行时，子类的方法将覆盖父类的方法。\n\n要求：\n\n- 子类重写的方法必须和父类被重写的方法**具有相同的方法名称**、**参数列表**\n- 子类重写的方法的**返回值类型不能大于**父类被重写的方法的返回值类型：\n  - 父类的方法返回类型是**引用类型**A，子类重写的方法返回值类型可以是A类或者A的子类\n  - ‌若父类返回的是**基本类型**，子类重写的方法返回值类型必须是**同样的基本类型**\n- 子类重写的方法使用的**访问权限不能小于**父类被重写的方法的访问权限\n  - **子类不能重写父类中声明为private权限的方法**\n- 子类方法抛出的异常不能大于父类被重写方法的异常：即子类不能抛出父类所抛出异常的父类异常，因为这不符合继承性和多态性。必须抛出父类所抛出异常的子类异常。\n- ‌父类**static**修饰的方法子类**不能重写（但可以访问）**\n- 父类**static**修饰的同名方法子类也必须**static**修饰\n\n### super 关键字\n\n 我们可以在子类的方法或构造器中。通过使用`\"super.属性\"`或`\"super.方法\"`的方式，显式地调用父类中声明的属性或方法。但是，通常情况下，我们习惯省略`\"super.\"`。特殊情况：\n\n- 当子类和父类中定义了同名的属性时，我们要想在子类中调用父类中声明的属性，则必须显式的使用`\"super.属性\"`的方式，表明调用的是父类中声明的属性。\n- 当子类重写了父类中的方法以后，我们想在子类的方法中调用父类中被重写的方法时，则必须显式的使用\"super.方法\"的方式，表明调用的是父类中被重写的方法。\n\n我们可以在子类的构造器中显式的使用`\"super(形参列表)\"`的方式，调用父类中声明的指定的构造器`\"super(形参列表)\"`的使用，但必须声明在子类构造器的**首行**。\n\n在类的构造器中，针对于`\"this(形参列表)\"`或\"`super(形参列表)\"`只能二选一，不能同时出现在构造器的首行。没有显式声明`\"this(形参列表)\"`或`\"super(形参列表)\"`，则默认调用的是父类中空参的构造器：`super()`在类的多个构造器中，至少有一个类的构造器中使用了`\"super(形参列表)\"`，调用父类中的构造器。\n\n**super.()可以忽略不写，缺省情况下调用父类的无参构造器**\n\n### 子类对象实例化的全过程\n\n从结果上来看：（继承性）\n\n- 子类继承父类以后，就获取了父类中声明的全部属性或方法（包括私有）。\n- 创建子类的对象，在堆空间中，就会加载所有父类中声明的属性。\n\n从过程上来看：\n\n- 当我们通过子类的构造器创建子类对象时，我们一定会直接或间接地调用其父类的构造器，进而调用父类的父类的构造器，...\n- 直到调用了`java.lang.Object`类中空参的构造器为止。正因为加载过所有的父类的结构，所以才可以看到内存中有父类中的结构，子类对象才可以考虑进行调用。\n\n明确：虽然创建子类对象时，调用了父类的构造器，但是自始至终就创建过一个对象，即为new的子类对象。\n\n![image-20210711094253729](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711094253729.png)\n\n![image-20210711094328686](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711094328686.png)\n\n### static 关键字\n\nstatic可以用来修饰属性、方法、代码块、内部类。static关键字修饰的属性所有对象共享一份数据，修饰的方法可以直接使用类.方法名()的方式使用，其不依赖于类对象，随着类的加载而加载，无需创建类对象即可使用。因为不需要实例就可以访问static方法，**因此static方法内部不能有this**。(也不能有super ) \n\n被修饰后的成员具备以下特点： \n\n- 随着类的加载而加载\n- 优先于对象存在\n- 修饰的成员，被所有对象所共享\n- 访问权限允许时，可不创建对象，直接被类调用\n- static修饰的方法不能被重写\n\n类变量 vs 实例变量内存解析：\n\n![image-20210711103801256](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711103801256.png)\n\n### main() 方法\n\n 由于Java虚拟机需要调用类的`main()`方法，所以该方法的访问权限必须是`public`，又因为Java虚拟机在执行`main()`方法时不必创建对象，所以该方法必须是`static`的，该方法接收一个`String`类型的数组参数，该数组中保存执行Java命令时传递给所运行的类的参数。 \n\n又因为`main()`方法是静态的，我们不能直接访问该类中的非静态成员，必须创建该类的一个实例对象后，才能通过这个对象去访问类中的非静态成员。\n\n### 代码块\n\n代码块(或初始化块)的作用： 对Java类或对象进行初始化 \n\n代码块(或初始化块)的分类： \n\n- 一个类中代码块若有修饰符，则只能被static修饰，称为静态代码块 (static block)，没有使用static修饰的，为非静态代码块。\n- static代码块通常用于初始化static的属性 \n\n``` java\nclass Person { \n    public static int total; \n    static {\n        total = 100; //为total赋初值 \n    } \n    …… //其它属性或方法声明 \n}\n```\n\n**静态代码块：用static修饰的代码块**\n\n1. 可以有输出语句。\n2. 可以对类的属性、类的声明进行初始化操作。\n3. 不可以对非静态的属性初始化。即：不可以调用非静态的属性和方法。\n4. 若有多个静态的代码块，那么按照从上到下的顺序依次执行。 \n5. 静态代码块的执行要**先于非静态代码块**。\n6. 静态代码块随着类的加载而加载，且只执行一次。\n\n**非静态代码块：没有static修饰的代码块 **\n\n1. 可以有输出语句。\n2. 可以对类的属性、类的声明进行初始化操作。 \n3. 除了调用非静态的结构外，还可以调用静态的变量或方法。 \n4. 若有多个非静态的代码块，那么按照从上到下的顺序依次执行。 \n5. 每次创建对象的时候，都会执行一次。**且先于构造器执行**。\n\n程序中成员变量赋值的执行顺序：\n\n1. 默认初始化（类加载到虚拟机中就会先为每个属性值赋初始值\n2. 显式初始化（`int i = 3`) 或 在代码块中赋值（`{ i = 3}`）。此时的顺序看二者谁先写谁后写\n3. 在构造器中初始化\n4. 有了对象后，通过\"对象.属性\"等方法赋值\n\n![image-20210711104038949](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711104038949.png)\n\n### 多态\n\n对象的多态性：父类的引用指向子类的对象，可以直接应用在抽象类和接口上。\n\nJava引用变量有两个类型：**编译时类型**和**运行时类型**。编译时类型由声明该变量时使用的类型决定，运行时类型由实际赋给该变量的对象决定。简称：**编译时，看左边；运行时，看右边**。若编译时类型和运行时类型不一致，就出现了对象的多态性(Polymorphism)。多态情况下：\n\n-  “看左边” ：看的是父类的引用（父类中不具备子类特有的方法和属性）\n-  “看右边” ：看的是子类的对象（实际运行的是子类重写父类的方法）\n\n**属性不遵循多态性**，直接`对象.属性`得到的是父类里的属性值，无法获得子类的属性值。\n\n一个引用类型变量如果声明为父类的类型，但实际引用的是子类对象，那么该变量就**不能再访问子类中独有的属性和方法，只能访问父类的属性和方法**。若仍想使用子类独有的属性和方法，则需要**向下转型**。\n\n![image-20210711141054224](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711141054224.png)\n\n**内存空间分析**：如下代码中，在`new Student()` 时，会在堆空间中创建出该对象的**所有属性和方法**，在栈空间中创建一个`Person`类型的引用变量，存储堆中`Student`对象的地址值。之后可以通过`p.方法()`的方式获取到`Student`类所**重写**的方法，但却无法访问到`Student`所**独有的属性和方法**（这些属性虽然已经加载在了堆空间中，但却无法被p对象所访问，因为编译时期编译器判断p对象所属的Person类并没有这些属性和方法，因此编译不通过），只有使用**向下转型**后p对象才能访问到这些独有的属性。**p对象可以获取到Person类拥有的属性值**。\n\n**关键原因还在于编译器在编译时期判断当前对象p是否有这些属性和方法，有的就可以调用，没有的就不能调用（只能使用向下转型后变成子类类型对象，编译器才能通过）。**\n\n``` java\nPerson p = new Student();\n```\n\n\n\n#### 虚拟方法调用\n\n子类中定义了与父类同名同参数的方法，在多态情况下，将此时父类的方法称为虚拟方法（类比C++中的虚函数）。简单理解：编译时使用该方法是虚拟的，运行时还是调用子类的方法。\n\n![image-20210711141318323](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711141318323.png)\n\n#### 对象类型转换\n\n![image-20210711143413130](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711143413130.png)\n\n#### 向上转型\n\n向上转型：多态的体现。将指向子类的父类引用对象向上转型为指向父类，该过程可以自动进行，就如同小的基本数据类型可以自动转换为大的数据类型，没有任何问题。\n\n``` java\nPerson p = new Student();\nPerson p1 = (Person) p; // 向上转型没有问题 可以忽略(Person)不写\n// 或 Person p1 = p;\n```\n\n#### 向下转型\n\n向下转型：父类引用类型对象原本无法使用所指向的子类独有的属性和方法，若想使用，则需要q强制类型转换。即从父类引用类型对象转换为子类引用类型对象（无继承关系的引用类型间的转换是非法的，在转型前可以使用`instanceof`操作符测试一个对象的类型是否有继承关系）。就如同大的基本数据类型向小的基本数据类型转换需要使用强制类型转换。\n\n``` java\nPerson p = new Student();\nStudent s = (Student) p; // 向下转型：强制转换为子类引用类型对象\n```\n\n![image-20210711141608212](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711141608212.png)\n\n#### 重写与重载的区别\n\n从编译和运行的角度看： 重载，是指允许存在多个同名方法，而这些方法的参数不同。编译器根据方法不同的参数表，对同名方法的名称做修饰。对于编译器而言，这些同名方法就成了不同的方法。**它们的调用地址在编译期就绑定了**。Java的重载是可以包括父类和子类的，即子类可以重载父类的同名不同参数的方法。**所以：对于重载而言，在方法调用之前，编译器就已经确定了所要调用的方法，这称为“早绑定”或“静态绑定”**；\n\n 而对于多态，只有等到方法调用的那一刻，解释运行器才会确定所要调用的具体方法，这称为 **“晚绑定”或“动态绑定”**。 \n\n> Bruce Eckel：“不要犯傻，如果它不是晚绑定，它就不是多态。”\n\n#### 谈谈你对多态性的理解？\n\n- 实现代码的**通用性**。\n- `Object`类中定义的`public boolean equals(Object obj){  }`\n- JDBC：使用java程序操作(获取数据库连接、CRUD)数据库(MySQL、Oracle、DB2、SQL Server)\n- 抽象类、接口的使用体现了多态性。（因为抽象类、接口不能实例化，需要通过多态性创建指向子类的对象）\n\n#### 多态性小结\n\n![image-20210711142448188](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210711142448188.png)\n\n#### 多态性练习\n\n若子类重写了父类方法，就意味着子类里定义的方法彻底覆盖了父类里的同名方法， 系统将不可能把父类里的方法转移到子类中：编译看左边，运行看右边\n\n对于属性变量则不存在这样的现象，即使子类里定义了与父类完全相同的属性变量，这个属性变量依然不可能覆盖父类中定义的属性变量：编译运行都看左边\n\n``` java\nclass Base {\n    int count = 10;\n\n    public void display() {\n        System.out.println(this.count);\n    }\n}\n\nclass Sub extends Base {\n    int count = 20;\n\n    public void display() {\n        System.out.println(this.count);\n    }\n}\n\npublic class FieldMethodTest {\n    public static void main(String[] args) {\n        Sub s = new Sub();\n        System.out.println(s.count);//20\n        s.display();//20\n\n        Base b = s;//多态性\n        //==：对于引用数据类型来讲，比较的是两个引用数据类型变量的地址值是否相同\n        System.out.println(b == s);//true\n        System.out.println(b.count);//10\n        b.display();//20\n    }\n}\n```\n\n## == 与 equals()\n\n### == 运算符\n\n== ：运算符。可以使用在基本数据类型变量和引用数据类型变量中。\n\n- 如果比较的是**基本**数据类型变量：比较两个变量保存的**数据是否相等**。（不一定类型要相同，int和double类型的变量也能比较）\n- 如果比较的是**引用**数据类型变量：比较两个对象的**地址值是否相同**。即两个引用是否指向同一个对象实体\n\n补充： == 符号使用时，必须保证符号左右两边的变量类型一致。\n\n### equals()\n\nequals()方法的使用：\n\n- 是一个**方法**，而**非运算符**\n- 只能适用于**引用数据类型**\n- `Object`类中`equals()`的定义：\n\n``` java\npublic boolean equals(Object obj) {\n    return (this == obj);\n}\n```\n\n说明：`Object`类中定义的`equals()`和`==`的作用是相同的：比较两个对象的地址值是否相同。即两个引用是否指向同一个对象实体\n\n像`String`、`Date`、`File`、包装类等都**重写**了`Object`类中的`equals()`方法。重写以后，比较的不是两个引用的地址是否相同，而是比较两个对象的\"实体内容\"是否相同。\n\n通常情况下，我们自定义的类如果使用`equals()`的话，也通常是比较两个对象的\"实体内容\"是否相同。那么，我们就需要对`Object`类中的`equals()`进行重写。重写的原则：比较两个对象的实体内容是否相同。\n\n```java\npublic class EqualsTest {\n\tpublic static void main(String[] args) {\n\t\t\n\t\t//基本数据类型\n\t\tint i = 10;\n\t\tint j = 10;\n\t\tdouble d = 10.0;\n\t\tSystem.out.println(i == j);//true\n\t\tSystem.out.println(i == d);//true\n\t\t\n\t\tboolean b = true;\n//\t\tSystem.out.println(i == b);\n\t\t\n\t\tchar c = 10;\n\t\tSystem.out.println(i == c);//true\n\t\t\n\t\tchar c1 = 'A';\n\t\tchar c2 = 65;\n\t\tSystem.out.println(c1 == c2);//true\n\t\t\n\t\t//引用类型：\n\t\tCustomer cust1 = new Customer(\"Tom\",21);\n\t\tCustomer cust2 = new Customer(\"Tom\",21);\n\t\tSystem.out.println(cust1 == cust2);//false\n\t\t\n\t\tString str1 = new String(\"zhangsan\");\n\t\tString str2 = new String(\"zhangsan\");\n\t\tSystem.out.println(str1 == str2);//false\n\t\tSystem.out.println(\"****************************\");\n\t\tSystem.out.println(cust1.equals(cust2));//false--->true\n\t\tSystem.out.println(str1.equals(str2));//true\n\t\t\n\t\tDate date1 = new Date(32432525324L);\n\t\tDate date2 = new Date(32432525324L);\n\t\tSystem.out.println(date1.equals(date2));//true\n\t}\n}\n```\n\n![image-20210712180142189](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210712180142189.png)\n\n## final\n\nfinal 可以用来修饰：类、方法、变量。\n\n- final 用来修饰**类**：此类**不能被其他类所继承**。比如：`String`类、`System`类、`StringBuffer`类\n- final 用来修饰**方法**：表明此方法**不可以被重写**。比如：`Object`类中`getClass()`;\n- final 用来修饰**变量**：此时的\"变量\"就称为是一个**常量**\n  - final修饰属性：可以考虑赋值的位置：显式初始化、代码块中初始化、构造器中初始化\n  - final修饰局部变量：尤其是使用final修饰形参时，表明此形参是一个常量。当我们调用此方法时，给常量形参赋一个实参。**一旦赋值以后，就只能在方法体内使用此形参，但不能进行重新赋值**。\n\n**static final 用来修饰的属性：全局常量**\n\n![image-20210713132535979](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210713132535979.png)\n\n## abstract\n\n可以用来修饰：类、方法。\n\n`abstract`修饰类：抽象类\n\n- **此类不能实例化**\n- **抽象类中一定有构造器，便于子类实例化时调用**（涉及：子类对象实例化的全过程）\n- 开发中，都会提供抽象类的子类，让子类对象实例化，完成相关的操作 --->  抽象的使用前提：继承性\n\n`abstract`修饰方法：抽象方法\n\n- 抽象方法只有方法的声明，没方法体\n- 包含抽象方法的类，一定是一个抽象类。反之，**抽象类中可以没有抽象方法的**。\n- 若子类重写了父类中的所的抽象方法后，此子类方可实例化\n- 若子类没重写父类中的所的抽象方法，则此子类也是一个抽象类，需要使用`abstract`修饰\n\n注意点：\n\n- abstract不能用来修饰：属性、构造器等结构\n- abstract不能用来修饰私方法、静态方法、final的方法、final的类\n\n## interface\n\n**Java中，接口和类是并列的两个结构**。接口中不能定义构造器的！意味着**接口不可以实例化**。\n\n**接口也可以 new。**但是需要以匿名内部类的形式 new，同时实现其方法。（例如Lambda表达式）\n\n如何定义接口：定义接口中的成员，**JDK7及以前：只能定义全局常量和抽象方法。JDK8：除了定义全局常量和抽象方法之外，还可以定义静态方法、默认方法。**\n\n- 全局常量：`public static final`的。书写时，可以省略不写\n- 抽象方法：`public abstract`的\n\nJava开发中，接口通过让类去实现(**implements**)的方式来使用。\n\n- 如果实现类覆盖了接口中的所有抽象方法，则此实现类就可以实例化\n- 如果实现类没覆盖接口中所有的抽象方法，则此实现类仍为一个抽象类\n\nJava类**可以实现多个接口**---> 弥补了Java单继承性的局限性。格式：`class AA extends BB implements CC,DD,EE`\n\n接口与接口之间可以继承，而且可以多继承。接口的具体使用，体现多态性。接口，实际上可以看做是一种**规范**。\n\n### Java 8 中关于接口的新规范\n\n- 知识点1：接口中定义的静态方法，只能通过接口来调用。\n- 知识点2：通过实现类的对象，可以调用接口中的默认方法。如果实现类重写了接口中的默认方法，调用时，仍然调用的是重写以后的方法。\n- 知识点3：如果子类(或实现类)继承的父类和实现的接口中声明了同名同参数的默认方法，那么子类在没重写此方法的情况下，默认调用的是父类中的同名同参数的方法。--> **类优先原则**\n- 知识点4：如果实现类实现了多个接口，而这多个接口中定义了同名同参数的默认方法，那么在实现类没重写此方法的情况下，报错。--> **接口冲突**。这就需要我们必须在实现类中重写此方法。\n- 知识点5：如何在子类(或实现类)的方法中调用父类、接口中被重写的方法\n\n### 抽象类和接口的异同\n\n- 相同点：都不能实例化；都可以包含抽象方法的。\n- 不同点：\n  - 把抽象类和接口(java7,java8,java9)的定义、内部结构解释说明\n  - 抽象类里可以没有抽象方法，但接口里都是抽象方法（Java 8之后可以定义默认方法）\n  - 抽象类中必须定义构造器，接口中不能定义构造器\n  - 类：单继承性，接口：多继承\n  - 类与接口：多实现\n\n## 异常\n\n**运行时异常**：\n\n- 是指编译器不要求强制处置的异常。一般是指编程时的逻辑错误，是程序员应该积极避免其出现的异常。`java.lang.RuntimeException`类及它的子类都是运行时异常。 \n- 对于这类异常，可以不作处理，因为这类异常很普遍，若全处理可能会对程序的可读性和运行效率产生影响。 \n\n**编译时异常**：\n\n- 是指编译器要求必须处置的异常。即程序在运行时由于外界因素造成的一般性异常。编译器要求Java程序必须捕获或声明所有编译时异常。\n- 对于这类异常，如果程序不处理，可能会带来意想不到的结果。\n\n### 常见异常\n\n![image-20210712202713944](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210712202713944.png)\n\n常见异常：\n\n- 空指针异常：`NullPointerException`\n- 数学运算异常：`ArithmetricException`\n- IO异常：`IOException`，例如`FileNotFoundException`\n- 数组越界异常：`ArrayIndexOutOfBoundsException`\n\n补充一些高级异常：\n\n- 并发修改异常：`ConcurrentModificationException`\n- 非法监控器状态异常：`IllegalMonitorStateException`（解锁的线程和占有锁的线程不同时会抛出）\n- 栈溢出异常：`StackOverflowError`\n- 内存溢出异常：`OutOfMemoryError`\n\n编译时异常与运行时异常：\n\n- 编译时异常：执行`javac.exe`命名时，可能出现的异常\n- 运行时异常：执行`java.exe`命名时，出现的异常\n\n![image-20210712203924066](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210712203924066.png)\n\n### 异常体系结构\n\n![image-20210712203715919](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210712203715919.png)\n\n### 异常总结\n\n![image-20210712203002466](/images/%E3%80%90Java%E3%80%91Java%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/image-20210712203002466.png)\n\n\n\n","tags":["Java"],"categories":["Java"]},{"title":"【Hexo】Hexo 常用命令与配置教程","url":"/2021/02/03/【Hexo】Hexo/","content":"## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n\n\n\n## Hexo 博客部署教程\n\n- https://its201.com/article/qq_46150940/105308878#_655\n- https://segmentfault.com/a/1190000021942348\n\n\n\n","tags":["Hexo"],"categories":["Hexo"]}]